{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_file = f'result/ContextLS/HC3/gpt_rewrite/HC3-random-800.json'\n",
    "watermark_file = 'result/ContextLS/HC3/z_score/HC3-random-800.json'\n",
    "z_score_file = f'result/ContextLS/HC3/z_score/gpt_rewrite/HC3-random-800.json'\n",
    "\n",
    "rewrite_dataset = json.load(open(rewrite_file))\n",
    "watermark_dataset = json.load(open(watermark_file))\n",
    "\n",
    "output = []\n",
    "for index in range(len(rewrite_dataset)):\n",
    "    output.append({\n",
    "        'text-index': rewrite_dataset[index]['text-index'],\n",
    "        'sentence-length': rewrite_dataset[index]['sentence-length'],\n",
    "        'ori-fast-z-score': watermark_dataset[index]['ori-fast-z-score'],\n",
    "        'water-fast-z-score': watermark_dataset[index]['water-fast-z-score'],\n",
    "        'rewrite-fast-z-score': rewrite_dataset[index]['z-score']\n",
    "    })\n",
    "\n",
    "os.makedirs(os.path.dirname(z_score_file), exist_ok=True)\n",
    "with open(z_score_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "original_dataest = json.load(open('result/ContextLS/M4/z_score/dolly-original-random-800.json'))\n",
    "watermark_dataest = json.load(open('result/ContextLS/M4/z_score/dolly-watermark-random-800.json'))[:252]\n",
    "dataset252 = json.load(open('result/ContextLS/M4/z_score/dolly/dolly-random-800-252.json'))[:226]\n",
    "dataset478 = json.load(open('result/ContextLS/M4/z_score/dolly/dolly-random-800-478.json'))\n",
    "z_score_result = []\n",
    "for index in range(0, 252):\n",
    "    z_score_result.append({\n",
    "        'text-index': original_dataest[index]['text-index'],\n",
    "        'sentence-length': original_dataest[index]['sentence-length'],\n",
    "        'ori-fast-z-score': original_dataest[index]['z-score'],\n",
    "        'water-fast-z-score': watermark_dataest[index]['z-score']\n",
    "    })\n",
    "for data1 in dataset252:\n",
    "    z_score_result.append(data1)\n",
    "for data2 in dataset478:\n",
    "    z_score_result.append(data2)\n",
    "os.makedirs(os.path.dirname('result/ContextLS/M4/z_score/dolly-random-800.json'), exist_ok=True)\n",
    "with open('result/ContextLS/M4/z_score/dolly-random-800.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(z_score_result, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548, 322)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "dataset252 = json.load(open('result/ContextLS/M4/z_score/dolly/dolly-random-800-252.json'))\n",
    "dataset478 = json.load(open('result/ContextLS/M4/z_score/dolly/dolly-random-800-478.json'))\n",
    "len(dataset252), len(dataset478)\n",
    "# result = []\n",
    "# for data in dataset252:\n",
    "#     result.append(data)\n",
    "# for data2 in dataset478:\n",
    "#     result.append(data2)\n",
    "# os.makedirs(os.path.dirname('result/ContextLS/M4/z_score/dolly-random-800.json'), exist_ok=True)\n",
    "# with open('result/ContextLS/M4/z_score/dolly-random-800.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(result, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "before_dataset = json.load(open('result/ContextLS/M4/rewrite/z_score/cohere-random-800.json'))\n",
    "after_dataset = json.load(open('result/ContextLS/M4/rewrite/z_score/cohere-random-800-87.json'))\n",
    "result = []\n",
    "for data1 in before_dataset[:87]:\n",
    "    result.append(data1)\n",
    "for data2 in after_dataset:\n",
    "    result.append(data2)\n",
    "os.makedirs(os.path.dirname('result/ContextLS/M4/rewrite/z_score/dolly-random-800.json'), exist_ok=True)\n",
    "with open('result/ContextLS/M4/rewrite/z_score/dolly-random-800.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dataset_87 = json.load(open('result/ContextLS/M4/rewrite/z_score/cohere-random-800-87.json'))\n",
    "dataset = json.load(open('result/ContextLS/M4/rewrite/z_score/cohere-random-800.json'))[:87]\n",
    "result = []\n",
    "for data1 in dataset:\n",
    "    result.append(data1)\n",
    "for data2 in dataset_87:\n",
    "    result.append(data2)\n",
    "os.makedirs(os.path.dirname('result/ContextLS/M4/rewrite/z_score/context-cohere-random-800-all.json'), exist_ok=True)\n",
    "with open('result/ContextLS/M4/rewrite/z_score/context-cohere-random-800-all.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 269, 7, 315)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "dataset = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800.json'))\n",
    "dataset_209 = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800-209_478.json'))\n",
    "dataset_478 = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800-478_485.json'))\n",
    "dataset_485 = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800-485.json'))\n",
    "len(dataset), len(dataset_209), len(dataset_478), len(dataset_485)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "watermark_dataset = json.load(open('result/ContextLS/M4/z_score/chatGPT-random-800.json'))\n",
    "\n",
    "dataset_209 = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800-209.json'))\n",
    "dataset_209_478 = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800-209_478.json'))\n",
    "dataset_478_485 = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800-478_485.json'))\n",
    "dataset_485 = json.load(open('result/ContextLS/M4/translate/store/context-chatGPT-random-800-485.json'))\n",
    "\n",
    "z_score = []\n",
    "\n",
    "for data2 in dataset_209:\n",
    "    z_score.append(data2)\n",
    "for data in dataset_209_478:\n",
    "    z_score.append(data)\n",
    "for data3 in dataset_478_485:\n",
    "    z_score.append(data3)\n",
    "for data4 in dataset_485:\n",
    "    z_score.append(data4)\n",
    "\n",
    "z_score_result = []\n",
    "for index in range(len(watermark_dataset)):\n",
    "    z_score_result.append({\n",
    "        'text-index':index,\n",
    "        'sentence-length': watermark_dataset[index]['sentence-length'],\n",
    "        'ori-fast-z-score':watermark_dataset[index]['ori-fast-z-score'],\n",
    "        'trans-fast-z-score':z_score[index]['z-score']\n",
    "    })\n",
    "\n",
    "\n",
    "os.makedirs(os.path.dirname('result/ContextLS/M4/translate/z_score/chatGPT-random-800-all.json'), exist_ok=True)\n",
    "with open('result/ContextLS/M4/translate/z_score/chatGPT-random-800-all.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(z_score_result, f, indent=4, ensure_ascii=False)\n",
    "len(z_score_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'c_idx': 658,\n",
       "  'sen_idx': 0,\n",
       "  's_idset_str': [4,\n",
       "   4,\n",
       "   8,\n",
       "   9,\n",
       "   1,\n",
       "   2,\n",
       "   0,\n",
       "   7,\n",
       "   6,\n",
       "   8,\n",
       "   7,\n",
       "   6,\n",
       "   1,\n",
       "   1,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   7,\n",
       "   1,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   0,\n",
       "   8,\n",
       "   2],\n",
       "  's_indices_str': [2, 2, 3, 4, 3],\n",
       "  'clean_wm_text': 'We present new measurements from a sample of galaxies with inclinations ranging from 30° to 80° derived from the Sloan Digital Sky Survey Data Release 7, including rotation width (W20) and surface brightness (SB).',\n",
       "  'keys_str': 'fresh new, sample specimen, Data Digital',\n",
       "  'message_str': [0, 0, 0]},\n",
       " {'c_idx': 658,\n",
       "  'sen_idx': 1,\n",
       "  's_idset_str': [9, 8, 7, 4, 1, 9, 0, 5, 7],\n",
       "  's_indices_str': [2, 0],\n",
       "  'clean_wm_text': 'We found that W20 has a strong correlation with the fixed luminosity of supernovae (SB), but exhibits poor or almost no correlation with galaxy mass.',\n",
       "  'keys_str': 'poorly weakly',\n",
       "  'message_str': [0]},\n",
       " {'c_idx': 658,\n",
       "  'sen_idx': 2,\n",
       "  's_idset_str': [5,\n",
       "   3,\n",
       "   1,\n",
       "   0,\n",
       "   2,\n",
       "   3,\n",
       "   9,\n",
       "   5,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   7,\n",
       "   6,\n",
       "   2,\n",
       "   0,\n",
       "   7,\n",
       "   6,\n",
       "   3,\n",
       "   5,\n",
       "   9,\n",
       "   6,\n",
       "   1,\n",
       "   7,\n",
       "   4,\n",
       "   5,\n",
       "   4],\n",
       "  's_indices_str': [8, 1, 4, 2, 3],\n",
       "  'clean_wm_text': 'This correlation still exists when we limit our analysis to late spiral galaxies known to have flat rotation curves.',\n",
       "  'keys_str': 'limit restrict, like type, flat flattened',\n",
       "  'message_str': [0, 0, 1]},\n",
       " {'c_idx': 658,\n",
       "  'sen_idx': 3,\n",
       "  's_idset_str': [6, 7, 9, 6, 2, 3, 9, 8, 1, 0, 3, 1, 7, 9, 1, 3, 8],\n",
       "  's_indices_str': [1, 5, 2, 1],\n",
       "  'clean_wm_text': 'These results indicate that the scatter observed in the Tully-Fisher relation may primarily be due to the variations in surface brightness (SB) among galaxies of similar luminosity, rather than differences in their mass.',\n",
       "  'keys_str': 'relation relationship, variants variations',\n",
       "  'message_str': [0, 0]},\n",
       " {'c_idx': 658,\n",
       "  'sen_idx': 4,\n",
       "  's_idset_str': [1,\n",
       "   7,\n",
       "   6,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   6,\n",
       "   6,\n",
       "   2,\n",
       "   7,\n",
       "   5,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   6,\n",
       "   2,\n",
       "   4,\n",
       "   7,\n",
       "   5,\n",
       "   3,\n",
       "   1,\n",
       "   0,\n",
       "   5,\n",
       "   9,\n",
       "   2,\n",
       "   6,\n",
       "   7,\n",
       "   9,\n",
       "   6,\n",
       "   2,\n",
       "   3,\n",
       "   9,\n",
       "   8],\n",
       "  's_indices_str': [1, 1, 1, 3, 1, 8, 2, 4],\n",
       "  'clean_wm_text': 'In addition, we indicate that this effect can explain why previous studies did not find a significant dependence on the direction angle in the TF relationship.',\n",
       "  'keys_str': 'past previous, discovered found, inclination orientation, relation relationship',\n",
       "  'message_str': [1, 0, 1, 1]},\n",
       " {'c_idx': 658,\n",
       "  'sen_idx': 5,\n",
       "  's_idset_str': [6, 7, 9, 6, 2, 3, 9, 8],\n",
       "  's_indices_str': [2, 0],\n",
       "  'clean_wm_text': 'Finally, we demonstrate how these correlations affect the estimate of the Hubble constant derived from the TF relation.',\n",
       "  'keys_str': 'relation relationship',\n",
       "  'message_str': [1]},\n",
       " {'c_idx': 658,\n",
       "  'sen_idx': 6,\n",
       "  's_idset_str': [1, 4, 7, 2, 2, 7, 6, 7, 8, 0, 2, 5, 9, 9, 8, 5],\n",
       "  's_indices_str': [1, 8, 2, 2],\n",
       "  'clean_wm_text': 'Our research results also provide an explanation for the significant differences in values obtained by different authors when selecting samples over various ranges of inclination angles.',\n",
       "  'keys_str': 'different separate, samples specimens',\n",
       "  'message_str': [1, 0]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "dataset = json.load(open('result/ContextLS/M4/translate/context-cohere-random-800-e.json'))\n",
    "dataset[658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "dataset0 = json.load(open('result/ContextLS/M4/translate/store/bloomz/context-bloomz-random-800.json'))[:95]\n",
    "dataset95 = json.load(open('result/ContextLS/M4/translate/store/bloomz/context-bloomz-random-800-95.json'))[:41]\n",
    "dataset135 = json.load(open('result/ContextLS/M4/translate/store/bloomz/context-bloomz-random-800-135.json'))[:526]\n",
    "dataset662 = json.load(open('result/ContextLS/M4/translate/store/bloomz/context-bloomz-random-800-662.json'))\n",
    "\n",
    "ori_dataset = json.load(open('result/ContextLS/M4/z_score/bloomz-random-800.json'))\n",
    "\n",
    "z_score = []\n",
    "for data in dataset0:\n",
    "    z_score.append(data)\n",
    "for data in dataset95:\n",
    "    z_score.append(data)\n",
    "for data in dataset135:\n",
    "    z_score.append(data)\n",
    "for data in dataset662:\n",
    "    z_score.append(data)\n",
    "\n",
    "z_score_result = []\n",
    "for index in range(len(ori_dataset)):\n",
    "    z_score_result.append({\n",
    "        'text-index': ori_dataset[index]['text-index'],\n",
    "        'sentence-length': ori_dataset[index]['sentence-length'],\n",
    "        'ori-fast-z-score':ori_dataset[index]['ori-fast-z-score'],\n",
    "        'trans-fast-z-score': z_score[index]['z-score']\n",
    "    })\n",
    "os.makedirs(os.path.dirname('result/ContextLS/M4/translate/z_score/bloomz-random-800-all.json'), exist_ok=True)\n",
    "with open('result/ContextLS/M4/translate/z_score/bloomz-random-800-all.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(z_score_result, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "dataset0 = json.load(open('result/ContextLS/M4/translate/store/cohere/context-cohere-random-800.json'))[:87]\n",
    "dataset87 = json.load(open('result/ContextLS/M4/translate/store/cohere/context-cohere-random-800-87.json'))[:571]\n",
    "# dataset657 = json.load(open('result/ContextLS/M4/translate/store/cohere/context-cohere-random-800-657.json'))\n",
    "dataset658 = json.load(open('result/ContextLS/M4/translate/store/cohere/context-cohere-random-800-658.json'))\n",
    "ori_dataset = json.load(open('result/ContextLS/M4/z_score/cohere-original-random-800.json'))\n",
    "\n",
    "z_score = []\n",
    "for data in dataset0:\n",
    "    z_score.append(data)\n",
    "for data in dataset87:\n",
    "    z_score.append(data)\n",
    "for data in dataset658:\n",
    "    z_score.append(data)\n",
    "\n",
    "z_score_result = []\n",
    "for index in range(len(ori_dataset)):\n",
    "    z_score_result.append({\n",
    "        'text-index': ori_dataset[index]['text-index'],\n",
    "        'sentence-length': ori_dataset[index]['sentence-length'],\n",
    "        'ori-fast-z-score':ori_dataset[index]['z-score'],\n",
    "        'trans-fast-z-score': z_score[index]['z-score']\n",
    "    })\n",
    "os.makedirs(os.path.dirname('result/ContextLS/M4/translate/z_score/cohere-random-800-all.json'), exist_ok=True)\n",
    "with open('result/ContextLS/M4/translate/z_score/cohere-random-800-all.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(z_score_result, f, indent=4, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
