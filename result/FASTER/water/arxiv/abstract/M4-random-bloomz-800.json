[
    {
        "original_text": "We study vacuum energy in quantum field theory with boundary conditions that break conformal invariance, such as Dirichlet or Neumann boundary conditions. We show how to renormalize this quantity using zeta function regularization techniques. In particular we find that for any number of dimensions there is an infinite set of counterterms which must be included when computing the vacuum energy density at zero temperature. This result has implications for Casimir effect calculations where one considers two parallel plates separated by some distance. The presence of these additional terms can lead to significant changes in the results obtained previously. Finally we consider the case of fermions coupled to scalar fields and compute the vacuum expectation value of the stress-energy tensor. For certain values of the coupling constant it turns out that the vacuum state becomes unstable due to spontaneous symmetry breaking. Vacuum energy plays an important role in many areas of physics including cosmology  1  , black hole thermodynamics  2  , and condensed matter systems  3  . It also appears in various contexts within string theory  4  .\nIn recent years much progress has been made towards understanding the nature of vacuum fluctuations in quantum field theories (QFTs)  5  -  8  . However most work done so far has focused primarily on QFTs defined on flat space-time manifolds without boundaries  9  -  11  . Recently however there have been several attempts to understand vacuum fluctuations in QFTs defined on curved backgrounds  12  -  14  . Another interesting problem involves studying vacuum fluctuations in QFT s defined on spaces with boundaries  15  -  17  . Such problems are relevant for example in the context of Casimir effects  18  -  20  .",
        "watermark_text": "We research vacuum energy in quantum field theory with boundary constraints that broke conformal invariance , such as Dirichlet or Neumann border conditions . We see how to renormalize this quantity use zeta function regularization techniques .In particular we find that for any number of dimensions there is an endless system of counterterms which requires be included when computing the vacuum energy density at zero temperature . This result has implications for Casimir effect calculations where one considers two adjacent plates connected by some distance .The presence of these additional terms can lead to significant changes in the results derived earlier . Finally we study the case of fermions connected to scalar fields and compute the vacuum expectation value of the strain - energy tensor .For specific values of the interaction factor it turns out that the vacuum state grows unstable due to spontaneous symmetry breaking . Vacuum energy serves an important role in multiple fields of science specifically cosmology 1 , white hole thermodynamics 2 , and condensed matter structures 3 .It additionally occurs in different settings within string theory 4 . In recent years much work has been achieved towards studying the nature of vacuum fluctuations in quantum field theories ( QFTs ) 5 - 8 .However most work done so far has concentrated mostly on QFTs defined on straight space - time manifolds without boundaries 9 - 11 . Recently however there have been numerous attempts to explain vacuum fluctuations in QFTs defined on curved backgrounds 12 - 14 .Another important task means analyzing vacuum fluctuations in QFT s characterized on spaces with borders 15 - 17 . Such issues are applicable for example in the context of Casimir interactions 18 - 20 .",
        "ori-fast-z-score": -1.0366421106976322,
        "water-fast-z-score": 7.0837210897671525
    },
    {
        "original_text": "We present the results of an optical spectroscopic survey of radio galaxies in clusters at redshifts z=0.4-0.8, carried out with the William Herschel Telescope (WHT). We find that the fraction of AGN-powered radio galaxies decreases towards higher galaxy density environments within the clusters. This is consistent with previous studies which have found evidence for environmental quenching of star formation activity among massive galaxies. However we also find that there are many examples where powerful radio sources reside in dense regions without any obvious signs of being environmentally suppressed. These objects may be undergoing rapid evolution or they could represent a population of recently accreted field galaxies whose properties are still evolving to resemble those of their local counterparts. The sample consists of 20 radio galaxies selected from the VLA-COSMOS 3 GHz Large Project catalogue (Smolčić et al., 2009) using the following criteria: 1) They lie in one of four X-ray luminous clusters at 0.4 < z < 0.8; 2) Their radio luminosity lies above L(3GHz) = 10 25 W Hz-1; 3) They do not show strong emission lines indicative of ongoing nuclear activity; 4) They were observed during our WHT run on 2010 May 24-25.",
        "watermark_text": "We present the conclusion of an optical spectroscopic study of radio stars in clusters at redshifts z = 0 . 4 - 0 . 8 , conducted out with the William Herschel Telescope ( WHT ) . We see that the fraction of AGN - powered radio stars reduces towards higher galaxy concentration environments within the clusters .This is consistent with previous research which have shown evidence for environmental quenching of galaxy formation activity among huge objects . However we also find that there are many instance where powerful radio sources exist in dense areas without any obvious signs of being environmentally suppressed .These bodies may be experiencing rapid evolution or they may contain a population of newly accreted field galaxies whose characteristics are still changing to reflect those of their nearby rivals . The sample consists of 20 radio objects chose from the VLA - COSMOS 3 GHz Large Project catalogue ( Smolčić et al . , 2009 ) applying the following criteria : 1 ) They sit in one of four X - ray luminous clusters at 0 . 4 < z < 0 . 8 ; 2 ) Their radio luminosity sits above L ( 3GHz ) = 10 25 W Hz - 1 ; 3 ) They do not show weak absorption tracks indicative of ongoing nuclear activity ; 4 ) They were detected during our WHT running on 2010 May 24 - 25 .",
        "ori-fast-z-score": -1.1793237883215741,
        "water-fast-z-score": 6.685631938613182
    },
    {
        "original_text": "We propose to use thermal noise as the information carrier for totally secure communications, zero power consumption devices, and computing systems. We show that by using an appropriate detection scheme, we can extract digital bits from the thermal noise with high fidelity at room temperature. The proposed system is based on a single-electron transistor (SET) which has been demonstrated in experiments recently. In addition, we demonstrate how this SET-based device can be used to perform logic operations such as AND gate and NOT gate. Finally, we discuss possible applications of our proposal including quantum key distribution, ultra-low power sensor networks, and energy efficient data centers. This work was supported by NSF under Grant No. ECCS-0926491. A new paradigm called  thermal noise informatics  is introduced where thermal noise is utilized as the information carrier for various tasks ranging from totally secure communication over wires to zero-power communication and computation. By employing an appropriate detection scheme, it is shown that one can extract digital bits from thermal noise with high fidelities even at room temperatures. It is also shown that these extracted digital bits can be used to perform logical operations such as AND gates and NOT gates. Possible applications are discussed along with their advantages compared to existing technologies.",
        "watermark_text": "We suggest to use thermal noise as the information carrier for totally secure services , zero power consumption devices , and computing systems . We see that by using an appropriate detection system , we can extract digital bits from the thermal noise with high fidelity at room temperature .The proposed system is based on a single - ion transistor ( SET ) which has been shown in experiments recently . In addition , we prove how this SET - based device can be used to conduct logic events such as AND gate and NOT gate .Finally , we review possible users of our proposal including molecular key transmission , ultra - low power detector networks , and energy effective data systems . This project was supported by NSF under Grant No .ECCS - 0926491 . A different technology called temperature noise informatics is adopted where thermal noise is utilized as the information carrier for various jobs ranging from completely secure transmission over wires to zero - energy transmission and computation .By using an appropriate detection system , it is demonstrated that one can extract digital bits from temperature noise with high fidelities even at room temperatures . It is also shown that these obtained digital frames can be used to conduct logical functions such as AND doors and NOT gates .Possible products are discussed along with their benefits compared to existing technologies .",
        "ori-fast-z-score": 1.3987572123604708,
        "water-fast-z-score": 8.541985556144386
    },
    {
        "original_text": "We present new constructions for locally decodable codes (LDCs) based on nice subsets of finite fields, prime factors of Mersenne numbers, and the Chinese remainder theorem. Our first construction is an explicit family of LDCs with optimal query complexity that are derived from nice subsets of finite fields. We then show how to use these results in conjunction with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the number of primes used in their construction. Finally we give a lower bound on the length of any LDC over a binary alphabet which uses only one-sided queries. The proofs of our main theorems appear at the end of this extended abstract. \nIntroduction\n\nLocally decodable codes (abbreviated as LCDs)\nare error correcting codes where each codeword has associated with it some decoding algorithm that allows efficient recovery of individual bits or symbols when queried about them. In particular, if the codeword is corrupted by up to t errors, then there exists a deterministic polynomial time algorithm that recovers the original uncorrupted word using O(t) queries per symbol. This property makes such codes useful in applications like data storage systems, peer-to-peer networks, and streaming media distribution services. \n \n A large body of work has been devoted towards understanding the trade-off between the rate of the code, its distance, and the query complexity of the decoder. For example, Guruswami et al. (2005), Chan et al. (2006) , and Kopparty & Saraf (2007)  studied the problem of constructing codes with low query complexity while maintaining high rates and distances. Recently, several works have focused on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain amount of corruption. These include the recent breakthrough result of Dvir et al. (2010a) (which improved upon the previous best-known upper bound due to Sudan et al., 2005 ) and the subsequent improvements made by Dvir et al. (2011 ), Feldman et al. (2012 , and Kopparty et al. (2013) . \n \n Another important",
        "watermark_text": "We introduce novel constructions for locally decodable codes ( LDCs ) based on pleasant subsets of finite fields , prime elements of Mersenne numbers , and the Chinese remainder theorem . Our first build is an explicit class of LDCs with optimal query complexity that are derived from good subsets of finite fields .We then show how to use these results in partnership with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the number of primes used in their design . Finally we give a smaller bound on the length of any LDC over a binary alphabet which uses only one - sided queries .The proofs of our major theorems emerge at the end of this enlarged abstract . Introduction Locally decodable codes ( denoted as LCDs ) are mistake correcting codes where each codeword has associated with it some decoding algorithm that enables efficient returning of individual characters or characters when queried about them .In particular , if the codeword is corrupted by up to t errors , then there exists a deterministic polynomial period algorithm that recovers the actual uncorrupted phrase using O ( t ) queries per symbol . This property gives such codes helpful in applications like data storage systems , peer - to - peer systems , and streaming media distribution services .A vast body of research has been focused towards studying the trade - off between the frequency of the code , its location , and the query complexity of the decoder . For instance , Guruswami et al .( 2005 ) , Chan et al . ( 2006 ) , and Kopparty & Saraf ( 2007 ) studied the question of constructing coding with little query complexity while maintaining high frequencies and distances .Recently , various efforts have concentrated on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain quantity of corruption . These include the recent breakthrough result of Dvir et al .( 2010a ) ( which updated upon the previous good - used upper bound due to Sudan et al . , 2005 ) and the subsequent improvements done by Dvir et al . ( 2011 ) , Feldman et al .( 2012 , and Kopparty et al . ( 2013 ) .Another important",
        "ori-fast-z-score": -0.40689422938557973,
        "water-fast-z-score": 7.021870595978444
    },
    {
        "original_text": "We present an analysis of the relativistic Riemann problem for ideal fluids in two space dimensions, with emphasis on the role played by vortex sheets. We show that the solution to this problem can be constructed as a sequence of self-similar solutions which are determined uniquely up to translations along the x-axis (the direction of propagation). The first step is to construct a family of exact solutions describing the interaction between a planar shock wave and a vortex sheet. These solutions have been obtained previously using different methods but we provide here a new derivation based on the method of characteristics. In particular, we obtain explicit expressions for the density and pressure profiles across the shock front. Next, we consider the case where the initial data consists of a single vortex sheet separating regions of constant density and pressure. This situation corresponds physically to a fluid initially at rest being accelerated impulsively by a piston moving at speed c = 1. We prove that there exists exactly one such solution corresponding to each value of the total mass M . Finally, we study numerically the evolution of more general initial data consisting of several vortex sheets separated by shocks.",
        "watermark_text": "We present an assessment of the relativistic Riemann problem for perfect fluids in two space dimensions , with emphasis on the part played by vortex sheets . We see that the solve to this question can be synthesized as a sequence of self - similar solutions which are decided uniquely up to translations along the x - axis ( the direction of propagation ) .The first step is to build a family of precise solutions governing the interaction between a planar blast flow and a vortex sheet . These solutions have been constructed previously using separate methods but we provide here a new derivation based on the method of characteristics .In particular , we obtain precise expressions for the density and tension characteristics across the shock front . Next , we find the case where the first data contains of a single vortex sheet separating areas of constant density and pressure .This problem corresponds physically to a fluid initially at rest being advanced impulsively by a cylinder moved at speed c = 1 . We prove that there exists precisely one such solution corresponding to each value of the total mass M .Finally , we study numerically the evolution of more general initial evidence consisting of several vortex strands divided by shocks .",
        "ori-fast-z-score": -0.7107423155935334,
        "water-fast-z-score": 5.858884758402822
    },
    {
        "original_text": "We propose a new string derived model with stable proton in which the lightest supersymmetric particle (LSP) is not neutralino but gravitino. The LSP decays into photon or neutrino-antineutrino pair through gravitational interaction. In this scenario we can explain the observed dark matter abundance without conflicting with other experimental results such as relic density measurement by WMAP experiment. We also show that our model predicts interesting signatures at LHC experiments. Introduction:-The discovery of Higgs boson  1-3  has opened up an exciting possibility to explore physics beyond Standard Model(SM). Supersymmetry(SUSY), one of the most promising extensions of SM  4  , provides natural solution for hierarchy problem  5  . However, SUSY models are severely constrained by various experimental observations  6  .\nIn order to solve these problems, several authors have proposed different mechanisms  7-9 . One of them is introducing additional gauge symmetries  10  . Another way is adding extra dimensions  11  . Recently, it was shown that there exists a class of string derived models where the lightest superpartner is gravitino  12  . Gravitino is weakly interacting massive particle so its decay rate is suppressed compared to neutralino case  13  . This feature makes gravitino a good candidate for cold dark matter  14  . Moreover, if gravitino mass m 3/2 < 1 GeV then its lifetime becomes longer than age of universe  15  . Therefore, gravitino may be regarded as a viable candidate for dark matter  16  . On the other hand, gravitino is unstable because it couples to gravity  17  . It decays into photon or lepton-neutrino pairs  18  . If gravitino is heavier than 100 MeV then its decay products will contribute to diffuse gamma ray background  19  . Thus, gravitino should satisfy following conditions  20  :",
        "watermark_text": "We suggest a new string derived model with stable proton in which the lightest supersymmetric object ( LSP ) is not neutralino but gravitino . The LSP decays into photon or neutrino - antineutrino bond through gravity interaction .In this situation we can describe the seen dark matter density without conflicting with other experimental outcome such as relic volume observation by WMAP study . We additionally prove that our model predicts exciting signatures at LHC experiments .Introduction : - The observation of Higgs boson 1 - 3 has opened up an exciting possibility to study physics beyond Standard Model ( SM ) . Supersymmetry ( SUSY ) , one of the most attractive extensions of SM 4 , offers natural solution for hierarchy problem 5 .However , SUSY models are severely constrained by various experimental studies 6 . In try to solve these problems , various scientists have proposed different processes 7 - 9 .One of them is adding additional gauge symmetries 10 . Another means is adding extra dimensions 11 .Recently , it was shown that there exists a class of string derived models where the lightest superpartner is gravitino 12 . Gravitino is weakly interacting massive object so its degradation rate is suppressed compared to neutralino case 13 .This characteristic makes gravitino a better contender for cold gray material 14 . Moreover , if gravitino mass m 3 / 2 < 1 GeV then its duration remains longer than age of universe 15 .Therefore , gravitino might be regarded as a viable contender for black matter 16 . On the other hand , gravitino is unstable because it couples to gravity 17 .It decays into photon or lepton - neutrino pairs 18 . If gravitino is heavier than 100 MeV then its degradation elements will contribute to diffuse gamma ray background 19 .Thus , gravitino should satisfy following conditions 20 :",
        "ori-fast-z-score": -0.19069251784911848,
        "water-fast-z-score": 6.620784138506228
    },
    {
        "original_text": "We report on the detection and characterization of a massive galaxy cluster, Abell S1063 (z = 0.90), using data obtained with the Wide Field Camera 3 (WFC3) aboard Hubble Space Telescope (HST). The cluster was discovered as part of an ongoing survey for distant clusters carried out by our team within the framework of the UKIRT Infrared Deep Sky Survey Data Release 8 (UKIDSS DR8). We use photometric redshifts to select galaxies that are likely members of this structure over a large area around its center. Using these candidates we identify two brightest cluster galaxies (BCGs) separated by about 1 arcmin along the line-of-sight. These BCGs have magnitudes mF160B = 20.6 ± 0.1 mag and mF140W = 21.0 ± 0.2 mag respectively. Their colors suggest they are both early-type galaxies.",
        "watermark_text": "We report on the discovery and description of a huge galaxy cluster , Abell S1063 ( z = 0 . 90 ) , using data acquired with the Wide Field Camera 3 ( WFC3 ) aboard Hubble Space Telescope ( HST ) . The cluster was discovered as part of an continuing survey for distant galaxies carried out by our team within the framework of the UKIRT Infrared Deep Sky Survey Data Release 8 ( UKIDSS DR8 ) .We use photometric redshifts to select clusters that are likely elements of this formation over a large area around its core . Using these candidates we identify two brightest cluster clusters ( BCGs ) connected by about 1 arcmin along the line - of - view .These BCGs have magnitudes mF160B = 20 . 6 ± 0 . 1 mag and mF140W = 21 . 0 ± 0 . 2 mag respectively . Their colors indicate they are both earliest - class objects .",
        "ori-fast-z-score": -0.6030226891555273,
        "water-fast-z-score": 4.824181513244218
    },
    {
        "original_text": "We present an analysis of the linear stability of epitaxially self-assembled quantum dots (QDs) on semiconductor surfaces, which are grown by molecular beam epitaxy under conditions where QDs form spontaneously and in regular arrays. We show that the QD ordering is determined by two competing mechanisms: surface diffusion and strain relaxation. The former tends to smooth out the QD density profile while the latter leads to its steepening. In particular we find that for small values of the QD size dispersion there exists a critical value of the growth rate above which ordered QD arrays cannot be formed. This result explains why it has been so difficult to grow ordered QD arrays with large QD sizes using conventional techniques. \n \n Keywords: Ordering, Strain Relaxation, Surface Diffusion, Quantum Dot Arrays, Stability, Growth Rate, Molecular Beam Epitaxy \n \n 1 Introduction \n \n Semiconductor nanocrystals or quantum dots (QDs), also known as colloidal quantum dots, have attracted considerable attention due to their unique optical properties  1  . They can be used in optoelectronic devices such as light-emitting diodes  2  , lasers  3  , solar cells  4  , photodetectors  5  , etc., and they may even play important roles in biological systems  6  .\n \nThe most common method for growing QDs is based on the so-called Stranski-Krastanov process  7, 8  . It involves depositing a thin layer of material onto a substrate at high temperatures followed by annealing at lower temperatures. Under these conditions islands nucleate randomly over the entire sample area but then evolve into ordered arrays through Ostwald ripening  9  . However, this technique does not allow one to control the position of individual QDs within each array  10  . Recently developed methods  11, 12  enable us to produce highly ordered QD arrays; however, they require very precise temperature control during deposition  13  . \n \n 2 Model Description \n \n Here we consider a model describing the formation of QDs on a two-dimensional lattice. Our starting point is the continuum equation proposed by Tersoff et al.  14  :",
        "watermark_text": "We present an assessment of the linear stability of epitaxially self - assembled quantum dots ( QDs ) on semiconductor surfaces , which are grown by molecular wave epitaxy under environments where QDs form spontaneously and in regular arrays . We see that the QD ordering is chosen by two different processes : material absorption and strain relaxation .The first helps to smooth out the QD density profile while the second contributes to its steepening . In particular we find that for low values of the QD width dispersion there exists a critical value of the growth rate above which organized QD arrays cannot be formed .This result explains why it has been so difficult to develop ordered QD arrays with large QD sizes using conventional methods . Keywords : Ordering , Strain Relaxation , Surface Diffusion , Quantum Dot Arrays , Stability , Growth Rate , Molecular Beam Epitaxy 1 Introduction Semiconductor nanocrystals or quantum dots ( QDs ) , sometimes called as colloidal quantum dots , have garnered considerable scrutiny due to their extraordinary optical properties 1 .They can be used in optoelectronic equipment such as light - emitting diodes 2 , lasers 3 , solar cells 4 , photodetectors 5 , etc . , and they may even hold important roles in biological environments 6 . The most common method for growing QDs is based on the so - called Stranski - Krastanov process 7 , 8 .It involves depositing a thin layer of material onto a substrate at high temperatures followed by annealing at lower temperatures . Under these conditions islands nucleate randomly over the entire sample region but then evolve into organized arrays through Ostwald ripening 9 .However , this methodology does not enable one to affect the placement of individual QDs within each array 10 . Recently developed methods 11 , 12 enable us to produce fully ordered QD arrays ; however , they demand very exact heat control during deposition 13 .2 Model Description Here we imagine a description explaining the formation of QDs on a two - dimensional crystal . Our opening point is the continuum equation proposed by Tersoff et al .14  :",
        "ori-fast-z-score": -0.6069769786668839,
        "water-fast-z-score": 6.219852664185793
    },
    {
        "original_text": "We present an experimental investigation into complementarity between position and momentum measurements on single photons using a modified version of the original Einstein-Bohr photon box experiment.  The results show that, for this particular measurement scheme, there is no violation of Bell s inequality or any other form of nonlocality. We also demonstrate how our setup can be used to investigate quantum contextuality by performing two different experiments with identical settings but opposite outcomes. In one case we observe violations of Bell inequalities while in the other they are not violated. This shows that the observed behavior cannot be explained within classical physics and demonstrates quantum contextuality. Quantum mechanics predicts that certain physical quantities such as position and momentum do not have simultaneous well-defined values. Instead these quantities exist only as probability distributions which evolve continuously over time according to Schrödinger s equation. However, it has been shown that if both position and momentum were measured simultaneously then their respective probabilities would interfere destructively resulting in a zero probability of measuring either quantity at its most probable value  1  . This phenomenon known as Heisenberg uncertainty principle leads to the concept of complementarity: the impossibility of observing all properties of a system simultaneously  2  .\nIn 1964 John Bell showed that local hidden variable theories could not explain some predictions made by quantum mechanics  3  , leading to the formulation of Bell s theorem  4  . Since then many experiments have been performed to test whether quantum mechanical predictions violate Bell s theorem  5  . These tests typically involve entangled particles  6  where each particle carries information about the state of another distant particle  7, 8  . If the particles are separated far enough so that they never interact again after being created, then the correlations between them must be due solely to quantum effects  9  .",
        "watermark_text": "We present an experimental inquiry into complementarity between position and momentum estimates on single photons using a altered version of the original Einstein - Bohr photon box observation . The results show that , for this special measurement scheme , there is no violation of Bell s inequality or any other form of nonlocality .We additionally prove how our setup can be used to examine quantum contextuality by performing two different trials with identical settings but different outcomes . In one instance we exhibit abuses of Bell inequalities while in the other they are not upheld .This shows that the seen behavior cannot be described within classical physics and demonstrates quantum contextuality . Quantum theory predicts that particular physical components such as position and momentum do not have simultaneous well - defined parameters .Instead these quantities occur only as probability distributions which evolution continuously over time according to Schrödinger s equation . However , it has been shown that if both position and momentum were calculated separately then their different probabilities would interfere destructively resulting in a zero probability of assessing either quantity at its most likely value 1 .This phenomenon known as Heisenberg uncertainty theory gives to the notion of complementarity : the impossibility of experiencing all characteristics of a system simultaneously 2 . In 1964 John Bell demonstrated that nearby secret variable theories cannot not understand some observations made by quantum mechanics 3 , leading to the realization of Bell s theorem 4 .Since then many tests have been performed to test whether quantum mechanical predictions violate Bell s theorem 5 . These studies typically involve entangled particles 6 where each particle contains information about the state of another distant particle 7 , 8 .If the molecules are apart farther enough so that they cannot interact again after being created , then the correlations between them need be due exclusively to quantum effects 9 .",
        "ori-fast-z-score": -0.17149858514250882,
        "water-fast-z-score": 8.231932086840423
    },
    {
        "original_text": "We report on the discovery of an X-ray pulsar, PSR J1814-1744, associated with the unidentified TeV gamma-ray source HESS J1813-178 in the Galactic plane at l = 18.6 deg., b = -0.1 deg.. The pulsar has spin period Psr = 2.16 s and is located within 0.2 arcmin (0.01 pc) of the centroid position determined by the High Energy Stereoscopic System (HESS). We also discovered a faint extended nebula around this pulsar using Chandra observations. This nebula shows a shell-like structure with radius Rneb ~ 1.5 arcmin (0.06 pc), which is consistent with that expected for a wind nebula powered by the pulsar s relativistic winds. The observed flux density of the nebula at radio wavelengths is Fν(3 GHz) ~ 3 mJy beam-1 , while its luminosity at X-rays is Lx ~ 1033 erg s-1 . These values are comparable to those seen in other young pulsars.",
        "watermark_text": "We report on the discovery of an X - ray pulsar , PSR J1814 - 1744 , associated with the unidentified TeV gamma - ray source HESS J1813 - 178 in the Galactic jet at l = 18 . 6 deg . , b = - 0 . 1 deg . . The pulsar has spin date Psr = 2 . 16 s and is situated within 0 . 2 arcmin ( 0 . 01 pc ) of the centroid point determined by the High Energy Stereoscopic System ( HESS ) .We additionally discovered a faint extended nebula around this pulsar utilizing Chandra measurements . This nebula shows a shell - like structure with diameter Rneb ~ 1 . 5 arcmin ( 0 . 06 pc ) , which is compatible with that expected for a wind nebula powered by the pulsar s relativistic winds .The observed flux concentration of the nebula at radio wavelengths is Fν ( 3 GHz ) ~ 3 mJy beam - 1 , while its luminosity at X - radiation is Lx ~ 1033 erg s - 1 . These figures are comparable to those observed in other young pulsars .",
        "ori-fast-z-score": 0.16012815380508713,
        "water-fast-z-score": 4.643716460347527
    },
    {
        "original_text": "We report on observations made by the High Energy Stereoscopic System (H.E.S. S.) telescope array in Namibia, which detected very-high-energy (VHE) gamma rays from the distant blazar  1ES1102-232 at redshift z = 0.186. The source was observed for more than 50 hours between September 2005 and March 2006 using data taken simultaneously with four telescopes. A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV. No significant variability is seen during this period. We present results from spectral analysis performed over different time intervals as well as broadband modelling of the multi-wavelength spectrum including radio through X-ray measurements. This work demonstrates that H.E.S.  S. can detect sources beyond redshifts previously accessible only to ground-based Cherenkov telescopes. It also shows how such observations are important for understanding the physics of these extreme objects.",
        "watermark_text": "We report on observations made by the High Energy Stereoscopic System ( H . E . S . S . ) telescope array in Namibia , which detected very - large - energy ( VHE ) gamma radiation from the distant blazar 1ES1102 - 232 at redshift z = 0 . 186 .The source was seen for more than 50 hours between September 2005 and March 2006 using data taken concurrently with four telescopes . A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV .No considerable variability is seen during this time . We see results from spectral study performed over different time periods as well as broadband analysis of the multi - wavelength spectrum including radio through X - ray observations .This research proves that H . E . S . S . can identify sources beyond redshifts previously accessible only to surface - based Cherenkov telescopes .It additionally shows how such observations are important for studying the physics of these extreme objects .",
        "ori-fast-z-score": 1.016001016001524,
        "water-fast-z-score": 5.505585837114527
    },
    {
        "original_text": "We present results for the evolution of magnetized protostellar accretion discs in which we have included both Ohmic and ambipolar diffusion, as well as radiative transfer effects using flux-limited diffusion (FLD). We find that the inclusion of these additional physical processes has important consequences for disc structure and evolution.  In particular, we show that the presence of an initial magnetic field can significantly affect the mass distribution within the disc at early times by suppressing fragmentation near the central star. This leads to more massive discs than those found previously with purely hydrodynamic simulations. The resulting discs are also less flared due to the increased pressure support provided by the magnetic field. As time progresses, however, the magnetic field is dissipated through ohmic dissipation and turbulence driven by gravitational instabilities. Once this happens, the disc becomes thinner and more flared compared to non-magnetic models.",
        "watermark_text": "We see results for the evolution of magnetized protostellar accretion balls in which we have incorporated both Ohmic and ambipolar diffusion , as well as radiative transfer effects utilizing flux - limited absorption ( FLD ) . We see that the introduction of these additional material processes has crucial consequences for disc composition and evolution .In particular , we find that the presence of an initial magnetic force can significantly affect the mass distribution within the disc at early periods by suppressing fragmentation near the main star . This leads to more massive discs than those identified previously with solely hydrodynamic simulations .The produced discs are also less flared due to the increased pressure support offered by the magnetic force . As time progresses , however , the magnetic force is dissipated through ohmic dissipation and turbulence driven by gravitational instabilities .Once this happens , the disc becomes thinner and more flared relative to non - magnetic models .",
        "ori-fast-z-score": 0.3511234415883917,
        "water-fast-z-score": 5.500933918218137
    },
    {
        "original_text": "We present the results of our investigation on semiclassical scalar propagator in curved space-time, which is based on the WKB approximation to the wave function. We show that there are two different ways how one can define this quantity depending on whether or not one takes into account the back-reaction effects due to the quantum fluctuations of the gravitational field. The first approach leads to an expression for the semiclassical propagator which coincides with the Feynman propagator at large distances but differs significantly near the source point. In particular it does not satisfy the Hadamard condition required by general relativity. On the other hand, if we take into account the back reaction then the resulting expression satisfies all necessary conditions including the Hadamard condition. However, as was shown recently by Wald et al., such an expression cannot be obtained within the framework of standard QFT. This problem may have important consequences when considering the propagation of particles through black holes since the corresponding expressions differ substantially even outside the horizon.",
        "watermark_text": "We present the conclusion of our analysis on semiclassical scalar propagator in curved space - time , which is based on the WKB approximation to the wave function . We see that there are two different ways how one can define this quantity based on whether or not one takes into consideration the back - reaction effects due to the quantum fluctuations of the gravitational field .The first method results to an definition for the semiclassical propagator which coincides with the Feynman propagator at large distances but varies dramatically near the origin point . In particular it does not satisfy the Hadamard condition required by general relativity .On the other hand , if we took into consideration the back response then the resulting expression satisfies all necessary circumstances including the Hadamard condition . However , as was shown lately by Wald et al . , such an form cannot be obtained within the framework of standard QFT .This problem could have important implications when examining the propagation of particles through black holes since the equivalent definitions differ substantially even outside the horizon .",
        "ori-fast-z-score": 0.5698028822981898,
        "water-fast-z-score": 5.128225940683707
    },
    {
        "original_text": "We present highly resolved numerical simulations of the incompressible Navier-Stokes equations with the LANS-alpha model, which is known to produce good results for wall-bounded flows at low Reynolds numbers. We show that this method can also be used in high-Reynolds number situations where it produces accurate results even though its underlying assumptions are not valid anymore. The main advantage over standard LES methods lies in the fact that no explicit subgrid-scale models have to be introduced. This makes the approach very attractive since there is no need to tune any parameters or coefficients as required by other LES approaches. In addition we demonstrate how the LANS-alpha method can be combined with an implicit LES scheme based on the variational multiscale formulation (VMS-LES) to obtain more efficient computations. Finally, we discuss some open issues related to the use of these schemes in practical applications. Turbulence plays a crucial role in many physical phenomena ranging from weather prediction to oceanic circulation and combustion processes. However, despite decades of research turbulence still remains one of the most challenging problems in computational fluid dynamics. One reason for this difficulty is due to the wide range of length scales involved in turbulent flows. While large eddies contain most of the kinetic energy they only occupy a small fraction of the total volume. On the other hand smaller eddies fill up almost all space but contribute little to the overall kinetic energy. Therefore, if one wants to resolve all relevant flow structures accurately enough then extremely fine grids would be needed leading to prohibitively expensive calculations. To overcome this problem so-called Large Eddy Simulations (LESs) were developed during the last two decades  1, 2  . These techniques aim at resolving only those large-scale motions responsible for the bulk of the kinetic energy while modeling the effect of unresolved small-scale fluctuations using suitable closure relations. Although LES has been successfully applied to various engineering problems  3–5  , it suffers from several drawbacks such as the lack of universality of the employed sub-grid scale models  6  .\nIn recent years new classes of LES-like methods have emerged  7–10  . They are based",
        "watermark_text": "We create highly resolved numerical simulations of the incompressible Navier - Stokes equations with the LANS - alpha simulation , which is known to produce excellent results for wall - defined currents at low Reynolds numbers . We see that this method can also be used in high - Reynolds number circumstances where it generates accurate conclusions albeit though its core assumptions are not valid anymore .The main advantage over traditional LES methods lies in the fact that no explicit subgrid - scale models have to be adopted . This makes the approach very appealing since there is no necessary to tune any coefficients or coefficients as required by other LES approaches .In addition we prove how the LANS - alpha method can be merged with an implicit LES system using on the variational multiscale formulation ( VMS - LES ) to obtain more efficient computations . Finally , we explain some open concerns relevant to the using of these schemes in practical applications .Turbulence plays a crucial role in many natural phenomena ranging from weather prediction to oceanic circulation and combustion cycles . However , despite decades of research turbulence nonetheless continues one of the most challenging difficulties in computational liquid mechanics .One reason for this difficulty is due to the broad variety of length scales implicated in turbulent streams . While big eddies contain most of the kinetic power they only comprise a small fraction of the total quantity .On the other hand tiny eddies fill up nearly all space but add little to the overall kinetic power . Therefore , if one wants to resolve all relevant stream dynamics correctly sufficiently then extremely good grids might be needed leading to prohibitively expensive calculations .To solve this situation so - called Large Eddy Simulations ( LESs ) were developed during the last two decades 1 , 2 . These methods aim at resolving only those huge - scale motions responsible for the majority of the kinetic power while solving the impact of unresolved small - scale fluctuations using appropriate completion relations .Although LES has been successfully applied to numerous technical problems 3 – 5 , it suffers from several drawbacks such as the lack of universality of the involved sub - grid size models 6 . In recent years new classes of LES - like methods have developed 7 – 10 .They are based",
        "ori-fast-z-score": -1.4122588778696161,
        "water-fast-z-score": 7.345410552159442
    },
    {
        "original_text": "We present new observations and analysis of the Balmer-dominated shocks driven by supernova remnants (SNRs) into dense molecular clouds, which are known as  molecular cloud shocks  or  Balmer-dominated shocks . We find that these shocks have an intermediate temperature between those of typical J-type and C-type shocks. The observed emission lines show prominent P-Cygni profiles with blueshifted absorption features indicating high velocities up to 100 km s-1 . These results suggest that the transition zone is located at the interface between the shocked gas and unshocked ambient medium. In addition, we found that the widths of the Hα line profiles increase toward the center of SNR W28. This indicates that the density structure of the surrounding environment may be more complicated than previously thought. Our study suggests that Balmer-dominated molecular cloud shocks can provide important information on the physical conditions of the interstellar medium around young SNRs.",
        "watermark_text": "We report new studies and investigation of the Balmer - dominated shocks driven by supernova remnants ( SNRs ) into thick molecular clouds , which are known as atom cluster shocks or Balmer - dominated shocks . We see that these shocks have an intermediate heat between those of typical J - class and C - class shocks .The observed emission lines show marked P - Cygni profiles with blueshifted emission elements suggesting high velocities up to 100 km s - 1 . These data suggest that the shift area is situated at the interface between the excited gas and unshocked ambient material .In addition , we recovered that the widths of the Hα line profiles increase toward the center of SNR W28 . This implies that the density structure of the nearby region might be more complicated than previously thought .Our study implies that Balmer - dominated molecular storm shocks can provide important information on the physical conditions of the interstellar medium around early SNRs .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.861993625888845
    },
    {
        "original_text": "We present new U BVRI photometric observations for the barred galaxy NGC 3367, obtained with the 1 m telescope at Cerro Tololo Inter-American Observatory (CTIO). The main goal is to study the stellar structures in this galaxy and their relation to its nuclear activity. We find that there are two bright knots along the major axis of the galaxy which may be associated with star formation regions. These knots have colors similar to those found in HII regions. In addition we detect several other faint knots on both sides of the nucleus. Their color indices suggest that they could also be related to recent star formation events. Finally, we identify an extended structure towards south-east direction whose nature remains unclear. This work was supported by CONACyT grant 36586-E. We thank J. M. Alloin for his help during our observing run at CTIO. Keywords: Starburst galaxies; Nuclear activity",
        "watermark_text": "We report new U BVRI photometric surveys for the barred star NGC 3367 , obtained with the 1 m observatory at Cerro Tololo Inter - American Observatory ( CTIO ) . The main goal is to study the stars formations in this galaxy and their connection to its nuclear activity .We see that there are two bright knots along the main axis of the galaxy which may be identified with star formation regions . These threads have colors similar to those present in HII centers .In addition we find several other slight knots on both sides of the nucleus . Their color indices indicate that they may also be connected to recent star formation changes .Finally , we identify an extended structure towards south - eastward direction whose nature remains unsure . This project was supported by CONACyT grant 36586 - E . We praise J . M . Alloin for his help during our observing run at CTIO .Keywords : Starburst galaxies ; Nuclear activity",
        "ori-fast-z-score": -0.48507125007266594,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We present new near-infrared integral field spectroscopy (IFS) data for the brightest galaxy in the cluster Abell 2218, which is known to be interacting with its nearest neighbor, the radio-quiet quasar I Zw 1 at z = 0.0625. We find that this galaxy has an extended low-surface-brightness component surrounding it, extending out to about 10 kpc on both sides along the major axis. This feature shows no evidence of rotation but does show some velocity structure consistent with infalling gas or tidal debris. In addition we detect two compact objects within 5 kpc of the center of the galaxy. One of these appears to have a very high surface brightness and may represent a nuclear starburst; however, the other one displays much lower surface brightness and could possibly be associated with a supermassive black hole binary system. These results are discussed in terms of possible evolutionary scenarios for this interacting pair.",
        "watermark_text": "We present new near - infrared integral field spectroscopy ( IFS ) statistics for the brightest galaxy in the cluster Abell 2218 , which is known to be interacting with its closest neighbor , the radio - quiet quasar I Zw 1 at z = 0 . 0625 . We see that this galaxy has an extended low - exterior - brightness core covering it , extending out to about 10 kpc on both sides along the main axis .This structure exhibits no evidence of rotation but does display some velocity pattern correlated with infalling dust or tidal debris . In addition we find two compact entities within 5 kpc of the center of the galaxy .One of these seems to have a very high surface brightness and may indicate a nuclear starburst ; however , the other one exhibits far lower surface brightness and could possibly be identified with a supermassive black hole binary system . These conclusions are discussed in terms of possible evolved situations for this interacting pair .",
        "ori-fast-z-score": 0.47140452079103173,
        "water-fast-z-score": 5.656854249492381
    },
    {
        "original_text": "We study the nonlinear perturbations of general relativity (GR) and other metric theories of gravity, focusing on their effects on conserved quantities such as energy-momentum tensors. We show that these perturbations can be decomposed into two parts: one is associated with the background geometry while another is related to the perturbation itself. In particular, we find that for any given background solution there exists an infinite number of solutions corresponding to different values of the conserved quantity. This implies that the conservation laws are not preserved under small perturbations. Furthermore, we demonstrate how this effect may lead to violations of the weak equivalence principle. Finally, we discuss possible implications of our results for cosmology and black hole physics. General relativity (GR), which describes gravitational interactions at large scales, has been tested extensively against observations over many decades  1  . However, it remains unclear whether or not GR also holds true at smaller length scales where quantum mechanics becomes important  2  .\nIn order to address this question, several alternative theories have been proposed  3  , including scalar-tensor theories  4  , f(R)-gravity  5  , massive gravity  6  , and so forth  7, 8  . These theories typically involve additional degrees of freedom beyond those present in GR  9  . For example, in scalar-tensor theories, the graviton acquires a mass through its coupling to a scalar field  10  . Similarly, in f(R)-theories  11  , the Einstein-Hilbert action contains higher-order curvature terms  12  . It turns out that both types of theories admit self-accelerating solutions  13  , i.e., de Sitter-like solutions without requiring dark energy  14  .",
        "watermark_text": "We research the nonlinear perturbations of general relativity ( GR ) and other metric explanations of gravitational , concentrating on their impacts on conserved parameters such as energy - momentum tensors . We see that these perturbations can be decomposed into two parts : one is associated with the background geometry while another is related to the perturbation itself .In particular , we find that for any given background solution there exists an endless number of solutions associated to different values of the conserved quantity . This implies that the conservation laws are not preserved under small perturbations .Furthermore , we explain how this effect could lead to infringement of the weak equivalence principle . Finally , we explain possible possibilities of our findings for cosmology and dark hole physics .General relativity ( GR ) , which explains gravitational interactions at large scales , has been tested extensively against measurements over numerous centuries 1 . However , it remains unsure whether or not GR still holds true at greater size scales where quantum mechanics becomes crucial 2 .In order to meet this question , various alternative theories have been proposed 3 , notably scalar - vector models 4 , f ( R ) - gravity 5 , giant gravity 6 , and so forth 7 , 8 . These explanations typically involve additional degrees of autonomy beyond those present in GR 9 .For instance , in scalar - vector theories , the graviton acquires a mass through its interaction to a scalar field 10 . Similarly , in g ( R ) - fields 11 , the Einstein - Hilbert action contains upper - order curvature terms 12 .It turns out that both types of theories admit self - accelerating problems 13 , i . e . , de Sitter - like solutions without using dark energy 14 .",
        "ori-fast-z-score": -1.4485719366802965,
        "water-fast-z-score": 6.454545454545454
    },
    {
        "original_text": "We report on the electronic structure and magnetic properties of zigzag graphene nanoribbons (ZGNRs) with different edge structures, including hydrogenated ZGNR (H-ZGNR), fluorinated ZGNR (F-ZGNR), oxygenated ZGNR (O-ZGNR), and nitrogen-doped O-ZGNR (N-ZGNR). We find that all these ZGNRs are half-metals except for H-ZGNR which is metallic. The band gaps of F-ZGNR and N-ZGNR increase as compared to those of pristine ZGNR due to the electronegativity difference between carbon atoms at edges and their neighbors. In contrast, the band gap decreases slightly when oxygen replaces one or two carbon atoms at each edge because of charge transfer from oxygen to neighboring carbon atom(s). Our results show that the spin polarization can be enhanced by introducing oxygen into the edges of ZGNRs.",
        "watermark_text": "We report on the electronic structure and magnetic properties of zigzag graphene nanoribbons ( ZGNRs ) with various edge structures , notably hydrogenated ZGNR ( H - ZGNR ) , fluorinated ZGNR ( F - ZGNR ) , oxygenated ZGNR ( O - ZGNR ) , and nitrogen - doped O - ZGNR ( N - ZGNR ) . We see that all these ZGNRs are half - metals except for H - ZGNR which is metallic .The band holes of F - ZGNR and N - ZGNR increase as compared to those of pristine ZGNR due to the electronegativity difference between carbon atoms at corners and their relatives . In comparison , the band gap falls slightly when oxygen replaces one or two carbon atoms at each edge because of charge transfer from nitrogen to neighboring carbon molecule ( s ) .Our results show that the spin polarization can be enhanced by bringing oxygen into the edges of ZGNRs .",
        "ori-fast-z-score": 0.5897678246195885,
        "water-fast-z-score": 3.8334908600273256
    },
    {
        "original_text": "We present the results of an analysis of all available data on cometary dust tails, including those observed by spacecraft and ground-based telescopes in recent years. We find that most of these objects are associated with Jupiter family comets (JFCs), which have orbital periods less than 20 yr. The JFCs produce dust tails that can be traced for up to several thousand AU along their orbits. These tails appear as narrow streams of material extending outward at high speed from the parent bodies. In some cases they show evidence of being disrupted into multiple fragments or branches. Most of the tail structures we observe are consistent with models where particles are released continuously over time scales ranging from months to thousands of years. However, there is growing observational evidence suggesting that many of these tails may also contain significant amounts of freshly produced dust grains ejected during more recent outburst events. This suggests that the production rate of dust particles in these systems varies significantly both spatially and temporally. \n \n Keywords: Comet",
        "watermark_text": "We publish the conclusion of an assessment of all available data on cometary dust tails , particularly those observed by satellites and land - based telescopes in recent seasons . We see that most of these objects are identified with Jupiter class comets ( JFCs ) , which have orbital periods fewer than 20 yr .The JFCs produce dust tails that can be traced for up to several thousand AU along their orbits . These tails occur as short streams of debris extending outward at high velocity from the parent bodies .In some cases they show proof of being disrupted into multiple pieces or limbs . Most of the tail structures we study are compatible with models where objects are released constantly over time ranges varied from months to thousands of years .However , there is growing observational evidence indicating that several of these tails might additionally carry significant amounts of newly released powder grains ejected during more recent outburst events . This implies that the production frequency of dust particles in these systems vary significantly both spatially and temporally .Keywords: Comet",
        "ori-fast-z-score": 0.10846522890932808,
        "water-fast-z-score": 7.979625217054442
    },
    {
        "original_text": "We present an effective model to study the properties of dense quark matter in the presence of large strange quarks masses, which are relevant for compact stars with high central density. The model is based on the Nambu-Jona-Lasinio (NJL) Lagrangian extended by including vector mesons as explicit degrees of freedom. We show that this extension allows us to reproduce simultaneously several features observed experimentally or theoretically in nuclear physics such as: i) saturation of nuclear matter; ii) appearance of hyperon resonances; iii) restoration of chiral symmetry at finite baryonic densities; iv) existence of a critical endpoint in the phase diagram of strongly interacting matter. In addition we find that our results agree well with recent lattice simulations performed within the framework of the PNJL model. Finally, we discuss how these findings can be used to explore new regions of the parameter space of the NJL model.",
        "watermark_text": "We present an efficient model to study the properties of dense quark matter in the presence of large odd quarks masses , which are important for compact stellar with high central density . The model is based on the Nambu - Jona - Lasinio ( NJL ) Lagrangian extended by including tensor mesons as explicit degrees of liberty .We see that this extension permits us to capture concurrently many features detected experimentally or theoretically in nuclear science such as : i ) saturation of nuclear material ; ii ) presence of hyperon resonances ; iii ) restoration of chiral symmetry at finite baryonic densities ; iv ) creation of a critical endpoint in the phase diagram of highly correlated matter . In addition we find that our findings agree well with recent lattice simulations conducted within the framework of the PNJL theory .Finally , we talk how these results can be used to study new regions of the parameter space of the NJL model .",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 5.898906801202691
    },
    {
        "original_text": "We present the first results on differential rotation for an evolved star, based on observations with the Microvariability and Oscillations of STars (MOST) satellite. The target is the F-type main-sequence star kappa 1 Cet (HD 128898), which has been observed in two consecutive runs during 2005-2006. We find that the surface shear rate decreases towards lower latitudes, but increases again at mid-latitudes. This behaviour can be explained if we assume that there are two differentially rotating regions on opposite sides of the equator. In addition to this large-scale pattern, we also detect smaller-scale features such as spots and plages. These structures appear to have lifetimes between one week and several months. Finally, we show how our results compare with theoretical predictions made using stellar evolution models. Keywords: Differential rotation; Stellar activity; Spots; Plages; MOST",
        "watermark_text": "We report the first findings on differential rotation for an evolved star , based on observations with the Microvariability and Oscillations of STars ( MOST ) satellite . The target is the F - class major - sequence star kappa 1 Cet ( HD 128898 ) , which has been observed in two consecutive ran during 2005 - 2006 .We see that the surface shear rate decreases nearer lower latitudes , but grows again at mid - latitudes . This behaviour can be described if we suppose that there are two differentially rotating zones on opposite sides of the equator .In addition to this big - scale signature , we also observe lower - scale characteristics such as spots and plages . These structures appear to have lifetimes between one month and many months .Finally , we tell how our findings compare with theoretical estimates made using stellar evolution models . Keywords : Differential rotation ; Stellar activity ; Spots ; Plages ; MOST",
        "ori-fast-z-score": -0.7745966692414834,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "We report the discovery of three planets orbiting an intermediate-mass subgiant star, HD 168625 (M = 1.5 Msun), using high-precision radial velocity measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile. The planet masses are 0.7 MJup , 2.1 MJup , and 3.2 MJup . We find that all three planets have orbital periods shorter than 100 days; two of them are close to their host stars (P orb < 10 d). All three planets are located within the habitable zone around their host star. This is one of only four systems known so far where more than one planet has been found inside this region.  These results demonstrate that it should be possible to detect terrestrial planets in the habitable zones of evolved stars by means of Doppler spectroscopy. Keywords: exoplanet, planetary system",
        "watermark_text": "We report the discovery of three planets orbiting an intermediate - weight subgiant star , HD 168625 ( M = 1 . 5 Msun ) , using high - precision radial speed measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile . The planet masses are 0 . 7 MJup , 2 . 1 MJup , and 3 . 2 MJup .We see that all three worlds have orbital periods shorter than 100 hours ; two of them are close to their host stars ( P orb < 10 d ) . All three planets are situated within the habitable zone around their host star .This is one of only four systems available so far where more than one planet has been seen inside this area . These data demonstrate that it should be possible to identify terrestrial worlds in the habitable zones of evolved planets by means of Doppler spectroscopy .Keywords: exoplanet, planetary system",
        "ori-fast-z-score": -0.29488391230979427,
        "water-fast-z-score": 3.5386069477175313
    },
    {
        "original_text": "We study pair production of doubly-charged scalars in association with two jets, which can be induced by both weak gauge bosons (W or Z) and photons via loops involving heavy fermions such as top quarks. We derive constraints on the masses of these particles using current experimental data for W+jets and Z+jets processes collected by ATLAS and CMS experiments at the Large Hadron Collider (LHC). In addition to the standard model backgrounds, we also consider contributions from other new physics models that may have similar signatures. The results are presented in terms of exclusion limits on the mass parameters of various new physics scenarios. Finally, we discuss possible signals of this process at future runs of the LHC. PACS numbers: 12.60.Jv, 13 .85.Rm, 14.80.Ly \nI. INTRODUCTIO N\nThe discovery of neutrinos has opened up an exciting possibility of probing beyond Standard Model (SM), especially its Majorana nature  1  , through their lepton number violating interactions  2  . One interesting scenario is the seesaw mechanism  3  where SM singlet right-handed neutrinos acquire large Majorana masses after electroweak symmetry breaking  4  .\nIn order to test whether the observed light neutrinos are indeed Majorana particles, one needs to look for lepton-number-violating processes mediated by virtual heavy neutrinos  5  . These include neutrinoless double beta decay  6  , tritium beta decay  7  , and charged-current quasielastic scattering  8  . However, it turns out that all these processes suffer from severe astrophysical and/or nuclear matrix element uncertainties  9  . On the other hand, colliders provide clean environments to probe lepton number violation directly  10  . For example, searches for same-sign dileptons  11  and trileptons  12  at hadronic colliders could lead to important information about Majorana neutrinos  13  . Another promising channel is the production of doubly-charge scalar particles  14  , which can occur either through s-channel exchange of neutral gauge bosons  15  or t-channel exchange of heavy ferm",
        "watermark_text": "We research pair production of doubly - charged scalars in association with two jets , which can be induced by both weak gauge bosons ( W or Z ) and photons via loops involving heavy fermions such as top quarks . We derive restrictions on the masses of these ions using current experimental evidence for W + jets and Z + jets interactions collected by ATLAS and CMS observations at the Large Hadron Collider ( LHC ) .In addition to the standard description backgrounds , we also consider contributions from other recent physics systems that might have related signatures . The results are presented in terms of exclusion limits on the mass parameters of several novel physics scenarios .Finally , we explain possible transmissions of this process at next ran of the LHC . PACS scores : 12 . 60 . Jv , 13 . 85 . Rm , 14 . 80 . Ly I . INTRODUCTIO N The observation of neutrinos has opened up an exciting possibility of probing beyond Standard Model ( SM ) , particularly its Majorana nature 1 , through their lepton size violating interactions 2 .One interesting scenario is the seesaw mechanism 3 where SM singlet right - handed neutrinos gain big Majorana masses after electroweak symmetry breaking 4 . In order to test whether the seen light neutrinos are indeed Majorana objects , one needs to search for lepton - number - violating reactions mediated by virtual heavy neutrinos 5 .These include neutrinoless double alpha emission 6 , tritium alpha emission 7 , and charged - current quasielastic emission 8 . However , it turns out that all these mechanisms suffer from severe astrophysical and / or radioactive matrix element uncertainties 9 .On the other hand , colliders provide clean environments to probe lepton total violation directly 10 . For instance , searches for same - sign dileptons 11 and trileptons 12 at hadronic colliders may yield to key information about Majorana neutrinos 13 .Another promising channel is the production of doubly - charge scalar particles 14 , which can occur either through s - channel exchange of neutral gauge bosons 15 or t - channel exchange of heavy ferm",
        "ori-fast-z-score": 1.1188618555710317,
        "water-fast-z-score": 7.315635209502899
    },
    {
        "original_text": "The stopping power for uranium ions was measured at the National Superconducting Cyclotrons Laboratory (NSCL) using a thick target method and an ion chamber placed downstream of the target.  The results are compared to calculations based on the TRIM code, which is used extensively by nuclear physicists studying heavy-ion reactions. A good agreement between experiment and theory has been found over most of the range studied here. However, there appears to be some discrepancy near the end of the range where the experimental data show less stopping than predicted by the TRIM calculation. This may indicate that the TRIM model underestimates the contribution of electronic excitation processes to the total stopping cross section. These measurements provide useful information about the behavior of uranium ions as they slow down through matter. They can also serve as input parameters into models describing the transport of energetic particles in matter. Stopping powers were determined experimentally for uranium ions incident upon thin targets of carbon, copper, gold, silver, lead, tin, aluminum, iron, nickel, titanium, molybdenum, tungsten, tantalum, niobium, zirconium, hafnium, ytterbium, and uranium metal. Measurements were made at NSCL s Heavy Ion Accelerator Facility using a thick-target method and an ion chamber located downstream of the target. Results are presented along with comparisons to theoretical predictions obtained from the TRIM computer program.",
        "watermark_text": "The stopping power for nuclear atoms was measured at the National Superconducting Cyclotrons Laboratory ( NSCL ) using a thick target technique and an ion chamber placed downstream of the target . The results are compared to calculations based on the TRIM code , which is utilized heavily by nuclear physicists studying heavy - ion reactions .A good agreement between experiment and theory has been seen over most of the range studied here . However , there seems to be some discrepancy near the end of the range where the empirical data demonstrate fewer stopping than expected by the TRIM calculation .This might suggest that the TRIM theory underestimates the impact of electronic excitation systems to the total stopping cross area . These measurements give valuable info about the activity of nuclear ions as they slow down through matter .They can also help as input parameters into experiments describing the travel of energetic particles in matter . Stopping powers were determined experimentally for nuclear atoms incident upon thin targets of carbon , copper , gold , platinum , lead , tin , iron , iron , nickel , titanium , molybdenum , tungsten , tantalum , niobium , zirconium , hafnium , ytterbium , and uranium metal .Measurements were made at NSCL s Heavy Ion Accelerator Facility using a thick - target technique and an ion chamber situated downstream of the target . Results are presented along with comparisons to theoretical estimates obtained from the TRIM computer program .",
        "ori-fast-z-score": 0.2873478855663454,
        "water-fast-z-score": 6.735753140545634
    },
    {
        "original_text": "The dystrophin-glycoprotein complex (DGC) is an essential component of the muscle cell membrane, which provides structural support to skeletal muscles during contraction.  The DGC consists of several proteins including dystrophin, sarcoglycans, syntrophins, dystrobrevins, and utrophin.   In Duchenne muscular dystrophy (DMD), mutations in the gene encoding for dystrophin lead to loss of this protein from the sarcolemma resulting in severe muscle wasting.  However, it has been shown that expression of utrophin can compensate for the absence of dystrophin by binding to other components of the DGC such as alpha-dystroglycan (alpha-DG).  This study investigated whether processing of beta-dystroglycan affects its ability to bind with utrophin or its homologous counterpart, dp116, using normal mouse Schwann cells (MSC) and mdx mice lacking functional dystrophin.  Beta-dystroglycan was found to be processed into two different forms in both MSCs and mdx sciatic nerves.  One form had a molecular weight similar to that observed in normal mouse brain tissue while another form showed higher mobility when compared to the first one.  Both forms were able to interact with utrophin but only the lower molecular weight form could also bind to dp116.  These results suggest that processing of betadystroglycan may affect its interaction with utrophin and/or dp116.",
        "watermark_text": "The dystrophin - glycoprotein compound ( DGC ) is an essential component of the muscle cellular membrane , which offers functional strength to skeletal muscles during contraction . The DGC contains of several proteins namely dystrophin , sarcoglycans , syntrophins , dystrobrevins , and utrophin .In Duchenne muscular dystrophy ( DMD ) , defects in the gene encoding for dystrophin lead to lack of this protein from the sarcolemma culminating in severe muscle wasting . However , it has been shown that expression of utrophin can alleviate for the absence of dystrophin by binding to other components of the DGC such as alpha - dystroglycan ( beta - DG ) .This study investigated whether processing of beta - dystroglycan affects its capacity to interact with utrophin or its homologous counterpart , dp116 , using normal mice Schwann cells ( MSC ) and mdx mice lacking functional dystrophin . Beta - dystroglycan was shown to be processed into two different versions in both MSCs and mdx sciatic nerves .One version had a molecular weight similar to that detected in regular mouse skull tissue while another form showed higher mobility when compared to the first one . Both types were ability to interact with utrophin but only the smaller molecular weight version could also bind to dp116 .These data suggest that processing of betadystroglycan might impact its interaction with utrophin and / or dp116 .",
        "ori-fast-z-score": 1.0660035817780522,
        "water-fast-z-score": 6.901297485020058
    },
    {
        "original_text": "Der Spinecho ist ein technisches Hilfsmittel, das bei der Messung von magnetischen Resonanzspektren verwendet wird.  Dieser Artikel beschreibt die Theorie eines longitudinalen Atomstrahl-Spinechos (LASE), der einen neuen Ansatz für den Einfluß einer Paritätsverlängung auf die Spin-Resonanzfrequenz enthält. Die Berechnungen zeigen, dass eine LASE-Berry-Phasenfunktion mit einem Winkel θ = π/4 gegenüber dem Zeitstrahl existiert. Der Einfluss dieser Phase auf die Frequenzen der Spin-Resonanz ist analysiert. Es ergibt sich daraus, dass die Anzahl der Spin-Resonanten im Bereich der Frequenzen  ω0 - Δω/2, ω0 + Δω/2  um 2θΔω/π erhöht werden kann.",
        "watermark_text": "Der Spinecho ist ein technisches Hilfsmittel , das bei der Messung von magnetischen Resonanzspektren verwendet wird . Dieser Artikel beschreibt die Theorie eines longitudinalen Atomstrahl - Spinechos ( LASE ) , der einen neuen Ansatz mit den Einfluß einer Paritätsverlängung auf die Spin - Resonanzfrequenz enthält .Die Berechnungen zeigen , dass eine LASE - Berry - Phasenfunktion mit einem Winkel θ = π / 4 gegenüber dem Zeitstrahl existiert . Der Einfluss dieser Phase auf die Frequenzen die Spin - Resonanz ist analysiert .Es ergibt sich daraus , dass der Anzahl die Spin - Resonanten um Bereich der Frequenzen ω0 - Δω / 2 , ω0 + Δω / 2 um 2θΔω / π erhöht werden kann .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 2.6726124191242437
    },
    {
        "original_text": "We present the Bridge algorithm, which is an efficient direct tree hybrid n-body method that can be used to simulate fully self-consistently star clusters in galactic potentials with arbitrary mass distributions. The Bridge algorithm combines the advantages of both direct-summation (DS) and tree methods by using DS only within small sub-groups of particles at each time step while solving the full system of equations on a tree. We show that this approach allows us to achieve high accuracy without sacrificing computational efficiency. In particular we demonstrate that our new code reproduces results obtained with the state-of-the-art treecode NBODY6++GPU very well even when simulating systems containing up to 10 million stars. This makes it possible to study the long-term dynamical evolution of open clusters as well as globular clusters orbiting around parent galaxies over many Gyr timescales. \n \n Keywords: Open cluster; Globular cluster; Galactic potential",
        "watermark_text": "We introduce the Bridge algorithm , which is an efficient direct tree hybrid n - bodies method that can be used to simulate fully self - consistently star clusters in galactic potentials with arbitrary mass distributions . The Bridge technique combines the advantages of both direct - summation ( DS ) and tree methods by using DS only within tiny sub - families of atoms at each time step while solving the full system of equations on a tree .We suggest that this methodology allows us to achieve high efficiency without sacrificing computational efficiency . In particular we prove that our new code reproduces data derived with the state - of - the - art treecode NBODY6 + + GPU very best even when simulating complexes containing up to 10 million stars .This gives it able to study the long - term dynamical development of open complexes as well as globular complexes orbiting around parent objects over many Gyr timescales . Keywords : Open cluster ; Globular cluster ; Galactic potential",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 3.771236166328254
    },
    {
        "original_text": "We present an extension to the standard model that includes gravity, based on Feynman s ideas about quantum gravity. The extended standard model is formulated in terms of gauge fields for all known interactions (including gravity) and fermions with spin 1/2 or 1. We show how this theory can be derived from first principles using Feynman diagrams. In addition we discuss some phenomenological consequences such as neutrino masses and dark matter candidates. Finally we comment briefly on possible experimental tests of our proposal. This work was supported by NSF grant PHY-0456747. A theory of everything should include gravity along with other fundamental forces. Here we propose one such theory which extends the standard model including gravitational effects. Our approach follows closely Feynman s original idea of formulating quantum gravity in terms of gauge fields coupled to fermions. Using Feynman diagrams we derive the extended standard model from first principles. Some phenomenological consequences are discussed, e.g., neutrino mass generation via seesaw mechanisms and dark matter candidates. Possible experiments testing our proposal are also mentioned.",
        "watermark_text": "We introduce an addition to the standard theory that encompasses gravity , built on Feynman s ideas about particle gravity . The extended standard theory is implemented in terms of gauge fields for all known interactions ( including gravity ) and fermions with spin 1 / 2 or 1 .We see how this theory can be derived from first principles utilizing Feynman diagrams . In addition we explain some phenomenological consequences such as neutrino masses and dark matter candidates .Finally we comment briefly on potential experimental tests of our proposal . This project was supported by NSF grant PHY - 0456747 .A description of things should involve gravity along with other fundamental forces . Here we undertake one such idea which extends the standard theory including gravitational interactions .Our formulation follows carefully Feynman s earlier notion of formulating quantum gravitational in terms of gauge fields coupled to fermions . Using Feynman diagrams we derive the extended standard description from first principles .Some phenomenological consequences are discussed , e . g . , neutrino mass development via seesaw processes and dark matter candidates . Possible experiments testing our proposal are also discussed .",
        "ori-fast-z-score": 1.1531133203941102,
        "water-fast-z-score": 8.07179324275877
    },
    {
        "original_text": "We have investigated whether pulsar timing observations can be used to detect gravitational waves by observing the Shapiro effect, which is caused by the passage of gravitational waves through space-time around the Earth and its companion star (the Sun). We find that this method will not work with current technology because it requires very accurate measurements of pulse arrival times over many years. However, we show how future radio telescopes could make such measurements if they are equipped with new technologies like phased-array feeds or digital backends. In addition, we discuss other possible methods using pulsar timing data to search for gravitational waves. Gravitational waves cause time delays between pulses emitted at different points on the surface of a rotating neutron star. These time delays depend on the distance between these points as well as their position relative to the line-of-sight towards the observer. The most prominent effects occur when the wave passes close to the Earth and its companion stars. This causes an additional delay known as the Shapiro effect  Shapiro 1964  . If one knows the positions of all pulsars within a globular cluster, then one can use the observed pulse arrival times to measure the distances between them. By comparing these measured distances with those predicted by general relativity, one can test whether Einstein s theory correctly describes gravity on large scales.",
        "watermark_text": "We have researched whether pulsar timing observations can be used to identify gravitational waves by observing the Shapiro phenomenon , which is caused by the travel of gravitational waves through space - time around the Earth and its companion star ( the Sun ) . We see that this process will not work with current technology because it takes very accurate measurements of pulse onset times over numerous years .However , we explain how new radio telescopes might making such measurements if they are installed with modern innovations like phased - array feeds or digital backends . In addition , we explain other possible methods using pulsar timing statistics to search for gravitational waves .Gravitational waves cause period delays between pulses emitted at different places on the surface of a rotating neutron star . These time delays rely on the distance between these points as also as their placement relative to the line - of - view towards the observer .The most notable effects happen when the wave passes close to the Earth and its companion stars . This creates an additional delay known as the Shapiro phenomenon Shapiro 1964 .If one understands the places of all pulsars within a globular cluster , then one can using the known pulse onset times to measure the distances between them . By matching these measured distances with those predicted by general relativity , one can test whether Einstein s concept correctly describes gravitational on huge scales .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.619839033907137
    },
    {
        "original_text": "We present Herschel Space Observatory observations at 70, 160, 250, 350, and 500 microns toward two fields centered on the densest parts of the Rho Ophiuchi (RO) molecular cloud complex. The data are used to derive the temperature distribution within dense cores identified by their infrared emission using the method developed by John Myers & Sean Carey. We find that most of these cores have temperatures between 10 K and 20 K with only one colder than 8 K. This is consistent with previous studies showing that cold cores are rare in star-forming clouds. Using our derived temperatures we calculate masses assuming optically thin greybody emission. These masses range from 0.1 Msun to more than 100 Msun. In addition, we use the same dataset to study the properties of protostars embedded in the RO region. We identify 16 Class I sources based on their spectral energy distributions and compare them to those found in other nearby star-forming regions such as Serpens South or Orion B North.",
        "watermark_text": "We present Herschel Space Observatory images at 70 , 160 , 250 , 350 , and 500 microns toward two fields centered on the densest parts of the Rho Ophiuchi ( RO ) molecular mist complex . The data are using to derive the temperature balance within dense cores identified by their infrared emission utilizing the method developed by John Myers & Sean Carey .We see that most of these cores have temperatures between 10 K and 20 K with only one colder than 8 K . This is consistent with previous research indicating that cool cores are scarce in star - creating clouds . Using our derived temperatures we estimate masses assuming optically thin greybody emission .These masses range from 0 . 1 Msun to more than 100 Msun . In addition , we utilize the same dataset to study the properties of protostars embedded in the RO region .We distinguish 16 Class I sources based on their spectral power distributions and contrast them to those present in other nearby star - creating areas such as Serpens South or Orion B North .",
        "ori-fast-z-score": 0.5163977794943222,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "We present an approach to temporal runtime verification based on monadic difference logic (MDL). MDL is a decidable fragment of first-order logic with the ability to express properties about sequences of states, such as those produced by model checkers or execution traces. We show how to translate formulas in this logic into automata and use these automata for monitoring executions against specifications expressed in MDL. Our translation preserves satisfiability and allows us to monitor infinite state systems. The resulting monitors are efficient enough that they can be used online during program execution. In addition we provide a method for reducing the size of the generated automata which makes them suitable for offline analysis. Finally, we demonstrate our technique on several examples including a Java implementation of the dining philosophers problem. This work was supported by NSF grant CCF-0430018. Keywords: Runtime verification, Automata theory, Model checking",
        "watermark_text": "We present an perspective to temporal runtime verification relying on monadic difference reasoning ( MDL ) . MDL is a decidable fragment of first - order calculus with the ability to define properties about strings of states , such as those generated by model checkers or execution traces .We see how to translate formulas in this reasoning into automata and use these automata for monitoring executions against specifications expressed in MDL . Our translation retains satisfiability and allows us to observe infinite state systems .The produced screens are powerful sufficient that they can be used internet during program processing . In addition we provide a technique for decreasing the size of the produced automata which makes them useful for offline analysis .Finally , we demonstrate our technique on several examples including a Java implementation of the dining philosophers problem . This work was supported by NSF grant CCF - 0430018 .Keywords : Runtime verification , Automata analysis , Model checking",
        "ori-fast-z-score": -1.5,
        "water-fast-z-score": 4.093146241443879
    },
    {
        "original_text": "We report on non-adiabatic effects in dissociative oxygen adsorption and desorption processes occurring at low temperatures (<100 K). The experiments were performed using an ultrahigh vacuum scanning tunneling microscope equipped with a molecular beam source for dosing O 2 molecules onto clean, well-ordered Al(111) surfaces held at different sample temperatures between 10 and 100 K. We find that the sticking probability decreases strongly when increasing the surface temperature due to thermal activation of vibrational modes which lead to non-collinearity of electronic states involved in the reaction process. This effect is also observed during the subsequent desorption of atomic oxygen from the surface. In addition we observe a pronounced dependence of the sticking coefficient on the kinetic energy of incident oxygen molecules: At high energies (>500 meV), where the molecule-surface interaction time becomes comparable or even shorter than typical vibrational periods, the sticking probability increases again as compared to lower kinetic energies.",
        "watermark_text": "We report on non - adiabatic effects in dissociative oxygen adsorption and desorption processes occurring at low temperatures ( < 100 K ) . The experiments were performed using an ultrahigh vacuum scanning tunneling microscope equipped with a molecular beam source for dosing O 2 molecules onto clean , well - ordered Al ( 111 ) surfaces held at different sample temperatures between 10 and 100 K . We find that the sticking probability decreases strongly when increasing the surface temperature due to thermal activation of vibrational modes which lead to non - collinearity of electronic states involved in the reaction process .This phenomenon is also observed during the subsequent desorption of atomic oxygen from the surface . In addition we study a noticeable dependence of the sticking coefficient on the kinetic power of incident oxygen molecules : At high energies ( > 500 meV ) , where the molecule - surface interaction rate gets comparable or especially shorter than typical vibrational intervals , the sticking likelihood grows again as compared to higher kinetic energies .",
        "ori-fast-z-score": 0.22086305214969307,
        "water-fast-z-score": 3.092082730095703
    },
    {
        "original_text": "We present the theory behind relativistic fluctuation theorems, which are exact relations between entropy production in nonequilibrium processes and fluctuations in equilibrium states. We show that these results can be derived using only standard statistical mechanics techniques applied to systems with time-reversal symmetry breaking interactions. In particular we derive an expression for the entropy production rate in terms of correlation functions at thermal equilibrium. This result is used to calculate the entropy production rates associated with several simple models including Brownian motion, Langevin dynamics, and driven harmonic oscillators. Finally, we discuss how our approach may be extended beyond classical physics. Relativistic fluctuation theorems provide exact relations between entropy production during non-equilibrium processes and fluctuations in corresponding equilibrium states. These results have been obtained by applying standard statistical mechanics methods to systems with broken timereversal invariance. Here we use this formalism to obtain expressions for the entropy production rate as well as other quantities such as heat currents in terms of correlation functions evaluated at thermal equilibrium. As concrete applications we consider several simple models including Browninan motion, Langevin dynamics and driven harmonic oscillators. \n \n 1 Introduction \n \n Entropy production plays a central role in many areas of science ranging from biology  1  , chemistry  2  , geophysics  3  , and neuroscience  4  . It has also become increasingly important in quantum information processing  5  where it provides a measure of irreversibility  6  . Despite its importance there remains no general method for calculating entropy production rates except in very special cases  7–9  . Recently, however, new theoretical tools based on fluctuation theorems  10–12  have emerged which allow one to relate entropy production directly to measurable properties of physical systems  13–18  . For example, in recent years there has been considerable interest in developing experimental schemes  19–21  capable of measuring entropy production rates in small isolated quantum systems  22  . Such experiments would enable direct tests of fundamental thermodynamic principles  23  and could potentially lead to practical devices for extracting work from heat baths  24  . \n \n 2 Classical fluctuation theorems \n \n Perhaps the most famous fluctuation theorem was first proposed by Jarzynski  10 ",
        "watermark_text": "We introduce the principle behind relativistic fluctuation theorems , which are exact relations between entropy production in nonequilibrium systems and fluctuations in equilibrium states . We see that these results can be derived using only typical statistical mechanics algorithms used to systems with time - reversal symmetry breaking processes .In particular we derive an definition for the entropy production rate in terms of correlation functions at heat equilibrium . This result is utilized to estimate the entropy production rates associated with many simple theories including Brownian movement , Langevin mechanics , and driven harmonic oscillators .Finally , we explain how our approach may be generalized beyond classical physics . Relativistic fluctuation theorems allow exact relations between entropy production during non - equilibrium processes and fluctuations in associated equilibrium states .These conclusions have been achieved by using conventional statistical mechanics models to systems with broken timereversal invariance . Here we utilize this formalism to obtain definitions for the entropy production speed as well as other quantities such as heat currents in terms of correlation functions evaluated at heat equilibrium .As concrete uses we treat various simple theories including Browninan movement , Langevin mechanics and driven harmonic oscillators . 1 Introduction Entropy production plays a central role in multiple fields of science diverse from biology 1 , chemistry 2 , geophysics 3 , and neuroscience 4 .It has additionally grown increasingly important in quantum information processing 5 where it gives a estimate of irreversibility 6 . Despite its significance there survives no general technique for calculating entropy production rates except in very exceptional cases 7 – 9 .Recently , however , new theoretical tools based on fluctuation theorems 10 – 12 have arose which allow one to relate entropy production immediately to measurable properties of physical structures 13 – 18 . For instance , in recent months there has been substantial interest in establishing experimental schemes 19 – 21 capable of calculating entropy production rates in small scattered quantum systems 22 .Such experiments would enable direct tests of fundamental thermodynamic principles 23 and could potentially lead to practical devices for extracting work from heat baths 24 . 2 Classical fluctuation theorems Perhaps the most famous fluctuation theorem was first proposed by Jarzynski 10",
        "ori-fast-z-score": 0.37371754637596794,
        "water-fast-z-score": 9.391485505499116
    },
    {
        "original_text": "We present the results on the metallicity distribution functions (MDFs) for stars at different latitudes and distances from the Galactic plane, based on spectroscopic data obtained by the Sloan Digital Sky Survey (SDSS). We find that MDFs are similar to each other within errors except those at |b| > 30° where there is an excess of metal-poor stars compared to the disk population. The fraction of metal-poor stars increases towards higher latitude. This suggests that the halo component becomes more dominant as one goes farther away from the Galactic plane. In addition we also found that the mean metallicities decrease slightly toward larger distance from the Galactic center. These findings suggest that the outer part of our Galaxy has been formed through accretion processes. \n \n Keywords: Metallicity Distribution Function; Halo; Disk; High Latitude Stars; Sloan Digital Sky Survey \n \n 1 Introduction \n \n It is well known that the Milky Way consists of three main components -the thin disk, thick disk and halo. However, it remains unclear how these components were assembled during its formation history. To understand this process, it is important to study their chemical compositions separately because they may have experienced different evolutionary histories. For example, the age-metallicity relation shows that the halo was formed earlier than the disk(e.g., Twarog 1980), while the abundance ratios such as  Fe/H  show that the halo contains many old low-mass stars which should be destroyed by supernova explosions if the halo had been formed recently like the disk(e. g., Nissen & Schuster 1997). \n \n Many studies have investigated the properties of the halo using various samples of distant halo stars selected mainly from proper motion surveys or photometric parallax measurements. Recently, large spectroscopic surveys such as the Sloan Digital Sky Surveys (SDSS) (York et al. 2000) , RAVE survey (Steinmetz 2003 )and SEGUE survey (Yanny et al. 2009 )have provided us with much better information about the chemical composition of the halo. Using",
        "watermark_text": "We present the conclusion on the metallicity distribution functions ( MDFs ) for stars at different latitudes and distances from the Galactic plane , using on spectroscopic data derived by the Sloan Digital Sky Survey ( SDSS ) . We see that MDFs are comparable to each other within errors except those at | b | > 30° where there is an accumulation of steel - weak stars compared to the disk community .The percentage of metal - low stars increases towards higher latitude . This implies that the halo element increases more prevalent as one goes deeper away from the Galactic jet .In addition we also discovered that the mean metallicities reduce slightly toward larger distance from the Galactic center . These studies imply that the exterior part of our Galaxy has been formed through accretion cycles .Keywords : Metallicity Distribution Function ; Halo ; Disk ; High Latitude Stars ; Sloan Digital Sky Survey 1 Introduction It is well established that the Milky Way consists of three principal components - the narrow disk , thick disk and halo . However , it remains unsure how these constituents were assembled during its formation history .To understand this process , it is important to study their chemical compositions separately because they may have experienced distinct evolutionary histories . For instance , the age - metallicity relation shows that the halo was formed earlier than the disk ( e . g . , Twarog 1980 ) , while the density proportions such as Fe / H indicate that the halo contains much young high - density stars which should be killed by supernova explosions if the halo had been formed recently like the disk ( e . g . , Nissen & Schuster 1997 ) .Many experiments have explored the properties of the halo utilizing diverse samples of distant halo stars selected mainly from proper motion surveys or photometric parallax observations . Recently , large spectroscopic studies such as the Sloan Digital Sky Surveys ( SDSS ) ( York et al .2000 ) , RAVE study ( Steinmetz 2003 ) and SEGUE study ( Yanny et al . 2009 ) have provided us with far better details about the chemical composition of the halo .Using",
        "ori-fast-z-score": -0.26013299085723596,
        "water-fast-z-score": 8.419756985347481
    },
    {
        "original_text": "We present the results of N-body simulations for open and globular star clusters with different initial conditions, including primordial binaries in various proportions (from 0 to 100%). We find that the fraction of binaries among all stars decreases as the cluster evolves due to dynamical interactions between single and binary stars. The decrease is more pronounced if there are initially many hard binaries or few soft ones. In addition, we show how the number of binaries depends on their binding energy distribution at birth. Finally, we compare our results with observations of real open and globular clusters. Our main conclusions are:  1) Open clusters have fewer binaries than globulars because they lose most of them during early evolution.  2) Binaries can be destroyed by three-body encounters even when the total number of binaries remains constant.  3) Hard binaries dominate over soft ones after several relaxation timescales t rh .",
        "watermark_text": "We present the conclusion of N - bodies simulations for open and globular star clusters with various initial conditions , covering primordial binaries in different proportions ( from 0 to 100 % ) . We see that the fraction of binaries among all stars reduces as the cluster evolves due to dynamical interactions between single and binary galaxies .The decrease is more pronounced if there are initially multiple tough binaries or few hard ones . In addition , we study how the number of binaries depends on their binding energy flow at birth .Finally , we compare our findings with observations of real open and globular nuclei . Our main results are : 1 ) Open clusters have fewer binaries than globulars because they losing most of them during early evolution .2 ) Binaries can be damaged by three - bodies interactions even when the total number of binaries remains constant . 3 ) Hard binaries dominate over soft ones after many relaxation timescales t rh .",
        "ori-fast-z-score": -1.6378460497066512,
        "water-fast-z-score": 4.0
    },
    {
        "original_text": "In this paper, we propose an autonomous distributed admission control scheme to improve the performance and fairness in wireless local area networks (WLANs). The proposed scheme is based on the concept that each station maintains its own queue length information by using the packet inter-arrival time at the physical layer. In addition, it uses the number of active stations as well as their transmission rates to determine whether or not new connections are admitted into the network. We show through simulation results that our scheme can achieve better throughput than existing schemes while maintaining good fairness among competing stations. Keywords: Wireless Local Area Networks, Packet Inter-Arrival Time, Fairness, Throughput Improvement. 1 Introduction With the rapid development of mobile computing devices such as laptops, PDAs, smart phones etc., there has been growing interest in providing high quality services over wireless local area networks (WLANS)  1  . However, due to limited bandwidth resources available in WLANs, efficient resource management becomes crucially important  2  .\nThe most widely used medium access control protocol in current commercial WLAN products is the IEEE 802.11 Distributed Coordination Function (DCF), which provides both contention-based channel access mechanism called Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA)  3  , and contention-free service via Point Coordinated Function (PCF)  4  . Although CSMA/CA allows multiple stations to share the same radio channel simultaneously without any centralized coordination, it suffers from poor system performance when the traffic load increases  5  . This problem is mainly caused by the hidden terminal effect  6  where two nodes may transmit packets to one another simultaneously causing collisions. To alleviate these problems, several approaches have been proposed  7 -10  . Among them, the authors in  8  introduced a simple but effective method known as Virtual Reservation Channel (VRC) to reduce the probability of collision between data frames transmitted by different stations. They also presented a modified version of VRC  9  to further enhance the performance of CSMA/CA under heavy loads. However, all these works assume that the number of active stations within the",
        "watermark_text": "In this paper , we propose an autonomous spread entry system scheme to ensure the performance and fairness in mobile regional region systems ( WLANs ) . The proposed system is based on the idea that each broadcaster keeps its own queue length information by using the message inter - arrival rate at the physical layer .In addition , it utilizes the quantity of active stations as well as their transmission rates to estimate whether or not fresh connections are admitted into the channel . We see through simulation data that our scheme can attain better throughput than existing schemes while maintaining good fairness among competing networks .Keywords : Wireless Local Area Networks , Packet Inter - Arrival Time , Fairness , Throughput Improvement . 1 Introduction With the fast development of mobile computing devices such as laptops , PDAs , smart phones etc . , there has been growing interest in providing superior grade services over wireless regional area networks ( WLANS ) 1 .However , owing to limited bandwidth assets available in WLANs , efficient resource control becomes crucially vital 2 . The most commonly used medium access control protocol in current consumer WLAN applications is the IEEE 802 . 11 Distributed Coordination Function ( DCF ) , which offers both contention - based network entry method called Carrier Sense Multiple Access with Collision Avoidance ( CSMA / CA ) 3 , and contention - free service via Point Coordinated Function ( PCF ) 4 .Although CSMA / CA enables many affiliates to share the same radio channel simultaneously without any centralized coordination , it suffers from poor system performance when the traffic burden rises 5 . This problem is mainly caused by the concealed terminal effect 6 where two nodes may transmit streams to one another simultaneously creating collisions .To reduce these problems , various approaches have been proposed 7 - 10 . Among them , the published in 8 developed a simple but effective technology called as Virtual Reservation Channel ( VRC ) to reduce the probability of collision between information frames transmitted by separate stations .They even presented a altered version of VRC 9 to further enhance the performance of CSMA / CA under heavy loads . However , all these works assume that the number of active stations within the",
        "ori-fast-z-score": -1.0999438818457405,
        "water-fast-z-score": 8.485281374238571
    },
    {
        "original_text": "We present the results on the super quantum mechanics (SQM) in dimer models with free fermion boundary conditions. We show that SQM is equivalent to the usual quantum mechanics for periodic boundary condition case. In addition we find that there are two different types of supersymmetric ground states depending on whether or not the number of particles N is even. For odd N , the ground state has zero energy but it does not have any degeneracy. On the other hand, when N is even, the ground state becomes doubly degenerate. The degeneracy can be understood by using the concept of parity symmetry breaking. Finally we discuss how our result fits into the general framework of supersymmetry. PACS: 11.10.Wx, 05.45.Mt, 11.15.Tk \nI. INTRODUCTORY REMARK\nIn this work we study the super quantum mechanics ( S Q M ) i n d im e r m odels w ith f ree fermi b oundary c o ndition s . T hese models were first introduced by Rokhsar et al  1  as an exactly solvable model which describes spin-1/2 Heisenberg antiferromagnet on a square lattice. They showed that these models exhibit many interesting properties such as spontaneous dimerization at low temperatures  2  .\nThe main purpose of this work is to investigate the effect of boundary conditions on the supersymmetric structure of the system. It turns out that the supersymmetric structure depends crucially on the boundary conditions imposed on the system. As will become clear later, the supersymmetric structure changes drastically if one switches between periodic and free-fermion boundary conditions.",
        "watermark_text": "We present the results on the super quantum mechanics ( SQM ) in dimer models with free fermion boundary rules . We see that SQM is analogous to the usual quantum mechanics for periodic border condition case .In addition we find that there are two different kinds of supersymmetric ground laws varying on whether or not the quantity of particles N is even . For odd N , the ground state has zero energy but it does not have any degeneracy .On the other hand , when N is even , the ground state remains doubly degenerate . The degeneracy can be understood by using the notion of parity symmetry breaking .Finally we talk how our consequence fits into the broad context of supersymmetry . PACS : 11 . 10 . Wx , 05 . 45 . Mt , 11 . 15 . Tk I .INTRODUCTORY REMARK In this research we study the super quantum mechanics ( S Q M ) i n d im e r m odels v ith f ree fermi b oundary c o ndition s . T hese models were first described by Rokhsar et al 1 as an exactly solvable theory which presents spin - 1 / 2 Heisenberg antiferromagnet on a square lattice .They showed that these models exhibit several interesting properties such as spontaneous dimerization at low temperatures 2 . The main aim of this research is to examine the impact of boundary rules on the supersymmetric composition of the system .It happens out that the supersymmetric structure depends crucially on the boundary rules imposed on the system . As will become clear afterwards , the supersymmetric geometry changes significantly if one switches between periodic and free - fermion boundary conditions .",
        "ori-fast-z-score": -1.165543034828717,
        "water-fast-z-score": 5.703745285369415
    },
    {
        "original_text": "We report on the discovery of an Einstein ring galaxy at z = 1.62, which is composed of two merging galaxies with different mass-to-light ratios (M/L). The lensing galaxy has M/LB = 0.7 ± 0.1 for B-band luminosity LB = 2 × 10^10L⊙, while its companion galaxy has M/LB > 5. We find that this system can be explained by a model where the lensing galaxy consists of both luminous and dark components, but the companion galaxy does not have any dark component. This suggests that the fraction of dark matter to total mass increases as one goes down in mass scale. \n \n Keywords: Dark Matter, Galaxy Evolution, Gravitational Lens, Massive Black Hole \n \n \n \n A&A proofs: manuscript no. ms \nThe existence of dark matter around galaxies is inferred mainly through gravitational lensing effects such as strong lensing or weak lensing. In particular, the presence of multiple images due to strong lensing provides us with information about the distribution of dark matter along the line-of-sight toward distant objects. However, it remains unclear how much dark matter exists within individual galaxies themselves because we cannot directly observe them. Here we present new results based on our ongoing survey program using Subaru/Suprime-Cam. Our target was selected from the Sloan Digital Sky Survey Data Release 7 photometric catalogs, and follow-up observations were carried out with Suprime-Cam mounted on the 8.2 m Subaru Telescope. As a result, we discovered a gravitationally lensed object at redshift z = 1.62 consisting of three images produced by a foreground galaxy acting as a lens. Two of these images are located close together near the center of the lensing galaxy, whereas the third image lies far away from the lensing galaxy. Using high-resolution Hubble Space Telescope imaging data taken under the Hubble Frontier Fields project, we found that there exist two merging galaxies in front of the background source. One of these galaxies shows clear signs of tidal interaction between itself and the other galaxy.",
        "watermark_text": "We report on the discovery of an Einstein circle star at z = 1 . 62 , which is composed of two combining galaxies with varying mass - to - light proportions ( M / L ) . The lensing galaxy has M / LB = 0 . 7 ± 0 . 1 for B - band luminosity LB = 2 × 10 ^ [UNK] , while its daughter galaxy has M / LB > 5 .We see that this scheme can be described by a theory where the lensing galaxy consists of both luminous and dark elements , but the companion galaxy does not have any dark element . This implies that the fraction of dark matter to total mass rises as one goes down in mass scale .Keywords : Dark Matter , Galaxy Evolution , Gravitational Lens , Massive Black Hole A & A proofs : book no . ms The nature of dark matter around galaxies is inferred mainly through gravity lensing effects such as powerful lensing or strong lensing .In particular , the presence of multiple images thanks to powerful lensing offers us with data about the distribution of dark matter along the line - of - view toward distant objects . However , it remains unclear how many dark matter exists within individual galaxies themselves because we lack directly observe them .Here we present new data based on our ongoing survey program use Subaru / Suprime - Cam . Our objective was selected from the Sloan Digital Sky Survey Data Release 7 photometric catalogs , and follow - up observations were carried out with Suprime - Cam mounted on the 8 . 2 m Subaru Telescope .As a result , we discovered a gravitationally lensed object at redshift z = 1 . 62 composed of three images produced by a foreground galaxy acting as a lens . Two of these images are situated close together near the center of the lensing galaxy , whereas the third picture sits far back from the lensing galaxy .Using high - resolution Hubble Space Telescope imaging information taken under the Hubble Frontier Fields program , we concluded that there exist two merging galaxies in ahead of the background source . One of these objects displays clear indication of tidal impact between itself and the other galaxy .",
        "ori-fast-z-score": -0.9538209664765319,
        "water-fast-z-score": 6.454972243679029
    },
    {
        "original_text": "We present cosmological hydrodynamic simulations that follow the formation of galaxy clusters in the preheating scenario, where gas is heated by an early generation of stars before it collapses into dark matter haloes. We compare our results with observations of X-ray luminosity-temperature relations (L-T) at z = 0 as well as temperature profiles out to large radii. Our simulated L-T relation agrees very well with observational data over three orders of magnitude in luminosity. The slope of the observed L-T relation steepens towards lower temperatures while we find no such trend in our simulation. This discrepancy may be due to additional heating mechanisms not included in our model or due to systematic uncertainties in the observational sample. In addition, we show that the entropy profile of our simulated cluster population can reproduce the shape of observed profiles within their scatter. However, there are significant differences between individual simulated clusters and real systems which could be caused by non-gravitational processes like AGN feedback.",
        "watermark_text": "We create cosmological hydrodynamic simulations that take the formation of galaxy galaxies in the preheating model , where gas is hot by an early generation of stars before it collapses into dark matter haloes . We relate our findings with observations of X - ray luminosity - temperature relations ( L - T ) at z = 0 as well as temperature profiles out to large radii .Our simulated L - T relation agrees very best with observational data over three orders of magnitude in luminosity . The slope of the reported L - T relation steepens towards lower elevations while we find no such trend in our modeling .This discrepancy may be due to extra heating factors not mentioned in our model or due to systematic uncertainties in the observational sample . In addition , we find that the entropy profile of our simulated cluster colony can mimic the shape of observed profiles within their scatter .However , there are significant variations between individual simulated clusters and actual environments which could be caused by non - gravitational processes like AGN feedback .",
        "ori-fast-z-score": -0.6974858324629157,
        "water-fast-z-score": 4.04145188432738
    },
    {
        "original_text": "The authors present the results of their study on the scattering between two protons and one neutron, which is known as the triton channel in nuclear physics.  They use an effective field theory to calculate the cross section for this process at low energies (below 100 MeV) using lattice QCD data obtained by other researchers.   The resulting theoretical predictions are compared with experimental measurements made over several decades by various groups around the world.    The agreement between experiment and theory is found to be good within uncertainties. This work was supported by the U.S. Department of Energy under Contract No. DE-AC02-05CH11231. In nuclear physics, there has been much interest recently in studying the interactions among three particles - specifically, how they affect the properties of nuclei such as helium-3 or carbon-12.  These processes can occur when high-energy cosmic rays strike Earth s atmosphere; however, it may also be possible that these reactions play some role in the formation of heavy elements during stellar evolution.  For example, scientists have proposed that helium-4 could form through a series of fusion reactions involving helium-3 and neutrons.  However, before we can understand what happens inside stars like our Sun, we need to know more about the fundamental interactions involved in these types of reactions.  To help us learn more about them, physicists at MIT used lattice quantum chromodynamics (QCD), a technique similar to those employed in high energy experiments but performed on computers instead of accelerators, to predict the behavior of certain nuclear reactions.  Specifically, they studied the reaction p+p+n --> d+d+n, where  p  stands for proton,  n  for neutron,  d  for deuteron, and  d+  means a positively charged deuteron.  Their calculations were based on...",
        "watermark_text": "The authors present the conclusion of their experiment on the scattering between two protons and one neutron , which is known as the triton channel in nuclear physics . They use an efficient field model to estimate the cross section for this process at low energies ( below 100 MeV ) using lattice QCD evidence derived by other researchers .The resulting theoretical estimates are compared with observation observations made over numerous generations by various groups around the world . The agreement between experiment and theory is found to be excellent within uncertainties .This project was supported by the U . S . Department of Energy under Contract No . DE - AC02 - 05CH11231 .In nuclear science , there has been much interest notably in investigating the interactions among three particles - particularly , how they impact the properties of nuclei such as helium - 3 or carbon - 12 . These mechanisms can occur when high - energy cosmic rays strike Earth s atmosphere ; however , it could also be possible that these reactions serve some role in the formation of heavy metals during stellar evolution .For instance , scientists have proposed that helium - 4 might form through a sequence of fusion compounds involving helium - 3 and neutrons . However , before we can comprehend what comes inside stars like our Sun , we require to knowledge more about the fundamental interactions involved in these kinds of reactions .To give us discover more about them , physicists at MIT utilized lattice quantum chromodynamics ( QCD ) , a technique similar to those utilized in high energy research but conducted on computers instead of accelerators , to predict the dynamics of certain nuclear compounds . Specifically , they examined the response pp + p + n - - > d + d + n , where p sits for proton , k for neutron , d for deuteron , and d + means a positively charged deuteron .Their calculations were based on...",
        "ori-fast-z-score": 1.044465935734187,
        "water-fast-z-score": 8.649670160944275
    },
    {
        "original_text": "The radial distribution of the inner magnetospheric (IM) plasma pressure is studied by analyzing the magnetic field and particle measurements made onboard two satellites at low altitude in the equatorial plane for an intense geomagnetic storm that occurred between March 1-5, 1982 . The results show that there are significant differences in the IM plasma pressure profiles obtained with different satellites. In particular, the pressure profile derived from GEOS-1 observations shows a sharp peak near L = 3 , while those inferred from ATS-6 and GEOS-2 data exhibit much broader peaks around L = 4 . These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space. It is also found that the pressure profiles inferred from the three satellites agree well when they are shifted outward along the L-shell coordinate system. This suggests that the observed difference in the pressure profiles can be attributed mainly to the spatial variation of the pressure rather than temporal changes.",
        "watermark_text": "The radial distribution of the inner magnetospheric ( IM ) plasma pressure is studied by analyzing the magnetic field and particle measurements made onboard two spacecraft at low height in the equatorial plane for an extreme geomagnetic cyclone that occurred between March 1 - 5 , 1982 . The results show that there are significant variations in the IM plasma pressure profiles obtained with various satellites .In particular , the pressure model derived from GEOS - 1 studies shows a sharp peak near L = 3 , while those inferred from ATS - 6 and GEOS - 2 data display considerably wider peaks around L = 4 . These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space .It is also discovered that the pressure profiles inferred from the three satellites conform well when they are shifted outward along the L - shell coordinate system . This implies that the seen contrast in the pressure profiles can be due mainly to the spatial variation of the pressure rather than temporal changes .",
        "ori-fast-z-score": 1.4814874939752933,
        "water-fast-z-score": 5.584068246522259
    },
    {
        "original_text": "We present an analytic expression for the thermal Casimir force acting on two parallel plates made out of different materials, one being metallic (silver) while another is dielectric (silicon dioxide). The result obtained agrees with that derived by Lifshitz theory within 1% accuracy in the whole range of separations considered here. We also show how our results can be used to calculate the temperature dependence of the Casimir pressure at fixed separation distance. \n \n In this work we consider the case where one plate consists of silver and other of silicon dioxide. Silver has been chosen because it is widely used as a coating material in microelectromechanical systems (MEMS), whereas SiO2 is often employed as a substrate or insulator layer in MEMS devices. Our results are applicable not only to these specific cases but also to any system consisting of two parallel plates separated by vacuum gap filled with gas medium. This includes such diverse situations like semiconductor heterostructures, quantum dots, nanowires etc., which have attracted considerable attention recently due to their potential applications in nanotechnology. \n \n It should be noted that the problem under consideration was first addressed theoretically more than 50 years ago  1  . However, despite numerous attempts  2  , no exact solution has yet been found. Therefore, most theoretical studies were performed using approximate methods  3  -  6  . These approaches include various modifications of the proximity force approximation  7, 8  , the Derjaguin-Muller-Toporov method  9  , the multiple reflection expansion  10  , the scattering matrix formalism  11  , the Green s function technique  12  , the density functional theory  13  , the mode summation  14  , the fluctuating surface charge model  15  , the effective-medium theory  16  , the generalized plasmon-pole model  17  , the Drude-Lorentz model  18  , the hydrodynamic model  19  , the nonlocal response  20  , the local field correction  21  , the random phase approximation  22  , the Monte Carlo simulation  23  , the finite element method  24  , the numerical integration  25  , the variational principle  26  , the perturbation theory  27  , the renormalization group  28  , the self-consistent screening  29  ,",
        "watermark_text": "We present an analytic definition for the thermal Casimir force acting on two connected sheets formed out of different materials , one being metallic ( silver ) while another is dielectric ( silicon dioxide ) . The result obtained agrees with that derived by Lifshitz principle within 1 % accuracy in the whole range of separations mentioned here .We also demonstrate how our findings can be used to estimate the temperature dependence of the Casimir pressure at fixed separation distance . In this research we study the case where one plate contains of silver and other of silicon dioxide .Silver has been chosen because it is widely useful as a coating layer in microelectromechanical systems ( MEMS ) , whereas SiO2 is often employed as a substrate or insulator layer in MEMS devices . Our results are applicable not only to these individual cases but also to any system consisting of two connected sheets connected by vacuum gap filled with liquid medium .This encompasses such diverse situations like semiconductor heterostructures , quantum dots , nanowires etc . , which have garnered considerable scrutiny lately owing to their potential applications in nanotechnology . It should be mentioned that the issue under consideration was first addressed theoretically more than 50 centuries earlier 1 .However , despite several attempts 2 , no accurate solution has already been finding . Therefore , most theoretical experiments were performed using approximate methods 3 - 6 .These approaches involve various alterations of the proximity stress approximation 7 , 8 , the Derjaguin - Muller - Toporov method 9 , the multiple mirror expansion 10 , the scattering matrix formalism 11 , the Green s function method 12 , the density functional theory 13 , the mode summation 14 , the fluctuating surface charge model 15 , the effective - medium theory 16 , the generalized plasmon - pole hypothesis 17 , the Drude - Lorentz model 18 , the hydrodynamic model 19 , the nonlocal response 20 , the local field correction 21 , the random phase approximation 22 , the Monte Carlo simulation 23 , the finite element method 24 , the numerical integration 25 , the variational theory 26 , the perturbation theory 27 , the renormalization group 28 , the self - consistent screening 29 ,",
        "ori-fast-z-score": 1.5461980716652028,
        "water-fast-z-score": 7.7309903583260144
    },
    {
        "original_text": "We present new results on the evolution of the dust content in Lyman break galaxies (LBGs) using deep near-infrared data obtained by the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III program. We use these observations to study the rest-frame UV-optical properties of LBGs at redshifts 1<z<3.5. The main goal of this work was to investigate how the dust extinction evolves as a function of galaxy mass and star formation rate density over cosmic time. Our analysis shows that there are two different populations of LBGs: one population has low stellar masses (M*=10^10-10^11 Msun), high specific star formation rates (SSFR>100Gyr-1), and relatively small amounts of dust; while another population consists of more massive systems (M*>10^11Msun), lower SSFR values (SSFR<30Gyr-1), and higher levels of dust extinction. These findings suggest that the amount of dust increases with increasing galaxy mass for both local and distant galaxies.",
        "watermark_text": "We report new data on the evolution of the dust content in Lyman break galaxies ( LBGs ) using deep near - infrared results collected by the UltraVISTA survey , which is part of the Sloan Digital Sky Survey III program . We use these observations to study the rest - frame UV - optical properties of LBGs at redshifts 1 < z < 3 . 5 .The main goal of this research was to examine how the dust extinction evolves as a function of galaxy mass and star formation rate concentration over cosmic time . Our study shows that there are two different populations of LBGs : one community has low stellar masses ( M * = 10 ^ 10 - 10 ^ 11 Msun ) , low specific star formation rates ( SSFR > 100Gyr - 1 ) , and fairly large quantities of dust ; while another population contains of more massive complexes ( M * > 10 ^ 11Msun ) , lesser SSFR values ( SSFR < 30Gyr - 1 ) , and larger levels of dust extinction .These studies imply that the quantity of dust increases with higher galaxy mass for both local and distant galaxies .",
        "ori-fast-z-score": 1.1470786693528088,
        "water-fast-z-score": 5.735393346764043
    },
    {
        "original_text": "We report the discovery of an isolated white dwarf (WD) in the Sloan Digital Sky Survey Data Release 7, SDSSJ104341.53 + 085558.2, which has a large infrared excess and is surrounded by dusty material that may be part of a debris disc. The WD s temperature is T eff = 13000 ± 1000 K, its radius R wd = 0.0120 ± 0.0010 R ⊙ , and it has log g = 8.0 ± 0.1 cm s −2 . We find no evidence for binarity or accretion activity associated with this object. This is only the second known example of such a system; the first was GD 362. Our results suggest that these systems are rare but not unique among WDs. If confirmed, they would provide important constraints on models of planetary formation around WDs. \n \n Keywords: White dwarfs",
        "watermark_text": "We report the discovery of an isolated white dwarf ( WD ) in the Sloan Digital Sky Survey Data Release 7 , SDSSJ104341 . 53 + 085558 . 2 , which has a large infrared excess and is enclosed by dusty matter that might be part of a debris ring . The WD s temperature is T eff = 13000 ± 1000 K , its radius R wd = 0 . 0120 ± 0 . 0010 R [UNK] , and it has log f = 8 . 0 ± 0 . 1 cm s −2 .We see no evidence for binarity or accretion activity related with this object . This is only the second documented example of such a system ; the first was GD 362 .Our results show that these systems are unlikely but not unusual among WDs . If confirmed , they may provide important restrictions on estimates of planetary formation around WDs .Keywords: White dwarfs",
        "ori-fast-z-score": -0.29488391230979427,
        "water-fast-z-score": 4.423258684646914
    },
    {
        "original_text": "We propose to search for new physics in events with two energetic jets and large missing transverse energy (MET) using data collected by the CDF experiment during Run II of Fermilab s Tevatron Collider. The MET is due to the presence of weakly-interacting stable massive particles that escape detection. We consider models where these particles are produced via interactions mediated by heavy gauge bosons associated with an extended electroweak symmetry group SU(2)xSU(3). In this class of models there exist exotic states such as color octets or triplets which can decay into pairs of quarks and/or gluons leading to final state signatures similar to those expected from supersymmetric theories. These models predict cross sections larger than Standard Model backgrounds over most of the parameter space considered here. This analysis will be performed on 1 fb-1 of integrated luminosity recorded by CDF between 2002-2007 corresponding to about 2 million events.",
        "watermark_text": "We suggest to search for new dynamics in events with two energetic jets and large missing radial energy ( MET ) using data provided by the CDF project during Run II of Fermilab s Tevatron Collider . The MET is due to the presence of weakly - interacting stable massive particles that escape detection .We consider scenarios where these objects are produced via coupling facilitated by massive gauge bosons associated with an extended electroweak symmetry class SU ( 2 ) xSU ( 3 ) . In this class of models there exist unconventional states such as color octets or triplets which can evolve into sets of quarks and / or gluons leading to finished state signatures comparable to those expected from supersymmetric theories .These methods estimate cross sections larger than Standard Model backgrounds over most of the parameter room considered here . This assessment will be performed on 1 fb - 1 of integrated luminosity measured by CDF between 2002 - 2007 corresponding to about 2 million events .",
        "ori-fast-z-score": -0.7385489458759964,
        "water-fast-z-score": 4.185110693297313
    },
    {
        "original_text": "The BFKL equation is an effective theory for describing high-energy scattering processes at small Bjorken-x, where x denotes the fraction of longitudinal momentum carried by one of the colliding hadrons or nuclei. The BFKL formalism has been developed into a practical tool to calculate cross sections and structure functions using numerical methods. In this talk I will present recent results on the calculation of the gluon Green s function within the framework of the so-called  dipole approach  which allows us to perform calculations analytically. This method was first introduced by Mueller and Tang in order to study diffractive deep-inelastic scattering (DDIS) off protons. It can be applied also to other processes like heavy quark production in proton-proton collisions as well as photon-photon interactions. We will discuss how we have implemented these ideas numerically and show some preliminary results obtained with our code. Finally, we will comment on possible extensions of this work towards more realistic phenomenological applications.",
        "watermark_text": "The BFKL equation is an efficient model for describing long - energy scattering phenomena at small Bjorken - x , where x denotes the fraction of longitudinal momentum carried by one of the colliding hadrons or nuclei . The BFKL formalism has been built into a practical tool to estimate cross sections and structure functions using numerical models .In this talk I will present recent results on the determination of the gluon Green s function within the framework of the so - called dipole approach which allows us to conduct measurements analytically . This method was first developed by Mueller and Tang in order to study diffractive deep - inelastic reflection ( DDIS ) off protons .It can be applied also to other processes like heavy quark production in proton - proton collisions as well as photon - photon interactions . We will explore how we have formulated these ideas numerically and get some preliminary outcomes received with our code .Finally , we will mention on potential extensions of this research towards more realistic phenomenological applications .",
        "ori-fast-z-score": 0.601929265428846,
        "water-fast-z-score": 5.259005881071332
    },
    {
        "original_text": "The Blazhko effect is one of the most mysterious phenomena in pulsating stars, and it has been observed for more than 100 years now only on RR Lyrae-type variables (RR Lyr). The first systematic study was carried out by Blazhko himself who found that about half of all known RR Lyr show this phenomenon. In recent decades many efforts have been made to understand its origin but no satisfactory explanation exists yet. \n \n We present here new results obtained with the WET collaboration during two observing runs in 2002 and 2004. Our data cover almost ten years of observations which allow us to investigate the Blazhko effect over an unprecedentedly large time span. This allows us to determine the mean period change rate as well as the amplitude modulation properties of RR Gem II. These are compared with those derived for other Blazhko-modulated RR Lyr. \nWe find that our results agree very well with previous studies.",
        "watermark_text": "The Blazhko effect is one of the most unexpected processes in pulsating stars , and it has been observed for more than 100 years now only on RR Lyrae - class variables ( RR Lyr ) . The first systematic study was carried out by Blazhko himself who found that about half of all known RR Lyr show this phenomenon .In past decades several efforts have been made to comprehend its identity but no satisfactory excuse exists yet . We present here new data acquired with the WET collaboration during two observing walks in 2002 and 2004 .Our data cover nearly ten years of measurements which allow us to examine the Blazhko effect over an unprecedentedly large time frame . This enables us to study the mean period change rate as well as the frequency modulation properties of RR Gem II .These are compared with those generated for other Blazhko - modulated RR Lyr . We see that our findings agree very well with previous researchers .",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 5.75
    },
    {
        "original_text": "We report on an unusual bright optical transient (OT) discovered by the Palomar Transient Factory (PTF). The OT was detected at R = 16.7 mag and peaked at R = 14.6 mag, with a rise time of about 1 day. It is located near the center of M85, one of the nearest galaxies to our own Milky Way Galaxy. We find that this event has many properties similar to those observed for supernovae Ia but it lacks spectroscopic signatures typical of these events. This suggests that we are witnessing another type of explosion which may be related to some other types of transients such as tidal disruption flares or superluminous supernovae. \n \n Keywords: Supernova, Optical transient, PTF, Tidal disruption flare, Brightest cluster galaxy \n \n Introduction \n \n In recent years there have been several discoveries of extremely luminous optical transients associated with nearby galaxies. These include the famous outbursts of Eta Carinae (Davidson & Humphreys 1997; Smith et al. 1998), SN 2005ap (Gal-Yam et al. 2005; Foley et al. 2007), ASASSN-14li (Holoien et al. 2014a), ATLAS14aaq (Dong et al. 2015), PS1-10jh (Gezari et al. 2012), iPTF16axa (Kasliwal et al. 2016), and ASASSN-15oi (Shappee et al. 2016). Many of them were found to be associated with supermassive black holes residing in galactic nuclei. However, their exact nature remains unclear. Some authors suggested that they could be caused by tidal disruptions of stars by massive black holes (TDE) (Komossa 2002; Gezari et al. 2009a; Bloom et al. 2011; Holoien et al. 2013b; Arcavi et al. 2014; Brown et al. 2017), while others argued that they might represent new classes of thermonuclear explosions (SNe Ia-like) (Valenti et al. 2009; Kas",
        "watermark_text": "We report on an strange bright optical transient ( OT ) discovered by the Palomar Transient Factory ( PTF ) . The OT was measured at R = 16 . 7 mag and peaked at R = 14 . 6 mag , with a rise time of about 1 day .It is situated near the center of M85 , one of the nearest clusters to our own Milky Way Galaxy . We see that this event has numerous characteristics similar to those observed for supernovae Ia but it lacks spectroscopic signatures common of these events .This implies that we are witnessing another type of explosion which perhaps be connected to some other types of transients such as tidal disruption flares or superluminous supernovae . Keywords : Supernova , Optical transient , PTF , Tidal disruption explosion , Brightest cluster galaxy Introduction In recent history there have been numerous discoveries of incredibly luminous optical transients associated with nearby galaxies .These include the famous outbursts of Eta Carinae ( Davidson & Humphreys 1997 ; Smith et al . 1998 ) , SN 2005ap ( Gal - Yam et al .2005 ; Foley et al . 2007 ) , ASASSN - 14li ( Holoien et al .2014a ) , ATLAS14aaq ( Dong et al . 2015 ) , PS1 - 10jh ( Gezari et al .2012 ) , iPTF16axa ( Kasliwal et al . 2016 ) , and ASASSN - 15oi ( Shappee et al .2016 ) . Many of them were found to be identified with supermassive black holes residing in galactic nuclei .However , their exact form continues unclear . Some authors proposed that they may be caused by tidal disruptions of stars by massive black holes ( TDE ) ( Komossa 2002 ; Gezari et al .2009a ; Bloom et al . 2011 ; Holoien et al .2013b ; Arcavi et al . 2014 ; Brown et al .2017 ) , while others argued that they may signal new classes of thermonuclear explosions ( SNe Ia - like ) ( Valenti et al . 2009 ; Kas",
        "ori-fast-z-score": -0.9434563530497265,
        "water-fast-z-score": 3.249682993837947
    },
    {
        "original_text": "The Chandra X-ray Observatory has observed the supernova remnant (SNR) produced by SN1987A in the Large Magellanic Cloud for over ten years, providing an unprecedented view into this young and energetic object.  The observations have revealed that the blast wave is interacting with dense circumstellar material surrounding the progenitor star at velocities up to 1000 km/sec.  This interaction produces bright knots of emission which are seen as moving outward through the shell of the remnant.  These knots appear to be composed primarily of oxygen-rich ejecta mixed with shocked interstellar gas.  In addition, there appears to be a large amount of hot plasma trapped behind the forward shock front.  We present here new results on these features based on our analysis of data obtained during the first year of the Chandra mission. The Chandra X-ray Observatory has observed  the supernova remnant ( SNR ) produced by SN1987A , in the Large Magellan ic Cloud , for over ten years . It provides an unprecedented view into this y oung and en erg i c obj ect .  T he obse rvations ha ve reve al ed tha t th e b las t wa ve is interactin g wi th d ens e circumstell ar m aterial surroundi ng th e proge nitor star-at-rou nd -velocities up to 1 000 k m/ sec . Thi s interac tion produ ces brigh t kn ots of emi ssion wh ich appea r to be co mp osed pri marily of oxyg ene -rico h ej ec ta mixe d w ith sh ocked int erstel lar ga s .",
        "watermark_text": "The Chandra X - ray Observatory has observed the supernova remnant ( SNR ) produced by SN1987A in the Large Magellanic Cloud for over ten years , providing an remarkable insight into this young and intense object . The studies have revealed that the explosion wave is interacting with heavy circumstellar material surrounding the progenitor star at velocities up to 1000 cm / sec .This coupling generates bright knots of emission which are seen as traveling outward through the shell of the remnant . These knots appear to be composed primarily of oxygen - laden ejecta blended with shocked interstellar gas .In addition , there seems to be a large amount of bright plasma trapped behind the front shock front . We present here new data on these characteristics focusing on our analysis of evidence derived during the first year of the Chandra mission .The Chandra X - ray Observatory has observed the supernova remnant ( SNR ) produced by SN1987A , in the Large Magellan ic Cloud , for over ten years . It provides an remarkable view into this y oung and en erg i c obj ect .T he obse rvations ha ve reve al ed tha t th e f las t wa ve is interactin g wi th d ens e circumstell ar m aterial surroundi ng th e proge nitor star - at - rou nd - velocities up to 1 000 k m / sec . Thi s interac tion produ ces brigh t kn ots of emi ssion wh ich appea r to be co mp osed pri marily of oxyg ene - rico h ej ec ta mixe d w ith sh ocked int erstel lar ga s .",
        "ori-fast-z-score": 1.0425720702853738,
        "water-fast-z-score": 5.421374765483944
    },
    {
        "original_text": "The isobaric analog state (IAS) in nuclei has been studied by using the folding model with microscopic nucleon-nucleon interactions based on chiral effective field theory. The IAS was found to be sensitive to both the isoscalar and isovector parts of the nuclear matter density distribution as well as the strength of the spin-orbit interaction. In particular, it was shown that the IAS can provide useful information about the density dependence of the nuclear symmetry energy at subsaturation densities. It was also demonstrated that the effect of the tensor force on the IAS depends strongly on the choice of the nuclear mean-field potentials used for describing the ground-state properties of nuclei. Finally, we have discussed how one could extract the information about the nuclear symmetry energy from experimental data on the IAS in heavy nuclei. PACS numbers: 25.20.Lj, 27.60.+j, 29.40.+s",
        "watermark_text": "The isobaric analog state ( IAS ) in nuclei has been studied by using the folding method with microscopic nucleon - nucleon interactions using on chiral effective field model . The IAS was shown to be sensitive to both the isoscalar and isovector portions of the atomic matter density flow as also as the strength of the spin - orbit interaction .In particular , it was shown that the IAS can provide useful details about the density relation of the atomic symmetry power at subsaturation densities . It was also demonstrated that the impact of the tensor stress on the IAS depends strongly on the selection of the atomic mean - field potentials used for describing the ground - state properties of nuclei .Finally , we have explored how one might obtain the information about the atomic symmetry power from experimental evidence on the IAS in heavy nuclei . PACS codes : 25 . 20 . Lj , 27 . 60 . + j , 29 . 40 . + s",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.581563056514381
    },
    {
        "original_text": "We study the effect of radiative transfer (RT) on ultraviolet pumping of the 21 cm line at high redshifts, using cosmological hydrodynamic simulations with RT and without it. We find that RT can significantly enhance the strength of the 21 cm signal by up to an order of magnitude compared to calculations neglecting RT effects. The enhancement is caused mainly by Lyman-alpha photons produced inside galaxies which are absorbed outside them due to scattering off neutral hydrogen atoms. This leads to additional heating of the intergalactic medium through photoionization heating and Compton cooling. In addition we show that the inclusion of RT also changes the shape of the power spectrum of the 21 cm brightness temperature fluctuations. Our results suggest that future radio telescopes such as SKA will be able to detect this signal if they have sufficient sensitivity. Keywords: Hydrogen, Radiation transfer, Power Spectrum, Cosmic Dawn",
        "watermark_text": "We research the impact of radiative transfer ( RT ) on ultraviolet flow of the 21 cm line at high redshifts , using cosmological hydrodynamic simulations with RT and without it . We see that RT can significantly boost the strength of the 21 cm signal by up to an order of magnitude compared to calculations neglecting RT effects .The enhancement is caused mainly by Lyman - alpha photons generated inside galaxies which are reflected outside them due to scattering off neutral hydrogen atoms . This leads to extra heating of the intergalactic medium through photoionization heating and Compton heating .In addition we prove that the inclusion of RT also shifts the form of the power spectrum of the 21 cm brightness thermal fluctuations . Our results show that future radio telescopes such as SKA will be possible to identify this signal if they have sufficient sensitivity .Keywords : Hydrogen , Radiation exchange , Power Spectrum , Cosmic Dawn",
        "ori-fast-z-score": 0.39735970711951313,
        "water-fast-z-score": 5.165676192553671
    },
    {
        "original_text": "We report on the detection by HESS of an exceptional flaring activity in the very-high-energy (VHE) gamma-ray band for the blazar PKS 2155-304, which was observed between September and November 2007 with a flux doubling time scale as short as ~1 day. The source reached its highest recorded state ever detected at TeV energies during this period. We present results based on data taken simultaneously with Swift-XRT and UVOT instruments that show no significant change in X-ray or optical emission properties over the course of the outburst. This suggests that the high-energy emission is produced via inverse Compton scattering off relativistic electrons located close to the central black hole rather than synchrotron radiation emitted by particles accelerated up to high Lorentz factors within the jet itself. These findings are consistent with theoretical models where particle acceleration takes place in shocks formed when jets collide with surrounding clouds. Keywords: Blazars, Very High Energy Emission",
        "watermark_text": "We report on the discovery by HESS of an exceptional flaring activity in the very - large - energy ( VHE ) gamma - ray band for the blazar PKS 2155 - 304 , which was seen between September and November 2007 with a flux doubling time scale as short as ~ 1 hour . The source achieved its highest confirmed state yet detected at TeV energies during this era .We present results based on evidence drawn independently with Swift - XRT and UVOT instruments that demonstrate no major shift in X - ray or optical emission behavior over the course of the outburst . This implies that the high - energy emission is produced via inverse Compton absorption off relativistic electrons located close to the main white hole rather than synchrotron emission generated by particles advanced up to low Lorentz factors within the jet itself .These conclusions are compatible with theoretical theories where particle motion takes occur in shocks formed when jets collide with nearby clouds . Keywords : Blazars , Very High Energy Emission",
        "ori-fast-z-score": -0.3464101615137754,
        "water-fast-z-score": 6.119912853410033
    },
    {
        "original_text": "We study the dynamics of carrier-carrier interactions in semiconductor quantum dots (QDs) by solving numerically the time-dependent Schrödinger equation for two interacting electrons or holes confined to an anisotropic QD potential well. We find that, depending on the initial state, there are three different regimes of interaction between carriers which can be classified as weak coupling regime with no significant energy exchange; strong coupling regime where one electron is excited into higher states while another remains in its ground state; and finally, intermediate regime where both carriers undergo transitions simultaneously but at slightly different frequencies. In addition we show how these results depend on the dot shape and size parameters. Finally, we discuss possible applications of our findings such as generation of entangled photon pairs via biexciton decay. Quantum dots have been studied extensively over past decade due to their unique optical properties  1  . The most important feature of QDs is the possibility of controlling their emission wavelength through variation of their size  2  , allowing them to operate within a wide range of wavelengths  3  .\nIn this work we focus on studying the effects of carrier-carrier interactions  4  in semiconductor QDs using numerical solution of timedependent Schrödinger equations  5  . Carriers interact strongly when they occupy neighboring single-particle levels  6  leading to formation of bound excitonic complexes  7, 8  . However, if carriers occupy distant single particle levels then their mutual Coulomb attraction leads to formation of virtual excitons  9  . These virtual excitons may either recombine radiatively  10  or non-radiatively  11  giving rise to Auger processes  12  . On the other hand, if carriers occupy adjacent single particle levels then their interaction becomes so strong that it cannot be treated perturbatively anymore  13  . This situation occurs e.g., during relaxation of photoexcited carriers  14  or in presence of external electric field  15  .",
        "watermark_text": "We research the dynamics of carrier - carrier interactions in semiconductor quantum dots ( QDs ) by solving numerically the period - dependent Schrödinger equation for two interacting electrons or holes localized to an anisotropic QD potential well . We see that , depending on the initial state , there are three different regimes of coupling between carriers which can be categorized as weak interaction regime with no considerable energy exchange ; strong coupling regime where one electron is excited into higher states while another stays in its ground state ; and finally , intermediate regime where both carriers undergo transitions simultaneously but at slightly different frequencies .In addition we explain how these results vary on the dot structure and size parameters . Finally , we explain possible use of our findings such as transmission of entangled photon pairs via biexciton decay .Quantum dots have been studied frequently over past year due to their distinct optical properties 1 . The most important feature of QDs is the possibility of controlling their emission spectrum through variation of their size 2 , allowing them to work within a broad variety of wavelengths 3 .In this research we focus on studying the effects of carrier - carrier interactions 4 in semiconductor QDs using numerical solving of timedependent Schrödinger coefficients 5 . Carriers behave significantly when they inhabit neighboring single - particle concentrations 6 resulting to formation of bound excitonic complexes 7 , 8 .However , if carriers occupy remote single molecule concentrations then their mutual Coulomb affinity leads to formation of virtual excitons 9 . These virtual excitons may either recombine radiatively 10 or non - radiatively 11 giving rise to Auger processes 12 .On the other hand , if carriers occupy neighbouring single molecule concentrations then their interaction gets so powerful that it cannot be treated perturbatively anymore 13 . This condition occurs e . g . , during relaxation of photoexcited carriers 14 or in presence of external electric field 15 .",
        "ori-fast-z-score": -0.48989794855663565,
        "water-fast-z-score": 6.042074698865172
    },
    {
        "original_text": "We present an approach to the analysis of metabolic networks based on information-theoretic concepts, in particular Shannon s entropy measure. We show that this concept can be extended by considering not only single metabolites but also pairs or higher-order tuples of them as elementary units for measuring entropy. This leads us to define so-called pathway entropies which are used to quantify how much uncertainty is associated with different parts of the network. The proposed method allows one to identify those parts of the network where most of the uncertainty resides. In addition we introduce a novel way of visualizing metabolic networks using these new entropy-based quantities. Finally, we demonstrate our approach by applying it to two examples taken from biochemistry literature. Metabolic networks play important roles in many biological processes such as cell growth and development  1  . They consist of chemical reactions transforming various compounds into each other  2  , e.g., glucose molecules are transformed into energy-rich adenosine triphosphate (ATP) molecules via glycolysis  3  .\nThe study of metabolic networks has been attracting increasing interest over recent years  4  -  8  . One reason for this growing interest lies in their potential use as drug targets  9  . Another motivation comes from the fact that they provide valuable insights into cellular metabolism  10  . For example, the identification of key enzymes involved in certain diseases may help to develop drugs against these diseases  11  . Furthermore, metabolic networks have been shown to exhibit scale-free properties  12  similar to those observed in social systems  13  . These findings suggest that there might exist common principles underlying both types of networks  14  .\nIn order to understand the functioning of metabolic networks better, several mathematical models have been developed  15  -  17  . Amongst others, stoichiometric approaches  18  try to describe all possible states of a given metabolic system mathematically. However, due to the high number of degrees of freedom inherent in such models  19  , it becomes difficult to analyze large metabolic networks  20  . Therefore, alternative methods have been suggested  21  -  23  .",
        "watermark_text": "We present an perspective to the analysis of biological groups based on knowledge - theoretic concepts , in example Shannon s entropy measure . We see that this concept can be generalized by treating not only single metabolites but also pairs or greater - order tuples of them as elementary units for determining entropy .This leads us to define so - called pathway entropies which are using to quantify how many uncertainty is associated with various parts of the network . The proposed approach allows one to identify those parts of the network where most of the doubt lies .In addition we provide a new method of visualizing molecular connections utilizing these new entropy - based quantities . Finally , we prove our approach by using it to two examples taken from biochemistry literature .Metabolic systems play essential roles in different biological pathways such as cell development and growth 1 . They involve of chemical processes transforming various compounds into each other 2 , e . g . , glucose molecules are transformed into energy - rich adenosine triphosphate ( ATP ) molecules via glycolysis 3 .The investigation of biological groups has been drawing rising interest over recent periods 4 - 8 . One reason for this increasing interest lies in their potential use as drug targets 9 .Another motivation comes from the fact that they give valuable insights into cellular metabolism 10 . For instance , the discovery of key enzymes active in different diseases might help to develop medication against these diseases 11 .Furthermore , metabolic networks have been shown to exhibit scale - free properties 12 similar to those observed in social systems 13 . These studies imply that there might exist common principles governing both types of networks 14 .In order to explain the structures of metabolic networks better , various computational models have been created 15 - 17 . Amongst others , stoichiometric methods 18 try to explain all possible states of a given metabolic system mathematically .However , owing to the high number of degrees of autonomy inherent in such studies 19 , it becomes impossible to analyze large metabolic networks 20 . Therefore , alternative techniques have been proposed 21 - 23 .",
        "ori-fast-z-score": -0.909717652294684,
        "water-fast-z-score": 8.743828992755144
    },
    {
        "original_text": "We present optical and near-infrared photometry of SN 2006bp, which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett (Puckett et al., 2007) . The supernova is located at an unusually large distance for its host galaxy, with a recession velocity of ~1000 km/sec. \n \n We find that the light curve can be well fit using a model consisting of three components: shock breakout emission, radioactive decay powered luminosity, and dust extinction. Using this model we derive physical parameters such as the progenitor radius, mass loss rate, and explosion energy. Our results are consistent with those found for other type-II SNe but suggest that the progenitor star had a lower initial mass than previously thought. This may indicate that there exists more diversity among progenitors of type-II SNe than has been realized so far. In addition to these findings, our observations provide new insights into the physics of shock breakout and early-time evolution of type-II SNe.",
        "watermark_text": "We present visual and far - infrared photometry of SN 2006bp , which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett ( Puckett et al . , 2007 ) . The supernova is situated at an exceptionally wide distance for its host galaxy , with a collapse speeds of ~ 1000 cm / sec .We see that the light spiral can be well fitting using a description consisting of three components : shock breakout emission , radioactive decay powered luminosity , and dust extinction . Using this description we derive physical factors such as the progenitor diameter , mass loss rate , and explosion power .Our results are compatible with those detected for other class - II SNe but suggest that the progenitor star had a smaller original mass than previously thought . This might suggest that there exists more diversity among progenitors of type - II SNe than has been realized so far .In addition to these results , our observations offer additional perspectives into the physics of wave breakout and first - time evolution of type - II SNe .",
        "ori-fast-z-score": -0.9299811099505543,
        "water-fast-z-score": 5.579886659703326
    },
    {
        "original_text": "We present the results of our numerical simulations of magnetized, rotating white dwarf stars that undergo accretion-induced collapse (AIC). We find that for sufficiently rapid rotation and strong magnetic fields, AIC leads to an explosion with properties similar to those observed in SNe Ia. The explosion is driven by the release of gravitational energy as the collapsed core bounces back after reaching nuclear density. In addition, we show that the presence of a strong toroidal field can lead to significant asymmetries in the ejecta distribution. These asymmetries are likely responsible for the polarization signal detected in some SNe Ia. \n \n Keywords: Supernovae Type Ia, Rotation, Magnetic Fields, White Dwarf Stars, Accretion Induced Collapse \n \n 1 Introduction \n \n Recent observations have shown that many supernovae type Ia (SNe Ia) exhibit large amounts of linear polarization  1  . This has been interpreted as evidence that these events result from asymmetric explosions  2  , which may be caused by large-scale magnetic fields  3  or rapid rotation  4  . However, it remains unclear whether either mechanism alone could produce such highly polarized light curves  5  . \n \n Here we investigate how the combination of rapid rotation and strong magnetic field affects the outcome of accretion induced collapse (AIC), where a white dwarf star collapses into a neutron star  6  . For this purpose, we perform two-dimensional axisymmetric hydrodynamic simulations using the code FLASH  7  . Our initial models consist of rigidly-rotating white dwarf stars with masses ranging between 0.6-1.2 Msun  8  . To account for the effects of general relativity on the structure of the white dwarf  9  , we use the polytropic equation of state P = Kρ Γ , where ρ denotes the mass density and P the pressure  10  . \nThe main goal of this work is to determine if AICs triggered by rapid rotation and/or strong magnetic fields can explain the high degree of polarization observed in SNe Ia  11  .",
        "watermark_text": "We present the conclusion of our numerical simulations of magnetized , moving white dwarf stars that suffer accretion - caused collapse ( AIC ) . We see that for enough fast rotation and strong magnetic fields , AIC leads to an explosion with properties similar to those observed in SNe Ia .The explosion is powered by the release of gravitational energy as the collapsed center bounces backward after reaching nuclear density . In addition , we find that the presence of a powerful toroidal field can lead to significant asymmetries in the ejecta distribution .These asymmetries are likely responsible for the polarization signal found in some SNe Ia . Keywords : Supernovae Type Ia , Rotation , Magnetic Fields , White Dwarf Stars , Accretion Induced Collapse 1 Introduction Recent measurements have shown that several supernovae class Ia ( SNe Ia ) exhibit substantial concentrations of linear polarization 1 .This has been viewed as proof that these phenomena come from asymmetric explosions 2 , which may be caused by large - scale magnetic waves 3 or rapid rotation 4 . However , it remains unsure whether either mechanism alone could generate such heavily polarized light curves 5 .Here we investigate how the combination of rapid rotation and strong magnetic force determines the result of accretion induced collapse ( AIC ) , where a white dwarf star collapses into a neutron galaxy 6 . For this use , we perform two - dimensional axisymmetric hydrodynamic simulations using the code FLASH 7 .Our preliminary estimates consist of rigidly - spinning white dwarf stars with masses ranging between 0 . 6 - 1 . 2 Msun 8 . To account for the effects of general relativity on the composition of the white dwarf 9 , we utilize the polytropic equation of state P = Kρ Γ , where ρ indicates the mass density and P the pressure 10 .The main goal of this research is to find if AICs triggered by rapid rotation and / or strong magnetic waves can describe the high degree of polarization observed in SNe Ia 11 .",
        "ori-fast-z-score": 1.1188618555710317,
        "water-fast-z-score": 7.487767802667673
    },
    {
        "original_text": "We present an analysis of the Bondi accretion rate onto primordial black holes (PBHs) during the radiation-dominated era, taking into account the effects of pressure and viscosity on the gas flow. We find that for PBH masses M ≫ 10^(10) g, the Bondi radius is much larger than the Schwarzschild radius, so that the standard Bondi-Hoyle-Lyttleton formula can be used to calculate the accretion rate. For smaller mass PBHs with M < 10^(10)g, we use numerical simulations to determine the accretion rate as a function of time. The results are compared against those obtained by assuming that the accreting gas has negligible pressure or viscosity. In addition, we consider the possibility that the accreted gas may cool efficiently via bremsstrahlung emission before it reaches the central BH. Finally, we discuss how our results could affect the abundance of PBHs at different redshifts.",
        "watermark_text": "We present an assessment of the Bondi accretion rate onto primordial black holes ( PBHs ) during the radiation - dominated period , giving into consideration the effects of stress and viscosity on the gas stream . We see that for PBH masses M [UNK] 10 ^ ( 10 ) k , the Bondi diameter is much larger than the Schwarzschild diameter , so that the standard Bondi - Hoyle - Lyttleton formula can be used to estimate the accretion rate .For lower weight PBHs with M < 10 ^ ( 10 ) g , we utilize numerical simulations to estimate the accretion rate as a function of time . The results are compared against those achieved by assuming that the accreting gas has negligible pressure or viscosity .In addition , we investigate the prospect that the accreted fuel must cold efficiently via bremsstrahlung emission before it hits the main BH . Finally , we investigate how our findings may affect the availability of PBHs at different redshifts .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.040095911547238
    },
    {
        "original_text": "We present results for photoionised gas in an expanding spherical shell, irradiated by multiple point-like and extended sources with different luminosities and spatial distributions. We find that the presence of additional sources can significantly affect the thermal state of the gas at large distances (several times larger than the Strömgren radius) from the central source(s). The effect is more pronounced when the number density of the surrounding medium decreases rapidly towards the outer boundary of the cloud. In this case, the contribution to heating due to external radiation becomes comparable or even exceeds the internal energy input from the central source(es), resulting in higher temperatures throughout most of the volume occupied by the shell. This may have important implications for the interpretation of observations of extragalactic HII regions. We also show how the inclusion of dust grains affects our results. Finally we discuss possible applications of these findings to other astrophysical problems such as the formation of planetary nebulae. \n \n Keywords: Photoionization",
        "watermark_text": "We report findings for photoionised gas in an increasing spherical shell , irradiated by various point - like and extended sources with various luminosities and spatial distributions . We see that the presence of added sources can significantly affect the thermal state of the gas at large distances ( several twice bigger than the Strömgren diameter ) from the main source ( s ) .The phenomenon is more pronounced when the number density of the associated medium falls steadily towards the exterior boundary of the cloud . In this instance , the contribution to heating due to external emission grows equivalent or even equals the internal energy source from the main supply ( es ) , leading in greater temperatures throughout most of the volume occupied by the shell .This might have important implications for the interpretation of measurements of extragalactic HII zones . We additionally understand how the inclusion of dust grains affects our findings .Finally we explain possible applied of these results to other astrophysical problems such as the formation of planetary nebulae . Keywords : Photoionization",
        "ori-fast-z-score": -1.6464638998453551,
        "water-fast-z-score": 5.673665146135802
    },
    {
        "original_text": "We study the correlations and sum rules in a semi-infinite system with impurities at its surface, which is described by the quantum two-dimensional (2D) one component plasma model. We use the exact diagonalization method to calculate the density-density correlation function and static structure factor as well as their corresponding sum rules. The results show that there are two different regimes depending on whether the temperature T is larger or smaller than the Fermi energy EF . In particular, we find that when T < EF , the behavior of these quantities can be understood within the framework of Landau s Fermi liquid theory. However, if T > EF , our numerical data deviate significantly from this picture. Finally, we also investigate how the presence of impurities affects the above mentioned physical properties. Our findings suggest that the effect of impurities depends strongly on the distance between them. If they are close enough, then the impurity-impurity interaction dominates over other interactions leading to an increase of the effective mass of particles near the surface.",
        "watermark_text": "We consider the correlations and sum rules in a semi - infinite system with impurities at its surface , which is characterized by the quantum two - dimensional ( 2D ) one element plasma model . We use the exact diagonalization technique to estimate the density - density correlation function and static structure parameter as well as their corresponding sum rules .The results show that there are two different regimes depending on whether the temperature T is bigger or smaller than the Fermi energy EF . In particular , we find that when T < EF , the dynamics of these quantities can be understood within the framework of Landau s Fermi liquid physics .However , if T > EF , our numerical statistics deviate substantially from this picture . Finally , we also investigate how the presence of impurities impacts the above mentioned physical properties .Our findings show that the impact of impurities relies highly on the distance between them . If they are close enough , then the impurity - impurity interaction dominates over other molecules giving to an increase of the effective mass of molecules near the surface .",
        "ori-fast-z-score": 2.5927248643506746,
        "water-fast-z-score": 6.4372630957871815
    },
    {
        "original_text": "We present the results of an analysis of microlensing events detected by the Optical Gravitational Lensing Experiment (OGLE) and its follow-up network, including the Microlensing Observations in Astrophysics collaboration (MOA). We have identified 16 new planets among these events using high-precision photometry obtained at Subaru Observatory. The masses of all but one planet are determined to be less than 1 M⊕ . Fourteen of them are found to orbit stars more massive than 0.5 M⊙ , while two others are around low-mass dwarfs. These planets are located between 0.1 AU and 4 AU away from their host stars. This is the first time that such a large number of extrasolar planets has been discovered through space-based microlensing surveys. Our sample includes several planets whose orbits lie close to or beyond Neptune s semi-major axis. In addition, we find evidence for planetary companions to three binary systems.",
        "watermark_text": "We present the conclusion of an assessment of microlensing events discovered by the Optical Gravitational Lensing Experiment ( OGLE ) and its follow - up network , notably the Microlensing Observations in Astrophysics collaboration ( MOA ) . We have discovered 16 new objects among these phenomena using high - precision photometry obtained at Subaru Observatory .The masses of all but one planet are decided to be less than 1 M⊕ . Fourteen of them are found to orbit stars more massive than 0 . 5 [UNK] , while two others are around low - weight dwarfs .These planets are situated between 0 . 1 AU and 4 AU away from their home stars . This is the first time that such a large number of extrasolar stars has been detected through space - based microlensing observations .Our specimen includes several planets whose orbits lie close to or beyond Neptune s semi - major axis . In addition , we find proof for planetary companions to three binary systems .",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 4.6475800154489
    },
    {
        "original_text": "The crystal structure of the title compound, C7H14N2O4·H2O, has been determined by single-crystal X-ray diffraction analysis at room temperature.  The asymmetric unit contains one molecule of alanine in which both carboxylate groups are protonated to give an overall charge of +1. In the crystal lattice each amino acid is linked via O-H⋯O hydrogen bonds into chains running parallel to  010  . These chains are further connected through N-H⋯O hydrogen bonding interactions between adjacent molecules along the c-axis direction leading to layers perpendicular to (001). The water molecules form intermolecular O-H⋯O and O-H⋯π interactions with neighbouring amino acids within these layers. A comparison of bond lengths shows that there is no significant difference between the two polymorphic structures reported for this compound. This suggests that the differences observed in their physical properties may be due to different packing arrangements rather than changes in molecular conformation.",
        "watermark_text": "The crystal composition of the title compound , C7H14N2O4 · H2O , has been determined by single - crystal X - ray diffraction examination at room temperature . The asymmetric unit contains one molecule of alanine in which both carboxylate groups are protonated to give an overall charge of + 1 .In the crystal lattice each amino acid is linked via O - [UNK] hydrogen bonds into chains flowing parallel to 010 . These chains are further connected through N - [UNK] hydrogen bonding interactions between adjacent molecules along the c - axis direction leading to layers perpendicular to ( 001 ) .The water molecules form intermolecular O - [UNK] and O - [UNK] interactions with neighbouring amino acids within these layers . A comparison of bond lengths demonstrates that there is no considerable difference between the two polymorphic structures described for this compound .This supports that the differences found in their biological behavior may be due to different packing structures instead than shifts in molecular conformation .",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 2.6558112382722783
    },
    {
        "original_text": "We show that, in addition to gravitational waves and neutrinos, there is an additional source of energy loss during the final stages of stellar evolution which has been largely ignored by previous authors. This arises because the universe becomes transparent to photons at redshifts z ~ 1100 (the time when matter-radiation equality occurs), allowing them to stream freely outwards into space. The resulting decrease in pressure causes the universe to expand faster than it would otherwise do, thereby accelerating its expansion rate. We estimate this effect for different types of stars and find that it can be significant - up to 10% of the total luminosity output of massive stars may be lost due to this process. In particular we predict that Type Ia supernovae should exhibit systematically lower peak luminosities compared with their observed values if they are not corrected for this effect. Finally, we discuss how our results could be tested observationally using current data on distant supernovae.",
        "watermark_text": "We suggest that , in addition to gravitational waves and neutrinos , there is an additional source of power transfer during the last phases of stars evolution which has been mostly overlooked by earlier authors . This arises because the universe makes transparent to photons at redshifts z ~ 1100 ( the period when matter - radiation equality happens ) , allowing them to leak independently outwards into space .The resulting shift in pressure creates the universe to expand faster than it would normally do , thereby accelerating its expansion speed . We estimate this effect for different kinds of stars and find that it can be considerable - up to 10 % of the total luminosity production of large galaxies must be lost due to this process .In particular we estimate that Type Ia supernovae should exhibit systematically lower peak luminosities contrasted with their observed values if they are not corrected for this effect . Finally , we explain how our findings may be evaluated observationally using current data on remote supernovae .",
        "ori-fast-z-score": 0.22941573387056174,
        "water-fast-z-score": 6.653056282246291
    },
    {
        "original_text": "We study the dynamics and mechanics of single microtubules in vitro, using optical tweezers to apply forces along their length. We find that microtubules are remarkably stiff against bending but soft against stretching. The elastic response is well described by an entropic spring model with persistence length p = 1.5 mm. Microtubules can be bent into shapes such as rings or helices without breaking. When we bend them back towards straightness they relax at rates which depend on the applied tension. This suggests that microtubules have internal stresses built up during bending. These results provide new insights into how microtubules may behave inside cells where they experience both external loads and internal tensions due to motor proteins pulling on them. Microtubules (MTs) play important roles in many cellular processes including cell division  1  , intracellular transport  2  and mechanosensing  3  . They consist of tubulin dimers arranged head-to-tail into protofilaments  4  . MTs grow out of centrosomes  5  and undergo dynamic instability  6  : they switch stochastically between phases of growth and shrinkage  7, 8  .\nMicrotubules also interact strongly with motors  9  . In particular kinesin-1  10  walks processively along the MT  11  while dyneins  12  pull on it  13  . Motors generate forces which cause MTs to buckle  14, 15  and deform  16  . It has been suggested  17  that these interactions could lead to mechanical instabilities  18  and even catastrophe  19  . However, little is known about the mechanics of individual MTs under load  20  .\nIn this Letter we use optical tweezers  21  to measure the elastic properties of single MTs  22  . We show that MTs are very stiff against bending but soft when stretched. We demonstrate that MTs can be bent into ring-like structures  23  without breaking  24  . Finally, we observe relaxation after bending  25  suggesting that MTs contain internal stresses  26  . Our experiments reveal novel aspects of MT mechanics which will help us understand how MTs respond to forces generated by motors inside living cells. \nExperimental setup. To manipulate MTs optically  27 ",
        "watermark_text": "We explore the dynamics and mechanics of single microtubules in vitro , using optical tweezers to apply forces along their length . We see that microtubules are unusually stiff against bent but soft against stretching .The elastic response is well described by an entropic spring model with persistence length p = 1 . 5 mm . Microtubules can be bending into shapes such as bands or helices without breaking .When we stretch them back towards straightness they relaxation at levels which depend on the applied strain . This implies that microtubules have internal stresses built up during bending .These data provide fresh insights into how microtubules might react inside cells where they encounter both external loads and internal stresses thanks to motor molecules pulling on them . Microtubules ( MTs ) play essential roles in multiple cell processes including cellular division 1 , intracellular transport 2 and mechanosensing 3 .They comprise of tubulin dimers arranged head - to - tail into protofilaments 4 . MTs grow out of centrosomes 5 and undergo dynamic instability 6 : they change stochastically between phases of growth and shrinkage 7 , 8 .Microtubules additionally interact heavily with motors 9 . In particular kinesin - 1 10 moves processively along the MT 11 while dyneins 12 pull on it 13 .Motors create pressures which cause MTs to buckle 14 , 15 and deform 16 . It has been proposed 17 that these interactions might lead to structural instabilities 18 and even catastrophe 19 .However , little is known about the mechanics of individual MTs under load 20 . In this Letter we using optical tweezers 21 to measure the elastic properties of single MTs 22 .We suggest that MTs are very stiff against stretching but soft when stretched . We showed that MTs can be bending into ring - like structures 23 without breaking 24 .Finally , we study relax after bending 25 implying that MTs contain inner stresses 26 . Our experiments discover novel elements of MT mechanics which will assist us explain how MTs reply to forces generated by motors inside live cells .Experimental setup.To manipulate MTs optically  27",
        "ori-fast-z-score": -1.0215078369104984,
        "water-fast-z-score": 7.663582481705323
    },
    {
        "original_text": "We study the circular and non-circular motion near the event horizons of rotating black holes by using the Hamilton-Jacobi method, which is an extension of the standard geodesic approach to include higher-order corrections due to gravitational radiation reaction effects. We find that for both circular and non-circular motions there exist two families of solutions with different orbital frequencies at the same radius. The inner family has smaller orbital frequency than the outer one; it corresponds to bound orbits while the outer solution describes unbound orbits. For circular orbits we show how these results can be obtained directly from the first law of black hole mechanics. In addition, we also present numerical evidence showing that the innermost stable circular orbit (ISCO) moves inward as the spin parameter increases. Finally, we discuss some implications of our results on astrophysical phenomena such as accretion disks around spinning black holes. Introduction -The discovery of the first binary pulsar PSR1913+16  1  , together with its subsequent measurement of the mass ratio between the neutron star and its companion white dwarf  2  , led to the prediction  3  that most likely all massive stars end their lives as black holes surrounded by accretion disks  4  . Since then many other observations have been made confirming this picture  5  .\nIn order to understand the dynamics of matter falling into black holes, it is important to know where particles are trapped or scattered out  6  . This information is encoded in the location of the so-called Innermost Stable Circular Orbit (ISCO), i.e., the smallest possible radius r ISCO of a particle s circular orbit  7, 8  . It turns out that the value of r ISCO depends sensitively on the spin angular momentum J = Ma 2 /(2r g ) of the black hole  9  : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO decreases rapidly until finally it reaches the Schwarzschild radius R s ≡ 2GM/c 2  10  . Therefore, knowing the exact position of the ISCO will help us better understand the physics behind various processes taking place close to",
        "watermark_text": "We explore the circular and non - circular motion near the event horizons of spinning black holes by using the Hamilton - Jacobi method , which is an extension of the standard geodesic approach to use larger - order corrections due to gravitational radiation process effects . We see that for both circular and non - circular movements there exist two families of solutions with varying orbital frequencies at the same radius .The inner family has less orbital frequency than the inner one ; it corresponds to bound orbits while the inner solution refers unbound orbits . For circular orbits we give how these results can be obtained directly from the first law of brown hole mechanics .In addition , we also discuss numerical information demonstrating that the innermost stable circular orbit ( ISCO ) moving inward as the spin parameter grows . Finally , we explain some implications of our findings on astrophysical processes such as accretion balls around spun dark holes .Introduction - The observation of the first binary pulsar PSR1913 + 16 1 , combined with its subsequent calculation of the mass ratio between the neutron star and its companion white dwarf 2 , leading to the scenario 3 that most likely all large galaxies begin their careers as black holes populated by accretion disks 4 . Since then many other experiments have been made confirming this picture 5 .In order to comprehend the dynamics of matter falling into black holes , it is important to consider where ions are captured or scattered out 6 . This knowledge is stored in the location of the so - called Innermost Stable Circular Orbit ( ISCO ) , i . e . , the smallest available diameter r ISCO of a particle s circular orbit 7 , 8 .It turns out that the value of r ISCO relies sensitively on the spin angular velocity J = Ma 2 / ( 2r g ) of the dark hole 9 : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO falls slowly until finally it meets the Schwarzschild diameter R s ≡ 2GM / c 2 10 . Therefore , knowing the exact position of the ISCO will assist us better understand the physics behind several mechanisms taking place nearby to",
        "ori-fast-z-score": -1.7905475715715027,
        "water-fast-z-score": 6.6577138248976375
    },
    {
        "original_text": "We present the results of an extensive multi-wavelength survey of two nearby (< 1 kpc) and well-studied star-forming regions, Orion Nebula Cluster (ONC), NGC 2024, in order to investigate their physical properties as well as those of individual protostars embedded within them. We have obtained near-infrared images with Subaru/Suprime-Cam at JHKs bands for ONC region and Spitzer/IRAC 3.6-8.0 micron data for both regions. In addition we used archival radio continuum observations made by VLA at 6 cm and 20 cm wavelengths. Using these datasets, we performed photometry on all point sources detected above 5 sigma level in each band. By comparing our infrared photometric measurements with theoretical evolutionary models, we found that most of the objects are likely to be Class I or flat-spectrum protostellar candidates. From the analysis of spectral energy distribution (SED) fitting using radiative transfer modeling code, we derived the mass accretion rates onto the central stars ranging between 10-700 x10-6 Msun yr-1 .",
        "watermark_text": "We publish the conclusion of an extensive multi - wavelength search of two adjacent ( < 1 kpc ) and well - investigated star - creating areas , Orion Nebula Cluster ( ONC ) , NGC 2024 , in order to examine their physical properties as well as those of several protostars embedded within them . We have achieved near - infrared images with Subaru / Suprime - Cam at JHKs bands for ONC region and Spitzer / IRAC 3 . 6 - 8 . 0 micron data for both locations .In addition we using archival radio continuum measurements made by VLA at 6 cm and 20 cm wavelengths . Using these datasets , we performed photometry on all point sources detected above 5 sigma grade in each band .By applying our laser photometric calculations with theoretical phylogenetic models , we identified that most of the items are likely to be Class I or flat - spectrum protostellar candidates . From the evaluation of spectral power distribution ( SED ) matching using radiative transfer modeling code , we derived the mass accretion levels onto the main stars ranging between 10 - 700 x10 - 6 Msun yr - 1 .",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 5.0089472186085136
    },
    {
        "original_text": "The present work is devoted to the investigation of the photothermal properties and dynamics of the Cu2O/CuO nanocomposite films prepared by pulsed laser deposition (PLD) on Si(100). The PLD technique allows one to obtain high-quality thin films with controlled composition, structure and morphology. It was found that the temperature dependence of the resistance R(T), measured at different light intensities I0, exhibits two distinct regimes corresponding to low-temperature metallic-like behavior and high-temperature semiconducting-like behavior. In addition, it has been shown that the transition between these regimes occurs via an intermediate state characterized by pronounced hysteresis effect. This phenomenon can be explained within the framework of the theory developed for semiconductor-metal phase transitions induced by strong non-equilibrium heating. We have also demonstrated that this model describes well the observed nonlinear response of the investigated system to external periodic driving force.",
        "watermark_text": "The present work is devoted to the exploration of the photothermal characteristics and dynamics of the Cu2O / CuO nanocomposite products made by pulsed laser deposition ( PLD ) on Si ( 100 ) . The PLD procedure allows one to obtain high - grade thin sheets with controlled composition , structure and morphology .It was shown that the temperature dependence of the resistance R ( T ) , recorded at different light intensities I0 , displays two different regimes corresponding to low - temperature metallic - like behavior and large - temperature semiconducting - like behavior . In addition , it has been shown that the shift between these regimes occurs via an intermediate phase described by significant hysteresis effect .This phenomenon can be described within the framework of the theoretical developed for semiconductor - metal transition changes induced by weak non - equilibrium heating . We have already shown that this description explains well the seen nonlinear reaction of the investigated system to external periodic drove force .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.812381937190964
    },
    {
        "original_text": "We present the results of our theoretical study on massive planet migration in protoplanetary disks, focusing on its dependence on disk properties such as viscosity and surface density profiles. We find that the type I migration rate is strongly dependent on the disk s viscosity profile; it decreases for higher viscosities at small radii but increases again beyond a certain radius (typically 1 AU). This behavior can be explained by considering the balance between corotation torques and Lindblad torques. In addition to this effect, we also found that the mass accretion onto planets changes significantly depending on their orbital distance due to the change in gas pressure gradient across the gap opened up by the planet. Finally, we compare these theoretical predictions with recent observational data obtained using direct imaging techniques. Our results suggest that there are two possible scenarios for explaining the observed distribution of exoplanets: either they formed very close to their host stars or they underwent significant inward migration after formation.",
        "watermark_text": "We present the conclusion of our theory study on massive planet migration in protoplanetary disks , concentrating on its dependence on disk properties such as viscosity and surface volume profiles . We see that the class I travel speed is strongly dependent on the disk s viscosity profile ; it reduces for greater viscosities at small radii but drops again beyond a certain distance ( commonly 1 AU ) .This phenomenon can be described by examining the balance between corotation torques and Lindblad torques . In addition to this effect , we also discovered that the mass accretion onto planets changes significantly depending on their orbital height owing to the shift in gas pressure gradient across the gap opened up by the planet .Finally , we compare these theoretical estimates with recent observational data acquired using direct imaging procedures . Our results propose that there are two possible strategies for explaining the seen distribution of exoplanets : either they formed very close to their host stars or they underwent considerable inward movement after formed .",
        "ori-fast-z-score": -0.7875615306482168,
        "water-fast-z-score": 6.037383539249432
    },
    {
        "original_text": "We present the first detection and characterization of infrared extinction law (IRAL) toward an extremely dark cloud core, L183. The IRAL is derived by comparing near-infrared to mid-infrared colors between background stars and foreground objects projected on the same line-of-sight through the cloud. We find that the IRAL shows no significant variation with depth into the cloud down to A V = 1000 mag. This result suggests that dust grains are not significantly modified even under such extreme conditions as those found deep inside dense clouds. Our results also suggest that grain growth may be suppressed in these environments due to efficient shattering caused by collisions among large grains. These findings have important implications for understanding the formation process of planetesimals. \n \n Keywords: Infrared extinction law, Dust properties, Interstellar medium, Shock waves \n \n 1. Introduction \n \n It has been suggested that interstellar dust grains grow up to millimeter sizes or larger within dense molecular clouds because they can survive against destructive collisions with other particles (e.g., coagulation theory; Ossenkopf & Henning 1994). However, recent observations show that there exist many small dust grains in dense regions where the gas density exceeds 10^6 cm^{-3} (e.g., Stepnik et al. 2003; Pagani et al. 2003), which contradicts this scenario. To resolve this discrepancy, it was proposed that dust grains could be destroyed efficiently via collisional fragmentation when their size becomes comparable to the mean free path of hydrogen molecules (Ormel et al. 2007). \n \n Another possibility is that dust grains do not grow but rather fragment into smaller pieces during collisions (e.g., Blum & Wurm 2008). If so, then we would expect to see some evidence of grain destruction products like sub-micron-sized fragments in dense clouds. Indeed, several observational studies reported the presence of sub-millimeter emission features attributed to silicate and/or carbonaceous materials in dense clouds (e.g., Jones et al. 1993; Chiar et al. 1998; Kessler",
        "watermark_text": "We present the first recognition and description of infrared extinction law ( IRAL ) toward an incredibly dark cloud core , L183 . The IRAL is calculated by using near - infrared to mid - infrared colors between background stars and foreground objects projected on the same line - of - view through the cloud .We see that the IRAL displays no considerable variation with depth into the cloud down to A V = 1000 mag . This result suggests that dust grains are not dramatically distorted even under such extreme circumstances as those observed deep inside dense clouds .Our results also suggest that grain growth could be ceased in these habitats due to efficient crushing caused by collisions among huge grains . These conclusions have important implications for studying the formation system of planetesimals .Keywords : Infrared extinction law , Dust properties , Interstellar medium , Shock effects 1 . Introduction It has been proposed that interstellar dust grains grow up to millimeter sizes or larger within dense molecular clouds because they can endure against damaging collisions with other particles ( e . g . , coagulation hypothesis ; Ossenkopf & Henning 1994 ) .However , recent observations show that there remain many small dust grains in dense areas where the gas density reaches 10 ^ 6 cm ^ { - 3 } ( e . g . , Stepnik et al . 2003 ; Pagani et al .2003 ) , which contradicts this situation . To settle this discrepancy , it was suggested that dust grains could be devastated easily via collisional fragmentation when their size grows equivalent to the mean free path of hydrogen compounds ( Ormel et al .2007 ) . Another possibility is that dust grains do not grow but rather cluster into tiny pieces during collisions ( e . g . , Blum & Wurm 2008 ) .If so , then we may expect to see some evidence of grain loss substances like sub - micron - sized fragments in dense clouds . Indeed , various observational surveys reported the formation of sub - millimeter emission elements owing to silicate and / or carbonaceous materials in dense clouds ( e . g . , Jones et al .1993 ; Chiar et al . 1998 ; Kessler",
        "ori-fast-z-score": 0.3965257928590721,
        "water-fast-z-score": 8.379912286910033
    },
    {
        "original_text": "We present the results obtained by applying the semi-analytic code VESPA to model the evolution of galaxies in the Millennium Simulation, including chemical enrichment as well as dust extinction effects on their observed properties.  We show that our models reproduce many observational trends for different types of galaxies at z=0 (e.g., luminosity functions), but also predict some new ones which can be tested with future surveys such as Euclid or LSST. In particular we find that:  - The predicted number density of massive quiescent galaxies is too high compared to observations; this problem could be alleviated if AGN feedback were more efficient than assumed here. - Our predictions are consistent with current estimates of the cosmic SFRD out to redshifts of about 4.5, although they tend to overpredict it slightly beyond that redshift. - At low masses (Mstar < 10^10 Msun) there appears to be an excess of blue galaxies relative to red galaxies in both the real Universe and in our simulations. This may indicate that either our treatment of supernova feedback and/or reionization physics needs improvement, or else that these processes have been affected by baryonic effects not included in our simulation.",
        "watermark_text": "We present the results derived by using the semi - analytic coding VESPA to model the evolution of galaxies in the Millennium Simulation , notably chemical enrichment as well as dust extinction effects on their observed properties . We suggest that our designs represent many observational changes for different kinds of stars at z = 0 ( e . g . , luminosity functions ) , but also predict some additional ones which can be evaluated with current surveys such as Euclid or LSST .In particular we find that : - The predicted number density of large quiescent galaxies is too high compared to observations ; this situation could be alleviated if AGN feedback were more efficient than implied here . - Our predictions are compatible with current estimates of the cosmic SFRD out to redshifts of about 4 . 5 , although they tend to overpredict it somewhat beyond that redshift .- At small masses ( Mstar < 10 ^ 10 Msun ) there seems to be an accumulation of blue stars relative to blue stars in both the real Universe and in our simulations . This might suggest that either our treatment of supernova feedback and / or reionization theory requires improvement , or otherwise that these mechanisms have been affected by baryonic effects not involved in our modeling .",
        "ori-fast-z-score": -1.3251783128981585,
        "water-fast-z-score": 5.888888888888889
    },
    {
        "original_text": "We present here the rigorous mathematical formulation and complete proof of our previous results on the equivalence between Ising spin glasses (ISGs) and Ising models (IMs). We show that, in the thermodynamic limit N → ∞ with fixed ratio J / T , ISG partition functions can be mapped to IM ones by means of a suitable transformation which preserves all relevant physical quantities such as free energy density f = −k B T ln Z/N . The main idea is to introduce a new set of variables {s} ≡ {s1, ..., sN } representing the local magnetizations of each site i ∈ {1, .., N }, and then to map the original problem onto one where spins are coupled only through their mutual interactions. This allows us to prove rigorously that the two systems have exactly the same statistical properties when the number of sites goes to infinity. \nThe manuscript is organized as follows. In Sec. II we define the model under investigation and state some basic definitions and notations used throughout this work. In Sec. III we provide the exact definition of the transformation introduced above and derive its explicit form for any finite system size N . Then, in Sec. IV, we discuss how it can be extended to infinite-size lattices. Finally, in Sec. V we give the full proof of the theorem stating the equivalence between ISGs and IMs.",
        "watermark_text": "We present here the thorough mathematical formulation and complete proving of our previous findings on the equivalence between Ising spin glasses ( ISGs ) and Ising models ( IMs ) . We see that , in the thermodynamic limit N → ∞ with constant ratio J / T , ISG partition functions can be mapped to IM ones by means of a suitable decomposition which preserves all relevant physical components such as free energy density g = −k B T ln Z / N .The main idea is to introduce a new collection of variables { s } ≡ { s1 , . . . , sN } representing the local magnetizations of each site i ∈ { 1 , . . , N } , and then to map the previous problem onto one where spins are coupled only through their mutual interactions . This enables us to prove rigorously that the two systems have exactly the same statistical characteristics when the number of places goes to infinity .The manuscript is organized as follows.In Sec.II we define the model under inquiry and explain some fundamental definitions and notations used throughout this study . In Sec .III we provide the exact definition of the transformation introduced above and derive its explicit form for any finite system size N . Then , in Sec .IV , we explain how it can be generalized to infinite - length lattices . Finally , in Sec .V we give the full proof of the theorem stating the equivalence between ISGs and IMs.",
        "ori-fast-z-score": 1.801996396010812,
        "water-fast-z-score": 5.7564193416014815
    },
    {
        "original_text": "We consider the possibility that dark matter is made up of bosonic particles, which can condense into a superfluid state at low temperatures. We show how this scenario could explain several puzzling observations in astrophysics and cosmology. In particular we argue that: (i) The observed flat rotation curves of spiral galaxies are explained by the presence of a halo of cold dark matter surrounding each galaxy. (ii) The formation of large-scale structures such as clusters of galaxies proceeds through gravitational collapse of overdensities in the primordial density field seeded by quantum fluctuations during inflation. (iii) Dark energy may arise naturally if the universe contains a large number of weakly interacting massive particles with masses around $10^{22}$ GeV. This article is part of a series on Quantum Matter. For more information see http://arxiv.org/abs/quant-ph/0604070 . \nIntroduction:  Many theories beyond the Standard Model predict new types of elementary particles whose existence has yet to be confirmed experimentally. One particularly interesting class of models involves so-called WIMPZILLAs  1  , i.e., stable relic particles with masses around $10^9$ GeV or higher  2  . These particles would have been produced thermally in the early Universe but their abundance today should still be determined by their annihilation cross section  3  .\nIn this Letter we propose an alternative explanation for the origin of dark matter based on the idea that it consists of self-gravitating bosons  4  . Boson stars  5  are gravitationally bound states of scalar fields  6  predicted by many extensions of the Standard Model  7, 8  . They were first studied in the context of supersymmetric grand unified theories  9  where they play the role of solitonic solutions  10  . More recently, boson stars have also been considered within the framework of string theory  11  . If these objects exist then they will form a population of compact remnants  12  that might constitute all or some fraction of the dark matter  13  .",
        "watermark_text": "We consider the prospect that dark matter is made up of bosonic particles , which can condense into a superfluid state at low temperatures . We see how this situation could explain several puzzling discoveries in astrophysics and cosmology .In particular we claim that : ( i ) The observed flat rotation curves of spiral nuclei are explained by the presence of a halo of cold dark matter surrounding each galaxy . ( ii ) The formation of large - scale structures such as clusters of stars happens through gravity collapse of overdensities in the primordial density field seeded by quantum fluctuations during inflation .( iii ) Dark energy may arise naturally if the universe consists a large number of mildly interacting massive particles with masses around $ 10 ^ { 22 } $ GeV . This page is part of a trilogy on Quantum Matter .For more information see www : / / arxiv . org / abs / quant - ph / 0604070 . Introduction : Many theories beyond the Standard Model predict new types of primary objects whose existence has yet to be verified experimentally .One especially interesting class of models involves so - called WIMPZILLAs 1 , i . e . , stable relic objects with masses around $ 10 ^ 9 $ GeV or greater 2 . These particles might have been created thermally in the early Universe but their density today should still be determined by their annihilation cross section 3 .In this Letter we propose an additional argument for the origin of dark matter based on the idea that it consists of self - gravitating bosons 4 . Boson galaxies 5 are gravitationally bound states of scalar fields 6 expected by many extensions of the Standard Model 7 , 8 .They were first investigated in the context of supersymmetric grand unified fields 9 where they hold the part of solitonic answers 10 . More recently , boson stars have also been discussed within the framework of string theory 11 .If these objects exist then they will form a population of compact remnants 12 that might constitute all or some fraction of the dark matter 13 .",
        "ori-fast-z-score": 1.6783627165933783,
        "water-fast-z-score": 7.495152097492019
    },
    {
        "original_text": "We present the demographics and properties of transition objects in SDSS DR7, which are defined as galaxies with both emission lines (ELGs) and absorption features (AGNs). We find that there is an excess number of ELG-AGN pairs at small separations compared to random distributions. The fraction of AGNs among all ELGs increases towards lower luminosities. There appears to be no significant difference between the fractions of AGNs found within different types of ELGs. These results suggest that some ELGs may harbor hidden AGNs. This work was supported by NASA grant NNX10AD65G. We thank the anonymous referee for helpful comments on this manuscript. In recent years, it has been shown that many active galactic nuclei (AGNs), especially those with low luminosity or obscured by dusty torii, have strong emission line components (see e.g., Ho et al. (1997) , Hao et al. (2005) ), making them appear like normal star-forming galaxies when observed through optical spectroscopic surveys such as Sloan Digital Sky Survey (SDSS; York et al. (2000) ) .\nIn order to identify these  transition objects , we use two criteria based on their spectral energy distribution (SED): 1) they must show both emission lines (ELGs; see Section 2.1 below) and absorption features (Section 2.2) simultaneously; and 2) they should not be classified as quasars according to the BPT diagram (Baldwin et al. 1981 , Kewley et al. 2001 . By applying these selection criteria to the entire sample of galaxies in the seventh data release (DR7; Abazajian et al. 2009 ) of the SDSS, we obtain a total of 16,082 transition objects out of a parent sample of 3,962,843 galaxies.",
        "watermark_text": "We present the demographics and features of transfer objects in SDSS DR7 , which are specified as galaxies with both emission lines ( ELGs ) and emission elements ( AGNs ) . We see that there is an excess amount of ELG - AGN pairs at small separations compared to random distributions .The percentage of AGNs among all ELGs increases towards less luminosities . There seems to be no major variation between the fractions of AGNs observed within various types of ELGs .These data suggest that some ELGs might harbor hidden AGNs . This research was supported by NASA grant NNX10AD65G .We thank the anonymous referee for useful comments on this manuscript . In recent years , it has been shown that several active galactic nuclei ( AGNs ) , particularly those with poor luminosity or obscured by dusty torii , have strong emitted path constituents ( saw e . g . , Ho et al .( 1997 ) , Hao et al . ( 2005 ) ) , making them seem like usual star - creating galaxies when observed through optical spectroscopic studies such as Sloan Digital Sky Survey ( SDSS ; York et al .( 2000 ) ) . In order to identify these transition objects , we using two requirements according on their spectral power distribution ( SED ) : 1 ) they must show both emission lines ( ELGs ; seeing Section 2 . 1 below ) and emission elements ( Section 2 . 2 ) simultaneously ; and 2 ) they should not be categorized as quasars according to the BPT chart ( Baldwin et al .1981 , Kewley et al . 2001 .By applying these selection criteria to the entire sample of galaxies in the seventh data release ( DR7 ; Abazajian et al . 2009 ) of the SDSS , we obtain a total of 16 , 082 transition objects out of a parent sample of 3 , 962 , 843 galaxies .",
        "ori-fast-z-score": -3.104378865665871,
        "water-fast-z-score": 4.308294733275792
    },
    {
        "original_text": "We present an argument for why quantum mechanics is nonlocal, based on the fact that it allows one to predict with certainty whether or not a measurement will be made in any given experiment. We show how this can lead to superluminal communication between two parties sharing entangled particles by using only local operations and classical communication (LOCC). Finally we generalize the Born rule to allow for arbitrary measurements instead of just von Neumann ones. The usual formulation of quantum mechanics assumes that all experiments are performed under ideal conditions where no errors occur during the preparation of states or the execution of measurements. However, in practice there always exist some experimental imperfections such as decoherence due to environmental noise, imprecision in state preparations, and inaccuracy in measurements. In order to account for these effects, several approaches have been proposed including stochastic Schrödinger equations  1  , open systems  2  , and generalized probabilistic theories  3  . Here we consider another approach known as Quantum Bayesianism  4  .\nIn Quantum Bayesianism, the wave function is regarded as representing our knowledge about the system rather than describing its physical properties. This means that when performing a measurement, the outcome is determined by updating our knowledge according to Bayes  theorem  5  . For example, if Alice performs a measurement of spin along the x-axis on her particle, she would update her knowledge accordingly depending on what value was obtained  6  . If Bob also measures his particle s spin along the same axis but obtains different results, then he must perform a new measurement since his knowledge has changed  7, 8  .",
        "watermark_text": "We present an argument for why quantum mechanics is nonlocal , based on the fact that it allows one to predict with confidence whether or not a measurement will be made in any certain study . We see how this can lead to superluminal transmission between two sides sharing entangled particles by using only local operations and classical communication ( LOCC ) .Finally we generalize the Born rule to allow for arbitrary measurements rather of just von Neumann ones . The typical interpretation of quantum mechanics implies that all experiments are performed under ideal circumstances where no errors occur during the preparation of states or the execution of measurements .However , in practice there always arise some experimental imperfections such as decoherence caused to environmental pollution , imprecision in state preparations , and inaccuracy in measurements . In order to explain for these phenomena , various approaches have been proposed namely stochastic Schrödinger equations 1 , open systems 2 , and generalized probabilistic models 3 .Here we define another methodology called as Quantum Bayesianism 4 . In Quantum Bayesianism , the wave function is regarded as representing our information about the system instead than representing its physical properties .This implies that when performing a measurement , the result is chosen by updating our information according to Bayes principle 5 . For instance , if Alice performs a measurement of spin along the x - axis on her particle , she would update her knowledge appropriately depending on what quantity was obtained 6 .If Bob also measures his particle s spin along the same axis but obtains changed conclusions , then he must perform a new measurement since his knowledge has altered 7 , 8 .",
        "ori-fast-z-score": -0.27975144247209416,
        "water-fast-z-score": 6.444022325288263
    },
    {
        "original_text": "We present results of our numerical simulations of the interaction between the fast stellar winds and the slow dense shell ejected during previous eruption in the recurrent nova RS Oph (T Sco). We find that the observed X-ray light curve can be reproduced by assuming an initial mass loss rate of ~10-6 Msun/yr for the red giant component, which is consistent with theoretical predictions.  The predicted temperature structure of the shocked region agrees well with the observationally inferred one. Our model also predicts that the optical depth to X-rays should increase as time goes on because of the increasing density of the ejecta. This prediction seems to be supported by recent Swift/XRT observations. In addition we show that the observed UV fluxes are not explained by the standard steady state photoionization model but require additional heating source such as shocks or magnetic reconnection. Finally we discuss possible scenarios for future evolution of this system based on our numerical results.",
        "watermark_text": "We present results of our numerical simulations of the interaction between the fast stellar winds and the slow dense shell ejected during earlier eruption in the recurrent nova RS Oph ( T Sco ) . We see that the emitted X - ray light curve can be reproduced by assuming an initial mass loss rate of ~ 10 - 6 Msun / yr for the red dwarf component , which is compatible with theoretical estimates .The predicted temperature structure of the shocked areas agrees well with the observationally inferred one . Our model also predicts that the optical height to X - radiation should expand as time go on because of the increasing volume of the ejecta .This prediction seems to be supported by recent Swift / XRT studies . In addition we prove that the seen UV fluxes are not explained by the standard steady state photoionization theory but need extra heating source such as shocks or mechanical reconnection .Finally we explain possible strategies for future evolution of this scheme depending on our numerical findings .",
        "ori-fast-z-score": 0.11547005383792514,
        "water-fast-z-score": 6.1942248145051675
    },
    {
        "original_text": "We study the efficiency of cosmic ray (CR) acceleration by relativistic shocks using Monte Carlo simulations and analytical calculations. We find that, for strong shocks with Mach number M = 10 - 100, only about 1% CRs can be accelerated to ultra-high energy (UHE). This is because most particles are scattered back upstream before they gain enough energy to cross the shock front again. The low efficiency of UHE particle production leads to an upper limit on the maximum proton energy as well as the total CR luminosity produced by such shocks. Our results suggest that the observed fluxes of UHE protons cannot be explained solely by diffusive shock acceleration mechanism operating at cosmological shocks. However, our findings do not rule out other mechanisms proposed recently to explain the origin of UHE cosmic rays. \n \n Keywords: Cosmic Ray Acceleration, Diffusive Shock Acceleration, Relativistic Shocks",
        "watermark_text": "We research the performance of cosmic ray ( CR ) displacement by relativistic shocks using Monte Carlo simulations and mathematical calculations . We see that , for strong shocks with Mach number M = 10 - 100 , only about 1 % CRs can be enhanced to ultra - large energy ( UHE ) .This is because most grains are scattered backwards upstream before they get enough energy to pass the shock front again . The poor efficiency of UHE particle production gives to an upper limitation on the maximum proton power as well as the total CR luminosity generated by such shocks .Our results show that the known fluxes of UHE protons impossible be described solely by diffusive shock velocity process working at cosmological shocks . However , our findings do not leave out other mechanisms proposed lately to explain the origin of UHE cosmic rays .Keywords: Cosmic Ray Acceleration, Diffusive Shock Acceleration, Relativistic Shocks",
        "ori-fast-z-score": -1.721892064184557,
        "water-fast-z-score": 5.430582663966679
    },
    {
        "original_text": "The author presents an alternative approach to teaching special relativity by using the concept of transformation groups and their generators, which are used in physics for describing symmetry properties of physical systems.  The main idea is that students can learn about the foundations of special relativity without having to deal with complicated mathematical concepts such as tensors or spinor fields. This article describes how this method works on examples related to the Lorentz transformations. It also discusses some possible applications of these ideas in other areas of physics. In particular, it shows how one can use them to explain the origin of gauge symmetries in quantum field theory. Special relativity (SR) has been taught at many universities since its discovery in 1905  1  . However, despite numerous attempts  2  , there still exists no generally accepted way of introducing SR into undergraduate courses  3  .\nIn recent years, several authors have proposed new approaches to teaching SR  4  -  8  . These methods usually involve presenting the basic principles of SR through simple experiments performed in different reference frames  9  -  11  . They often require only minimal knowledge of mathematics  12  -  14  . Some of these proposals were inspired by Feynman s lectures  15  . Other authors tried to develop similar techniques based on modern computer technology  16  -  18  .",
        "watermark_text": "The author presents an different approach to teaching regular gravity by using the idea of transformation groups and their generators , which are needed in science for describing symmetry properties of physical structures . The main idea is that students can know about the foundations of regular gravity without having to deal with difficult numerical notions such as tensors or spinor fields .This page describes how this process uses on examples related to the Lorentz transformations . It additionally outlines some possible applied of these ideas in other areas of physics .In particular , it demonstrates how one can using them to explain the origin of gauge symmetries in quantum field theory . Special relativity ( SR ) has been taught at many universities since its discovery in 1905 1 .However , despite several efforts 2 , there still exists no usually agreed way of introducing SR into undergraduate courses 3 . In recent years , various authors have proposed additional strategies to teaching SR 4 - 8 .These methods usually include presenting the fundamental principles of SR through ordinary observations performed in different reference spaces 9 - 11 . They often use only limited knowledge of math 12 - 14 .Some of these proposals were inspired by Feynman s lectures 15 . Other scholars try to develop similar method using on contemporary computer technology 16 - 18 .",
        "ori-fast-z-score": 0.769800358919501,
        "water-fast-z-score": 7.120653320005384
    },
    {
        "original_text": "We present new observations with Hubble Space Telescope (HST) and Spitzer Space Telescope to study the galaxy population in the cluster Abell 2744 at z = 0.308. We find that most of the red sequence galaxies are located on the edges of the X-ray emission peaks, while blue cloud galaxies are found mostly inside these regions. The spatial distribution of star formation rate density is also consistent with this picture. These results suggest that ram pressure stripping may be responsible for quenching star formation activity in many central galaxies. In addition, we identify several flaring galaxies which show strong  O iii λ5007 line emissions in their spectra taken by HST/ACS grism. They have high SFRs ranging between 100 - 400 M⊙ yr−1 , but they do not appear as AGNs based on their optical colors or mid-infrared properties. Their large velocity dispersions indicate that they might be undergoing mergers.",
        "watermark_text": "We present new experiments with Hubble Space Telescope ( HST ) and Spitzer Space Telescope to study the galaxy community in the cluster Abell 2744 at z = 0 . 308 . We see that most of the red sequence galaxies are situated on the edges of the X - ray radiation peaks , while dark cloud galaxies are found primarily inside these regions .The spatial distribution of galaxy formation rate concentration is also consistent with this picture . These conclusions propose that ram pressure stripping may be responsible for quenching star formation activity in many central galaxies .In addition , we identify several flaring stars which show intense O iii λ5007 line emissions in their spectra made by HST / ACS grism . They have high SFRs varied between 100 - 400 [UNK] yr−1 , but they do not appear as AGNs based on their optical colors or mid - infrared properties .Their large velocity dispersions suggested that they may be experiencing mergers .",
        "ori-fast-z-score": -0.7385489458759964,
        "water-fast-z-score": 4.185110693297313
    },
    {
        "original_text": "We present an analysis of the distribution of planetary orbital parameters and masses for all known extrasolar planets with measured mass (N=73). We find that this sample can be divided into three distinct groups, which we call super-Earths, mini-Neptunes, and hot Jupiters. The first two are characterized by low eccentricities and high mutual inclinations between their orbits; in contrast, hot Jupiters have small mutual inclinations but large eccentricities. Super-Earths and mini-Neptunes also appear to form separate sequences on the radius-mass diagram. These results suggest that these three populations may represent different formation mechanisms or evolutionary histories. In particular, our findings support previous suggestions that super-Earths formed via core accretion followed by significant inward migration while mini-Neptunes were likely assembled through gravitational instability. Finally, we show how these results can be used as priors when searching for additional exoplanets using transit surveys such as Kepler.",
        "watermark_text": "We present an assessment of the distribution of planetary orbital characteristics and masses for all known extrasolar planets with calculated mass ( N = 73 ) . We see that this specimen can be grouped into three different categories , which we call super - Earths , mini - Neptunes , and hot Jupiters .The first two are marked by low eccentricities and large mutual inclinations between their orbits ; in comparison , hard Jupiters have small mutual inclinations but large eccentricities . Super - Earths and mini - Neptunes additionally appear to form different series on the radius - mass graph .These conclusions show that these three communities may contain different formation factors or evolutionary histories . In particular , our findings support previous suggestions that super - Earths formed via nucleus accretion followed by significant eastward migration while mini - Neptunes were likely formed through gravity instability .Finally , we show how these results can be used as priors when looking for additional exoplanets using transit surveys such as Kepler .",
        "ori-fast-z-score": -0.7071067811865476,
        "water-fast-z-score": 5.656854249492381
    },
    {
        "original_text": "We present the results of our study on the possible existence and stability of terrestrial planets around the star Gliese 581, which is located at about 20 light-years away from Earth. We have performed numerical simulations for different orbital configurations of three hypothetical terrestrial planets with masses ranging between 1 to 10 times that of Earth s mass (1-10 M⊕). Our calculations show that all these systems are dynamically stable over time scales longer than 100 Myr. The most massive planet has an eccentric orbit with e=0.2 and its periastron distance ranges between 0.05 AU and 0.15 AU depending on the initial conditions used. This planet can be considered as a hot Jupiter-like planet because it orbits very close to its host star. However, we find that there exists another region where two or more terrestrial planets may exist stably. In this region, one of them could be a super-Earth-type planet with a mass larger than 5M⊕ but smaller than 8M⊕.",
        "watermark_text": "We present the conclusion of our research on the possible existence and dynamics of terrestrial worlds around the star Gliese 581 , which is situated at about 20 light - years distance from Earth . We have done mathematical simulations for different orbital arrangements of three hypothetical terrestrial worlds with masses differing between 1 to 10 twice that of Earth s mass ( 1 - 10 M⊕ ) .Our calculations show that all these systems are dynamically stable over time ranges longer than 100 Myr . The most large planet has an eccentric orbit with e = 0 . 2 and its periastron speed ranges between 0 . 05 AU and 0 . 15 AU depending on the early conditions utilized .This planet can be regarded as a bright Jupiter - like planet because it orbits very close to its host star . However , we find that there exists another region where two or more terrestrial worlds may arise stably .In this area , one of them could be a super - Earth - class planet with a mass greater than 5M⊕ but smaller than 8M⊕ .",
        "ori-fast-z-score": -1.3438638879193574,
        "water-fast-z-score": 4.185110693297313
    },
    {
        "original_text": "We present the results of numerical simulations of two-dimensional N = (2, 2)\nsuper-Yang-Mills theory with gauge group SU(N). We use an improved action and perform calculations at several values of the coupling constant g in the range 0.1 < g < 1.0. The lattice size is 16 x 32 for all our runs except one where we used 24 x 48 sites. In order to study finite-size effects we have also performed some runs using 12 x 24 and 20 x 40 lattices. \nThe main goal of this work was to check whether the phase transition between confinement and deconfinement phases observed previously by other authors persists when the continuum limit is approached. \n \n Our data show that there are no significant differences between the results obtained on different sizes of lattices within statistical errors. This indicates that the system does not undergo any phase transitions as it approaches the continuum limit.",
        "watermark_text": "We present the conclusion of statistical simulations of two - dimensional N = ( 2 , 2 ) super - Yang - Mills theory with gauge group SU ( N ) . We use an modified action and conduct measurements at several values of the interaction factor g in the range 0 . 1 < g < 1 . 0 .The lattice size is 16 x 32 for all our runs except one where we using 24 x 48 locations . In order to study discrete - length effects we have already completed some runs use 12 x 24 and 20 x 40 lattices .The main goal of this research was to test whether the phase shift between confinement and deconfinement cycles observed previously by other researchers persists when the continuum limit is neared . Our data demonstrate that there are no considerable variations between the results derived on various sizes of lattices within statistical errors .This implies that the system does not undergo any phase transitions as it approaches the continuum limit .",
        "ori-fast-z-score": -1.5650160901149996,
        "water-fast-z-score": 5.176591682688076
    },
    {
        "original_text": "We present spatially-resolved spectroscopic observations for the central regions (r < 1 kpc) of six nearby, massive early-type galaxies in clusters or groups with Mvir > 1013M⊙. The data were obtained using the Gemini Multi-Object Spectrograph on Gemini North telescope as part of our ongoing program to study the formation histories of these systems. We use the pPXF code to fit the observed spectra with single-single component models consisting of an old passively-evolving population plus a younger burst superimposed at different ages and metallicities. Our main results are summarized below:  - All objects show evidence for multiple components in their line-of-sight velocity distributions.  - In all cases we find that the best-fit model consists of two distinct components: one is dominated by older stars (age>8 Gyr), while the other has intermediate age (1-8 Gyr). - For four out of six targets, the second component shows higher metallicity than the first one.",
        "watermark_text": "We generate spatially - resolved spectroscopic observations for the central regions ( r < 1 kpc ) of six nearby , massive early - type galaxies in clusters or groups with Mvir > [UNK] . The data were obtained using the Gemini Multi - Object Spectrograph on Gemini North telescope as part of our ongoing program to study the formation histories of these systems .We use the pPXF code to pack the known spectra with single - single component versions comprised of an old passively - expanding population plus a later burst superimposed at different ages and metallicities . Our main results are presented below : - All bodies exhibit data for multiple components in their line - of - seeing velocity distributions .- In all situations we find that the best - fitting model consists of two separate phases : one is dominated by older stars ( age > 8 Gyr ) , while the other has intermediate older ( 1 - 8 Gyr ) . - For four out of six targets , the second component displays higher metallicity than the first one .",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 4.798687035041354
    },
    {
        "original_text": "We study the relic density of dark matter (DM) produced by thermal freeze-out and freezein processes in Universal Extra Dimension (UED) model, where we include effects due to Majorana mass terms for the right handed neutrino fields. We find that the DM can be either fermionic or bosonic depending on the values of the parameters involved. In particular, if the UED scale is close to 1 TeV then the DM candidate could be a scalar particle which has been recently proposed as a possible explanation for the PAMELA positron excess observed at high energies. The results are presented in the context of LHC searches for new physics beyond Standard Model. Introduction:-The discovery of the Higgs-like resonance  1-3  at Large Hadron Collider (LHC), alongwith other experimental evidences  4  , have established the existence of a fundamental scalar field responsible for breaking electroweak symmetry. However, there still remain many open questions about the nature of this scalar sector such as: What is its spin? Is it CP-even or odd? Does it couple only to gauge bosons or also to fermions? Are there any additional scalars present in Nature ? These issues will be addressed once more data becomes available from ongoing experiments like ATLAS  5  and CMS  6  . On the theoretical front, one of the most interesting possibilities is to consider extensions of the Standard Model (SM). One possibility is to extend SM into higher dimensions  7-9 , thereby introducing Kaluza-Klein excitations of all particles  10  .\nIn recent years, several authors  11-13  studied the phenomenology of these theories in detail. It was shown that the lightest KaluzaKlein excitation of the graviton may act as cold Dark Matter (CDM)  14-16 . This scenario is particularly appealing since CDM constitutes around 23%  17  of the energy content of our universe  18  . Moreover, the presence of an extra spatial dimension opens up the possibility of producing Kaluza-Klein states through various production mechanisms  19-21  including decay  22  and annihilation  23  . Recently, it has been pointed out  24 ",
        "watermark_text": "We explore the relic thickness of dark matter ( DM ) produced by temperature freeze - out and freezein cycles in Universal Extra Dimension ( UED ) model , where we include effects due to Majorana mass terms for the right handed neutrino fields . We see that the DM can be either fermionic or bosonic varying on the values of the variables required .In particular , if the UED scale is close to 1 TeV then the DM candidate could be a scalar object which has been lately considered as a possible mechanism for the PAMELA positron excess observed at high energies . The results are presented in the context of LHC searches for future physics beyond Standard Model .Introduction : - The observation of the Higgs - like resonance 1 - 3 at Large Hadron Collider ( LHC ) , alongwith other experimental evidences 4 , have confirmed the existence of a basic scalar field involved for breaking electroweak symmetry . However , there still continue several open questions about the nature of this scalar sector such as : What is its spin ?Is it CP - even or odd ? Does it couple only to gauge bosons or also to fermions ?Are there any additional scalars present in Nature ? These issues will be addressed once more data becomes available from continuing studies like ATLAS 5 and CMS 6 .On the theoretical front , one of the most exciting possibilities is to consider extensions of the Standard Model ( SM ) . One possibility is to expanded SM into larger dimensions 7 - 9 , thereby introducing Kaluza - Klein excitations of all particles 10 .In past times , various scientists 11 - 13 examined the phenomenology of these theories in detail . It was shown that the lightest KaluzaKlein excitation of the graviton could act as chill Dark Matter ( CDM ) 14 - 16 .This scenario is especially appealing since CDM constitutes around 23 % 17 of the power content of our universe 18 . Moreover , the presence of an additional spatial dimension opens up the prospect of creating Kaluza - Klein states through several production mechanisms 19 - 21 notably emission 22 and annihilation 23 .Recently, it has been pointed out  24",
        "ori-fast-z-score": 0.9918365981341755,
        "water-fast-z-score": 7.902633289178096
    },
    {
        "original_text": "We present new results on the distribution of loop widths in active regions observed by TRACE at 171 Å, using data obtained during solar maximum (May-June 2001). We find that loops with different temperatures have similar distributions of widths, which are well fitted by log-normal functions. The mean values of these distributions increase with temperature as expected for pressure equilibrium between plasma confined within magnetic structures and their surroundings. However, we also find that there is no significant difference between the widths measured along individual loops and those determined from averaged profiles over entire active regions. This suggests that the apparent constancy of loop widths may be due to averaging effects rather than being intrinsic properties of coronal structures. In addition, we show that the widths derived from observations made under different viewing angles do not depend significantly on the position angle of the line-of-sight relative to the direction perpendicular to the local magnetic field vector.",
        "watermark_text": "We report new data on the distribution of loop widths in active regions observed by TRACE at 171 Å , using data acquired during thermal maximum ( May - June 2001 ) . We see that loops with varying temperatures have similar distributions of widths , which are better fitted by log - normal functions .The mean estimates of these distributions increase with temperature as anticipated for pressure equilibrium between plasma confined within magnetic structures and their environment . However , we also find that there is no considerable difference between the widths calculated along individual loops and those estimated from averaged profiles over whole active regions .This implies that the apparent constancy of loop widths might be due to averaging influences rather than being intrinsic characteristics of coronal structures . In addition , we prove that the widths generated from measurements made under distinct observation angles do not depend greatly on the orientation angle of the line - of - view relative to the direction perpendicular to the local magnetic force vector .",
        "ori-fast-z-score": -0.4364357804719848,
        "water-fast-z-score": 4.939391699536065
    },
    {
        "original_text": "The Sloan Digital Sky Survey (SDSS) is an ongoing project to map the distribution and motion of galaxies, quasars, stars, and other celestial objects in space. The fourth data release was made public on September 30th 2003. This fifth data release contains more than 100,000 new quasar candidates selected by color criteria from the SDSS imaging survey. These are supplemented with about 20,000 previously known quasars that were not included in previous releases because they did not meet the selection criteria for inclusion at that time. \n \n In addition to these newly discovered quasars, this catalog also includes all quasars found during the first four years of the survey as well as those found since then but which have yet to be released publicly. A total of over 250,000 quasars are now available through this catalog. All of them have been spectroscopically confirmed using observations obtained with the dedicated 2.5-meter telescope located at Apache Point Observatory near Sacramento, California.",
        "watermark_text": "The Sloan Digital Sky Survey ( SDSS ) is an continuing work to map the distribution and motion of galaxies , quasars , stars , and other celestial entities in space . The fourth information publication was making public on September 30th 2003 .This fifth information update contains more than 100 , 000 new quasar finalists chosen by color categories from the SDSS imaging survey . These are supplemented with about 20 , 000 former recognized quasars that were not included in earlier versions because they did not meet the selection standards for inclusion at that point .In addition to these newly discovered quasars , this list also contains all quasars discovered during the first four seasons of the census as well as those identified since then but which have never to be available openly . A total of over 250 , 000 quasars are now released through this catalog .All of them have been spectroscopically confirmed using observations collected with the reserved 2 . 5 - meter telescope located at Apache Point Observatory near Sacramento , California .",
        "ori-fast-z-score": -1.5,
        "water-fast-z-score": 5.25
    },
    {
        "original_text": "The Fermi Large Area Telescope (LAT) has revolutionized our understanding of blazar jets by providing unprecedented sensitivity to gamma rays above 100 MeV. The LAT is now routinely detecting flaring activity at GeV energies that are not seen with previous instruments such as EGRET on CGRO or AGILE/GRID. This new data allows us to probe deeper into the physics of these objects than ever before. \n \n In this talk I will discuss how we can use the upcoming generation of space-based observatories - including GLAST and EXIST - to study blazars over an even broader energy range. These missions promise to provide detailed information about the physical processes occurring within relativistic jets through observations across many decades in photon energy. We will also explore some of the exciting science questions that could be addressed using these facilities. Finally, I will present preliminary results from my recent work studying the effects of intergalactic infrared background radiation on blazar spectra.",
        "watermark_text": "The Fermi Large Area Telescope ( LAT ) has revolutionized our knowing of blazar jets by offering extraordinary exposure to gamma radiation above 100 MeV . The LAT is now regularly detecting flaring activity at GeV values that are not seen with previous instruments such as EGRET on CGRO or AGILE / GRID .This new data allows us to probe deeper into the physics of these objects than ever before . In this talk I will explain how we can using the latest generation of space - based observatories - including GLAST and EXIST - to study blazars over an much broader energy range .These expeditions promise to provide comprehensive information about the natural reactions evolving within relativistic jets through observations across many years in photon energy . We will also investigate some of the exciting science problems that might be addressed using these facilities .Finally , I will present preliminary results from my current work studying the effects of intergalactic infrared background radiation on blazar spectra .",
        "ori-fast-z-score": 1.4770978917519928,
        "water-fast-z-score": 6.474980550884177
    },
    {
        "original_text": "The effect of adding small amounts (0.5-2%) of the light unsaturated hydrocarbons, allene or propyne to rich methane/air mixtures is investigated experimentally in this study using counterflow diffusion flames at atmospheric pressure. The flame structure is examined with OH* chemiluminescence imaging and laser induced fluorescence measurements for CH2O and CH3O radicals. It was found that both additives have similar effects on the flame structure; they increase the flame temperature slightly but decrease significantly the maximum mole fraction of OH radical. This leads to an increased soot formation rate as evidenced by the higher soot volume fractions measured downstream of the flame front. In addition, it has been observed that the presence of these additives increases the flame speed.  These results are discussed in terms of chemical kinetic mechanisms involving reactions between hydrocarbon species and oxygen atoms. Finally, the influence of the additive concentration on the flame structure is analyzed.",
        "watermark_text": "The impact of adding small concentrations ( 0 . 5 - 2 % ) of the light unsaturated hydrocarbons , allene or propyne to rich methane / atmosphere mixtures is investigated experimentally in this study using counterflow diffusion flames at atmospheric pressure . The flame composition is investigated with OH * chemiluminescence scanning and infrared triggered fluorescence measurements for CH2O and CH3O radicals .It was shown that both additives have similar influences on the burn structure ; they change the burning heat slightly but decrease greatly the maximum mole proportion of OH radical . This leads to an elevated soot accumulation frequency as demonstrated by the higher soot mass fractions calculated downstream of the burning front .In addition , it has been observed that the presence of these additives increases the burning speed . These data are discussed in terms of chemical kinetic mechanisms governing reactions between hydrocarbon species and oxygen atoms .Finally , the impact of the additive concentration on the flame composition is evaluated .",
        "ori-fast-z-score": -0.8427009716003844,
        "water-fast-z-score": 6.215188768538847
    },
    {
        "original_text": "The physical characteristics, spectral energy distributions (SEDs), and atmospheric properties of late-type dwarfs are reviewed in this chapter.  The SEDs for these objects have been measured by many authors using ground-based telescopes as well as space observatories such as ISO, Spitzer Space Telescope, and AKARI.  These observations show that the infrared flux increases with decreasing effective temperature.  In addition to their red colors, they also exhibit strong water vapor absorption bands at wavelengths longer than 2 microns.   Their near-infrared spectra reveal features due to methane gas which is abundant in their atmospheres.  They also display prominent atomic lines of potassium and sodium in their optical spectra.  Finally, we discuss how the observed photometric data can be used to determine the fundamental parameters of these objects including mass, radius, luminosity, surface gravity, age, metallicity, and distance.   ... This chapter reviews the physical characteristics, spectral energy distribution (SED) measurements, and atmospheric properties of late type dwarfs.",
        "watermark_text": "The physical qualities , spectral power distributions ( SEDs ) , and atmospheric characteristics of late - class dwarfs are reviewed in this page . The SEDs for these objects have been measured by many scientists using ground - based telescopes as well as space observatories such as ISO , Spitzer Space Telescope , and AKARI .These measurements show that the infrared flux changes with decreasing effective heat . In addition to their red colors , they even exhibit strong water vapor absorption groups at wavelengths greater than 2 microns .Their near - infrared spectra demonstrate characteristics owing to methane gas which is abundant in their atmospheres . They even exhibit prominent atomic patterns of potassium and sodium in their infrared spectra .Finally , we explain how the observed photometric data can be used to determine the fundamental variables of these objects including mass , diameter , luminosity , surface gravity , age , metallicity , and distance . . . .This section reviews the physical qualities , spectral power distribution ( SED ) observations , and atmospheric characteristics of late type dwarfs .",
        "ori-fast-z-score": 0.22360679774997896,
        "water-fast-z-score": 6.555555555555555
    },
    {
        "original_text": "The magnetic properties of carbon nanotubes and fullerenes have been studied extensively, but the effect on their electronic structure is still not well understood. In this work we use density functional theory to investigate how the presence of an external magnetic field affects the electronic structure of single-wall zigzag (n = 3) and armchair (n = 4) nanographenes with different sizes. We find that for small n=3 or n=4 nanographenes there are no significant changes in the band gap when applying a magnetic field up to 10 T along the tube axis. However, as the size increases, the energy gaps decrease significantly under applied fields due to the formation of Landau levels. The results show that the magnetic response depends strongly on the chirality of the nanographene. For example, while the zigzag tubes exhibit diamagnetic behavior at low fields, they become paramagnetic above 1 T. On the other hand, the armchair tubes always display paramagnetic behavior even at very weak fields.",
        "watermark_text": "The magnetic properties of carbon nanotubes and fullerenes have been studied thoroughly , but the impact on their electronic structure is also not well understood . In this research we utilize density functional theory to examine how the presence of an external magnetic force influence the electronic structure of double - wall zigzag ( n = 3 ) and armchair ( n = 4 ) nanographenes with various sizes .We see that for little n = 3 or n = 4 nanographenes there are no major changes in the band gap when applying a magnetic force up to 10 T along the tunnel axis . However , as the height rises , the electricity gaps decline considerably under applied fields thanks to the formation of Landau concentrations .The results show that the magnetic response depends strongly on the chirality of the nanographene . For instance , while the zigzag tubes undergo diamagnetic activity at low fields , they become paramagnetic above 1 T . On the other hand , the armchair devices always display paramagnetic activity even at very low fields .",
        "ori-fast-z-score": -1.6059101370939322,
        "water-fast-z-score": 4.965212315030781
    },
    {
        "original_text": "The electronic structure and transport properties of intrinsic ripples on single-layered graphene are investigated by using the tight-binding model with first-principles hopping parameters, which is based on density-functional theory (DFT). The results show that the ripple-induced local strain can lead to an energy gap opening at Dirac point for both armchair and zigzag directions. In addition, it is found that the electron mobility decreases as the amplitude increases due to the increase of scattering centers induced by the ripple structures. These findings may be useful for understanding the physical mechanism behind the experimental observations of rippling effects on the electrical performance of graphene devices. Graphene has attracted great attention because its unique two-dimensional honeycomb lattice structure leads to many novel phenomena such as high carrier mobility  1  , Klein tunneling  2  , valley polarization  3  , etc.. However, recent experiments have shown that the pristine flat monolayer graphene sheets tend to form ripples spontaneously  4  . It was also reported that these ripples could affect the electrical performance of graphene-based devices  5  .\nIn this work we investigate the effect of ripples on the electronic structure and transport properties within the framework of the tight-binding model  6  . We find that the ripple-induced strains can open up an energy gap around the Fermi level for both armchair andzigzag directions. Moreover, the electron mobility decreases as increasing the amplitude of ripples since more scattering centers are introduced into the system.",
        "watermark_text": "The mechanical composition and transport properties of intrinsic ripples on single - layered graphene are examined by using the fast - binding model with first - principles hopping characteristics , which is based on density - functional theory ( DFT ) . The results show that the ripple - caused local tension can lead to an energy gap opening at Dirac position for both armchair and zigzag directions .In addition , it is found that the electron mobility decreases as the frequency rises due to the increase of absorption centers caused by the ripple structures . These conclusions could be valuable for studying the physical mechanism behind the empirical observations of rippling influence on the electrical performance of graphene devices .Graphene has garnered great popularity because its unique two - dimensional honeycomb structure form gives to many novel processes such as long carrier density 1 , Klein tunneling 2 , valley polarization 3 , etc . . However , recent experiments have shown that the pristine rolled monolayer graphene strands tend to form ripples spontaneously 4 .It was also reported that these ripples could affect the electrical performance of graphene - based products 5 . In this research we investigate the impact of ripples on the electronic structure and transport properties within the framework of the tight - binding model 6 .We see that the ripple - mediated strains can offer up an energy gap around the Fermi level for both armchair andzigzag directions . Moreover , the electron mobility decreases as increasing the frequency of ripples since more scattering centers are introduced into the system .",
        "ori-fast-z-score": 0.3746343246326776,
        "water-fast-z-score": 6.80336051416609
    },
    {
        "original_text": "We present the results for hadron production in semiinclusive DIS off nuclei at large Bjorken x and low Q^2, obtained with the HERMES experiment using data taken between 1997 and 2002. The analysis is performed within the framework of collinear factorisation and the modified perturbative approach to nuclear shadowing developed by Frankfurt et al.. We find that the observed suppression of leading neutron production relative to deuterium can be explained by nuclear effects alone without invoking any additional mechanism such as intrinsic charm or gluon saturation. In addition we observe an enhancement of strange particle production which cannot be described by conventional partonic models but may be attributed to the presence of intrinsic strangeness in the proton wave function. \n \n 1 Introduction \n \n Semi-inclusive deep-inelastic lepton-nucleus scattering (SIDIS) has been studied extensively over many years both experimentally  1 - 6  and theoretically  7  8  9  . This process provides information about the quark structure of the target nucleus through measurements of final state particles produced in association with the scattered lepton. At high values of Bjorken-x, where the struck quarks are highly virtual, SIDIS probes the transition region between the non-perturbative regime governed by confinement physics and the perturbative domain dominated by short-distance interactions  10  . \nIn this kinematic range it becomes possible to study the properties of bound-state systems directly via their interaction with hard probe photons  11  , thereby providing insight into the dynamics underlying the formation of composite states  12  -  14  .\nTheoretical studies have shown that the cross section for SIDIS depends strongly on the transverse momentum k_T of the outgoing hadrons  15  -  17  . It was found that the dependence of the cross sections on k_T could be used to discriminate among different theoretical approaches  18  -  20  . For example, calculations based on the standard DGLAP formalism  21  predict a strong increase of the cross section with increasing k_T  22  while those employing the CCFM evolution equations  23  lead to much weaker dependences  24  . \n \n 2 Experimentally measured quantities",
        "watermark_text": "We present the results for hadron emission in semiinclusive DIS off hydrogen at large Bjorken x and low Q ^ 2 , obtained with the HERMES experiment using data taken between 1997 and 2002 . The investigation is conducted within the framework of collinear factorisation and the modified perturbative methodology to nuclear shadowing developed by Frankfurt et al . . We see that the seen suppression of leading neutron production relative to deuterium can be described by nuclear effects alone without invoking any additional process such as intrinsic charm or gluon saturation .In addition we study an enhancement of odd particle production which cannot be described by traditional partonic theories but might be due to the presence of intrinsic strangeness in the proton wave function . 1 Introduction Semi - inclusive shallow - inelastic lepton - nucleus scattering ( SIDIS ) has been studied thoroughly over numerous years both experimentally 1 - 6 and theoretically 7 8 9 .This process provides knowledge about the quark configuration of the target nucleus through measurements of last state particles generated in association with the scattered lepton . At high values of Bjorken - x , where the strikes quarks are extremely virtual , SIDIS probes the transfer region between the non - perturbative period controlled by confinement physics and the perturbative domain dominated by short - distance interactions 10 .In this kinematic range it becomes possible to study the properties of bound - state systems fully via their association with hard probe photons 11 , thereby providing information into the dynamics underlying the formation of composite states 12 - 14 . Theoretical experiments have shown that the cross section for SIDIS relies highly on the transverse momentum n _ T of the outgoing hadrons 15 - 17 .It was shown that the dependence of the cross sections on k _ T might be used to discriminate among different conceptual approaches 18 - 20 . For instance , analyses based on the standard DGLAP formalism 21 predict a positive increase of the cross section with expanding k _ T 22 while those adopting the CCFM evolution equations 23 lead to considerably weaker dependences 24 .2 Experimentally recorded quantities",
        "ori-fast-z-score": -0.7474093186836597,
        "water-fast-z-score": 6.560592908445457
    },
    {
        "original_text": "We present the discovery of two gravitationally lensed quasars, QSO B1608+656A and QSO B1608+655B (hereafter A and B), which are separated by 1.5 arcsec in projection on to the sky but have very different redshifts z = 2.7 and z = 3.6 respectively. The lensing galaxy is identified with an elliptical galaxy at redshift 0.33 located between the quasar images. We find that this system has properties similar to those found for other known gravitational lenses produced by massive clusters of galaxies. However, we show that it can be explained as being due to the lensing effect of only one cluster member -the central globular cluster of the lensing galaxy-if its mass-to-light ratio M/LV ~ 100M⊙ /L⊙ V . This value agrees well with previous estimates based on observations of Galactic globular clusters.",
        "watermark_text": "We report the discovery of two gravitationally lensed quasars , QSO B1608 + 656A and QSO B1608 + 655B ( hereafter A and B ) , which are apart by 1 . 5 arcsec in projection on to the heavens but have very different redshifts z = 2 . 7 and z = 3 . 6 respectively . The lensing galaxy is identified with an elliptical galaxy at redshift 0 . 33 located between the quasar images .We see that this scheme has properties similar to those noted for other known gravitational lenses generated by massive clusters of clusters . However , we find that it can be understood as being owing to the lensing effect of only one cluster member - the main globular cluster of the lensing galaxy - if its mass - to - light density M / LV ~ [UNK] / [UNK] V .This value agrees well with previous estimates based on observations of Galactic globular regions .",
        "ori-fast-z-score": 0.14907119849998599,
        "water-fast-z-score": 4.221158824088691
    },
    {
        "original_text": "We present results on semi-inclusive deep-inelastic scattering (SIDIS), ep -> e  p X , with an emphasis on final state interaction effects for both proton and neutron targets. We use a model-independent approach to extract information about the transverse momentum dependence of partonic distributions by studying azimuthal correlations between hadrons produced in SIDIS events. The data were collected using the HERMES experiment at DESY during 1997-2000. Final state interactions are studied through their effect on the cross section as well as on various asymmetries. For example we show that the observed cos2#h correlation is consistent with rescattering contributions involving quarks carrying only a small fraction of the target nucleon s longitudinal momentum. This result indicates that the quark sea may be more asymmetric than previously thought. Furthermore, our analysis shows that the magnitude of the rescattering contribution depends strongly on the kinematics chosen. Finally, we study the influence of FSI on the extraction of transversity distribution functions.",
        "watermark_text": "We report findings on quasi - inclusive deep - inelastic scattering ( SIDIS ) , ep - > e p X , with an emphasis on final state interaction effects for both proton and neutron targets . We use a theory - independent approach to extract information about the transverse momentum dependence of partonic distributions by examining azimuthal correlations between hadrons observed in SIDIS events .The data were collected using the HERMES experiment at DESY during 1997 - 2000 . Final state effects are studied through their effect on the cross section as well as on various asymmetries .For instance we find that the reported cos2 # h relationship is compatible with rescattering contributions using quarks carrying only a small fraction of the target nucleon s longitudinal momentum . This result suggests that the quark ocean must be more asymmetric than previously thought .Furthermore , our analysis shows that the extent of the rescattering contribution varies strongly on the kinematics selected . Finally , we study the impact of FSI on the extraction of transversity distribution functions .",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 4.242640687119286
    },
    {
        "original_text": "We study the dynamics of string cosmologies with nontrivial dilaton potentials, focusing on their chaotic behavior. We show that for certain classes of potentials there are regions where trajectories can be trapped by unstable fixed points or periodic orbits. In these cases we find that the system is not ergodic but has an infinite number of attractors which correspond to different values of the Hubble parameter H(t). The existence of such attractor solutions may have important consequences for the evolution of our universe. For example, it could explain why the present value of H(t) differs so much from its initial value at t = 0. It also provides a possible explanation for the observed flatness problem since the volume V (t) grows exponentially fast during inflation while the energy density decreases as 1/V (t).\nThe results presented here were obtained using numerical methods based on the fourth-order Runge-Kutta algorithm combined with Newton s method for finding roots.",
        "watermark_text": "We research the dynamics of string cosmologies with nontrivial dilaton potentials , concentrating on their chaotic dynamics . We see that for particular categories of potentials there are areas where trajectories can be trapped by unstable fixed points or periodic orbits .In these circumstances we find that the system is not ergodic but has an endless number of attractors which belong to different values of the Hubble parameter H ( t ) . The existence of such attractor solutions may have important implications for the evolution of our universe .For instance , it could explain why the present value of H ( t ) changes so greatly from its initial value at t = 0 . It additionally offers a possible reason for the seen flatness problem since the volume V ( t ) rises exponentially rapidly during inflation while the electricity capacity reduces as 1 / V ( t ) .The results presented here were obtained using numerical technique based on the fourth - order Runge - Kutta algorithm coupled with Newton s method for finding roots .",
        "ori-fast-z-score": -0.48507125007266594,
        "water-fast-z-score": 4.85071250072666
    },
    {
        "original_text": "We present integral formulas for the steady-state distribution and current in the asymmetric simple exclusion process (ASEP) with open boundaries, which is one of the most important models to describe non-equilibrium phenomena such as traffic flow on highways or biochemical reactions at molecular motors.  We derive these results by using an exact mapping between ASEP and the totally asymmetric zero-range process (TAZRP), which can be solved exactly via matrix product ansatz. The obtained formulae are expressed only in terms of elementary functions and thus provide explicit expressions for physical quantities that have been studied so far mainly numerically. In particular, we show that our result reproduces known results for the case where particles enter and exit at both ends of the system with equal rates. Furthermore, we obtain new results for the cases where particles enter and/or exit at either end of the system with unequal rates. \nI. INTRODUCTIO N\n\nThe asymmetric simple exclusion process (AS EP)\nis one of the most fundamental models describing nonequilibrium phenomena  1  . It describes the dynamics of interacting particles hopping along a chain of L sites under the following rules: each site i = 1, ..., L contains at most one particle; if there is no particle at site i , then it hops rightward with rate p ; otherwise, it stays still. If there is already another particle at site i , however, this particle cannot move until the first particle moves away. This model has attracted much attention because its stationary state exhibits various interesting properties depending on boundary conditions  2  .\nIn recent years, several studies have focused on the so-called open-boundary condition  3  -  8  : Particles enter into the leftmost site of the chain with probability α per unit time and leave from the rightmost site with probability β per unit time. For example, when α = β = 1/2, the stationary state becomes uniform regardless of the initial configuration  9  . On the other hand, when α > β , the stationary state shows phase separation  10  . Moreover, when α < β , the stationary state displays shock profiles  11  . These features make the AS EP a powerful tool to",
        "watermark_text": "We present integral formulas for the stable - state distribution and current in the asymmetric simple exclusion cycle ( ASEP ) with open boundaries , which is one of the most important models to explain non - equilibrium phenomena such as traffic flow on highways or biochemical reactions at molecular motors . We derive these results by using an precise mapping between ASEP and the completely asymmetric zero - range method ( TAZRP ) , which can be solved exactly via matrix product ansatz .The achieved formulae are written only in terms of elementary functions and therefore offer explicit expressions for mechanical parameters that have been studied so far primarily numerically . In particular , we prove that our consequence reproduces known data for the case where objects enter and exit at both sides of the system with equal rates .Furthermore , we obtain new data for the situations where objects enter and / or enter at either end of the process with unequal levels . I . INTRODUCTIO N The asymmetric simple elimination mechanism ( AS EP ) is one of the most important models explaining nonequilibrium phenomena 1 .It studies the dynamics of interacting particles hopping along a network of L locations under the following laws : each site i = 1 , . . . , L includes at most one particle ; if there is no particle at site i , then it hops rightward with speed r ; otherwise , it remains still . If there is already another molecule at site i , however , this particle cannot move until the first particle moves away .This theory has garnered considerable scrutiny because its stationary state exhibits several interesting properties depending on boundary constraints 2 . In recent years , various studies have concentrated on the so - called open - boundary relation 3 - 8 : Particles enter into the leftmost site of the chain with probability α per unit time and leave from the rightmost site with probability β per unit time .For instance , when α = β = 1 / 2 , the stationary state remains regular regardless of the first configuration 9 . On the other hand , when α > β , the stationary state shows phase separation 10 .Moreover , when α < β , the stationary state presents shock profiles 11 . These features make the AS EP a powerful tool to",
        "ori-fast-z-score": 0.6135719910778963,
        "water-fast-z-score": 8.743288094601613
    },
    {
        "original_text": "We have recently shown that the one-range addition theorems derived in our previous work are valid not only for the Coulomb interaction potential but also its derivatives, such as the nuclear attraction potential or the exchange potential. \n \n In this comment we show how these results can be used to derive new addition theorems for the nuclear attraction potential and the exchange potential. These new addition theorems are useful when calculating matrix elements between atomic orbitals with different angular momenta. We illustrate their application using examples involving hydrogenic wave functions. Finally, we discuss some possible extensions of these results. DOI: 10.1063/1.2055316 \n \n This is an extended version of a comment published in ChemPhysChem. DOI: 10.1002/cphc.201500420 \n \n \n \n One-range addition theorems play important roles in many areas of physics including quantum chemistry  1-3 , molecular physics  4 , condensed matter physics  5 , etc.. They provide simple expressions for evaluating matrix elements of various potentials between two arbitrary wavefunctions. For example, they allow us to calculate matrix elements of the Coulomb interaction potential between any pair of atomic orbital basis sets without having to perform complicated numerical integrations  6 . Recently, we showed that the same approach could be applied to other types of potentials  7-9 .",
        "watermark_text": "We have recently shown that the one - range addition theorems generated in our previous study are applicable not only for the Coulomb interaction potential but also its derivatives , such as the atomic attraction potential or the exchange potential . In this comment we give how these results can be used to derive new addition theorems for the atomic attraction potential and the transfer potential .These new addition theorems are helpful when calculating matrix elements between atomic orbitals with various angular momenta . We illustrate their application using examples involving hydrogenic wave systems .Finally , we explain some possible extensions of these results . DOI : 10 . 1063 / 1 . 2055316 This is an extended version of a note published in ChemPhysChem .DOI : 10 . 1002 / cphc . 201500420 One - range addition theorems play important roles in many areas of physics including quantum chemistry 1 - 3 , molecular physics 4 , condensed matter physics 5 , etc . . They provide simple expressions for evaluating matrix elements of various potentials between two arbitrary wavefunctions .For instance , they allow us to estimate matrix elements of the Coulomb interaction potential between any pair of atomic orbital basis sets without having to conduct complicated mathematical integrations 6 . Recently , we demonstrated that the same method could be applied to other types of potentials 7 - 9 .",
        "ori-fast-z-score": -0.5076730825668095,
        "water-fast-z-score": 3.7567808109943908
    },
    {
        "original_text": "We have studied the dependence of growth rates for collisionless magnetic instabilities (CMIs) in nonrelativistic electron-ion plasmas with Maxwellian velocity distributions, using linear kinetic theory. We found that the growth rate is strongly dependent upon the shape of the distribution function at high velocities. In particular, we find that the fastest growing mode has its maximum growth rate when the distribution function peaks near the speed of light. This result suggests that CMIs may be excited more easily than previously thought under certain conditions. \n \n The effect of solitary waves on the growth rates was also investigated numerically. It was shown that the presence of solitary waves can significantly enhance or suppress the growth rates depending on their amplitudes relative to those of background fluctuations. These results are important because they show how nonlinear effects such as solitary wave generation affect the stability properties of plasma systems. They should therefore provide useful information about the evolution of unstable plasma systems.",
        "watermark_text": "We have researched the dependence of growth rates for collisionless magnetic instabilities ( CMIs ) in nonrelativistic electron - ion plasmas with Maxwellian velocity distributions , using linear kinetic theory . We showed that the development frequency is strongly dependent upon the morphology of the distribution function at high velocities .In particular , we find that the fastest growing mode has its highest growth speed when the distribution parameter peaks near the speed of light . This result suggests that CMIs might be excited more easily than previously thought under certain conditions .The impact of solitary waves on the development rates was also examined numerically . It was shown that the presence of solitary waves can significantly affect or resist the development rates depending on their amplitudes compared to those of background fluctuations .These conclusions are important because they show how nonlinear effects such as solitary wave generation affect the stability properties of plasma networks . They should therefore offer useful details about the evolution of unstable plasma networks .",
        "ori-fast-z-score": 1.3251783128981585,
        "water-fast-z-score": 5.963302408041713
    },
    {
        "original_text": "We study spin effects on the lattice QCD using recurrence lattices (RL) with multi-site exchanges, which are constructed by applying the RL transformation to the original fermion action. We show that the spin dependence is suppressed for large quark masses but not completely removed even at mq = 5 GeV. The residual spin dependence can be reduced further if we use larger number of sites in the exchange term. In this work, we adopt Ns = 4 as an example. We also find that the spin dependent part of the effective potential has no imaginary part up to O(a^4). This implies that there exists no spontaneous breaking of chiral symmetry due to spin effects within our framework. Finally, we discuss possible extensions of our method. PACS numbers: 11.15.Ha, 12.38.Gc, 13 .25.Hw \nI. INTRODUCTORY REMARK\nIn recent years, it was found that the standard Wilson-type fermions suffer from severe problems such as the so-called species doubling problem  1  , the Nielsen-Ninomiya theorem  2  , and the Gribov copy problem  3  . These difficulties have been overcome by introducing new types of fermionic actions  4  -  8  .\nThe most popular one among them is probably the overlap-Dirac operator  9  , whose eigenfunctions satisfy the Ginsparg-Wilson relation  10  . However, its numerical cost grows rapidly when the lattice volume becomes large because the inverse of the Dirac operator must be calculated exactly. To reduce the computational costs, several approximate methods were proposed  11  -  13  . Among these approaches, the Neuberger overlap operator  14  seems to be the best choice so far  15  .\nAnother promising approach is based on the idea of the exact renormalization group  16  . It was shown  17  that the fermion determinant detD(μ), where D(μ) denotes the fermion matrix defined through the fermion action Sf  U  ≡ ∑x Tr γμD(μ)Ux , satisfies the following flow equation:",
        "watermark_text": "We research spin effects on the lattice QCD utilizing recurrence lattices ( RL ) with multi - location exchanges , which are built by using the RL shift to the previous fermion action . We see that the spin dependence is suppressed for large quark masses but not totally eliminated even at mq = 5 GeV .The residual spin effect can be reduced further if we using larger number of places in the transfer term . In this study , we follow Ns = 4 as an instance .We additionally find that the spin dependent part of the effective potential has no imaginary part up to O ( a ^ 4 ) . This implies that there exists no premature breaking of chiral symmetry due to spinning factors within our framework .Finally , we investigate possible extensions of our technique . PACS numbers : 11 . 15 . Ha , 12 . 38 . Gc , 13 . 25 . Hw I .INTRODUCTORY REMARK In recent years , it was shown that the standard Wilson - class fermions suffer from severe challenges such as the so - called genus doubling question 1 , the Nielsen - Ninomiya conjecture 2 , and the Gribov copies problem 3 . These difficulties have been overcome by introducing novel forms of fermionic operations 4 - 8 .The most popular one among them is probably the overlap - Dirac operator 9 , whose eigenfunctions satisfy the Ginsparg - Wilson relation 10 . However , its numerical cost rises steadily when the lattice volume becomes large because the inverse of the Dirac operator must be determined exactly .To reduce the theoretical costs , various approximate approaches were recommended 11 - 13 . Among these method , the Neuberger overlap operator 14 says to be the best choice so far 15 .Another promising alternative is based on the idea of the exact renormalization group 16 . It was shown 17 that the fermion determinant detD ( μ ) , where D ( μ ) denotes the fermion matrix established through the fermion action Sf U ≡ [UNK] Tr γμD ( μ ) Ux , satisfies the following fluid equation :",
        "ori-fast-z-score": -0.8838834764831843,
        "water-fast-z-score": 7.424621202458749
    },
    {
        "original_text": "We present new results on outflow properties in quasars based on observations with Chandra, XMM-Newton, Spitzer Space Telescope (SST), Hubble Space Telescope (HST) and ground-based optical telescopes. We find that quasar winds are ubiquitous at all luminosities probed by our sample; they have high velocities (up to 0.26c) and mass loss rates (10-100 Msun/yr). The wind kinetic power is comparable or exceeds the bolometric luminosity for most objects studied here. Winds appear to be launched close to the central black hole but can extend up to several hundred parsecs away. They show evidence for both thermal and non-thermal emission components. In addition we report on the discovery of an X-ray absorber associated with one of these winds which has been previously detected only in absorption lines seen in UV spectra. This absorber shows significant variability over timescales as short as days.",
        "watermark_text": "We report new data on outflow properties in quasars based on observations with Chandra , XMM - Newton , Spitzer Space Telescope ( SST ) , Hubble Space Telescope ( HST ) and land - based optical telescopes . We see that quasar clouds are ubiquitous at all luminosities probed by our sample ; they have high velocities ( up to 0 . 26c ) and mass loss patterns ( 10 - 100 Msun / yr ) .The wind kinetic power is equal or exceeds the bolometric luminosity for most objects discussed here . Winds appear to be launched close to the central black hole but can extend up to several hundred parsecs apart .They show proof for both thermal and non - thermal emitted elements . In addition we publish on the discovery of an X - ray absorber associated with one of these winds which has been previously observed only in absorption patterns shown in UV spectra .This absorber indicates considerable variability over timescales as short as days .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.532898610306738
    },
    {
        "original_text": "We have recently shown that the primordial spectrum of density fluctuations can be obtained by solving an initial value problem for a massless scalar field in deSitter space-time, which is known as the cosmological slingshot effect (CSE). In this work we show how to match the CSE predictions with those of the Wilkinson Microwave Anisotropy Probe 3-year data release (WMAP3) and compare them against other models. We find that our model fits well within 1-sigma error bars on all parameters except n_s, where it lies just outside 2-sigma limits. The best-fit values are given by:  H_0 = 72.6 +/- 0.9 km/s/Mpc,  Omega_m = 0.26 +/- 0.01,   Omega_Lambda = 0.74 +/- 0.02,    n_s = 0.96 +/- 0.06.   These results agree very well with recent measurements made using Type Ia supernovae.  Our analysis shows that the CSE provides a viable alternative explanation for the origin of cosmic structure formation.",
        "watermark_text": "We have recently shown that the primordial range of density fluctuations can be obtained by solving an initial value problem for a massless scalar field in deSitter space - time , which is known as the cosmological slingshot phenomenon ( CSE ) . In this research we find how to tie the CSE predictions with those of the Wilkinson Microwave Anisotropy Probe 3 - month data release ( WMAP3 ) and compare them against other models .We see that our model fits well within 1 - sigma error bars on all parameters except k _ s , where it lies just outside 2 - sigma limits . The best - fitting values are given by : H _ 0 = 72 . 6 + / - 0 . 9 km / s / Mpc , Omega _ m = 0 . 26 + / - 0 . 01 , Omega _ Lambda = 0 . 74 + / - 0 . 02 , n _ s = 0 . 96 + / - 0 . 06 .These conclusions agree very best with recent observations made using Type Ia supernovae . Our study shows that the CSE provides a viable alternative theory for the origin of universe mechanism formation .",
        "ori-fast-z-score": -0.9271726499455306,
        "water-fast-z-score": 3.841143835488627
    },
    {
        "original_text": "We study evolutionary games played by agents that are randomly distributed over the nodes of an unstructured network, and interact only with their immediate neighbors in this network. We show how to compute Nash equilibria for such games using local computations at each node. Our approach is based on computing best responses locally at every agent s neighborhood, which we then use as input to a global algorithm that computes all Nash equilibria. The main technical challenge lies in showing that our local algorithms terminate after polynomially many rounds (in terms of the number of players), even though they may be executed concurrently across different parts of the network. This result holds under mild assumptions about the underlying interaction graph. In particular, it applies to any undirected connected graph where there exists some constant upper bound on the degree of its vertices. As a consequence, we obtain polynomial-time algorithms for finding Nash equilibria in several classes of games including congestion games, matching pennies games, and coordination games.",
        "watermark_text": "We research evolutionary matches played by agents that are randomly distributed over the nodes of an unstructured system , and interact only with their immediate relatives in this network . We see how to compute Nash equilibria for such players using local computations at each node .Our strategy is based on solving best responses locally at every agent s neighborhood , which we then use as input to a global algorithm that computes all Nash equilibria . The main engineering obstacle lies in showing that our regional algorithms end after polynomially many tournaments ( in terms of the number of teams ) , even though they may be executed concurrently across different components of the organization .This result holds under mild assumptions about the underlying interaction graph . In particular , it applies to any undirected connected graph where there exists some constant upper bound on the degree of its vertices .As a consequence , we obtain polynomial - time computers for finding Nash equilibria in multiple groups of games including congestion games , matching pennies games , and coordination games .",
        "ori-fast-z-score": 1.2074068598865937,
        "water-fast-z-score": 4.939391699536065
    },
    {
        "original_text": "In this work, we present an algorithm for the analysis and comparison of profile Hidden Markov Models (HMMs). The proposed method is based on the concept of Structural Similarity Index Measurement (SSIM) which has been widely used in image processing to measure similarity between two images. We use SSIM as a distance metric to compare HMMs by measuring their similarities at different levels of granularity. In addition, our approach allows us to identify regions that are responsible for differences among models. Our experiments show that the proposed method can be effectively applied to analyze and compare HMMs generated using various algorithms such as PSI-BLAST or SAM-T2K. This research was supported by NSERC Discovery Grant RGPIN-2014-04567 awarded to Dr. Yi-Chun Wu. Profile hidden markov model(HMM),Structural similarity index measurement(SSIM),Similarity score matrix(SCM),PSI-BLAST",
        "watermark_text": "In this research , we present an algorithm for the evaluation and contrast of model Hidden Markov Models ( HMMs ) . The proposed approach is based on the idea of Structural Similarity Index Measurement ( SSIM ) which has been widely useful in image processing to measure similarity between two images .We use SSIM as a distance metric to identify HMMs by assessing their similarities at different levels of granularity . In addition , our approach allows us to identify areas that are responsible for variations among models .Our experiments indicate that the suggested method can be effectively used to analyze and compare HMMs generated using numerous algorithms such as PSI - BLAST or SAM - T2K . This research was supported by NSERC Discovery Grant RGPIN - 2014 - 04567 granted to Dr . Yi - Chun Wu .Profile hidden markov model ( HMM ) , Structural similarity index monitoring ( SSIM ) , Similarity rating matrix ( SCM ) , PSI - BLAST",
        "ori-fast-z-score": -0.40451991747794525,
        "water-fast-z-score": 5.258758927213289
    },
    {
        "original_text": "We report on high-resolution spectroscopy of the lithium-like ions C VI, N VII, O VIII, Ne IX, Mg XI, Si XIII, S XV, Ar XVII, Ca XIX, Fe XXIII, Ni XXIX observed with Chandra HETGS during an outburst of the black hole candidate Cen X-4 (Nova Muscae 1991). The measured line fluxes are used to determine the abundance ratios between different elements as well as their relative abundances compared to solar values. We find that the Li-Be-B element abundances are enhanced by factors up to 100 times solar for some lines. This is consistent with previous results obtained using ASCA data taken at lower spectral resolution. In addition we detect strong emission features due to highly ionized iron which have not been seen before in this source. These new observations allow us to study the chemical composition of the accretion disk around the compact object more accurately than previously possible.",
        "watermark_text": "We report on wide - resolution spectroscopy of the lithium - like ions C VI , N VII , O VIII , Ne IX , Mg XI , Si XIII , S XV , Ar XVII , Ca XIX , Fe XXIII , Ni XXIX found with Chandra HETGS during an outburst of the dark hole contender Cen X - 4 ( Nova Muscae 1991 ) . The measured line fluxes are using to estimate the availability proportions between various objects as well as their relative abundances compared to solar values .We see that the Li - Be - B element abundances are increased by factors up to 100 times solar for some lines . This is compatible with previous findings obtained using ASCA information taken at lower spectral resolution .In addition we perceive strong radiation elements owing to strongly ionized iron which have not been seen before in this source . These new studies permit us to study the chemical composition of the accretion disk around the compact body more accurately than previously possible .",
        "ori-fast-z-score": -1.2909944487358056,
        "water-fast-z-score": 4.905778905196061
    },
    {
        "original_text": "We present an improved factorization formula for the fragmentation functions (FFs) of hadrons containing one heavy quark, which is valid in both leading order and next-to-leading order QCD perturbation theory. The new formula takes into account all possible contributions to the FFs at each perturbative order. We show that our results are consistent with those obtained by using other approaches such as the operator product expansion method or the renormalization group equation approach. Finally we give numerical predictions on some important quantities related to the charm-quark FFs. PACS numbers: 12.38.Qk, 13.25.Gv, 11.15.Tk \nI. INTRODUCTORY REMARK\nThe fragmentation function D(z), where z = Phadron/Pquark , describes how quarks fragment into hadrons when they are produced in hard processes like deep-inelastic scattering  1  . It plays an essential role in understanding many phenomena observed experimentally  2  .\nIn this work, we will study the fragmentation functions of hadronic states containing only one heavy quark. In particular, we consider the case of charmed-meson production in e + e-annihilation processes:",
        "watermark_text": "We introduce an updated factorization formula for the fragmentation functions ( FFs ) of hadrons containing one heavy quark , which is valid in both leading order and last - to - leading order QCD perturbation theory . The revised formula takes into consideration all possible contributions to the FFs at each perturbative order .We see that our findings are compatible with those achieved by using other methods such as the operator product expansion method or the renormalization group function method . Finally we give quantitative predictions on some important quantities related to the charm - quark FFs .PACS codes : 12 . 38 . Qk , 13 . 25 . Gv , 11 . 15 . Tk I . INTRODUCTORY REMARK The fragmentation relation D ( z ) , where z = Phadron / Pquark , explains how quarks cluster into hadrons when they are produced in hard processes like shallow - inelastic scattering 1 .It plays an essential part in understanding several phenomena observed experimentally 2 . In this research , we will research the fragmentation processes of hadronic states involving only one heavy quark .In particular , we treat the case of charmed - meson production in e + e - annihilation processes :",
        "ori-fast-z-score": -0.11867816581938533,
        "water-fast-z-score": 5.976143046671968
    },
    {
        "original_text": "We present near-infrared photometry for brown dwarfs (BDs) with masses below 0.075 Msun, members of the young open cluster Lambda Orionis. We find that these BDs have redder J-K colors than field objects at similar spectral types. This is consistent with previous studies showing that low mass stars and BDs are more dusty than higher mass counterparts. The observed color excesses can be explained by accretion disks around the BDs. Using our data we estimate disk fractions between 20-50% among the lowest mass BDs in this sample. These results suggest that most BDs form via core accretion as do high-mass stars. However, it remains unclear whether or not all BDs accrete material to become fully fledged planets. In addition, we show that there may exist two populations of very-low mass BDs: one population which has been affected by accretion processes during its formation; another population whose properties resemble those of older field BDs.",
        "watermark_text": "We see near - infrared photometry for brown dwarfs ( BDs ) with masses below 0 . 075 Msun , part of the young open dwarf Lambda Orionis . We see that these BDs have redder J - K colors than field objects at comparable spectral classes .This is consistent with previous research indicating that minimum mass stars and BDs are more dusty than higher mass rivals . The observed brightness excesses can be described by accretion disks around the BDs .Using our information we estimate disk fractions between 20 - 50 % among the lowest mass BDs in this specimen . These data suggest that most BDs form via nucleus accretion as do large - density stars .However , it remains unsure whether or not all BDs accrete material to become completely fledged planets . In addition , we find that there may contain two communities of very - low mass BDs : one community which has been affected by accretion events during its formation ; another population whose characteristics resemble those of older field BDs .",
        "ori-fast-z-score": -1.61245154965971,
        "water-fast-z-score": 5.169842621131974
    },
    {
        "original_text": "We report on the detection and analysis of an optical shock front in the supernova remnant (SNR) Tycho using data obtained with Subaru High Dispersion Spectrograph (HDS). The observed spectrum shows strong emission lines of hydrogen, helium, nitrogen, oxygen, sulfur, argon, calcium, magnesium, silicon, iron ions at wavelengths between 3200Å and 9400Å. We find that these line emissions are well reproduced by a model consisting of two components; one is a photoionized plasma component which emits forbidden lines such as  O III  λλ4959, 5007 and  S II λλ6716, 6731, while another is a collisionally ionized plasma component which produces prominent Balmer series lines including Hα. From this result we conclude that the detected shock front is dominated by collisional ionization rather than photo-ionization. \n \n Keywords: Supernova remnants",
        "watermark_text": "We report on the discovery and evaluation of an optical shock front in the supernova remnant ( SNR ) Tycho using data received with Subaru High Dispersion Spectrograph ( HDS ) . The observed spectrum displays large emitted lines of sulfur , helium , nitrogen , hydrogen , sulfur , argon , potassium , magnesium , silicon , iron ions at wavelengths between 3200Å and 9400Å .We see that these line emissions are better illustrated by a theory consisting of two parts ; one is a photoionized plasma component which emits forbidden lines such as O III λλ4959 , 5007 and S II λλ6716 , 6731 , while another is a collisionally ionized plasma component which generates distinctive Balmer series curves including Hα . From this consequence we suppose that the detected shock front is dominated by collisional ionization instead than photo - ionization .Keywords: Supernova remnants",
        "ori-fast-z-score": -1.8203641092364127,
        "water-fast-z-score": 3.780756226875626
    },
    {
        "original_text": "The Sun is the nearest star to Earth, and its activity has been studied for thousands of years.  The Sun s magnetic field plays an important role in solar activity.   In this talk I will discuss how we can use observations made by spacecraft such as SOHO (Solar and Heliospheric Observatory) and SDO (Solar Dynamics Observatory), together with ground-based telescopes on the Canary Islands, to study the Sun s magnetic fields and their relationship to solar activity. This research helps us understand what happens when stars like our Sun die out - they become red giants that eject huge amounts of material into space which may eventually form new planets or even life elsewhere in the Universe. Keywords: Solar Activity, Red Giant Star, Magnetic Field, Space Weather. Title: Cool Stars in Hot Places. Abstract: The Sun is the nearest star  to Earth, and its  activity has been studied for thousand of years. The Sun s magnetic field play an important role in solar activities. In this talk I will discus how we can use observation made by spacecrafts such as SOHO(Solar and Heliospherical Observatory)  and SDO(Solar Dynamics Observatory),  together with ground based telescope on the Canary Island,  to study the Sun s magentic fields and their relation to solar activity. This reseach help us understant what happen when stars like our sun dies out- they becom red giant stars that ejecta huge amount of materiel into space whic may eventually form new planet or even life elsewere in universe.",
        "watermark_text": "The Sun is the nearest star to Earth , and its activity has been studied for thousands of years . The Sun s magnetic force plays an important role in solar activity .In this talk I will explore how we can using observations made by satellites such as SOHO ( Solar and Heliospheric Observatory ) and SDO ( Solar Dynamics Observatory ) , combined with ground - based telescopes on the Canary Islands , to study the Sun s magnetic waves and their connection to solar activity . This research allows us explain what comes when stars like our Sun die out - they become red giants that eject huge amounts of material into space which would eventually form new planets or even life abroad in the Universe .Keywords : Solar Activity , Red Giant Star , Magnetic Field , Space Weather . Title : Cool Stars in Hot Places .Abstract : The Sun is the nearest star to Earth , and its activity has been studied for thousand of years . The Sun s magnetic force serve an important role in solar movements .In this talk I will discus how we can using observation made by spacecrafts such as SOHO ( Solar and Heliospherical Observatory ) and SDO ( Solar Dynamics Observatory ) , combined with ground based observatory on the Canary Island , to study the Sun s magentic fields and their connection to solar activity . This reseach help us understant what happen when stars like our sun kills out - they becom red massive planets that ejecta huge amount of materiel into space whic may eventually form new planet or even life elsewere in universe .",
        "ori-fast-z-score": 2.041241452319315,
        "water-fast-z-score": 6.736096792653741
    },
    {
        "original_text": "We demonstrate that it is possible to generate all four Bell states in one single nonlinear crystal by using two pump beams with orthogonal polarizations and slightly different wavelengths, which are generated via second-harmonic generation (SHG) inside an optical parametric oscillator (OPO). The OPO consists of a periodically poled lithium niobate (PPLN) crystal as nonlinear medium and a concave mirror for cavity feedback. We show experimentally that this approach allows us to obtain high-visibility quantum interference between photons emitted at degenerate wavelength pairs across the entire PPLN acceptance bandwidth. This method can be used to simplify future experiments on continuous-variable entanglement distribution over large distances. \n \n Quantum information processing requires the ability to create and manipulate entangled states of light. In particular, the Bell state measurement plays a key role in many applications such as teleportation or quantum repeaters  1  . However, generating these highly nonclassical states is challenging because they require indistinguishable photon pairs  2  , which cannot be produced deterministically  3  .\nIn recent years, several approaches have been developed to overcome this problem  4  . One possibility is based on spontaneous parametric down-conversion (SPDC), where a pump beam creates correlated pairs of signal and idler photons  5  . By adjusting the relative phases of the pump fields  6  , it has become possible to produce any desired superposition of the four Bell states  7, 8  . Another option uses squeezed vacuum states  9  or displaced number states  10  instead of coherent laser pulses  11  . These methods allow for efficient generation of entangled states but usually suffer from low visibility due to imperfections  12  .",
        "watermark_text": "We suggest that it is easy to create all four Bell states in one single nonlinear crystal by using two pump beams with orthogonal polarizations and slightly different wavelengths , which are produced via second - harmonic production ( SHG ) inside an optical parametric oscillator ( OPO ) . The OPO consists of a periodically poled lithium niobate ( PPLN ) crystal as nonlinear material and a concave frame for cavity feedback .We suggest experimentally that this methodology allows us to obtain high - visibility particle interference between photons generated at degenerate intensity pairs across the entire PPLN acceptance bandwidth . This method can be used to simplify future research on continuous - variable entanglement flow over large distances .Quantum knowledge processing requires the ability to create and manipulate entangled states of light . In particular , the Bell state measurement plays a key importance in many applications such as teleportation or quantum repeaters 1 .However , constructing these strongly nonclassical states is problematic because they use indistinguishable photon pairs 2 , which cannot be made deterministically 3 . In recent years , various approaches have been formulated to overcome this situation 4 .One possibility is based on spontaneous parametric down - transfer ( SPDC ) , where a pump beam creates correlated pairs of signal and idler photons 5 . By adjusting the relative modes of the pump fields 6 , it has become able to produce any desired superposition of the four Bell states 7 , 8 .Another option uses squeezed vacuum states 9 or displaced number states 10 instead of coherent beam waves 11 . These methods provide for efficient production of entangled states but typically suffer from small brightness due to imperfections 12 .",
        "ori-fast-z-score": 0.7302967433402214,
        "water-fast-z-score": 6.818181818181818
    },
    {
        "original_text": "We present the first detection and characterization of polarized foreground emission at microwave frequencies using three years of data from WMAP. We find that this emission is dominated by synchrotron radiation, with an amplitude consistent with previous measurements in the literature. The polarization fraction for this component ranges between 0.5% to 2% across the sky. In addition we detect significant levels of polarized dust emission over much of the sky. This emission has a lower fractional polarization than previously reported but its total intensity is comparable or higher. Finally, we report on the detection of polarized thermal Sunyaev-Zeldovich effect associated with galaxy clusters. These results are important as they provide new information about Galactic foregrounds which will be used to extract cosmological signals such as primordial gravitational waves. \n \n Keywords: Cosmic microwave background anisotropies, Galaxy cluster, Synchrotron Radiation, Dust Emission, Thermal Sunyaev-Zeldovitch Effect",
        "watermark_text": "We present the first recognition and description of polarized foreground emission at microwave frequencies using three years of measurements from WMAP . We see that this emission is dominated by synchrotron emission , with an frequency consistent with previous detection in the literature .The polarization fraction for this component varies between 0 . 5 % to 2 % across the sky . In addition we find considerable rates of polarized dust pollution over much of the sky .This emission has a smaller fractional polarization than previously reported but its total activity is equal or greater . Finally , we publish on the observation of polarized thermal Sunyaev - Zeldovich effect related with star clusters .These data are important as they give novel knowledge about Galactic foregrounds which will be used to extract cosmological messages such as primordial gravitational waves . Keywords : Cosmic microwave background anisotropies , Galaxy cluster , Synchrotron Radiation , Dust Emission , Thermal Sunyaev - Zeldovitch Effect",
        "ori-fast-z-score": -1.0327955589886444,
        "water-fast-z-score": 4.816989706290483
    },
    {
        "original_text": "The thermal Casimir force is the quantum mechanical effect that arises when two objects are separated by vacuum, which causes them to attract each other due to zero-point fluctuations in their electromagnetic fields.  In this talk I will present some recent results for the thermal Casimir force between dielectrics as well as related problems such as the van der Waals interaction between polarizable atoms or molecules at finite temperature. The first part of my talk will be devoted to an overview of our work on the subject published recently in Physical Review Letters (PRL)  1  . This includes new exact expressions for the thermal Casimir energy density and pressure valid for arbitrary temperatures and dielectric functions. These formulas can also be used to calculate the leading order corrections to Lifshitz theory  2  , which has been widely applied to describe the Casimir force between real materials  3  .\nIn the second part of my talk I will discuss how these results have been extended to include retardation effects  4  . We find that retardation leads to additional contributions to both the energy density and pressure that depend strongly on the distance between the bodies. Finally, we will show how these results can be used to study the van der Waals interactions between polarizable atoms or molecules; i.e., systems where retardation plays no role but where the dispersion forces still give rise to non-trivial behavior  5  .  For example, we will demonstrate how one can use our formalism to obtain accurate predictions for the critical point of the liquid-vapor phase transition in water  6  .",
        "watermark_text": "The thermal Casimir force is the quantum mechanical effect that arises when two bodies are apart by vacuum , which makes them to attract each other owing to zero - point fluctuations in their electromagnetic fields . In this talk I will present some latest findings for the thermal Casimir force between dielectrics as well as related problems such as the van der Waals interaction between polarizable atoms or compounds at finite temperature .The first part of my talk will be devoted to an overview of our work on the subject released lately in Physical Review Letters ( PRL ) 1 . This contains new accurate expressions for the thermal Casimir energy density and tension applicable for arbitrary pressures and dielectric functions .These formulas can also be used to estimate the main order corrections to Lifshitz principle 2 , which has been widely applied to explain the Casimir force between real substances 3 . In the second part of my talk I will explore how these results have been extended to include retardation properties 4 .We see that retardation contributes to extra contributions to both the power concentration and tension that rely highly on the distance between the bodies . Finally , we will show how these results can be used to study the van der Waals relationships between polarizable atoms or compounds ; i . e . , systems where retardation plays no part but where the dispersion forces nevertheless give rise to non - simple properties 5 .For instance , we will prove how one can using our formalism to obtain precise predictions for the important moment of the liquid - fluid phase shift in water 6 .",
        "ori-fast-z-score": 0.4622501635210242,
        "water-fast-z-score": 7.799204203436179
    },
    {
        "original_text": "The growth in stellar mass is driven by star formation, which occurs when dense gas collapses to form stars.  The rate at which this happens depends on how much gas there is available for collapse.   In turn, the amount of gas available for collapse depends on the balance between inflow (from larger scales) and outflow (from smaller scales).   This talk will discuss recent work that has been done using numerical simulations to understand these processes better. It will also present some new results on the role played by magnetic fields during star formation. Star formation takes place when dense gas clouds collapse under their own gravity into bound objects called protostars.  These protostars then grow through accretion until they reach the main sequence stage where nuclear fusion begins.  During this process, gravitational energy is released as radiation and kinetic energy, heating up surrounding material and driving powerful winds and jets.  As such, understanding what controls the rate at which stars are formed requires an understanding of how gas flows onto forming stars.  Gas can flow towards forming stars either directly or indirectly via filaments.  Directly flowing gas may be channeled along magnetic field lines while indirectly flowing gas may be transported along with turbulent motions.  Both types of flows have been observed around young stars but it remains unclear whether one type dominates over another.  Recent observations suggest that both direct and indirect flows play important roles depending on the environment.  For example, observations show that most low-mass stars accrete...",
        "watermark_text": "The growth in stellar mass is caused by star formation , which occurs when dense gas collapses to form stars . The rate at which this happens depends on how many gas there is provided for collapse .In turn , the quantity of gas provided for collapse depends on the balance between inflow ( from larger scales ) and outflow ( from lower scales ) . This discussion will explore latest work that has been performed using numerical simulations to comprehend these mechanisms better .It will also bring some fresh results on the part played by magnetic fields during star formation . Star formation occurs place when dense gas formations sink under their own gravitational into binding structures called protostars .These protostars then grow through accretion until they reach the main sequence phase where nuclear fusion occurs . During this process , gravity energy is released as radiation and kinetic power , heating up surrounding rock and generating powerful storms and jets .As such , studying what controls the pace at which stars are created requires an knowledge of how gas transfers onto forming stars . Gas can move towards forming stars either directly or indirectly via filaments .Directly flowing gas may be channeled along magnetic field lines while indirectly running gas may be transported along with turbulent movements . Both types of flows have been observed around old galaxies but it remains unsure whether one sort dominates over another .Recent measurements suggest that both direct and indirect flows act key roles depending on the surroundings . For instance , observations show that most lowest - weight objects accrete . . .",
        "ori-fast-z-score": -0.7689218919450849,
        "water-fast-z-score": 8.172062695283987
    },
    {
        "original_text": "The formation and characterization of bovine serum albumin (BSA) nanoparticles formed by electrostatic interaction between anionic graft copolymer poly(acrylic acid-co-methacrylamide) (PAM-g-PAA) and protein in aqueous solution are reported here. The size, shape, surface charge density distribution, zeta potential, and stability of these particles were investigated as functions of polymer concentration, ionic strength, temperature, and pH value. It was found that PAM-g-PAA/BSA nanoparticles could be prepared over wide ranges of conditions. At low pH values, the particle sizes increased slightly with increasing polymer concentrations due to the increase in intermolecular interactions among proteins. However, when the pH value reached 7.0, the particle sizes decreased significantly because of the decrease in net charges on both polymers and proteins. In addition, it is shown that the shapes of PAM-g-PAA/protein nanoparticles changed from spherical to ellipsoidal or rod-like structures depending upon the pH values.",
        "watermark_text": "The formation and description of bovine plasma albumin ( BSA ) nanoparticles formed by electrostatic interaction between anionic graft copolymer poly ( acrylic acid - co - methacrylamide ) ( PAM - g - PAA ) and protein in aqueous solution are published here . The size , shape , surface charge density distribution , zeta potential , and strength of these ions were researched as functions of polymer concentration , ionic intensity , temperature , and pH value .It was shown that PAM - h - PAA / BSA nanoparticles able be formed over broad ranges of conditions . At reduced pH levels , the particle sizes increased slightly with higher polymer levels related to the increase in intermolecular interactions among proteins .However , when the pH value reached 7 . 0 , the particle sizes reduced greatly because of the decrease in net charges on both polymers and proteins . In addition , it is demonstrated that the shapes of PAM - h - PAA / gene nanoparticles changed from spherical to ellipsoidal or rod - like structures depending upon the pH levels .",
        "ori-fast-z-score": -1.0681034923744679,
        "water-fast-z-score": 4.478342947514801
    },
    {
        "original_text": "We present an explicit, physically sound formulation for the dynamical Casimir effect (DCE) in terms of a time-dependent Schrödinger equation with a non-Hermitian effective potential that is derived directly from first principles and has no free parameters.  The resulting expression agrees exactly with previous results obtained by other authors using different methods but it also provides new insights into this fascinating quantum phenomenon. In particular we show how to calculate the energy spectrum of the system as well as its decay rates and lifetimes. We demonstrate our approach on two examples - one involving a single harmonic oscillator coupled to a thermal bath at finite temperature and another where the oscillators are replaced by fermions. Finally, we discuss possible extensions of these ideas beyond the standard model of particle physics. The dynamical Casimir effect (DCE), predicted more than twenty years ago  1-3 , refers to the generation of photons due to vacuum fluctuations when macroscopic objects move or change shape  4  . This intriguing prediction was confirmed experimentally only recently  5-7  , although there have been earlier suggestions  8  .\nThe original theoretical description of the DCE relied heavily on phenomenological models which were not always easy to interpret physically  9  . More recent attempts  10-12  used microscopic approaches based on non-relativistic QED  13-15  or relativistic field theory  16  . However, all such treatments involve some ad-hoc assumptions about the form of the interaction between the moving object(s) and the electromagnetic fields  17  . Here we propose a completely different method that avoids any such approximations and leads to a simple, transparent physical picture of the process. Our starting point is the exact Heisenberg-Langevin equations describing the dynamics of the electric field operatorsÊ(r, t). These can be written in the compact form:",
        "watermark_text": "We present an explicit , physically sound formulation for the dynamical Casimir effect ( DCE ) in terms of a time - dependent Schrödinger equation with a non - Hermitian effective potential that is developed directly from initial principles and has no free parameters . The resulting expression agrees exactly with previous findings obtained by other researchers using separate methods but it also provides new information into this fascinating quantum concept .In particular we prove how to estimate the power spectrum of the system as well as its degradation times and lifetimes . We test our approach on two examples - one utilizing a single harmonic oscillator coupled to a heat shower at finite temperature and another where the oscillators are replaced by fermions .Finally , we investigate possible extensions of these ideas beyond the standard theory of particle theory . The dynamical Casimir effect ( DCE ) , predicted more than twenty years previously 1 - 3 , relates to the generation of photons due to vacuum fluctuations when macroscopic objects moving or change form 4 .This unusual prediction was confirmed experimentally only recently 5 - 7 , although there have been earlier suggestions 8 . The original theoretical formulation of the DCE depended heavily on phenomenological models which were not always easier to predict physically 9 .More current approaches 10 - 12 used microscopic techniques based on non - relativistic QED 13 - 15 or relativistic field principle 16 . However , all such treatments include some ad - hoc assumptions about the form of the interaction between the moved object ( s ) and the electromagnetic forces 17 .Here we attempt a completely different method that avoids any such approximations and leads to a simple , straightforward mechanical picture of the process . Our starting point is the exact Heisenberg - Langevin coefficients governing the dynamics of the electric field [UNK] ( r , t ) .These can be written in the compact form :",
        "ori-fast-z-score": 0.43033148291193524,
        "water-fast-z-score": 7.150554858373488
    },
    {
        "original_text": "We report on the temporal evolution of step fluctuations under electromigration conditions in Cu(111) and Ag(111). The experiments were performed by scanning tunneling microscopy (STM), which allows for direct observation of atomic-scale processes at surfaces. We find that, during current-induced mass transport along steps, the step edges fluctuate strongly with time. These fluctuations are characterized by an exponential growth followed by saturation after about 1 hour. In addition to this general behavior we observe different types of fluctuations depending on the applied voltage and temperature. For low voltages and temperatures below 300 K, the fluctuations show a sawtooth-like shape indicating periodic changes between two states. At higher voltages or temperatures above 400 K, the fluctuations become more irregular but still exhibit some periodicity. Finally, at high voltages and temperatures around 500 K, no regular pattern is observed anymore. Our results suggest that these fluctuations can be explained as a result of competition between diffusion and drift currents.",
        "watermark_text": "We report on the temporal evolution of step fluctuations under electromigration conditions in Cu ( 111 ) and Ag ( 111 ) . The studies were performed by scanning tunneling microscopy ( STM ) , which allows for detailed observation of atomic - scale processes at surfaces .We see that , during current - mediated mass transport along stairs , the step paths fluctuate strongly with time . These fluctuations are marked by an exponential growth followed by saturation after about 1 hour .In addition to this special phenomenon we study various types of fluctuations based on the introduced voltage and heat . For low voltages and conditions below 300 K , the fluctuations show a sawtooth - like shape suggesting periodic shifts between two states .At higher voltages or temperatures above 400 K , the fluctuations get more erratic but still exhibit some periodicity . Finally , at high voltages and temperatures around 500 K , no normal behavior is observed anymore .Our results propose that these fluctuations can be described as a outcome of competition between diffusion and drift currents .",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 5.986302773458956
    },
    {
        "original_text": "The problem of finding the energy levels of an electron bound to a nucleus is one of the most important problems in physics, which has been studied for many years. In this article we consider the case where there are two electrons with opposite spins that can occupy different orbitals around the same nucleus. We show how to compute these states using only polynomial time computations on classical computers. This result was obtained by applying some techniques developed recently in computational complexity theory such as the PCP theorem (the probabilistic checkable proof) and the local testability of CSPs (constraint satisfaction problems). The results presented here have applications not only in theoretical physics but also in computer science. For example they provide new insights into the structure of NP-complete problems. Quantum mechanical systems play an essential role in modern physics. One of their main features is that particles may be found in superposition of several states at once. A famous example is Schrödinger s cat experiment  1  . Another feature is entanglement  2  , i.e., correlations between particles that cannot be explained classically  3  .\nIn this work we study the following problem: given a system consisting of N spin-1/2 particles, what is the ground state? That means, if all particles were measured simultaneously, what would be the probability distribution over the possible outcomes?\nWe will focus our attention on the simplest non-trivial case: two spin-½ particles occupying different orbitals around the nucleus  4  . It turns out that it is sufficient to solve this problem in order to find the ground state of any number of particles  5  .",
        "watermark_text": "The question of finding the power concentrations of an electron bound to a nucleus is one of the most important problems in physics , which has been studied for numerous years . In this article we define the case where there are two electrons with opposite spins that can occupy separate orbitals around the same nucleus .We see how to compute these states using only polynomial period computations on classical computers . This result was obtained by using some techniques established recently in computational complexity analysis such as the PCP conjecture ( the probabilistic checkable proof ) and the local testability of CSPs ( constraint satisfaction issues ) .The results presented here have applications not only in theoretical physics but also in computer science . For instance they give novel knowledge into the formation of NP - full problems .Quantum mechanical models play an essential part in modern physics . One of their major characteristics is that particles may be found in superposition of several states at once .A popular example is Schrödinger s cat experiment 1 . Another phenomenon is entanglement 2 , i . e . , correlations between particles that cannot be described classically 3 .In this research we study the following puzzle : given a system consisting of N spin - 1 / 2 particles , what is the ground state ? That implies , if all particles were measured simultaneously , what would be the probability distribution over the possible events ?We will focus our focus on the trivial non - trivial case : two spin - ½ particles occupying various orbitals around the atom 4 . It turns out that it is enough to solve this situation in order to find the ground state of any number of particles 5 .",
        "ori-fast-z-score": -0.7242859683401482,
        "water-fast-z-score": 5.7272727272727275
    },
    {
        "original_text": "We report on the detection and analysis of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 (SOL2010-07-20T17:48) at 17:48 UT on July 20, 2010 using the Nançay Decameter Array (NDA). The event was accompanied by a fast halo coronal mass ejection (CME), which reached Earth at 18:20 UT on July 21. We find that the radio source is located near the center of the CME front as seen in white light images taken by STEREO-Ahead/EUVI 195 Å . The radio flux density shows rapid evolution during the first hour after the onset of the flare, followed by gradual decay over several hours. The radio spectrum has a power-law shape between 1 MHz to 5 GHz. The spectral index decreases rapidly below 100 MHz but remains nearly constant above this frequency.",
        "watermark_text": "We report on the detection and assessment of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 ( SOL2010 - 07 - 20T17 : 48 ) at 17 : 48 UT on July 20 , 2010 using the Nançay Decameter Array ( NDA ) . The event was accompanied by a rapid halo coronal mass ejection ( CME ) , which reached Earth at 18 : 20 UT on July 21 .We see that the radio source is situated near the center of the CME front as shown in white light pictures taken by STEREO - Ahead / EUVI 195 Å . The radio flux concentration displays rapid change during the first hour after the outbreak of the flare , followed by rapid fading over numerous weeks .The radio signal has a power - law shape between 1 MHz to 5 GHz . The spectral index drops rapidly below 100 MHz but maintains fairly constant above this signal .",
        "ori-fast-z-score": -1.1920791213585393,
        "water-fast-z-score": 3.841143835488627
    },
    {
        "original_text": "We study statistics of conductance oscillations in open quantum dots with electron-phonon interaction and dephasing time saturation at high temperatures. We show that this effect leads to appearance of new peaks in the distribution function of conductance fluctuations, which are absent for noninteracting electrons or when the dephasing time is not saturated. The positions of these peaks depend on temperature and dot size. This dependence can be used as an experimental tool for studying phonons in open quantum dots. \n \n Introduction \n \n In recent years there has been growing interest in transport through mesoscopic systems such as semiconductor nanowires  1  , carbon nanotubes  2  , graphene  3  . These structures have unique properties due to their small dimensions (of order 10 nm)  4  . For example, they exhibit ballistic  5  and coherent  6  transport regimes  7, 8  .\n \nIn particular, it was shown experimentally  9  that the amplitude of conductance fluctuations in open quantum dots depends strongly on temperature T and dot size L. It decreases rapidly with increasing T and decreasing L  10  . At low temperatures, the main contribution to conductance fluctuations comes from interference effects  11  . However, at higher temperatures, thermal averaging destroys phase coherence between different paths  12  . As a result, the amplitude of conductance fluctuation decreases exponentially with temperature  13  :",
        "watermark_text": "We research data of conductance oscillations in open quantum dots with electron - phonon interaction and dephasing time saturation at high temperatures . We see that this effect results to appearance of new peaks in the distribution function of conductance fluctuations , which are missing for noninteracting particles or when the dephasing time is not saturated .The places of these peaks vary on temperature and dot size . This dependence can be used as an research technique for studying phonons in open quantum dots .Introduction In recent years there has been growing interest in transport through mesoscopic systems such as semiconductor nanowires 1 , carbon nanotubes 2 , graphene 3 . These structures have special characteristics owing to their tiny dimensions ( of order 10 nm ) 4 .For instance , they demonstrate ballistic 5 and coherent 6 transport regimes 7 , 8 . In particular , it was shown experimentally 9 that the frequency of conductance fluctuations in open quantum dots relies highly on pressure T and dot width L . It drops rapidly with rising T and decreasing L 10 .At small temperatures , the main contribution to conductance fluctuations depends from interference effects 11 . However , at higher temperatures , thermal averaging destroys phase coherence between various paths 12 .As a result , the frequency of conductance fluctuation decreases exponentially with temperature 13 :",
        "ori-fast-z-score": -0.9434563530497265,
        "water-fast-z-score": 3.8786538958710977
    },
    {
        "original_text": "We present measurements of galaxy clustering on scales between 1 and 100 h-1 Mpc, using data from the Cosmic Evolution Survey (COSMOS). We use photometric redshifts to select samples with different luminosities at z = 0.5-0.8. The correlation function is measured for each sample by counting pairs as a function of separation angle. We find that the amplitude of the correlation function increases strongly with luminosity over this range. This trend can be explained if we assume that more luminous galaxies are biased towards higher density regions than less luminous ones. In addition, we measure the evolution of the bias factor with redshift. Our results show that the bias factor evolves rapidly out to z ~1 but then flattens off beyond this point. These findings suggest that the growth rate of dark matter haloes decreases significantly after z ~1. Finally, we compare our results with those obtained from numerical simulations.",
        "watermark_text": "We create measurements of galaxy clustering on scales between 1 and 100 h - 1 Mpc , using data from the Cosmic Evolution Survey ( COSMOS ) . We use photometric redshifts to select samples with various luminosities at z = 0 . 5 - 0 . 8 .The interaction function is measured for each specimen by counting pairs as a function of separation angle . We see that the frequency of the correlation function increases strongly with luminosity over this spectrum .This trend can be described if we suppose that more luminous clusters are biased towards higher velocity centers than less luminous ones . In addition , we measure the evolution of the bias coefficient with redshift .Our results show that the bias coefficient evolves fast out to z ~ 1 but then flattens off beyond this point . These conclusions show that the development frequency of dark matter haloes drops considerably after z ~ 1 .Finally , we compare our findings with those achieved from numerical simulations .",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 5.0
    },
    {
        "original_text": "We present an analysis of the time variation in the supernova neutrino signal observed by KamLAND, based on the results obtained with the latest version (v5) of the numerical simulation code for core-collapse supernovae developed at Garching.  We find that the simulated time variations are consistent with those observed by KamLAND within statistical errors when we take into account the uncertainties associated with the nuclear reaction rates used to calculate the energy generation rate inside the supernova envelope as well as the uncertainty in the initial conditions assumed for the simulations. The agreement between theory and experiment is improved if we assume that the central density of the progenitor star was higher than previously thought. This result suggests that future observations of gravitational waves emitted during the collapse phase may be able to provide information about the structure of the progenitor stars prior to their explosion. In addition, our study shows that the effect of convection plays only a minor role in determining the temporal behavior of the neutrino fluxes detected by KamLAND.",
        "watermark_text": "We present an assessment of the period change in the supernova neutrino wave observed by KamLAND , relying on the results derived with the latest version ( v5 ) of the numerical model code for core - collapse supernovae published at Garching . We see that the simulated time variations are compatible with those observed by KamLAND within statistical errors when we took into consideration the uncertainties involved with the atomic reaction rates taken to estimate the power generation rate inside the supernova envelope as also as the instability in the early conditions assumed for the simulations .The agreement between theoretical and observation is enhanced if we assume that the main concentration of the progenitor star was greater than previously thought . This result suggests that future discoveries of gravitational waves emitted during the failure phase may be possible to provide details about the composition of the progenitor stars prior to their explosion .In addition , our research shows that the impact of convection plays only a minor importance in shaping the temporal activity of the neutrino fluxes observed by KamLAND .",
        "ori-fast-z-score": -1.3251783128981585,
        "water-fast-z-score": 7.288480720939871
    },
    {
        "original_text": "In this work, we introduce the higher order Schwarzian derivative (HOSD) to study chaotic behavior in dynamical systems. The HOSD is defined as the second-order differential operator with respect to time variable t acting on the first-order derivatives of the state variables x(t). We show that the HOSD can be used to construct new invariant sufficient conditions of chaos by using its properties such as non-negativity and monotonicity under some suitable assumptions. In addition, it also provides an alternative way to investigate the existence of periodic orbits in nonlinear autonomous systems. Finally, numerical examples are given to illustrate our results. Keywords: Dynamical systems; Chaos; Periodic orbit; Nonlinearity; Higher order Schwarzian derivative. 1 Introduction Let us consider the following nonautonomous ordinary differential equations (ODEs)\nx = f(t; x; u), where f: R × Rn × Rm → Rn, (1.1) which describes many physical phenomena arising in engineering fields  1  . Here, t ∈  0, T  denotes time; x ∈ Rn represents the state vector; and u ∈ Rm stands for control input or parameter vector. It should be noted that the function f may depend explicitly on both time t and control parameters u. For example, if one considers the motion of a particle moving along a straight line at constant speed v, then the position of the particle at any instant of time t is described by the equation x = vt + x0, where x0 is the initial position of the particle  2  .\nThe main goal of this article is to present a novel approach based on the higher order Schwarzian",
        "watermark_text": "In this research , we introduce the higher order Schwarzian derivative ( HOSD ) to study chaotic dynamics in dynamical systems . The HOSD is characterized as the second - order differential function with regard to time variable t acting on the first - order derivatives of the state components x ( t ) .We see that the HOSD can be used to build new invariant sufficient conditions of chaos by using its properties such as non - negativity and monotonicity under some suitable assumptions . In addition , it also provides an additional means to probe the existence of periodic orbits in nonlinear autonomous regions .Finally , numerical examples are given to illustrate our findings . Keywords : Dynamical systems ; Chaos ; Periodic orbit ; Nonlinearity ; Higher degree Schwarzian function .1 Introduction Let us consider the following nonautonomous ordinary differential equations ( ODEs ) x = f ( t ; x ; u ) , where f : R × Rn × Rm → Rn , ( 1 . 1 ) which explains many mechanical phenomena arising in engineering fields 1 . Here , t ∈ 0 , T denotes speed ; x ∈ Rn represents the state vector ; and u ∈ Rm stood for control input or parameter vector .It should be mentioned that the function f may depend explicitly on both time t and control values u . For instance , if one looks the movement of a particle moving along a straight line at constant speed v , then the placement of the particle at any instant of time t is characterized by the equation x = vt + x0 , where x0 is the first orientation of the particle 2 .The main goal of this page is to provide a novel method based on the higher order Schwarzian",
        "ori-fast-z-score": 0.08873565094161139,
        "water-fast-z-score": 5.833630944789017
    },
    {
        "original_text": "We study the effect of confinement on the structure and dynamics of a simple model system, namely an ensemble of N identical particles interacting via repulsive pair potentials confined in a volume V by two parallel impenetrable walls at distance L apart.  We use Monte Carlo simulations to calculate the density profiles for different values of the wall separation L and particle number N . The results show that the density profile is not affected significantly when increasing the wall separation beyond a certain value which depends on both the temperature T and the particle number N .  In addition we find that the self-diffusion coefficient D decreases with decreasing wall separation but increases again if one further reduces the wall separation below some critical value depending on the temperature T .\nThe observed behavior can be explained within the framework of mode-coupling theory (MCT) using a generalized version of MCT developed recently by us  Physica A, vol. 315, no. 1, pp. 39-48, (2003), Physica A, vol. 320, no. 3, pp. 633-646, (2004) .",
        "watermark_text": "We research the impact of confinement on the composition and dynamics of a simple model network , namely an ensemble of N identical particles interacting via repulsive pair potentials restricted in a volume V by two connected impenetrable walls at distance L apart . We use Monte Carlo simulations to estimate the density characteristics for different values of the wall separation L and electron number N .The results show that the density profile is not affected greatly when increasing the wall separation beyond a certain value which depends on both the temperature T and the particle number N . In addition we find that the self - diffusion coefficient D reduces with decreasing wall separation but grows again if one further decreases the wall separation below some significant value depending on the temperature T .The observed behavior can be described within the framework of mode - correlation theory ( MCT ) using a generalized version of MCT created recently by us Physica A , vol . 315 , no .1 , pp . 39 - 48 , ( 2003 ) , Physica A , vol .320 , no . 3 , pp .633-646, (2004) .",
        "ori-fast-z-score": 0.45291081365783825,
        "water-fast-z-score": 4.98201895023622
    },
    {
        "original_text": "We present the discovery, photometric and spectroscopic observations of SN 2005hj (PTF10ygu), an apparently normal-bright Type Ia supernova discovered by PTF in late March 2005 at z = 0.084. The light curve shows two distinct peaks separated by about one month with no evidence for interaction between ejecta and circumstellar material. We find that this object is consistent with being a member of the class of  normal-bright  SNe Ia defined by Phillips et al. (1999) but has a higher peak luminosity than most members of this class. Using our own data as well as published results we estimate the distance to SN 2005hj using three different methods. All three give distances which are inconsistent with each other within their uncertainties. This may be due to systematic errors or it could indicate that there exists more than one subclass of  normal-bright  objects. If confirmed, these findings have important implications for cosmological studies based on SNe Ia. \n \n Keywords: Supernovae",
        "watermark_text": "We present the discovery , photometric and spectroscopic observations of SN 2005hj ( PTF10ygu ) , an apparently normal - bright Type Ia supernova discovered by PTF in late March 2005 at z = 0 . 084 . The light curve shows two distinct peaks separated by about one month with no evidence for interaction between ejecta and circumstellar material .We see that this body is compatible with being a member of the class of normal - faint SNe Ia defined by Phillips et al . ( 1999 ) but has a higher peak luminosity than most members of this class .Using our own observations as well as published results we estimate the distance to SN 2005hj using three different methods . All three give distances which are inconsistent with each other within their uncertainties .This might be due to systematic errors or it could indicate that there exists more than one subclass of normal - faint objects . If confirmed , these results have important implications for cosmological researchers using on SNe Ia .Keywords: Supernovae",
        "ori-fast-z-score": 1.2909944487358056,
        "water-fast-z-score": 3.9691432779197755
    },
    {
        "original_text": "We present multimodal nested sampling (MNS), a novel algorithm that is able to efficiently explore the posterior distribution in high-dimensional parameter spaces, such as those encountered when fitting complex models to observational data sets. MNS combines ideas from simulated annealing with importance sampling techniques to find the global maximum likelihood solution within a given tolerance level. We demonstrate how this method can be used on real-world problems by applying it to two different astrophysics applications: modelling the observed fluxes of gamma-ray bursts using a time-dependent model; and determining the parameters of a binary black hole merger event detected by gravitational waves. In both cases we show that our new approach outperforms existing Markov chain Monte Carlo algorithms. The code implementing these examples will be made publicly available at https://github.com/mns-method/mns-method/tree/master/examples. Multimodal nested sampling (M NS) is a novel algorithm that is capable of exploring the posterior distribution in high dimensional parameter spaces, such as are found when fitting complex models to large observational datasets. It combines ideas from simulated annealling with importance sampling techniques to locate the global maximum likelihood solution to any problem within some specified tolerance. This talk describes the basic principles behind M NS and demonstrates its application to two astrophysics problems: modelling the observed light curves of gamma ray bursts; and determining the physical properties of a binary black hole system inferred from gravitational wave observations.",
        "watermark_text": "We create multimodal nested sampling ( MNS ) , a new algorithm that is able to easily examine the posterior distribution in high - dimensional parameter sets , such as those experienced when fitting large models to observational data sets . MNS mixes ideas from simulated annealing with importance sampling methods to find the global maximum likelihood solution within a given tolerance level .We suggest how this algorithm can be used on real - global issues by using it to two different astrophysics applications : modelling the emitted fluxes of gamma - ray clusters using a time - dependent model ; and determining the variables of a binary white hole merger event detected by gravitational waves . In both cases we prove that our new approach outperforms previous Markov chain Monte Carlo algorithms .The software implementing these examples will be made fully available at https : / / github . com / mns - method / mns - method / tree / master / examples . Multimodal nested filtering ( M NS ) is a novel algorithm that is capable of analyzing the posterior distribution in high dimensional parameter sets , such as are found when fitting large models to large observational datasets .It combines insights from simulated annealling with importance sampling methods to locate the global maximum likelihood solution to any question within some specified tolerance . This discussion describes the fundamental principles behind M NS and demonstrates its use to two astrophysics issues : modelling the emitted light curves of gamma radiation bursts ; and determining the physical properties of a binary white hole system inferred from gravitational wave surveys .",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 8.348430768491543
    },
    {
        "original_text": "We report on the detection of an extremely rare supersoft X-ray outburst event in the transient source 1E0102. 2-7219 (=GX 354-0) with the Suzaku satellite, which was triggered by a large increase in its hard Xray flux. The duration and peak luminosity are estimated to be about 100 s and 2×1036 erg/s at 6 kpc distance, respectively. This is one of only two such events ever detected for this object. We discuss possible origins of these events based on their observed properties. \n \n Keywords: Supernova remnant, Soft gamma-ray repeater, Transient source, Supersoft X-ray emission, Hard X-ray bursts \n \n \n \n 1 Introduction \n \n In recent years, several new classes of transients have been discovered through systematic searches using satellites like RXTE/ASM or Swift/BAT. These include soft-gamma repeaters (SGRs; e.g., Hurley et al. 2005), anomalous X-ray pulsars (AXPs; e.g., Kaspi & Beloborodov 2017) , and magnetar candidates (e.g., Rea et al. 2012) . Among them, SGRs show repeated short-duration bursts of high-energy radiation ranging from radio waves to gammarays. AXPs are characterized by persistent X-ray emissions that often exhibit periodic pulsations. Magnetar candidates also show similar characteristics as those of AXPs but lack clear evidence of periodicity. All three types of sources occasionally emit giant flares accompanied by energetic particle acceleration phenomena (e.g., Palmer 2014; Kashiyama et al. 2013 ). On the other hand, some of these objects sometimes undergo very faint outbursts lasting for hours to days. For example, SGR 0526-66 showed a series of such outbursts between 1979 and 1989 (Mazets et al. 1981; Cline et al. 1982; Kulkarni et al. 1993; Kouveliotou et al. 1998 ) while SGR 1900+14 exhibited another series of fainter ones between 1997 and 2001 . Such",
        "watermark_text": "We report on the observation of an incredibly rare supersoft X - ray outburst incident in the transient stream 1E0102 . 2 - 7219 ( = GX 354 - 0 ) with the Suzaku spacecraft , which was sparked by a large rise in its hard Xray flux .The period and peak luminosity are estimated to be about 100 s and 2×1036 erg / s at 6 kpc distance , respectively . This is one of only two such events ever observed for this object .We discuss possible origins of these events according on their observed properties . Keywords : Supernova remnant , Soft gamma - ray repeater , Transient precursor , Supersoft X - ray radiation , Hard X - ray flare 1 Introduction In recent years , various additional types of transients have been detected through widespread searches using satellites like RXTE / ASM or Swift / BAT .These include soft - gamma repeaters ( SGRs ; e . g . , Hurley et al . 2005 ) , anomalous X - ray pulsars ( AXPs ; e . g . , Kaspi & Beloborodov 2017 ) , and magnetar candidates ( e . g . , Rea et al .2012 ) . Among them , SGRs exhibit frequent short - duration bursts of high - energy rays ranging from radio beams to gammarays .AXPs are marked by persistent X - ray emissions that frequently exhibit periodic pulsations . Magnetar candidates often show identical traits as those of AXPs but lack firm indication of periodicity .All three categories of sources occasionally emit giant flares driven by energetic particle acceleration phenomena ( e . g . , Palmer 2014 ; Kashiyama et al . 2013 ) .On the other hand , some of these objects sometimes undergo very faint outbursts lasting for days to days . For instance , SGR 0526 - 66 demonstrated a sequence of such outbursts between 1979 and 1989 ( Mazets et al .1981 ; Cline et al . 1982 ; Kulkarni et al .1993 ; Kouveliotou et al . 1998 ) while SGR 1900 + 14 exhibited another series of fainter ones between 1997 and 2001 .Such",
        "ori-fast-z-score": -1.1141720290623112,
        "water-fast-z-score": 5.501778368617852
    },
    {
        "original_text": "We present new constraints on warm dark matter (WDM) models by combining the results of two recent surveys for gravitationally lensed quasars, SDSS and CFHTLS Wide. We find that the observed number density of lenses is consistent with predictions based on cold dark matter simulations but inconsistent at more than 3 sigma confidence level if we assume a standard thermal relic WDM model with mass mX = 1 keV. This result suggests either that the current WDM scenario needs to be modified or that there are other systematic effects which have not been taken into account in our analysis. The full text can be found at: http://arxiv.org/abs/astro-ph/0604070v1.pdf . \nThe existence of dark matter has now been established beyond reasonable doubt through its gravitational influence on visible matter. However, despite decades of research, little else about this mysterious substance is known. In particular, it remains unclear whether dark matter consists of one particle species only - as assumed in most theoretical studies -or whether it comprises several different particles. One possibility is that dark matter consists of weakly interacting massive particles (WIMPs), such as neutralinos predicted within supersymmetric extensions of the Standard Model  1  .\nIn order to test these scenarios observationally, astronomers look for signatures of dark matter in astrophysical objects like galaxies  2  , clusters  3  and quasars  4  . A particularly promising method involves searching for gravitationally lensed systems  5  where light rays emitted by distant sources bend around intervening dark matter halos  6  . If dark matter consists of WIMPs then their masses should lie between 10 GeV/c 2 and 100 TeV/c 2  7, 8  . For example, the recently discovered galaxy cluster Abell 2218  9  may contain a halo made up entirely of WIMPs  10  .",
        "watermark_text": "We introduce novel constraints on warm dark matter ( WDM ) estimates by combining the conclusion of two latest surveys for gravitationally lensed quasars , SDSS and CFHTLS Wide . We see that the seen number density of lenses is compatible with predictions based on cold bright matter simulations but inconsistent at more than 3 sigma confidence rate if we expect a traditional thermal relic WDM theory with volume mX = 1 keV .This result suggests either that the present WDM situation needs to be altered or that there are other systematic effects which have not been took into consideration in our analysis . The full text can be found at : www : / / arxiv . org / abs / astro - ph / 0604070v1 . pdf .The nature of dark matter has now been known beyond reasonable question through its gravitational impact on visible matter . However , despite decades of research , nothing much about this secret quantity is known .In particular , it remains unsure whether dark matter contains of one particle species only - as implied in most theoretical researchers - or whether it contains multiple distinct objects . One possibility is that dark matter contains of weakly interacting massive electrons ( WIMPs ) , such as neutralinos expected within supersymmetric extensions of the Standard Model 1 .In order to test these scenarios observationally , astronomers look for signatures of dark matter in astrophysical objects like stars 2 , galaxies 3 and quasars 4 . A particularly useful technique means searching for gravitationally lensed systems 5 where light rays generated by distant sources bend around intervening black material halos 6 .If heavy material contains of WIMPs then their masses should lie between 10 GeV / c 2 and 100 TeV / c 2 7 , 8 . For instance , the recently discovered star cluster Abell 2218 9 would contain a halo made up completely of WIMPs 10 .",
        "ori-fast-z-score": 0.08804509063256238,
        "water-fast-z-score": 9.068644335153925
    },
    {
        "original_text": "The zeta-function is the main object in number theory and algebraic geometry.  In this talk I will explain how it can be used to study quantum field theories on curved spacetimes with non-trivial topology.   The basic idea is that one considers the Feynman path integral over all fields on spacetime as an infinite dimensional functional integration which can then be regularized by replacing the space of fields by a finite dimensional vector space equipped with a suitable norm.    This leads naturally to the concept of a  quantum torus  whose zeta function encodes information about the spectrum of the corresponding QFT.   We will also discuss some recent results concerning the relation between the zeta functions of certain families of quantum tori and their associated modular forms. Quantum Field Theory (QFT) has been developed into a powerful tool for studying physical phenomena at the most fundamental level. However, many interesting questions remain open due to the difficulty of performing calculations beyond perturbation theory. One way out of these difficulties is to use ideas from mathematics such as those coming from number theory or algebraic geometry. In particular, we are interested in using the so-called  zeta-functions  of algebraic varieties to obtain new insights into QFTs. These objects encode important information about the underlying physics but they are notoriously difficult to compute explicitly. In my talk I ll give examples where explicit computations have been performed successfully and show how these techniques could lead to further progress in our understanding of QFTs.",
        "watermark_text": "The zeta - function is the main object in number theory and algebraic topology . In this talk I will explain how it can be used to study quantum field theories on curved spacetimes with non - trivial geometry .The basic idea is that one considers the Feynman line expansion over all fields on spacetime as an infinite dimensional functional integration which can then be regularized by replacing the space of fields by a finite dimensional vector space equipped with a suitable norm . This leads naturally to the idea of a quantum torus whose zeta function encodes data about the spectrum of the associated QFT .We will also discuss some latest findings concerning the relation between the zeta functions of certain classes of quantum tori and their associated modular forms . Quantum Field Theory ( QFT ) has been built into a powerful tool for studying physical phenomena at the most important level .However , many interesting problems continue open thanks to the difficulty of performing calculations beyond perturbation theory . One path out of these problems is to use insights from mathematics such as those coming from number theory or algebraic theory .In particular , we are concerned in use the so - called zeta - functions of algebraic fields to obtain new understanding into QFTs . These items encode crucial data about the fundamental theories but they are notoriously difficult to compute accurately .In my talk I ll offer examples where explicit computations have been performed effectively and suggest how these procedures could lead to further progress in our understanding of QFTs .",
        "ori-fast-z-score": 0.5570860145311556,
        "water-fast-z-score": 6.009252125773315
    },
    {
        "original_text": "We study the stability properties of planar streamers in air, which are ionized regions that propagate into un-ionized gas under the influence of an applied electric field. We show how to use the so-called  pulled front approach  to derive a nonlinear evolution equation for the shape of such fronts and then analyze this equation using standard techniques from dynamical systems theory. In particular we find that there is a critical value of the applied voltage beyond which the planar solution becomes unstable with respect to small perturbations. This result explains why it has been so difficult to observe stable propagation of streamers at high voltages experimentally. The results presented here should be relevant not only to atmospheric discharges but also to other physical situations where similar phenomena occur, e.g., combustion flames or chemical waves on catalytic surfaces. Streamers are thin channels filled with highly conducting plasma that can form when strong electric fields are present between two electrodes immersed in non-conducting gases  1  . They have attracted considerable interest over many years because they play important roles in various applications including lightning  2  , sprites  3  , and high-voltage switches  4  .\nIn recent years much progress has been made towards understanding their formation mechanisms  5, 6, 7, 8  as well as their dynamics  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96,",
        "watermark_text": "We explore the stability properties of planar streamers in atmosphere , which are ionized areas that propagate into un - ionized gas under the effects of an applied electric field . We see how to use the so - called tugged forward approach to derive a nonlinear development formula for the shape of such fronts and then investigate this equation using conventional methods from dynamical systems models .In particular we find that there is a critical factor of the introduced voltage beyond which the planar solution gets unstable with regard to small perturbations . This result explains why it has been so difficult to observe consistent diffusion of streamers at high voltages experimentally .The results presented here should be applicable not only to ambient discharges but also to other physical conditions where similar phenomena arise , e . g . , combustion burning or molecular currents on catalytic surfaces . Streamers are thin tubes filled with highly conducting plasma that can form when strong magnetic waves are present between two electrodes immersed in non - conducting gases 1 .They have garnered considerable interest over numerous years because they serve major roles in different applications notably lightning 2 , sprites 3 , and large - frequency switches 4 . In recent years much work has been given towards studying their formed mechanisms 5 , 6 , 7 , 8 as well as their mechanics 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 ,",
        "ori-fast-z-score": -1.5689290811054724,
        "water-fast-z-score": 7.256297000112809
    },
    {
        "original_text": "We present an optical source catalog for the north ecliptic pole region (NEPR) based on data obtained with the Palomar Observatory Sky Survey (POSS-II). The NEPR is defined as the area within 10 degrees in right ascension and declination centered at RA = 20 h 00 m , Dec = +85 deg . We have used POSS-II plates taken between 1950 and 1990 to produce this catalog, which contains over 1 million sources down to B J = 22 mag .\nThe photometric calibration was performed using Landolt standard stars observed during the same nights that the sky survey plates were exposed. Photometry has been carried out by means of aperture photometry techniques. Magnitudes are given in the Johnson system. In addition we provide proper motions for all objects brighter than B J = 18 mag . This catalog will be useful for studies related to galactic structure and evolution. \n \n Keywords: Palomar Observatory Sky Survey",
        "watermark_text": "We create an optical source catalog for the north ecliptic pole region ( NEPR ) based on evidence derived with the Palomar Observatory Sky Survey ( POSS - II ) . The NEPR is characterized as the area within 10 degrees in right ascension and declination centered at RA = 20 h 00 m , Dec = + 85 deg .We have utilized POSS - II sheets taken between 1950 and 1990 to produce this database , which contains over 1 million sources down to B J = 22 mag . The photometric calibration was done utilizing Landolt standard stars observed during the same hours that the sky survey plates were uncovered .Photometry has been carried out by means of aperture photometry method . Magnitudes are given in the Johnson system .In addition we provide proper motions for all bodies brighter than B J = 18 mag . This collection will be valuable for research associated to galactic composition and evolution .Keywords: Palomar Observatory Sky Survey",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.714951667914447
    },
    {
        "original_text": "We report on new spectroscopic observations of the eclipsing binary system HAT-TR-205-1013, which was discovered by the Hungarian Automated Telescope (HAT) survey for transiting exoplanets. The light curve shows two partial eclipses with an orbital period of 1.8 days. We find that this is most likely caused by reflection effects rather than occultation events due to the presence of a third body. Using our radial velocity measurements we determine the mass function f(m) = 0.0027 ± 0.0007M⊙, where m is the mass of the unseen companion star. Assuming circular orbits, we derive the minimum masses of both components as M1 sin i = 0.84 ± 0.04M⊙ and M2 sin i = 0.16 ± 0.02M⊙. From these values we estimate the radius ratio between the primary and secondary component as q = 0.53 ± 0.06.",
        "watermark_text": "We report on new spectroscopic observations of the eclipsing binary system HAT - TR - 205 - 1013 , which was discovered by the Hungarian Automated Telescope ( HAT ) study for transiting exoplanets . The light curve shows two partial eclipses with an orbital period of 1 . 8 days .We see that this is most likely due by reflection influences rather than occultation processes due to the presence of a third body . Using our radial speed measurements we determine the mass function f ( m ) = 0 . 0027 ± 0 . [UNK] , where m is the mass of the unseen companion star .Assuming circular orbits , we derive the minimum masses of both components as M1 sin i = 0 . 84 ± 0 . [UNK] and M2 sin i = 0 . 16 ± 0 . [UNK] . From these values we estimate the radius ratio between the primary and secondary component as q = 0 . 53 ± 0 . 06 .",
        "ori-fast-z-score": 0.6401843996644799,
        "water-fast-z-score": 2.1766269588592317
    },
    {
        "original_text": "We present the first direct determination of the stellar radius in an interacting binary system, using interferometric observations obtained with the VLTI and AMBER instrument. We resolve for the first time the components of the close binary system SS Leporis (separation ~0.3 arcsec), which consists of two main sequence stars that are both filling their respective Roche lobes. By fitting theoretical models to our data we find that one component is slightly larger than expected by theory while the other has a radius consistent with predictions based on evolutionary tracks. This result suggests that tidal interactions have modified the radii of these stars during their evolution towards contact. Our results also show that the orbital inclination angle i = 60 ± 5 degrees, as determined previously through radial velocity measurements, agrees well with our new estimate derived directly from the observed separation between the two stars. Keywords: Interferometry; Binary Stars; Stellar Radius",
        "watermark_text": "We present the first complete measurement of the stellar radius in an interacting binary system , using interferometric observations derived with the VLTI and AMBER method . We resolve for the first time the parts of the distant binary system SS Leporis ( separation ~ 0 . 3 arcsec ) , which consists of two principal sequence stars that are both filling their separate Roche lobes .By fitting theoretical estimates to our information we find that one part is slightly larger than expected by hypothesis while the other has a diameter compatible with predictions based on evolutionary tracks . This result suggests that tidal interactions have modified the radii of these stars during their development towards contact .Our results also demonstrate that the orbital inclination distance i = 60 ± 5 degrees , as determined earlier through radial speed measurements , agrees well with our new estimate calculated directly from the observed separation between the two stars . Keywords : Interferometry ; Binary Stars ; Stellar Radius",
        "ori-fast-z-score": 0.3511234415883917,
        "water-fast-z-score": 4.649905549752772
    },
    {
        "original_text": "We report on the observation of ground state magneto optical resonance (GMOR) in cesium vapor confined to a sub-micron thickness layer inside a glass micro-cell. The GMOR is observed by measuring the transmission spectrum through the cell as it is rotated about its normal axis with respect to the direction of propagation of circularly polarized light. We show that this effect can be explained using simple classical electrodynamics and we present experimental results which demonstrate the dependence of the GMOR signal strength on various parameters such as the intensity, frequency detuning and polarization angle of the incident laser beam. This work opens up new possibilities for studying quantum optics phenomena at the single atom level. \n \n In recent years there has been considerable interest in developing techniques for trapping atoms or molecules within microscopic volumes  1  . Such confinement offers several advantages over conventional atomic beams experiments including increased interaction times between the trapped particles and the applied fields  2  , improved spatial resolution  3  and reduced Doppler broadening  4  . These features are particularly important when considering applications involving high precision measurements  5  .\nIn addition to these practical benefits, confining neutral matter to small dimensions also provides opportunities for exploring fundamental physics  6  . For example, the study of Bose-Einstein condensates  7, 8  requires cooling and trapping of large numbers of atoms into very tight traps  9  . Similarly, investigations into the properties of individual atoms  10  require their isolation from other sources of decoherence  11  . Finally, studies of macroscopic quantum effects  12  may benefit from the ability to control the number of particles involved  13  . \n \n Here we describe our efforts towards achieving controlled confinement of neutral matter to extremely small dimensions. Specifically, we have developed a technique for producing a thin film of cesium gas inside a glass micro-cell  14  . By exploiting the strong magnetic dipole moment associated with the cesium ground state  15  , we observe a novel form of magneto-optical resonance  16  known as ground state magneto-optical resonance  17  . Our observations suggest that this phenomenon could provide a useful tool for investigating quantum optics processes occurring at the single atom level  18  .",
        "watermark_text": "We report on the observation of ground state magneto optical resonance ( GMOR ) in cesium vapor confined to a sub - micron thickness sheet inside a glass micro - cell . The GMOR is observed by monitoring the propagation spectrum through the cell as it is rotated about its regular axis with regard to the direction of propagation of circularly polarized light .We see that this effect can be described using simple classical electrodynamics and we present experimental results which demonstrate the dependence of the GMOR wave strength on various variables such as the frequency , frequency detuning and polarization angle of the incident beam beam . This research raises up new possibilities for studying quantum optics dynamics at the single atom level .In recent years there has been substantial interest in improving procedures for trapping atoms or compounds within microscopic volumes 1 . Such confinement gives numerous benefits over traditional molecular beams studies namely increased interaction times between the captured particles and the applied fields 2 , enhanced angular resolution 3 and reduced Doppler broadening 4 .These features are particularly important when assessing uses concerning high precision observations 5 . In addition to these useful benefits , confining neutral matter to small dimensions additionally offers options for studying basic physics 6 .For instance , the investigations of Bose - Einstein condensates 7 , 8 requires freezing and trapping of large numbers of atoms into very strict trapping 9 . Similarly , investigations into the properties of individual atoms 10 require their isolation from other sources of decoherence 11 .Finally , investigations of macroscopic quantum effects 12 may benefit from the ability to affect the quantity of particles concerned 13 . Here we explain our initiatives towards attain controlled confinement of neutral matter to incredibly small sizes .Specifically , we have developed a technique for producing a thin film of cesium gas inside a glass micro - cell 14 . By exploiting the strong magnetic dipole point involved with the cesium ground state 15 , we study a new form of magneto - optical resonance 16 known as ground state magneto - optical resonance 17 .Our observations suggest that this phenomenon might give a helpful resource for investigating quantum optics processes observed at the single atom level 18 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.460169506877884
    },
    {
        "original_text": "The low-energy parameters of neutron-proton scattering are determined by using modern experimental data obtained in partial-wave analyses (PWAs). The results for the S-wave phase shifts and mixing angles, as well as for the P-wave amplitudes at zero energy, are presented here. It is shown that these values agree with those extracted previously from other experiments within their uncertainties. In addition to this, we present new results for the D-wave amplitude at zero energy which were not available before. \nI. INTRODUCTIO N\nNeutron-proton elastic scattering has been studied extensively over many decades  1  . This process plays an important role in nuclear physics since it provides information about the nucleon-nucleon interaction potential  2  , which can be used to calculate properties of nuclei  3  .\nIn recent years there have been significant advances in our understanding of the structure of the nucleon-nucleus system  4  . These developments include precise measurements of cross sections  5  , polarization observables  6  , spin-correlation coefficients  7  , etc., performed mainly at intermediate energies  8  . However, despite all efforts made so far, some questions remain open  9  . For example, one still needs more accurate determinations of the lowenergy parameters of the nucleonnucleon interaction  10  .",
        "watermark_text": "The lowest - energy parameters of neutron - proton diffusion are decided by using contemporary experimental evidence derived in partial - wave assessments ( PWAs ) . The results for the S - wave phase change and mixing angles , as well as for the P - wave amplitudes at zero energy , are presented here .It is demonstrated that these parameters agree with those retrieved previously from other experiments within their uncertainties . In addition to this , we present new data for the D - wave amplitude at zero energy which were not accessible before .I . INTRODUCTIO N Neutron - proton elastic scattering has been studied extensively over numerous years 1 . This process holds an important role in nuclear science since it gives information about the nucleon - nucleon collision potential 2 , which can be used to estimate features of nuclei 3 .In recent years there have been significant advances in our knowing of the structure of the nucleon - nucleus system 4 . These advances require precise observations of cross sections 5 , polarization observables 6 , spin - correlation coefficients 7 , etc . , conducted predominantly at intermediate energies 8 .However , despite all efforts made so far , some questions remain open 9 . For instance , one currently needs more accurate determinations of the lowenergy variables of the nucleonnucleon interaction 10 .",
        "ori-fast-z-score": -0.21081851067789195,
        "water-fast-z-score": 6.81385143869247
    },
    {
        "original_text": "The WiFeS instrument is an integral field spectrograph for the Australian National University 2.3m telescope at Siding Spring Observatory, Australia.  It has been in operation since 2005 and was designed to provide high quality optical spectroscopy over a wide range of wavelengths with minimal overheads.   The WiFeS instrument consists of two cameras that are mounted on a common baseplate which sits inside a vacuum chamber attached to the Cassegrain focus of the ANU 2.3m telescope.    Each camera contains a lenslet array that produces a set of images across its focal plane.  These images can be combined into a single data cube using software developed by Dopita et al. (2007).    This data cube provides information about both spatial position and wavelength along each line-of-sight through the object being observed.  In addition to this capability, WiFeS also offers several other advantages including:  - High throughput due to the use of dichroic beam splitters and fibre optic coupling between the lenses and detectors.  - Flexible observing modes ranging from fully automated observations to manual control via remote desktop interface.  - Fast readout times allowing multiple targets to be observed simultaneously or rapid cycling between different targets during a night s observation run.  - Low maintenance requirements as it does not require any moving parts within the vacuum enclosure.  - Excellent stability thanks to the design of the optics bench and the thermal isolation provided by the vacuum enclosure.  - Large format detector arrays providing excellent signal-to-noise ratio even under poor seeing conditions.  - Robust mechanical design ensuring long-term reliability...",
        "watermark_text": "The WiFeS instrument is an integral field spectrograph for the Australian National University 2 . 3m telescope at Siding Spring Observatory , Australia . It has been in operation since 2005 and was built to provide high quality optical spectroscopy over a broad variety of wavelengths with minimal overheads .The WiFeS instrument consists of two cameras that are installed on a common baseplate which sits inside a vacuum chamber connected to the Cassegrain scope of the ANU 2 . 3m telescope . Each lens includes a lenslet antenna that generates a pair of pictures across its focal surface .These photographs can be merged into a single data cube using software created by Dopita et al . ( 2007 ) .This data cube provides information about both visual orientation and wavelength along each line - of - view through the element being detected . In addition to this capability , WiFeS also provides various other advantages namely : - High throughput owing to the using of dichroic laser splitters and fibre optic coupling between the lenses and detectors .- Flexible monitoring mechanisms ranging from fully autonomous observations to manual control via remote desktop interface . - Fast readout hours permitting multiple targets to be spotted concurrently or rapid cycling between various destinations during a night s observation run .- Low maintenance requirements as it does not require any shifting components within the vacuum enclosure . - Good integrity thanks to the design of the optics bar and the thermal isolation provided by the vacuum enclosure .- Large format detector arrays offering good signal - to - noise ratio especially under bad seeing conditions . - Robust mechanical architecture ensuring long - term reliability . . .",
        "ori-fast-z-score": -0.6211495565912797,
        "water-fast-z-score": 7.0101164243872995
    },
    {
        "original_text": "We present an overview of the state-of-the-art methods for spectral analysis on spherical data, with emphasis on their applications to problems arising in geophysical sciences (e.g., global seismological tomography) and astrophysics (e.g., cosmic microwave background). We also discuss some recent advances in this area that have been made by our group at Columbia University. The main focus is on the development of new algorithms for computing accurate estimates of the power spectrum of signals defined over the surface of the unit sphere using only partial information about these signals. In particular, we consider two classes of methods: those based on the use of spherical harmonic expansions and those based on wavelet transforms. Finally, we briefly describe several open research questions related to the topic discussed here. Spherical data arise naturally in many areas of science including astronomy, meteorology, oceanography, geodesy, and medicine. For example, astronomers routinely collect large amounts of data describing the positions of celestial objects such as stars or galaxies; similarly, weather forecasters gather measurements of atmospheric pressure, temperature, humidity, wind speed, etc., at various locations around the globe. These types of data are often represented mathematically as functions defined over the surface of a sphere.",
        "watermark_text": "We bring an overview of the state - of - the - art methods for spectral modeling on spherical measurements , with emphasis on their applications to problems arose in geophysical sciences ( e . g . , global seismological tomography ) and astrophysics ( e . g . , planetary microwave background ) . We also discuss some latest advances in this area that have been made by our team at Columbia University .The main interest is on the development of new method for calculation precise estimates of the power spectrum of waves defined over the surface of the unit sphere utilizing only partial knowledge about these signals . In particular , we investigate two groups of methods : those relying on the using of spherical harmonic expansions and those based on wavelet transforms .Finally , we briefly illustrate numerous open scientific questions related to the subject mentioned here . Spherical data arise naturally in multiple fields of science including science , meteorology , oceanography , geodesy , and medicine .For instance , astronomers typically gather huge amounts of statistics explaining the places of astronomical bodies such as planets or galaxies ; likewise , weather forecasters gather measurements of atmospheric pressure , temperature , moisture , breeze pressure , etc . , at numerous locations around the globe . These sorts of statistics are often depicted mathematically as functions defined over the surface of a sphere .",
        "ori-fast-z-score": -2.011435198964418,
        "water-fast-z-score": 6.674238124719146
    },
    {
        "original_text": "The search is performed in the context of the Minimal Supersymmetric Standard Model (MSSM) using data collected by the Compact Muon Solenoid experiment at sqrt(s) = 7 TeV, corresponding to an integrated luminosity of 5 fb-1 . The results are interpreted as limits on the production cross section times branching fraction into two photons of neutral Higgs bosons decaying within the detector acceptance. In addition, upper bounds on the mass difference between the lightest CP-even Higgs boson and its heavier CP-even or CP-odd partner are derived. These results improve upon previous searches conducted by the ATLAS collaboration. \n \n A summary of this work has been presented at: \n \n \n \n \n \n This document contains additional information that may be useful to readers interested in reproducing our analysis or applying it to other datasets. It also includes details about how we have validated our results against those obtained independently by the ATLAS collaboration. \n \nIntroduction\n\nThe discovery of a new particle consistent with the Standard Model (SM) Higgs boson  1–3  has opened up a new era in particle physics. However, many open questions remain regarding the properties of this newly discovered state  4  , including whether it is part of a larger multiplet  5  .\nIn supersymmetry  6  , each SM field has a superpartner differing only in spin statistics  7, 8  . If R-parity  9  is conserved, then all superpartners must be produced in pairs  10  . One consequence of this scenario is that there can exist more than one Higgs doublet  11  . In particular, if the lighter scalar Higgs boson observed at the LHC  12–18  corresponds to the lightest CP-eigenstate h0 of such a model  19, 20  , then the next-to-lightest CP-eigenstates H0 and A0 could both couple strongly to fermions  21  . Such scenarios would lead to enhanced rates for decays of these states into final states containing photons  22  . \n \n In order to explore possible deviations from the SM predictions  23  , precise measurements of the masses and couplings of the Higgs bosons predicted by",
        "watermark_text": "The scan is conducted in the context of the Minimal Supersymmetric Standard Model ( MSSM ) using data taken by the Compact Muon Solenoid experiment at sqrt ( s ) = 7 TeV , corresponding to an integrated luminosity of 5 fb - 1 . The results are seen as limits on the production cross section times branching fraction into two photons of neutral Higgs bosons decaying within the detector acceptance .In addition , upper limits on the mass ratio between the lightest CP - even Higgs boson and its lighter CP - even or CP - even partner are derived . These data improve upon recent searches undertaken by the ATLAS collaboration .A description of this research has been presented at : This text includes added details that might be valuable to readers interested in reproducing our analysis or applying it to other datasets . It additionally contains details about how we have validated our findings against those acquired independently by the ATLAS collaboration .Introduction The discovery of a new particle compatible with the Standard Model ( SM ) Higgs boson 1 – 3 has opened up a new period in particle science . However , many open questions remain regarding the properties of this freshly found state 4 , particularly whether it is part of a greater multiplet 5 .In supersymmetry 6 , each SM field has a superpartner varying only in spin statistics 7 , 8 . If R - parity 9 is conserved , then all superpartners must be made in pairs 10 .One result of this situation is that there can occur more than one Higgs doublet 11 . In particular , if the heavier scalar Higgs boson seen at the LHC 12 – 18 corresponds to the lightest CP - eigenstate h0 of such a theory 19 , 20 , then the second - to - lightest CP - eigenstates H0 and A0 could both couple strongly to fermions 21 .Such scenarios would result to accelerated rates for decays of these states into last states carrying photons 22 . In order to examine possible deviations from the SM predictions 23 , detailed observations of the masses and couplings of the Higgs bosons predicted by",
        "ori-fast-z-score": -2.658425641381813,
        "water-fast-z-score": 6.141879930089016
    },
    {
        "original_text": "Graphene nanoribbons (GNRs) are promising candidates for future nanoelectronic devices due to their unique electronic properties and high carrier mobility at room temperature. However, the scaling behaviors of GNRFETs have not been fully understood yet because of the difficulty in simulating realistic device structures with atomistic details using conventional approaches such as density functional theory or tight-binding method. In this work, we perform large-scale quantum transport simulations on GNR-FETs by solving the nonequilibrium Green s function equations within an effective mass approximation. We find that the subthreshold swing decreases rapidly when the channel length is reduced below 10 nm while it increases slowly beyond 20 nm. The ON/OFF current ratio also shows similar trends but its value becomes saturated around 100 nm. These results suggest that the optimal channel length should be between 10-20 nm depending on the required performance parameters. Our findings can provide useful guidelines for designing practical graphene-based transistors.",
        "watermark_text": "Graphene nanoribbons ( GNRs ) are promising candidates for future nanoelectronic devices owing to their distinct mechanical behavior and large carrier movement at room temperature . However , the scaling interactions of GNRFETs have not been totally understood yet because of the difficulty in simulating realistic device designs with atomistic features using conventional approaches such as density functional theory or tight - binding method .In this research , we perform large - scale quantum carrier simulations on GNR - FETs by solving the nonequilibrium Green s function equations within an effective mass approximation . We see that the subthreshold swing decreases quickly when the channel length is decreased below 10 nm while it rises steadily beyond 20 nm .The ON / OFF present ratio therefore displays similar trends but its value gets saturated around 100 nm . These data suggest that the ideal network duration should be between 10 - 20 mm depending on the necessary performance parameters .Our findings can provide useful guidelines for constructing practical graphene - based transistors .",
        "ori-fast-z-score": 0.8834522085987723,
        "water-fast-z-score": 6.184165460191406
    },
    {
        "original_text": "The future neutrino factory experiments will be able to search for new physics beyond the Standard Model (SM) with unprecedented precision, and are expected to provide important information on the origin of matter-antimatter asymmetry as well as dark matter candidates.  In this talk I will present an overview of our recent studies on how to probe various types of new physics using these facilities. The results presented here were obtained by combining the analyses performed at the T2K experiment and its off-axis near detector ND280. These include searches for sterile neutrinos, lepton flavor violating processes such as neutrinoless double beta decay, CP violation effects in leptonic sector, and exotic Higgs bosons that can couple to both quarks and leptons. We also discuss possible improvements in sensitivity which may be achieved if we combine the data taken at T2K and NOvA experiments. Finally, prospects for probing new physics at future accelerator-based neutrino factories are discussed.",
        "watermark_text": "The future neutrino plant experiments will be possible to search for fresh physics beyond the Standard Model ( SM ) with incredible clarity , and are expected to provide important information on the origin of matter - antimatter asymmetry as well as dark matter candidates . In this talk I will present an overview of our latest studies on how to probe various types of new science using these facilities .The results presented here were obtained by combining the calculations performed at the T2K experiment and its off - axis near sensor ND280 . These include searches for sterile neutrinos , lepton flavor violating reactions such as neutrinoless single gamma decay , CP violation processes in leptonic sector , and rare Higgs bosons that can couple to both quarks and leptons .We also discuss possible changes in sensitivity which would be obtained if we merge the information taken at T2K and NOvA studies . Finally , prospects for probing novel physics at possible accelerator - based neutrino farms are discussed .",
        "ori-fast-z-score": -0.23570226039551587,
        "water-fast-z-score": 5.656854249492381
    },
    {
        "original_text": "The statistical mechanics of time-independent non-dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation theorem. The main results are formulated for systems with discrete energy levels, but they can be extended to continuous spectrum as well. It is shown that the probability distribution function (PDF) of the total entropy production has an exponential tail at large values of entropy production. This result agrees with recent experimental data on PDFs of heat fluxes between two reservoirs connected by a single molecule junction. In addition it is demonstrated how this approach allows one to calculate the average value of the total entropy production and its fluctuations. Finally we discuss possible applications of these results to transport phenomena in molecular junctions. We show that our theory predicts correctly the dependence of the current-voltage characteristics on temperature difference between the leads. Statistical mechanics of time independent non-dissipative non-equilibrium states is studied within the framework of generalized entropy-production and fluctuation theorem. Main results are formulated for systems having discrete energy-levels, however extension to continuum spectra is also discussed. It is shown that probability-distribution-function (PDF) of total entropy-production has exponential tails at large values of entropy-production. This result agrees with recently obtained experimental data on PDF s of heat-fluxes between two reservoirs coupled via a single-molecule-junction. In addition it is shown how this approach allows us to calculate the average-value of total entropy-production and it s fluctuations. Finally we discuss possibilities of applying these results to transport phenomena occurring in molecular junctions.",
        "watermark_text": "The statistical mechanics of time - independent non - dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation theorem . The main results are formulated for models with discrete energy levels , but they can be applied to continuous spectrum as also .It is demonstrated that the probability distribution relation ( PDF ) of the total entropy production has an exponential tail at large values of entropy production . This result agrees with recent experimental evidence on PDFs of thermal fluxes between two basins connected by a single molecule interchange .In addition it is demonstrated how this methodology allows one to estimate the average value of the total entropy production and its fluctuations . Finally we explain possible use of these results to transport phenomena in molecular junctions .We see that our theory predicts correctly the relationship of the current - electrical properties on temperature difference between the leads . Statistical mechanics of time independent non - dissipative non - equilibrium states is studied within the framework of generalized entropy - production and fluctuation principle .Main findings are formulated for models having discrete energy - rates , however application to continuum spectra is also discussed . It is seen that probability - distribution - function ( PDF ) of gross entropy - production has exponential tails at large values of entropy - production .This result agrees with recently obtained experimental evidence on PDF s of temperature - fluxes between two basins coupled via a single - atom - junction . In addition it is demonstrated how this methodology allows us to estimate the average - value of gross entropy - production and it s fluctuations .Finally we explain options of using these results to transport phenomena occurring in molecular junctions .",
        "ori-fast-z-score": 1.8347785189881796,
        "water-fast-z-score": 8.30018853827986
    },
    {
        "original_text": "Spin echoes are observed when the spin system is subjected to two successive radio-frequency (RF) pulses separated by an interval, known as the pulse separation time Tsep. The first RF pulse creates a macroscopic magnetization vector M0 that precesses around the external magnetic field Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins. After the second RF pulse with flip angle θ2 and phase shift φ2 relative to the first one, the transverse component of the magnetization vector M2(t) decays exponentially due to dephasing caused by local magnetic fields created by neighboring nuclei. In this work we show how strong π-pulses can be used to generate spin echoes even if there is no net initial magnetization present before applying these pulses. We demonstrate theoretically and experimentally that such spin echoes originate intrinsically from the dipolar interactions between nuclear spins.",
        "watermark_text": "Spin signals are observed when the spin network is subjected to two subsequent radio - frequency ( RF ) bursts separated by an interval , known as the pulse splitting rate Tsep . The first RF signal creates a macroscopic magnetization vector M0 that precesses around the external magnetic force Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins .After the second RF signal with flip angle θ2 and phase shift φ2 relative to the first one , the transverse component of the magnetization vector M2 ( t ) decays exponentially due to dephasing generated by local magnetic waves created by adjacent nuclei . In this research we show how strong π - pulses can be used to create spin signals even if there is no net initial magnetization present before applying these pulses .We suggest theoretically and experimentally that such spin signals originate intrinsically from the dipolar relationships between nuclear spins .",
        "ori-fast-z-score": -1.8325416653445783,
        "water-fast-z-score": 3.0542361089076304
    },
    {
        "original_text": "We present the results of our numerical simulations of magnetorotational collapse (MRC) in primordial stars with initial masses between 100 and 1000 M⊙, which are formed at redshifts z = 20 − 30. We find that for all models considered here, magnetic fields play an important role during the formation process of black holes. The final mass of the central object is determined by the strength of the magnetic field. For weak magnetic fields (B < 10^10 G), we obtain stellar-mass black holes; while for stronger fields (B > 10^{10}G), supermassive black holes form. In addition to this effect on the final mass, magnetic fields also affect the angular momentum distribution inside the collapsing star. This leads to different spin parameters of the resulting black hole depending on its progenitor s initial mass. \n \n Keywords: Black Hole, Primordial Star Formation, Magnetohydrodynamics",
        "watermark_text": "We present the conclusion of our numerical simulations of magnetorotational formation ( MRC ) in primordial stars with initial masses between 100 and 1000 [UNK] , which are created at redshifts z = 20 − 30 . We see that for all models discussed here , magnetic fields play an important role during the formation period of red holes .The final mass of the main object is chosen by the strength of the magnetic force . For weak magnetic fields ( B < 10 ^ 10 G ) , we obtain stellar - weight blue holes ; while for heavier fields ( B > 10 ^ { 10 } G ) , supermassive black holes create .In addition to this effect on the finished mass , magnetic waves additionally affect the angular velocity distribution inside the falling star . This leads to different spinning characteristics of the resulting black hole depending on its progenitor s initial mass .Keywords: Black Hole, Primordial Star Formation, Magnetohydrodynamics",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.185110693297313
    },
    {
        "original_text": "We study the decay amplitudes for charmless hadronic B decays into a scalar meson and an axial-vector or tensor meson in the framework of QCD factorization with generalized form factors at large recoil.  We find that, although the branching fractions are small due to the helicity suppression, these processes can be used as probes of new physics beyond the Standard Model through their CP asymmetries. \nPACS numbers: 11.15.Tk, 12.38.Qk, 13 .25.Hw \nI. INTRODUCTORY REMAR K\nIn this work we will consider the following two types of charmless hadronic:  B → S V (S = P , A 0 ;V = T 1 )andB → SV(S=P;V=A1). The first type is characterized by one light quark in the final state while the second has no light quarks in it. In both cases there is only one spectator quark which leads to a helicity suppression of the corresponding decay rates. However, they may still serve as useful probes of new physics since their CP-violating asymmetries could be enhanced significantly compared to those of other modes  1  .\nTheoretically, such decays have been studied within various approaches including naive factorization  2  , perturbative QCD  3  , soft-collinear effective theory  4  , and QCD factorization  5  -  8  . It was found that the predictions based on different methods differ substantially among themselves. For example, using naive factorization, Ref.  2  predicted Br(B − →K * 0 π − )/Br(B − →Kπ)=0.27 ±0.04, whereas Refs.  6, 7  obtained values around 0.1−0.2. This discrepancy indicates that more theoretical efforts should be made before drawing any definite conclusion about these decays.",
        "watermark_text": "We research the decay amplitudes for charmless hadronic B decays into a scalar meson and an axial - vector or vector meson in the framework of QCD factorization with generalized form factors at large recoil . We see that , although the branching fractions are small owing to the helicity suppression , these mechanisms can be used as probes of new dynamics beyond the Standard Model through their CP asymmetries .PACS numbers : 11 . 15 . Tk , 12 . 38 . Qk , 13 . 25 . Hw I . INTRODUCTORY REMAR K In this study we will explore the following two forms of charmless hadronic : B → S V ( S = P , A 0 ; V = T 1 ) andB → SV ( S = P ; V = A1 ) .The first sort is characterized by one light quark in the last position while the second has no light quarks in it . In both cases there is only one spectator quark which results to a helicity suppression of the associated decay rates .However , they may still provide as helpful probes of new theory since their CP - breaking asymmetries may be enhanced considerably compared to those of other modes 1 . Theoretically , such decays have been studied within various approaches including naive factorization 2 , perturbative QCD 3 , soft - collinear effective theory 4 , and QCD factorization 5 - 8 .It was shown that the estimates based on various methods varies dramatically among themselves . For instance , using naive factorization , Ref .2 observed Br ( B − →K * 0 π − ) / Br ( B − →Kπ ) = 0 . 27 ±0 . 04 , whereas Refs . 6 , 7 obtained values around 0 . 1−0 . 2 .This discrepancy implies that more theoretical efforts should be made before drew any explicit conclusion about these decays .",
        "ori-fast-z-score": 0.3375263702778072,
        "water-fast-z-score": 6.484597134749389
    },
    {
        "original_text": "We study the phenomenology of string compactifications with large extra dimensions, focusing on supersymmetric particles in the mass range accessible to current experiments at the Large Hadron Collider (LHC). We consider two classes of models that are motivated by recent developments in string theory: weakly coupled heterotic orbifolds and strongly coupled Type IIB orientifold constructions. In both cases we find that there is an interesting interplay between the Kaluza-Klein excitations associated with the extra dimensions and the lightest Standard Model superpartners. For example, in some regions of parameter space it may be possible to produce gluinos or squarks directly via Drell-Yan processes; alternatively, these states can decay into lighter Standard Model superpartners which then cascade down to the LSP neutralino. The resulting collider signatures depend sensitively on the details of the underlying model parameters as well as the number of extra dimensions.",
        "watermark_text": "We research the phenomenology of string compactifications with large extra dimensions , concentrating on supersymmetric particles in the mass range available to recent experiments at the Large Hadron Collider ( LHC ) . We consider two groups of models that are motivated by recent developments in string theory : weakly connected heterotic orbifolds and strongly coupled Type IIB orientifold constructions .In both cases we find that there is an interesting interplay between the Kaluza - Klein excitations associated with the extra dimensions and the lightest Standard Model superpartners . For instance , in some regions of parameter room it could be possible to produce gluinos or squarks directly via Drell - Yan processes ; alternatively , these states can evolve into heavier Standard Model superpartners which then cascade down to the LSP neutralino .The produced collider signatures vary sensitively on the details of the underlying model variables as also as the number of added dimensions .",
        "ori-fast-z-score": 0.9271726499455306,
        "water-fast-z-score": 5.165676192553671
    },
    {
        "original_text": "We present an algorithm for consistent hypothesis testing in which we consider all possible hypotheses that are compatible with some given set of observations, and select those that maximize their posterior probability according to Bayes  theorem.  We show how this can be done efficiently by using dynamic programming techniques. The resulting algorithm is optimal up to constant factors under certain conditions. Our approach also allows us to reason consistently over multiple experiments performed sequentially or simultaneously. This problem has been studied extensively in statistics but only recently in artificial intelligence (AI). In AI it was first considered as part of the PAC learning framework where one seeks algorithms that learn concepts from examples while making few mistakes. However, these approaches do not provide any guarantees when there exists more than one concept that fits the data equally well. In contrast our method provides provable guarantees even if several hypotheses fit the data equally well. Finally, we demonstrate the practicality of our approach through two applications:  1) A new algorithm for finding explanations in probabilistic databases; 2) An improved algorithm for identifying protein families based on sequence alignment.",
        "watermark_text": "We present an algorithm for consistent hypothesis testing in which we investigate all possible hypotheses that are compatible with some particular set of measurements , and select those that maximize their posterior likelihood according to Bayes principle . We see how this can be performed efficiently by using dynamic programming tools .The resulting algorithm is efficient up to constant factors under certain conditions . Our solution therefore allows us to reason consistently over multiple studies performed sequentially or separately .This problem has been studied frequently in statistics but only lately in artificial intelligence ( AI ) . In AI it was first considered as part of the PAC learning framework where one seeks methods that learn concepts from instances while making few errors .However , these perspectives do not offer any promises when there exists more than one concept that fits the information equally perfectly . In comparison our technique provides provable assurance even if several hypotheses fitted the information equally perfectly .Finally , we prove the practicality of our approach through two applications : 1 ) A modern algorithm for finding explanations in probabilistic libraries ; 2 ) An upgraded method for finding protein families using on sequence alignment .",
        "ori-fast-z-score": -2.3849888978799783,
        "water-fast-z-score": 5.848076606885379
    },
    {
        "original_text": "We present the catalog of host galaxies used by the Laser Interferometer Gravitational-Wave Observatory (LIGO) to search for gravitational waves associated with compact binary coalescences, including black hole-neutron star and neutron star-black hole binaries.  The catalog contains information on all known host galaxies within the sensitivity volume of the first-generation Advanced LIGO detectors during their initial science runs between September 2005 and January 2010. We provide positions, redshifts, distances, and references for each galaxy. This is an update to our previous publication  1  . \nThe data are available at http://arxiv.org/abs/1306.5481. They can also be downloaded as a text file or via the Zenodo repository  2  .\nAuthor Information\n\nCorresponding Author:\nE-mail: jennifer.marrone@ligo.gov; Jennifer Marrone, National Science Foundation",
        "watermark_text": "We present the catalog of host galaxies utilized by the Laser Interferometer Gravitational - Wave Observatory ( LIGO ) to search for gravitational waves related with compact binary coalescences , notably black hole - neutron star and neutron star - black hole binaries . The collection contains information on all known host galaxies within the sensitivity volume of the first - generation Advanced LIGO detectors during their early scientific ran between September 2005 and January 2010 .We derive positions , redshifts , distances , and references for each galaxy . This is an update to our previous publish 1 .The data are available at http : / / arxiv . org / abs / 1306 . 5481 . They can also be downloaded as a text file or via the Zenodo repository 2 .Author Information Corresponding Author : E - mail : jennifer . marrone @ ligo . gov ; Jennifer Marrone , National Science Foundation",
        "ori-fast-z-score": 0.42008402520840293,
        "water-fast-z-score": 2.3804761428476167
    },
    {
        "original_text": "We study the quantum noise properties of gravitational wave detectors with signal recycling mirror (SRM). We show that, for an interferometer with SRM, there is no fundamental limit on its sensitivity at high frequencies due to vacuum fluctuations. The shot-noise limited sensitivity can be improved by increasing the circulating power inside the cavity formed between the two arms of the detector. This improvement comes at the expense of increased thermal noise associated with the mirrors forming this cavity. In addition we find that the effect of radiation pressure noise depends strongly on whether or not the input test mass is suspended. Finally, we discuss how these results may be used to improve existing designs of advanced LIGO-like detectors. PACS numbers: 04.80.Nn, 95.35.+d, 98.80.Cq Quantum noise limits the performance of current generation ground-based gravitationalwave detectors such as Advanced LIGO  1  . These detectors are based on Michelson-interferometric configurations which use Fabry-Perot cavities to enhance their sensitivity  2  . However, it has been shown recently  3  , using semi-classical analysis, that the shot-noise limited sensitivity of these detectors cannot be further improved beyond certain frequency range without introducing additional technical noise sources into the system. It was also suggested  4  that one way to overcome this problem could be to introduce another mirror called  signal recycling  mirror (SRM) into the optical path of the interferometer. Using this approach, it should be possible to increase the circulating power within the interferometer while keeping the same level of shot-noise limited sensitivity achieved before adding the SRM.",
        "watermark_text": "We research the quantum noise characteristics of gravitational wave detectors with signal recycling window ( SRM ) . We see that , for an interferometer with SRM , there is no profound limit on its sensitivity at high frequencies owing to vacuum fluctuations .The shot - noise limited quality can be improved by increasing the circulating force inside the cavity formed between the two arms of the sensor . This improvement comes at the cost of enhanced thermal noise identified with the mirrors forming this cavity .In addition we find that the impact of radiation volume noise depends strongly on whether or not the input test mass is suspended . Finally , we explain how these results may be used to upgrade existing models of advanced LIGO - like detectors .PACS codes : 04 . 80 . Nn , 95 . 35 . + d , 98 . 80 . Cq Quantum noise limits the performance of recent generation ground - based gravitationalwave detectors such as Advanced LIGO 1 . These detectors are based on Michelson - interferometric designs which use Fabry - Perot cavities to expand their sensitivity 2 .However , it has been shown recently 3 , using semi - classical study , that the shot - noise limited accuracy of these detectors cannot be further increased beyond particular wavelength range without introducing additional technical sound sources into the device . It was also suggested 4 that one means to overcome this situation could be to introduce another glass called wave filtering mirror ( SRM ) into the optical track of the interferometer .Using this methodology , it should be possible to expand the circulating capacity within the interferometer while maintaining the same level of shooting - noise limited accuracy achieved before add the SRM .",
        "ori-fast-z-score": 0.45454545454545453,
        "water-fast-z-score": 7.967145651741631
    },
    {
        "original_text": "We study non-commutative Donaldson–Thomas invariants for Calabi-Yau threefolds in terms of their crepant resolutions, which are called conifolds. We show that these invariants can be computed by counting holomorphic curves on the resolved spaces with suitable boundary conditions. As an application we compute the Donaldson–Thomas invariant of the quintic threefold using its crepant resolution as well as the mirror quintic. The results agree with those obtained previously via other methods. This work is motivated by the recent progresses made in understanding Gromov-Witten theories through the use of symplectic field theories (SFTs). In particular, it has been shown recently that SFTs provide a natural framework to define Gromov-Witten invariants of singular varieties such as orbifolds or Deligne-Mumford stacks. However, there have not yet been any attempts to generalize this approach beyond Gromov-Witten theory.",
        "watermark_text": "We research non - commutative Donaldson – Thomas invariants for Calabi - Yau threefolds in terms of their crepant resolutions , which are called conifolds . We see that these invariants can be computed by counting holomorphic curves on the resolved spaces with suitable boundary constraints .As an implementation we compute the Donaldson – Thomas invariant of the quintic threefold using its crepant resolution as well as the mirror quintic . The results agree with those achieved prior via other methods .This research is prompted by the recent progresses done in understanding Gromov - Witten theories through the using of symplectic field theories ( SFTs ) . In particular , it has been shown lately that SFTs allow a natural framework to define Gromov - Witten invariants of singular varieties such as orbifolds or Deligne - Mumford stacks .However , there have not already been any efforts to generalize this methodology beyond Gromov - Witten theory .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.041451884327381
    },
    {
        "original_text": "We present new observations and analysis of the neutral hydrogen (HI) disks surrounding isolated galaxies, using data obtained with the Very Large Array (VLA). We have observed 12 nearby galaxies at 21 cm wavelength to determine their total HI mass and distribution within the optical disk. The sample includes both late-type spirals and dwarf irregulars. Our results show that all but one galaxy has an extended HI halo beyond its optical radius; this is true even for the most gas-rich systems such as NGC 4254 and NGC 5253. In addition, we find evidence for significant amounts of atomic gas outside our detection limits which may be associated with tidal features or other interactions between these galaxies and neighboring companions. These findings are consistent with previous studies showing that many isolated spiral galaxies contain large quantities of cold interstellar medium distributed over several kiloparsecs. \n \n Keywords: Atomic Hydrogen, Galaxy Evolution, Spiral Structure",
        "watermark_text": "We report new studies and investigation of the neutral hydrogen ( HI ) disks comprising isolated stars , using data acquired with the Very Large Array ( VLA ) . We have noted 12 nearby galaxies at 21 cm wavelength to obtain their total HI mass and distribution within the optical disk .The sample comprises both late - class spirals and dwarf irregulars . Our results show that all but one star has an extended HI halo beyond its optical diameter ; this is true even for the most gas - rich complexes such as NGC 4254 and NGC 5253 .In addition , we find proof for significant amounts of atomic liquid outside our detection limits which may be correlated with tidal features or other relationships between these objects and surrounding companions . These conclusions are compatible with previous research indicating that several isolated spiral clusters hold significant amounts of cold interstellar medium spread over several kiloparsecs .Keywords: Atomic Hydrogen, Galaxy Evolution, Spiral Structure",
        "ori-fast-z-score": -0.5852057359806528,
        "water-fast-z-score": 5.969098507002659
    },
    {
        "original_text": "The lattice Boltzmann method (LBM) is an alternative approach for solving the Navier-Stokes equations in fluid dynamics, which has been widely used due to its advantages over traditional numerical methods such as finite difference and finite element approaches.  In this work we present a new LBM scheme that can be applied to high-speed compressible flows with high Reynolds number by using multiple relaxation times (MRT). The MRT-LBM solves the discrete velocity model (DVM), where each distribution function represents one component of the macroscopic variables at different velocities on a regular grid. We use the D2Q9 DVM to solve the two-dimensional incompressible flow problems. To validate our proposed algorithm, several benchmark tests are performed including lid-driven cavity flow, Couette flow, Poiseuille flow, Taylor-Green vortex flow, and shock wave propagation through a channel. Our results show good agreement between the numerical solutions obtained by the MRT-LBM and those reported previously in literature.",
        "watermark_text": "The lattice Boltzmann technique ( LBM ) is an additional method for solving the Navier - Stokes equations in flow dynamics , which has been widely using due to its benefits over traditional numerical methods such as finite difference and finite element approaches . In this study we present a new LBM technique that can be applied to large - speed compressible flows with high Reynolds number by using multiple relaxation times ( MRT ) .The MRT - LBM solves the discrete momentum system ( DVM ) , where each distribution function reflects one element of the macroscopic parameters at different velocities on a regular grid . We use the D2Q9 DVM to solve the two - dimensional incompressible flow difficulties .To validate our proposed algorithm , various benchmark tests are performed including lid - driven cavity flow , Couette fluid , Poiseuille flow , Taylor - Green vortex flow , and blast wave propagation through a channel . Our results show good agreement between the numerical answers obtained by the MRT - LBM and those published previously in literature .",
        "ori-fast-z-score": 1.462614271203831,
        "water-fast-z-score": 5.737948294722722
    },
    {
        "original_text": "We present new observations of the distant galaxy cluster RX J1117.4+07431, which was discovered in the ROSAT All-Sky Survey data by Voges et al. (1999) . The cluster is located at redshift z = 0.485 ± 0.001 with an estimated mass M500 = 1.7 × 1013 h-1M⊙ within r500 = 2.1h-1Mpc . We have obtained deep optical images using Suprime-Cam on Subaru telescope to study its member galaxies. In addition we observed this cluster with Chandra ACIS-I for about 50 ks. Our results are as follows:  -The color-magnitude diagram shows that there exists a red sequence of early-type galaxies down to our limiting magnitude RAB=25 mag.  -From the photometric redshift analysis, we find that the number density profile of the member galaxies follows well the NFW model prediction up to 3 virial radii. -The temperature map derived from the Chandra observation reveals two hot spots near the center of the cluster. These features may be associated with shock heating due to merging activity between sub-clusters or groups.",
        "watermark_text": "We present new observations of the distant galaxy cluster RX J1117 . 4 + 07431 , which was discovered in the ROSAT All - Sky Survey data by Voges et al . ( 1999 ) .The cluster is situated at redshift z = 0 . 485 ± 0 . 001 with an estimated mass M500 = 1 . 7 × 1013 h - [UNK] within r500 = 2 . 1h - 1Mpc . We have achieved deep optical images using Suprime - Cam on Subaru observatory to study its member galaxies .In addition we studied this cluster with Chandra ACIS - I for about 50 ks . Our results are as follows : - The color - magnitude diagram indicates that there exists a red series of early - class stars down to our limiting magnitude RAB = 25 mag .- From the photometric redshift studies , we find that the number density profile of the member galaxies resembles better the NFW model prediction up to 3 virial radii . - The temperature diagram derived from the Chandra observation discovers two hot areas near the center of the cluster .These features could be correlated with shock heating due to merging behavior between sub - communities or bands .",
        "ori-fast-z-score": -0.23249527748763857,
        "water-fast-z-score": 3.9524197172898554
    },
    {
        "original_text": "We present new spectroscopic data for the galaxy cluster Abell115 (z=0.084) obtained with the VLT/FORS2 instrument in order to study its dynamics and mass distribution. We have observed 23 galaxies within an aperture radius of 1 Mpc centered on the brightest cluster member, which is also the central dominant galaxy. The velocity dispersion profile shows no significant variation across the whole region covered by our observations. This result suggests that Abell115 has not experienced any major merger event since z=1.5-2.0. Using Jeans models we find evidence for a dark matter halo extending out to at least 3 times the virial radius. From this analysis we derive a total mass of 2.1(+0.7-0.6)x10^14M_sun inside a sphere of radius R200=850kpc. Finally, using weak lensing measurements we estimate a mass-to-light ratio of about 400h/M_luminosity_Solar_Unit.",
        "watermark_text": "We present new spectroscopic data for the galaxy cluster Abell115 ( z = 0 . 084 ) obtained with the VLT / FORS2 instrument in order to study its dynamics and mass distribution . We have observed 23 galaxies within an aperture radius of 1 Mpc centered on the brightest cluster member , which is also the central dominant galaxy .The velocity dispersion model shows no considerable variation across the whole area covered by our observations . This result suggests that Abell115 has not experienced any big merger event since z = 1 . 5 - 2 . 0 .Using Jeans techniques we find proof for a black material halo reaching out to at least 3 times the virial diameter . From this analysis we derive a total mass of 2 . 1 ( + 0 . 7 - 0 . 6 ) x10 ^ 14M _ sun inside a sphere of radius R200 = 850kpc .Finally , using weak lensing observations we estimate a mass - to - light percentage of about 400h / M _ luminosity _ Solar _ Unit .",
        "ori-fast-z-score": 0.762000762001143,
        "water-fast-z-score": 4.0
    },
    {
        "original_text": "In this thesis, we study power control problems in cellular mobile radio systems with code division multiple access (CDMA). We consider the uplink scenario where each user transmits to its base station using an orthogonal spreading sequence and all users share the same frequency band. The objective is to minimize the total transmit power subject to individual quality-of-service constraints at each user s receiver. In order to obtain tractable results, we make use of tools from stochastic geometry which allow us to model the locations of both mobiles and interferers as point processes. Our main contributions are summarized below.  First, we derive closed-form expressions for the outage probability when the number of active users grows without bound. These expressions can be used to determine how many users can simultaneously communicate reliably over the network. Second, we propose distributed power control schemes that achieve these limits asymptotically under certain conditions. Third, we develop centralized power control algorithms that guarantee performance close to optimality even if only partial information about the channel gains or interference levels is available. Finally, we present simulation results illustrating our theoretical findings.",
        "watermark_text": "In this dissertation , we study control power problems in cell mobile radio circuits with code division multiple entry ( CDMA ) . We consider the uplink situation where each consumer transmits to its base station use an orthogonal spreading pattern and all users share the same frequency band .The goal is to minimize the total broadcast capacity related to individual quality - of - service restrictions at each consumer s receiver . In order to obtain tractable results , we make using of tools from stochastic geometry which allow us to model the places of both mobiles and interferers as point processes .Our main contributions are presented below . First , we derive closed - form expressions for the outage likelihood when the number of active usage rises without bound .These expressions can be used to predict how many users can independently connect reliably over the network . Second , we develop dispersed power control schemes that attain these limits asymptotically under certain conditions .Third , we develop concentrated control power methods that guarantee efficiency high to optimality even if only partial knowledge about the channel gains or interference concentrations is accessible . Finally , we present modeling results illustrating our theoretical results .",
        "ori-fast-z-score": 0.19802950859533489,
        "water-fast-z-score": 7.4
    },
    {
        "original_text": "We study the statistical properties of simulated dark matter halos in cosmological N-body simulations, focusing on their shapes and orientations with respect to each other. We find that these quantities are strongly correlated for pairs of halos separated by less than one virial radius (the region within which the density is roughly constant). This correlation persists even when we consider only those pairs whose mutual separation lies along the line-of-sight between them. The correlations can be understood as arising due to tidal forces exerted by neighboring halos. In particular, we show that the distribution of halo shapes depends sensitively upon whether or not they lie close to an axis of symmetry of the local gravitational potential field. Finally, we compare our results against observations of galaxy clusters obtained using weak lensing techniques. Our analysis suggests that the observed cluster morphologies may provide useful constraints on the nature of primordial fluctuations responsible for structure formation in the universe.",
        "watermark_text": "We research the statistical characteristics of virtual dark matter halos in cosmological N - bodies simulations , concentrating on their shapes and orientations with regard to each other . We see that these quantities are strongly correlated for pairs of halos separated by less than one virial diameter ( the region within which the density is approximately zero ) .This coupling persists even when we treat only those couples whose mutual separation lies along the line - of - view between them . The correlations can be understood as occurring due to wave forces exerted by adjacent halos .In particular , we prove that the distribution of halo patterns depends sensitively upon whether or not they lay close to an axis of symmetry of the local gravity potential field . Finally , we compare our findings against measurements of galaxy galaxies acquired using weak lensing methods .Our study implies that the known cluster morphologies may provide useful limitations on the nature of primordial fluctuations involved for structure development in the universe .",
        "ori-fast-z-score": -1.5215349135496974,
        "water-fast-z-score": 6.671345390179443
    },
    {
        "original_text": "We investigate whether we can detect anisotropy in quasar H II regions during reionization through their small-scale redshifted 21 cm power spectrum (21-cm PS). In our model, quasars are assumed to be located at peaks of dark matter density fluctuations and ionize surrounding gas with an anisotropic Strömgren sphere whose shape is determined by the local tidal field. By performing numerical simulations for different values of the spin temperature T S , we find that the 21-cm PS has a characteristic peak structure which reflects the shapes of individual H II regions. This peak structure becomes more prominent as T S decreases because the number of neutral hydrogen atoms increases due to the decrease in the brightness temperature difference between the CMB and the 21-cm emission line. Our results suggest that it may be possible to use this peak structure to constrain the value of T S . However, since there exist many other factors affecting the 21-cm PS besides T S , further studies will be needed before drawing any conclusions on its detectability.",
        "watermark_text": "We explore whether we can identify anisotropy in quasar H II regions during reionization through their tiny - scale redshifted 21 cm power spectrum ( 21 - cm PS ) . In our model , quasars are expected to be found at peaks of dark matter density fluctuations and ionize neighboring plasma with an anisotropic Strömgren ball whose shape is chosen by the local tidal field .By conducting numerical simulations for different values of the spin temperature T S , we find that the 21 - cm PS has a typical peak structure which reflects the shapes of different H II regions . This peak structure becomes more prominent as T S drops because the proportion of neutral hydrogen atoms increases owing to the decrease in the brightness temperature difference between the CMB and the 21 - cm absorption line .Our results propose that it could be possible to use this peak structure to constrain the value of T S . However , since there remain many other influences involving the 21 - cm PS besides T S , further studies will be needed before drew any findings on its detectability .",
        "ori-fast-z-score": 1.7320508075688772,
        "water-fast-z-score": 6.350852961085883
    },
    {
        "original_text": "We study the dynamics of two interacting bosonic species confined to an optical lattice, with one species being initially prepared as a coherent state at each site while the other is initially prepared as a thermal cloud. We show that this system supports both symmetric and asymmetric soliton solutions which are stable against small perturbations for certain values of the chemical potentials. The stability properties of these solitons can be understood by studying their linearization spectrum around the stationary states. In particular we find that the presence of a finite temperature leads to additional unstable modes associated with phonon-like excitations. Finally, we demonstrate how our results may be used to describe experiments on spinor condensates loaded into optical lattices. Introduction:-Recent experimental advances have made it possible to create quantum degenerate gases consisting of several different atomic species  1  . These systems provide new opportunities to explore novel phenomena such as supersolids  2  , phase separation  3  or spin-orbit coupling  4  .\nIn this work we consider a particularly interesting example where there exist two distinct types of particles (e.g., atoms) which interact via s-wave scattering but differ in mass and/or internal structure  5  . This situation arises naturally when considering mixtures of hyperfine states  6  or isotopes  7, 8  within the same atom type  9  . For instance, recent experiments involving 87 Rb and 41 K  10  have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling  11  . Another possibility would involve using 40 K and 6 Li  12  . Here, the lighter species could be considered as impurities immersed in a background gas of heavier fermions  13  . Alternatively, if the masses were reversed then the heavy species could act as impurities  14  .",
        "watermark_text": "We research the dynamics of two interacting bosonic species confined to an optical lattice , with one species being initially made as a coherent state at each site while the other is initially prepared as a heat bubble . We see that this scheme holds both symmetric and asymmetric soliton solutions which are stable against small perturbations for particular values of the chemical potentials .The stability properties of these solitons can be understood by examining their linearization spectrum around the stationary states . In particular we find that the presence of a finite temperature leads to extra weak modes associated with phonon - like excitations .Finally , we prove how our findings may be used to explain studies on spinor condensates stacked into optical lattices . Introduction : - Recent research developments have enabled it able to create quantum degenerate gases composed of several different atomic species 1 .These systems present new opportunities to examine novel processes such as supersolids 2 , phase splitting 3 or spin - orbit resonance 4 . In this research we imagine a particularly exciting example where there exist two different kinds of atoms ( e . g . , atoms ) which interact via s - wave scattering but differ in mass and / or internal structure 5 .This condition occurs naturally when examining mixtures of hyperfine states 6 or isotopes 7 , 8 within the same atom type 9 . For instance , recent experiments concerning 87 Rb and 41 K 10 have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling 11 .Another possibility would include utilizing 40 K and 6 Li 12 . Here , the softer species may be regarded as impurities immersed in a background gas of heavier fermions 13 .Alternatively , if the masses were reversed then the heavy species may function as impurities 14 .",
        "ori-fast-z-score": -0.3481553119113957,
        "water-fast-z-score": 6.5033247714309
    },
    {
        "original_text": "We consider an additive white Gaussian noise (AWGN) channel with multiple paths, each having different delay and gain coefficients. We assume that these channels are sparse; i.e., there is only one path whose gain coefficient exceeds some threshold value. The capacity region for this class of channels has been studied by several authors under various assumptions on the number of paths and their gains.  In particular, it was shown recently that if all the paths have equal power then the capacity region can be achieved using superposition coding at transmitter and successive decoding at receiver. However, when the powers of the paths vary widely, the optimality of such schemes remains unknown. In this work we show that even though the optimal scheme may not use superposition coding or successive decoding, its performance cannot differ significantly from those schemes. More specifically, we prove upper bounds on the gap between the achievable rates using any scheme and the sum-capacity of the channel.",
        "watermark_text": "We consider an additive white Gaussian sound ( AWGN ) channel with many lanes , each having specific delay and gain values . We assume that these networks are sparse ; i . e . , there is only one path whose gain coefficient exceeds some threshold value .The capacity area for this class of channels has been studied by various scientists under various observations on the number of paths and their benefits . In particular , it was shown lately that if all the paths have equal energy then the ability area can be obtained using superposition coding at transmitter and subsequent decoding at receiver .However , when the powers of the paths differ widely , the optimality of such schemes remains undisclosed . In this research we prove that even though the ideal method may not use superposition coding or successive decoding , its effectiveness cannot differ significantly from those schemes .More specifically , we prove upper limits on the gap between the achievable rates using any scheme and the sum - capacity of the channel .",
        "ori-fast-z-score": 0.22645540682891913,
        "water-fast-z-score": 5.737948294722722
    },
    {
        "original_text": "We study one-way permutation families with respect to their ability to resist certain attacks by adversaries that are computationally restricted in the sense that they can only perform limited number of queries to the permutation family. We show how this notion relates to computational complexity theory and present several new results on the topic. In particular we prove that any one-way permutation family is resistant against an adaptive chosen-ciphertext attack if it resists a non-adaptive one. This result implies that for every one-way permutation there exists another one-way permutation which is secure under both types of attacks simultaneously. Finally, we introduce a novel concept called distortion measure between two one-way permutation families and use it to derive lower bounds on the security parameters required to achieve resistance against different classes of attacks. The research leading to these results has been funded by the European Research Council under the Seventh Framework Programme (FP7/2007-2013) / ERC Grant Agreement n o 339032",
        "watermark_text": "We research one - way permutation families with regard to their ability to resist various attacks by adversaries that are computationally confined in the sense that they can only conduct small number of queries to the permutation family . We see how this phenomenon relates to computational complexity analysis and publish numerous current conclusions on the subject .In particular we prove that any one - way permutation family is resistant against an adaptive chosen - ciphertext attack if it resists a non - adaptive one . This result requires that for every one - way permutation there exists another one - way permutation which is stable under both types of assaults simultaneously .Finally , we approach a new notion called distortion function between two one - way permutation families and use it to derive smaller bounds on the safety parameters essential to achieve resistance against diverse classes of assaults . The studies leading to these results has been sponsored by the European Research Council under the Seventh Framework Programme ( FP7 / 2007 - 2013 ) / ERC Grant Agreement n o 339032",
        "ori-fast-z-score": -0.23904572186687872,
        "water-fast-z-score": 6.215188768538847
    },
    {
        "original_text": "We present the results on galaxy population in the most massive supercluster, SCl 126 (Abell 1689), based on spectroscopic data obtained with VLT/VIMOS and Keck/DEIMOS telescopes. We find that galaxies are distributed along filaments which connect clusters at different redshifts. The fraction of blue galaxies increases towards lower redshift, while the fraction of early-type galaxies decreases. This trend is more pronounced for bright galaxies than faint ones. In addition to this general picture we also detect some interesting features such as an excess of late-type galaxies around Abell 1689A cluster or a lack of bright galaxies between Abell 1689B and C clusters. These findings suggest that there may be significant differences among galaxy properties within individual clusters depending on their location relative to other structures. Our analysis shows that the observed trends can not be explained by simple passive evolution of stellar populations but require additional mechanisms like mergers and/or interactions.",
        "watermark_text": "We present the results on galaxy population in the most large supercluster , SCl 126 ( Abell 1689 ) , using on spectroscopic data acquired with VLT / VIMOS and Keck / DEIMOS telescopes . We see that galaxies are distributed along filaments which link clusters at different redshifts .The percentage of blue stars increases towards lower redshift , while the fraction of early - class objects decreases . This trend is more pronounced for strong galaxies than dim ones .In addition to this general picture we also observe some interesting features such as an accumulation of late - class objects around Abell 1689A cluster or a lack of bright clusters between Abell 1689B and C clusters . These conclusions show that there may be considerable variations among galaxy structures within individual clusters depending on their placement relative to other structures .Our study shows that the known trends can not be described by simple passive evolution of stars populations but need extra causes like mergers and / or relationships .",
        "ori-fast-z-score": -2.324952774876386,
        "water-fast-z-score": 5.347391382215687
    },
    {
        "original_text": "We present the discovery and characterization of two  hot Jupiter  planets orbiting stars that are members of wide binaries, HD 196885AB (a = 1.8 AU) and HD 208598AB (a = 3.6 AU). The planet around HD 196885A is an inflated gas giant with M sin i = 0.88 MJup and P = 4.3 days; it orbits its primary at a distance of only 0.04 AU. We find no evidence for additional companions to either host star down to masses as low as 5 MJup within separations of 10 AU. Both systems have orbital eccentricities consistent with zero. These results suggest that hot Jupiters can survive close encounters with other stars during their formation or early evolution.  - Introduction \n \n Hot Jupiters are massive gaseous planets on short-period orbits about solar-type stars. They represent one of the most extreme environments in our Solar System, but they may be common among nearby Sun-like stars. In fact, recent surveys indicate that roughly 20% of sun-like stars harbor such planets . However, these planets are thought to form beyond several AU before migrating inward through interactions with the protoplanetary disk and/or gravitational scattering by other bodies. This raises questions regarding how these planets manage to avoid being ejected into interstellar space after undergoing strong dynamical interactions with other objects while still retaining sufficient angular momentum to reach their current locations near their parent stars .\n\nIn this Letter we report the detection of two new  hot Jupiter  planets using high-precision radial velocity measurements obtained over more than eight years with the High Accuracy Radial Velocity Planet Searcher instrument (HARPS), which is installed on the European Southern Observatory s 3.6-m telescope located at La Silla Observatory in Chile. One of these planets has an extremely small semi-major axis of just 0.04 AU, making it one of the closest known exoplanets to its parent star.",
        "watermark_text": "We present the discovery and description of two hot Jupiter planets orbiting planets that are part of wide binaries , HD 196885AB ( a = 1 . 8 AU ) and HD 208598AB ( a = 3 . 6 AU ) . The planet around HD 196885A is an inflated gas giant with M sin i = 0 . 88 MJup and P = 4 . 3 days ; it orbits its primary at a distance of only 0 . 04 AU .We see no evidence for additional companions to either host star down to masses as low as 5 MJup within separations of 10 AU . Both components have orbital eccentricities consistent with zero .These data suggest that hot Jupiters can endure close contacts with other stars during their development or early evolved . - Introduction Hot Jupiters are enormous gaseous planets on short - duration orbits about solar - class stars .They represent one of the most intense environments in our Solar System , but they may be prevalent among neighboring Sun - like stars . In reality , recent studies confirm that approximately 20 % of sun - like stars harbor such planets .However , these planets are said to form beyond many AU before migrating inward through interactions with the protoplanetary disk and / or gravitational absorption by other bodies . This opens questions regarding how these planets cope to resist being ejected into interstellar space after undergoing stable dynamical interactions with other objects while nevertheless possessing adequate angular velocity to reach their current places near their sister planets .In this Letter we publish the observation of two new warm Jupiter planets using high - precision radial speed measurements obtained over more than eight years with the High Accuracy Radial Velocity Planet Searcher instrument ( HARPS ) , which is installed on the European Southern Observatory s 3 . 6 - m observatory situated at La Silla Observatory in Chile . One of these planets has an incredibly small semi - major axis of just 0 . 04 AU , making it one of the nearest known exoplanets to its parent star .",
        "ori-fast-z-score": -1.7960530202677492,
        "water-fast-z-score": 6.286185570937122
    },
    {
        "original_text": "We study the evolution of magnetized, rotating flows in the presence of strong magnetic fields and rotation using 3D numerical simulations with ideal MHD equations. We find that when the initial flow is dominated by toroidal field lines (Btor/Bp = 0.5), it becomes unstable to non-axisymmetric perturbations at t ~ 1.2P0/c where P0 is the initial pressure scale height. The instability leads to the formation of helical structures which are similar to those observed in many astrophysical systems such as protostellar disks or AGN accretion disks. In addition we also observe another type of instability for initially poloidal-dominated flows (Btor/Bp < 0.1) which develops into an axisymmetric spiral structure. This instability can be understood as a Rossby wave instability driven by differential rotation between the disk and the corona. Finally, we show that these two types of instabilities lead to different observational signatures.",
        "watermark_text": "We research the evolution of magnetized , moving flows in the presence of large magnetic fields and rotation utilizing 3D numerical simulations with ideal MHD equations . We see that when the first flow is dominated by toroidal field lines ( Btor / Bp = 0 . 5 ) , it becomes unstable to non - axisymmetric perturbations at t ~ 1 . 2P0 / c where P0 is the initial pressure scale length .The instability leads to the formation of helical structures which are comparable to those observed in many astrophysical systems such as protostellar disks or AGN accretion disks . In addition we also observe another type of instability for initially poloidal - dominated streams ( Btor / Bp < 0 . 1 ) which becomes into an axisymmetric spiral shape .This instability can be understood as a Rossby wave disturbance driven by differential rotation between the disk and the corona . Finally , we find that these two forms of instabilities lead to different observational signatures .",
        "ori-fast-z-score": 0.508000508000762,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "The article is devoted to the problem of possible existence of dark matter particles in our Galaxy, which are not detected by other methods than their gravitational effects on visible objects (stars). The author considers the possibility that these hypothetical particles can be described as celestial mechanics daemons with certain properties. In particular, it is shown how such daemons could explain some features observed recently for the DAMA experiment at Gran Sasso National Laboratory. It should be noted that this explanation does not contradict any known experimental data. However, there are also serious difficulties associated with the proposed model. These problems will require further study. This work was supported by Russian Science Foundation grant No 14-50-00040. URL: http://arxiv.org/abs/1409.5189 . \nI. INTRODUCTORY REMARK .\nDark Matter (DM) is one of the most important mysteries of modern physics  1  -  4  . Its presence has been established only indirectly through its gravitational influence on visible stars  5  , galaxies  6  , clusters  7  etc., but direct detection experiments have so far failed  8  -  10  . There exist many theoretical models describing DM  11  -  13  ; however, none of them has yet been confirmed experimentally  14  . One of the possibilities is that DM consists of new elementary particles  15  -  17  . If they interact weakly or electromagnetically with ordinary matter then they would escape detection even if they were produced in large quantities  18  . On the other hand, if they interact strongly enough with normal matter, then they may be detectable directly  19  -  21  . A number of experiments searching for DM particles have been carried out  22  -  26  . Recently, the results obtained by the DAMA collaboration  27  attracted considerable attention  28  -  30  . According to these results, the annual modulation effect  31  -  33  caused by the motion of Earth around Sun  34  -  36  leads to an increase in the rate of nuclear recoils registered by detectors during June-October period  37  compared to December-February period. Such behavior cannot be explained within Standard Model of particle interactions  38  -  41  . Several authors suggested different explanations based on",
        "watermark_text": "The essay is devoted to the question of possible existence of dark matter molecules in our Galaxy , which are not observed by other methods than their gravitational impacts on visible objects ( stars ) . The author considers the prospect that these hypothetical particles can be described as celestial mechanics daemons with certain characteristics .In particular , it is demonstrated how such daemons might explain some features detected lately for the DAMA experiment at Gran Sasso National Laboratory . It should be mentioned that this explanation does not contradict any established experimental evidence .However , there are also serious difficulties linked with the suggested model . These difficulties will demand further study .This project was supported by Russian Science Foundation program No 14 - 50 - 00040 . URL : www : / / arxiv . org / abs / 1409 . 5189 .I.INTRODUCTORY REMARK .Dark Matter ( DM ) is one of the most important wonders of modern physics 1 - 4 . Its presence has been known only indirectly through its gravitational impact on visible stars 5 , galaxies 6 , galaxies 7 etc . , but direct detection experiments have so far unsuccessful 8 - 10 .There exist many theoretical theories describing DM 11 - 13 ; however , none of them has already been confirmed experimentally 14 . One of the possibilities is that DM consists of new primary nucleus 15 - 17 .If they interact weakly or electromagnetically with everyday matter then they may survive observation even if they were produced in large quantities 18 . On the other hand , if they interact heavily enough with normal matter , then they may be detectable directly 19 - 21 .A variety of studies looking for DM nuclei have been carried out 22 - 26 . Recently , the results derived by the DAMA collaboration 27 drew substantial scrutiny 28 - 30 .According to these results , the annual modulation effect 31 - 33 induced by the movement of Earth around Sun 34 - 36 results to an increase in the frequency of nuclear recoils registered by detectors during June - October year 37 contrast to December - February time . Such action cannot be described within Standard Model of particle particles 38 - 41 .Several articles suggested different explanations based on",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.780541105074454
    },
    {
        "original_text": "The following is an excerpt from the author s thesis, which can be downloaded at http://arxiv.org/abs/1306.5189. \n \n The formula evaluation problem for propositional logic formulas in conjunctive normal form (CNF) has been studied extensively and many efficient algorithms have been developed. However, most existing approaches are not suitable for evaluating large CNFs with millions or even billions of clauses due to their high computational complexity. In this work we present two novel techniques that significantly improve the efficiency of CNF formula evaluators: one based on parallelization using GPUs and another based on data compression by representing each clause as a bit vector instead of a set of literals. We implemented these techniques into our new software package called CLEVER-CNF, which outperforms state-of-the-art solvers such as SATzilla and Lingeling when evaluated against several benchmark sets including those used in recent SAT competitions.",
        "watermark_text": "The following is an excerpt from the writer s thesis , which can be downloaded at http : / / arxiv . org / abs / 1306 . 5189 . The formula evaluation problem for propositional logic formulas in conjunctive normal form ( CNF ) has been studied thoroughly and many efficient methods have been built .However , most existing techniques are not suitable for evaluating large CNFs with thousands or maybe billions of clauses due to their high computational complexity . In this research we present two novel techniques that significantly improve the performance of CNF formula evaluators : one based on parallelization use GPUs and another based on data encoding by representing each sentence as a bit vector rather of a group of literals .We introduced these techniques into our new software suite named CLEVER - CNF , which outperforms state - of - the - art solvers such as SATzilla and Lingeling when evaluated against several benchmark sets including those utilized in recent SAT tests .",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 4.25
    },
    {
        "original_text": "The composition of cosmic rays is studied by measuring their energy spectrum and mass distribution at Earth. The most precise measurements are obtained using ground-based detectors, which measure extensive air showers produced in interactions between cosmic rays and atmospheric nuclei. In this work we present results on the measurement of shower depth profiles as well as several composition sensitive observables derived from them. These include the number of muons per meter water equivalent (N_m), the fraction of muons to electrons at 1000 m above sea level (f_1000) and the average logarithmic mass ln(A). We compare these results for different zenith angles and energies. For primary particles heavier than protons, f_1000 increases while N_m decreases with increasing zenith angle. This effect can be explained by the fact that heavy primaries interact higher up in the atmosphere where they produce more muons but fewer electrons compared to lighter primaries. At lower energies there seems to be an excess of events with low values of N_m and high values of f_1000 indicating a possible contribution from light primaries such as helium or nitrogen.",
        "watermark_text": "The composition of cosmic rays is studied by monitoring their power spectrum and mass distribution at Earth . The most accurate measurements are achieved using ground - based detectors , which measure significant air showers generated in interactions between cosmic rays and atmospheric atoms .In this research we present results on the determination of shower depth profiles as also as several composition sensitive observables generated from them . These include the quantity of muons per meter water equivalent ( N _ m ) , the fraction of muons to ions at 1000 m above water level ( f _ 1000 ) and the average logarithmic mass ln ( A ) .We contrast these results for different zenith angles and energies . For principal particles heavier than protons , f _ 1000 increases while N _ m falls with rising zenith angle .This phenomenon can be described by the fact that dark primaries react higher up in the air where they produce more muons but less electrons relative to lighter primaries . At lower energies there seems to be an accumulation of events with lowest values of N _ m and low values of f _ 1000 suggesting a possible input from light primaries such as helium or nitrogen .",
        "ori-fast-z-score": -1.2792042981336627,
        "water-fast-z-score": 6.182820774312702
    },
    {
        "original_text": "The spin transistor is an important device for future quantum information processing and communication technologies, but its realization in practice has been challenging due to the lack of suitable materials with large spin-orbit coupling (SOC). Here we propose that graphene can be used as such material by exploiting its unique electronic structure. We show how this leads to a novel type of spin transistor which operates at room temperature without external magnetic fields or applied gate voltages. The proposed device consists of two ferromagnetic contacts connected via a single layer of graphene. By applying a voltage between these contacts one can control the SOC strength in the graphene channel leading to a change in the transmission probability through it. This results in a switching behavior similar to conventional transistors. In addition, our analysis shows that the proposed device exhibits high on/off ratios even when operating under realistic conditions. Finally, we discuss possible experimental realizations of the proposed device. Graphene is a promising candidate for applications in spintronics because of its unique electronic properties  1  . It offers the possibility to realize devices based on pure spin currents  2  , which are not limited by Joule heating effects  3  .\nIn particular, the spin Hall effect  4  allows for efficient generation  5  and detection  6  of spin currents using only electric fields  7, 8  . However, despite many theoretical proposals  9  , there have so far been very few successful attempts to experimentally demonstrate spintronic devices based on graphene  10  . One reason might be the difficulty to find appropriate materials with sufficiently strong spin-orbit interaction  11  . Another problem is related to the fact that most experiments were performed at low temperatures  12  where thermal fluctuations limit the performance of spintronic devices  13  .",
        "watermark_text": "The spin transistor is an important technology for future quantum information processing and communication technologies , but its acceptance in practice has been challenging due to the lack of appropriate substances with large spin - orbit coupling ( SOC ) . Here we propose that graphene can be used as such material by exploiting its unique electronic content .We see how this results to a new kind of spin transistor which operates at room temperature without external magnetic fields or applied gate voltages . The proposed system consists of two ferromagnetic contacts connected via a single thickness of graphene .By applying a voltage between these contacts one can influence the SOC intensity in the graphene channel resulting to a change in the propagation probability through it . This results in a switching environment similar to conventional transistors .In addition , our analysis shows that the suggested system displays high on / off ratios even when operating under realistic conditions . Finally , we study possible experimental realizations of the suggested system .Graphene is a potential candidate for applications in spintronics because of its unique electronic properties 1 . It provides the prospect to realize devices using on true spin currents 2 , which are not limited by Joule cooling effects 3 .In particular , the spin Hall phenomenon 4 enables for efficient production 5 and confirmation 6 of spin currents using only electric forces 7 , 8 . However , despite many theoretical proposals 9 , there have so far been very few successful proposals to experimentally prove spintronic systems based on graphene 10 .One reason could be the difficulty to find adequate devices with adequate strong spinning - orbit interaction 11 . Another difficulty is related to the fact that most studies were performed at low temperatures 12 where thermal fluctuations limit the performance of spintronic systems 13 .",
        "ori-fast-z-score": 1.4316582658130823,
        "water-fast-z-score": 8.397070403831712
    },
    {
        "original_text": "The Relativistic Heavy Ion Collider (RHIC) is an accelerator complex located in Brookhaven National Laboratory, New York. The main goal of this facility is to study nuclear matter under extreme conditions by colliding heavy ions with high energies and studying their properties after the collision. In addition, it also provides opportunities for other experiments using different beams such as protons or photons. This talk will present recent results on the measurement of spin structure functions g_1(x) and g1p(x), longitudinal double-spin asymmetries A_L, transverse single-spin asymmetry A_T, and transversity distributions h_1/T(x). These measurements are performed by the Solenoidal Tracker At RHIC experiment (STAR) which uses two large Time Projection Chambers (TPCs) filled with a gas mixture consisting of 90% helium-4 and 10% isobutane-1.",
        "watermark_text": "The Relativistic Heavy Ion Collider ( RHIC ) is an accelerator complex located in Brookhaven National Laboratory , New York . The main goal of this lab is to study nuclear material under extreme circumstances by colliding heavy ions with high energies and studying their properties after the interaction .In addition , it also provides opportunities for other experiments using separate beams such as protons or photons . This discussion will present recent results on the determination of spin structure parameters h _ 1 ( x ) and g1p ( x ) , longitudinal single - spinning asymmetries A _ L , transverse single - spin asymmetry A _ T , and transversity distributions x _ 1 / T ( x ) .These measurements are performed by the Solenoidal Tracker At RHIC observation ( STAR ) which uses two huge Time Projection Chambers ( TPCs ) filled with a gas mixture consisting of 90 % helium - 4 and 10 % isobutane - 1 .",
        "ori-fast-z-score": 1.386750490563073,
        "water-fast-z-score": 4.9923017660270625
    },
    {
        "original_text": "We present new results on thermal inertia measurements of NEAs based on infrared observations with Spitzer Space Telescope (SST). We use these data to derive an improved estimate of the mean value of the surface thermal inertia, I = 100 ± 50 J m-2 s-1/2 K-1, which is in good agreement with previous estimates obtained by other authors using different methods. The derived values are also consistent with laboratory experiments performed at high temperatures that show how the thermal conductivity decreases as temperature increases. Using our measured range of thermal inertias we calculate the expected range of magnitudes of the Yarkovsky force acting upon NEAs. Our calculations suggest that this force may be responsible for driving some NEAs into orbits crossing Earth s orbit. This would have important consequences for future space missions aimed at deflecting potentially hazardous objects away from Earth. Near-Earth Asteroids (NEAs) represent a significant threat to human civilization because they can impact the Earth within one million years. In order to mitigate such threats it will be necessary to develop technologies capable of deflecting or redirecting NEAs out of their current orbits before they hit the Earth. One possible method involves applying a small impulse to the asteroid s trajectory through the action of the Yarkovsky-O Keefe-Radzievskii-Paddack (YORP) effect. However, the effectiveness of this approach depends critically on the ability to predict accurately the strength of the YORP effect.",
        "watermark_text": "We report new data on cooling inertia studies of NEAs based on infrared observations with Spitzer Space Telescope ( SST ) . We use these information to derive an better estimate of the mean value of the surface heat inertia , I = 100 ± 50 J m - 2 s - 1 / 2 K - 1 , which is in good agreement with previous calculated obtained by other researchers using separate methods .The derived values are also consistent with lab experiments conducted at high temperatures that demonstrate how the thermal conductivity decreases as temperature increases . Using our measured range of thermal inertias we determine the expected range of magnitudes of the Yarkovsky force acting upon NEAs .Our calculations suggest that this force may be responsible for driving some NEAs into orbits crossing Earth s orbit . This might have important implications for future space missions targeted at deflecting possibly hazardous objects away from Earth .Near - Earth Asteroids ( NEAs ) constitute a major danger to human civilization because they can affect the Earth within one million years . In order to mitigate such threats it will be required to develop technologies capable of deflecting or redirecting NEAs out of their current orbits before they struck the Earth .One possible method means using a small impulse to the asteroid s path through the operation of the Yarkovsky - O Keefe - Radzievskii - Paddack ( YORP ) effect . However , the performance of this methodology varies critically on the ability to predict correctly the strength of the YORP effect .",
        "ori-fast-z-score": 1.3471506281091268,
        "water-fast-z-score": 7.319250547113999
    },
    {
        "original_text": "We present the results obtained with a new approach to nuclear fusion, which combines the advantages of both microscopic and macroscopic models. The method is based on an extension of the statistical Hauser-Feshbach theory that includes the effects of nuclear structure in the form of single-particle level densities and transmission coefficients calculated within the framework of the Hartree-Fock-Bogoliubov (HFB) approximation. We apply this formalism to calculate cross sections for neutron-induced reactions on nuclei near the doubly-magic 132Sn nucleus. In particular we study the influence of pairing correlations on the fusion process by comparing our results with those obtained using the standard HFB+BCS approach. Our calculations show that the inclusion of pairing correlations leads to significant changes in the predicted fusion probabilities as well as in the corresponding astrophysical S-factors. These differences are particularly pronounced when considering heavy-ion collisions at low incident energies below the Coulomb barrier. \n \n Keywords: Nuclear fusion, Statistical model",
        "watermark_text": "We present the results derived with a new approach to nuclear fusion , which mixes the advantages of both microscopic and macroscopic models . The method is based on an extension of the empirical Hauser - Feshbach theory that contains the effects of nuclear formation in the form of double - nucleus level densities and transmission coefficients calculated within the framework of the Hartree - Fock - Bogoliubov ( HFB ) algorithm .We use this formalism to estimate cross sections for neutron - caused reactions on clusters near the doubly - magic 132Sn element . In particular we study the impact of coupling correlations on the fusion reaction by comparing our findings with those achieved using the standard HFB + BCS approach .Our calculations show that the introduction of pairing correlations brings to significant variations in the expected fusion probabilities as well as in the associated astrophysical S - variables . These changes are particularly pronounced when using heavy - ion collisions at low collision energies below the Coulomb barrier .Keywords: Nuclear fusion, Statistical model",
        "ori-fast-z-score": -0.819288030372914,
        "water-fast-z-score": 5.579886659703326
    },
    {
        "original_text": "We report on the first simultaneous observations with XMM-Newton and Spitzer Space Telescope (SST) during an active state of the Galactic black hole candidate GRS 1915+105, which is known to show strong variability at all wavelengths. We find that there are two parallel tracks in the evolution of the source s luminosity between the near-infrared (NIR), optical/UV, soft/hard X-ray bands as well as radio wavebands. The NIR-optical track follows closely the hard X-ray light curve but lags behind by about 20 days; while the UV-X-ray track shows no lag compared to the hard X-ray light curve. This suggests that different physical processes may be responsible for these two tracks. In addition, we also found evidence for a hysteresis effect in both tracks. These results provide new insights into the physics of accretion flows onto supermassive black holes.",
        "watermark_text": "We report on the first simultaneous measurements with XMM - Newton and Spitzer Space Telescope ( SST ) during an active state of the Galactic brown hole member GRS 1915 + 105 , which is known to indicate strong variability at all wavelengths . We see that there are two simultaneous tracks in the evolution of the target s luminosity between the near - infrared ( NIR ) , optical / UV , soft / soft X - ray regions as well as radio wavebands .The NIR - optical track follows carefully the hard X - ray light line but lags behind by about 20 days ; while the UV - X - ray band sees no lag compared to the hard X - ray light line . This implies that different physical processes possibly be responsible for these two lines .In addition , we also discovered evidence for a hysteresis effect in both tracks . These data provide fresh insights into the physics of accretion flows onto supermassive black holes .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.75
    },
    {
        "original_text": "The Variable Star One-Shot project is an open-source software package for the analysis of astronomical data.  It was developed by members of the Harvard-Smithsonian Center for Astrophysics (CfA) in collaboration with researchers at other institutions around the world.   The goal of this project is to provide a single tool that can be used to analyze all types of astronomical data sets, including photometric time series, spectroscopic observations, images, etc., using state-of-the-art techniques such as image subtraction, cross correlation, period finding algorithms, spectral line fitting, etc.    This software has been released under the GNU General Public License v3.0 and is available on GitHub at: https://github.com/VariableStar/one-shot-astro .\nOne Shot Astro includes several tools which are useful for analyzing large amounts of astronomical data quickly and efficiently.   These include one-shot-datacleaner , which performs automated quality control checks on raw data files;   one-shot-mosaic , which creates mosaicked images from multiple dithered exposures;  one-shot-astrometry , which determines astrometric solutions for individual frames or entire mosaic images;    one-shot-photometry , which measures fluxes and/or magnitudes for stars across a field-of-view;    one-shot-pipeline , which automates the process of running these various tasks together into a pipeline;    one-shot-wikimapia , which allows users to create custom sky maps based on their own catalogs of objects.     In addition to these core packages, there are also many additional modules available through the one-shot-astro repository which allow users to perform more specialized analyses, such as:    one-shot-catalog , which provides access to a variety of different astrophysical databases via SQL queries;    one-shot-fastphot , which uses machine learning methods to measure stellar",
        "watermark_text": "The Variable Star One - Shot initiative is an free - source software tool for the analysis of astronomical data . It was developed by participants of the Harvard - Smithsonian Center for Astrophysics ( CfA ) in partnership with researchers at other institutions around the world .The goal of this project is to provide a single method that can be used to analyze all types of astronomical data sets , including photometric period series , spectroscopic observations , photographs , etc . , using state - of - the - art methods such as image subtraction , inter correlation , period finding methods , spectral line fitting , etc . This program has been released under the GNU General Public License v3 . 0 and is accessible on GitHub at : https : / / github . com / VariableStar / one - shot - astro .One Shot Astro includes several methods which are helpful for studying huge amounts of astronomical data easily and smoothly . These include one - shot - datacleaner , which performs automated quality control checks on raw data data ; one - shot - mosaic , which forms mosaicked images from multiple dithered exposures ; one - shot - astrometry , which determines astrometric solutions for individual frames or entire mosaic images ; one - shot - photometry , which estimates fluxes and / or magnitudes for planets across a field - of - view ; one - shot - pipeline , which automates the process of running these numerous tasks combined into a pipeline ; one - shot - wikimapia , which allows users to create custom skies mapping based on their own catalogs of items .In addition to these core programs , there are also many extra modules available through the one - shot - astro repository which allow users to conduct more sophisticated analyses , such as : one - shot - collection , which offers connections to a variety of different astrophysical databases via SQL queries ; one - shot - fastphot , which uses computer learning techniques to measure stellar",
        "ori-fast-z-score": 1.2094157958139042,
        "water-fast-z-score": 8.465910570697329
    },
    {
        "original_text": "We present an algorithm for obtaining the spacetime metric from observational data, such as those obtained by the Planck satellite and other experiments. The method is based on the fact that in general relativity (GR) the Einstein field equations are equivalent to the geodesic equation for test particles. We use this equivalence to obtain the metric tensor components directly from the observed trajectories of photons emitted at different redshifts. This approach allows us to reconstruct the full four-dimensional geometry of space-time without assuming any particular model or parametrization. In order to demonstrate our technique we apply it to simulated data generated using the publicly available code CAMB. Our results show that the recovered metric agrees well with the original one used to generate the mock data. Finally, we discuss possible applications of our method to real astrophysical datasets. Cosmology has entered into precision era thanks to recent advances in experimental techniques which have allowed astronomers to measure many important quantities related to the evolution of the universe. Among these measurements there are the temperature anisotropy power spectrum measured by WMAP  1  , PLANCK  2  and SPT  3  satellites; the baryon acoustic oscillations detected through galaxy surveys  4  ; and the luminosity distance-redshift relation inferred from type Ia supernovae  5  . These new data provide unprecedented opportunities to study fundamental physics beyond the Standard Model  6  .\nIn addition to providing accurate measurements of various physical parameters describing the state of the universe today, modern cosmological experiments also allow us to probe its large-scale structure over time  7, 8  . For example, the measurement of the cosmic microwave background radiation provides information about the early stages of the universe s history when the energy density was dominated by dark matter and radiation  9  . On the other hand, the detection of distant galaxies gives access to the late stage of the universe s expansion when dark energy starts dominating  10  .",
        "watermark_text": "We present an algorithm for acquiring the spacetime metric from observational data , such as those achieved by the Planck satellite and other experiments . The method is based on the fact that in general relativity ( GR ) the Einstein field equations are comparable to the geodesic equation for test particles .We use this equivalence to obtain the metric tensor parts directly from the seen trajectories of photons generated at different redshifts . This method enables us to reconstruct the full four - dimensional topology of space - time without assuming any specific theory or parametrization .In order to test our technique we apply it to simulated evidence generated using the publicly accessible code CAMB . Our results show that the recovered metric fits well with the original one used to create the mock data .Finally , we explain possible use of our technique to real astrophysical datasets . Cosmology has entered into precision era thanks to recent developments in experimental methods which have enabled astronomers to measure various crucial variables connected to the evolution of the universe .Among these measurements there are the temperature anisotropy energy spectrum measured by WMAP 1 , PLANCK 2 and SPT 3 spacecraft ; the baryon acoustic oscillations detected through galaxy surveys 4 ; and the luminosity distance - redshift function inferred from type Ia supernovae 5 . These new data provide great opportunities to study theoretical physics beyond the Standard Model 6 .In addition to offering accurate measurements of several physical factors describing the state of the universe today , modern cosmological experiments also enable us to probe its large - scale nature over time 7 , 8 . For instance , the observation of the cosmic microwave background radiation presents knowledge about the early stages of the universe s history when the power concentration was dominated by black material and radiation 9 .On the other hand , the observation of distant galaxies provides access to the late stage of the universe s advance when dark energy starts dominating 10 .",
        "ori-fast-z-score": 0.9669875568304563,
        "water-fast-z-score": 8.273159087695738
    },
    {
        "original_text": "We present the results on the distribution and luminosity function (LF) of active galactic nuclei (AGNs) in clusters of galaxies based on Chandra observations of 16 galaxy clusters at redshifts 0.1 < z < 1.0. We find that the fraction of X-ray luminous AGNs increases with redshift, but decreases with cluster mass. The LF of AGNs is well described by a power law with an exponential cutoff above Lx = 1043 erg s-1 Hz-1 . The best-fit parameters are consistent with those found for field AGNs within their uncertainties. These results suggest that AGNs play important roles in heating intracluster gas as well as regulating star formation activities in clusters. This work was supported by NASA grant NNG06GH50G to J.E.K., and NSF grants AST-0707765 and AST-0708164 to A.M..",
        "watermark_text": "We present the conclusion on the distribution and luminosity function ( LF ) of active galactic nuclei ( AGNs ) in clusters of stars based on Chandra measurements of 16 galaxy galaxies at redshifts 0 . 1 < z < 1 . 0 . We see that the fraction of X - ray luminous AGNs increases with redshift , but decreases with cluster mass .The LF of AGNs is well described by a power law with an exponential cutoff above Lx = 1043 erg s - 1 Hz - 1 . The best - fitting characteristics are compatible with those observed for field AGNs within their uncertainties .These data suggest that AGNs serve active roles in heating intracluster gas as well as affecting star formation interactions in clusters . This research was supported by NASA award NNG06GH50G to J . E . K . , and NSF grants AST - 0707765 and AST - 0708164 to A . M . .",
        "ori-fast-z-score": -0.4375949744936837,
        "water-fast-z-score": 5.10527470242631
    },
    {
        "original_text": "In this work, we propose an efficient direct-voting scheme to provide data fusion assurance (DFA) in wireless sensor networks (WSNs). The proposed DFA scheme is based on the concept that each node can directly vote its local decision with other nodes  decisions and then obtain final global decision by majority voting rule. In order to reduce communication overheads caused by direct voting process, our scheme adopts two novel techniques: 1) only one-hop neighbors are allowed to cast their votes at any time instant; 2) all nodes use different time slots to transmit their votes simultaneously. We also present theoretical analysis to show how much energy consumption will be saved compared with existing schemes. Finally, extensive simulation results demonstrate that our scheme outperforms state-of-the-art approaches in terms of both accuracy and power efficiency. Keywords: Data fusion assurance, Wireless sensor network, Power-efficient direct-voting scheme. This research was supported by National Natural Science Foundation of China under Grant No. 61371040",
        "watermark_text": "In this research , we develop an efficient direct - voted scheme to provide resource fusion assurance ( DFA ) in wireless sensor networks ( WSNs ) . The proposed DFA system is based on the idea that each node can personally voting its local decision with other nodes decisions and then obtain final global ruling by majority voting control .In order to reduce communication overheads caused by direct voting process , our scheme adopts two novel techniques : 1 ) only one - hop neighbors are allowed to cast their votes at any time instant ; 2 ) all nodes use different time slots to transmit their votes concurrently . We additionally offer experimental analysis to see how many electricity usage will be saved compared with existing plans .Finally , extensive modeling results show that our scheme outperforms state - of - the - art methods in terms of both precision and power performance . Keywords : Data fusion assurance , Wireless sensor network , Power - efficient direct - voting system .This research was supported by National Natural Science Foundation of China under Grant No.61371040",
        "ori-fast-z-score": 0.6324555320336759,
        "water-fast-z-score": 5.7655666019705505
    },
    {
        "original_text": "The missing satellites problem (MSP) is one of the most important problems in space science and technology, with applications ranging from satellite navigation to space debris removal.  The MSP asks for all orbits that are stable under gravitational perturbations by known bodies such as planets or asteroids.   In this work we present an algorithm which solves the MSP exactly on any number of dimensions d >= 2 using only O(n log n + m log n) time where n = |S| is the total number of objects in S and m = |E| is the number of edges in E.   Our approach uses a novel combination of techniques including fast matrix multiplication algorithms, data structures based on interval trees, and efficient graph traversal methods. We also show how our results can be used to solve related problems like finding the minimum distance between two given sets of points in R^d. Finally, we demonstrate the practicality of our method through experiments performed on real-world datasets.",
        "watermark_text": "The missing satellites question ( MSP ) is one of the most important problems in space physics and technology , with applications diverse from satellite communication to space wreckage extraction . The MSP asks for all orbits that are stable under gravity perturbations by known objects such as planets or asteroids .In this project we present an algorithm which solves the MSP exactly on any number of dimensions d > = 2 using only O ( n log n + m log n ) time where n = | S | is the total number of items in S and m = | E | is the number of vertices in E . Our solution uses a innovative combination of techniques including rapid matrix multiplication methods , data models using on interval trees , and elegant graph traversal methods . We additionally prove how our findings can be used to solve related problems like finding the minimum height between two given sets of points in R ^ d .Finally , we prove the practicality of our technique through experiments conducted on real - time datasets .",
        "ori-fast-z-score": -1.709408646894569,
        "water-fast-z-score": 4.529108136578382
    },
    {
        "original_text": "We report on the polarization dependent photoluminescence (PL) and Raman scattering spectra of CdSe/CdS core/shell quantum dots in solution at room temperature. The PL spectrum shows that the emission is polarized along the direction perpendicular to the excitation light, which can be explained by the selection rules for dipole transitions between electronic states with different angular momenta. In addition we observe an anisotropic broadening of the Stokes linewidths as well as a splitting into two components when exciting circularly polarized light. These effects are attributed to the presence of exciton fine structure due to spin-orbit coupling. We also find evidence for a strong electron-phonon interaction leading to phonon sidebands in both the Stokes and anti-Stokes parts of the Raman spectrum. Finally, we show how these results can be used to determine the orientation of individual QDs embedded in a polymer matrix. Polarized luminescence measurements have been performed on single QD emitters using confocal microscopy.",
        "watermark_text": "We report on the polarization dependent photoluminescence ( PL ) and Raman absorption spectra of CdSe / CdS core / shell quantum dots in solution at room temperature . The PL spectrum reveals that the emission is polarized along the direction perpendicular to the excitation light , which can be described by the selection rules for dipole changes between electronic states with various angular momenta .In addition we witness an anisotropic broadening of the Stokes linewidths as well as a dividing into two parts when exciting circularly polarized light . These effects are traced to the presence of exciton fine structure owing to spin - orbit bonding .We additionally find proof for a powerful atom - phonon interaction leading to phonon sidebands in both the Stokes and anti - Stokes parts of the Raman spectrum . Finally , we find how these results can be used to predict the orientation of different QDs integrated in a polymer matrix .Polarized luminescence measurements have been performed on single QD emitters using confocal microscopy .",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 5.5
    },
    {
        "original_text": "We report on deep near-infrared observations with VLT/VISIR, which reveal that the X-ray source NGC 300 X-1 is associated with an infrared point-like object (X-ray counterpart) at RA = 03h45m55s.6 DEC = -27d19 59.9  (J2000), located in the central part of the galaxy s spiral arm. The observed fluxes are compatible with those expected for a WR star with T eff ~ 50 kK and log g ~ 5.5-6.0. We also find evidence for extended emission around this source, possibly due to dust heated by the stellar wind or radiation field. Using our VISIR data we estimate the total number of WR stars in NGC 300 as NWR = 1.1 x 10^7 ± 0.3 x 10^7 per M_sun. This value agrees well with previous estimates based on HST/ACS imaging and spectroscopy. \n \n \n \n Keywords: Wolf-Rayet stars",
        "watermark_text": "We report on far near - infrared observations with VLT / VISIR , which show that the X - ray source NGC 300 X - 1 is associated with an infrared point - like body ( X - ray counterpart ) at RA = 03h45m55s . 6 DEC = - 27d19 59 . 9 ( J2000 ) , located in the central half of the universe s spiral arm . The observed fluxes are compatible with those expected for a WR galaxy with T eff ~ 50 kK and log k ~ 5 . 5 - 6 . 0 .We additionally find proof for extended emission around this source , possibly due to dust warmed by the planetary wind or radiation field . Using our VISIR information we estimate the total number of WR galaxies in NGC 300 as NWR = 1 . 1 x 10 ^ 7 ± 0 . 3 x 10 ^ 7 per M _ sun .This value agrees well with previous accounts based on HST / ACS observation and spectroscopy . Keywords : Wolf - Rayet stars",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 4.180039147272101
    },
    {
        "original_text": "We present new models for non-abelian string networks, which are based on the idea that the network is composed by many entangled strings with different velocities and orientations. We show how to construct such velocity-dependent models in terms of Feynman diagrams. In particular we consider two types of diagrams: (i) ladder-like diagrams corresponding to the exchange of gluons between pairs of strings, (ii) cross-ladder like-diagrams describing interactions among three or more strings. The latter type of diagrams can be interpreted as representing junctions where several strings meet at one point. We discuss some properties of these models and compare them with previous results obtained within the framework of Abelian-Higgs model. Finally, we study numerically the evolution of an initial configuration consisting of a single straight string into a complicated tangle of interacting strings using Monte Carlo simulations. This work was supported by the DFG under contract SFB-TR9  Gravitational Physics ",
        "watermark_text": "We introduce novel theories for non - abelian string systems , which are based on the idea that the network is composed by many entangled strings with various velocities and orientations . We see how to build such velocity - dependent models in terms of Feynman diagrams .In particular we define two forms of diagrams : ( i ) ladder - like diagrams corresponding to the transfer of gluons between pairs of sequences , ( ii ) cross - ladder like - diagrams describing relationships among three or more strings . The last sort of diagrams can be interpreted as representing junctions where many strings join at one point .We discuss some properties of these models and link them with previous findings obtained within the framework of Abelian - Higgs system . Finally , we study numerically the evolution of an initial structure consisting of a single straight string into a complicated tangle of interacting strings using Monte Carlo simulations .This project was supported by the DFG under contract SFB - TR9 Gravitational Physics",
        "ori-fast-z-score": 0.9847319278346618,
        "water-fast-z-score": 5.41602560309064
    },
    {
        "original_text": "We present the results of an investigation into the properties and evolution of transients that arise when initial conditions are generated using Lagrangian perturbation theory (LPT) for cosmological N-body simulations. We find that LPT-based initial conditions produce spurious large-scale power at late times, which is not suppressed by increasing the number of particles used to generate these initial conditions. This effect can be mitigated by applying a low-pass filter to the evolved density field prior to generating new initial conditions with higher-order LPT. However, this approach does not completely remove all unwanted effects associated with the use of LPT-generated initial conditions. In addition, we show how the choice of time step used to evolve the initial conditions affects their accuracy. Finally, we demonstrate that it is possible to construct accurate initial conditions for large-volume cosmological simulations without having to resort to expensive high-resolution hydrodynamic simulations. The generation of realistic initial conditions for cosmological N-body",
        "watermark_text": "We present the conclusion of an research into the properties and evolution of transients that arise when initial conditions are produced utilizing Lagrangian perturbation theory ( LPT ) for cosmological N - bodies simulations . We see that LPT - based initial conditions generate spurious large - scale power at late times , which is not suppressed by expanding the quantity of atoms used to create these initial conditions .This phenomenon can be mitigated by using a reduced - pass filter to the evolved density field prior to generating new initial conditions with higher - order LPT . However , this methodology does not totally reduce all unwanted phenomena associated with the using of LPT - produced early conditions .In addition , we show how the selection of time phase employed to evolve the first parameters impacts their accuracy . Finally , we prove that it is easy to build correct preliminary conditions for large - volume cosmological simulations without having to resort to expensive high - resolution hydrodynamic simulations .The generation of realistic initial conditions for cosmological N - body",
        "ori-fast-z-score": -0.2182178902359924,
        "water-fast-z-score": 6.037034299432969
    },
    {
        "original_text": "The work function is one of the most important parameters in semiconductor devices, and its accurate measurement is essential for device design and performance prediction.  In this article we review some recent progresses on the determination of the work functions of various materials by using ultraviolet photoelectron spectroscopy (UPS) with synchrotron radiation as well as other techniques such as scanning tunneling microscopy/spectroscopy (STM/STS), inverse photoemission spectroscopy (IPES), and Kelvin probe force microscopy (KPFM). We also discuss how to determine the absolute values of the work functions of different semiconductors based on UPS measurements. Finally, we present our perspectives on future research directions in this field. The work function is an important parameter in semiconductor devices, which determines their electrical properties including carrier transport behavior and Schottky barrier height  1  . Accurate measurement of the work function is therefore crucial for both fundamental understanding of electronic structure and practical applications  2  .\nIn this article, we will first briefly introduce several experimental methods used to measure the work function of various materials. Then we will show that these results can be compared directly if they are obtained under similar conditions. Afterwards, we will demonstrate how to determine the absolute value of the work function of different semiconductors through ultraviolet photoelectron spectroscopy (UPES) experiments. Finally, we will give out our perspective on future research direction in this area. \nExperimental Methods\n\nUltraviolet Photoelectron Spectroscopy (UPS)\nUltraviolet photoelectron spectroscopy has been widely applied to study the surface electronic structures of many kinds of materials  3  , especially those with low electron binding energies  4  . It measures the kinetic energy distribution of electrons emitted from a sample when it is illuminated by monochromatic light at a specific photon energy hν  5  . By measuring the kinetic energy Ekin of photoelectrons emitted from the Fermi level EF into vacuum  6  , the work function Φ can then be determined according to the following equation: \nwhere e is the elementary charge and m* is the effective mass of the photoelectrons  7, 8  . For example, Figure 1 shows",
        "watermark_text": "The job function is one of the most important characteristics in semiconductor devices , and its precise measurement is crucial for product design and performance measurement . In this article we review some latest progresses on the determination of the work functions of different materials by using ultraviolet photoelectron spectroscopy ( UPS ) with synchrotron rays as well as other techniques such as scanning tunneling microscopy / spectroscopy ( STM / STS ) , inverse photoemission spectroscopy ( IPES ) , and Kelvin probe force microscopy ( KPFM ) .We also discuss how to predict the absolute values of the work functions of different semiconductors based on UPS studies . Finally , we present our perspectives on future research paths in this area .The job function is an important element in semiconductor devices , which determines their electrical properties including carrier carrier behavior and Schottky barrier elevation 1 . Accurate measurement of the work integral is consequently essential for both basic knowing of electronic stability and useful use 2 .In this article , we will first briefly provide several experimental methods used to measure the labor function of different materials . Then we will show that these results can be compared directly if they are derived under corresponding conditions .Afterwards , we will prove how to estimate the absolute value of the work function of different semiconductors through ultraviolet photoelectron spectroscopy ( UPES ) experiments . Finally , we will giving out our viewpoint on future research direction in this area .Experimental Methods Ultraviolet Photoelectron Spectroscopy ( UPS ) Ultraviolet photoelectron spectroscopy has been widely applied to study the surface electronic properties of several kinds of substances 3 , particularly those with lowest ion binding temperatures 4 . It studies the kinetic power distribution of atoms produced from a sample when it is lit by monochromatic light at a certain photon energy hν 5 .By measuring the kinetic power Ekin of photoelectrons induced from the Fermi level EF into vacuum 6 , the work function Φ can then be determined according to the following equation : where e is the elementary charge and m * is the effective mass of the photoelectrons 7 , 8 . For instance , Figure 1 shows",
        "ori-fast-z-score": -1.8717134551736667,
        "water-fast-z-score": 7.568232666571783
    },
    {
        "original_text": "We study the (0, 2) gauged linear sigma model in four dimensions with gauge group SU(N). We consider two different supermanifolds as target spaces for this model: one is the supersphere and another is the supercoset space $SL(3,R)/SO(3)$. The latter has been studied by Witten  1  . In both cases we find that there are no tachyons or ghosts at tree level. However, when we calculate the beta functions to one-loop order, we find that they do not vanish even if we take into account all possible counterterms allowed by symmetries. This indicates that these models suffer from perturbative non-renormalizability. On the other hand, it turns out that the theories have exact global symmetry which can be used to construct an infinite number of conserved currents. These currents lead us to propose new Ward identities which relate correlation functions involving operators of different spin.",
        "watermark_text": "We explore the ( 0 , 2 ) gauged linear sigma system in four dimensions with gauge group SU ( N ) . We consider two different supermanifolds as target spaces for this model : one is the supersphere and another is the supercoset space $ SL ( 3 , R ) / SO ( 3 ) $ .The last has been studied by Witten 1 . In both cases we find that there are no tachyons or ghosts at tree level .However , when we estimate the beta functions to one - loop order , we find that they do not vanish even if we took into consideration all possible counterterms allowed by symmetries . This implies that these models suffer from perturbative non - renormalizability .On the other hand , it turns out that the theories have precise global symmetry which can be used to build an endless number of conserved flows . These currents help us to propose new Ward identities which compare coupling systems concerning functions of different spin .",
        "ori-fast-z-score": 0.13245323570650439,
        "water-fast-z-score": 3.9391929857916765
    },
    {
        "original_text": "We present an experimental investigation into complementarity and quantum nonlocality using a photonic implementation of the Einstein-Bohr photon box thought experiment. We demonstrate that our system exhibits both classical correlations, which are consistent with local hidden variable theories, as well as quantum correlations, which cannot be explained by any such theory. Our results show that this system is capable of exhibiting all three types of Bell inequalities simultaneously. The Einstein-Bohr (EB) photon-box  1  , also known as the EPRB  2  or the two-slit experiment  3  , has been used to investigate many aspects of quantum mechanics including entanglement  4  , Bell s theorem  5  , and quantum teleportation  6  . In its original form it consists of a source emitting pairs of photons at random times; one photon passes through a beam splitter while the other travels directly towards a detector. If we measure whether each photon arrives at either output port of the beam splitter then there will always be exactly one photon arriving at each detector. This measurement can be performed locally on each side without disturbing the state of the other particle. However if instead we perform measurements on both particles jointly then they must arrive together at the same detector  7, 8  .\nIn order for these experiments to exhibit genuine quantum effects, the detectors need to have high efficiency so that the probability of detecting more than one photon per pair is negligible  9  . Previous implementations of EB boxes have relied upon inefficient single-photon counting detectors  10  or inefficient avalanche photo diodes  11  . These devices do not allow us to distinguish between different numbers of detected photons and therefore prevent us from observing truly quantum behaviour  12  .",
        "watermark_text": "We present an experimental inquiry into complementarity and quantum nonlocality utilizing a photonic implementation of the Einstein - Bohr photon box thought experiment . We suggest that our system displays both classical correlations , which are compatible with local hidden variable theories , as well as particle correlations , which cannot be described by any such theory .Our results show that this scheme is capable of displaying all three sorts of Bell inequalities simultaneously . The Einstein - Bohr ( EB ) photon - box 1 , sometimes called as the EPRB 2 or the two - slit experiment 3 , has been used to examine multiple matters of quantum mechanics including entanglement 4 , Bell s theorem 5 , and quantum teleportation 6 .In its initial structure it consists of a source emitting sets of photons at random times ; one photon passes through a beam splitter while the other travels immediately towards a detector . If we measure whether each photon arrives at either output port of the beam splitter then there will always be exactly one photon entering at each sensor .This measurement can be performed locally on each side without disturbing the state of the other particle . However if instead we perform observations on both particles jointly then they must appear together at the same detector 7 , 8 .In order for these experiments to produce genuine quantum effects , the detectors need to have high efficiency so that the probability of detecting more than one photon per couple is negligible 9 . Earlier implementations of EB Box have relied upon inefficient single - photon counting detectors 10 or inefficient avalanche photographic diodes 11 .These machines do not enable us to distinguish between multiple numbers of identified photons and therefore prevent us from observing truly quantum behaviour 12 .",
        "ori-fast-z-score": 0.0949157995752499,
        "water-fast-z-score": 5.651175082804793
    },
    {
        "original_text": "We present an exact solution for the nonequilibrium dynamics of a two-level system coupled to fermionic reservoirs in terms of a Coulomb gas model defined on the Keldysch contour. The partition function is expressed as a functional integral over complex fields, which are related to the density matrix and current operators by means of a Hubbard-Stratonovich transformation. We show that this formulation allows us to obtain explicit expressions for the time evolution of observables such as the occupation probabilities and currents through the junction between the leads and the central region. In particular we find that the relaxation towards equilibrium occurs via damped oscillations whose frequency depends on the bias voltage across the junction. This behavior can be understood within a simple rate equation approach. Finally, we discuss how our results may be generalized to more complicated systems with multiple levels or spin degrees of freedom. \nI. INTRODUCTORY REMARK\nThe study of transport properties of mesoscopic devices has attracted considerable attention during recent years due to their potential applications in quantum information processing  1  . A particularly interesting class of problems concerns the description of charge transfer processes taking place at low temperatures when the electronic states involved in the process are localized near Fermi surfaces  2  .\nIn order to describe these phenomena one usually considers models where electrons tunnel coherently between different regions (leads) connected by some scattering center  3  , e.g., a single level  4  or multi-level  5  impurity. These models have been studied extensively using various techniques ranging from perturbation theory  6  to numerical methods  7, 8  . However, it turns out that many important features cannot be captured by perturbative approaches  9  while standard numerical schemes suffer from severe limitations  10  . For example, they do not allow to treat large systems and/or strong interactions  11  . Therefore, new theoretical tools are needed to understand the physics behind these phenomena  12  .\nRecently, there has been growing interest in developing analytical solutions for non-equilibrium transport problems based on mapping them onto effective statistical mechanics models  13  . One of the most successful examples of this kind is provided by the so-called Caldeira-Leggett model  14  describing the interaction of",
        "watermark_text": "We present an precise solving for the nonequilibrium dynamics of a two - level scheme coupled to fermionic reservoirs in terms of a Coulomb gas model characterized on the Keldysch contour . The partition function is expressed as a functional integral over complex fields , which are related to the density function and current operators by means of a Hubbard - Stratonovich decomposition .We see that this interpretation permits us to obtain precise expressions for the period evolution of observables such as the occupation probabilities and currents through the junction between the leads and the main region . In particular we find that the relaxation towards equilibrium results via damped oscillations whose frequency depends on the bias frequency across the junction .This phenomenon can be understood within a simple rate equation methodology . Finally , we explain how our findings may be generalized to more complicated machines with many levels or spin degrees of freedom .I . INTRODUCTORY REMARK The investigation of transport properties of mesoscopic devices has garnered considerable scrutiny during recent seasons due to their potential applications in quantum information processing 1 .A notably important group of difficulty concerns the description of charge transfer mechanisms taking place at low temperatures when the electronic states participating in the process are localized near Fermi surfaces 2 . In order to explain these phenomena one usually uses models where electrons tunnel coherently between various regions ( leads ) connected by some scattering center 3 , e . g . , a single level 4 or multi - level 5 impurity .These systems have been studied frequently using numerous tools including from perturbation theory 6 to numerical theories 7 , 8 . However , it turns out that several important features cannot be captured by perturbative approaches 9 while standard numerical theories suffer from severe constraints 10 .For instance , they do not enable to treat large systems and / or strong interactions 11 . Therefore , new theoretical tools are needed to comprehend the physics behind these phenomena 12 .Recently , there has been growing interest in building mathematical solutions for non - equilibrium transport issues based on mapping them onto effective statistical mechanics models 13 . One of the most popular instance of this kind is provided by the so - called Caldeira - Leggett model 14 modeling the interaction of",
        "ori-fast-z-score": 1.4045204148136883,
        "water-fast-z-score": 8.648888870168502
    },
    {
        "original_text": "We study the effect of an external magnetic field on the modified Coulomb potential for two particles with opposite charges and masses, which are confined to move along one dimension. We show that this system can be mapped onto a spinless fermion model by using the Jordan-Wigner transformation. The ground state energy is calculated exactly within the framework of Bethe ansatz method. It turns out that there exists a critical value of the magnetic field strength beyond which the ground state becomes degenerate. This result agrees well with previous numerical calculations based on exact diagonalization technique. \n \n In addition we calculate the density-density correlation function as well as the momentum distribution function numerically. These results agree very well with those obtained analytically through the use of Bethe ansatz equations. Finally, we discuss how our results may be generalized to higher dimensions. Introduction:-In recent years considerable attention has been paid to the problem of strongly correlated electrons in low dimensional systems such as quantum wires or carbon nanotubes  1-3 . One of the most interesting phenomena observed experimentally in these systems is the fractional quantized Hall effect (FQHE)  4  . In particular it was shown that when the number of electrons N is odd ,the lowest Landau level(LLL) will contain only one electron per flux quanta  5  .The FQHEs have attracted much interest because they provide us with a unique opportunity to investigate many-body effects in condensed matter physics  6  .\nRecently, several authors  7-10  studied the properties of the modified coulomb interaction between two oppositely charged particles moving in a uniform magnetic field B perpendicularly to their plane of motion. They found that the ground-state energy depends crucially upon whether the total angular momentum J = L + S is zero or not where L is orbital angular momentum and S is spin angular momentum. For example if J=0 then the ground state energy is given by E0=−e2/lB+O(1/N),where lB=eB/mc is the magnetic length  11  .On the other hand if J=1/2 then the ground state energy takes the form E0",
        "watermark_text": "We explore the impact of an external magnetic force on the modified Coulomb potential for two particles with opposite charges and masses , which are confined to move along one dimension . We see that this scheme can be mapped onto a spinless fermion theory by using the Jordan - Wigner transformation .The ground state energy is calculated exactly within the framework of Bethe ansatz technique . It happens out that there exists a critical quantity of the magnetic force power beyond which the ground state remains degenerate .This result agrees well with previous quantitative calculations based on exact diagonalization technique . In addition we estimate the density - density correlation function as well as the velocity distribution relation numerically .These conclusions follow very best with those achieved analytically through the using of Bethe ansatz equations . Finally , we talk how our findings may be generalized to higher dimensions .Introduction : - In recent years considerable focus has been paid to the question of highly correlated electrons in low dimensional complexes such as quantum wires or carbon nanotubes 1 - 3 . One of the most exciting phenomena observed experimentally in these systems is the fractional quantized Hall influence ( FQHE ) 4 .In particular it was shown that when the number of atoms N is odd , the lowest Landau scale ( LLL ) will hold only one particle per flux quanta 5 . The FQHEs have garnered great concern because they give us with a unique opportunity to examine multiple - bodies phenomena in condensed matter theory 6 . Recently , various scientists 7 - 10 studied the properties of the modified coulomb interaction between two oppositely charged particles moving in a uniform magnetic force B perpendicularly to their direction of movement .They found that the ground - state energy relies crucially upon whether the total angular velocity J = L + S is zero or not where L is orbital angular velocity and S is spin angular velocity . For instance if J = 0 then the ground state energy is given by E0 = −e2 / lB + O ( 1 / N ) , where lB = eB / mc is the magnetic speed 11 . On the other hand if J = 1 / 2 then the ground state energy takes the form E0",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.058229640253803
    },
    {
        "original_text": "We study the evolutionarily stable strategy (ESS) and its stability properties for a class of ultimatum games with two-sided incomplete information, where one player is informed about his opponent s type while the other has no such information. We show that there exists a unique ESS which coincides with the Nash equilibrium if the set of types is finite or compactly supported on  0, 1  . If this set contains unbounded elements then we prove that the ESS may be unstable under small perturbations of the payoff functions. In particular, it can be shown that any ESS must satisfy certain conditions related to the distribution function of the types. Finally, we present some numerical examples illustrating our results. The evolutionary game theory studies how strategies evolve over time when players interact repeatedly within large populations. It provides a natural framework for analyzing strategic interactions between self-interested agents who are unable to commit themselves ex-ante but have the opportunity to learn by observing past play. A typical example of such situation arises in bargaining problems where each agent makes offers sequentially without knowing what proposals will be made by their opponents. This problem was first studied by Guth et al. (1982) , who introduced the so-called ultimatum game as a model of bargaining between two selfish individuals. In this game, Player 1 proposes a division of a fixed amount of money M into shares x and y = M −x offered to himself and Player 2 respectively; Player 2 either accepts or rejects the offer. If he accepts, both players receive their respective shares according to the proposal; otherwise they get nothing. Since the seminal work of Guth et al., many authors have investigated various aspects of the ultimatum game including existence and multiplicity of equilibria, efficiency loss due to lack of commitment power etc. (see e.g. Binmore & Shaked, 1993; Ochs & Roth, 1989) . However, all these works assume complete information among the players.",
        "watermark_text": "We research the evolutionarily stable strategy ( ESS ) and its stability properties for a class of ultimatum games with two - sided unfinished data , where one player is informed about his opponent s type while the other has no such information . We see that there exists a unique ESS which coincides with the Nash equilibrium if the set of types is finite or compactly backed on 0 , 1 .If this set contains unbounded members then we prove that the ESS might be unstable under small perturbations of the payoff distributions . In particular , it can be shown that any ESS must satisfy certain conditions related to the distribution function of the types .Finally , we present some numerical examples illustrating our findings . The evolutionary game theory explores how strategies evolve over time when teams engage consistently within large populations .It provides a natural framework for evaluating strategic interactions between self - interested agents who are unable to commit themselves ex - ante but have the option to teach by observing past games . A typical example of such situation occurs in negotiating conflicts where each player makes options sequentially without knowing what bids will be made by their opponents .This problem was first examined by Guth et al . ( 1982 ) , who developed the so - called ultimatum game as a theory of negotiating between two selfish individuals .In this player , Player 1 suggests a division of a specified quantity of money M into shares x and y = M −x offered to himself and Player 2 respectively ; Player 2 either accepts or accepts the offer . If he agrees , both participants receive their respective stocks according to the proposal ; therefore they get nothing .Since the seminal research of Guth et al . , various scientists have analyzed various components of the ultimatum game including existence and multiplicity of equilibria , efficiency losing resulting to lack of commitment power etc . ( saw e . g .Binmore & Shaked , 1993 ; Ochs & Roth , 1989 ) . However , all these works assume complete data among the players .",
        "ori-fast-z-score": 1.5778641172210595,
        "water-fast-z-score": 8.166666666666666
    },
    {
        "original_text": "Entropies are measures of uncertainty, and entropy power inequalities (EPIs) quantify the trade-off between information transmission rates in different communication channels.  In this work we present new proofs for EPIs based on information theory concepts such as mutual information and channel capacity.   We also show that these results can be used to prove Shannon s source coding theorem by applying them to an appropriate binary memoryless symmetric channel model. Finally, we discuss how our approach could potentially lead to improved bounds on the minimum distance of linear block codes over finite fields. Entropies are measures of uncertainty; entropy power inequalities (EPIS) quantify the tradeoff between information transmission rates in various communication channels. In this work we present novel proofs for EPIs using information-theory concepts like mutual information and channel capacity. We also demonstrate that these results may be utilized to verify Shannon s source coding theorem via their application to a suitable binary memoryless-symmetric channel model. Finally,we discuss how our technique might possibly yield better bounds on the minimal distance of linear block codes across finite fields.",
        "watermark_text": "Entropies are measures of uncertainty , and entropy energy inequalities ( EPIs ) quantify the trade - off between information transmission rates in different communication channels . In this research we present new proofs for EPIs based on communication theory ideas such as mutual information and channel capacity .We additionally prove that these results can be used to prove Shannon s source coding theorem by application them to an appropriate binary memoryless symmetric channel structure . Finally , we talk how our approach could potentially lead to greater bounds on the minimum length of linear block sequences over discrete fields .Entropies are measures of uncertainty ; entropy energy inequalities ( EPIS ) quantify the tradeoff between information transmission rates in different communication streams . In this research we present new proofs for EPIs using info - theory ideas like mutual information and channel capacity .We additionally prove that these results may be employed to confirm Shannon s source coding theorem via their application to a suitable binary memoryless - symmetric channel structure . Finally , we explain how our technique may possibly deliver improved bounds on the reduced distance of linear block sequences across bounded fields .",
        "ori-fast-z-score": 0.8,
        "water-fast-z-score": 7.0710678118654755
    },
    {
        "original_text": "We present a real-time renormalization-group approach for calculating the current through an interacting quantum dot coupled to leads at finite bias voltage, temperature, and gate voltage. We show that this method allows us to calculate the current as well as the time-dependent density matrix with high accuracy even when the system is far away from equilibrium. The results are compared to those obtained by numerically solving the Kadanoff-Baym equations within the Keldysh formalism. In particular we find excellent agreement between both methods if one chooses the cutoff scale appropriately. This shows that our method can be used to study strongly correlated systems out of equilibrium without any restriction on the strength of interactions or the coupling to external reservoirs. \nI. INTRODUCTIO N\nThe transport properties of nanoscale devices such as single-molecule transistors  1  , carbon nanotubes  2  , semiconductor nanowires  3  , and quantum dots  4  have attracted considerable interest over recent years due to their potential applications in future electronic circuits  5  . However, it has been shown recently  6  that these devices often operate far away from thermal equilibrium which makes theoretical predictions based on standard approaches like the LandauerBüttiker formula  7, 8  questionable  9  .\nIn order to describe non-equilibrium phenomena correctly, various extensions of the conventional scattering theory  10  were developed  11  -  16  . These theories usually rely on the assumption that the relaxation times associated with different degrees of freedom (e.g., charge carriers) are much longer than typical time-scales characterizing the dynamics of the device  17  . As a consequence they cannot account for situations where strong correlations lead to fast equilibration processes  18  . Moreover, most of them do not allow to treat non-Markovian effects arising e.g.",
        "watermark_text": "We present a real - time renormalization - group method for calculating the charge through an interacting quantum dot connected to leads at finite bias voltage , temperature , and gate current . We see that this method enables us to estimate the current as well as the time - dependent density matrix with high sensitivity especially when the system is far back from equilibrium .The results are compared to those achieved by numerically solving the Kadanoff - Baym equations within the Keldysh formalism . In particular we find excellent agreement between both approaches if one chooses the cutoff scale appropriately .This shows that our technique can be used to study highly correlated systems out of equilibrium without any restriction on the strength of coupling or the interaction to external reservoirs . I . INTRODUCTIO N The transport properties of nanoscale devices such as single - molecule transistors 1 , silicon nanotubes 2 , semiconductor nanowires 3 , and quantum dots 4 have garnered considerable interest over recent years owing to their potential applications in future electronic circuits 5 .However , it has been shown recently 6 that these systems often act close away from temperature equilibrium which makes theoretical estimates based on normal approaches like the LandauerBüttiker equation 7 , 8 questionable 9 . In order to explain non - equilibrium phenomena correctly , various extensions of the usual absorption theory 10 were developed 11 - 16 .These studies typically rely on the assumption that the relaxation minutes associated with various degrees of freedom ( e . g . , charge carriers ) are greatly lengthy than usual time - scales characterizing the dynamics of the device 17 . As a consequence they cannot account for situations where weak correlations lead to rapid equilibration processes 18 .Moreover , most of them do not enable to treat non - Markovian influences arising e . g .",
        "ori-fast-z-score": -1.986254132645683,
        "water-fast-z-score": 5.361109642475096
    },
    {
        "original_text": "We present results on testing different outer boundary conditions in numerical relativity, using two black hole spacetimes as testbeds.  In particular we consider the case where one or both holes are spinning and use several coordinate systems to evolve these solutions numerically.   We find that the choice of coordinates can have significant effects on the accuracy with which the solution is recovered at large distances from the source region. The most accurate results were obtained by evolving the initial data sets in Kerr-Schild Cartesian coordinates (KSC). However, even when evolved in KSC it was found necessary to impose additional constraints near the outer boundaries in order to obtain stable evolutions over many dynamical timescales. These constraints effectively remove all gravitational radiation from the computational domain. Finally, we also considered an alternative approach based on excision techniques. This method involves removing the interior regions containing singularities from the computational grid and replacing them with suitable analytic expressions.",
        "watermark_text": "We report findings on proving different exterior boundary parameters in mathematical relativity , using two black hole spacetimes as testbeds . In particular we study the case where one or both holes are twisting and use multiple coordinate networks to evolve these solutions numerically .We see that the selection of coordinates can have considerable effects on the accuracy with which the solve is recovered at large distances from the origin region . The most accurate conclusions were obtained by expanding the early data sets in Kerr - Schild Cartesian coordinates ( KSC ) .However , even when evolved in KSC it was found necessary to apply additional constraints near the exterior walls in order to obtain stable evolutions over numerous dynamical timescales . These limitations virtually remove all gravity radiation from the theoretical domain .Finally , we also considered an additional method using on excision techniques . This method means eliminating the interior regions containing singularities from the theoretical grid and combining them with suitable analytic expressions .",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 7.509343773089564
    },
    {
        "original_text": "We present new exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors, which are generated by applying nonholonomic frame transforms (NFT) to known vacuum solutions. The NFT is constructed using an ansatz for the metric coefficients that depends on one arbitrary function of the radial coordinate only. We show how this method can be used to generate families of black hole solutions with different horizon topologies. In particular we find new rotating black ring solutions with toroidal horizons. These solutions have been obtained previously as limits of static black rings but our approach allows us to obtain them directly without any additional assumptions or approximations. Finally, we discuss some open problems related to these results. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq \nI. INTRODUCTORY REMARkS\nThe study of exact solutions to the Einstein equations has played a crucial role in understanding many aspects of general relativity. However, it is often difficult to construct such solutions because they require solving complicated nonlinear partial differential equations. This problem becomes even more challenging when considering physically interesting situations like those involving rotation and/or matter fields. Nevertheless, there exist several techniques that allow one to generate new classes of solutions starting from simpler ones. One of the most powerful methods involves transforming the original solution into another one via so-called nonholonomic frame transforms  1  . Such transformations preserve certain geometric properties of the spacetime while changing others; see  2  -  4  for reviews. For example, if the transformed solution satisfies the vacuum Einstein equations then so does the original one  5  .\nIn this work we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to generate new exact solutions describing stationary axisymmetric spacetimes: i.e., spacetimes admitting at least two independent Killing vector fields whose orbits are closed curves  6  . Stationary axisymmetric spacetimes play an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars, planets, and black holes  7, 8 ",
        "watermark_text": "We introduce novel exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors , which are produced by using nonholonomic frame transforms ( NFT ) to known vacuum solutions . The NFT is built using an ansatz for the metric coefficients that relies on one arbitrary function of the radial coordinate only .We see how this algorithm can be used to create families of grey hole problems with various horizon topologies . In particular we find unique spinning black ring solutions with toroidal horizons .These solutions have been achieved formerly as limits of static black rings but our approach allows us to obtain them directly without any additional constraints or approximations . Finally , we explain some open problems related to these results .PACS codes : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq I . INTRODUCTORY REMARkS The investigation of precise solutions to the Einstein equations has held a crucial role in understanding several parts of general relativity .However , it is often challenging to build such problems because they demand solving complicated nonlinear partial differential equations . This problem remains especially more challenging when exploring physically exciting situations like those concerning rotation and / or matter forces .Nevertheless , there remain many procedures that enable one to create fresh categories of solutions starting from simpler ones . One of the most popular methods means mapping the previous solve into another one via so - called nonholonomic frame transforms 1 .Such transformations maintain certain geometric properties of the spacetime while altering others ; look 2 - 4 for reviews . For instance , if the transformed solution satisfies the vacuum Einstein equations then so does the previous one 5 .In this research we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to create novel exact solutions governing stationary axisymmetric spacetimes : i . e . , spacetimes admitting at least two independent Killing matrix fields whose orbits are closed curves 6 . Stationary axisymmetric spacetimes serve an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars , planets , and dark holes 7 , 8",
        "ori-fast-z-score": -1.3805369799252667,
        "water-fast-z-score": 7.777427086962838
    },
    {
        "original_text": "The concept of dynamical 3-space is introduced in this review article as an alternative to the standard space-time picture of relativistic physics. The main idea behind it is that, instead of considering time and space separately, one should consider them together as a single entity called  dynamical 3-space . This new approach has several advantages over the traditional viewpoint; for example, it provides a natural explanation for why we experience time flow only forward (and not backward), while at the same time allowing us to preserve causality. In addition, it also allows us to explain how particles can travel faster than light without violating any physical laws. Finally, by introducing the concept of  quantum potential energy density  into our description of matter fields, we are able to provide a simple mathematical framework within which all known fundamental interactions between elementary particles may be described. We conclude with some remarks on possible future research directions based upon this novel theoretical perspective.",
        "watermark_text": "The concept of dynamical 3 - space is proposed in this review article as an alternative to the standard space - time view of relativistic physics . The main idea behind it is that , rather of considering time and space simultaneously , one should consider them combined as a common organization called dynamical 3 - space .This new approach has numerous benefits over the usual interpretation ; for example , it gives a natural explanation for why we experience time flow only ahead ( and not backward ) , while at the same time allowing us to restore causality . In addition , it also enables us to explain how atoms can travel quicker than light without violating any physical rules .Finally , by bringing the notion of quantum potential energy density into our description of matter fields , we are able to provide a simple mathematical framework within which all known fundamental interactions between elementary particles may be described . We continue with some remarks on potential future research paths based upon this new theoretical perspective .",
        "ori-fast-z-score": 1.3093073414159544,
        "water-fast-z-score": 5.965587590013045
    },
    {
        "original_text": "We present the results of laboratory measurements on composite interstellar grains, which are composed of amorphous silicate and carbonaceous materials with various compositions. The samples were irradiated by energetic protons in order to simulate cosmic ray bombardment under conditions similar to those found in dense clouds where dust is formed. We have measured infrared (IR) emission spectra before and after proton irradiation at energies ranging from 1 MeV/nucleon up to 100 MeV/nucleon for different sample temperatures between 10 K and 300 K. In addition we performed IR transmission spectroscopy experiments using synchrotron radiation as well as electron energy loss spectroscopy (EELS). Our experimental data show that the composition of the grain material has an important influence on its response towards proton irradiation. For example, the intensity ratio of the 3.4 micron feature over the 11 micron feature increases significantly when the amount of aromatic hydrocarbons relative to silicates decreases.",
        "watermark_text": "We present the results of research studies on composite interstellar fragments , which are composed of amorphous silicate and carbonaceous materials with various compositions . The samples were irradiated by energetic protons in order to simulate cosmic ray bombardment under environments similar to those observed in dense clouds where dust is formed .We have recorded laser ( IR ) emission spectra before and after proton irradiation at energies ranging from 1 MeV / nucleon up to 100 MeV / nucleon for different specimen temperatures between 10 K and 300 K . In addition we performed IR transmission spectroscopy observations use synchrotron rays as well as electron energy loss spectroscopy ( EELS ) . Our research data reveal that the composition of the grain matter has an important affect on its reactions towards proton irradiation .For instance , the intensity ratio of the 3 . 4 micron feature over the 11 micron feature grows significantly when the proportion of aromatic hydrocarbons compared to silicates drops .",
        "ori-fast-z-score": -1.8073922282301278,
        "water-fast-z-score": 4.131182235954578
    },
    {
        "original_text": "We present the first fully self-consistent, atomistic quantum transport calculations for ballistic graphene nanoribbons (GNRs) with realistic band structure and electrostatic potential profiles using nonequilibrium Green s function formalism in combination with density functional theory (DFT). We show that the GNRs  electronic properties are strongly dependent on their widths as well as edge structures. The calculated current-voltage characteristics reveal several interesting features such as negative differential resistance at low bias voltages due to resonant tunneling through localized states near the Fermi level. In addition, we find that the presence of hydrogen passivation layers can significantly enhance the device performance by suppressing the backscattering effect caused by defects or impurities along the edges. \n \n Keywords: Ballistic transport, Graphene nanoribbon, Nonequilibrium Green s functions, Density functional theory, Quantum transport calculation. 1 Introduction \n \n Graphene is an emerging material which has attracted considerable attention recently because it exhibits unique physical properties  1  . It consists of carbon atoms arranged into a honeycomb lattice where each carbon atom forms covalent bonds with three neighboring carbons  2  . Due to its two-dimensional nature, graphene shows high carrier mobility  3  , thermal conductivity  4  , mechanical strength  5  , optical transparency  6  , and flexibility  7  . These remarkable properties make graphene promising candidates for future nanoelectronic devices  8  .\n \nGraphene nanoribbons (G-NR), i.e., strips of graphene with finite width  9  , have been proposed as building blocks for various applications including transistors  10  , interconnects  11  , photodetectors  12  , solar cells  13  , sensors  14  , etc.. Compared to conventional silicon-based electronics  15  , GNRs offer many advantages  16  : they exhibit higher electron mobilities  17  ; they allow better control over the charge carriers  18  ; they provide more design freedom  19  ; and they enable new functionality  20  . However, there still exist some challenges associated with practical realization of GNRs  21  . For example, the fabrication process requires precise control of ribbon width  22  and edge roughness  23  . Moreover, the electrical properties of GNRs depend sensitively",
        "watermark_text": "We present the first fully self - stable , atomistic quantum travel calculations for ballistic graphene nanoribbons ( GNRs ) with realistic band structure and electrostatic potential configurations using nonequilibrium Green s function formalism in combination with density functional theory ( DFT ) . We suggest that the GNRs magnetic properties are strongly dependent on their widths as well as edge properties .The measured power - voltage parameters reveal numerous interesting features such as negative integral resistance at low bias voltages due to resonant tunneling through confined states near the Fermi level . In addition , we find that the presence of hydrogen passivation layers can significantly boost the device performance by suppressing the backscattering effect caused by defects or impurities along the edges .Keywords : Ballistic diffusion , Graphene nanoribbon , Nonequilibrium Green s functions , Density functional theory , Quantum transport calculation . 1 Introduction Graphene is an developing material which has garnered considerable scrutiny lately because it displays unusual physical properties 1 .It consists of carbon atoms arranged into a honeycomb structure where each carbon molecule forms covalent bonds with three adjacent carbons 2 . Due to its two - dimensional existence , graphene shows high carrier density 3 , thermal conductivity 4 , thermal strength 5 , optical transparency 6 , and flexibility 7 .These exceptional properties make graphene promising candidates for future nanoelectronic technologies 8 . Graphene nanoribbons ( G - NR ) , i . e . , sheets of graphene with finite width 9 , have been proposed as building blocks for various uses including transistors 10 , interconnects 11 , photodetectors 12 , sun cells 13 , cameras 14 , etc . .Compared to conventional silicon - based equipment 15 , GNRs offer several advantages 16 : they represent greater electron mobilities 17 ; they allow easier control over the charge carriers 18 ; they give more configuration autonomy 19 ; and they enable new capabilities 20 . However , there still emerge some challenges associated with practical development of GNRs 21 .For instance , the fabrication process requires careful management of ribbon diameter 22 and edge roughness 23 . Moreover , the electrical properties of GNRs depend sensitively",
        "ori-fast-z-score": -0.32025630761017426,
        "water-fast-z-score": 8.327056459580765
    },
    {
        "original_text": "We study the evolution of age structure and life history traits by using an age-structured population model with stochastic demographic events, where individuals can reproduce at any age. We show that selection against demographic stochasticity leads to increased reproductive effort early in life (i.e., earlier reproduction) and decreased mortality rates later in life. This is because higher reproductive efforts increase offspring numbers but also lead to more deaths due to competition for resources among siblings. In contrast, lower mortality rates decrease sibling competition and thus reduce the number of deaths caused by this source of demographic stochasticity. Our results are robust across different levels of environmental stochasticity and initial conditions. The evolutionary consequences of demographic stochasticity have been studied extensively in recent years  1–3  . However, most studies on this topic focus on populations without age structure or assume that all individuals reproduce at the same age  4–6  , which may not be realistic  7–9  .\nHere we use an age-structured model with stochastic demographic events  10, 11  to investigate how selection acts on life-history traits when there is variation in individual ages at first reproduction  12  . Specifically, we consider a scenario where individuals can reproduce at various ages and compete for limited resources within their family groups  13  . We find that selection against demographic stochasticities increases reproductive effort early in life and decreases mortality rates late in life. These findings are consistent with previous theoretical work showing that selection favors reduced variance in offspring number  14–18  .",
        "watermark_text": "We research the evolution of age structure and life history characteristics by using an age - organized community model with stochastic demographic conditions , where adults can mature at any age . We suggest that selection against demographic stochasticity causes to greater sexual attempt early in life ( i . e . , earlier reproduction ) and diminished mortality rates later in life .This is because higher reproductive attempts increase offspring numbers but also lead to more killed due to competition for resources among brothers . In comparison , lower deaths levels decrease brother conflict and therefore decrease the quantity of fatalities caused by this source of demographic stochasticity .Our results are robust across different levels of environmental stochasticity and original conditions . The evolutionary impacts of demographic stochasticity have been studied significantly in recent periods 1 – 3 .However , most studies on this theme focus on groups without age structure or assume that all individuals mature at the same age 4 – 6 , which may not be realistic 7 – 9 . Here we using an age - organized model with stochastic demographic patterns 10 , 11 to examine how selection acts on life - history characteristics when there is variation in individual ages at first reproduction 12 .Specifically , we investigate a situation where adults can mature at several ages and contest for limited supplies within their family groups 13 . We see that selection against demographic stochasticities raises reproductive effort early in life and decreases mortality rates soon in life .These conclusions are compatible with previous conceptual research indicating that selection favors reduced variance in offspring year 14 – 18 .",
        "ori-fast-z-score": -1.2456821978060995,
        "water-fast-z-score": 8.055411545812778
    },
    {
        "original_text": "We study evolutionary dynamics in an ensemble of genotypes, each with its own fitness value and connected to other genotypes by mutations. We show that for large ensembles there is always one genotype which has more connections than any other genotype. This genotype dominates all others at equilibrium. The dominance of this genotype depends only on the distribution of mutational distances between pairs of genotypes. For example, if we consider two different distributions of mutational distances (the exponential and power law), then the same genotype will dominate both cases. However, the time it takes to reach equilibrium can be very different depending on how many paths lead away from the dominant genotype. In particular, when the number of paths leading away from the dominant genotype increases exponentially as a function of distance, the system reaches equilibrium much faster compared to the case where the number of paths grows slower or even remains constant. \n \n We also find that the average population size of the dominant genotype decreases slowly over time until reaching equilibrium.",
        "watermark_text": "We see adaptive dynamics in an ensemble of genotypes , each with its own health quality and related to other genotypes by genes . We see that for large ensembles there is usually one genotype which has more networks than any other genotype .This genotype dominates all others at equilibrium . The dominance of this genotype determines only on the spread of mutational lengths between pairs of genotypes .For instance , if we treat two different distributions of mutational distances ( the exponential and power law ) , then the same genotype will dominate both cases . However , the period it takes to reach equilibrium can be very different depending on how many routes go away from the dominant genotype .In particular , when the quantity of paths leading away from the dominant genotype rises exponentially as a function of distance , the system reaches equilibrium somewhat quickly contrast to the case where the quantity of paths grows faster or even keeps constant . We additionally find that the average population size of the dominant genotype decreases slowly over time until achieving equilibrium .",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 6.812733176437583
    },
    {
        "original_text": "We present an open-source code, called XSCORT (X-ray Spectral Code for Reprocessed Torus), which computes the reprocessing of radiation by optically-thick matter in the form of a torus and its associated wind. The code is written as a set of IDL routines that can be easily modified to study different geometries or physical conditions. We describe how we implemented our model using Monte Carlo techniques and discuss some tests performed with simulated data. Finally, we show examples of applications of this new tool to two well-studied objects, NGC 4151 and Mrk 509. \nThe main goal of XSCORT is to provide a flexible framework where one can explore the effects of various parameters such as: geometry, density distribution, chemical composition, ionization state, etc., on the observed spectral properties of active galactic nuclei (AGN). This will allow us to better understand their nature and evolution. \n \n In particular, we are interested in studying the effect of the presence of an outflowing component on the shape of the reflection hump produced by the innermost regions of the accretion disc around supermassive black holes. These winds may play an important role in shaping the broad-band continuum emission of these sources through absorption and/or scattering processes. They also affect the amount of material available to produce the reflected emission at larger distances from the central source.",
        "watermark_text": "We produce an open - source code , known XSCORT ( X - ray Spectral Code for Reprocessed Torus ) , which computes the reprocessing of radiation by optically - heavy material in the form of a torus and its attendant wind . The language is read as a group of IDL routines that can be easily modified to study various geometries or material conditions .We discuss how we implemented our model utilizing Monte Carlo methods and explain some experiments conducted with simulated evidence . Finally , we give instance of applications of this new method to two better - examined objects , NGC 4151 and Mrk 509 .The main goal of XSCORT is to provide a broad platform where one can examine the effects of several variables such as : topography , density flow , chemical composition , ionization state , etc . , on the known spectral properties of active galactic nuclei ( AGN ) . This will provide us to easier understand their nature and evolution .In particular , we are concerned in examining the impact of the presence of an outflowing component on the form of the reflection hump produced by the innermost sectors of the accretion disc around supermassive black holes . These winds may play an important role in shaping the broad - band continuum emission of these sources through absorption and / or scattering mechanisms .They also affect the quantity of material provided to produce the reflected emission at larger distances from the main source .",
        "ori-fast-z-score": -1.7650452162436565,
        "water-fast-z-score": 6.601706163700764
    },
    {
        "original_text": "We report the observation of electron-hole puddles in graphene using scanning single-electron transistors (SETs). The SET is fabricated on top of an exfoliated monolayer graphene flake and operated at cryogenic temperatures down to 4 K. We observe that the conductance through the SET depends strongly on its position with respect to the underlying graphene sheet, which we attribute to local variations in charge carrier density induced by charged impurities trapped between the substrate and the graphene layer. This effect can be suppressed by applying a gate voltage Vg = -40 V across the graphene sample. Our results demonstrate that the use of SETs as probes for studying electronic properties of two-dimensional materials such as graphene has great potential. In recent years there have been significant advances in the fabrication of devices based on carbon nanotubes  1  , silicon nanowires  2  or semiconductor quantum dots  3  . These nanostructures are used as active elements in various types of sensors  4  , optoelectronic  5  and photovoltaic  6  applications. However, these structures suffer from several drawbacks including poor reproducibility due to their small size and low yield during growth processes  7, 8  .\nIn contrast, graphene  9  offers many advantages over other two dimensional materials  10  : it is mechanically flexible  11  , chemically stable  12  , biocompatible  13  and electrically conductive  14  . Moreover, it can be produced in large quantities via chemical vapor deposition  15  or mechanical exfoliation  16  techniques  17  . Recently, graphene-based field-effect transistors  18  were demonstrated  19, 20  opening up new avenues towards high-performance electronics  21  . Despite all these attractive features, however, one major challenge remains in achieving high-quality electrical contacts to graphene  22  .",
        "watermark_text": "We report the observation of electron - hole puddles in graphene using scanning single - ion transistors ( SETs ) . The SET is manufactured on top of an exfoliated monolayer graphene flake and operated at cryogenic temperatures down to 4 K . We establish that the conductance through the SET depends strongly on its position with regard to the underlying graphene cover , which we attribute to local differences in charge carrier density resulting by charged impurities stored between the substrate and the graphene layer .This phenomenon can be suppressed by using a gate pressure Vg = - 40 V across the graphene sample . Our results show that the using of SETs as probes for studying electronic properties of two - dimensional surfaces such as graphene has tremendous promise .In recent years there have been significant advances in the fabrication of applications based on carbon nanotubes 1 , silicon nanowires 2 or semiconductor quantum dots 3 . These nanostructures are applied as active elements in different kinds of sensors 4 , optoelectronic 5 and photovoltaic 6 applications .However , these structures face from several drawbacks including low reproducibility due to their tiny size and low yield during growth processes 7 , 8 . In comparison , graphene 9 offers several advantages over other two dimensional ceramics 10 : it is mechanically flexible 11 , chemically neutral 12 , biocompatible 13 and electrically conductive 14 .Moreover , it can be made in large quantities via chemical vapor precipitation 15 or mechanical exfoliation 16 techniques 17 . Recently , graphene - based field - effect transistors 18 were shown 19 , 20 closing up new avenues towards high - performance computers 21 .Despite all these interesting features , however , one major challenge lies in obtaining high - grade electrical contacts to graphene 22 .",
        "ori-fast-z-score": -1.034792955221957,
        "water-fast-z-score": 5.9941491941228415
    },
    {
        "original_text": "We study the scattering amplitudes for gluons and gravitons at strong coupling using classical string solutions in Anti-de Sitter space (AdS). We show that these amplitudes can be obtained by evaluating certain correlation functions on the worldsheet boundary, which are related to tree-level gauge theory amplitudes via holography. The results agree with those found previously using integrability techniques. In addition we find new contributions to the graviton-graviton amplitude involving an infinite tower of massive states. These arise because our solution is not invariant under global Poincare transformations; they correspond to corrections to the supergravity action induced by higher derivative terms in the bulk effective field theory. \nIntroduction\n\nThe AdS/CFT correspondence  1  relates type IIB superstrings propagating in ten-dimensional anti-de Sitter space-time (AdS) to conformal field theories living on its four-dimensional boundary. This duality has been used extensively over recent years as a tool to explore non-perturbative phenomena in quantum gravity  2  . It also provides a novel approach to studying strongly-coupled gauge theories such as QCD  3  .\nIn this talk we will consider the simplest example of the AdS/CFT correspondence -the maximally supersymmetric Yang-Mills (N=4 SYM) theory  4  , whose dual description involves type IIA strings moving in AdS 5 × S 5  5  . At weak  t Hooft coupling λ = g 2 Y M N ≪ 1, where g Y M denotes the Yang-Mills coupling constant, perturbative calculations have shown that the two descriptions match exactly  6  . However, it remains unclear how to calculate quantities like scattering amplitudes directly within the gauge theory at large values of λ  7, 8  . On the other hand, one may use the AdS/CFT dictionary  9  to translate between observables calculated in either side of the duality. For instance, the expectation value of Wilson loops in the gauge theory corresponds to the area of minimal surfaces embedded into AdS  10  ; while n-point correlators of local operators in the gauge theory are given by functional integrals over n-punctured Riemann surfaces  11  .",
        "watermark_text": "We research the scattering amplitudes for gluons and gravitons at strong coupling using traditional string solutions in Anti - de Sitter space ( AdS ) . We see that these amplitudes can be obtained by evaluating several coupling functions on the worldsheet border , which are related to tree - level gauge theory amplitudes via holography .The results agree with those shown previously used integrability methods . In addition we find new contributions to the graviton - graviton amplitude involving an endless tower of large states .These occur because our solution is not invariant under universal Poincare shifts ; they relate to corrections to the supergravity act caused by higher derivative conditions in the bulk effective field theory . Introduction The AdS / CFT relationship 1 relates class IIB superstrings propagating in ten - dimensional anti - de Sitter space - time ( AdS ) to conformal field schemes residing on its four - dimensional boundary .This duality has been used heavily over recent years as a platform to examine anti - perturbative processes in particle gravity 2 . It additionally offers a new approach to investigating strongly - coupled gauge fields such as QCD 3 .In this talk we will take the simplest example of the AdS / CFT relationship - the maximally supersymmetric Yang - Mills ( N = 4 SYM ) theory 4 , whose dual description requires type IIA strings moving in AdS 5 × S 5 5 . At weak t Hooft coupling λ = g 2 Y M N [UNK] 1 , where h Y M denotes the Yang - Mills coupling constant , perturbative calculations have shown that the two explanations match exactly 6 .However , it remains unclear how to estimate quantities like absorption amplitudes directly within the gauge theory at large values of λ 7 , 8 . On the other hand , one may use the AdS / CFT dictionary 9 to translate between observables calculated in either face of the duality .For instance , the expectation value of Wilson loops in the gauge theory corresponds to the area of minimal surfaces embedded into AdS 10 ; while n - point correlators of local operators in the gauge theory are given by functional integrals over n - punctured Riemann spheres 11 .",
        "ori-fast-z-score": -1.643989873053573,
        "water-fast-z-score": 5.488853867477571
    },
    {
        "original_text": "The increasing amount and complexity of oceanographic data requires new approaches to the analysis, visualization and interpretation of these datasets. In this work we present an interactive visual analytics system that allows users to explore large volumes of 3D oceanographic data in order to detect patterns and anomalies. The main goal is to provide scientists with powerful tools to analyze their data without having to be experts on computer graphics or visualization techniques. We use state-of-the-art volume rendering algorithms combined with advanced interaction techniques such as brushing, linking and querying. Our approach has been tested by using real-world oceanographic data sets collected during several research cruises around Europe. This article presents our results and discusses future directions. Oceanographers are increasingly collecting massive amounts of data about the oceans  physical properties (e.g., temperature, salinity) and biological processes (e.g., plankton blooms). These data can be used to study phenomena like global warming, pollution spreading, marine life migration etc.. However, analyzing and interpreting these huge volumes of data remains challenging due to its high dimensionality and complex relationships between variables. Interactive visual analytics systems have shown great potential in helping scientists discover hidden patterns and anomalies within their data  1  . They allow researchers to interactively explore their data through different views while simultaneously performing queries and applying filters  2  .\nIn this work we present Diagnostic Tools for Unstructured Data (DUT), a novel visual analytics tool designed specifically for exploring large volumes of 3D oceanic data. DUT provides scientists with powerful tools to perform exploratory analyses of their data without requiring them to be experts on computer science or visualization techniques  3  , thus allowing them to focus more on the actual content of their data rather than how it should be presented  4  .",
        "watermark_text": "The increasing quantity and complexity of oceanographic data requires innovative approaches to the analysis , visualization and understanding of these datasets . In this project we present an interactive visual analytics system that enables users to examine large quantities of 3D oceanographic data in order to identify trends and anomalies .The main goal is to provide researchers with powerful tools to analyze their information without having to be specialists on digital graphics or visualization techniques . We use state - of - the - art book graphics methods coupled with sophisticated interaction tools such as brushing , linking and querying .Our concept has been tested by using real - time oceanographic observations sets generated during many research cruises around Europe . This page presents our findings and explains future directions .Oceanographers are increasingly collecting huge amounts of statistics about the oceans physical properties ( e . g . , temperature , salinity ) and biological phenomena ( e . g . , plankton blooms ) . These data can be used to study phenomena like global cooling , contamination spreading , sea life growth etc . .However , reviewing and interpreting these enormous volumes of evidence remains challenging due to its high dimensionality and difficult connections between parameters . Interactive graphical analytics systems have shown great potential in assisting scientists find hidden patterns and anomalies within their information 1 .They allow scientists to interactively examine their information through different views while simultaneously performing queries and using filters 2 . In this project we present Diagnostic Tools for Unstructured Data ( DUT ) , a new graphical analytics method designed specifically for studying huge volumes of 3D oceanic data .DUT offers scientists with powerful tools to conduct exploratory analyses of their information without mandate them to be specialists on computer science or visualization techniques 3 , thus allowing them to focus more on the actual text of their information rather than how it should be displayed 4 .",
        "ori-fast-z-score": -0.3223291856101521,
        "water-fast-z-score": 9.895506688976516
    },
    {
        "original_text": "We present new observations in the mid-infrared (MIR) and near-infrared (NIR), as well as archival data, to study the physical conditions of the gas surrounding the young stellar object Re 4 IRS located at the center of the reflection nebula NGC 1333 IRAS 2. We find that the MIR spectrum is dominated by strong ro-vibrational lines of H$_2$O and CO, while the NIR spectrum shows prominent Brackett-γ line emission with an equivalent width of ~1 Å. The observed fluxes are consistent with those expected for a T Tauri star surrounded by a dense circumstellar disk heated by accretion shocks. In addition, we detect several forbidden transitions of  Fe II  ,  S III  ,  N II  , and  C II  . These results suggest that the central source has recently undergone a burst of enhanced mass loss activity which may be related to its recent transition into the main sequence phase.",
        "watermark_text": "We use new images in the mid - infrared ( MIR ) and near - infrared ( NIR ) , as well as archival data , to study the physical conditions of the gas surrounding the young stellar object Re 4 IRS located at the center of the reflection nebula NGC 1333 IRAS 2 . We see that the MIR spectrum is dominated by weak ro - vibrational lines of H $ _ 2 $ O and CO , while the NIR spectrum displays rare Brackett - γ line emission with an comparable width of ~ 1 Å .The observed fluxes are compatible with those expected for a T Tauri star supported by a dense circumstellar disk heated by accretion shocks . In addition , we find several forbidden transitions of Fe II , S III , N II , and C II .These data suggest that the main source has recently undergone a burst of enhanced mass loss activity which may be connected to its recent shift into the main series process .",
        "ori-fast-z-score": 0.75,
        "water-fast-z-score": 4.913538149119954
    },
    {
        "original_text": "We present an efficient numerical scheme to detect the existence of periodic orbits in chaotically behaving dynamical systems, such as chaotic maps or chaotic flows. The proposed algorithm is based on the concept of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor. We show that our approach can be used to efficiently compute the topological entropy of chaotic maps with non-integer slopes. Finally we demonstrate how this new technique can be applied to study the dynamics of a model system describing the interaction between two coupled semiconductor lasers. Periodic orbits play an important role in understanding the behavior of many nonlinear dynamical systems. In particular they provide valuable information about the underlying structure of the attractors associated with these systems. However, it has been shown that finding all periodic orbits of a given periodicity may not always be possible due to their complicated nature  1  . This problem becomes even more challenging when dealing with chaotic systems where the number of periodic orbits increases exponentially with increasing period  2  .\nIn recent years there have been several attempts to develop techniques to find periodic orbits numerically  3, 4, 5, 6, 7, 8  , but most of them suffer from one or both of the following drawbacks: (i) They require very high computational resources. (ii) They do not guarantee convergence towards the desired orbit. Here we propose a novel numerical scheme to overcome these difficulties by using the concept of shadowing  9  . Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor. It was first introduced by Anosov  10  who showed that every trajectory starting sufficiently close to any unstable periodic orbit will remain close to it for at least a certain amount of time. Since then various authors  11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44",
        "watermark_text": "We present an efficient numerical system to identify the existence of periodic orbits in chaotically behaving dynamical systems , such as chaotic maps or turbulent flows . The proposed algorithm is based on the idea of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor .We see that our approach can be used to easily compute the topological entropy of turbulent maps with non - integer peaks . Finally we prove how this new technique can be applied to study the dynamics of a prototype system describing the interaction between two coupled semiconductor lasers .Periodic orbits take an important role in understanding the dynamics of several nonlinear dynamical systems . In particular they give valuable info about the fundamental structure of the attractors associated with these systems .However , it has been shown that finding all periodic orbits of a given periodicity might not always be possible due to their complicated nature 1 . This problem arises even more challenging when dealing with turbulent systems where the number of periodic orbits changes exponentially with expanding period 2 .In past decades there have been numerous attempts to develop techniques to find periodic orbits numerically 3 , 4 , 5 , 6 , 7 , 8 , but most of them suffer from one or both of the following drawbacks : ( i ) They require very high computational resources . ( ii ) They do not guarantee convergence towards the desired orbit .Here we develop a new numerical system to overcome these problems by using the idea of shadowing 9 . Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor .It was first developed by Anosov 10 who demonstrated that every orbital beginning sufficiently next to any weak periodic orbit will remain close to it for at least a certain quantity of time . Since then various authors 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44",
        "ori-fast-z-score": -0.43033148291193524,
        "water-fast-z-score": 6.688444820557844
    },
    {
        "original_text": "We study the propagation of traveling waves (TWs) in excitable media with spatially distributed parameters, which are subject to both external forcing and internal fluctuations. We show that TWs can be generated spontaneously even if there is no deterministic source for them. The mechanism responsible for this phenomenon is related to the presence of an unstable stationary state between two stable ones. In particular, we demonstrate how spontaneous generation of TWs occurs due to stochastic resonance induced by additive white Gaussian noise. Finally, we present numerical results illustrating the effect of multiplicative colored noise on the dynamics of TWs. Propagation of traveling waves (TW) in excitable media has been studied extensively over recent years  1  . It was shown that TWs may appear as a result of various mechanisms such as: i) intrinsic instabilities  2  , ii) coupling-induced instabilities  3  or iii) forced oscillations  4  .\nIn many cases it is assumed that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates. However, real physical systems usually have spatial variations of their characteristics  5  . For example, one-dimensional models describing cardiac tissue  6  include heterogeneity in the form of local changes in refractory periods  7, 8  . Another important factor influencing wave propagation is noise  9  . Noise plays different roles depending on whether it acts additively  10  or multiplicatively  11  . Moreover, noise may also affect the shape of the propagating front  12  .",
        "watermark_text": "We test the propagation of traveling signals ( TWs ) in excitable media with spatially scattered characteristics , which are subject to both external forcing and internal fluctuations . We see that TWs can be emitted spontaneously even if there is no deterministic source for them .The pathway responsible for this phenomenon is related to the presence of an weak stationary state between two stable ones . In particular , we prove how premature formation of TWs occurs due to stochastic resonance caused by additive white Gaussian interference .Finally , we present numerical findings illustrating the impact of multiplicative colored interference on the dynamics of TWs . Propagation of traveling signals ( TW ) in excitable media has been studied thoroughly over recent years 1 .It was shown that TWs might appear as a outcome of several mechanisms such as : i ) inherent instabilities 2 , ii ) coupling - caused instabilities 3 or iii ) forced oscillations 4 . In many situations it is expected that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates .However , real biological models usually have spatial variations of their characteristics 5 . For instance , one - dimensional models explaining cardiac tissue 6 include heterogeneity in the form of local changes in refractory intervals 7 , 8 .Another important process influencing wave propagation is sound 9 . Noise takes varied roles depending on whether it functions additively 10 or multiplicatively 11 .Moreover , noise might additionally affect the form of the propagating front 12 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.023912859079006
    },
    {
        "original_text": "In this article, we present an approach for studying special Finsler manifolds by using global methods and techniques in Riemannian geometry. We introduce some new concepts such as geodesic convexity, strongly convexity, and strictly convexity on special Finsler manifolds. Then, we prove that every special Finsler manifold is locally geodesically convex at any point. Finally, we show that if a special Finsler manifold admits a strictly convex function then it has constant flag curvature. Keywords: Geodesic convexity, Finsler metric, Flag curvature. Mathematics Subject Classification (2010): 53C20, 53C25, 53A10. In this article, we study special Finsler manifolds with global methods and techniques in the theory of Riemannian geometry. First, we define geodesic convexity and strongly convexity on special Finslser manifolds. Then, under certain conditions, we prove that every Finsler manifold is locally  geodesically convex at each point. Next, we give necessary and sufficient conditions for a special Finsler manifold to have constant flag curvature.",
        "watermark_text": "In this article , we present an perspective for studying special Finsler manifolds by using global tools and techniques in Riemannian topology . We introduce some additional concepts such as geodesic convexity , strongly convexity , and strictly convexity on particular Finsler manifolds .Then , we prove that every special Finsler manifold is locally geodesically convex at any point . Finally , we prove that if a unique Finsler manifold admits a strictly convex map then it has constant flag curvature .Keywords : Geodesic convexity , Finsler tensor , Flag curvature . Mathematics Subject Classification ( 2010 ) : 53C20 , 53C25 , 53A10 .In this article , we study unique Finsler manifolds with global approaches and techniques in the theory of Riemannian topology . First , we define geodesic convexity and strongly convexity on particular Finslser manifolds .Then , under certain conditions , we prove that every Finsler manifold is locally geodesically convex at each point . Next , we give necessary and sufficient requirements for a unique Finsler manifold to have constant flag curvature .",
        "ori-fast-z-score": 0.8962581595302719,
        "water-fast-z-score": 4.318004318006477
    },
    {
        "original_text": "We show that any physical realization of the quantum NOT gate must be accompanied by an energy cost, which is bounded below by a universal constant times the number of qubits in the system. This result follows directly from our proof of the existence of a lower bound on the ground-state energy density of certain spin systems with competing interactions and open boundary conditions. Our results are relevant to recent efforts aimed at realizing large-scale quantum computers using solid state devices such as semiconductor quantum dots or trapped ions. We also discuss possible extensions of this work to other types of quantum gates. The ability to perform arbitrary unitary transformations on a set of n qubits would constitute a quantum computer capable of solving problems exponentially faster than classical computers  1  . However, it has been shown  2  that no quantum algorithm can solve all computational problems more efficiently than its best known classical counterpart unless the polynomial hierarchy collapses. Thus, practical quantum computing requires efficient methods for implementing only those algorithms whose solutions cannot be found classically  3  .\nIn order to implement these algorithms, one needs to be able to perform basic operations such as single-qubit rotations  4  , two-qubit entangling gates  5  , and measurements  6  . In particular, the so-called CNOT (controlled-NOT) gate plays a central role  7, 8  since it allows one to construct many important quantum circuits  9  . Unfortunately, there exists no known method for constructing a general CNOT gate  10  ; however, several proposals have recently emerged  11  -  16  . These schemes typically involve coupling the spins of individual atoms via magnetic fields  17  and/or optical cavities  18  . While some experimental progress towards building small-scale quantum computers has already been made  19, 20  , scaling up these technologies remains extremely challenging  21  .",
        "watermark_text": "We see that any physical formulation of the quantum NOT gate must be accompanied by an energy cost , which is bounded below by a universal constant times the number of qubits in the system . This result follows directly from our proof of the existence of a lower bound on the ground - state energy density of certain spin systems with competing interactions and open boundary constraints .Our results are applicable to recent efforts aimed at developing huge - scale quantum computers utilizing steady state systems such as semiconductor quantum dots or trapped ions . We especially consider possible extend of this research to other types of quantum gates .The able to conduct arbitrary unitary transformations on a group of n qubits would create a quantum computer capable of solution problems exponentially better than classical processors 1 . However , it has been shown 2 that no quantum algorithm can answer all computational problems more efficiently than its best known classical counterpart unless the linear hierarchy collapses .Thus , practical quantum modeling needs efficient methods for applying only those algorithms whose solutions cannot be found classically 3 . In order to execute these algorithms , one needs to be able to conduct basic operations such as single - qubit rotations 4 , two - qubit entangling gates 5 , and measurements 6 .In particular , the so - called CNOT ( restricted - NOT ) loop plays a central role 7 , 8 since it allows one to build much crucial quantum networks 9 . Unfortunately , there exists no available method for constructing a general CNOT gate 10 ; however , various options have recently surfaced 11 - 16 .These methods typically involve bonding the spins of individual atoms via magnetic waves 17 and / or optical cavities 18 . While some experimental development towards creating low - scale quantum computers has already been achieved 19 , 20 , scaling up these concepts remains incredibly problematic 21 .",
        "ori-fast-z-score": -0.39405520311955033,
        "water-fast-z-score": 6.442528450810767
    },
    {
        "original_text": "We report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical bonding at interfaces.  The interface between La0.7Sr0.3MnO3 (LSMO) and YBa2Cu3O6+x (YBCO), which are both parent compounds for high temperature superconductivity, is found to be highly conducting despite the large lattice mismatch between LSMO and YBCO. This suggests that charge transfer across the interface occurs due to strong electronic hybridization rather than strain relaxation alone. We also find that the hole concentration in the YBCO layer can be controlled by varying the thickness of the LSMO layer grown on top of it. These results demonstrate an alternative approach towards engineering the carrier density in cuprate superconductors using oxide heterostructures. High-temperature superconductivity has been observed only in materials containing copper-oxygen planes known as CuO2 layers  1  . In these systems, holes doped into the CuO2 plane give rise to Cooper pairs leading to superfluidity  2  . However, the maximum critical temperature Tc = 92 K achieved so far in this class of materials is still well below the theoretical limit predicted by Bardeen-Cooper-Schrieffer theory  3  , raising questions about how to further enhance Tc  4  .\nIn recent years there have been significant efforts made to explore new routes toward enhancing Tc beyond its current record value  5  . One promising route involves introducing electrons into the CuO2 plane  6  . For example, replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the system  7, 8  . Alternatively, one may introduce electrons directly into the CuO2 plane by growing thin films of transition metal oxides such as SrTiO3  9  or LaAlO3  10  onto the surface of cuprate superconductors. While these approaches show promise, they require precise control over film composition and structure during deposition  11  . An alternative strategy would involve controlling the carrier density in cuprates without changing their crystal structures  12  .",
        "watermark_text": "We report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical bonding at connections . The interface between La0 . 7Sr0 . 3MnO3 ( LSMO ) and YBa2Cu3O6 + x ( YBCO ) , which are both parent molecules for high heat superconductivity , is found to be highly conducting despite the huge lattice mismatch between LSMO and YBCO .This implies that charge transfer across the interface comes driven to strong electronic hybridization instead than strain relaxation alone . We additionally find that the gap concentration in the YBCO layer can be determined by varying the height of the LSMO layer grown on top of it .These data demonstrate an additional method towards engineering the carrier density in cuprate superconductors using oxide heterostructures . High - temperature superconductivity has been observed only in structures carrying copper - oxygen planes known as CuO2 layers 1 .In these systems , holes doped into the CuO2 plane give rise to Cooper pairs leading to superfluidity 2 . However , the maximum essential temperature Tc = 92 K attained so far in this class of substances is already much below the theoretical maximum expected by Bardeen - Cooper - Schrieffer model 3 , placing questions about how to further enhance Tc 4 .In recent seasons there have been significant efforts made to pursue new routes toward promoting Tc beyond its current record value 5 . One promising route includes introducing electrons into the CuO2 plane 6 .For instance , replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the system 7 , 8 . Alternatively , one may introduce electrons directly into the CuO2 plane by expanding narrow bands of transition iron oxides such as SrTiO3 9 or LaAlO3 10 onto the surface of cuprate superconductors .While these models show success , they demand exact power over movie structure and shape during deposition 11 . An alternative approach would include governing the carrier density in cuprates without altering their crystal structures 12 .",
        "ori-fast-z-score": 0.33567254331867563,
        "water-fast-z-score": 7.7754191435023525
    },
    {
        "original_text": "We study number density correlation functions (NDCFs) in classical one-component plasma at high temperatures and find that they are not well defined due to infrared divergences, which is related with the fact that NDCF can be expressed as an integral over the whole space. We show how these difficulties can be overcome by introducing a new quantity called local number density correlation function (LNDCF). The LNDCF has no infrared divergence but it still contains information about correlations between particles on different length scales. In particular we calculate LNDCF for two limiting cases - when all particles have equal velocities or when their distribution is Maxwellian. Finally we discuss possible applications of our results. PACS numbers: 52.27.Lw, 52.35.Jm, 52.38.Bx \nI. INTRODUCTORY REMARK\nIn this work we consider classical one component plasma consisting of charged particles interacting via screened Coulomb potential  1  . This system is described by the following Hamiltonian:",
        "watermark_text": "We explore number density correlation functions ( NDCFs ) in classical one - component plasma at high altitudes and find that they are not well characterised due to infrared divergences , which is related with the fact that NDCF can be described as an integral over the whole space . We see how these problems can be overcome by using a new quantity called regional number density correlation function ( LNDCF ) .The LNDCF has no infrared divergence but it still contains information about correlations between particles on various length scales . In particular we estimate LNDCF for two limiting cases - when all particles have equal velocities or when their distribution is Maxwellian .Finally we explain possible applications of our findings . PACS codes : 52 . 27 . Lw , 52 . 35 . Jm , 52 . 38 . Bx I .INTRODUCTORY REMARK In this research we define classical one element plasma consisting of charged particles interacting via screened Coulomb potential 1 . This system is characterized by the following Hamiltonian :",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 4.608176875690327
    },
    {
        "original_text": "We present new observational constraints on the cosmic ray (CR) energy density and its evolution with redshift, based on gamma-ray observations by Fermi/LAT in the range 0 < z < 1.5. We find that CRs contribute at most 10% to the total pressure budget of the universe at redshifts below 2. This upper limit is consistent with theoretical expectations for the contribution of CRs accelerated by supernovae. The results are also compatible with previous measurements using radio data. These limits can be used as priors when modeling the effects of CRs on cosmological observables such as galaxy clustering or weak lensing. Cosmic rays (CRs), charged particles which fill space uniformly over large volumes, have been observed throughout our Galaxy and beyond. They play an important role in many astrophysical phenomena including galactic winds, star formation, and possibly even the acceleration of ultra-high-energy cosmic rays  1  . However, their origin remains unknown  2  .\nIn this work we use gamma-ray observations made by the Large Area Telescope (LAT) aboard the Fermi satellite  3  , to place tight constraints on the amount of CRs contributing to the overall pressure budget of the Universe  4  . In particular, we consider two different models for the CR distribution function f(p,z). First, we assume that it follows a power law spectrum dN/dE ~ E^{-alpha} between energies Emin = 10 GeV and Emax = 100 TeV; secondly, we adopt a broken power-law model where the spectral index changes from alpha1 = -2.2 to alpha2 = -3 above some break energy Eb = 50 GeV. For both cases, we fix the normalization factor A by requiring that the integral of f(p,z) over all momenta equals unity. \nThe resulting CR distributions are shown in Figure 1 . \nTo calculate the effect of these CR populations on the expansion history of the universe, we solve numerically the coupled system of equations describing the time-evolution of the background...",
        "watermark_text": "We introduce novel observational restrictions on the cosmic ray ( CR ) energy density and its progression with redshift , using on gamma - ray observations by Fermi / LAT in the range 0 < z < 1 . 5 . We see that CRs contribute at most 10 % to the total pressure budget of the universe at redshifts below 2 .This upper maximum is compatible with theoretical expectations for the impact of CRs accelerated by supernovae . The results are also consistent with previous measurements involving radio data .These restrictions can be used as priors when modeling the effects of CRs on cosmological observables such as galaxy clustering or strong lensing . Cosmic rays ( CRs ) , charged particles which fill space uniformly over large quantities , have been observed throughout our Galaxy and beyond .They play an important role in different astrophysical processes including galactic winds , sun formation , and maybe even the acceleration of ultra - large - energy cosmic rays 1 . However , their source remains unidentified 2 .In this research we utilize gamma - ray observations made by the Large Area Telescope ( LAT ) aboard the Fermi satellite 3 , to place secure constraints on the proportion of CRs causing to the overall pressure budget of the Universe 4 . In particular , we consider two different models for the CR distribution relation h ( p , z ) .First , we suppose that it takes a power law spectrum dN / dE ~ E ^ { - alpha } between frequencies Emin = 10 GeV and Emax = 100 TeV ; secondly , we adopt a broken power - law description where the spectral index shifts from alpha1 = - 2 . 2 to alpha2 = - 3 above some broken power Eb = 50 GeV . For both cases , we solve the normalization factor A by requiring that the integral of f ( p , z ) over all momenta equals unity .The resulting CR variables are shown in Figure 1 . To estimate the impact of these CR populations on the expansion history of the universe , we solve numerically the coupled system of equations explaining the period - progression of the background . . .",
        "ori-fast-z-score": 1.0215078369104984,
        "water-fast-z-score": 8.342314001435737
    },
    {
        "original_text": "We present new near-infrared (NIR) observations and modeling results for the young stellar object, Barnard 68 (B68). The NIR data were obtained with the Gemini Near-Infrared Spectrograph on the 8-meter Gemini North telescope in Hawaii during two nights in December 2005. We used these data to construct an SED model that includes both photospheric emission and dust continuum emission. Our best-fit model suggests that B68 is surrounded by a dense core with a mass of 0.1 M_solar_(M_solar = 1.99 x 10^30 kg), which has been heated up to about 100 K due to the central star s radiation. This temperature corresponds to a luminosity of 3 L_sun_(L_sun = 3.84 x 10^26 W). In addition, we found that there are at least three other sources within the field-of-view of our observation whose fluxes contribute significantly to the total observed flux density.",
        "watermark_text": "We report new near - infrared ( NIR ) observations and modeling results for the small stellar object , Barnard 68 ( B68 ) . The NIR data were obtained with the Gemini Near - Infrared Spectrograph on the 8 - meter Gemini North telescope in Hawaii during two evenings in December 2005 .We utilized these information to build an SED simulation that contains both photospheric emission and dust continuum emission . Our best - fitting model suggests that B68 is scattered by a dense core with a mass of 0 . 1 M _ solar _ ( M _ solar = 1 . 99 x 10 ^ 30 kg ) , which has been heated up to about 100 K due to the main star s radiation .This temperature corresponds to a luminosity of 3 L _ sun _ ( L _ sun = 3 . 84 x 10 ^ 26 W ) . In addition , we concluded that there are at least three other sources within the field - of - view of our observation whose fluxes contribute greatly to the total observed flux concentration .",
        "ori-fast-z-score": 1.0504514628777804,
        "water-fast-z-score": 4.464418717230567
    },
    {
        "original_text": "The Double Chooz experiment is designed to measure the mixing angle θ13 by searching for the appearance of electron neutrinos in a muon neutrino beam produced at the CERN SPS accelerator complex and directed towards France. The near detector (ND) measures the flux, energy spectrum and composition of this beam with high precision. In addition it provides an accurate measurement of the backgrounds expected in the far detector (FD). This document describes how we exploit these measurements to improve our knowledge on the systematic uncertainties affecting the FD analysis. \nIntroduction\n\nDouble Chooz  1  aims at measuring the third mixing angle θ 13 . It uses a reactor-based neutrino source located at about 1 km distance from its near detector ND280  2  , which consists of several sub-detectors surrounding the target volume where neutrinos are created. The main goal of the experiment is to search for the appearance of electron-neutrinos in a muon-neutrino beam produced at CERN s Super Proton Synchrotron (SPS), as illustrated in Figure 1 .\nIn order to achieve the required statistical accuracy within reasonable running time, the experiment will run in two phases. Phase I started in 2011 and ran until 2014; during that phase only one out of four possible detectors was operational. Phase II has just begun and runs until 2019 or 2020 when all detectors should be fully operational. During both phases data taking takes place simultaneously with the far detector (FD) situated 12 m underground at a distance of 1 km from the ND280 target  3  . \nNeutrino Flux Prediction\nThe prediction of the neutrino flux Φ(Eν ) reaching the ND280 detector depends on many parameters such as: the number N p of protons hitting the production target per second, their kinetic energy T p , the fraction f π 0 of neutral pions decaying into photons, the pion momentum distribution dN/dpπ etc.. These quantities can be measured directly using dedicated calibration experiments  4  . For example, the proton current Ip = Np /T p is determined by counting the number of protons hitting the target over a given period of time",
        "watermark_text": "The Double Chooz project is designed to measure the mix circle θ13 by searching for the appearance of electron neutrinos in a muon neutrino laser produced at the CERN SPS accelerator complex and directed towards France . The near detector ( ND ) measures the flux , energy spectrum and formation of this beam with high precision .In addition it gives an accurate measurement of the backgrounds predicted in the far detector ( FD ) . This report explains how we utilize these measurements to improve our information on the systematic uncertainties affecting the FD analysis .Introduction Double Chooz 1 aims at calculating the third mixing angle θ 13 . It utilizes a reactor - based neutrino source located at about 1 mi distance from its near sensor ND280 2 , which consists of several sub - detectors surrounding the target volume where neutrinos are created .The main goal of the program is to search for the appearance of electron - neutrinos in a muon - neutrino laser produced at CERN s Super Proton Synchrotron ( SPS ) , as shown in Figure 1 . In order to achieve the necessary mathematical accuracy within reasonable running time , the program will go in two phases .Phase I begun in 2011 and ran until 2014 ; during that phase only one out of four possible detectors was operational . Phase II has just started and ran until 2019 or 2020 when all detectors should be fully deployed .During both phases information taking takes place concurrently with the far detector ( FD ) situated 12 m underground at a distance of 1 km from the ND280 target 3 . Neutrino Flux Prediction The calculation of the neutrino flux Φ ( Eν ) reaching the ND280 detector depends on numerous variables such as : the number N p of protons striking the production target per second , their kinetic power T p , the fraction f π 0 of neutral pions decaying into photons , the pion momentum function dN / dpπ etc . .These quantities can be determined directly using dedicated calibration experiments 4 . For instance , the proton current Ip = Np / T p is calculated by counting the proportion of protons striking the target over a given time of time",
        "ori-fast-z-score": -0.08362420100070908,
        "water-fast-z-score": 6.713450866373513
    },
    {
        "original_text": "We present new results on the evolution of galaxy clustering in the range 0 < z < 5, based on an analysis of data obtained with the VIMOS spectrograph at the Very Large Telescope (VLT). The sample consists of about 2000 galaxies selected by their Lyman-alpha emission line fluxes and covers a wide range of redshifts between 2<z<5. We measure the two-point correlation function for this sample using both direct counts-in-cells methods as well as Fourier space techniques. Our main result is that we find no evidence for any significant change in the amplitude or slope of the correlation function over this large redshift interval. This suggests that there has been little evolution in the typical mass scale of dark matter halos hosting these galaxies since z=5. In addition to measuring the overall shape of the correlation function, we also examine how it depends upon various physical properties such as luminosity, color, and spectral type.",
        "watermark_text": "We current new data on the evolution of galaxy clustering in the range 0 < z < 5 , using on an assessment of evidence derived with the VIMOS spectrograph at the Very Large Telescope ( VLT ) . The sample consists of about 2000 galaxies determined by their Lyman - alpha emission line fluxes and covers a broad variety of redshifts between 2 < z < 5 .We estimate the two - point coupling function for this specimen using both direct counts - in - cells methods as well as Fourier space methods . Our main consequence is that we find no evidence for any large change in the frequency or slope of the correlation function over this big redshift interval .This implies that there has been nothing evolution in the typical mass scale of dark matter halos hosting these objects since z = 5 . In addition to assessing the overall shape of the interaction function , we also investigate how it depends upon several physical properties such as luminosity , color , and spectral type .",
        "ori-fast-z-score": -1.5428161556520092,
        "water-fast-z-score": 4.628448466956028
    },
    {
        "original_text": "We study the cosmological evolution of modified-gravity theories with an action that contains higher-order curvature terms (f(R)) by using a combination of analytical techniques and numerical simulations. We show how to obtain exact solutions for the background expansion history of these models at early times when the universe is dominated by radiation or matter; we also derive approximate analytic expressions valid on all scales during the late-time accelerated phase driven by dark energy. In particular, we find that there are two classes of viable f(R) models which can reproduce the observed cosmic acceleration without introducing any new degrees of freedom beyond those present in general relativity. The first class includes models where the effective gravitational constant decreases as time goes on; this leads to a phantom-like behavior characterized by w < −1. The second class consists of models where the effective gravitational coupling increases with time; here one finds quintessence-like behaviors with w > −1. Finally, we discuss some observational tests that could be used to distinguish between different types of f(R) models.",
        "watermark_text": "We research the cosmological evolution of modified - gravity theories with an action that contains upper - order curvature terms ( f ( R ) ) by using a combination of analytical techniques and mathematical simulations . We see how to obtain exact solutions for the background expansion history of these models at early periods when the universe is dominated by radiation or material ; we also generate approximate analytic expressions applicable on all scales during the early - time accelerated phase fueled by black radiation .In particular , we find that there are two groups of feasible f ( R ) scenarios which can mimic the known cosmic acceleration without using any new degrees of liberty beyond those present in general relativity . The first class includes theories where the effective gravitational constant reduces as time go on ; this results to a phantom - like behavior defined by w < −1 .The second class consists of models where the effective gravitational coupling increases with time ; here one sees quintessence - like interactions with w > −1 . Finally , we explain some observational tests that might be used to distinguish between various types of f ( R ) models .",
        "ori-fast-z-score": 0.6123724356957946,
        "water-fast-z-score": 6.531972647421809
    },
    {
        "original_text": "In this work, we consider the problem of multiuser detection (MUD) for code division multiple access systems with time-varying channels. We propose an algorithm that jointly performs user identification and data detection by using a maximum likelihood criterion. The proposed method is based on the expectation-maximization (EM) algorithm which iteratively estimates both the channel coefficients and transmitted symbols. In order to reduce computational complexity, we also develop a low-complexity suboptimal MUD scheme. Numerical results show that our proposed algorithms outperform existing schemes under various scenarios. Index Terms-Data detection, EM algorithm, Multiuser detection, Time varying channels. 1 Introduction Code-division-multiple-access (CDMA) has been widely used as one of the most promising technologies for next-generation wireless communications due to its high spectral efficiency  1  . However, CDMA suffers from severe interference between users caused by multipath propagation  2  , especially when the number of active users increases  3  .\nTo mitigate inter-user interference, multiuser detectors have been developed  4  -  6  . Among them, linear multiuser detectors are attractive because they can be implemented easily at low cost  7  . Unfortunately, these detectors suffer from performance loss compared to optimal multiuser detectors  8  . To improve their performance, nonlinear multiuser detectors such as successive interference cancellation  9  or parallel interference cancellation  10  were introduced. These detectors require accurate knowledge about the received signals  11  . Therefore, blind multiuser detectors  12  -  14  were proposed to estimate unknown parameters without any training sequence  15  . Although blind multiuser detectors do not need prior information about the received signal, they usually perform worse than conventional multiuser detectors  16  .\nRecently, there has been growing interest in developing multiuser detectors for time-varying channels  17  -  20  . Since the channel varies over time, it becomes more difficult to detect the transmitted symbol accurately  21  . Moreover, if the channel changes rapidly, then the detector may fail completely  22  . Thus, it is important to design robust multiuser detectors against rapid channel variations  23  .",
        "watermark_text": "In this research , we investigate the question of multiuser tracking ( MUD ) for code division multiple entry systems with time - differing channels . We suggest an algorithm that together manages user identification and information detection by using a maximum likelihood threshold .The proposed approach is based on the expectation - maximization ( EM ) algorithm which iteratively generates both the channel coefficients and transmitted symbols . In order to reduce numerical complexity , we also build a small - complexity suboptimal MUD scheme .Numerical results show that our proposed methods outperform established algorithms under various circumstances . Index Terms - Data tracking , EM algorithm , Multiuser tracking , Time varying channels .1 Introduction Code - division - multiple - access ( CDMA ) has been widely adopted as one of the most attractive devices for next - class wireless communications thanks to its high spectral power 1 . However , CDMA suffers from severe interference between clients caused by multipath propagation 2 , particularly when the proportion of active consumers increases 3 .To mitigate inter - customer interference , multiuser detectors have been created 4 - 6 . Among them , continuous multiuser detectors are interesting because they can be deployed easily at low cost 7 .Unfortunately , these detectors suffer from performance loss compared to optimal multiuser detectors 8 . To increase their performance , nonlinear multiuser detectors such as consecutive interference cancellation 9 or parallel interference cancellation 10 were introduced .These detectors need accurate knowledge about the received messages 11 . Therefore , blind multiuser detectors 12 - 14 were developed to estimate unknown parameters without any testing sequence 15 .Although blind multiuser detectors do not require prior information about the received signal , they generally work worse than conventional multiuser detectors 16 . Recently , there has been growing interest in building multiuser detectors for time - differing channels 17 - 20 .Since the channel varies over time , it becomes more impossible to locate the transmitted expression accurately 21 . Moreover , if the channel shifts rapidly , then the sensor may fail entirely 22 .Thus , it is important to build robust multiuser detectors against sudden channel variations 23 .",
        "ori-fast-z-score": -1.0309670614335873,
        "water-fast-z-score": 8.751130125933031
    },
    {
        "original_text": "We present exact solutions to the field equations of the Einstein-Gauss-Bonet (EGB) gravity with negative cosmological constant in 5D space-time. We find that there are three classes of black hole solutions depending on whether the Gauss-Bonnet coupling constant is positive or negative. The first class contains two types of static spherically symmetric black holes which have no horizons but possess naked singularities at their centers. In addition we also obtain another type of solution describing an asymptotically anti-de Sitter wormhole whose throat connects two asymptotic regions. Finally, by using the method developed recently by one of us, we construct a new type of solution representing a time-dependent spacetime horn. This work was supported by NSFC under Grant No. 10875030. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq . \nI. INTRODUCTORY REMARK\nThe discovery of gravitational waves has opened up a new window into our understanding of gravitation  1  , especially when it comes to testing general relativity  2  . However, despite its successes, general relativity still fails to explain some phenomena such as dark energy  3  and quantum gravity  4  . Therefore, many alternative theories of gravity were proposed over the years  5  .\nOne of these alternatives is the so-called Einstein-Gauss-Bonnet (EGB) gravity  6  -  8  . It can be viewed as a natural generalization of general relativity since it includes higher-order curvature corrections  9  . Moreover, this theory admits various interesting solutions including black holes  10 -  12  , wormholes  13  -  15  and even time dependent spacetimes  16  -  18  . Recently, EGB gravity attracted much attention due to its possible role in explaining the accelerated expansion of the universe  19  -  21  .",
        "watermark_text": "We present precise solutions to the field equations of the Einstein - Gauss - Bonet ( EGB ) gravity with negative cosmological constant in 5D space - time . We see that there are three categories of black hole solutions depending on whether the Gauss - Bonnet coupling constant is positive or negative .The first class includes two forms of static spherically symmetric black holes which have no horizons but possess naked singularities at their centers . In addition we also obtain another type of solution describing an asymptotically anti - de Sitter wormhole whose throat connects two asymptotic areas .Finally , by using the method developed ago by one of us , we create a new kind of solution representing a time - dependent spacetime horn . This project was supported by NSFC under Grant No .10875030 . PACS dates : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq .I . INTRODUCTORY REMARK The observation of gravitational waves has opened up a new window into our knowing of gravitation 1 , particularly when it comes to proving general relativity 2 .However , despite its successes , universal relativity also fails to explain some phenomena such as dark energy 3 and quantum gravitational 4 . Therefore , various alternative theories of gravitational were offered over the years 5 .One of these solutions is the so - called Einstein - Gauss - Bonnet ( EGB ) gravity 6 - 8 . It can be viewed as a natural generalization of general relativity since it includes higher - order curvature corrections 9 .Moreover , this theory admits various exciting solutions namely black holes 10 - 12 , wormholes 13 - 15 and even period based spacetimes 16 - 18 . Recently , EGB gravitational attracted much attention due to its potential importance in understanding the advanced expansion of the universe 19 - 21 .",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 7.061788191316445
    },
    {
        "original_text": "We study the dynamic properties of molecular motors by using burnt-bridge models, which are simple kinetic Monte Carlo simulations for motor proteins such as kinesin and myosin V. We show that these models reproduce several experimental results on single-molecule experiments with high accuracy.  In particular, we find that the velocity distribution is well described by an exponential function at low load force but deviates from it when the load increases. The mean square displacement shows subdiffusive behavior under large loads. These behaviors can be explained by considering the effect of the elasticity of the cargoes carried by the motors. Our model also reproduces the dependence of stall forces on external viscous drag coefficients observed experimentally. Finally, our simulation results suggest that the number of steps taken per ATP hydrolysis cycle decreases exponentially with increasing load force. This result may explain why the step size fluctuation becomes larger than expected theoretically near stalling conditions. \nI. INTRODUCTIO N\nMolecular motors play important roles in many biological processes including muscle contraction  1  , vesicle transport  2  , chromosome segregation  3  , and cell division  4  . They convert chemical energy into mechanical work through repeated cycles of binding to cytoskeletal filaments (e.g., microtubules) and releasing them  5  .\nThe most extensively studied class of molecular motors is the kinesins  6  . Kinesins walk along microtubules toward their plus ends  7, 8  . Myosins move towards actin filaments  minus ends  9  . Both types of motors have been shown to take discrete steps  10 -12  . Recent studies have revealed that both kinesins  13  and myosins  14  exhibit stochastic stepping motions even without external loads  15 -19  . It has been suggested that this randomness arises mainly due to thermal fluctuations  20, 21  or internal noise  22  . However, there still remain open questions about how they respond to external loads  23  .\nIn order to understand the mechanism underlying the operation of molecular motors, various theoretical approaches have been developed so far  24  . Among those methods, kinetic Monte Carlo (KMC) simulations  25  provide useful information on",
        "watermark_text": "We research the dynamic characteristics of molecular motors by using burnt - bridge machines , which are simple kinetic Monte Carlo simulations for motor molecules such as kinesin and myosin V . We see that these models reproduce many experimental results on single - cell experiments with high sensitivity . In particular , we find that the velocity distribution is well described by an exponential vector at low load pressure but deviates from it when the load changes .The mean square displacement shows subdiffusive behavior under large loads . These habits can be described by using the impact of the elasticity of the cargoes carried by the motors .Our model also reproduces the relationship of stall forces on external viscous drag coefficients observed experimentally . Finally , our modeling results show that the number of steps took per ATP hydrolysis process reduces exponentially with expanding load pressure .This result may understand why the step height fluctuation gets wider than expected theoretically near stalling circumstances . I . INTRODUCTIO N Molecular motors play important roles in multiple physical processes including muscle contraction 1 , vesicle transport 2 , genome segregation 3 , and cellular division 4 .They convert chemical electricity into mechanical labor through continuous periods of binding to cytoskeletal filaments ( e . g . , microtubules ) and releasing them 5 . The most extensively studied class of molecular motors is the kinesins 6 .Kinesins walk along microtubules toward their plus ends 7 , 8 . Myosins walk towards actin filaments minus ends 9 .Both types of motors have been shown to take distinct phases 10 - 12 . Recent research have revealed that both kinesins 13 and myosins 14 demonstrate stochastic stepping motions even without external loads 15 - 19 .It has been proposed that this randomness comes mostly owing to heat fluctuations 20 , 21 or internal sound 22 . However , there still continue open questions about how they react to external loads 23 .In order to comprehend the process underlying the operation of molecular motors , various theoretical methods have been proposed so far 24 . Among those techniques , kinetic Monte Carlo ( KMC ) simulations 25 provide useful details on",
        "ori-fast-z-score": -0.9428090415820634,
        "water-fast-z-score": 7.747580267412529
    },
    {
        "original_text": "We study the ground state properties and excitations in the spin-1/2 Heisenberg antiferromagnet on the square lattice with nearest-neighbor interactions only, using exact diagonalization (ED) for small clusters up to 12 sites as well as density-matrix renormalization group (DMRG) calculations for larger systems. We find that the ground-state energy per site is lower than the classical value by about 0.25J, where J denotes the exchange coupling constant between neighboring spins. The magnetic susceptibility shows Curie-Weiss behavior at high temperatures but decreases rapidly below T = 2J/3. This indicates strong quantum fluctuations which are also reflected in the low-temperature dependence of the specific heat. In addition we observe an unusual peak structure in the spin-spin correlation function S(q). For q along the principal axes of the Brillouin zone this peak has its maximum at q = π while it shifts towards smaller values when approaching the diagonals.",
        "watermark_text": "We research the ground state properties and excitations in the spin - 1 / 2 Heisenberg antiferromagnet on the square lattice with nearest - neighbor interactions only , using accurate diagonalization ( ED ) for large clusters up to 12 locations as well as density - vector renormalization group ( DMRG ) estimates for larger systems . We see that the ground - state energy per site is lower than the classical value by about 0 . 25J , where J refers the transfer coupling constant between neighboring spins .The magnetic susceptibility displays Curie - Weiss behavior at high temperatures but decreases quickly below T = 2J / 3 . This implies deep quantum fluctuations which are also reflected in the small - temperature dependence of the specific heat .In addition we encounter an peculiar peak structure in the spin - spinning correlation function S ( q ) . For q along the primary axes of the Brillouin zone this peak has its highest at q = π while it shifts towards lesser values when approaching the diagonals .",
        "ori-fast-z-score": 0.4588314677411235,
        "water-fast-z-score": 5.505977612893481
    },
    {
        "original_text": "The study of critical phenomena is one of the most important topics in statistical physics, and has been applied to many fields such as biology, sociology, computer science, etc.. In this talk I will introduce some recent results on critical phenomena in complex networks. The main idea behind these works is that we can use the concept of  network resilience  to characterize different phases of a system with respect to its robustness against external perturbations or internal failures. We show how to detect phase transitions by measuring the size fluctuations of the largest connected component (LCC) of an evolving network under random attacks. Furthermore, we propose a new method for detecting phase transitions based on the evolution of the LCC s diameter. Finally, we discuss possible extensions of our work to other types of networks beyond scale-free ones. This research was supported by NSFC grant No.11271063. Keywords: Critical phenomena; Complex networks; Phase transition",
        "watermark_text": "The investigation of critical processes is one of the most important topics in statistical mechanics , and has been used to many fields such as biology , sociology , computer science , etc . . In this talk I will explain some latest findings on critical processes in complex networks .The main idea behind these works is that we can using the idea of system resilience to characterize different stages of a system with regard to its robustness against external perturbations or internal failures . We see how to identify phase transitions by assessing the size fluctuations of the greatest connected component ( LCC ) of an evolving network under random attacks .Furthermore , we investigate a new method for detecting phase transitions based on the evolution of the LCC s diameter . Finally , we investigate possible extend of our work to other types of networks beyond size - safe ones .This research was supported by NSFC award No . 11271063 . Keywords : Critical phenomena ; Complex networks ; Phase transition",
        "ori-fast-z-score": 0.7071067811865476,
        "water-fast-z-score": 5.815230125149881
    },
    {
        "original_text": "We study the dynamics of an interacting tachyonic field in a spatially flat Friedmann-Robertson-Walker universe with zero spatial curvature, using numerical methods to solve the equations of motion.  We find that there are two distinct phases during which the energy density evolves differently; one phase is dominated by the kinetic energy of the fields while the other is dominated by their potential energies.  The transition between these phases occurs when the Hubble parameter becomes comparable to the mass scale associated with the interaction term.  During this transition period we observe oscillatory behavior in both the Hubble parameter and the energy densities of each individual field.  In addition, we find that the total energy density decreases more slowly than it would if only one component were present (i.e., either a single tachyonic or a single scalar field).  Finally, we show how our results can be used to construct viable inflationary models. We consider a model consisting of a tachyonic field coupled to another scalar field through a quartic self-interaction term.  Using numerical techniques, we examine the time-evolution of various quantities such as the Hubble parameter, the energy densities of each field individually, and the total energy density.  Our analysis reveals several interesting features including the presence of a transition region where the Hubble parameter becomes comparable...",
        "watermark_text": "We research the dynamics of an interacting tachyonic field in a spatially straight Friedmann - Robertson - Walker universe with zero spatial curvature , using numerical methods to correct the coefficients of movement . We see that there are two separate phases during which the power concentration evolves differently ; one phase is dominated by the kinetic power of the fields while the other is dominated by their potential energies .The shift between these stages occurs when the Hubble parameter becomes comparable to the mass scale involved with the interaction term . During this shift period we study oscillatory behavior in both the Hubble parameter and the power densities of each individual field .In addition , we find that the total energy density decreases more slowly than it would if only one element were found ( i . e . , either a single tachyonic or a single scalar field ) . Finally , we show how our findings can be used to build feasible inflationary theories .We consider a theory consisting of a tachyonic field coupled to another scalar field through a quartic self - interaction term . Using numerical technology , we investigate the period - evolve of several quantities such as the Hubble parameter , the electricity densities of each field individually , and the total energy density .Our study reveals numerous interesting features including the presence of a transition region where the Hubble parameter becomes identical . . .",
        "ori-fast-z-score": -0.5940885257860046,
        "water-fast-z-score": 5.671711984196938
    },
    {
        "original_text": "We report on neutron scattering experiments performed to study magnetic excitations in an underdoped cuprate superconductor, YBa2Cu3Ox (x = 6.35). We observe that the intensity and linewidth of the low-energy spin waves decrease with increasing temperature up to T* ~ 150 K, which is higher than Tc by about 50 K. The observed behavior can be explained within the framework of the spin-fermion model if one assumes that the spin-wave lifetime decreases rapidly at temperatures close to T* due to the decay into fermionic quasiparticles. This interpretation implies that the pseudogap opens already below T* as suggested previously. \n \n Introduction \n \n In recent years there has been considerable interest in studying the properties of high-temperature superconductors using neutron scattering techniques  1-5 . Neutron scattering allows us not only to investigate the static structure factor S(Q) but also dynamic correlations such as phonons or magnons  6 . It was found recently  7-9  that the low energy spin wave spectrum in optimally doped YBa2Cu3O3 displays unusual features compared to conventional metals. For example, it exhibits a strong dispersion anisotropy along different crystallographic directions  8  and shows significant deviations from the usual linear dependence between the inverse spin wave velocity and momentum  9 . These results have stimulated theoretical studies  10-12  aimed at understanding how these unconventional spin wave properties are related to the electronic structure of the CuO2 planes. However, little attention has so far been paid to the effect of doping on the spin wave dynamics. Here we present new experimental data obtained on an underdoped sample of YBa2Cu3OX (x= 6.35), where x denotes the oxygen content  13 . Our main goal is to explore whether the spin wave properties change significantly when going away from optimal doping towards lower values of x.",
        "watermark_text": "We report on particle scattering experiments conducted to study magnetic excitations in an underdoped cuprate superconductor , YBa2Cu3Ox ( x = 6 . 35 ) . We see that the strength and linewidth of the high - energy spinning waves reduce with advancing heat up to T * ~ 150 K , which is higher than Tc by about 50 K . The observed behavior can be described within the framework of the spin - fermion theory if one suppose that the spin - wave life falls swiftly at conditions close to T * due to the decay into fermionic quasiparticles .This interpretation means that the pseudogap opens already below T * as suggested previously . Introduction In recent years there has been substantial interest in investigating the properties of high - temperature superconductors using neutron scattering methods 1 - 5 .Neutron diffusion allows us not only to examine the static structure parameter S ( Q ) but also dynamic correlations such as phonons or magnons 6 . It was shown ago 7 - 9 that the reduced intensity spin wave spectrum in optimally doped YBa2Cu3O3 exhibits unusual characteristics compared to conventional metals .For instance , it displays a powerful dispersion anisotropy along various crystallographic directions 8 and shows significant deviations from the usual linear dependence between the inverse spinning wave velocity and momentum 9 . These data have stimulated theoretical experiments 10 - 12 aiming at studying how these unconventional momentum wave properties are related to the electronic properties of the CuO2 planes .However , little attention has so far been paid to the impact of doping on the spin wave behavior . Here we present new empirical data derived on an underdoped specimen of YBa2Cu3OX ( x = 6 . 35 ) , where x denotes the oxygen composition 13 .Our main goal is to examine whether the spin wave properties change considerably when going away from efficient doping towards lower values of x .",
        "ori-fast-z-score": -2.151657414559676,
        "water-fast-z-score": 6.627104836843802
    },
    {
        "original_text": "We present the results of three-dimensional MHD simulations that show how magnetic fields can be amplified by shocks in molecular clouds, and lead to the formation of dense filaments with high mass-to-flux ratios. The initial conditions are based on observations of nearby star-forming regions. We find that shock compression leads to an increase in density and temperature at the post-shock region. This causes the gas pressure gradient across the shock front to decrease rapidly as time progresses. As a result, the field lines become more tangled due to turbulent motions induced by the shock wave. In addition, we observe that the magnetic energy is transferred into kinetic energy through Alfvén waves generated behind the shock fronts. Finally, we demonstrate that these processes cause the magnetic flux-to-mass ratio to increase significantly within the shocked region. \n \n Keywords: Magnetic fields, Shocks, Star formation, Turbulence \n \n 1. Introduction \n \n Molecular clouds play important roles in star formation (SF) because they provide the material for stars to form out of. However, it remains unclear what physical mechanisms drive SF inside molecular clouds. One possible mechanism involves supersonic turbulence driven by supernovae explosions or stellar winds (Mac Low & Klessen 2004). Another possibility is that large-scale gravitational collapse may trigger localised fragmentation leading to the formation of dense cores which then evolve into protostars (Larson 1978; Bonnell et al. 1997) . It has been suggested that both scenarios could operate simultaneously during different stages of evolution of molecular clouds (Krumholz 2014). \n \n Recent observational studies have shown that many young massive stars are associated with filamentary structures observed in infrared dust emission maps (André et al. 2010; Peretto et al. 2013 ). These filaments often appear to be aligned along magnetic field directions inferred from polarisation measurements (Chapman et al. 2011) , suggesting that magnetic fields might play an important role in regulating the dynamics of such systems. Indeed, theoretical models suggest that magnetic fields can affect the stability properties of self-gravitating clouds against global collapse (Mouschovias 1976; Tomis",
        "watermark_text": "We present the conclusion of three - dimensional MHD simulations that demonstrate how magnetic waves can be amplified by shocks in molecular clouds , and lead to the formation of dense filaments with high mass - to - flux proportions . The initial conditions are based on observations of nearby star - creating areas .We see that shock compression contributes to an increase in volume and heat at the post - shock zone . This leads the gas pressure slope across the shock front to reduce rapidly as time progresses .As a result , the field lines become more twisted due to chaotic motions created by the shock wave . In addition , we determine that the magnetic energy is transferred into kinetic power through Alfvén currents produced behind the shock fronts .Finally , we prove that these mechanisms create the magnetic flux - to - mass ratio to expand significantly within the shocked region . Keywords : Magnetic fields , Shocks , Star formation , Turbulence 1 .Introduction Molecular clouds play crucial roles in star formation ( SF ) because they provide the material for stars to form out of . However , it remains unsure what physical mechanisms drive SF inside molecular clouds .One potential mechanism involves supersonic turbulence driven by supernovae explosions or stellar winds ( Mac Low & Klessen 2004 ) . Another possibility is that high - scale gravitational failure may generate localised fragmentation leading to the formation of dense cores which then evolve into protostars ( Larson 1978 ; Bonnell et al .1997 ) . It has been proposed that both scenarios could operate simultaneously during various phases of evolved of molecular clouds ( Krumholz 2014 ) .Recent observational investigations have shown that several young massive stars are related with filamentary structures discovered in infrared dust emission images ( André et al . 2010 ; Peretto et al .2013 ) . These filaments often seem to be aligned along magnetic force directions inferred from polarisation observations ( Chapman et al .2011 ) , showing that magnetic waves might play an important role in controlling the dynamics of such systems . Indeed , theoretical theories indicate that magnetic waves can affect the stability properties of self - gravitating clouds against global failure ( Mouschovias 1976 ; Tomis",
        "ori-fast-z-score": 0.07602859212697055,
        "water-fast-z-score": 7.732600044504815
    },
    {
        "original_text": "We present an alternative description of the electron in terms of its position and velocity, which is based on the idea that it moves along a helical trajectory around the nucleus. The new approach leads to a simple analytical expression for the energy levels of the helium atom as well as for the wave functions corresponding to these states. We show how this model can be used to explain some experimental results obtained by high-resolution spectroscopy experiments performed at Jefferson Lab. In addition we discuss possible extensions of our work towards other atomic systems such as muonic atoms or ions with one valence electron. Helium has been studied extensively over many decades both experimentally and theoretically. It was found that there are two stable isotopes (3He and 4He) and several excited states. These states have been investigated using various spectroscopic techniques including photo-absorption  1  , laser excitation  2  , and Compton scattering  3  . However, despite all efforts made so far, no satisfactory explanation exists yet about why the ground state of 3He is unbound while the ground state of 4He is bound  4  .\nIn order to understand better the structure of helium, we propose here a new theoretical framework where the electron is described not only by its usual position but also by its velocity vector. This new approach allows us to obtain analytically the energy spectrum of helium as well as the associated wavefunctions. Our formalism is inspired by the so-called Bohmian mechanics  5  , which describes particles moving along trajectories instead of following classical equations of motions  6  .",
        "watermark_text": "We introduce an different characterization of the electron in terms of its position and speed , which is based on the idea that it travels along a helical trajectory around the nucleus . The modern perspective results to a simple analytical expression for the power concentrations of the helium atom as well as for the wave functions associated to these states .We see how this description can be used to explain some experimental results acquired by high - resolution spectroscopy investigations undertaken at Jefferson Lab . In addition we explain possible extend of our work towards other nuclear systems such as muonic atoms or ions with one valence electron .Helium has been studied frequently over numerous years both experimentally and theoretically . It was shown that there are two stable isotopes ( 3He and 4He ) and many excited states .These states have been investigated using numerous spectroscopic techniques including photo - absorption 1 , laser excitation 2 , and Compton absorption 3 . However , despite all efforts made so far , no satisfactory excuse exists yet about why the ground state of 3He is unbound while the ground state of 4He is bound 4 .In order to explain better the composition of helium , we undertake here a new theoretical framework where the electron is characterized not only by its traditional position but also by its velocity tensor . This new approach allows us to obtain analytically the power spectrum of helium as well as the associated wavefunctions .Our formalism is influenced by the so - called Bohmian theory 5 , which explains particles moving along trajectories rather of following classical equations of motions 6 .",
        "ori-fast-z-score": -0.27975144247209416,
        "water-fast-z-score": 7.243550686553699
    },
    {
        "original_text": "We present an algorithm for decomposing functions defined over quadratic surfaces in three dimensions, such as the surface of a sphere or ellipsoid, into multipole expansions. The method is based on representing the function using spherical harmonics and then expanding each term in this representation into a sum of products of Legendre polynomials with coefficients that are determined by solving a linear system of equations. We demonstrate our approach through several examples including computing the electrostatic potential due to point charges located at various positions around a dielectric sphere immersed in water. Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space. This work was supported by NSF grant DMS-0852653 (CAREER). Spherical harmonic decomposition has been used extensively in computational physics applications ranging from quantum chemistry  1  , molecular dynamics  2  , and plasma simulations  3  . In these applications, one often needs to represent a given function f(r) defined over some domain Ω in terms of its expansion coefficients C lm :",
        "watermark_text": "We present an algorithm for decomposing functions defined over quadratic spheres in three dimensions , such as the surface of a sphere or ellipsoid , into multipole expansions . The method is based on representing the function using spherical harmonics and then increasing each term in this representation into a sum of products of Legendre polynomials with coefficients that are decided by solving a linear network of equations .We showed our approach through several examples namely calculation the electrostatic potential due to point charges situated at numerous positions around a dielectric sphere immersed in water . Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space .This work was supported by NSF grant DMS - 0852653 ( CAREER ) . Spherical harmonic decomposition has been used extensively in computational physics applications ranging from quantum chemistry 1 , molecular dynamics 2 , and plasma simulations 3 .In these uses , one frequently needs to depict a given function f ( r ) established over some domain Ω in terms of its expansion function C lm :",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 3.2627549126854696
    },
    {
        "original_text": "The vapor pressure, solubility in water, and interfacial tension between oil and water are important parameters for understanding the behavior of crude oils during their production or transport through pipelines.  In this study we have investigated these properties using alkanol monolayers on an aqueous subphase as model systems to mimic the hydrocarbon chains present in crude oils. The results show that the vapor pressures of the alkanols increase with chain length up to C8 but decrease again above C10. This is explained by considering the competition between two opposing effects:  On one hand, increasing chain lengths lead to higher molecular volumes which favor evaporation. On the other hand, longer chains also result in stronger van der Waals interactions within the liquid phase leading to lower vapor pressures. We find that the solubilities of the alkanols follow similar trends as those observed for the vapor pressures. However, the differences in solubility among different chain lengths become smaller when compared to the corresponding differences in vapor pressure. Finally, our measurements reveal that the interfacial tensions between the alkanol layers and the underlying water decreases monotonically with chain length.",
        "watermark_text": "The vapor tension , solubility in water , and interfacial tension between petroleum and water are important characteristics for studying the activity of crude oils during their production or delivery through pipelines . In this study we have analyzed these characteristics utilizing alkanol monolayers on an aqueous subphase as simulation structures to mimic the hydrocarbon chains present in crude oils .The results show that the liquid pressures of the alkanols increase with chain length up to C8 but decrease again above C10 . This is explained by using the competition between two conflicting factors : On one hand , increasing chain lengths result to higher molecular volumes which favor evaporation .On the other hand , wider chains also lead in heavier van der Waals bonds within the liquid phase leading to smaller liquid pressures . We see that the solubilities of the alkanols follow similar trends as those observed for the liquid pressures .However , the differences in solubility among different chain lengths become smaller when compared to the associated changes in vapor tension . Finally , our measurements reveal that the interfacial pressures between the alkanol layers and the underlying water reduces monotonically with chain depth .",
        "ori-fast-z-score": 0.21081851067789195,
        "water-fast-z-score": 6.324555320336758
    },
    {
        "original_text": "We derive bounds on the absolute values of all entries in the up- and down-quark mass matrices, using only information about the CKM-matrix and current experimental data for the masses of quarks. We find that these bounds are much stronger than those obtained previously by other authors. \n \n The results presented here can be used as input parameters for future studies of CP violation within the Standard Model or its extensions. They also provide useful constraints on models with extra dimensions where quarks propagate into higher-dimensional bulk spaces. \nI. INTRODUCTORY REMARK\nThe Cabibbo-Kobayashi-Maskawa (CKM)  1  quark mixing matrix V is an unitary 3 x 3 complex matrix which describes how quarks mix among themselves after electroweak symmetry breaking. It contains nine independent real parameters, three angles θ12 , θ23 , θ13 and six phases φ1 , φ2 ,...",
        "watermark_text": "We derive bounds on the absolute values of all entries in the up - and down - quark mass matrices , using only data about the CKM - matrix and current experimental evidence for the masses of quarks . We see that these limits are greatly strengthened than those achieved previously by other researchers .The results presented here can be used as input parameters for future research of CP violation within the Standard Model or its extended . They especially offer useful limitations on models with extra dimensions where quarks propagate into larger - dimensional bulk spaces .I . INTRODUCTORY REMARK The Cabibbo - Kobayashi - Maskawa ( CKM ) 1 quark mixing function V is an unitary 3 x 3 complex graph which explains how quarks blend among themselves after electroweak symmetry breaking .It contains nine independent real functions , three curves θ12 , θ23 , θ13 and six phases φ1 , φ2 , . . .",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 4.635863249727653
    },
    {
        "original_text": "We study the geometry and topology of generalized Lagrangian submanifolds (GLSMs) in complex symplectic manifolds, focusing on GLSMs that are special Lagrangians with respect to some Kähler form. We show how these can be constructed as holomorphic sections of certain line bundles over moduli spaces of parabolic Higgs bundles. In particular we consider the case where the base is a partial flag variety. This leads us to define new families of Calabi-Yau varieties which have been studied by physicists recently. These varieties are obtained by taking products of Grassmannian manifolds or their quotients by finite groups. The main results of this thesis are:  1. A construction of GLSMs using parabolic Higgs bundles.  2. An explicit description of the cohomology ring of the total space of a vector bundle associated to a parabolic Higgs bundle.  3. A proof of mirror symmetry between two different types of GLSMs defined above when the base is a product of Grassmannians.",
        "watermark_text": "We research the topology and topology of generalized Lagrangian submanifolds ( GLSMs ) in complex symplectic manifolds , concentrating on GLSMs that are special Lagrangians with regard to some Kähler form . We see how these can be formed as holomorphic sections of certain line bundles over moduli spaces of parabolic Higgs bundles .In particular we define the case where the base is a partial flag variety . This leads us to define novel families of Calabi - Yau extensions which have been studied by physicists recently .These varieties are derived by take products of Grassmannian manifolds or their quotients by finite groups . The main results of this dissertation are : 1 .A design of GLSMs involving parabolic Higgs bundles . 2 .An exact description of the cohomology ring of the total space of a vector bundle related to a parabolic Higgs bundle . 3 .A proof of mirror symmetry between two different kinds of GLSMs provided above when the base is a product of Grassmannians .",
        "ori-fast-z-score": 0.39735970711951313,
        "water-fast-z-score": 4.900769721140662
    },
    {
        "original_text": "We present the results of an optimization study for future galaxy surveys, aimed at constraining cosmological parameters in the context of general relativity (GR) and alternative theories of gravitation. We consider two different classes of experiments: weak lensing tomography with Euclid-like specifications, and 21cm intensity mapping observations with SKA1-LOW-like specifications. In both cases we assume that systematics can be controlled down to percent level accuracy. For each experiment we compute the Fisher matrix associated with the measurement of several relevant observables as functions of the underlying cosmology. The resulting covariance matrices are then used to perform parameter forecasts using Monte Carlo Markov Chains. Our main findings are:  - Weak lensing tomography is able to provide competitive constraints on w0 and wa when combined with Planck data.  - Intensity mapping experiments will not significantly improve our knowledge about the equation-of-state of dark energy beyond what has already been achieved by current CMB measurements.",
        "watermark_text": "We present the conclusion of an optimization investigation for future universe surveys , aiming at constraining cosmological values in the context of general relativity ( GR ) and new theories of gravitation . We consider two different categories of studies : soft lensing tomography with Euclid - like standards , and 21cm intensity projection measurements with SKA1 - LOW - like requirements .In both cases we suppose that systematics can be regulated down to percent level precision . For each experiment we compute the Fisher vector associated with the observation of several applicable observables as functions of the fundamental cosmology .The resulting covariance matrices are then utilized to conduct parameter forecasts using Monte Carlo Markov Chains . Our main results are : - Weak lensing tomography is ability to provide competitive limitations on w0 and wa when coupled with Planck information .- Intensity mapping observations will not considerably enhance our information about the equation - of - state of dark energy beyond what has already been achieved by current CMB observations .",
        "ori-fast-z-score": -2.215646837627989,
        "water-fast-z-score": 5.908391567007971
    },
    {
        "original_text": "We study the dynamics of an asymmetric exclusion process with two species on a ring, where particles can hop to their right or left neighboring site and are subject to hard-core repulsion. We show that for any initial condition there exists a unique stationary state which is characterized by a density profile depending only on the distance between sites. In particular we find that this profile decays exponentially fast as one moves away from the origin. This result implies that the system exhibits dynamic screening, i.e., correlations decay exponentially fast at large distances even though the underlying microscopic model does not have translational invariance. The proof relies on a combination of techniques from probability theory (in particular martingale methods) and functional analysis. Our results hold both for finite systems and infinite lattices. \nI. INTRODUCTORY REMARK\nIn recent years much attention has been devoted to studying nonequilibrium steady states of driven lattice gases  1  . These models describe interacting particle systems evolving according to stochastic rules such that detailed balance cannot be satisfied globally  2  , but nevertheless they exhibit interesting macroscopic behavior  3  .\nOne class of these models consists of so-called exclusion processes  4  describing particles moving along a regular lattice under mutual exclusion constraints  5  . For example, consider a chain of L sites labeled by integers 1, ..., L, each occupied by either zero or one particle. Particles may jump to the right or left neighboring site provided it is empty  6  . If all jumps occur independently then the resulting Markov process satisfies detailed balance with respect to some product measure  7, 8  . However if the rates depend on the number of particles occupying adjacent sites  9  then detailed balance breaks down  10  . Despite this lack of equilibrium properties many of these models still display non-trivial features reminiscent of those observed in thermal equilibrium  11  .",
        "watermark_text": "We work the dynamics of an asymmetric exclusion cycle with two organisms on a ring , where ions can jump to their right or left neighboring place and are subject to rough - core repulsion . We see that for any initial situation there exists a unique stationary state which is characterized by a density profile depending only on the distance between locations .In particular we find that this profile decays exponentially rapidly as one moves away from the origin . This result suggests that the process exhibits dynamic filtering , i . e . , correlations decay exponentially rapidly at large distances even though the underlying microscopic theory does not have translational invariance .The proof uses on a combination of techniques from likelihood analysis ( in instance martingale models ) and functional analysis . Our results hold both for finite systems and infinite lattices .I . INTRODUCTORY REMARK In recent years much attention has been focused to investigating nonequilibrium steady states of driven lattice gases 1 .These systems represent interacting particle structures operating due to stochastic laws such that detailed balance cannot be satisfied globally 2 , but still they show exciting macroscopic behavior 3 . One class of these models includes of so - called exclusion mechanisms 4 describing particles moving along a regular lattice under mutual exclusion constraints 5 .For instance , consider a network of L locations labeled by integers 1 , . . . , L , each inhabited by either zero or one particle . Particles must hop to the right or left neighboring area provided it is vacant 6 .If all jumps happen independently then the resulting Markov process satisfies detailed balance with regard to some product measure 7 , 8 . However if the rates differ on the quantity of particles occupying adjoining sites 9 then detailed balance breaks down 10 .Despite this lack of stability properties many of these models remain show non - simple details resembling of those observed in heat equilibrium 11 .",
        "ori-fast-z-score": 0.39904344223381105,
        "water-fast-z-score": 8.96717661308488
    },
    {
        "original_text": "We consider the wiretap channel model in which an eavesdropper can obtain feedback about its observations and use it to improve future decoding attempts. We show that, for any positive integer , there exists a sequence of (2, ) codes such that each code has rate at least . This result is obtained by combining polar coding techniques with ideas from successive cancellation list decoding. The proof relies on a new converse bound for the secrecy capacity region of the wiretap channel with feedback. Finally, we present numerical results illustrating our achievability scheme. In this work, we study the wiretap channel model introduced by Wyner  1  . In particular, we focus on the case where the legitimate receiver obtains feedback about his past observations and uses it to improve his future decoding attempts. Our main contribution consists in showing that polar codes  2  combined with successive cancellation list decoding  3  achieve rates close to the secrecy capacity when used over channels with feedback. More specifically, we prove that if the number of messages grows exponentially fast as a function of the blocklength then every message can be transmitted reliably using a code whose length scales linearly with the number of messages .\nThe remainder of this paper is organized as follows. Section II introduces some notation and definitions. Section III presents our main theorem. Section IV provides a sketch of the proof of Theorem 3.1. Finally, Section V concludes the paper.",
        "watermark_text": "We consider the wiretap network theory in which an eavesdropper can obtain feedback about its measurements and use it to assist future decoding attempts . We see that , for any positive integer , there exists a sequence of ( 2 , ) codes such that each code has rate at least .This result is found by combining polar compression techniques with ideas from successive cancellation list decoding . The proof uses on a new converse bound for the secrecy ability area of the wiretap network with feedback .Finally , we present numerical findings illustrating our achievability scheme . In this research , we study the wiretap channel theory introduced by Wyner 1 .In particular , we focus on the case where the legitimate receiver obtains input about his past discoveries and using it to improve his future decoding attempts . Our main effort consists in discovering that polar codes 2 combined with successive cancellation list decoding 3 achieve speeds close to the silence ability when utilized over networks with feedback .More specifically , we prove that if the quantity of transmissions grows exponentially rapid as a function of the blocklength then every message can be delivered reliably using a code whose width scales linearly with the number of transmissions . The remainder of this paper is organized as follows .Section II offers some terminology and definitions . Section III presents our major theorem .Section IV offers a sketch of the proof of Theorem 3 . 1 . Finally , Section V concludes the paper .",
        "ori-fast-z-score": 0.2873478855663454,
        "water-fast-z-score": 6.674238124719146
    },
    {
        "original_text": "We present new observations of intervening metal systems at z ~ 1.5-2.0 towards the gamma-ray burst (GRB) 050525A, which is one of only two GRBs with spectroscopic redshifts known to date. We detect absorption lines due to Mg ii λλ2796, 2803, Feii λ2382, 2344+2600, Ciii λ977, Siiv λ1394, 1403, Ovi λ1032, 1038, Nv λ1239, 1243, Lyα, and Lyβ associated with an absorber at z = 2.01 ± 0.02. This system has log NHI/cm−2 = 19.6 +0.2 −0.1 , corresponding to a total hydrogen column density of 5 × 1020 cm−2 . It also shows strong low-ionization transitions such as Al iii λ1854, 1854 + 1862, and S iv λ1063, 1073 that are not seen in typical high-redshift absorbers. These features suggest that this absorber may be similar to those found along quasar sightlines.",
        "watermark_text": "We report new images of intervening metal systems at z ~ 1 . 5 - 2 . 0 towards the gamma - ray flare ( GRB ) 050525A , which is one of only two GRBs with spectroscopic redshifts discovered to date . We detect absorption tracks due to Mg ii λλ2796 , 2803 , Feii λ2382 , 2344 + 2600 , Ciii λ977 , Siiv λ1394 , 1403 , Ovi λ1032 , 1038 , Nv λ1239 , 1243 , Lyα , and Lyβ associated with an absorber at z = 2 . 01 ± 0 . 02 .This system has log NHI / cm−2 = 19 . 6 + 0 . 2 −0 . 1 , equivalent to a total hydrogen row density of 5 × 1020 cm−2 . It additionally shows bright low - ionization transitions such as Al iii λ1854 , 1854 + 1862 , and S iv λ1063 , 1073 that are not seen in standard high - redshift absorbers .These features indicate that this absorber could be similar to those observed along quasar sightlines .",
        "ori-fast-z-score": -1.9466570535691505,
        "water-fast-z-score": 2.7221786146864813
    },
    {
        "original_text": "Glutamatergic synapses are the most abundant excitatory connections in the brain, but how they form is not well understood. Here we show that glutamate receptors (GluRs) can be delivered directly to synaptic sites by lateral diffusion on the plasma membrane or indirectly via endocytosis followed by recycling endosomes. We used single-particle tracking with total internal reflection fluorescence microscopy to follow GluR2-containing AMPA receptors tagged with quantum dots at hippocampal neuron dendrites. The results reveal two distinct trafficking routes for receptor delivery to synapses. First, receptors diffuse laterally along the surface until encountering an existing synapse where they become trapped. Second, receptors enter endosomal vesicles after endocytosis and then recycle back to the cell surface through Rab11-positive recycling endosomes before being targeted to new synapses. These findings provide insights into mechanisms underlying formation of functional neuronal circuits during development as well as plasticity of mature neurons.",
        "watermark_text": "Glutamatergic synapses are the most widespread excitatory connections in the brain , but how they shape is not well understood . Here we show that glutamate receptors ( GluRs ) can be delivered directly to synaptic sites by vertical diffusion on the plasma membrane or indirectly via endocytosis followed by recycling endosomes .We utilized single - particle tracking with total internal reflection fluorescence microscopy to follow GluR2 - containing AMPA proteins tagged with quantum dots at hippocampal neuron dendrites . The results show two different transport ways for receptor delivery to synapses .First , receptors diffuse laterally along the surface until encountering an established synapse where they become trapped . Second , receptors enter endosomal vesicles after endocytosis and then recycle back to the cell surface through Rab11 - positive recycling endosomes before being directed to fresh synapses .These studies provide insights into mechanisms governing formation of functional neuronal systems during development as well as plasticity of mature neurons .",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 3.75
    },
    {
        "original_text": "We present the results on the unique type Ib supernova (SN) 2005bf in NGC 6946, which is one of only two SNe with an unambiguous association to a gamma-ray burst (GRB). The light curve and spectral evolution are compared with those of other GRB-associated SNe as well as normal SNe Ia and IIb. We find that SN 2005bf shows several unusual features among these objects. In particular, it has a very slow decline rate during its nebular phase, indicating that the ejecta mass may be much larger than expected for ordinary core-collapse SNe. This suggests that the progenitor star was massive enough to form a black hole directly without going through a neutron-star stage. If this is true, we expect that the central engine of the associated GRB would have been powered by accretion onto such a black hole rather than by radioactive decay energy. Our analysis also indicates that the explosion site should be located close to the center of the host galaxy, suggesting that the progenitor system might have experienced significant natal kick before the explosion. \n \n Keywords: Gamma-ray bursts",
        "watermark_text": "We present the results on the unusual type Ib supernova ( SN ) 2005bf in NGC 6946 , which is one of only two SNe with an unambiguous association to a gamma - ray burst ( GRB ) . The light curve and spectral evolution are compared with those of other GRB - associated SNe as well as normal SNe Ia and IIb .We see that SN 2005bf demonstrates several unique features among these objects . In particular , it has a very slow trend rate during its nebular phase , showing that the ejecta density might be much larger than expected for normal core - collapse SNe .This implies that the progenitor star was massive enough to form a black hole directly without going through a neutron - star stage . If this is true , we expect that the main motor of the associated GRB would have been driven by accretion onto such a black hole rather than by radioactive decay electricity .Our study also shows that the explosion area should be found nearby to the center of the host universe , showing that the progenitor system might have experienced significant natal kick before the explosion . Keywords : Gamma - ray bursts",
        "ori-fast-z-score": 0.1125087900926024,
        "water-fast-z-score": 5.287913134352312
    },
    {
        "original_text": "We study how classical and quantum uncertainty affect the price dynamics in an incomplete information setting, where agents have access to different sources of information about the underlying state variable. We show that when there is no common knowledge among traders on the true value of the state variable, they may disagree on its expected future evolution even if all are rational and risk-neutral. This disagreement leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based solely on their private signals. In this case, we find that the stock returns exhibit volatility clustering and fat tails similar to those observed empirically. Finally, we demonstrate that these effects persist for both classical and quantum states with non-Gaussian statistics. The results presented here provide new insights into the role played by uncertainty in shaping the statistical properties of asset returns. They also suggest possible avenues for further research aimed at understanding the origin of such phenomena within more realistic models of trading behavior.",
        "watermark_text": "We research how classical and quantum uncertainty influence the price dynamics in an incomplete information context , where agents have access to different sources of information about the underlying state variable . We see that when there is no shared information among traders on the true value of the state variable , they may differ on its expected past development even if all are realistic and chance - neutral .This dispute leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based primarily on their private signals . In this instance , we find that the stock returns display volatility clustering and lean tails identical to those observed empirically .Finally , we prove that these consequences persist for both classical and quantum states with non - Gaussian statistics . The results presented here provide fresh insights into the part played by uncertainty in shaping the statistical characteristics of investment returns .They also suggest possible avenues for further studies aimed at studying the origin of such patterns within more realistic descriptions of market behavior .",
        "ori-fast-z-score": -0.7504787743864564,
        "water-fast-z-score": 5.9696200579570915
    },
    {
        "original_text": "We present an algorithm to solve numerically the time-dependent equations describing the growth of ionized regions in the early universe, based on the Weighted Essentially Non-Oscillatory (WENO) scheme. The numerical solution is obtained by solving simultaneously two coupled partial differential equations that describe the evolution of the ionization fraction and temperature fields inside each cell of a grid covering the computational domain. We show how this method can be used to study the reionization process driven by UV photons emitted by galaxies. In particular we compare our results with those obtained using the Smooth Particle Hydrodynamics technique. Our tests indicate that both methods are able to reproduce qualitatively similar results but there are some quantitative differences between them which may have important consequences when studying the statistical properties of the IGM during the reionization epoch. \n \n Keywords: Numerical Methods, Computational Science, Cosmology, Reionization",
        "watermark_text": "We present an algorithm to solve numerically the time - dependent equations explaining the development of ionized areas in the early universe , using on the Weighted Essentially Non - Oscillatory ( WENO ) scheme . The mathematical solution is found by solving simultaneously two coupled partial differential equations that explain the evolution of the ionization fraction and heat fields inside each cell of a grid covering the theoretical domain .We see how this technology can be used to study the reionization process driven by UV photons generated by galaxies . In particular we compare our findings with those achieved using the Smooth Particle Hydrodynamics technique .Our tests show that both approaches are able to predict qualitatively identical outcome but there are some quantitative variations between them which would have important implications when examining the empirical features of the IGM during the reionization epoch . Keywords : Numerical Methods , Computational Science , Cosmology , Reionization",
        "ori-fast-z-score": -2.1766269588592317,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "In this work, we propose an approach to human identification based on the analysis of image attributes and their relationships with each other. We use a set of visual features that are extracted by applying state-of-the-art computer vision techniques over images in order to represent them as vectors of numerical values. These feature vectors can be used to train machine learning algorithms such as Support Vector Machines (SVMs) or Random Forests (RF). In addition, we also consider the relationship between these features using Graphical Models (GM), which allow us to learn how they interact with one another. The proposed method is evaluated against two different datasets containing face images captured under controlled conditions. Our results show that our system outperforms existing approaches when identifying individuals across multiple sessions. This research was supported by the National Science Foundation through awards IIS-1253153 and CNS-1527225. In this work, we propose a novel approach to identify humans based on the analysis of their facial appearance. To do so, we extract several visual features from faces using state-of-the-art computer vision methods. Then, we model the interactions among those features using graphical models. Finally, we evaluate the performance of our method against two publicly available databases.",
        "watermark_text": "In this project , we develop an way to human identification relying on the examination of visual attributes and their connections with each other . We use a group of visual elements that are derived by using state - of - the - art computer vision techniques over images in order to represent them as matrices of numerical values .These feature vectors can be used to train machine understanding algorithms such as Support Vector Machines ( SVMs ) or Random Forests ( RF ) . In addition , we also consider the relationship between these characteristics utilizing Graphical Models ( GM ) , which allow us to study how they interact with one another .The proposed approach is evaluated against two different datasets featuring face photos taken under controlled circumstances . Our results show that our system outperforms previous techniques when identifying persons across multiple sessions .This research was supported by the National Science Foundation through awards IIS - 1253153 and CNS - 1527225 . In this research , we propose a innovative method to identify humans based on the evaluation of their facial form .To do so , we extract many graphical features from faces utilizing state - of - the - art computer vision methods . Then , we study the interactions among those characteristics utilizing graphical descriptions .Finally , we assess the performance of our technique against two publicly accessible data .",
        "ori-fast-z-score": -1.507556722888818,
        "water-fast-z-score": 6.4
    },
    {
        "original_text": "We revisit the slow relaxation in a model glass-forming system, namely a binary mixture of Lennard-Jones particles interacting via a Weeks-Chandler-Andersen potential with an additional repulsive shoulder at short distances. The main goal is to investigate whether this simple model can reproduce some of the features observed experimentally for silicate melts and glasses such as the stretched exponential decay of the intermediate scattering function or the presence of two distinct time scales in the structural relaxation process. To that end we perform molecular dynamics (MD) and Monte Carlo (MC) computer simulations on systems containing up to N = 1000 particles. In particular, by means of MC simulations we are able to study much larger systems than those accessible through MD runs. Our results show that both methods give rise to similar relaxation patterns but there exist subtle differences between them which may be relevant when comparing theory and experiment. Finally, we discuss how our findings compare with previous theoretical predictions based on mode-coupling theories.",
        "watermark_text": "We revisit the slow relaxation in a model glass - creating scheme , namely a binary mixture of Lennard - Jones atoms interacting via a Weeks - Chandler - Andersen current with an additional repulsive shoulder at short distances . The main goal is to examine whether this straightforward model can mimic some of the properties observed experimentally for silicate melts and glasses such as the stretched exponential decay of the intermediate absorption parameter or the presence of two separate time scales in the structural relaxation process .To that end we perform molecular mechanics ( MD ) and Monte Carlo ( MC ) computer simulations on structures containing up to N = 1000 particles . In particular , by means of MC simulations we are able to study considerably wider structures than those accessible through MD runs .Our results show that both approaches give rise to similar relax patterns but there remain simple changes between them which may be applicable when comparing theory and observation . Finally , we explain how our findings compare with previous conceptual predictions based on phase - correlation experiments .",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 5.888888888888889
    },
    {
        "original_text": "We present an analysis of data obtained with the Chandra X-ray Observatory to search for evidence that dark matter particles are being annihilated by collisions at the Galactic Center (GC). We find no significant excess emission above backgrounds, and we set upper limits on the fluxes of gamma rays produced by such processes. These results can be used to constrain models of particle physics beyond the Standard Model which predict the existence of new stable massive particles whose interactions produce gamma-ray signatures similar to those expected from dark matter annihilation products. \n \n The GC is one of the most promising targets for indirect searches for dark matter because it contains large amounts of dark matter concentrated within a small volume. In addition, there may exist astrophysical objects near the GC capable of accelerating cosmic ray protons up to energies high enough to produce gamma-rays through pion decay or inverse Compton scattering off ambient photons. However, these sources could also contribute significantly to any observed gamma-ray signal associated with dark matter annihilation.",
        "watermark_text": "We present an assessment of evidence generated with the Chandra X - ray Observatory to search for indication that dark matter elements are being annihilated by collisions at the Galactic Center ( GC ) . We see no considerable residual emission above backgrounds , and we setting lower limits on the fluxes of gamma radiation generated by such processes .These data can be used to constrain models of particle science beyond the Standard Model which predict the existence of new stable massive bodies whose interactions generate gamma - ray signatures identical to those expected from dark matter annihilation products . The GC is one of the most attractive sites for indirect searches for black material because it contains large quantities of bright particles concentrated within a small quantity .In addition , there may contain astrophysical objects near the GC capable of accelerating cosmic ray protons up to energies high enough to produce gamma - rays through pion decay or inverse Compton absorption off ambient photons . However , these sources might additionally contribute considerably to any observed gamma - ray signal associated with bright matter annihilation .",
        "ori-fast-z-score": 1.7056057308448833,
        "water-fast-z-score": 6.609222207023923
    },
    {
        "original_text": "We report on the magnetic properties of self-assembled arrays of cobalt (Co) hollow spheres, which are prepared by an electrochemical deposition method onto carbon-coated copper grids. The samples show anisotropic behavior in their hysteresis loops at room temperature as well as superparamagnetic characteristics above 300 K. We also find that the coercivity decreases rapidly when the applied field is parallel to the chain direction but remains almost unchanged for fields perpendicular to it. This indicates that the easy axis lies along the chain direction. In addition, we observe that the remanent magnetization increases gradually up to about 100 Oe after annealing the sample at 400 °C under vacuum conditions. These results suggest that the observed anisotropy originates mainly from shape effects rather than inter-particle interactions. \n \n Keywords: Anisotropy, Cobalt, Hollow sphere, Self-assembling, Superparamagnetism",
        "watermark_text": "We report on the magnetic properties of self - assembled arrays of cobalt ( Co ) hollow spheres , which are prepared by an electrochemical deposition technology onto carbon - wrapped copper grids . The samples show anisotropic dynamics in their hysteresis loops at room temperature as well as superparamagnetic qualities above 300 K . We additionally find that the coercivity decreases quickly when the introduced field is parallel to the chain direction but remains virtually unchanged for fields perpendicular to it .This implies that the easy axis lies along the chain direction . In addition , we determine that the remanent magnetization increases slowly up to about 100 Oe after annealing the sample at 400 °C under vacuum environments .These data suggest that the seen anisotropy derives mainly from shape impacts rather than inter - particle processes . Keywords : Anisotropy , Cobalt , Hollow sphere , Self - assembling , Superparamagnetism",
        "ori-fast-z-score": 0.6401843996644799,
        "water-fast-z-score": 5.505585837114527
    },
    {
        "original_text": "The Stochastic Loewner Evolution (SLE) is an important tool in the study of random curves and fractals, especially those arising as scaling limits of discrete models such as lattice paths or self-avoiding walks.  The SLE trace can be thought of as a continuous version of Brownian motion with drift; it has been shown to have connections to many other fields including quantum gravity, string theory, statistical mechanics, probability theory, mathematical physics, number theory, and computer science.   In this article we will give a brief introduction to the basic concepts behind the SLE process, along with some examples that illustrate its use. We also provide references for further reading on the subject. For more information about the SLE process see the following articles:  http://arxiv.org/abs/math/9906028 http://arxiv.org/sabs/0909.0366 http://arxiv.org/10.1103/PhysRevE.71.026110",
        "watermark_text": "The Stochastic Loewner Evolution ( SLE ) is an important tool in the study of random curves and fractals , particularly those arose as scaling limits of linear models such as lattice trails or self - escaping tours . The SLE trace can be thought of as a continuous version of Brownian movement with drift ; it has been shown to have link to many other fields including quantum gravitational , string theory , statistical mechanics , probability theory , mathematical science , number theory , and computer science .In this article we will provide a brief introduction to the fundamental concepts behind the SLE method , along with some examples that highlight its use . We additionally offer references for further reading on the subject .For more information about the SLE method see the following articles : www : / / arxiv . org / abs / math / 9906028 http : / / arxiv . org / sabs / 0909 . 0366 www : / / arxiv . org / 10 . 1103 / PhysRevE . 71 . 026110",
        "ori-fast-z-score": 0.24618298195866545,
        "water-fast-z-score": 5.25
    },
    {
        "original_text": "Muon-catalyzed fusion (MCF) is an exotic nuclear reaction that can be used to produce energy in future reactors, but it requires extremely pure hydrogen gas as fuel.  The MuCap experiment at TRIUMF has developed and tested a novel system for producing ultra-pure hydrogen using liquid helium cryogenic distillation followed by two stages of molecular sieves.  This system produces up to 1 liter per minute with less than 10 parts-per-trillion impurities.  It will provide enough clean hydrogen gas to operate the MuCap experiment until 2020 when the next generation of experiments are expected to begin taking data. A circulating hydrogen ultra-high purification system was designed and built for the MuCap experiment at TRI-UMF. Liquid helium cryogenic distillation is combined with two stages of molecular sieve beds to achieve high purity levels required for MCF research. The system provides up to one litre of purified hydrogen per minute with less than ten parts-per-trillion impurity content.",
        "watermark_text": "Muon - catalyzed fusion ( MCF ) is an exotic radioactive reaction that can be used to produce energy in future reactors , but it costs extremely solid hydrogen energy as fuel . The MuCap project at TRIUMF has constructed and demonstrated a innovative system for producing ultra - pure hydrogen utilizing liquid helium cryogenic distillation preceded by two stages of molecular sieves .This system creates up to 1 liter per minute with fewer than 10 parts - per - trillion impurities . It will provide enough clean hydrogen energy to run the MuCap project until 2020 when the new generation of studies are expected to begin take data .A circulating hydrogen super - high purification system was developed and developed for the MuCap project at TRI - UMF . Liquid helium cryogenic distillation is combined with two stages of molecular sieve beds to achieve high purity levels needed for MCF research .The system provides up to one litre of purified fuel per moment with fewer than ten components - per - trillion impurity content .",
        "ori-fast-z-score": -0.6882472016116852,
        "water-fast-z-score": 6.119912853410033
    },
    {
        "original_text": "We present an analytical method to determine the physical properties (size, mass, and density) of exomoons using only their light curves in transits. We show that this method is robust against uncertainties in the planet s orbital parameters by applying it to simulated data sets with different values for the semi-major axis, eccentricity, inclination angle, argument of periastron, longitude of ascending node, mean anomaly at epoch, and time of passage through periastron. The results are compared to those obtained when fitting directly for these six orbital elements as well as the moon-to-host radius ratio and moon phase function simultaneously. Our analysis shows that our new method can be used to obtain accurate estimates of the moon s physical characteristics even if its orbit has significant eccentricities or inclinations. \n \n Keywords: Exoplanet, Moon, Transit Timing Variations, Photometry \n \n Transiting planets have been found around more than 1000 stars so far1. Many of them exhibit periodic dimming events caused by moons2-5. These moons may play important roles in planetary evolution6-8 but they cannot be detected via direct imaging techniques because of their small sizes9-11. Therefore, we need other methods to study their physical properties12-14. In particular, the detection of moons around extrasolar giant planets would provide valuable information about how such systems form15-17. \n \n Here we propose a novel approach to estimate the physical characteristics of exomoons based on their light curves alone18-20. This method does not require any prior knowledge of the planet s orbital parameters21-24. It also allows us to detect moons whose orbits are highly inclined25-27 and/or eccentric28-30 relative to the plane of the sky31-33. Moreover, it works equally well whether the moon is tidally locked34-36 or free-rotating37-39. Finally, it provides reliable measurements of the moon s size, mass, and bulk density40-42. \n \n To demonstrate the feasibility of our method, we apply it to simulated data sets generated under various conditions43-45. We find that our technique yields accurate estimates of",
        "watermark_text": "We present an analytical method to estimate the physical properties ( size , mass , and density ) of exomoons utilizing only their light curves in transits . We see that this technology is robust against uncertainties in the planet s orbital variables by using it to modeled information sets with various estimates for the semi - major axis , eccentricity , inclination angle , argument of periastron , longitude of ascending node , mean anomaly at epoch , and period of passage through periastron .The results are compared to those achieved when fitting directly for these six orbital elements as well as the lunar - to - host radius ratio and moon phase equation simultaneously . Our study shows that our new method can be used to obtain precise estimates of the lunar s physical qualities even if its orbit has significant eccentricities or inclinations .Keywords : Exoplanet , Moon , Transit Timing Variations , Photometry Transiting planets have been detected around more than 1000 stars so far1 . Many of them exhibit periodic dimming events produced by moons2 - 5 .These moons might play vital functions in planetary evolution6 - 8 but they cannot be identified via direct scanning techniques because of their tiny sizes9 - 11 . Therefore , we require other methods to study their physical properties12 - 14 .In particular , the observation of moons around extrasolar giant worlds may provide valuable info about how such systems form15 - 17 . Here we undertake a new approach to estimate the physical qualities of exomoons depending on their light curves alone18 - 20 .This method does not require any earlier knowledge of the planet s orbital parameters21 - 24 . It additionally lets us to identify moons whose orbits are extremely inclined25 - 27 and / or eccentric28 - 30 relative to the plane of the sky31 - 33 .Moreover , it works extremely good whether the lunar is tidally locked34 - 36 or free - rotating37 - 39 . Finally , it gives reliable measurements of the lunar s diameter , mass , and bulk density40 - 42 .To show the feasibility of our technique , we apply it to modeled information sets generated under various conditions43 - 45 . We see that our technique yields good estimates of",
        "ori-fast-z-score": -0.4931969619160719,
        "water-fast-z-score": 8.713146327183937
    },
    {
        "original_text": "We present an analytical model to study the effect of mass loading feedback on particle concentration and enstrophy in fully developed turbulence. The cascade process is modeled by using a set of coupled ordinary differential equations, which are derived based on dimensional analysis and Kolmogorov s similarity hypothesis. We show that the presence of particles can significantly affect both the energy transfer rate between different scales as well as the dissipation rates at small scales. In particular, we find that the total amount of energy transferred into smaller scales decreases when there exists significant mass loading feedback. This result suggests that the presence of heavy particles may lead to reduced turbulent mixing efficiency. Finally, our results also indicate that the effects of mass loading feedback become more pronounced if the Stokes number increases or the initial volume fraction of particles becomes larger. Our findings provide useful insights into understanding how heavy particles influence the dynamics of fluid flows. C \nAuthor(s): Yi-Chun Chen , Shih-Chieh Hwang , Chia-Hui Wu , Yu-Ting Lin , Ming-Yuan Liu , Chao-Lin Wang , Jie-Sheng Huang , Wen-Ju Tsai , Tzi-Chao Chan , Chin-Fa Lee , Kuo-Yang Chang , Chung-Ming Yeh , Yuan-Kang Chiou , Chien-Nan Chu , Cheng-Wei Hsieh , Chien-Wen Lu , Chien-Chung Wu , Chien-Shu Chen , Chien-Chin Wu , Chien-Chin Yang , Chien-Chin Lai , Chien-Chin Su , Chien-Chin Hung , Chien-Chin Chen , Chien-Ching Wu , Chien-Ching Tai , Chien-Ching Li , Chien-Ching Sun , Chien-Ching Liang , Chien-Ching Chen , Chien-Chong Wu , Chien-Chung Chen , Chien-Chung Lai , Chien-Chung Su , Chien-Chung Hung , Chien-Chung",
        "watermark_text": "We present an analytical theory to study the impact of mass displacement feedback on particle concentration and enstrophy in fully developed turbulence . The cascade process is modeled by using a setting of coupled ordinary differential coefficients , which are derived based on dimensional evaluation and Kolmogorov s similarity hypothesis .We see that the presence of particles can significantly affect both the power transfer frequency between various scales as well as the dissipation levels at small scales . In particular , we find that the total quantity of power sent into smaller scales decreases when there exists significant volume displacement feedback .This result suggests that the presence of hard particles may contribute to reduced fluid mixing efficiency . Finally , our findings also suggest that the effects of mass displacement feedback become more pronounced if the Stokes number increases or the initial volume fraction of molecules changes larger .Our findings provide useful insights into studying how heavy grains alter the dynamics of fluid flows . C Author ( s ) : Yi - Chun Chen , Shih - Chieh Hwang , Chia - Hui Wu , Yu - Ting Lin , Ming - Yuan Liu , Chao - Lin Wang , Jie - Sheng Huang , Wen - Ju Tsai , Tzi - Chao Chan , Chin - Fa Lee , Kuo - Yang Chang , Chung - Ming Yeh , Yuan - Kang Chiou , Chien - Nan Chu , Cheng - Wei Hsieh , Chien - Wen Lu , Chien - Chung Wu , Chien - Shu Chen , Chien - Chin Wu , Chien - Chin Yang , Chien - Chin Lai , Chien - Chin Su , Chien - Chin Hung , Chien - Chin Chen , Chien - Ching Wu , Chien - Ching Tai , Chien - Ching Li , Chien - Ching Sun , Chien - Ching Liang , Chien - Ching Chen , Chien - Chong Wu , Chien - Chung Chen , Chien - Chung Lai , Chien - Chung Su , Chien - Chung Hung , Chien - Chung",
        "ori-fast-z-score": 0.7844645405527362,
        "water-fast-z-score": 7.060180864974626
    },
    {
        "original_text": "We present an algorithm for quantum search that is based on the Grover s algorithm and uses only two qubits to represent one item in the database, which can be viewed as a binary number. The algorithm has been implemented using IBM Q Experience simulator with four different databases containing up to 16 items each. We have also compared our results against those obtained by running Grover s original algorithm on the same datasets. Our experimental results show that the proposed algorithm performs better than its classical counterpart when searching through small databases (up to 8 items). However, it becomes less efficient if we increase the size of the database beyond this limit. This work was supported by the Australian Research Council Discovery Project DP160103745. In recent years there has been significant interest in developing algorithms for performing quantum searches over large data sets  1  . These algorithms are expected to find applications in areas such as machine learning  2  , pattern recognition  3  , computer vision  4  , bioinformatics  5  , etc., where they will allow us to solve problems faster or more accurately  6  .\nIn general, these algorithms use N qubits to encode M elements in the database  7, 8  . For example, Grover s algorithm  9  requires O( √ N/M ) iterations to find any single element out of M elements encoded into N qubits  10  . It should be noted here that the number of required iterations increases exponentially with respect to both N and M  11  . Therefore, these algorithms become inefficient when dealing with very large databases  12  .",
        "watermark_text": "We introduce an algorithm for quantum search that is based on the Grover s algorithm and using only two qubits to represent one element in the database , which can be viewed as a binary value . The algorithm has been deployed using IBM Q Experience simulator with four different databases containing up to 16 artifacts each .We have already compared our findings against those achieved by running Grover s original method on the same datasets . Our research results show that the suggested method performs better than its classical rival when looking through tiny data ( up to 8 objects ) .However , it becomes slower efficient if we increase the length of the database beyond this limit . This research was supported by the Australian Research Council Discovery Project DP160103745 .In recent years there has been significant interest in building methods for performing quantum searches over large data sets 1 . These methods are expected to find uses in areas such as machine computing 2 , image learning 3 , computer vision 4 , bioinformatics 5 , etc . , where they will let us to solve issues quicker or more accurately 6 .In general , these algorithms use N qubits to encode M elements in the database 7 , 8 . For instance , Grover s algorithm 9 requires O ( √ N / M ) iterations to find any single element out of M elements stored into N qubits 10 .It should be mentioned here that the number of required iterations increases exponentially with regard to both N and M 11 . Therefore , these algorithms get inefficient when dealing with very huge databases 12 .",
        "ori-fast-z-score": -0.19802950859533489,
        "water-fast-z-score": 7.389969586232199
    },
    {
        "original_text": "Circinus X-1 is an X-ray binary system with a neutron star and its companion, which has been observed in many wavelengths ranging from radio to gamma-ray bands. The source shows periodic dipping activity at X-ray energies that are caused by obscuration of the central X-ray emitting region due to matter falling onto the accretion disk around the compact object. In this work we present results obtained using data collected during two different observational campaigns carried out with Suzaku satellite (from 2005 to 2007) and INTEGRAL/IBIS telescope (from 2003 to 2009). We have analyzed the spectral properties of the source for both observations separately as well as combined together. Our analysis reveals that the spectrum can be described by a combination of several components such as: blackbody emission from the neutron star surface; Comptonized component produced by hot plasma surrounding the neutron star; reflection component originating from reprocessing of hard radiation emitted by the central X-ray source into softer photons; iron line feature arising from fluorescence of cold material located close to the neutron star.",
        "watermark_text": "Circinus X - 1 is an X - ray binary system with a neutron star and its companion , which has been observed in multiple wavelengths ranging from radio to gamma - ray bands . The source shows irregular dipping activity at X - ray energies that are created by obscuration of the main X - ray emitting area owing to matter falling onto the accretion disk around the compact body .In this project we present results collected using data taken during two different observational campaigns carried out with Suzaku spacecraft ( from 2005 to 2007 ) and INTEGRAL / IBIS telescope ( from 2003 to 2009 ) . We have analyzed the spectral properties of the origin for both surveys independently as well as combined together .Our study reveals that the spectrum can be described by a combination of several parts such as : blackbody emission from the neutron star surface ; Comptonized component produced by hot plasma surrounding the neutron star ; reflection portion arising from reprocessing of hard radiation emitted by the main X - ray source into stronger photons ; iron line feature arising from fluorescence of cold matter located close to the neutron star .",
        "ori-fast-z-score": 1.801996396010812,
        "water-fast-z-score": 6.041987916036252
    },
    {
        "original_text": "We present an analysis of the basis-set dependence of post-Hartree-Fock (HF) corrections to atomization energies for small molecules, using explicitly correlated Gaussian functions and extrapolation techniques.  We show that the correlation energy contribution is more sensitive than the HF energy to the choice of basis sets used in calculations. The results are compared with those obtained by other authors who have studied this problem previously. Finally we discuss how these findings can be applied to improve the accuracy of thermochemical data calculated at the CCSD(T) level. In recent years there has been considerable interest in improving the accuracy of theoretical predictions of thermochemical properties such as enthalpies of formation or heats of reaction. These quantities are often determined experimentally but it would clearly be useful if they could also be predicted theoretically. One approach which has proved successful involves calculating the total electronic energy E tot  n  of a molecule within some chosen approximation n to quantum mechanics, where n = 1 corresponds to Hartree-Fock theory and n = 2 to second-order Møller-Plesset perturbation theory (MP2). Corrections beyond MP2 may then be estimated either by performing higher-level ab initio calculations on smaller subsets of atoms  1  , or alternatively by fitting empirical parameters to experimental data  2  .",
        "watermark_text": "We present an assessment of the basis - set dependence of post - Hartree - Fock ( HF ) corrections to atomization energies for little molecules , using explicitly coupled Gaussian functions and extrapolation methods . We see that the correlation power contribution is more sensitive than the HF power to the selection of basis sets involved in calculations .The results are compared with those acquired by other researchers who have researched this question previously . Finally we talk how these results can be applied to improve the accuracy of thermochemical data calculated at the CCSD ( T ) level .In recent years there has been substantial interest in improving the accuracy of theoretical estimates of thermochemical properties such as enthalpies of formation or heats of reaction . These quantities are often determined experimentally but it would clearly be valuable if they could also be determined theoretically .One approach which has found successful means measuring the total electronic energy E tot n of a molecule within some selected approximation n to quantum mechanics , where n = 1 corresponds to Hartree - Fock physics and n = 2 to second - order Møller - Plesset perturbation theory ( MP2 ) . Corrections beyond MP2 might then be estimated either by performing higher - grade ab initio analyses on smaller subsets of atoms 1 , or alternatively by fitting experimental parameters to experimental data 2 .",
        "ori-fast-z-score": -0.7035264706814485,
        "water-fast-z-score": 5.050762722761053
    },
    {
        "original_text": "We present new observations of three protostellar cores in Orion B, which are among the youngest known prestellar objects. The data were obtained with the Submillimeter Array (SMA) at 1.3 mm and 0.87 mm wavelengths as part of an ongoing survey to study the earliest stages of star formation. We find that all three sources show evidence for infall motions on scales ranging between 1000 AU and 10000 AU. In addition, we detect outflows associated with two of these sources. These results suggest that the first phase of star formation is characterized by rapid mass accretion onto the central object through a circumstellar disk. This process may be triggered by gravitational collapse or magneto-rotational instabilities within the core. Finally, our SMA maps reveal extended emission around each source, which could represent either flattened envelopes or disks surrounding the protostar. Our findings provide important constraints on theoretical models describing the early evolution of young stellar objects.",
        "watermark_text": "We report new studies of three protostellar cores in Orion B , which are among the youngest known prestellar objects . The data were obtained with the Submillimeter Array ( SMA ) at 1 . 3 cm and 0 . 87 mm wavelengths as part of an continuing survey to study the earliest periods of star formation .We see that all three reports show proof for infall motions on scales ranging between 1000 AU and 10000 AU . In addition , we find outflows associated with two of these sources .These data suggest that the first phase of star formation is characterized by rapid mass accretion onto the main object through a circumstellar disk . This process may be triggered by gravitational failure or magneto - rotational instabilities within the core .Finally , our SMA images produce extended emission around each source , which could indicate either flattened envelopes or disks circling the protostar . Our findings provide important restrictions on theoretical theories describing the early evolved of young stellar bodies .",
        "ori-fast-z-score": 0.47809144373375745,
        "water-fast-z-score": 5.976143046671968
    },
    {
        "original_text": "The structure and dynamics of lipid membranes are important for many biological processes, such as cell division or protein transport across the membrane. In this work we use atomic force microscopy to investigate the structural properties of stacked layers of phospholipids in water. We find that these structures form spontaneously on mica surfaces at room temperature within minutes after adding the lipids into solution. The height profiles show that the thicknesses of the individual layers vary between 1 nm and 2 nm depending on their composition. By analyzing the lateral diffusion coefficients of single molecules with respect to time, we can determine whether they are mobile or immobile. Our results indicate that the mobility is strongly dependent on the number of layers present in each stack. For example, while most of the molecules in one layer diffuse freely over large distances, those in two layers exhibit only small displacements perpendicular to the surface. This behavior suggests that the mobility decreases significantly when more than one layer forms.",
        "watermark_text": "The structure and dynamics of lipid membranes are important for numerous biological events , such as cell division or protein transport across the membrane . In this research we utilize atomic force microscopy to examine the structural structure of piled sheets of phospholipids in water .We see that these structures create spontaneously on mica surfaces at room temperature within moments after addition the lipids into solution . The height profiles indicate that the thicknesses of the individual layers varies between 1 nm and 2 nm depending on their composition .By analyzing the longitudinal diffusion coefficients of single particles with regard to time , we can determine whether they are portable or immobile . Our results show that the mobility is strongly dependent on the quantity of elements contained in each stack .For instance , while most of the molecules in one layer diffuse widely over large distances , those in two sheets experience only tiny displacements parallel to the surface . This phenomenon suggests that the mobility decreases dramatically when more than one surface exists .",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 5.8119893994415355
    },
    {
        "original_text": "We study the ground state properties of the spin-1/2 square lattice with nearest-neighbor antiferromagnetic interactions and vacancies, using exact diagonalization (ED) on finite clusters up to 12x12 sites. We find that for low concentrations of vacancies there is no significant change in the magnetic order parameter or the energy gap between singlet and triplet excitations as compared to the pure system. However, we observe an increase in the density of states at zero energy when increasing the concentration of vacancies. This effect can be explained by considering the formation of bound pairs of vacancies which are localized around each other due to their mutual interaction. The binding energies of these pairs depend strongly on the distance between them but only weakly on the size of the cluster considered. In addition, we show how this behavior changes if one considers next-nearest neighbor interactions instead of nearest-neighbor ones. Finally, we discuss possible experimental realizations of our results.",
        "watermark_text": "We research the ground state properties of the spin - 1 / 2 square lattice with nearest - neighbor antiferromagnetic interactions and vacancies , using accurate diagonalization ( ED ) on polynomial clusters up to 12x12 places . We see that for low levels of vacancies there is no major shift in the magnetic order parameter or the power gap between singlet and triplet excitations as compared to the pure system .However , we perceive an increase in the density of states at zero energy when increasing the density of vacancies . This phenomenon can be described by using the formation of bound pairs of vacancies which are localized around each other owing to their mutual interaction .The activation energies of these pairs depend greatly on the distance between them but only weakly on the length of the cluster considered . In addition , we show how this behavior changes if one considers next - nearest neighbor interactions instead of nearest - neighbor ones .Finally , we explain possible experimental realizations of our findings .",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "We present the results of our investigation into accretion disk continuum emission in black hole candidates (BHCs). We have developed an analytical model for calculating the spectrum emitted by a thin, optically thick accretion disk around a Schwarzschild black hole and applied it to several BHCs with known mass functions. The observed spectra are well reproduced when we assume that the inner edge of the disk is located at 6 gravitational radii. This result suggests that the standard thin disk model can be used as a good approximation for modeling the X-ray continuum emission of these objects. \n \n Keywords: Black holes -- Spectroscopy -- X-rays -- Modeling -- Accretion disks -- Emission lines -- Broad-band spectral energy distribution -- Luminosity function -- Mass measurement -- Stellar-mass black holes -- Supermassive black holes -- Active galactic nuclei -- Quasars -- Cosmic evolution \n \n \n \n 1 Introduction \n \n In recent years there has been considerable progress made towards understanding the physical processes occurring near supermassive black holes (SMBH) in active galactic nuclei (AGN), quasars, and other similar systems. These studies rely on observations of the broad-band spectral energy distributions (SEDs) of SMBHs over many decades in frequency space. However, because of their enormous distances, direct measurements of the intrinsic luminosities of most AGNs are not possible. Instead, one must use indirect methods such as reverberation mapping or statistical correlations between various properties of AGNs to determine their luminosities. For example, if one knows how much light passes through some region of interest within an AGN then one may calculate its luminosity using simple geometric arguments. Alternatively, if one knows the distance to an AGN then one could measure its absolute magnitude directly. Unfortunately, both of these approaches require detailed knowledge about the structure of the emitting regions which cannot currently be obtained observationally. Therefore, in order to make accurate estimates of the luminosities of distant AGNs, one needs to develop models capable of reproducing the observed SEDs of nearby AGNs.",
        "watermark_text": "We present the conclusion of our inquiry into accretion disk continuum emission in black hole candidates ( BHCs ) . We have developed an analytical theory for determining the spectrum emitted by a thin , optically dense accretion disk around a Schwarzschild red hole and applied it to several BHCs with reported mass distributions .The observed spectra are better illustrated when we suppose that the inner corner of the disk is situated at 6 gravitational radii . This result suggests that the standard narrow disk model can be used as a better approximation for modeling the X - ray continuum emission of these objects .Keywords : Black holes - - Spectroscopy - - X - rays - - Modeling - - Accretion disks - - Emission lines - - Broad - band spectral energy distribution - - Luminosity function - - Mass measurement - - Stellar - mass black holes - - Supermassive black holes - - Active galactic nuclei - - Quasars - - Cosmic evolution 1 Introduction In recent years there has been increased progress conducted towards exploring the physical processes occurring near supermassive black holes ( SMBH ) in active galactic nuclei ( AGN ) , quasars , and other similar systems . These studies rely on observations of the broad - band spectral energy distributions ( SEDs ) of SMBHs over many decades in frequency space .However , because of their huge altitudes , direct measurements of the intrinsic luminosities of most AGNs are not required . Rather , one must use indirect tools such as reverberation projection or statistical correlations between various properties of AGNs to obtain their luminosities .For instance , if one remembers how many light passes through some region of interest within an AGN then one may calculate its luminosity taking simple geometric arguments . Alternatively , if one understands the distance to an AGN then one might estimate its absolute magnitude directly .Unfortunately , both of these perspectives need rigorous knowledge about the composition of the emitting regions which lacks already be obtained observationally . Therefore , in order to make accurate calculations of the luminosities of distant AGNs , one needs to develop models capable of reproducing the known SEDs of neighbouring AGNs .",
        "ori-fast-z-score": -0.9733285267845753,
        "water-fast-z-score": 5.028864055053639
    },
    {
        "original_text": "We propose an improved metric on the space of worldsheet sigma model couplings that is suitable to study gradient renormalization group flows beyond first order in perturbation theory. The new metric has several advantages over previous proposals, including manifestly positive kinetic terms and no need for additional counterterms at higher orders. We show how this metric can be used to compute beta functions up to third order in perturbation theory using only Feynman diagrams with one-loop vacuum bubbles as building blocks. This allows us to obtain results for the beta function of the dilaton coupling to the Ricci scalar which are consistent with those obtained by other methods but have not been previously available due to technical difficulties. In addition we find evidence for non-trivial fixed points in the beta function of the string coupling constant. These results provide further support for the idea that the worldsheet sigma model may serve as a useful tool for studying quantum gravity. Introduction: It was recently shown  1  that the worldsheet sigma-model (WSSM) provides a powerful framework for investigating quantum gravity via its connection to the gravitational path integral  2  . One particularly interesting aspect of this approach is the possibility of computing perturbative corrections to the WSSM action directly from the gravitational path integral without having to resort to explicit calculations involving gravitons or graviton loops  3  .\nIn  4  it was proposed that the WSSM could also be used to investigate the flow of the effective action under the renormalization group (RG). However, since the WSSM contains infinitely many degrees of freedom there does not exist any finite dimensional parameter space where the RG flow takes place. Instead, the RG flow must take place along some infinite-dimensional trajectory through the space of all possible actions. To make progress towards understanding such trajectories it would be helpful if one were able to define a sensible metric on the space of WSSM actions so that distances between different actions could be measured. Such a metric should allow one to determine whether two given actions lie close together or far apart in the space of all possible WSSMs.",
        "watermark_text": "We suggest an better metric on the space of worldsheet sigma model couplings that is suitable to study gradient renormalization group flows beyond first order in perturbation theory . The updated metric has numerous benefits over past proposals , notably manifestly strong kinetic terms and no requirement for additional counterterms at higher orders .We see how this metric can be used to compute beta functions up to third order in perturbation theory employing only Feynman diagrams with one - ring vacuum bubbles as building blocks . This enables us to obtain results for the beta function of the dilaton coupling to the Ricci scalar which are compatible with those achieved by other methods but have not been previously available owing to technical problems .In addition we find proof for non - trivial fixing points in the beta function of the string coupling constant . These conclusions provide further evidence for the idea that the worldsheet sigma approach may serve as a helpful resource for studying quantum gravitational .Introduction : It was recently shown 1 that the worldsheet sigma - model ( WSSM ) presents a powerful framework for investigating quantum gravitational via its connection to the gravitational path integral 2 . One especially interesting aspect of this methodology is the prospect of computing perturbative corrections to the WSSM action directly from the gravitational path integral without having to resort to explicit experiments concerning gravitons or graviton loops 3 .In 4 it was suggested that the WSSM could also be used to examine the flow of the effective act under the renormalization group ( RG ) . However , since the WSSM contains infinitely many degrees of liberty there does not exist any finite dimensional parameter area where the RG flow takes place .Instead , the RG flow must take place along some infinite - dimensional trajectory through the space of all possible actions . To build progress towards studying such trajectories it would be nice if one were trying to define a practical metric on the space of WSSM actions so that lengths between multiple movements could be measured .Such a metric should enable one to estimate whether two given actions sit close together or far separated in the space of all possible WSSMs .",
        "ori-fast-z-score": 0.7715167498104595,
        "water-fast-z-score": 8.33543833063041
    },
    {
        "original_text": "We introduce the notion of dynamical objects associated to cohomologically expanding maps, and prove that they are equivalent to the usual ones in many cases.  We also show how these new objects can be used to study the dynamics of such maps on infinite-dimensional spaces. Let X be an infinite dimensional Banach space with norm . For each integer n ≥ 1 we define the open ball B(n) = {x ∈ X : x < n}. A map T : X → X is said to be cohomologically expanding if there exists some constant C > 0 so that for all integers m, n ≥ 1 one has  diam (T −m (B(n))) ≤ Cn. In this case it follows easily that T satisfies the following properties:\n(1)  T is continuous; \n(2)  T is surjective; \nThe main result of our work shows that under certain conditions, the existence of a dynamical object implies the existence of another one which behaves well when restricted to finite-dimensional subspaces. \nLet us now recall what a dynamical object is. Given any point x ∈ X , let O(x) denote the orbit of x; i.e., O(x) := {T k (x), k ∈ Z}. The set O(x) equipped with the metric dO defined by dO((x1, x2)) = sup{d(x1, x2), x1 ∈ O(x2), x2 ∈ O(x1)} becomes a compact metric space called the orbital space at x. If T is cohomologically expanding then every orbital space is homeomorphic to a Cantor set.",
        "watermark_text": "We introduce the notion of dynamical images attached to cohomologically extended spaces , and prove that they are analogous to the usual ones in many situations . We also demonstrate how these new objects can be used to study the dynamics of such maps on infinite - dimensional spaces .Let X be an infinite dimensional Banach space with norm . For each integer n ≥ 1 we define the open ball B ( n ) = { x ∈ X : x < n } .A mapping T : X → X is said to be cohomologically extended if there exists some variable C > 0 so that for all numbers m , n ≥ 1 one has diam ( T −m ( B ( n ) ) ) ≤ Cn . In this instance it appears easily that T satisfies the following properties : ( 1 ) T is continuous ; ( 2 ) T is surjective ; The main consequence of our work proves that under certain conditions , the existence of a dynamical object suggests the existence of another one which behaves well when confined to finite - dimensional subspaces .Let us now recall what a dynamical object is . Given any point x ∈ X , let O ( x ) define the orbit of x ; i . e . , O ( x ) : = { T k ( x ) , k ∈ Z } .The set O ( x ) equipped with the metric dO defined by dO ( ( x1 , x2 ) ) = sup { d ( x1 , x2 ) , x1 ∈ O ( x2 ) , x2 ∈ O ( x1 ) } becomes a compact metric space termed the orbital space at x . If T is cohomologically extended then every orbital space is homeomorphic to a Cantor set .",
        "ori-fast-z-score": 0.6123724356957946,
        "water-fast-z-score": 4.569057743101286
    },
    {
        "original_text": "We present evidence for dark matter annihilation in the cosmic microwave background (CMB) haze, which is an excess emission at large angles with respect to the Galactic center that was first detected by Wilkinson Microwave Anisotropy Probe (WMAP). We use data from Planck and Fermi Large Area Telescope (LAT), as well as new measurements of the CMB temperature anisotropies made using the Atacama Cosmology Telescope (ACT).\nThe observed spectrum of this signal can be explained if it originates from dark matter particles with masses between 1 GeV and 10 TeV, annihilating into pairs of photons or leptons. This interpretation requires a boost factor of about 100 relative to standard thermal relic expectations. \n \n If confirmed, our results would provide strong support for models where dark matter self-annihilates into Standard Model particles. They also have important implications on the nature of dark matter itself, since they require either non-thermal production mechanisms or additional interactions beyond those predicted within the minimal supersymmetric extension of the Standard Model.",
        "watermark_text": "We present evidence for black material annihilation in the cosmic microwave background ( CMB ) fog , which is an excess emission at large angles with regard to the Galactic center that was first detected by Wilkinson Microwave Anisotropy Probe ( WMAP ) . We use data from Planck and Fermi Large Area Telescope ( LAT ) , as well as new studies of the CMB altitude anisotropies made using the Atacama Cosmology Telescope ( ACT ) .The observed spectrum of this signal can be understood if it originates from dark matter molecules with masses between 1 GeV and 10 TeV , annihilating into sets of photons or leptons . This interpretation needs a boost factor of about 100 compared to standard temperature relic estimates .If confirmed , our findings would offer strong evidence for models where bright particles self - annihilates into Standard Model particles . They especially have important implications on the nature of bright matter itself , since they demand either non - temperature generation pathways or additional interactions beyond those predicted within the minimal supersymmetric extension of the Standard Model .",
        "ori-fast-z-score": 0.7276068751089989,
        "water-fast-z-score": 5.578319375835658
    },
    {
        "original_text": "We report on the detection and characterization of microwave continuum emission from air shower plasmas using data collected by the LOPES experiment in Germany during 2004-2006. The observed signal is consistent with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers, as predicted by theory. We find no evidence for any significant contribution from incoherent synchrotron or bremsstrahlung processes. These results provide new insights into the physics of cosmic ray interactions at high energy. They also demonstrate the potential utility of radio techniques for studying atmospheric phenomena such as thunderstorms. \n \n Keywords: Cosmic rays, Radio waves, Air showers, Coherence, Synchrotron radiation \n \n \n \n 1 Introduction \n \n In recent years there has been growing interest in developing novel methods for detecting ultra-high-energy (UHE) cosmic rays based upon their interaction with Earth s atmosphere  1  . One promising technique involves measuring the radio-frequency (RF) emission produced when UHE particles interact with molecules in the upper atmosphere  2  , which can be detected remotely over large areas  3  .\n \nThe most prominent feature of this RF emission is an intense broadband pulse lasting several microseconds  4  . This pulse arises because the charged particle cascade generated by each primary cosmic ray interacts strongly with the geomagnetic field, causing it to emit coherently across a wide range of frequencies  5  . However, other mechanisms may contribute significantly to the total RF emission  6  . \n \n Here we present observations made with the Low-Frequency Array (LOFAR), one component of the International LOFAR Telescope  7  . Our analysis focuses primarily on measurements taken between 2004 and 2006 with the Long Wavelength Array (LWA)  8  , a phased array consisting of 144 dual-polarized dipole antennas operating at wavelengths ranging from 10 m to 80 m  9  . During these three years, LWA was deployed near Karthaus Township, Germany  10  , where it recorded signals from more than 20 million cosmic-ray-induced air showers  11  .",
        "watermark_text": "We report on the characterization and description of microwave continuum emission from air spray plasmas using data taken by the LOPES experiment in Germany during 2004 - 2006 . The observed light is compatible with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers , as predicted by theory .We see no evidence for any large contribution from incoherent synchrotron or bremsstrahlung interactions . These data provide fresh insights into the physics of cosmic ray interactions at high energy .They especially demonstrate the possibilities utility of radio methods for studying air events such as thunderstorms . Keywords : Cosmic rays , Radio beams , Air showers , Coherence , Synchrotron emission 1 Introduction In recent years there has been growing interest in establishing novel techniques for detecting ultra - large - energy ( UHE ) cosmic rays based upon their association with Earth s atmosphere 1 .One promising hypothesis includes monitoring the television - frequency ( RF ) emission generated when UHE ions contact with compounds in the higher atmosphere 2 , which can be identified remotely over large areas 3 . The most notable feature of this RF absorption is an intense broadband wave lasting several microseconds 4 .This wave exists because the charged particle cascade generated by each main cosmic ray interacts heavily with the geomagnetic field , forcing it to emit coherently across a broad variety of rates 5 . However , other mechanisms may contribute greatly to the total RF radiation 6 .Here we present observations made with the Low - Frequency Array ( LOFAR ) , one element of the International LOFAR Telescope 7 . Our study consists primarily on observations made between 2004 and 2006 with the Long Wavelength Array ( LWA ) 8 , a phased array consisting of 144 multiple - polarized dipole antennas active at wavelengths ranging from 10 m to 80 m 9 .During these three years , LWA was deployed near Karthaus Township , Germany 10 , where it recorded transmissions from more than 20 million cosmic - ray - caused air showers 11 .",
        "ori-fast-z-score": -1.4631270419005797,
        "water-fast-z-score": 8.060433501697915
    },
    {
        "original_text": "We present the first results on the use of infrared calcium lines to determine stellar metallicities in open clusters and field stars, based on high-resolution spectra obtained with the CRIRES spectrograph at VLT/UT1 (ESO). We find that the equivalent widths of the two strongest components of the infrared Ca II triplet are strongly correlated with  Fe/H  for both cluster members and field stars.  The calibration is valid over a wide range of temperatures, including those typical of red giants. This method can be used to obtain accurate estimates of the iron abundance even when only low resolution data are available. It also provides an alternative way to estimate distances using parallaxes measured by space missions such as Hipparcos or Gaia. Keywords: Calcium, Metallicity, Red giant branch star, Open cluster, Infrared spectrum, Iron abundance, Distance determination, Space mission, High-Resolution spectroscopy",
        "watermark_text": "We present the first findings on the using of laser calcium bands to estimate stellar metallicities in open complexes and field stars , using on wide - resolution spectra obtained with the CRIRES spectrograph at VLT / UT1 ( ESO ) . We see that the equivalent widths of the two strongest elements of the infrared Ca II triplet are strongly correlated with Fe / H for both cluster groups and field stars .The calibration is valid over a broad variety of conditions , particularly those common of red giants . This method can be used to obtain precise estimates of the metal density even when only low resolution data are available .It additionally offers an additional means to estimate distances using parallaxes measured by space missions such as Hipparcos or Gaia . Keywords : Calcium , Metallicity , Red giant branch star , Open cluster , Infrared spectrum , Iron concentration , Distance finding , Space mission , High - Resolution spectroscopy",
        "ori-fast-z-score": -1.099524999206747,
        "water-fast-z-score": 5.0089472186085136
    },
    {
        "original_text": "We consider the problem of energy-efficient modulation for downlink transmissions over code-division multiple-access (CDMA) networks, where each user has an individual delay constraint and is equipped with a rechargeable battery that can be charged by harvesting ambient radio-frequency signals. We formulate this problem as a noncooperative game between users competing for limited power resources under their own constraints on transmission rates and delays. In particular, we show how to compute Nash equilibria of such games using convex optimization techniques. Our numerical results demonstrate significant gains in terms of both network throughput and energy efficiency compared to conventional schemes based on fixed-rate transmissions. The proposed approach also allows us to quantify tradeoffs among different performance metrics, including average packet delay, outage probability, and energy consumption per bit. This work was supported by NSF grants CNS-0932040 and CCF-0939370. \n \n Code available at http://arxiv.org/abs/1206.5481",
        "watermark_text": "We consider the issue of electricity - efficient modulation for downlink transmissions over code - division multiple - access ( CDMA ) networks , where each consumer has an individual delay constraint and is equipped with a rechargeable battery that can be charged by collecting ambient broadcast - frequency signals . We formulate this situation as a noncooperative contest between operators competing for limited power assets under their own restrictions on transmission rates and delays .In particular , we study how to compute Nash equilibria of such players utilizing convex optimization schemes . Our numerical findings show considerable gains in terms of both network throughput and energy efficiency compared to conventional systems relying on fixed - frequency transmissions .The proposed approach also enables us to quantify tradeoffs among different performance metrics , notably mean packet delay , outage likelihood , and energy consumption per bit . This effort was supported by NSF grants CNS - 0932040 and CCF - 0939370 .Code available at http : / / arxiv . org / abs / 1206 . 5481",
        "ori-fast-z-score": -1.0392304845413263,
        "water-fast-z-score": 5.114896104728048
    },
    {
        "original_text": "We study the UV behavior of gauged chiral supergravities in six dimensions, focusing on their possible supersymmetric AdS 7 vacua. We show that these theories are not free at high energies but instead have an interacting fixed point with a finite number of degrees of freedom. This is achieved by using the recently developed technique of holographic renormalization to compute the beta functions of the gauge coupling constants as well as those associated with higher-derivative terms in the action. The latter can be used to stabilize the scalar potential against quantum corrections. In particular we find that there exists a large class of models which admit metastable de Sitter solutions. These results provide further evidence for the existence of stable non-supersymmetric AdS 7 vacuua in this context. Introduction: Recently it has been shown  1  that certain classes of N = 1 superconformal field theories (SCFTs) in four dimensions may be realized via compactifications of type IIA string theory on Calabi-Yau threefolds X 3 . It was also found  2  that such constructions generically lead to massive gravitons in five dimensions whose masses scale like M 2 grav ∝ V −3 , where V denotes the volume of X 3 . As a result one expects that the effective gravitational constant G 5 will run logarithmically with energy  3  .\nIn  4  it was suggested that this running could be stopped if one considers non-perturbative effects due to Euclidean D3-branes wrapping special Lagrangian cycles L ∈ H 4 (X 3 ; Z). Indeed, it turns out that the corresponding instanton contributions generate a term proportional to R ∧ R in the lowenergy effective action  5  . If this term dominates over other contributions then the resulting vacuum solution should correspond to anti-de Sitter space  6  . Moreover, since the instanton contribution scales like e −1/g s , where g s denotes the string coupling constant, one finds that the radius of curvature of the anti-de Sitter space decreases exponentially fast when approaching weak coupling  7, 8  . Thus, in order to obtain a phenomen",
        "watermark_text": "We research the UV interactions of gauged chiral supergravities in six dimensions , concentrating on their possible supersymmetric AdS 7 vacua . We see that these theories are not free at high energies but instead have an interacting fixed point with a finite number of degrees of liberty .This is achieved by using the recently advanced technique of holographic renormalization to compute the beta functions of the gauge interaction constants as well as those associated with higher - derivative terms in the action . The latter can be used to stabilize the scalar current against quantum corrections .In particular we find that there exists a large class of models which admit metastable de Sitter solutions . These data provide further evidence for the existence of stable non - supersymmetric AdS 7 vacuua in this context .Introduction : Recently it has been shown 1 that particular categories of N = 1 superconformal field theories ( SCFTs ) in four dimensions may be realized via compactifications of type IIA string theory on Calabi - Yau threefolds X 3 . It was also discovered 2 that such constructions generically lead to massive gravitons in five dimensions whose masses range like M 2 grav [UNK] V −3 , where V denotes the volume of X 3 .As a result one expects that the effective gravitational constant G 5 will go logarithmically with energy 3 . In 4 it was suggested that this run could be halted if one considers non - perturbative properties due to Euclidean D3 - branes wrapping special Lagrangian curves L ∈ H 4 ( X 3 ; Z ) .Indeed , it turns out that the associated instanton contributions create a word proportional to R ∧ R in the lowenergy efficient action 5 . If this term dominates over other contributions then the resulting vacuum problem should approximate to anti - de Sitter space 6 .Moreover , since the instanton contribution varies like e −1 / g s , where g s indicates the string coupling constant , one discovers that the radius of curvature of the anti - de Sitter space reduces exponentially rapidly when approaching weak interaction 7 , 8 . Thus , in order to obtain a phenomen",
        "ori-fast-z-score": -0.26413527189768715,
        "water-fast-z-score": 5.396407334626633
    },
    {
        "original_text": "We report the discovery of an unusual object in the outer solar system that is likely to be composed primarily of ice particles. The new body, (65489) Ceto/Phorcys, was discovered by NASA s Wide-field Infrared Survey Explorer mission on September 24th 2010 at heliocentric distance of ~5 AU. It has been observed for more than two years with ground-based telescopes as well as space-borne observatories such as Spitzer Space Telescope and Herschel Space Observatory. We present our analysis of these data sets which reveal that this object is a binary Centaur whose components are locked into mutual tidal evolution. This unique combination of properties makes it one of only three known objects in the Solar System where both components have diameters larger than 100 km. Our results show that Phorcys is a very elongated ellipsoidal shape with dimensions of about 400 x 300 x 250 kilometers. Its surface temperature is estimated to be around -100 degrees Celsius.",
        "watermark_text": "We report the discovery of an unique body in the outer solar system that is probably to be composed primarily of ice particles . The newest body , ( 65489 ) Ceto / Phorcys , was discovered by NASA s Wide - field Infrared Survey Explorer mission on September 24th 2010 at heliocentric height of ~ 5 AU .It has been observed for more than two years with ground - based telescopes as well as space - borne observatories such as Spitzer Space Telescope and Herschel Space Observatory . We present our analysis of these information sets which confirm that this body is a binary Centaur whose components are locked into mutual tidal evolution .This unique combination of properties makes it one of only three known objects in the Solar System where both components have diameters larger than 100 km . Our results show that Phorcys is a very elongated ellipsoidal structure with sizes of about 400 x 300 x 250 meter .Its surface temperature is predicted to be around - 100 degrees Celsius .",
        "ori-fast-z-score": 1.8382900600361156,
        "water-fast-z-score": 5.252257314388902
    },
    {
        "original_text": "We report on our analysis of the Suzaku observation of the z = 1.55 quasar, RBS 315 (RA=00h45m53.6s; DEC=-36d19 59.6 ). The source is detected with an average 2-10 keV flux of 4 x 10^-13 erg cm-2 s-1 corresponding to a luminosity of 3 x 10^44 erg s-1 at this redshift. We find that the spectrum can be well fitted by a power law model modified by Galactic absorption plus reflection component using pexrav model in XSPEC. This gives photon index Γ=1.9 +0.2 -0.1 , reflection fraction f=0.7 +1.0 -1.3 . The observed 0.5-7 keV band luminosity is found to be 5x10^43 erg/sec which corresponds to Eddington ratio L/L edd =0.01-0.03 assuming black hole mass M BH ~10 9 M sun .",
        "watermark_text": "We report on our analysis of the Suzaku observation of the z = 1 . 55 quasar , RBS 315 ( RA = 00h45m53 . 6s ; DEC = - 36d19 59 . 6 ) . The source is detected with an estimated 2 - 10 keV flux of 4 x 10 ^ - 13 erg centimetres - 2 s - 1 resulting to a luminosity of 3 x 10 ^ 44 erg s - 1 at this redshift .We see that the spectrum can be well fitted by a power law theory derived by Galactic absorption plus reflection factor used pexrav system in XSPEC . This gives photon index Γ = 1 . 9 + 0 . 2 - 0 . 1 , absorption proportion f = 0 . 7 + 1 . 0 - 1 . 3 .The observed 0 . 5 - 7 keV band luminosity is found to be 5x10 ^ 43 erg / sec which equals to Eddington ratio L / L edd = 0 . 01 - 0 . 03 assuming black hole weight M BH ~ 10 9 M sun .",
        "ori-fast-z-score": -0.31622776601683794,
        "water-fast-z-score": 2.846049894151541
    },
    {
        "original_text": "In this work, we propose an adaptive service provisioning scheme to provide quality-of-service (QoS) guarantees and maximize the network utility by jointly optimizing resource allocation at both base stations (BSs) and mobile users (MUs). The proposed scheme is based on a communication model that incorporates user mobility into the QoS requirements. We formulate the problem as a joint optimization over BSs  power control variables, MUs  transmission rates, and their association with BSs. To solve it efficiently, we first decompose the original problem into two subproblems: one for each BS and another for all MUs. Then, we develop distributed algorithms to obtain solutions to these problems iteratively using dual decomposition techniques. Finally, simulation results show that our proposed algorithm can achieve better performance than existing schemes under various system settings. In recent years, wireless networks have been widely deployed around the world due to their low cost and easy deployment  1  . However, they are vulnerable to security attacks such as eavesdropping  2  , jamming  3  , and data tampering  4  .\nTo enhance the security level of wireless communications, physical layer security has attracted much attention recently  5  -  8  . Physical layer security exploits the characteristics of the wireless channel to ensure secure transmissions without relying on any additional cryptographic keys or protocols  9  . It was shown in  10  that if the legitimate transmitter-receiver pair shares no common information about the statistical properties of the channels between them and other potential eavesdroppers, then perfect secrecy cannot be achieved even when there exists infinite number of antennas at the transmitter side. Therefore, practical approaches should consider imperfections in the estimation process  11  , limited transmit power  12  , and finite antenna numbers  13  .",
        "watermark_text": "In this project , we propose an adaptive system provisioning scheme to provide quality - of - service ( QoS ) guarantees and maximize the service utility by jointly optimizing resource allocation at both base places ( BSs ) and portable consumers ( MUs ) . The proposed system is based on a communication plan that incorporates user connectivity into the QoS specifications .We formulate the question as a joint optimization over BSs power control factors , MUs transmission rates , and their association with BSs . To solve it easily , we first decompose the original problem into two subproblems : one for each BS and another for all MUs .Then , we develop dispersed schemes to obtain answers to these problems iteratively utilizing double decomposition techniques . Finally , simulation data demonstrate that our proposed algorithm can attain better performance than existing strategies under various system situations .In recent years , wireless networks have been widely deployed around the world thanks to their low cost and easy deployment 1 . However , they are susceptible to security attacks such as eavesdropping 2 , jamming 3 , and information tampering 4 .To increase the protection quality of mobile communications , physical layer security has garnered considerable scrutiny recently 5 - 8 . Physical layer security exploits the attributes of the wireless network to ensure safe communication without relying on any additional cryptographic codes or technologies 9 .It was shown in 10 that if the legitimate transmitter - receiver pair shares no shared information about the statistical characteristics of the channels between them and other potential eavesdroppers , then perfect secrecy fails be obtained even when there exists infinite quantity of antennas at the receiver side . Therefore , practical techniques should consider imperfections in the estimation method 11 , limited transmit energy 12 , and finite antenna numbers 13 .",
        "ori-fast-z-score": 0.5895063447465633,
        "water-fast-z-score": 7.7754191435023525
    },
    {
        "original_text": "SDSS J121811+465501 is an extremely faint galaxy discovered in the Sloan Digital Sky Survey (SDSS). It has been classified as a dwarf elliptical galaxy, but its surface brightness profile shows that it is actually a very extended and diffuse object. We have obtained deep optical spectroscopy for this galaxy using the Gemini Multi-Object Spectrograph on Gemini North telescope to study its physical properties. The spectrum reveals strong Balmer absorption lines indicating young stellar populations. Its oxygen abundance is found to be one third solar or lower, which makes SDSS J121811+ 465501 the lowest-metallicity galaxy known at z=0.1. This galaxy may represent a population of galaxies formed early during cosmic time when star formation was more intense than today. Keywords: Dwarf Elliptical Galaxy, Oxygen Abundance, Gemini Observatory, Sloan Digital Sky Survey, Low Surface Brightness",
        "watermark_text": "SDSS J121811 + 465501 is an incredibly faint galaxy discovered in the Sloan Digital Sky Survey ( SDSS ) . It has been classified as a dwarf elliptical galaxy , but its surface brightness profile reveals that it is actually a very extended and diffuse object .We have achieved dark optical spectroscopy for this galaxy using the Gemini Multi - Object Spectrograph on Gemini North telescope to study its physical properties . The spectrum reveals large Balmer spectral lines suggesting young stellar regions .Its oxygen abundance is found to be one third solar or smaller , which makes SDSS J121811 + 465501 the smallest - metallicity galaxy known at z = 0 . 1 . This galaxy might represent a population of galaxies formed early during cosmic time when galaxy formation was more intense than tomorrow .Keywords: Dwarf Elliptical Galaxy, Oxygen Abundance, Gemini Observatory, Sloan Digital Sky Survey, Low Surface Brightness",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 4.810702354423639
    },
    {
        "original_text": "We consider the problem of linear regression with measurement error, where the errors are assumed to be normally distributed and uncorrelated between different measurements but correlated within each measurement set (i.e., for one given star). We derive an expression for the covariance matrix of the estimated parameters which is valid even if the number of data points per measurement set differs significantly among sets. This allows us to study how the accuracy of the results depends on the distribution of the number of observations over all stars. The derived formula can also be used as a tool for optimizing observational strategies by minimizing the uncertainty of the resulting estimates. In particular we show that it may be advantageous to use only a small fraction of available data points when estimating the coefficients of the model function while using most or all data points for determining its first few derivatives. Finally, we apply our method to simulated data obtained from the Hipparcos astrometric satellite mission.",
        "watermark_text": "We consider the question of linear regression with measurement loss , where the errors are expected to be usually spread and uncorrelated between various measurements but correlated within each measurement set ( i . e . , for one given star ) . We derive an expression for the covariance matrix of the expected variables which is valid even if the proportion of data points per observation set differs greatly among setting .This enables us to study how the accuracy of the results varies on the distribution of the proportion of measurements over all stars . The derived formula can also be used as a tool for optimizing observational strategies by minimizing the uncertainty of the resulting estimates .In particular we prove that it could be advantageous to use only a small fraction of available data points when estimating the coefficients of the model function while using most or all information points for determining its initial few derivatives . Finally , we apply our technique to simulated images obtained from the Hipparcos astrometric satellite mission .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.047146145152358
    },
    {
        "original_text": "We present an analytical model for the growth, radial drift and fragmentation of dust grains in protoplanetary disks that evolve under the combined effects of viscous accretion onto the central star and photoevaporation by external radiation fields. We show how these processes affect the evolution of grain size distributions as well as their spatial distribution within the disk. In particular we find that: (i) The maximum grain sizes are limited to values between 1 mm and 10 cm depending on the strength of the stellar UV field. (ii) Grains grow faster at larger distances from the star due to lower gas densities and higher temperatures. (iii) Fragmentation is more efficient closer to the star where the local pressure maxima lead to enhanced collisional velocities.  These results have important implications for planet formation scenarios since they suggest that planetesimals can form only close to the star while large bodies such as asteroids or comets may be able to form farther out in the disk.",
        "watermark_text": "We present an analytical theory for the development , radial drift and fragmentation of dust grains in protoplanetary disks that develop under the combined influences of viscous accretion onto the main star and photoevaporation by external emission fields . We see how these mechanisms affect the evolution of grain length distributions as well as their temporal distribution within the disk .In particular we find that : ( i ) The maximum grain sizes are limited to values between 1 mm and 10 mm depending on the strength of the stellar UV field . ( ii ) Grains grow better at larger distances from the star due to higher gas densities and larger temperatures .( iii ) Fragmentation is more efficient closer to the star where the local pressure maxima lead to greater collisional velocities . These conclusions have important implications for planet development schemes since they show that planetesimals can form only close to the star while huge bodies such as asteroids or comets might be possible to form farther out in the disk .",
        "ori-fast-z-score": -0.11547005383792514,
        "water-fast-z-score": 4.50333209967908
    },
    {
        "original_text": "We present the results of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe (WMAP) satellite and the Swift observatory in the first year of operation, 2004-05. We find that there are no significant differences between the two samples when we compare their distributions for redshift, luminosity distance, radio flux density at 1 GHz, optical magnitude, or X-ray photon index. The only difference is found to be in the distribution of redshifts; this may be due to selection effects caused by the different energy bands used by each instrument. \n \n Keywords: Blazar, Swift, WMAP, survey, cosmology, statistics, gamma-ray bursts, galaxy clusters, dark matter, dark energy, neutrino mass, cosmic microwave background radiation, anisotropies, large-scale structure, gravitational lensing, relativistic jets, quasar, active galactic nuclei",
        "watermark_text": "We present the conclusion of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe ( WMAP ) satellite and the Swift telescope in the first year of operation , 2004 - 05 . We see that there are no considerable changes between the two specimens when we compare their distributions for redshift , luminosity distance , radio flux concentration at 1 GHz , optical magnitude , or X - ray photon index .The only difference is found to be in the distribution of redshifts ; this might be due to choice influences resulting by the different energy bands used by each instrument . Keywords : Blazar , Swift , WMAP , survey , cosmology , statistics , gamma - ray clusters , galaxy rings , soft material , soft energy , neutrino mass , cosmic microwave background radiation , anisotropies , large - scale structure , gravity lensing , relativistic jets , quasar , active galactic nuclei",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 3.3113308926626095
    },
    {
        "original_text": "We present the mid-infrared (MIR) spectrum of the central region in the Virgo galaxy cluster, obtained with Spitzer/IRS at high spatial resolution. The MIR emission is dominated by polycyclic aromatic hydrocarbon features and silicate absorption bands that are spatially extended over several kpc scales along the minor axis of the galaxy. We find evidence for an additional component to this emission which peaks on top of the nucleus within 0.5 arcsec (0.1 pc). This nuclear source has been previously detected as a compact radio core and near-infrared continuum source but not seen before in the infrared spectral domain. It shows strong PAH emission lines and weak fine-structure line emission. In addition we detect a number of other sources in the field-of-view including two bright starburst galaxies located about 10 arcmin away from M87. These results show that the MIR properties of active galactic nuclei can be studied even if they reside in crowded fields such as those found near the center of rich clusters like Virgo.",
        "watermark_text": "We present the mid - infrared ( MIR ) spectrum of the central region in the Virgo star cluster , obtained with Spitzer / IRS at high spatial resolution . The MIR emission is dominated by polycyclic aromatic hydrocarbon characteristics and silicate emission bands that are spatially extended over several kpc scales along the minor axis of the constellation .We get confirmation for an additional element to this emission which peaks on top of the nucleus within 0 . 5 arcsec ( 0 . 1 pc ) . This nuclear source has been previously observed as a compact radio core and near - infrared continuum source but not seen before in the infrared spectral domain .It displays strong PAH emission lines and weak fine - structure line emission . In addition we locate a number of other sources in the field - of - view including two bright starburst objects located about 10 arcmin away from M87 .These data demonstrate that the MIR properties of active galactic nuclei can be examined even if they live in busy fields such as those contained near the center of rich clusters like Virgo .",
        "ori-fast-z-score": 1.1322770341445956,
        "water-fast-z-score": 5.20847435706514
    },
    {
        "original_text": "Image registration is an important problem in medical imaging and computer vision, where the goal is to find a transformation that aligns two or more images taken at different times and/or by different sensors. In this work we present evolutionary optimisation methods for template based image registration problems. We consider both rigid and non-rigid transformations between images. The proposed algorithms are tested on synthetic data as well as real world datasets including brain MRI scans and CT angiography (CTA) volumes. Our results show that our approach outperforms state-of-the-art techniques in terms of accuracy while being computationally efficient. This research was supported by EPSRC grant EP/N014560/1. Keywords: Evolutionary Computation, Registration, Non-Rigid Transformation, Rigid Transformation, Brain Imaging, Computer Vision. 1 Introduction Image registration is one of the most fundamental tasks in many areas such as medical imaging  1  , remote sensing  2  , video processing  3  , etc., which aims to find a spatial transformation T that maps each point x ∈ Ω1 =  0, 1 d into its corresponding location y = Tx ∈ Ω2 =  0, 1 d in another image I(y). Here d denotes the dimension of the space. For example, if T1 and T2 denote two consecutive time points in a dynamic sequence of images then finding the optimal transformation T would allow us to track the movement of objects over time  4  . Similarly, if S1 and S2 represent two views of the same scene captured using cameras with slightly differing orientations then registering these images will help us fuse information across multiple viewpoints  5  .\nIn recent years there has been significant interest in developing fast and accurate registration algorithms  6  -  8  . However, despite considerable progress made towards solving this challenging problem  9  -  11  , it remains unsolved due to several factors including large number of degrees of freedom involved  12  , presence of noise  13  , partial occlusions  14  , lack of feature correspondence  15  , etc..",
        "watermark_text": "Image registration is an important challenge in medical imaging and computer vision , where the objective is to find a transformation that aligns two or more images took at different times and / or by various sensors . In this research we present evolutionary optimisation methods for template based image registration problems .We consider both stiff and non - flexible transformations between images . The proposed methods are tested on synthetic information as well as real life datasets including brain MRI scans and CT angiography ( CTA ) volumes .Our results show that our approach outperforms state - of - the - art methods in terms of precision while being computationally effective . This research was supported by EPSRC award EP / N014560 / 1 .Keywords : Evolutionary Computation , Registration , Non - Rigid Transformation , Rigid Transformation , Brain Imaging , Computer Vision . 1 Introduction Image registration is one of the most important responsibilities in different areas such as hospital photography 1 , remote sensing 2 , television recording 3 , etc . , which aims to find a spatial mapping T that mapped each point x ∈ Ω1 = 0 , 1 d into its corresponding location y = Tx ∈ Ω2 = 0 , 1 d in another image I ( y ) .Here d indicates the dimension of the space . For instance , if T1 and T2 denote two consecutive time points in a dynamic sequence of pictures then finding the ideal conversion T would enable us to track the movement of items over time 4 .Similarly , if S1 and S2 represent two perspectives of the same scene captured using cameras with slightly differing orientations then registering these images will assist us fuse information across multiple viewpoints 5 . In recent years there has been significant interest in building fast and precise registered methods 6 - 8 .However , despite considerable progress made towards solving this dangerous problem 9 - 11 , it remains unsolved due to several considerations including huge amount of degrees of freedom required 12 , presence of noise 13 , partial occlusions 14 , absence of feature relations 15 , etc . .",
        "ori-fast-z-score": 1.3620104492139977,
        "water-fast-z-score": 8.00044325013193
    },
    {
        "original_text": "We study the dynamics of open quantum systems in one dimension, focusing on their ability to generate entanglement between distant sites and how this is affected by decoherence.  We consider two different models for the system-environment interaction: (i) an environment that couples locally with each site; and (ii) an environment that couples globally with all sites simultaneously. In both cases we find that there are regimes where the system can be driven into highly entangled states even when it starts out unentangled or only weakly entangled. This occurs because the environment acts as a source of noise which drives the system towards its ground state. The effect of local coupling is more pronounced than global coupling since the former allows for faster relaxation timescales. Finally, we show that these results hold true also if the initial state has some degree of spatial correlations. Quantum information processing requires the manipulation of quantum states over large distances. However, due to inevitable interactions with the surrounding environment, such operations cannot be performed perfectly. Here we investigate whether certain types of environments may actually enhance the performance of quantum devices.",
        "watermark_text": "We research the dynamics of open quantum systems in one dimension , concentrating on their potential to create entanglement between distant objects and how this is affected by decoherence . We consider two different models for the system - landscape interaction : ( i ) an environment that pairs locally with each site ; and ( ii ) an environment that pairs internationally with all locations simultaneously .In both cases we find that there are regimes where the system can be pushed into extremely entangled states especially when it comes out unentangled or only lightly entangled . This occurs because the surroundings serves as a source of noise which drives the system towards its ground state .The impact of local coupling is more pronounced than worldwide coupling since the former provides for quicker recovery timescales . Finally , we prove that these results hold true also if the first state has some degree of spatial correlations .Quantum knowledge processing requires the processing of quantum states over large distances . However , owing to inherent interactions with the nearby surroundings , such operations unable be performed properly .Here we investigate whether particular kinds of conditions might actually increase the performance of quantum devices .",
        "ori-fast-z-score": -0.5129891760425771,
        "water-fast-z-score": 6.807380225308036
    },
    {
        "original_text": "We present new high angular resolution observations of the massive protostellar system, Orion Source I (OSI), obtained with ALMA in Band 7 and 9 at an average spatial resolution of 0.3 arcsec. We detect emission lines of SiO(5-4) and HCO+(4-3). The observed line profiles are consistent with those expected for Keplerian rotation around a central object of mass ~10 Msun. Using these results we derive physical parameters such as disk inclination angle, radius, temperature, density structure etc., which can be used to test theoretical models of circumstellar disks. In addition, we find that the kinematics of the innermost region probed by our data is dominated by infall motions rather than outflowing gas. This suggests that OSI may have recently undergone rapid accretion onto its central star. Finally, we also report detection of two compact continuum sources within the primary beam of the telescope.",
        "watermark_text": "We report new high angular resolution measurements of the huge protostellar body , Orion Source I ( OSI ) , obtained with ALMA in Band 7 and 9 at an estimated spatial resolution of 0 . 3 arcsec . We detect emission lines of SiO ( 5 - 4 ) and HCO + ( 4 - 3 ) .The observed line profiles are compatible with those expected for Keplerian rotation around a central object of mass ~ 10 Msun . Using these results we derive physical factors such as disk inclination angle , diameter , temperature , density structure etc . , which can be used to test theoretical theories of circumstellar disks .In addition , we find that the kinematics of the innermost region probed by our information is dominated by infall dynamics rather than outflowing gas . This implies that OSI may have subsequently undergone sudden accretion onto its primary star .Finally , we also report discovery of two compact continuum sources within the primary beam of the observatory .",
        "ori-fast-z-score": 1.116312611302876,
        "water-fast-z-score": 5.662208585049306
    },
    {
        "original_text": "We present the equation of state (EoS) for isospinasymmetric nuclear matter within the framework of relativistic mean field theory, including both nucleons and hyperons as well as their interactions via meson exchange. We consider two different parameterizations of the EoS: NL3* and TM1. The former one includes non-linear terms in the scalar self-interaction potential while the latter has been fitted to reproduce properties of finite nuclei. In addition we also study the effect on the EoS when using the so-called  chiral limit  instead of the standard values for the coupling constants between baryons and mesons. This work is motivated by recent experimental results obtained at GSI Darmstadt which suggest that the symmetry energy may be much softer than previously thought. It will allow us to make predictions about the composition of neutron stars and its dependence on the density profile inside these objects. Finally, we compare our results with those obtained recently by other authors.",
        "watermark_text": "We present the equation of state ( EoS ) for isospinasymmetric nuclear material within the framework of relativistic mean field theory , comprising both nucleons and hyperons as well as their interactions via meson exchange . We consider two different parameterizations of the EoS : NL3 * and TM1 .The first one includes non - linear terms in the scalar self - interaction potential while the former has been fitted to reproduce properties of finite nuclei . In addition we also study the impact on the EoS when using the so - called chiral limitation rather of the standard expressions for the interaction constants between baryons and mesons .This research is prompted by recent experimental studies obtained at GSI Darmstadt which propose that the symmetry power could be much softer than previously thought . It will provide us to make predictions about the composition of neutron galaxies and its dependence on the density profile inside these objects .Finally , we compare our findings with those achieved lately by other published .",
        "ori-fast-z-score": 0.12216944435630522,
        "water-fast-z-score": 5.093248125762992
    },
    {
        "original_text": "We present an analysis of the stability of planetary systems in which protoplanetary embryos evolve under oligarchy, i.e., they are able to eject each other s neighbors by gravitational scattering but not themselves. We find that this process leads to rapid growth of the largest embryo until it reaches its isolation mass (the minimum mass required for runaway accretion). The system then evolves into either a single planet or two planets with comparable masses depending on how close the initial conditions were to instability. This evolution is very different than what happens when all bodies grow simultaneously; in particular, we show that there can be multiple stable outcomes even if the initial conditions are identical. Our results suggest that the formation of terrestrial planets may have proceeded through several stages including oligarchy before reaching their final state as observed today. In addition, our work provides new insights about the origin of Mercury-like planets. Protoplanetary embryos form in circumstellar disks around young stars and undergo mutual gravitational interactions during their growth phase. These interactions lead to orbital migration and dynamical instabilities such as collisions between neighboring embryos. If these processes occur frequently enough, only one body will survive at the end of the growth stage leaving behind a planetary system consisting of just one planet. However, recent studies indicate that many planetary systems contain more than one planet suggesting that some mechanism must exist to prevent complete destruction of the system. Here we study the possibility that protoplanetary embryos follow a hierarchical evolutionary path where they first grow hierarchically via gravitational scattering followed by runaway accretion once the largest embryo has reached its isolation mass. Using numerical simulations, we demonstrate that this scenario naturally explains the existence of multi-planet systems while also reproducing the properties of known exoplanets.",
        "watermark_text": "We present an assessment of the stability of planetary networks in which protoplanetary embryos grow under oligarchy , i . e . , they are able to eject each other s neighbors by gravitational scattering but not themselves . We see that this process results to rapid growth of the greatest embryo until it hits its isolation volume ( the minimum mass needed for runaway accretion ) .The system then evolves into either a single planet or two planets with similar masses depending on how close the early conditions were to instability . This evolution is very different than what happens when all bodies grow simultaneously ; in particular , we prove that there can be several stable outcomes even if the first conditions are matched .Our results show that the formation of terrestrial worlds may have continued through several stages including oligarchy before reaching their final condition as found today . In addition , our work offer additional information about the origin of Mercury - like planets .Protoplanetary embryos form in circumstellar disks around new stars and undergo mutual gravitational interactions during their development period . These interactions result to orbital movement and dynamical instabilities such as collisions between neighboring embryos .If these mechanisms occur frequently enough , only one body will survive at the end of the development period leaving behind a planetary system consisting of just one planet . However , recent studies demonstrate that several planetary complexes include more than one planet suggesting that some method may arise to resist total destruction of the system .Here we study the prospect that protoplanetary embryos continue a hierarchical evolutionary course where they originally grow hierarchically via gravitational waves followed by runaway accretion once the greatest embryo has reached its isolation volume . Using numerical simulations , we prove that this situation naturally explains the existence of dual - planet systems while actually reproducing the properties of known exoplanets .",
        "ori-fast-z-score": -0.8333333333333334,
        "water-fast-z-score": 7.166666666666667
    },
    {
        "original_text": "We use hydrodynamic simulations to study how proto-clusters grow and evolve into galaxy clusters, focusing on their baryon content at high redshifts (z > 5). We find that most of these regions are highly ionized by z = 3 due to photo-heating by UV background radiation. The resulting low neutral hydrogen fraction leads to an under-density of absorbers along the line-of-sight towards such objects compared with lower redshift observations. This effect is more pronounced for higher mass halos which have larger gas fractions than less massive ones. Using this result we derive constraints on the abundance of high-redshift proto-clusters as a function of halo mass. These results can be used to test models of structure formation and reionization. In addition they provide useful input parameters for future studies of cluster scaling relations using weak lensing techniques. \n \n Keywords: Hydrogen ionization state, Galaxy Cluster, Reionization",
        "watermark_text": "We use hydrodynamic simulations to study how proto - galaxies grow and evolve into star clusters , concentrating on their baryon concentration at high redshifts ( z > 5 ) . We see that most of these regions are extremely ionized by z = 3 due to photo - heating by UV background radiation .The resulting lowered neutral hydrogen proportion leads to an under - density of absorbers along the line - of - view towards such objects compared with higher redshift observations . This phenomenon is more pronounced for greater weight halos which have larger gas fractions than less massive ones .Using this effect we derive restrictions on the availability of high - redshift proto - complexes as a function of halo mass . These conclusions can be used to test models of structure development and reionization .In addition they give valuable input parameters for future research of cluster scaling relations utilizing weak lensing methods . Keywords : Hydrogen ionization state , Galaxy Cluster , Reionization",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.5778737935111105
    },
    {
        "original_text": "We study holographically the confinement/deconfinement phase transitions of strongly coupled gauge theories on curved spaces by using the gravity dual with dilaton and axion fields, which is obtained as an exact solution to Einstein-Maxwell-dilaton-axion system in five dimensions. We find that the critical temperature for deconfinement decreases when we increase the curvature radius at fixed chemical potential or charge density. This result implies that the effect of gravitational backreaction becomes more important near the horizon than far away from it. In addition, we show that the critical temperature increases monotonously with increasing chemical potential (or charge density) at fixed curvature radius. The results are consistent with those found in flat space-time. Finally, we discuss how our results can be applied to QGP produced in heavy ion collisions. PACS: 04.50.+h, 11.10.Wx, 12.38.Mh",
        "watermark_text": "We research holographically the confinement / deconfinement phase transitions of highly coupled gauge theories on curved spaces by using the gravity twin with dilaton and axion fields , which is found as an precise answer to Einstein - Maxwell - dilaton - axion system in five dimensions . We see that the key temperature for deconfinement decreases when we increase the curvature length at fixed molecular potential or charge density .This result suggests that the impact of gravitational backreaction becomes more important near the horizon than far away from it . In addition , we find that the critical temperature increases monotonously with rising chemical potential ( or charge density ) at fixed curvature length .The results are compatible with those observed in flat space - time . Finally , we talk how our findings can be applied to QGP produced in heavy ion collisions .PACS: 04.50.+h, 11.10.Wx, 12.38.Mh",
        "ori-fast-z-score": 0.6201736729460423,
        "water-fast-z-score": 5.333493587335964
    },
    {
        "original_text": "We study the existence and uniqueness of equilibrium states for some classes of potentials in the presence of an external magnetic field, using results on the asymptotic behavior of solutions to Schrödinger equations obtained by J. Bourgain and M. Goldstein.  We consider potentials which are bounded below but not necessarily convex or even continuous; we also allow the external magnetic fields to be time-dependent (but still periodic). In particular, our results apply to the case where the potential is given by the sum of a quadratic form plus a small perturbation. The main tool used here is the so-called ``Bourgain-Goldstein method  , which consists in studying the evolution of the Wigner transform of the solution to the Schrödinger equation under the action of the unitary group generated by the corresponding Hamiltonian. \nIntroduction\n\nThe purpose of this article is to prove that there exists at most one equilibrium state associated to certain classes of potentials in the context of quantum mechanics when these potentials interact with an external magnetic field. This result was first proved by D. Ruelle  Ru  , who showed that if V : T d → R satisfies suitable conditions then there exists exactly one equilibrium measure µV . These assumptions include the fact that V should have superlinear growth at infinity and satisfy a condition known as ``uniform ellipticity  . However, it turns out that many interesting examples do not fall into this category. For example, let us mention the following two examples:  • If V = −|x| 2 + |y| 2 , then V does not grow faster than linearly at infinity.",
        "watermark_text": "We explore the existence and uniqueness of equilibrium states for some categories of potentials in the presence of an external magnetic force , using findings on the asymptotic nature of solutions to Schrödinger coefficients derived by J . Bourgain and M . Goldstein . We consider potentials which are bounded below but not necessarily convex or even continuous ; we also consider the external magnetic fields to be time - dependent ( but still periodic ) .In particular , our findings apply to the case where the potential is given by the sum of a quadratic form plus a small perturbation . The main technique applied here is the so - called ` ` Bourgain - Goldstein method , which consists in examining the evolution of the Wigner transform of the solution to the Schrödinger equation under the action of the unitary group produced by the associated Hamiltonian .Introduction The purpose of this page is to prove that there exists at most one equilibrium state associated to specified classes of potentials in the context of quantum mechanics when these potentials behave with an external magnetic force . This result was first proved by D . Ruelle Ru , who demonstrated that if V : T d → R satisfies suitable conditions then there exists precisely one equilibrium measure µV .These assumptions involve the fact that V should have superlinear development at infinity and meet a condition called as ` ` uniform ellipticity . However , it turns out that several interesting instances do not drop into this class .For instance , let us note the following two examples : • If V = − | x | 2 + | y | 2 , then V does not grow rapid than linearly at infinity .",
        "ori-fast-z-score": 0.19611613513818404,
        "water-fast-z-score": 6.148170459575759
    },
    {
        "original_text": "We present the fundamental plane (FP) for galaxy clusters detected in the Planck survey at 143 GHz, based on their X-ray luminosity Lx , temperature Tx and SZ flux Y500 . The FP is defined as log(Y500 ) = α + βlog(Tx /Lx ), where we find that the best-fit values are  α = 0.92 ± 0.01 and β = 1.27 ± 0.02 with an intrinsic scatter of σint = 0.10 ± 0.03 dex.  We compare our results to previous studies using different cluster samples and methods. Our sample consists of 31 massive clusters selected by applying cuts in mass M500 > 5 × 1014 h−1 70 M⊙ and redshift z < 0.3. These clusters have been observed with XMM-Newton and Chandra satellites and also with ground-based telescopes such as APEX-SZ or Bolocam.",
        "watermark_text": "We present the fundamental plane ( FP ) for galaxy galaxies found in the Planck survey at 143 GHz , using on their X - ray luminosity Lx , temperature Tx and SZ flux Y500 . The FP is calculated as log ( Y500 ) = β + βlog ( Tx / Lx ) , where we find that the best - fitting values are α = 0 . 92 ± 0 . 01 and β = 1 . 27 ± 0 . 02 with an intrinsic scatter of σint = 0 . 10 ± 0 . 03 dex .We match our results to previous studies using separate cluster samples and methods . Our sample consists of 31 massive clusters selected by applying cuts in mass M500 > 5 × 1014 h−1 70 [UNK] and redshift z < 0 . 3 .These clusters have been observed with XMM-Newton and Chandra satellites and also with ground-based telescopes such as APEX-SZ or Bolocam.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 2.3094010767585034
    },
    {
        "original_text": "We present the results of our analysis of pulsar data obtained with the LOFAR telescope in the Netherlands, which is part of the Low Frequency Array (LOFAR). The observations were carried out at frequencies between 10 MHz and 120 MHz using the High Band Antenna (HBA) system. We have detected two new types of pulsars - one that emits bursts of radio waves lasting several seconds and another whose pulses are modulated by an additional signal. In addition to these discoveries we also report on the detection of previously unknown phenomena associated with known pulsars. \n \n Pulsars are rapidly rotating neutron stars emitting beams of electromagnetic radiation across the entire visible universe. They can be observed over many decades as they spin down due to their magnetic dipole field losing energy into space. This causes them to slow down gradually until they stop completely after about ten billion years. As well as being extremely stable clocks for measuring time intervals, pulsars provide information about fundamental physics such as gravity, quantum electrodynamics and general relativity.",
        "watermark_text": "We present the conclusion of our analysis of pulsar information obtained with the LOFAR observatory in the Netherlands , which is part of the Low Frequency Array ( LOFAR ) . The surveys were carried out at speeds between 10 MHz and 120 MHz use the High Band Antenna ( HBA ) scheme .We have discovered two new types of pulsars - first that emits flashes of radio beams lasting several seconds and another whose pulses are modulated by an additional signal . In addition to these discoveries we also report on the discovery of previously unidentified behaviour associated with reported pulsars .Pulsars are rapidly spinning neutron stars emitting waves of electromagnetic radiation across the entire visible world . They can be viewed over numerous centuries as they rotate down due to their magnetic dipole field losing power into space .This forces them to halt down gradually until they stop completely after about ten billion decades . As well as being extremely reliable clocks for determining time periods , pulsars provide information about basic physics such as gravity , quantum electrodynamics and general relativity .",
        "ori-fast-z-score": -1.4814874939752933,
        "water-fast-z-score": 6.119912853410033
    },
    {
        "original_text": "We present the results of our analysis of molecular gas mass estimates based on CO and HCN observations in nearby galaxies, using data obtained with the IRAM 30m telescope. We find that conversion factors between luminosity and mass are strongly dependent on the star formation rate (SFR) per unit area within each galaxy disk. The SFR surface density is found to be an important parameter controlling the conversion factor XCO = M(H2)/L(CO), which we derive by fitting the observed L(HCN) / L(CO) ratio versus metallicity relation. For low values of ΣSFR < 1M⊙ yr-1 kpc-2 , corresponding to quiescent disks or nuclear regions dominated by old stellar populations, we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s. This value increases up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > 3M⊙yr-1kpc-2 . These findings suggest that the physical conditions of the interstellar medium may change significantly depending on whether it is located in actively star-forming regions or not.",
        "watermark_text": "We publish the conclusion of our analysis of molecular gas mass estimates based on CO and HCN measurements in nearby galaxies , using data derived with the IRAM 30m telescope . We see that conversion factors between luminosity and mass are strongly dependent on the star formation rate ( SFR ) per unit area within each galaxy disk .The SFR ground density is found to be an important function regulating the transformation parameter XCO = M ( H2 ) / L ( CO ) , which we derive by fitting the seen L ( HCN ) / L ( CO ) ratio versus metallicity relation . For low values of ΣSFR < [UNK] yr - 1 kpc - 2 , equivalent to quiescent disks or atomic regions dominated by ancient stars populations , we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s . This value rises up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > [UNK] - 1kpc - 2 .These studies imply that the physical conditions of the interstellar material may change considerably depending on whether it is situated in actively star - creating areas or not .",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 5.815230125149881
    },
    {
        "original_text": "We study the wetting properties of a fluid in contact with an attractive wall, using a simple model for which we can perform exact calculations. The system consists of particles interacting via a hard-core repulsion and a short-range attraction that decays exponentially fast at large distances. We show how to calculate exactly the density profile near the wall as well as the surface tension between the liquid phase and the gas phase. In particular, we find that there is no true equilibrium state corresponding to complete wetting by the liquid phase; instead, the interface becomes rough when the temperature decreases below some critical value T*. This phenomenon occurs because the exponential tail of the interaction potential leads to strong fluctuations in the number of particles adsorbed onto the wall. These fluctuations are responsible for the non-analytic behavior observed both in the density profile and in the surface tension. \n \n Introduction \n \n Wetting phenomena occur whenever two phases coexist in contact with each other  1  . For example, water droplets spread over glass surfaces due to capillary forces  2  , while oil spreads out on top of water  3  . A particularly interesting situation arises if one of these phases has a lower dimensionality than the others  4  . Indeed, this may lead to new types of transitions such as those occurring in systems where a thin film coexists with its vapor  5  or in confined geometries  6  . \n \n Here we consider a simple model describing the wetting properties of fluids in contact with walls  7, 8  . Our results suggest that even though the interactions decay rapidly away from the wall, they still give rise to nontrivial effects. More specifically, our analysis shows that the presence of a wall induces strong fluctuations in the number Nw of particles adsorbed on it  9  . As a result, the interface separating the liquid phase (containing all particles) from the gas phase (containing none) becomes rough  10  when the temperature drops below a certain threshold T*. Below T*, the average distance between neighboring particles increases significantly so that the interface acquires a fractal structure  11  . \nModel description\n\nThe system under consideration consists of N identical",
        "watermark_text": "We research the wetting properties of a fluid in contact with an attractive wall , using a simple simulation for which we can conduct accurate calculations . The system consists of molecules bonding via a hard - core repulsion and a small - range attraction that decays exponentially rapidly at large distances .We see how to estimate exactly the density profile near the wall as well as the surface friction between the liquid phase and the gas phase . In particular , we find that there is no true equilibrium state analogous to complete wetting by the liquid phase ; instead , the interface becomes rough when the temperature rises below some significant value T * .This phenomenon occurs because the exponential tail of the interaction potential leads to powerful fluctuations in the quantity of molecules adsorbed onto the wall . These fluctuations are responsible for the non - analytic activity observed both in the density profile and in the surface tension .Introduction Wetting processes arise whenever two phases coexist in contact with each other 1 . For instance , freshwater droplets distributed over glazed surfaces thanks to capillary forces 2 , while petroleum spreads out on top of water 3 .A notably important scenario occurs if one of these stages has a smaller dimensionality than the others 4 . Indeed , this might lead to novel sorts of transitions such as those occurring in systems where a thin glass coexists with its vapor 5 or in confined geometries 6 .Here we imagine a simple simulation explaining the wetting properties of fluids in contact with structures 7 , 8 . Our results propose that even though the interactions decay greatly back from the wall , they still give rise to nontrivial effects .More specifically , our analysis shows that the presence of a barrier induces strong fluctuations in the number Nw of molecules adsorbed on it 9 . As a result , the interface separating the liquid phase ( containing all ions ) from the gas phase ( containing nobody ) gets rough 10 when the temperature falls below a certain level T * .Below T * , the average distance between neighboring particles grows significantly so that the interface acquires a fractal structure 11 . Model description The system under consideration consists of N identical",
        "ori-fast-z-score": 0.5482823149915702,
        "water-fast-z-score": 8.227195572487128
    },
    {
        "original_text": "The magnetic reconnection is one of the most important processes for understanding many phenomena observed in space and laboratory plasmas, such as solar flares, magnetospheric substorms, sawtooth crashes in tokamaks etc.. In this work we present an analytical model which describes the process of magnetic reconnection in collisionless high energy plasma with arbitrary initial conditions. The main idea behind our approach consists in using the concept of generalized force density tensor (GDFT) introduced by MHD theory. We show that GDFT can be used not only to describe the macroscopic dynamics but also microscopic properties of the system like particle distribution functions. Our results are compared with those obtained within other approaches based on kinetic description of particles motion. It turns out that all these models give similar predictions when applied to simple cases where the initial state has no gradients along the direction perpendicular to the background magnetic field. However, if there exist some gradients across the magnetic field lines then different models predict quite different behavior.",
        "watermark_text": "The magnetic reconnection is one of the most important processes for studying many phenomena observed in space and lab plasmas , such as sun flares , magnetospheric substorms , sawtooth crashes in tokamaks etc . . In this research we present an analytical theory which explains the process of magnetic reconnection in collisionless high energy gas with arbitrary initial conditions .The main idea behind our approach consists in utilizing the notion of generalized force density tensor ( GDFT ) developed by MHD physics . We see that GDFT can be used not only to explain the macroscopic behavior but also microscopic characteristics of the process like particle distribution functions .Our results are compared with those achieved within other methods based on kinetic representation of particles movement . It turns out that all these models make comparable predictions when applied to simple instances where the first state has no gradients along the direction perpendicular to the background magnetic force .However , if there exist some gradients across the magnetic force lines then various models predict quite different properties .",
        "ori-fast-z-score": -0.7777777777777778,
        "water-fast-z-score": 5.74243935589202
    },
    {
        "original_text": "We present the results of our survey for southern M-dwarf binaries with separations between 0.1 AU and 10 AU, using data obtained by the Wide Field Camera 3 (WFC3) on board HST as part of program GO-12775. We find that about half of all systems are unresolved or only marginally resolved at these distances. The fraction of close binaries is higher among lower mass objects than it is among more massive ones; we estimate that this difference may be due to observational biases rather than intrinsic differences in formation mechanisms. \n \n In addition, we have identified several new candidate companions around known nearby ultracool dwarfs: GJ 436Bb, GJ 581Cc, GJ 674Ab, and GJ 758Aa. These candidates will require further observations before their status can be confirmed. Finally, we report the discovery of two previously unknown substellar objects: 2MASS J03552385+1133413AB and 2MASS J16252618-2434439AB.",
        "watermark_text": "We present the conclusion of our survey for southern M - dwarf binaries with separations between 0 . 1 AU and 10 AU , using data acquired by the Wide Field Camera 3 ( WFC3 ) on board HST as part of series GO - 12775 . We see that about half of all systems are unresolved or only marginally resolved at these distances .The percentage of close binaries is higher among lower weight objects than it is among more massive ones ; we estimate that this distinction might be due to observational biases rather than intrinsic differences in formation patterns . In addition , we have discovered several novel candidate companions around suspected local ultracool dwarfs : GJ 436Bb , GJ 581Cc , GJ 674Ab , and GJ 758Aa .These candidates will take further observations before their status can be verified . Finally , we publish the discovery of two formerly unidentified substellar objects : 2MASS J03552385 + 1133413AB and 2MASS J16252618 - 2434439AB .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.181036310903636
    },
    {
        "original_text": "We present an efficient numerical scheme to solve the incompressible Navierstokes (NS) equations by using the lattice Boltzmann method with the Inverse Kinetic Approach (IKA). The IKA is based on the idea that the NS equation can be recovered as the equilibrium state in the Chapman-Enskog expansion, and it has been successfully applied to various fluid dynamics problems. We show how this concept can be implemented into the LBM framework. Numerical results are presented to demonstrate the accuracy and efficiency of our proposed algorithm. Finally we discuss some possible extensions of the current work. Keywords: Lattice Boltzmann Method; Inverse Kinetic Approximation; Incompressible Navier-Stokes; Computational Fluid Dynamics. 1 Introduction The lattice Boltzmann method (LBM), originally developed by Frisch et al  1  , is one of the most promising approaches to computational fluid dynamics (CFD). It is particularly suitable for parallel computing due to its inherent locality  2  . Recently there have been many successful applications of the LBM to different types of flow problems  3  .\nThe basic idea behind the LBM is to represent the distribution function f(x,t) at each node x of a regular grid by a finite number of particles moving along discrete velocities c i = ciΔt/Δx, where Δx and Δt denote respectively the spatial and temporal resolutions  4  . Then the evolution of these particles is governed by the following equation: \nwhere τ denotes the relaxation time which controls the rate of approaching towards the equilibrium distribution function f eq i\n. By choosing appropriate values of τ, the macroscopic quantities such as density ρ and velocity u can be obtained through moments of the distribution function:",
        "watermark_text": "We present an efficient numerical system to solve the incompressible Navierstokes ( NS ) equations by using the lattice Boltzmann technique with the Inverse Kinetic Approach ( IKA ) . The IKA is based on the idea that the NS equation can be recovered as the equilibrium state in the Chapman - Enskog expansion , and it has been successfully application to numerous fluid theory issues .We see how this concept can be applied into the LBM framework . Numerical results are presented to indicate the accuracy and efficiency of our proposed algorithm .Finally we explain some possible extensions of the present work . Keywords : Lattice Boltzmann Method ; Inverse Kinetic Approximation ; Incompressible Navier - Stokes ; Computational Fluid Dynamics .1 Introduction The lattice Boltzmann technique ( LBM ) , previously developed by Frisch et al 1 , is one of the most attractive approaches to computational liquid dynamics ( CFD ) . It is especially suitable for concurrent processing due to its inherent locality 2 .Recently there have been many successful uses of the LBM to different kinds of flow questions 3 . The basic idea behind the LBM is to represent the distribution map g ( x , t ) at each node h of a regular grid by a finite number of atoms moved along continuous velocities c i = ciΔt / Δx , where Δx and Δt denote respectively the spatial and spatial resolutions 4 .Then the evolution of these objects is governed by the following equation : where τ represents the relaxation time which influences the speed of moving towards the equilibrium distribution function f eq i . By selecting appropriate values of σ , the macroscopic parameters such as density w and speed v can be obtained through moments of the distribution function :",
        "ori-fast-z-score": -2.3312620206007844,
        "water-fast-z-score": 4.786988013071282
    },
    {
        "original_text": "We present new results on the kinematics and dynamics of spiral arm streaming motions in the nearby grand-design galaxy NGC 5194 (M51). We use high-resolution near-IR integral field spectroscopy obtained with SINFONI at VLT to study the gas velocity fields, line-of-sight velocities, and mass surface density distributions along two different lines of sight through the central region of this interacting system. The main goal is to investigate whether or not there are systematic differences between these two viewing angles that could be related to an underlying gravitational potential perturbation caused by the companion galaxy NGC 5195. Our analysis shows that both sides of the nuclear ring exhibit similar large-scale streaming patterns which can be traced out to distances of about 1 kpc into the disk plane. However, we find significant deviations from circular rotation within the inner 100 pc radius around the nucleus. These non-circular motions appear to be dominated by radial inflow towards the center as well as counter-rotating components perpendicular to the major axis of the galactic bar.",
        "watermark_text": "We report new data on the kinematics and dynamics of spiral arm streaming movements in the nearby grand - design galaxy NGC 5194 ( M51 ) . We use large - resolution near - IR integral field spectroscopy derived with SINFONI at VLT to study the gas velocity fields , line - of - view velocities , and mass surface velocity distributions along two different lines of view through the main region of this interacting system .The main goal is to examine whether or not there are systematic differences between these two viewing angles that might be connected to an underlying gravitational potential perturbation caused by the companion galaxy NGC 5195 . Our study shows that both sides of the nuclear ring show identical large - scale drifting patterns which can be traced out to distances of about 1 kpc into the disk plane .However , we find considerable deviations from circular rotation within the inner 100 pc radius around the nucleus . These non - circular movements appear to be dominated by radial inflow towards the center as well as anti - spinning components parallel to the main axis of the galactic bar .",
        "ori-fast-z-score": 1.0660035817780522,
        "water-fast-z-score": 5.617988764033708
    },
    {
        "original_text": "We present new optical/NIR data for GRB 060206, which show that its X-ray to radio afterglow is well described by an achromatic break at tbreak = 1.3 days followed by a power-law decay with index -1.2 (Fν ∝ t-1.2). The lack of any spectral evolution across this break suggests it was caused by energy injection into the blast wave. We find no evidence for dust extinction along our line-of-sight; however we cannot rule out significant reddening due to host galaxy dust. Our results are consistent with previous claims that achromatic breaks observed in many other bursts may be explained as being due to late-time energy injections rather than jet-break effects. \n \n Keywords: Gamma-ray burst, Afterglow emission, Energy injection, Jet break, Redshift measurement \n \n INTRODUCTION \n \n In recent years there has been growing interest in understanding how gamma ray bursts (GRBs) produce their broadband electromagnetic radiation. This effort has led to several successful models describing the prompt phase of GRB emission (see e.g., Piran 2005; Zhang 2007), but less progress on explaining the origin of the afterglow component. A key feature of most afterglows is the presence of a steepening or  jet break  in the light curve around one day postburst (Rhoads 1999) . Such breaks have traditionally been interpreted as marking the time when the relativistic ejecta becomes optically thin to synchrotron self-absorption, causing the flux density to drop rapidly. However, some authors argue that such breaks can also arise if the ejecta undergoes continued energy input following the initial explosion (e.g., Kumar & Panaitescu 2000; Granot et al. 2001; Chevalier & Li 2000) , while others suggest that they could instead result from changes in the geometry of the emitting region (e.g., Racusin et al. 2008 ). An alternative explanation for these breaks invokes interstellar scintillation (Goodman 1997; Goodman & Narayan 2006 ) - a phenomenon",
        "watermark_text": "We present new optical / NIR data for GRB 060206 , which show that its X - ray to radio afterglow is well described by an achromatic crack at tbreak = 1 . 3 days preceded by a power - law decay with index - 1 . 2 ( Fν [UNK] t - 1 . 2 ) . The absence of any spectral evolution across this break suggests it was produced by energy flow into the explosion wave .We see no evidence for powder extinction along our line - of - seeing ; however we cannot leave out significant reddening due to host universe material . Our results are compatible with previous accounts that achromatic breaks found in many other bursts perhaps be understood as being result to late - time energy injections rather than jet - break interactions .Keywords : Gamma - ray flare , Afterglow emission , Energy injection , Jet break , Redshift measurement INTRODUCTION In past decades there has been growing interest in understanding how gamma ray clusters ( GRBs ) output their broadband electromagnetic radiation . This effort has led to several successful theories describing the prompt stage of GRB absorption ( saw e . g . , Piran 2005 ; Zhang 2007 ) , but less progress on explaining the origin of the afterglow component .A key feature of most afterglows is the formation of a steepening or jet break in the light spiral around one day postburst ( Rhoads 1999 ) . Such breaks have traditionally been viewed as indicating the period when the relativistic ejecta becomes optically thin to synchrotron self - absorption , forcing the flux concentration to fall swiftly .However , some writers argue that such breaks can also arise if the ejecta undergoes continued energy source following the first blast ( e . g . , Kumar & Panaitescu 2000 ; Granot et al . 2001 ; Chevalier & Li 2000 ) , while others suggest that they may rather result from alterations in the topology of the emitting area ( e . g . , Racusin et al .2008 ) . An alternative theory for these breaks invokes interstellar scintillation ( Goodman 1997 ; Goodman & Narayan 2006 ) - a phenomenon",
        "ori-fast-z-score": -0.33567254331867563,
        "water-fast-z-score": 7.72046849632954
    },
    {
        "original_text": "We present the first measurement of the supermassive black hole (SMBH) mass function for both early-(elliptical/S0, Sa-Sb) and latetype (Scd-Sm) galaxies using data from the Millennium Galaxy Catalogue (MGC). We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations. Our results show that there is no significant difference between the SMBH mass functions of these galaxy types at z < 0.1. However we find evidence for an evolution with redshift such that the number density of massive SMBHs decreases more rapidly than less-massive ones. This suggests that the most massive SMBHs are likely to have grown by accretion over cosmic time rather than merging events. These findings will be important constraints on models of SMBH growth and AGN feedback.",
        "watermark_text": "We present the first measurement of the supermassive black hole ( SMBH ) mass distribution for both late - ( elliptical / S0 , Sa - Sb ) and latetype ( Scd - Sm ) clusters using data from the Millennium Galaxy Catalogue ( MGC ) . We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations .Our results show that there is no major variation between the SMBH mass distributions of these galaxy forms at z < 0 . 1 . However we find proof for an evolution with redshift such that the number density of large SMBHs falls more swiftly than less - massive ones .This implies that the most gigantic SMBHs are likely to have expanded by accretion over universe time rather than joining events . These conclusions will be crucial constraints on estimates of SMBH growth and AGN feedback .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.077963596336064
    },
    {
        "original_text": "We present the results of our analysis on the statistical properties of dust FIR emission in nearby galaxies, based on data obtained by ISO and Spitzer space telescopes. We find that the distribution function of dust FIR luminosity is well described by a log-normal form with an exponential tail at high luminosities. The mean value of the logarithmic luminosity dispersion for all samples considered here is 0.3 dex (factor of 2). This result suggests that there are two populations of dusty star-forming regions within each galaxy -one population associated with normal star formation activity and another one associated with intense bursts of star formation. Our study also shows that the fraction of galaxies containing such extreme objects increases towards higher redshifts. These findings have important implications for understanding the physical processes responsible for the evolution of distant galaxies as well as their contribution to the cosmic infrared background radiation. \n \n Keywords: Infrared, Galaxy",
        "watermark_text": "We present the conclusion of our analysis on the statistical characteristics of dust FIR pollution in nearby galaxies , using on evidence derived by ISO and Spitzer space telescopes . We see that the distribution function of dust FIR luminosity is well described by a log - normal shape with an exponential tail at high luminosities .The mean value of the logarithmic luminosity dispersion for all specimens considered here is 0 . 3 dex ( factor of 2 ) . This result suggests that there are two communities of dusty star - creating areas within each galaxy - one community associated with normal star formation activity and another one linked with aggressive bursts of galaxy formation .Our study also shows that the fraction of stars bearing such extreme objects increases towards higher redshifts . These studies have important implications for studying the physical processes responsible for the evolution of distant galaxies as also as their impact to the cosmic infrared background radiation .Keywords: Infrared, Galaxy",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 5.427092530382482
    },
    {
        "original_text": "We present the Hamiltonian formulation for general relativity with matter fields on an arbitrary spacetime manifold, including both classical and quantum aspects. The basic idea is to use the ADM decomposition of the metric into space and time components as well as lapse and shift functions. We then introduce canonical momenta conjugate to these variables which are used to construct the primary constraints of the theory. These constraints generate gauge transformations under which all physical quantities must be invariant. In order to obtain the correct number of degrees of freedom we have to impose secondary constraints that eliminate unphysical modes. Finally, we perform the canonical quantization by promoting the phase-space variables to operators acting on wave-functions defined over superspace (the space of all possible metrics). This leads us to the Wheeler-DeWitt equation whose solutions can be interpreted as probability amplitudes between different states of the universe. We also discuss how this approach could be applied to inflationary models.",
        "watermark_text": "We introduce the Hamiltonian formulation for general relativity with matter fields on an arbitrary spacetime manifold , covering both classical and quantum aspects . The basic idea is to use the ADM decomposition of the metric into space and time parts as well as lapse and shift variables .We then introduce canonical momenta conjugate to these parameters which are applied to build the primary constraints of the theory . These restrictions produce gauge transformations under which all physical components must be invariant .In order to obtain the appropriate number of degrees of liberty we have to introduce secondary constraints that eliminate unphysical modes . Finally , we perform the canonical quantization by expanding the phase - space variables to functions acted on wave - functions defined over superspace ( the space of all possible metrics ) .This leads us to the Wheeler - DeWitt equation whose solutions can be interpreted as probability amplitudes between various states of the universe . We also discuss how this methodology possible be applied to inflationary theories .",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 3.849741916091625
    },
    {
        "original_text": "We propose an algorithm for network tomography that is able to reconstruct the internal structure of a network by using only one-dimensional (1-D) measurements, i.e., link counts between pairs of nodes in the network. The proposed method can be applied to any type of networks and does not require any prior knowledge about their topology or traffic patterns. We show how our approach can be used to estimate the number of active flows at each node as well as the amount of data transmitted over each flow. Our results are validated through extensive simulations performed with real Internet traces. Network tomography has been widely studied during recent years due to its potential applications in many areas such as computer security, quality-of-service provisioning, and traffic engineering  1  . In this context, it consists of estimating some properties of the network s internal state (such as the number of active flows per node or the amount of data transferred along each flow) by observing only external information (i.e., link-level statistics). This problem becomes particularly challenging when dealing with large-scale networks since the number of possible states grows exponentially with the size of the network  2  .\nIn order to overcome these limitations, several approaches have been recently proposed which exploit specific characteristics of the underlying network  3  , e.g., sparsity  4  -  6  , symmetry  7  , or regularity  8  . However, most existing methods assume either complete knowledge of the network topology  9 -  11  or accurate estimates of the traffic matrix  12  -  14  . Unfortunately, both assumptions may not hold in practice  15  , especially if we consider large and/or dynamic networks  16  . For example, in IP-based networks, the exact location of routers cannot always be determined  17  while the traffic matrix is usually unknown  18  . Moreover, even if the network topology were known, collecting all necessary information would still be impractical because of scalability issues  19  . Finally, obtaining accurate estimates of the traffic...",
        "watermark_text": "We suggest an algorithm for network tomography that is able to reconstruct the internal structure of a network by using only one - dimensional ( 1 - D ) observations , i . e . , link counts between pairs of nodes in the network . The proposed approach can be applied to any type of networks and does not require any earlier knowledge about their topology or traffic behavior .We see how our approach can be used to estimate the total of active flows at each node as also as the quantity of content conveyed over each flow . Our results are validated through ongoing simulations conducted with real Internet traces .Network tomography has been widely explored during recent years owing to its potential applications in different areas such as data security , quality - of - service provisioning , and route management 1 . In this context , it consists of estimating some properties of the organization s internal state ( such as the number of active flows per node or the quantity of content transferred along each flow ) by observing only external information ( i . e . , link - level statistics ) .This problem remains particularly challenging when dealing with large - scale networks since the number of possible states expands exponentially with the length of the network 2 . In try to overcome these limitations , various approaches have been lately advocated which use particular features of the underlying network 3 , e . g . , sparsity 4 - 6 , symmetry 7 , or regularity 8 .However , most existing techniques assume either complete understanding of the traffic topology 9 - 11 or accurate calculations of the traffic matrix 12 - 14 . Unfortunately , both conclusions may not hold in practice 15 , particularly if we study huge and / or dynamic networks 16 .For instance , in IP - based networks , the exact location of routers never always be determined 17 while the traffic matrix is usually unknown 18 . Moreover , even if the network topology were known , compiling all necessary data would still be impractical because of scalability concerns 19 .Finally , obtaining adequate figures of the traffic . . .",
        "ori-fast-z-score": -0.8723567442899586,
        "water-fast-z-score": 6.899548795747854
    },
    {
        "original_text": "We propose an algorithm to select the injection point in hybrid networks, which is based on local information and can be implemented with low overheads. The proposed algorithm has two phases. First, it elects one node as the injection point by using only local information. Second, if there are multiple nodes that have been elected as the injection points, then these nodes will negotiate among themselves to determine exactly one injection point. We prove that our algorithm always selects at least one node as the injection points when all nodes are reachable from each other. Furthermore, we show through simulations that our algorithm performs well even under various network conditions such as dynamic topologies or limited communication ranges. Keywords: Distributed system, Localization, Self-organization, Wireless sensor network (WSN), Data dissemination, Energy efficiency, Routing protocol, Location-based routing, Clustering, Load balancing, Traffic engineering, Internet service provider",
        "watermark_text": "We suggest an algorithm to select the injection point in hybrid networks , which is based on local information and can be deployed with minimum overheads . The proposed algorithm has two phases .First , it elects one node as the injection center by using only local information . Second , if there are multiple nodes that have been chosen as the injection points , then these nodes will agree among themselves to select exactly one injection point .We showed that our algorithm often selects at least one node as the injection points when all nodes are reachable from each other . Furthermore , we demonstrated through simulations that our algorithm performs better even under various network conditions such as dynamic topologies or restricted transmission ranges .Keywords : Distributed system , Localization , Self - organization , Wireless sensor channel ( WSN ) , Data dissemination , Energy quality , Routing protocol , Location - based scheduling , Clustering , Load balancing , Traffic management , Internet service provider",
        "ori-fast-z-score": -0.25,
        "water-fast-z-score": 4.0
    },
    {
        "original_text": "We present new high resolution (R = λ/Δλ ~ 20,000) far-ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE), as well as archival Hubble Space Telescope (HST) data for the hot white dwarf central star in the planetary nebula Sh2-216. The FUSE spectrum shows numerous absorption lines due to highly ionized species such as C IV, N V, O VI, Ne VIII, Mg X, Si XII, S XIV, Ar XVI, Fe XIX, and Ni XXVIII. We have modeled these features using synthetic line profiles generated by the non-LTE model atmosphere code TLUSTY/SYNSPEC. Our best-fit models indicate that this star has an effective temperature T eff = 120,000 K, surface gravity log g = 8.0, mass M = 0.6M☉ , radius R = 0.01R☉ , and is surrounded by a shell of material with density n(He II)/n(He I) = 1.5 x 10-3 .",
        "watermark_text": "We use new high resolution ( R = λ / Δλ ~ 20 , 000 ) far - ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer ( FUSE ) , as well as archival Hubble Space Telescope ( HST ) statistics for the cool white dwarf central star in the planetary nebula Sh2 - 216 . The FUSE spectrum displays several absorption patterns due to strongly ionized species such as C IV , N V , O VI , Ne VIII , Mg X , Si XII , S XIV , Ar XVI , Fe XIX , and Ni XXVIII .We have analyzed these characteristics utilizing artificial line profiles generated by the non - LTE model atmosphere code TLUSTY / SYNSPEC . Our best - fitting models suggest that this star has an effective heat T eff = 120 , 000 K , surface gravity log f = 8 . 0 , mass M = 0 . 6M☉ , diameter R = 0 . 01R☉ , and is enclosed by a shell of material with volume n ( He II ) / n ( He I ) = 1 . 5 x 10 - 3 .",
        "ori-fast-z-score": -1.5109662034355793,
        "water-fast-z-score": 3.6055512754639896
    },
    {
        "original_text": "The Earth s rotation axis is not fixed, but wobbles around its mean position with respect to distant stars (polar motion). The amplitude and phase of this wobble are determined by many factors including tidal forces between the Earth and other bodies such as the Sun and Moon.  Free Core Nutation (FCN) refers to an oscillation of the Earth s spin axis that occurs at a period of about 430 days. This phenomenon has been observed for more than 50 years using ground-based radio telescopes observing the positions of celestial objects near the celestial poles. In this study we use data spanning over 30 years obtained from two observatories located on opposite sides of the globe to investigate how FCN varies spatially across the surface of the Earth. We find that there exists significant differences in both the amplitudes and phases of the FCN signal recorded at each site. These results suggest that the FCN signal may be modulated by local geophysical effects which vary across the Earth s surface.",
        "watermark_text": "The Earth s rotation axis is not fixed , but wobbles around its average position with regard to distant stars ( polar motion ) . The amplitude and phase of this wobble are decided by many processes including tidal forces between the Earth and other bodies such as the Sun and Moon .Free Core Nutation ( FCN ) refers to an oscillation of the Earth s spin axis that happens at a period of about 430 days . This phenomenon has been observed for more than 50 weeks using ground - based radio telescopes observing the places of heavenly objects near the astronomical poles .In this study we utilize evidence covering over 30 years derived from two observatories situated on opposite ends of the globe to examine how FCN varies spatially across the surface of the Earth . We see that there exists significant variations in both the amplitudes and phases of the FCN signal recorded at each site .These data suggest that the FCN response possibly be modulated by regional geophysical influences which varies across the Earth s surface .",
        "ori-fast-z-score": -2.0768805540571886,
        "water-fast-z-score": 4.764608329895903
    },
    {
        "original_text": "We present an approach to robust multi-cellular developmental design that combines the advantages of both bottom-up and top-down approaches, while avoiding their respective disadvantages. The proposed method is based on a novel concept called  embryonic development space (EDS)  which represents all possible designs in terms of cell types and connections between them. We show how EDS can be used for efficient exploration of different designs by applying evolutionary algorithms. Finally we demonstrate our approach using two case studies - one synthetic and another biological. Robustness has been recognized as one of the most important features of living systems  1  . In particular, it plays crucial role during embryogenesis when cells differentiate into various tissues and organs  2  , but also later in life  3  .\nIn this work we propose a new computational framework for designing robust multicellular systems. Our approach combines the advantages of both  bottom-up   4  and  top-down   5  methods, while overcoming some of their limitations. Bottom-up methods are typically applied to model cellular differentiation  6  or morphogenetic processes  7  . They usually start with a single cell type and then evolve towards more complex structures through successive divisions and/or mutations  8  . Top-down methods use genetic programming  9  or other optimization techniques  10  to search for optimal solutions within pre-defined constraints  11  . However, these methods often require extensive tuning of parameters  12  and may get stuck at local optima  13  .\nOur approach uses a novel concept called  embryo-",
        "watermark_text": "We suggest an proposal to robust multi - cell developmental architecture that combines the advantages of both bottom - up and bottom - down approaches , while eliminating their different disadvantages . The proposed approach is based on a new theory called embryonic development space ( EDS ) which includes all possible designs in terms of gene groups and links between them .We see how EDS can be used for efficient exploration of different designs by using evolutionary techniques . Finally we prove our approach using two case studies - one natural and another biological .Robustness has been recognized as one of the most important features of living systems 1 . In particular , it serves crucial role during embryogenesis when cells transform into various tissues and tissues 2 , but also subsequently in life 3 .In this project we develop a new computational framework for constructing robust multicellular systems . Our solution combines the advantages of both bottom - up 4 and bottom - down 5 methods , while overcoming some of their limitations .Bottom - up methods are typically utilized to model cell differentiation 6 or morphogenetic pathways 7 . They often beginning with a single cell type and then evolve towards more sophisticated types through consecutive divisions and / or variants 8 .Top - down methods using genetic programming 9 or other optimization tools 10 to search for efficient answers within pre - defined constraints 11 . However , these algorithms often use extensive tuned of constraints 12 and may come stuck at local optima 13 .Our concept employs a novel concept called embryo -",
        "ori-fast-z-score": 0.3621429841700741,
        "water-fast-z-score": 9.0
    },
    {
        "original_text": "We present the results on X-ray luminosity, temperature, gas mass fraction and YX (the product of these three quantities) for a sample of 62 galaxy clusters observed with XMM-Newton. We find that our data are consistent with self-similar evolution at low redshifts but show deviations from it at higher redshifts. The deviation is more pronounced when we use the SZ signal to estimate cluster masses instead of using the X-ray temperatures. This may be due to non-thermal pressure support or biases introduced by different selection effects between X-ray and SZ surveys. Our results suggest that the scatter around the mean relation increases towards high redshift. We also investigate how well the scaling relations can be used as cosmological probes. Using the current observational constraints on the Hubble constant H0 = 73 km s-1 Mpc-1 , matter density parameter Omega_m = 0.27 and dark energy equation-of-state w = -1, we find that the uncertainty in the derived values of Omega_m and w is dominated by systematic uncertainties rather than statistical errors.",
        "watermark_text": "We present the results on X - ray luminosity , temperature , gas mass fraction and YX ( the product of these three quantities ) for a sample of 62 galaxy galaxies found with XMM - Newton . We see that our statistics are compatible with self - similar development at low redshifts but display deviations from it at higher redshifts .The deviation is more pronounced when we using the SZ signal to estimate cluster masses rather of using the X - ray temperatures . This might be due to non - cooling stress support or biases created by various selection effects between X - ray and SZ measurements .Our results propose that the scatter around the mean relation rises towards high redshift . We additionally observe how best the scaling relations can be used as cosmological probes .Using the present observational restrictions on the Hubble constant H0 = 73 km s - 1 Mpc - 1 , matter density variable Omega _ m = 0 . 27 and dark energy equation - of - state w = - 1 , we find that the uncertainty in the derived values of Omega _ m and v is dominated by systematic uncertainties rather than statistical mistakes .",
        "ori-fast-z-score": 0.11396057645963795,
        "water-fast-z-score": 5.887840577551898
    },
    {
        "original_text": "The SNO+ experiment is designed to measure the neutrino fluxes in the energy range between 1 MeV and 20 MeV, with an expected sensitivity at low energies comparable to that achieved by Super-Kamiokande (SK). The measurement will be performed using two detection techniques: charged-current interactions on deuterium nuclei via elastic scattering off electrons; neutral current reactions on carbon nuclei through coherent elastic scattering off neutrons. \n \n In this work we present results for the predicted rates of these processes as well as their uncertainties based on state-of-the-art Standard Solar Models (SSMs) and nuclear cross sections. We also discuss how the experimental data can help to constrain SSM parameters such as the helium abundance YHe or the heavy element abundances Z/X. Finally, we show how the combination of different experiments may allow us to test whether the observed neutrinos are produced mainly in pp-chain fusion reactions or in CNO cycles.",
        "watermark_text": "The SNO + experiment is designed to measure the neutrino fluxes in the power range between 1 MeV and 20 MeV , with an anticipated sensitivity at low energies comparable to that attained by Super - Kamiokande ( SK ) . The measurement will be performed using two detection methods : charged - current interactions on deuterium nuclei via elastic scattering off electrons ; neutral current reactions on carbon atoms through coherent elastic scattering off neutrons .In this research we present results for the expected rates of these mechanisms as well as their uncertainties according on state - of - the - art Standard Solar Models ( SSMs ) and reactor cross sections . We additionally discuss how the empirical data can help to constrain SSM characteristics such as the helium abundance YHe or the heavy atom abundances Z / X .Finally , we show how the combination of different experiments could enable us to test whether the seen neutrinos are produced chiefly in pp - chain fusion events or in CNO cycles .",
        "ori-fast-z-score": 0.48507125007266594,
        "water-fast-z-score": 5.658135095031152
    },
    {
        "original_text": "We present an accurate analytical model for the description of optical precursors in ultrashort laser pulses propagating through dispersive media, which is based on the concept of nonlinear phase modulation by self-phase-modulation (SPM) and cross-phase-modulation (XPM). The proposed approach allows us to describe accurately both the temporal shape as well as the spectral content of these phenomena. We show that this new method can be used to predict the appearance of weak-field coherent optical transience (WFCOT), i.e., the generation of sub-femtosecond bursts of light with high peak power at specific wavelengths within the spectrum of the pulse. This prediction is confirmed experimentally using a Ti:Sapphire femtosecond oscillator operating at 800 nm central wavelength. Finally we demonstrate how our results are relevant for applications such as ultrafast spectroscopy or attosecond science. \n \n Optical precursors have been observed since the early days of ultrafast optics  1–3  . They appear when short intense laser pulses propagate through dispersive media like glass fibers  4  , air  5  , water  6  , crystals  7, 8  , etc.. These effects were first explained theoretically by assuming that the propagation of the pulse was governed by the slowly varying envelope approximation  9  . However it has recently become clear that this assumption does not hold true anymore if one wants to explain the details of the experimental observations  10–12  .\n \nIn order to overcome this limitation several authors have developed more sophisticated models  13–19  . In particular, the so-called generalized nonlinear Schrödinger equation (GNLSE)  20, 21  has proven very useful because it takes into account all orders of dispersion  22  , self-steepening  23  , third-order dispersion  24  , Raman scattering  25  , stimulated Brillouin scattering  26  , self-frequency shift  27  , plasma defocusing  28  , gain saturation  29  , and other higher-order effects  30  . \n \nHowever, despite its successes, there still remain some discrepancies between theory and experiment  31  . For example, the GNLSE predicts that the intensity profile of the precursor should always exhibit a smooth bell-shaped structure  32 ",
        "watermark_text": "We present an accurate analytical explanation for the description of optical precursors in ultrashort laser pulses propagating through dispersive media , which is based on the idea of nonlinear phase modulation by self - phase - modulation ( SPM ) and cross - phase - modulation ( XPM ) . The proposed approach allows us to explain precisely both the temporal shape as well as the spectral content of these phenomena .We suggest that this new method can be used to predict the appearance of weak - field unified optical transience ( WFCOT ) , i . e . , the generation of sub - femtosecond bursts of light with high peak power at defined wavelengths within the spectrum of the pulse . This prediction is reported experimentally utilizing a Ti : Sapphire femtosecond oscillator running at 800 nm central frequency .Finally we prove how our findings are applicable for applications such as ultrafast spectroscopy or attosecond research . Optical precursors have been observed since the early days of ultrafast optics 1 – 3 .They arise when short intense laser messages propagate through dispersive media like glass fibers 4 , air 5 , water 6 , particles 7 , 8 , etc . . These effects were first explained theoretically by assuming that the propagation of the signal was regulated by the slowly varying envelope approximation 9 .However it has recently become clear that this claim does not stand true anymore if one wants to explain the details of the empirical observations 10 – 12 . In try to overcome this limitation many writers have developed more sophisticated models 13 – 19 .In particular , the so - called generalized nonlinear Schrödinger equation ( GNLSE ) 20 , 21 has proven very useful because it takes into consideration all orders of dispersion 22 , self - steepening 23 , fourth - order dispersion 24 , Raman absorption 25 , stimulated Brillouin absorption 26 , self - frequency shift 27 , plasma defocusing 28 , gain saturation 29 , and other higher - order effects 30 . However , despite its successes , there still continue some discrepancies between theoretical and experiment 31 .For instance , the GNLSE predicts that the intensity profile of the precursor should always exhibit a straight bell - shaped structure 32",
        "ori-fast-z-score": 2.1053798026662975,
        "water-fast-z-score": 7.888304767988878
    },
    {
        "original_text": "We present the results of long-term numerical simulations of binary black hole (BBH) evolution, including gravitational radiation reaction and general relativistic effects such as frame dragging and tidal disruption. We focus on binaries with total mass M = 100-1000M⊙ that evolve through collisional nuclear environments at high redshifts z > 10. Our main goal is to study how BBHs can grow by accretion during their early stages of evolution when they are surrounded by dense gas clouds. In particular we investigate whether these systems can reach masses above 1000M⊙ before merging within a Hubble time. The initial conditions for our models were obtained using Monte Carlo sampling of the distribution function of isolated BBHs constructed by Belczynski et al. (2010) . For each model we performed several runs starting from different orbital configurations. All calculations were carried out assuming circular orbits. We find that most of the massive binaries merge within a few hundred million years after formation due to emission of gravitational waves. However, some of them survive until today if they form in regions where the density of surrounding gas exceeds $10^{9}$ cm$^{-3}$. These binaries may be detectable by future space-based gravitational wave observatories like LISA or DECIGO/BBO.",
        "watermark_text": "We present the conclusion of long - term numerical simulations of binary dark hole ( BBH ) development , notably gravitational radiation reaction and general relativistic effects such as frame dragging and tidal disruption . We focus on binaries with total mass M = 100 - [UNK] that develop through collisional nuclear habitats at high redshifts z > 10 .Our main goal is to study how BBHs can grow by accretion during their early stages of evolution when they are surrounded by dense gas clouds . In particular we investigate whether these systems can reach masses above [UNK] before merging within a Hubble time .The initial conditions for our models were obtained using Monte Carlo analysis of the distribution function of isolated BBHs generated by Belczynski et al . ( 2010 ) .For each model we performed numerous runs beginning from varying orbital locations . All calculations were carried out assuming circular orbits .We see that most of the huge binaries dissolve within a few hundred million months after formed due to emission of gravitational waves . However , some of them remain until today if they exist in areas where the density of neighbouring gas approaches $ 10 ^ { 9 } $ cm $ ^ { - 3 } $ .These binaries may be detectable by future space - based gravity wave observatories like LISA or DECIGO / BBO .",
        "ori-fast-z-score": 0.5129891760425771,
        "water-fast-z-score": 5.437685266051317
    },
    {
        "original_text": "The Axion Dark Matter Search (ADMX) experiment is designed to search for dark matter in the form of axions, which are hypothetical particles predicted by theories beyond the Standard Model.  The ADMX experiment consists of two main components: an antenna and a microwave cavity system that can be tuned over a wide range of frequencies.   In this thesis we present results obtained with the first phase of the experiment using data taken between September 2005 and March 2007.    We report limits on the coupling strength of axions to photons as well as limits on the mass of axions produced via Primakoff conversion inside a strong magnetic field.  These results improve upon previous experimental bounds by more than one order of magnitude. This work was performed under the auspices of the U.S Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. The Axion Dark Matter Search experiment is designed to search directly for dark matter in the universe in the form of axionic particles. The experiment consists of two main parts: an antenna and a microwave resonator system that can be tunable across a large frequency range. In this dissertation I will discuss our recent results from the first stage of the experiment.",
        "watermark_text": "The Axion Dark Matter Search ( ADMX ) experiment is designed to search for black material in the form of axions , which are hypothetical particles expected by theories beyond the Standard Model . The ADMX experiment consists of two principal portions : an antenna and a microwave cavity network that can be tuned over a broad variety of frequencies .In this dissertation we present results derived with the first phase of the program including data taken between September 2005 and March 2007 . We report limits on the interaction strength of axions to photons as well as limits on the mass of axions produced via Primakoff transformation inside a powerful magnetic force .These data improve upon former empirical bounds by more than one order of magnitude . This research was done under the auspices of the U . S Department of Energy by Lawrence Livermore National Laboratory under Contract DE - AC52 - 07NA27344 .The Axion Dark Matter Search experiment is designed to search specifically for black material in the universe in the form of axionic particles . The project consists of two principal parts : an antenna and a microwave resonator system that can be tunable across a large frequency spectrum .In this dissertation I will explore our latest findings from the first phase of the project .",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 6.413001035278336
    },
    {
        "original_text": "We propose that gamma-ray bursts (GRBs) are the result of collisions between primordial black holes and stars in globular clusters, which occur at rates predicted by current models for GRB production.  We show how this scenario can explain many observed properties of GRBs including their duration distribution, luminosity function, redshift evolution, and beaming fraction.   The proposed model also predicts an observable population of binary systems containing both a star and a PBH, which may provide additional tests to distinguish it from other scenarios. Gamma-ray bursts (GRBs; see Figure 1 ) are intense flashes of high-energy radiation lasting only milliseconds up to several minutes  1  . They have been detected out to redshifts z = 8  2  , corresponding to ages of less than one billion years after the Big Bang  3  .\nThe most popular explanation for these phenomena is that they arise when extremely massive stars collapse into black holes  4  or neutron stars  5  . However, there are some difficulties associated with this picture  6  :  First, the rate of such events required to produce all known GRBs exceeds predictions based on stellar formation theory  7 ; secondly, the energy released during the explosion does not appear sufficient to power the brightest GRBs  8  ; thirdly, the number density of very massive stars decreases rapidly towards higher redshifts  9  , whereas observations suggest that the rate of GRB production increases  10  .  Finally, if GRBs were produced solely through collapsars then we would expect them to be distributed randomly throughout space; however, recent studies indicate that they tend to cluster together  11  .\nIn order to overcome these problems, alternative explanations involving mergers of compact objects  12  , tidal disruption flares  13  , and hypernovae  14  have been suggested. In addition,...",
        "watermark_text": "We suggest that gamma - ray clusters ( GRBs ) are the result of collisions between primordial black holes and stars in globular complexes , which occur at levels predicted by current scenarios for GRB development . We see how this situation can describe several observed properties of GRBs notably their duration distribution , luminosity function , redshift development , and beaming fraction .The proposed theory even predicts an observable population of binary systems featuring both a star and a PBH , which would offer additional studies to distinguish it from other scenarios . Gamma - ray bursts ( GRBs ; view Figure 1 ) are intense pulses of high - energy rays lasting only milliseconds up to several seconds 1 .They have been detected out to redshifts z = 8 2 , equivalent to periods of fewer than one billion days after the Big Bang 3 . The most popular reason for these phenomena is that they occur when immensely massive galaxies fall into black holes 4 or neutron galaxies 5 .However , there are some difficulties related with this picture 6 : First , the frequency of such events required to produce all known GRBs increases assumptions based on stellar formation theory 7 ; secondly , the electricity created during the explosion does not appear adequate to power the brightest GRBs 8 ; thirdly , the number density of very huge stars reduces rapidly towards higher redshifts 9 , whereas observations suggest that the frequency of GRB generation rises 10 . Finally , if GRBs were produced solely through collapsars then we would expect them to be spread randomly throughout space ; however , recent studies confirm that they tend to group together 11 .In try to overcome these problems , alternative theories involving mergers of compact objects 12 , tidal disruption flares 13 , and hypernovae 14 have been proposed . In addition , . . .",
        "ori-fast-z-score": 0.3481553119113957,
        "water-fast-z-score": 8.87796045374059
    },
    {
        "original_text": "We study the effects of noise on spatially extended systems by using an extension of the concept of nonequilibrium potential (NEP). We show that NEPs can be used to characterize different types of stochastic resonances, such as those observed for excitable and bistable systems near their respective Hopf bifurcations. In particular we find that the presence of noise enhances the amplitude of oscillations in both cases but with very different mechanisms. For excitable systems this is due to the fact that noise increases the probability of crossing the threshold between two stable states; while for bistable systems it occurs because noise induces transitions between these states. Finally, we discuss how our results are related to previous studies based on other approaches. Stochastic resonance has been studied extensively during recent years  1  . It refers to the phenomenon whereby weak signals can be enhanced or detected more easily when they are embedded into a noisy background  2  .\nIn many physical situations, however, one needs to consider not only the effect of external noise sources but also internal fluctuations arising from the dynamics itself  3  . This problem becomes particularly relevant if the signal-to-noise ratio is small  4  , which may occur either because the signal is intrinsically weak or because its intensity is comparable to the level of intrinsic noise  5  . Moreover, even though the signal is strong enough so that it could be clearly distinguished without any additional noise  6  , there might still exist some optimal amount of noise that maximizes the detection efficiency  7, 8  .",
        "watermark_text": "We research the effects of noise on spatially extended systems by using an extension of the idea of nonequilibrium potential ( NEP ) . We see that NEPs can be used to characterize many kinds of stochastic resonances , such as those observed for excitable and bistable systems near their different Hopf bifurcations .In particular we find that the presence of noise enhances the frequency of oscillations in both cases but with very different mechanisms . For excitable systems this is due to the fact that noise changes the probability of reaching the threshold between two stable states ; while for bistable systems it appears because sound induces transitions between these states .Finally , we talk how our findings are related to previous research based on other methods . Stochastic resonance has been studied significantly during recent seasons 1 .It refers to the situation whereby soft signals can be enhanced or detected more easily when they are lodged into a loud background 2 . In many physical conditions , however , one needs to consider not only the impact of external sound sources but also internal fluctuations originating from the dynamics itself 3 .This problem appears particularly relevant if the signal - to - noise proportion is tiny 4 , which may happen either because the signal is intrinsically weak or because its brightness is equal to the level of intrinsic noise 5 . Moreover , even though the signal is strong enough so that it could be obviously differentiated without any additional noise 6 , there might nevertheless exist some optimal level of noise that maximizes the detection efficiency 7 , 8 .",
        "ori-fast-z-score": 0.38138503569823695,
        "water-fast-z-score": 6.928853368993243
    },
    {
        "original_text": "The Sloan Digital Sky Survey (SDSS) is an ambitious project to map one quarter of the sky in five photometric bands, and obtain spectra for over 100 million galaxies, quasars, stars, and other celestial objects.  The survey has been completed on two thirds of its original footprint; it will be complete by 2008. This talk describes some of the science that can be done using this data set. It also discusses how astronomers are working together to make use of these vast resources. In particular I describe my own work on studying galaxy clusters as dark matter halos, measuring their masses through gravitational lensing effects, and determining their evolution across cosmic time. Finally, I discuss plans for future surveys which will build upon SDSS s successes. The Sloan Digital Sky Survey is an ambitious project to measure the positions and redshifts of more than 100 million galaxies, quasARS, stars, and other objects in our Universe.",
        "watermark_text": "The Sloan Digital Sky Survey ( SDSS ) is an ambitious project to map one quarter of the heavens in five photometric bands , and collect spectra for over 100 million galaxies , quasars , stars , and other celestial entities . The survey has been completed on two thirds of its initial footprint ; it will be full by 2008 .This discussion describes some of the science that can be performed using this data set . It especially discusses how astronomers are working united to make using of these enormous resources .In particular I outline my own research on studying galaxy galaxies as dark matter halos , measuring their masses through gravity lensing effects , and determining their development across universe time . Finally , I discuss projects for future surveys which will build upon SDSS s successes .The Sloan Digital Sky Survey is an ambitious project to measure the places and redshifts of more than 100 million galaxies , quasARS , stars , and other objects in our Universe .",
        "ori-fast-z-score": 1.016001016001524,
        "water-fast-z-score": 6.604006604009906
    },
    {
        "original_text": "BiFeO3 is an antiferromagnetic insulator with high Curie temperature (TC = 1103 K) that exhibits ferroelectricity at room temperature when doped or under pressure. Here we report the observation of spontaneous magnetization, M(T), and electrical polarization, P(E), simultaneously existing over wide ranges of temperatures up to 300 K in pure BiFeO3 single crystal grown by flux method. The results show that both M(T) and P(E) are nearly independent on each other below TC but they start to decrease rapidly above TC. We also found that the magnitude of M(T) decreases faster than that of P(E). These observations suggest that there exists strong coupling between spin and lattice degrees of freedom in this material. \n \n Keywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",
        "watermark_text": "BiFeO3 is an antiferromagnetic insulator with high Curie temperature ( TC = 1103 K ) that exhibits ferroelectricity at room temperature when doped or under pressure . Here we document the observation of induced magnetization , M ( T ) , and electrical polarization , P ( E ) , independently operating over broad ranges of conditions up to 300 K in pure BiFeO3 single crystal grown by flux technology .The results show that both M ( T ) and P ( E ) are nearly independent on each other below TC but they start to decline rapidly above TC . We additionally found that the magnitude of M ( T ) decreases quicker than that of P ( E ) .These measurements suggest that there exists strong coupling between spin and lattice degrees of liberty in this material . Keywords : Room - temperature multiferroic materials , BiFeO3 , Electric polarization , Magnetic properties , Flux growth technique .",
        "ori-fast-z-score": 0.14285714285714285,
        "water-fast-z-score": 3.857142857142857
    },
    {
        "original_text": "We present the results of an investigation into the physical properties of weak Mg II absorbers (WAs) in quasar spectra, using high-resolution spectroscopy and photoionization modeling. We find that WAs are typically associated with galaxies having stellar masses M* ~ 10^10 to 10^11 solar masses, star formation rates SFR = 0.1-10 Msun/yr, and metallicities Z = 0.2 - 1 times solar metallicity. The majority of these systems have low ionization parameters log U < -2.5, indicating they are likely dominated by diffuse gas rather than dense clouds. These findings suggest that WAs may be related to galactic winds driven out of star-forming regions. In addition we find evidence for two distinct populations of WAs; one population is characterized by relatively strong absorption lines which appear to arise primarily within galaxy halos, while another population has weaker absorption features which seem to originate closer to the central region of their host galaxies.",
        "watermark_text": "We present the conclusion of an research into the physical properties of weak Mg II absorbers ( WAs ) in quasar spectra , using high - resolution spectroscopy and photoionization mapping . We see that WAs are typically associated with galaxies having stellar masses M * ~ 10 ^ 10 to 10 ^ 11 solar masses , star formation rates SFR = 0 . 1 - 10 Msun / yr , and metallicities Z = 0 . 2 - 1 twice solar metallicity .The majority of these systems have lowest ionization factors log U < - 2 . 5 , showing they are likely dominated by diffuse plasma rather than dense clouds . These studies imply that WAs might be due to galactic winds driven out of galaxy - creating areas .In addition we find proof for two separate populations of WAs ; one community is characterized by relatively strong absorption patterns which appear to arise principally within star halos , while another population has less absorption elements which appear to arise farther to the inner region of their host galaxies .",
        "ori-fast-z-score": -0.47809144373375745,
        "water-fast-z-score": 6.215188768538847
    },
    {
        "original_text": "We present an algorithm to find galaxy groups using photometric redshifts, which is based on the Voronoi tessellation technique (VT). The VT method has been widely used for identifying clusters of galaxies with spectroscopic redshifts but it had not yet been applied to identify galaxy groups with photometric redshifts. We use the Sloan Digital Sky Survey data release five (SDSS DR5) as our input sample. Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available. In this work we have identified more than 12000 galaxy groups at 0 < z < 0.3. These groups contain about 30000 member galaxies. We also provide a catalog containing basic information such as positions, magnitudes, colors, and photometric redshifts for all these groups. \n \n Keywords: Galaxy Group, Photometric Redshift",
        "watermark_text": "We present an algorithm to find galaxy groups using photometric redshifts , which is based on the Voronoi tessellation method ( VT ) . The VT method has been widely using for finding clusters of stars with spectroscopic redshifts but it had not already been used to identify galaxy groups with photometric redshifts .We use the Sloan Digital Sky Survey data release five ( SDSS DR5 ) as our input data . Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available .In this research we have discovered more than 12000 star groups at 0 < z < 0 . 3 . These groups contain about 30000 member galaxies .We additionally offer a list containing essential information such as positions , magnitudes , colors , and photometric redshifts for all these groups . Keywords : Galaxy Group , Photometric Redshift",
        "ori-fast-z-score": -1.2602520756252087,
        "water-fast-z-score": 3.2206441932644223
    },
    {
        "original_text": "In this work, we consider a multiple-input-multiple-output (MIMO) system where each transmitter has limited feedback information about its channel state to the receiver. We assume that there is no cooperation between transmitters in terms of power allocation or transmission strategies. Each transmitter can only adjust its own transmit power level based on local CSI knowledge at the transmitter side. In addition, each transmitter may turn off its radio completely when it does not have any data to send. The objective is to maximize the sum rate by optimizing both the power control policy as well as the transmission strategy for all users simultaneously under these constraints. \n \n First, we derive an upper bound on the achievable sum-rate using finite-rate feedback assuming Gaussian codebooks. Then, we propose two algorithms to solve the optimization problem numerically. Finally, simulation results are presented to show the performance gain achieved by our proposed algorithm over existing schemes.",
        "watermark_text": "In this research , we study a multiple - input - multiple - output ( MIMO ) scheme where each antenna has restricted feedback info about its channel state to the receiver . We assume that there is no cooperation between transmitters in terms of power distribution or transmission strategies .Each antenna can only alter its own transmit energy level based on local CSI information at the transmitter side . In addition , each antenna could switch off its broadcast completely when it does not have any info to carry .The goal is to maximize the sum frequency by optimizing both the power control strategy as well as the transmission strategy for all users simultaneously under these requirements . First , we derive an upper bound on the achievable sum - speed using finite - frequency feedback assuming Gaussian codebooks .Then , we propose two strategies to solve the algorithms issue numerically . Finally , simulation data are presented to see the performance gain achieved by our proposed algorithm over existing strategies .",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 6.114295984380816
    },
    {
        "original_text": "The vortex dynamics is studied numerically for fractal cluster structure (FCCS) superconductor by solving time-dependent Ginzburg-Landau equations under an external magnetic field. The FCCS has been proposed as one possible candidate to explain the origin of high-Tc cuprates, and it consists of randomly distributed clusters which are connected each other via Josephson coupling. We find that the resistivity increases rapidly when the applied current exceeds some threshold value Ic(H), where H denotes the strength of the external magnetic field. This behavior can be understood by considering the motion of vortices inside the clusters. In addition, we show that the critical current density Jc decreases gradually with increasing temperature T . Finally, we discuss how these results may be relevant to experiments on high-Tc cuprate superconductors. PACS: 74.20.-q; 74.25.+s; 74.60.Bz; 74.70.-k",
        "watermark_text": "The vortex dynamics is studied numerically for fractal cluster structure ( FCCS ) superconductor by modeling period - dependent Ginzburg - Landau equations under an external magnetic force . The FCCS has been proposed as one possible candidate to explain the origin of high - Tc cuprates , and it consists of randomly distributed clusters which are connected each other via Josephson coupling .We see that the resistivity increases quickly when the introduced current reaches some threshold factor Ic ( H ) , where H represents the strength of the external magnetic force . This phenomenon can be understood by analyzing the movement of vortices inside the clusters .In addition , we show that the critical current density Jc falls gradually with rising heat T . Finally , we talk how these results may be applicable to experiments on high - Tc cuprate superconductors .PACS: 74.20.-q; 74.25.+s; 74.60.Bz; 74.70.-k",
        "ori-fast-z-score": 0.5252257314388902,
        "water-fast-z-score": 5.252257314388902
    },
    {
        "original_text": "The Kuiper belt is the source region for most short period comets, but its formation remains poorly understood. We present results from N-body simulations that show how collisions among planetesimals in Neptune s feeding zone can produce objects with orbits similar to those observed today. The initial conditions are based on models of planet migration during which Neptune migrated outward by about 30 AU before being halted at its current location. Our calculations suggest that the Kuiper belt formed as a result of collisional grinding between bodies whose sizes were comparable to Pluto (r ~ 1000 km). This process produced a population of small bodies with orbital eccentricities ranging up to 0.3. Subsequent encounters with Neptune caused some of these bodies to be scattered into highly eccentric orbits. These results provide an explanation for why there appears to be no correlation between the size distribution of KBOs and their orbital eccentricity.",
        "watermark_text": "The Kuiper belt is the origin region for most short period comets , but its formation appears poorly known . We publish results from N - bodies simulations that demonstrate how collisions among planetesimals in Neptune s feeding area can generate objects with orbits similar to those observed currently .The initial conditions are based on estimates of planet migration during which Neptune migrated outward by about 30 AU before being stopped at its current site . Our calculations suggest that the Kuiper belt developed as a outcome of collisional grinding between bodies whose sizes were analogous to Pluto ( r ~ 1000 kilometers ) .This process produced a population of tiny bodies with orbital eccentricities ranging up to 0 . 3 . Subsequent experiences with Neptune resulted some of these objects to be scattered into extremely eccentric orbits .These data provide an reason for why there seems to be no correlation between the size distribution of KBOs and their orbital eccentricity .",
        "ori-fast-z-score": -0.9847319278346618,
        "water-fast-z-score": 5.333493587335964
    },
    {
        "original_text": "We study the effect of temperature dependent shape anisotropy in an exchange coupled system consisting of two identical uniaxial single domain particles, one being magnetically softer than the other and both having their easy axes parallel to each other. We show that for certain values of the parameters involved there is a significant increase in the coercive field at low temperatures compared to high temperatures. This can be understood by considering the competition between the Zeeman energy barrier due to the applied magnetic field and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy. \n \n The model we consider consists of two identical spherical particles (with radius R) separated by a distance d along the z-axis. Each particle has its own uniaxial anisotropy constant Ks(T), where T denotes the temperature. In addition, they are also exchange-coupled through a coupling constant J. For simplicity, we assume that the anisotropy constants have the same functional form as given below, \n \n Ks = K1 + K2 tanh -(T/Tc) ,\n \nwhere Tc is some characteristic temperature scale which determines how rapidly the anisotropy changes with temperature.",
        "watermark_text": "We explore the impact of temperature dependent shape anisotropy in an exchange coupled system consisting of two different uniaxial single domain particles , one being magnetically softer than the other and both having their easy axes aligned to each other . We see that for particular values of the variables required there is a substantial rise in the coercive field at low temperatures relative to low temperatures .This can be understood by analyzing the competition between the Zeeman power barrier resulting to the introduced magnetic force and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy . The model we define consists of two equal spherical atoms ( with diameter R ) connected by a length d along the z - axis .Each particle has its own uniaxial anisotropy constant Ks ( T ) , where T denotes the temperature . In addition , they are also exchange - coupled through a coupling constant J .For simplicity , we suppose that the anisotropy constants have the same functional shape as provided below , Ks = K1 + K2 tanh - ( T / Tc ) , where Tc is some characteristic temperature scale which determines how swiftly the anisotropy changes with temperature .",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 5.590169943749474
    },
    {
        "original_text": "We present an exact quantum-mechanical treatment for the dynamics of open systems in which the system is coupled to many harmonic oscillators representing its surrounding environment.  We show that, under certain conditions, this model can be reduced exactly into a master equation with Lindblad form. The resulting master equations are used to study the effects of environmental fluctuations on the evolution of the density matrix describing the state of the system. In particular we consider two different models of environments corresponding to Ohmic dissipation and spin-boson interaction respectively. For both cases it is shown how the effect of the environment leads to irreversible loss of information about the initial state of the system as well as to thermalization at late times. Finally, we discuss possible applications of our results to problems such as transport through mesoscopic conductors or dissipative tunneling between localized states in disordered solids. Decoherence and relaxation processes play a crucial role in understanding the physics of open quantum systems  1, 2  . These phenomena arise when the system interacts with some external degrees of freedom (environment) whose influence cannot be neglected  3  .\nIn recent years there has been considerable interest in developing theoretical methods capable of treating these effects beyond the perturbative regime  4  . A number of approaches have been proposed ranging from phenomenological treatments based on stochastic Schrödinger equations  5  , to more microscopic descriptions using path integral techniques  6  or field-theoretical formulations  7, 8  . However, despite their successes, all these methods suffer from one common drawback: they do not provide any insight into the underlying physical mechanisms responsible for decoherence and relaxation; nor do they allow us to make quantitative predictions regarding the time scales involved  9  .\nRecently, several authors  10 -12  have suggested that the problem may be tackled within the framework of quantum mechanics itself. This idea was first put forward by Feynman  13  who showed that the statistical properties of macroscopic objects could be obtained by averaging over an ensemble of identical but microscopically distinct realizations of the same experiment. More recently, Leggett  14  introduced a method...",
        "watermark_text": "We present an precise quantum - mechanical explanation for the dynamics of open systems in which the system is linked to many harmonic oscillators describing its surrounding environment . We see that , under certain conditions , this description can be reduced exactly into a master equation with Lindblad form .The resulting master equations are using to study the effects of environmental fluctuations on the evolution of the density graph explaining the state of the system . In particular we investigate two different models of environments corresponding to Ohmic dissipation and spin - boson collision respectively .For both cases it is demonstrated how the impact of the surroundings leads to irreversible loss of information about the first state of the system as well as to thermalization at late times . Finally , we explain possible applied of our findings to problems such as transport through mesoscopic conductors or dissipative tunneling between localized states in disordered solids .Decoherence and relaxation processes take a crucial role in understanding the physics of open quantum systems 1 , 2 . These phenomena arise when the system interacts with some external degrees of autonomy ( surroundings ) whose influence cannot be forgotten 3 .In recent years there has been substantial interest in pursuing theoretical methods suitable of addressing these phenomena beyond the perturbative regime 4 . A variety of methods have been proposed ranging from phenomenological treatments based on stochastic Schrödinger coefficients 5 , to more microscopic descriptions using path integral methods 6 or field - theory formulations 7 , 8 .However , despite their successes , all these algorithms suffer from one common drawback : they do not offer any insight into the fundamental physical mechanisms involved for decoherence and relaxation ; nor do they allow us to make quantitative predictions regarding the period scales involved 9 . Recently , various scientists 10 - 12 have suggested that the issue may be tackled within the framework of quantum mechanics itself .This idea was first put forward by Feynman 13 who demonstrated that the empirical qualities of macroscopic objects may be obtained by averaging over an ensemble of different but microscopically different realizations of the same experiment . More recently , Leggett 14 proposed a technique . . .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.905694150420948
    },
    {
        "original_text": "We present new results on the properties and evolution of early-type galaxies (ETGs) in the Coma cluster, based on deep HST/ACS imaging data obtained as part of our ongoing survey for faint globular clusters associated with ETGs.  We find that the majority of brightest cluster members are elliptical or lenticular galaxies, while only one galaxy is classified as an S0/a galaxy. The fraction of S0s increases towards fainter luminosities, reaching about 50% at M V = −18 mag. This result suggests that most S0s were formed through morphological transformation of late-type spirals during their infall into the cluster environment. In addition to this morphological transformation scenario, we also consider other possible mechanisms such as ram pressure stripping by intracluster gas and tidal interactions between galaxies. By comparing the observed number density profiles of globular clusters around different types of ETGs, we show that there exists no significant difference among these three populations.",
        "watermark_text": "We report new data on the properties and evolution of early - class objects ( ETGs ) in the Coma cluster , using on deep HST / ACS scanning data acquired as part of our ongoing search for faint globular galaxies involved with ETGs . We see that the majority of brightest cluster elements are elliptical or lenticular galaxies , while only one galaxy is categorized as an S0 / a galaxy .The percentage of S0s increases towards fainter luminosities , increasing about 50 % at M V = −18 mag . This result suggests that most S0s were created through morphological transformation of late - class spirals during their infall into the cluster environment .In addition to this morphological transformation situation , we also consider other possible processes such as ram temperature stripping by intracluster gas and tidal interactions between galaxies . By matching the reported number density characteristics of globular complexes around different kinds of ETGs , we prove that there exists no major variation among these three communities .",
        "ori-fast-z-score": -1.4770978917519928,
        "water-fast-z-score": 5.662208585049306
    },
    {
        "original_text": "En este trabajo se estudia la existencia y estabilidad de agujeros de gusano en el espacio tiempo descrito por una solución exacta del campo gravitacional generado por un cuerpo esférico con simetría axial, que corresponde al caso más simple de agujero negro no rotante. Se muestra que los agujeros de gusano son estables bajo ciertas condiciones sobre las constantes cosmológicas involucradas. Además, se presenta una nueva clase de soluciones exactas para el problema de Einstein-Klein-Gordon en espacios homogéneos e isótropos. Estas soluciones corresponden a ondas escalares estacionarias localizadas alrededor de un punto singular donde existe una densidad infinita de energía escalar. Finalmente, se discute brevemente cómo estas soluciones pueden ser utilizadas como fuentes de radiación gravitatoria coherente. En este trabajo estudiamos la existencia y estabilidad de los llamados agujeros de gusano  en el espacio-tiempo descrito por una solución exacta correspondiente al campo gravitacional generado por una esfera con simetría axial. Esta solución corresponde al caso más sencillo posible de agujero negro sin rotación. Mostramos que estos agujeros de gusano resultan ser estables bajo determinadas condiciones sobre las constantes cosmológica involucradas.  También presentamos una nueva clase de soluciones exáctas para el problema de Klein-Gordon-Einstein en espacios homogéneos isotrópicos. Estas soluciones corresponden a olas escalares estacionarias localizdas alrededor de un punto singular en donde hay una densidad infinita de energía escalara. Por último discutimos brevemente cómo estas soluciones pueden utilizarse como fuentes de radiación gravitacional coherente.",
        "watermark_text": "En este trabajo se estudia la existencia y estabilidad de agujeros de gusano en el espacio tiempo descrito por una solución exacta en campo gravitacional generado por un cuerpo esférico con simetría axial , se corresponde un caso más simple de agujero negro no rotante . Se muestra que los agujeros de gusano son estables bajo ciertas condiciones sobre las constantes cosmológicas involucradas .Además , se presenta una nueva clase de soluciones exactas en su problema de Einstein - Klein - Gordon en espacios homogéneos e isótropos . Estas soluciones corresponden a ondas escalares estacionarias localizadas alrededor de un punto singular donde existe una densidad infinita de energía escalar .Finalmente , se discute brevemente cómo estas soluciones pueden ser utilizadas como fuentes de radiación gravitatoria coherente . En este trabajo estudiamos la existencia y estabilidad de los llamados agujeros de gusano en el espacio - tiempo descrito por una solución exacta correspondiente un campo gravitacional generado por una esfera con simetría axial .Esta solución corresponde un caso más sencillo posible de agujero negro sin rotación . Mostramos para estos agujeros de gusano resultan ser estables bajo determinadas condiciones sobre las constantes cosmológica involucradas .También presentamos una nueva clase de soluciones exáctas en su problema de Klein - Gordon - Einstein en espacios homogéneos isotrópicos . Estas soluciones corresponden a olas escalares estacionarias localizdas alrededor de un punto singular en donde hay una densidad infinita de energía escalara .Por último discutimos brevemente cómo estas soluciones pueden utilizarse como fuentes de radiación gravitacional coherente.",
        "ori-fast-z-score": -0.9284766908852594,
        "water-fast-z-score": 2.5018511664883785
    },
    {
        "original_text": "We reply to the comments by A. M. Braden and J. P. Dowling in their Comment  1  . We show that our results are robust against different choices for the fitting range, and we discuss how this is related to the choice of the initial state wave function used in Ref.  2  .\nPACS numbers: 11.10.Wx, 12.20.Ds, 13.25.Gv Quantum tunneling has been studied extensively since its discovery more than half century ago  3  , but it remains an active area of research  4  . In particular, recent experiments have shown that quantum tunneling can be observed even at room temperature  5  . Theoretically, there exist two types of tunneling processes  6  : extrinsic tunneling which occurs when particles move through barriers created by external potentials  7, 8  ; and intrinsic tunneling where particles tunnel between degenerate states without any potential barrier  9  . Intrinsic tunneling plays important roles in many physical systems such as molecular vibrations  10  , nuclear fission  11  , Josephson junctions  12  , Bose-Einstein condensates  13  , and semiconductor superlattices  14  . However, distinguishing intrinsic tunneling from other effects experimentally still poses great challenges  15  .",
        "watermark_text": "We respond to the remarks by A . M . Braden and J . P . Dowling in their Comment 1 . We see that our findings are robust against different decisions for the fitting range , and we explain how this is related to the selection of the first state wave system employed in Ref .2 . PACS scores : 11 . 10 . Wx , 12 . 20 . Ds , 13 . 25 . Gv Quantum tunneling has been studied thoroughly since its discovery more than quarter century ago 3 , but it remains an active area of research 4 .In particular , recent experiments have shown that molecular tunneling can be experienced even at room temperature 5 . Theoretically , there exist two forms of tunneling processes 6 : extrinsic tunneling which occurs when molecules travel through barriers created by external potentials 7 , 8 ; and intrinsic tunneling where ions tunnel between degenerate states without any potential barrier 9 .Intrinsic tunneling performs important roles in different physical structures such as chemical vibrations 10 , nuclear fission 11 , Josephson junctions 12 , Bose - Einstein condensates 13 , and semiconductor superlattices 14 . However , distinguishing intrinsic tunneling from other effects experimentally nevertheless remains big challenges 15 .",
        "ori-fast-z-score": -0.48507125007266594,
        "water-fast-z-score": 5.741963884746346
    },
    {
        "original_text": "We study the phase behavior and structure of binary mixtures composed of soft repulsive spheres with attractive depletants, which are modeled as hard-spheres that interact only via excluded volume interactions. We find that these systems exhibit rich phase diagrams including gas-liquid coexistence at low temperatures for all compositions studied here (0.25 < f < 0.75), where f is the fraction of particles made up by the smaller species. The liquid-gas binodal lines shift to higher pressures upon increasing the size ratio between the two components. For large size ratios we observe an additional fluid-fluid transition line along which both fluids have similar densities but different structures. This new fluid state has been observed experimentally in colloidal suspensions containing nonadsorbing polymer chains. Our results show good agreement with experimental data on colloid-polymer mixtures over wide ranges of temperature, pressure, and composition. \nI. INTRODUCTIO N\nThe presence of small particles can dramatically affect the properties of larger ones through depletion forces  1  . These effects play important roles in many physical phenomena such as protein crystallization  2  , gelation  3  , and sedimentation  4  .\nDepending on their sizes relative to each other, the mixture may be either miscible or immiscible  5  . In addition, there exist regions of metastability  6  and even multiple phases  7, 8  . A number of theoretical studies  9  -  11  have investigated the effect of depletion attractions on the phase diagram of simple model systems. However, most of them focused on idealized models neglecting hydrodynamic interactions  12  , finite-size effects  13  , polydispersity  14  , and particle shape  15  . Only recently did some authors  16  take into account more realistic features like Brownian motion  17  , electrostatic repulsion  18  , and van der Waals attraction  19  . Despite this progress, it remains difficult to predict the exact location of the critical point  20  due to strong correlations  21  among the particles  22  . Moreover, the influence of depletion forces on the structural  23  and dynamical  24  properties of complex fluids still needs further investigation  25  .\nIn recent years, experiments  26 ",
        "watermark_text": "We research the phase response and shape of binary mixtures consisting of soft repulsive balls with interesting depletants , which are modeled as hard - spheres that interact only via excluded volume interactions . We see that these systems exhibit rich phase diagrams including gas - fluid coexistence at low temperatures for all compositions studied here ( 0 . 25 < f < 0 . 75 ) , where f is the fraction of molecules making up by the smaller species .The gas - gas binodal lines shift to higher pressures upon increasing the height factor between the two parts . For large size ratios we study an additional liquid - fluid transition line along which both gases have equal densities but different structures .This new fluid state has been observed experimentally in colloidal suspensions containing nonadsorbing polymer complexes . Our results show good agreement with experimental evidence on colloid - polymer mixtures over broad ranges of temperature , pressure , and composition .I . INTRODUCTIO N The appearance of tiny particles can dramatically impact the properties of bigger ones through depletion forces 1 . These effects play essential roles in different physical phenomena such as protein crystallization 2 , gelation 3 , and sedimentation 4 .Depending on their sizes comparative to each other , the mixture might be either miscible or immiscible 5 . In addition , there exist zones of metastability 6 and even multiple components 7 , 8 .A variety of theoretical investigations 9 - 11 have explored the impact of depletion attractions on the phase diagram of simple model structures . However , most of them focused on idealized models neglecting hydrodynamic interactions 12 , finite - length effects 13 , polydispersity 14 , and electron shape 15 .Only lately did some writers 16 taking into consideration more realistic characteristics like Brownian movement 17 , electrostatic repulsion 18 , and van der Waals attraction 19 . Despite this progress , it remains impossible to predict the exact location of the critical position 20 due to powerful correlations 21 among the ions 22 .Moreover , the impact of depletion forces on the structural 23 and dynamical 24 properties of complex fluids already requires further investigation 25 . In recent years , observations 26",
        "ori-fast-z-score": -0.16012815380508713,
        "water-fast-z-score": 8.009821015753255
    },
    {
        "original_text": "The detection and study of cosmic rays is one of the main goals for imaging atmospheric Cherenkov telescopes (IACTs). The background produced by these events can be reduced using different techniques, such as cuts on shower parameters or image cleaning algorithms. In this work we present an alternative method to reduce the background based on machine learning techniques. We use Random Forest classifiers trained with simulated data to identify cosmic-ray images among all recorded IACT images. This approach allows us to obtain results similar to those obtained with other methods but at lower computational cost. Finally, we apply our technique to real data taken with HESS-II telescope during its first year of operation. Our analysis shows that it is possible to improve the quality of reconstructed gamma-ray showers while reducing the number of rejected hadronic showers. \n \n Keywords: Machine Learning; Cosmic Ray Identification; Image Cleaning; Gamma-ray Astrophysics; Hadronic Shower",
        "watermark_text": "The observation and investigation of cosmic rays is one of the main goals for imaging atmospheric Cherenkov telescopes ( IACTs ) . The background formed by these events can be reduced use different methods , such as cuts on shower parameters or image cleaning algorithms .In this project we present an additional method to reduce the background based on machine learning techniques . We use Random Forest classifiers trained with simulated evidence to identify cosmic - ray pictures among all collected IACT images .This method enables us to obtain results comparable to those acquired with other methods but at lower mathematical price . Finally , we apply our technique to real information taken with HESS - II telescope during its initial season of operation .Our study shows that it is possible to upgrade the performance of reconstructed alpha - ray showers while reducing the quantity of rejected hadronic showers . Keywords : Machine Learning ; Cosmic Ray Identification ; Image Cleaning ; Gamma - ray Astrophysics ; Hadronic Shower",
        "ori-fast-z-score": 0.46499055497527714,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "We present BVRI surface photometry for isolated spiral galaxies in the nearby universe (0.01 < z < 0.1). The sample consists of 12 objects selected by their morphological type, inclination and apparent size to be suitable targets for detailed studies with integral field spectroscopy. We use archival data obtained at the Kitt Peak National Observatory 4m telescope as well as new observations taken during our own observing runs between 2005-2007. Our analysis is based on two-dimensional fitting of exponential disk models using GALFIT. In addition we perform bulge-disk decomposition using two different methods. First, we fit Sérsic profiles to both components simultaneously. Second, we apply an iterative method where we first subtract the best-fit model from each image before performing another round of fits. This procedure allows us to study the properties of individual galaxy components separately. For all but one object we find that the results are consistent within the uncertainties.",
        "watermark_text": "We use BVRI ground photometry for isolated spiral galaxies in the nearby universe ( 0 . 01 < z < 0 . 1 ) . The sample consists of 12 objects chose by their morphological class , inclination and apparent size to be suitable destinations for detailed analyses with integral field spectroscopy .We use archival measurements obtained at the Kitt Peak National Observatory 4m telescope as well as additional observations made during our own observing runs between 2005 - 2007 . Our study is based on two - dimensional fitting of exponential disk maps using GALFIT .In addition we perform bulge - disk transformation use two different methods . First , we fit Sérsic profiles to both components simultaneously .Second , we apply an iterative method where we first subtract the best - fitting model from each map before performing another round of fits . This procedure allows us to study the properties of different universe components separately .For all but one object we find that the results are compatible within the uncertainties .",
        "ori-fast-z-score": 1.1785113019775793,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "We study effects of the axial U(1) A anomaly in the two-flavor lattice QCD with Wilson fermions at finite temperature and density by using the Polyakov-loop extended Nambu-Jona-Lasinio (PNJL) model. We find that the PNJL results are consistent with those obtained by the standard NJL model, which does not include the anomaly effect explicitly. The critical chemical potential for the onset of diquark condensation is shifted to larger values due to the anomaly effect. This shift becomes smaller as we increase the current quark mass. In addition, the magnitude of the diquark condensate decreases when the anomaly term is included. \n \n PACS numbers: 11.10.Wx, 12.38.Gc, 14.40.Nd \n \n Introduction: It has been known that the axial U(1) \n \n \n \n Here mq denotes the current quark mass.",
        "watermark_text": "We research effects of the axial U ( 1 ) A anomaly in the two - flavor lattice QCD with Wilson fermions at finite temperature and density by using the Polyakov - loop enhanced Nambu - Jona - Lasinio ( PNJL ) model . We see that the PNJL results are compatible with those achieved by the standard NJL theory , which does not include the anomaly effect explicitly .The vital chemical potential for the emergence of diquark condensation is shifted to larger estimates due to the anomaly effect . This shift gets smaller as we increase the current quark mass .In addition , the magnitude of the diquark condensate reduces when the anomaly word is included . PACS codes : 11 . 10 . Wx , 12 . 38 . Gc , 14 . 40 . Nd Introduction : It has been known that the axial U ( 1 ) Here mq indicates the present quark mass .",
        "ori-fast-z-score": -0.4375949744936837,
        "water-fast-z-score": 4.813544719430521
    },
    {
        "original_text": "The Standard Model (SM) is an extremely successful theory, but it leaves many questions unanswered about physics at very high energies. In particular, there are no known fundamental principles that can explain why the SM has three generations of quarks and leptons with such different masses or how gravity fits into this picture. Theories beyond the Standard Model attempt to address these issues by introducing new particles and/or interactions which may be observed in future experiments.  Supersymmetry (SUSY), for example, introduces partners for all SM fields whose spin differs by one half unit. These partner states have identical gauge quantum numbers as their SM counterparts, so they could mix with them if SUSY were broken at low energy scales. This mixing would lead to deviations from SM predictions for observables like cross sections and decay rates. Many extensions of the Standard Model also predict new phenomena associated with extra dimensions of space-time. For instance, theories based on string/M-theory often contain additional spatial dimensions compactified down to tiny sizes. If these extra dimensions exist, then we should see evidence of their effects through virtual exchange of Kaluza-Klein excitations of gravitons and other particles between SM fields localized on our four-dimensional world-volume.",
        "watermark_text": "The Standard Model ( SM ) is an incredibly successful theory , but it leaves many issues unanswered about physics at very high energies . In particular , there are no available fundamental principles that can describe why the SM has three generations of quarks and leptons with such distinct masses or how gravity fits into this picture .Theories beyond the Standard Model attempt to alleviate these problems by introducing additional particles and / or relationships which would be found in future research . Supersymmetry ( SUSY ) , for example , creates partners for all SM fields whose spin varies by one half unit .These partner states have equal gauge quantum values as their SM counterparts , so they may blend with them if SUSY were breaking at low power scales . This blending would result to deviations from SM predictions for observables like cross sections and decay rates .Many modifications of the Standard Model also predict new concepts associated with extra dimensions of space - time . For instance , theories based on string / M - theory often contain extra spatial dimensions compactified down to small sizes .If these extra dimensions exist , then we should see evidence of their influence through virtual exchange of Kaluza - Klein excitations of gravitons and other particles between SM fields confined on our four - dimensional world - volume .",
        "ori-fast-z-score": 1.2247448713915892,
        "water-fast-z-score": 7.005888539421972
    },
    {
        "original_text": "We present an algorithm that determines whether or not there exists a quantum circuit with a given number of qubits and gates, such that the corresponding time-independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state.  We also show how to find all possible circuits if they exist. Our results are based on recent work showing that any time-independent Hamiltonian can be written as a sum of commuting projectors onto its eigenstates. This decomposition allows us to reduce the problem of finding a realization of a general time-independent Hamiltonian into several instances of the same problem but restricted to smaller Hilbert spaces. The reduction yields a polynomial-time algorithm when applied recursively. Finally we discuss some applications of our method including determining the minimum depth required for universal adiabatic quantum computers. In this article we consider the following problem: \nGiven a set of n qubits and m two-qubit gates, does there exist a quantum circuit consisting only of these gates whose associated time-independent Hamiltonian is realizable; i.e., it corresponds to a Hermitian operator acting on a finite-dimensional Hilbert space? If so, what is the smallest circuit size needed?\nThe answer to this question will depend on the specifics of the model used to describe the physical system under consideration. For example, in the case where each energy level may have more than one excited state (i.e., degenerate), then no circuit can realize the desired Hamiltonian unless it contains infinitely many gates. On the other hand, if each energy level has exactly one excited state (i..",
        "watermark_text": "We present an algorithm that decide whether or not there exists a quantum circuit with a given number of qubits and gates , such that the associated time - independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state . We also study how to find all possible circuits if they exist .Our results are based on current work showing that any time - independent Hamiltonian can be written as a sum of commuting projectors onto its eigenstates . This decomposition allows us to reduce the question of finding a realization of a general time - independent Hamiltonian into numerous instances of the same problem but restricted to smaller Hilbert spaces .The reduction gives a polynomial - time algorithm when applied recursively . Finally we explain some applications of our technique including calculating the minimum depth needed for universal adiabatic quantum computers .In this article we investigate the following issue : Given a setting of n qubits and m two - qubit gates , does there exist a quantum circuit consisting only of these gates whose associated time - independent Hamiltonian is realizable ; i . e . , it corresponds to a Hermitian operator acting on a finite - dimensional Hilbert space ? If so , what is the smallest circuit length needed ?The answer to this question will depend on the specifics of the model used to explain the physical system under consideration . For instance , in the case where each energy level may have more than one excited state ( i . e . , degenerate ) , then no circuit can realize the desired Hamiltonian unless it contains infinitely many gates .On the other hand , if each energy level has precisely one excited state ( i . .",
        "ori-fast-z-score": 2.3539293971054818,
        "water-fast-z-score": 6.024948132556827
    },
    {
        "original_text": "We present an analysis of the alignments between galaxy spins and tidal fields in real space, using data from the Two Mass Redshfit Survey (TMRS). We find that galaxies are preferentially aligned perpendicular to their local tidal field on scales larger than 1 Mpc/h. This alignment is stronger for more massive galaxies at higher redshifts. The observed spin-tide correlation can be explained by the effect of gravitational torques exerted by large-scale structures during the formation process of these galaxies. Our results suggest that this mechanism may play an important role in shaping galactic angular momenta. These findings have implications for understanding how dark matter halos acquire their angular momentum as well as for interpreting observations of cosmic shear statistics. Introduction: Galaxies form within overdense regions of the universe where they experience strong gravitational interactions with other objects such as neighboring galaxies or clusters of galaxies. During the formation process, these interactions induce gravitational torques which affect the orientation of the galactic angular momentum vector. In turn, the orientations of galactic angular momenta determine the shapes of galaxies through dynamical friction processes. Therefore, it has been suggested that the shape distribution of galaxies could provide information about the origin of galactic angular momentums (e.g., Catelan & Theuns 1996; Lee et al. 2008) . However, observational studies show conflicting results regarding whether there exists any preferred direction of galaxy spin axes relative to their neighbors  positions (see e.g., Faltenbacher et al. 2002; Bailin et al. 2005; Paz et al. 2008; Codis et al. 2012 , for recent works).\nIn order to understand the physical mechanisms responsible for determining the directions of galactic angular momentas, we need to study the statistical properties of galaxy spin distributions over large volumes of the universe. Recent surveys like Sloan Digital Sky Survey (SDSS) allow us to measure galaxy orientations accurately enough to perform such analyses. For example, Lee et al. (2008) used SDSS DR4 data to investigate the alignments between galaxy spin vectors and their nearest neighbor s position angles. They found no",
        "watermark_text": "We present an assessment of the alignments between galaxy spins and tidal fields in real space , using data from the Two Mass Redshfit Survey ( TMRS ) . We see that galaxies are preferentially aligned perpendicular to their nearby tidal field on scales bigger than 1 Mpc / h .This alignment is strengthened for more massive galaxies at higher redshifts . The observed spinning - tide relationship can be described by the impact of gravitational torques exerted by large - scale structures during the formation period of these objects .Our results propose that this mechanism may play an important role in shaping galactic angular momenta . These studies have consequences for studying how dark matter halos acquire their angular velocity as also as for interpreting observations of universe shear trends .Introduction : Galaxies shape within overdense regions of the universe where they encounter strong gravitational interactions with other structures such as nearby galaxies or rows of clusters . During the formation period , these interactions initiate gravitational torques which affect the orientation of the galactic angular velocity tensor .In turn , the orientations of galactic angular momenta determine the shapes of galaxies through dynamical friction mechanisms . Therefore , it has been proposed that the form distribution of stars could give information about the origin of galactic angular momentums ( e . g . , Catelan & Theuns 1996 ; Lee et al .2008 ) . However , observational analyses suggest conflicting findings regarding whether there exists any preferred direction of galaxy spin axes relative to their neighbors places ( saw e . g . , Faltenbacher et al .2002 ; Bailin et al . 2005 ; Paz et al .2008 ; Codis et al . 2012 , for recent works ) .In order to comprehend the physical mechanisms involved for determining the directions of galactic angular momentas , we require to study the statistical characteristics of galaxy spin distributions over large quantities of the universe . Recent surveys like Sloan Digital Sky Survey ( SDSS ) able us to measure galaxy orientations correctly sufficiently to conduct such analyses .For instance , Lee et al . ( 2008 ) used SDSS DR4 data to examine the alignments between galaxy spin vectors and their closest neighbor s position angles .They found no",
        "ori-fast-z-score": -0.8512055557875505,
        "water-fast-z-score": 7.140584836498262
    },
    {
        "original_text": "We present an equation-of-state (EOS) model for solar matter that is based on the path integral formalism and includes quantum nuclear effects in the form of shell corrections, which are calculated using realistic nuclear interactions. The EOS covers densities ranging from 0 to 1.5 times normal density at temperatures between 10^6 K and 5×10^8 K. We compare our results against those obtained by other authors who used different methods or approximations. Our new EOS agrees well with previous calculations within their respective domains of validity but extends these into previously unexplored regions. In particular we find that the pressure increases more rapidly than predicted by standard models when approaching the center of the Sun. This leads to higher central temperatures and lower radii compared to standard models. These differences may be important for understanding the structure of stars like the Sun as well as for modeling stellar evolution. \n \n Keywords: Solar interior",
        "watermark_text": "We create an equation - of - state ( EOS ) model for solar material that is based on the path integral formalism and incorporates quantum nuclear effects in the form of shell corrections , which are measured using realistic nuclear interactions . The EOS includes densities extending from 0 to 1 . 5 times normal density at levels between 10 ^ 6 K and 5×10 ^ 8 K . We match our findings against those achieved by other researchers who used various methods or approximations .Our current EOS follows well with previous analyses within their different domains of validity but extends these into formerly unexplored regions . In particular we find that the pressure changes more fast than expected by traditional models when approaching the center of the Sun .This leads to higher central temperatures and less radii compared to standard models . These changes may be crucial for knowledge the composition of stars like the Sun as also as for modeling stellar evolution .Keywords: Solar interior",
        "ori-fast-z-score": -0.5852057359806528,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "We present new results on the faint-end slope and evolution of the luminosity function (LF) for optically-selected quasars in the redshift range 0.5 < z < 2.2, based on the VIMOS-VLT Deep Survey (VVDS). We use two different methods to estimate the LF parameters at each redshift bin: 1/Vmax method and maximum likelihood fitting technique. Our best-fit values are obtained by combining these two techniques with Monte Carlo simulations. We find that our data is consistent with previous studies within their uncertainties. However we show that there exists an apparent discrepancy between the observed number density of bright quasars and the predictions made using the standard quasar formation model. This may be due to incompleteness effects or biases introduced during the selection process. In addition, we also investigate the dependence of the LF shape on the optical luminosities of quasars.",
        "watermark_text": "We report new data on the faint - end slope and evolution of the luminosity function ( LF ) for optically - selected quasars in the redshift region 0 . 5 < z < 2 . 2 , using on the VIMOS - VLT Deep Survey ( VVDS ) . We use two different methods to estimate the LF variables at each redshift bin : 1 / Vmax method and greatest probability fitting technique .Our best - fitting values are derived by combining these two strategies with Monte Carlo simulations . We see that our information is compatible with previous research within their uncertainties .However we prove that there exists an apparent discrepancy between the expected number density of bright quasars and the assumptions produced using the standard quasar structure model . This might be due to incompleteness effects or biases created during the selection phase .In addition , we also investigate the relationship of the LF formation on the optical luminosities of quasars .",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 6.713171133426189
    },
    {
        "original_text": "We present results on polarized radio emission in the field surrounding the galaxy cluster Abell 2218, observed with the Australia Telescope Compact Array (ATCA) at 1.4 GHz and 4.8 GHz. We detect 16 compact sources above 5 mJy beam-1 at both frequencies; all but one are unresolved or marginally resolved by our observations. The majority have fractional linear polarization between 10% and 20%, while two objects show higher values up to 40%. All detected sources appear to be associated with galaxies within the central region of Abell 2218. In addition we find evidence for diffuse polarized emission around the brightest member of this galaxy cluster. This is likely due to synchrotron radiation produced by relativistic electrons accelerated in shocks driven into the intracluster medium during multiple mergers that occurred over time scales ranging from 10 Myr to several Gyrs ago. Our data also reveal an extended halo-like structure which surrounds the entire galaxy cluster.",
        "watermark_text": "We report findings on polarized radio emission in the field surrounding the galaxy cluster Abell 2218 , detected with the Australia Telescope Compact Array ( ATCA ) at 1 . 4 GHz and 4 . 8 GHz . We detect 16 compact sources above 5 mJy beam - 1 at both frequencies ; all but one are unresolved or marginally resolved by our observations .The majority have fractional linear polarization between 10 % and 20 % , while two bodies display larger ratings up to 40 % . All detected sources appear to be identified with galaxies within the inner region of Abell 2218 .In addition we find data for diffuse polarized emission around the brightest part of this galaxy cluster . This is probably due to synchrotron emission generated by relativistic electrons accelerated in shocks driven into the intracluster medium during various mergers that occurred over time ranges ranging from 10 Myr to several Gyrs ago .Our data also suggest an extended halo - like structure which covers the entire galaxy cluster .",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 4.6475800154489
    },
    {
        "original_text": "We report on an exceptional flare detected by Swift/XRT at t ~ 1 day post-burst, which lasted for more than 100 ks (~20 hr). The flare was followed up with observations performed with XMM-Newton/EPIC-pn between 2.5 days to 3 months post-burst. We find that this flare is best described as a superposition of two components: one component lasting about 50 ks peaking around 10^-3 s and another component lasting about 70 ks peaking around 5 x 10^4 s. Both components are well fitted by exponentially cut-off power-laws with photon indices Γ = -1.6 ± 0.1 and -2.2 ± 0.3 respectively. No significant spectral evolution during either of these flares has been found. This flare is among the most energetic ever seen in any gamma-ray burst.",
        "watermark_text": "We report on an exceptional burst detected by Swift / XRT at t ~ 1 day post - flare , which occurred for more than 100 ks ( ~ 20 hr ) . The flare was followed up with observations performed with XMM - Newton / EPIC - pn between 2 . 5 weeks to 3 weeks following - flare .We see that this flare is better depicted as a superposition of two parts : one element lasting about 50 ks peaking roughly 10 ^ - 3 s and another component lasting about 70 ks peaking roughly 5 x 10 ^ 4 s . Both components are better fitted by exponentially drop - off power - laws with photon indices Γ = - 1 . 6 ± 0 . 1 and - 2 . 2 ± 0 . 3 respectively . No notable spectral evolution during either of these flares has been determined .This burst is among the most intense yet shown in any gamma - ray flare .",
        "ori-fast-z-score": -0.8320502943378437,
        "water-fast-z-score": 4.900980294098034
    },
    {
        "original_text": "We study theoretically the influence of longitudinal magnetic fields in coronal loops on the damping rate of small amplitude prominence oscillations. We find that for sufficiently large values of the longitudinal magnetic field, the damping is dominated by resonant absorption and it increases with increasing longitudinal magnetic field strength. For smaller values of the longitudinal magnetic fields we find that the damping is due to phase mixing between Alfvén waves propagating along neighboring flux tubes. In this case the damping decreases as the longitudinal magnetic field becomes weaker. The results are compared with observations made at the Solar Ultraviolet Measurements of Emitted Radiation (SUMER) instrument aboard SOHO spacecraft. It has been known since the early 1980s that many prominences exhibit periodic transverse displacements which can be observed both in Hα images and in EUV lines formed higher up in the atmosphere than Hα . These motions have periods ranging from several minutes down to about one minute and amplitudes typically less than 100 km s-1 .\nTheoretical models suggest that these oscillations may be driven by slow magnetoacoustic waves trapped inside the prominence body or by fast kink modes excited by photospheric flows (see e.g., Oliver & Ballester 1994; Terradas et al. 2002) . However, there is still no consensus regarding what causes them.",
        "watermark_text": "We explore theoretically the impact of longitudinal magnetic fields in coronal loops on the damping rate of tiny intensity prominence oscillations . We see that for enough large values of the longitudinal magnetic field , the damping is dominated by resonant absorption and it changes with increasing transverse magnetic field intensity .For smaller values of the longitudinal magnetic fields we find that the damping is due to phase mixing between Alfvén currents propagating along neighboring flux tubes . In this situation the damping decreases as the longitudinal magnetic force gets smaller .The results are compared with observations made at the Solar Ultraviolet Measurements of Emitted Radiation ( SUMER ) experiment aboard SOHO satellites . It has been known since the early 1980s that several prominences exhibit periodic longitudinal displacements which can be viewed both in Hα images and in EUV bands formed higher up in the atmosphere than Hα .These motions have periods ranging from several seconds down to about one minute and amplitudes typically less than 100 km s - 1 . Theoretical models suggest that these oscillations must be caused by fast magnetoacoustic waves trapped inside the prominence body or by fast kink modes excited by photospheric flows ( see e . g . , Oliver & Ballester 1994 ; Terradas et al .2002 ) . However , there is nevertheless no agreed regarding what causes them .",
        "ori-fast-z-score": 0.7181848464596079,
        "water-fast-z-score": 5.569674729797484
    },
    {
        "original_text": "We present results on flame evolution during type Ia supernova (SN) explosions, based on two-dimensional hydrodynamic simulations with detailed nuclear reaction networks for both deflagrations and detonations. We find that the transition to detonation is triggered by shock-induced turbulent mixing at densities around 10$^{9}$ g/cm$^3$. The resulting detonation wave propagates through the entire white dwarf star within about 1 s after ignition. In this scenario, the observed light curve can be reproduced if we assume an initial central density of 2 x $10^8$ g/cm$^3$ or higher. For lower values of the central density, the explosion fails to produce enough 56Ni to explain observations. This work was supported by NASA grant NNX10AD03G. Keywords: Flame propagation, Hydrodynamics, Nuclear burning, Supernovae, White dwarfs. Subject headings: Nucleosynthesis",
        "watermark_text": "We report findings on flame evolution during type Ia supernova ( SN ) exploded , using on two - dimensional hydrodynamic simulations with comprehensive nuclear response systems for both deflagrations and detonations . We see that the shift to detonation is caused by shock - caused turbulent mixing at densities around 10 $ ^ { 9 } $ h / cm $ ^ 3 $ .The produced detonation radiation propagates through the entire white dwarf star within about 1 s after explosion . In this situation , the observed light curve can be reproduced if we suppose an initial central density of 2 x $ 10 ^ 8 $ h / cm $ ^ 3 $ or greater .For lower values of the central density , the explosion fails to produce enough 56Ni to explain observations . This research was supported by NASA grant NNX10AD03G .Keywords : Flame transmission , Hydrodynamics , Nuclear burning , Supernovae , White dwarfs . Subject headings : Nucleosynthesis",
        "ori-fast-z-score": -0.2672612419124244,
        "water-fast-z-score": 5.258758927213289
    },
    {
        "original_text": "We report the observation of dynamic condensation of water vapor on crack tips during slow fracture experiments performed under vacuum conditions (10-6 mbar) and low temperature (77 K). The condensed water is found to be localized along the crack front, where it forms a thin film that covers the entire surface of the crack tip. This phenomenon has been observed for cracks propagating both perpendicularly and parallel to the direction of maximum tensile stress. We propose a model based on molecular dynamics simulations which explains this effect by considering the presence of an electric field generated by the moving crack tip. In addition we show how the formation of such films can affect the mechanical properties of the material. Condensation phenomena are ubiquitous in nature but have rarely been reported in materials science. Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses. These results were obtained using a combination of optical microscopy techniques with environmental scanning electron microscopy (ESEM), Raman spectroscopy and infrared reflection absorption spectroscopy (IRAS).",
        "watermark_text": "We report the observation of dynamic condensation of liquid vapor on break tips during slow fracture studies performed under vacuum environments ( 10 - 6 mbar ) and low heat ( 77 K ) . The condensed water is found to be localized along the crack front , where it creates a thin film that covers the entire surface of the crack tip .This phenomenon has been observed for faults propagating both perpendicularly and parallel to the direction of maximum tensile tension . We suggest a theory based on protein mechanics simulations which explains this effect by assuming the presence of an electric field produced by the moved crack edge .In addition we study how the formation of such films can affect the structural properties of the material . Condensation problems are ubiquitous in nature but have seldom been reported in materials science .Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses . These conclusions were obtained using a combination of optical microscopy methods with environmental scan electron microscopy ( ESEM ) , Raman spectroscopy and infrared reflection detection spectroscopy ( IRAS ) .",
        "ori-fast-z-score": -0.32539568672798425,
        "water-fast-z-score": 5.1759731137650435
    },
    {
        "original_text": "We study lattice chiral gauge theories with Wilson fermions in four dimensions, focusing on their phase structure at finite temperature T . We show that there is no spontaneous breaking of parity (P) or time-reversal symmetry (T ) for any value of the bare quark mass m0 if the number Nf of flavors satisfies Nf > 2. This result implies that the theory does not have an order parameter associated to P and/or T , which are spontaneously broken by the standard model. In particular, we find that the spectrum contains two degenerate Dirac fermion species corresponding to left-handed and right-handed quarks, respectively. These fermions can be identified as mirror fermions because they transform into each other under reflection about one spatial axis. The existence of these mirror fermions leads to interesting consequences such as the absence of flavor changing neutral currents mediated by gluons. \n \n Introduction \n \n Chiral gauge theories play important roles both theoretically and phenomenologically. They provide a natural framework for describing low-energy phenomena involving hadrons  1  . On the other hand, it has been suggested recently that some extensions of the Standard Model may contain extra space-time symmetries beyond Poincaré invariance  2  . It would then be very useful to develop techniques to analyze the possible effects of such new symmetries on physical observables  3  .\n \nIn this Letter, we consider a class of chiral gauge theories defined on a Euclidean spacetime lattice  4  . Our main interest lies in studying how the presence of additional discrete symmetries affects the phase diagram of the system. For simplicity, let us first focus on the case where only parity (P), charge conjugation (C), and time reversal (T ) transformations act nontrivially on fields  5  . Then, the action S = d4 x L(U; ψ,ψ) should satisfy the following conditions  6  :",
        "watermark_text": "We research lattice chiral gauge physics with Wilson fermions in four dimensions , concentrating on their phase shape at finite temperature T . We see that there is no premature breaking of parity ( P ) or time - reversal symmetry ( T ) for any value of the bare quark mass m0 if the number Nf of flavors satisfies Nf > 2 .This result means that the model does not have an rank parameter identified to P and / or T , which are spontaneously shattered by the standard description . In particular , we find that the spectrum contains two degenerate Dirac fermion varieties corresponding to right - handed and left - handed quarks , respectively .These fermions can be identified as mirror fermions because they change into each other under reflection about one spatial axis . The existence of these mirror fermions contributes to useful consequences such as the absence of flavor changing neutral currents mediated by gluons .Introduction Chiral gauge fields take key roles both theoretically and phenomenologically . They offer a natural framework for describing low - energy phenomena involving hadrons 1 .On the other hand , it has been proposed lately that some extensions of the Standard Model possibly possess extra space - time symmetries beyond Poincaré invariance 2 . It would then be very useful to develop techniques to analyze the possible effects of such new symmetries on natural observables 3 .In this Letter , we investigate a class of chiral gauge fields formulated on a Euclidean spacetime lattice 4 . Our main interest lies in examining how the presence of added discrete symmetries affects the phase diagram of the system .For simplicity , let us first focus on the case where only parity ( P ) , charge conjugation ( C ) , and period correction ( T ) transformations act nontrivially on fields 5 . Then , the operation S = d4 x L ( U ; ψ , ψ ) should satisfy the following assumptions 6 :",
        "ori-fast-z-score": 0.2727272727272727,
        "water-fast-z-score": 6.636363636363637
    },
    {
        "original_text": "We present chemical abundances for stars in three halo globular clusters (M92, M15, and M68) based on high-resolution spectroscopy obtained with HIRES at Keck Observatory. We find that these clusters have very similar abundance patterns to those observed among field halo stars; they are all metal-poor, α-enhanced systems. The mean  Fe/H  values we derive range between -2.3 dex and -1.9 dex depending upon which cluster is considered.  These results confirm previous suggestions that there may be no significant differences between the properties of the stellar populations found within individual open or globular star clusters versus those found in the general Galactic halo population. In addition, our derived ages suggest that these clusters formed early during the formation history of the Galaxy. Finally, we compare the kinematics of these clusters to those of other nearby halo objects such as dwarf galaxies and ultra-faint dwarfs.",
        "watermark_text": "We create molecular abundances for stars in three halo globular complexes ( M92 , M15 , and M68 ) based on wide - resolution spectroscopy acquired with HIRES at Keck Observatory . We see that these complexes have very identical abundance patterns to those observed among field halo stars ; they are all iron - weak , α - enhanced systems .The mean Fe / H values we derive range between - 2 . 3 dex and - 1 . 9 dex vary upon which cluster is regarded . These data confirm preceding suggestions that there may be no considerable variations between the properties of the stellar groups found within individual open or globular star clusters versus those observed in the overall Galactic halo community .In addition , our derived ages suggest that these groups formed earliest during the formation history of the Galaxy . Finally , we compare the kinematics of these clusters to those of other nearby halo objects such as dwarf stars and ultra - faint dwarfs .",
        "ori-fast-z-score": -1.75,
        "water-fast-z-score": 4.341215710622296
    },
    {
        "original_text": "We present an algorithm for the construction of a discrete computer network in which each node is connected to all nodes within its distance, and also to some other nodes at larger distances. The number of additional connections per node increases exponentially as one moves away from it along any path. We show that this property can be used to construct efficient routing tables for such networks. Our results are based on a new concept called  expanding dimension . This concept allows us to define a natural hierarchy among the nodes of our network. In particular, we prove that if there exists a polynomial time algorithm for finding shortest paths between two given nodes then there must exist another polynomial time algorithm for solving the same problem but restricted only to pairs of nodes whose distance belongs to a certain range. Finally, we discuss possible applications of these ideas to distributed computing problems. Keywords: Computer network, Expanding Dimension, Hierarchy, Routing",
        "watermark_text": "We present an algorithm for the creation of a discrete computer network in which each node is linked to all nodes within its distance , and also to some other connections at larger distances . The amount of added connections per node increases exponentially as one moves away from it along any path .We see that this property can be used to build efficient routing charts for such connections . Our results are based on a new notion called expanding dimension .This concept allows us to define a natural hierarchy among the nodes of our system . In particular , we prove that if there exists a polynomial time algorithm for finding shortest links between two given nodes then there need arise another polynomial time algorithm for solving the same difficulty but restricted only to pairs of vertices whose distance belongs to a certain range .Finally , we study possible applied of these ideas to dispersed computing problems . Keywords : Computer network , Expanding Dimension , Hierarchy , Routing",
        "ori-fast-z-score": 1.4814874939752933,
        "water-fast-z-score": 5.887840577551898
    },
    {
        "original_text": "We study heavy quarkonium transitions to hybrid mesons by using the multipole expansion method within the framework of nonrelativistic potential models. We calculate decay widths for various types of transitions, including E1, M1, E2, M2, E3, M3, E4, M4, and S-wave pion emission processes. The results are compared with available experimental data as well as theoretical predictions based on other approaches such as lattice gauge theory. \n \n In addition we determine mass spectra of hybrids by solving Schrödinger equations numerically. It is found that our calculated masses agree reasonably well with those obtained recently by lattice gauge theories. Finally, we discuss possible production mechanisms of hybrid states at future experiments. This work was supported by the National Natural Science Foundation of China under Grant No. 10675040. We thank Professors J. H. Chen and C. T. Chan for helpful discussions.",
        "watermark_text": "We research heavy quarkonium interactions to hybrid mesons by using the multipole expansion method within the framework of nonrelativistic potential methods . We calculate decay widths for various types of transitions , notably E1 , M1 , E2 , M2 , E3 , M3 , E4 , M4 , and S - wave pion emission cycles .The results are compared with existing experimental evidence as well as conceptual predictions based on other methods such as lattice gauge theory . In addition we determine mass spectra of hybrids by solving Schrödinger coefficients numerically .It is found that our measured masses agree reasonably well with those achieved lately by lattice gauge experiments . Finally , we explain possible generation systems of hybrid states at possible experiments .This project was supported by the National Natural Science Foundation of China under Grant No . 10675040 .We praise Professors J . H . Chen and C . T . Chan for helpful talks .",
        "ori-fast-z-score": -0.254000254000381,
        "water-fast-z-score": 5.08000508000762
    },
    {
        "original_text": "We present 8.4 GHz Very Long Baseline Interferometry (VLBI) images and light curves for the supernova remnant (SNR) associated with the Type IIb supernova SN2004et, which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1. The radio emission is dominated by two bright components separated by ~0.5 arcsec at all epochs observed between 2005 January and 2007 December. We find that both components are expanding with velocities of ~5000 km/s, consistent with previous estimates based on single-dish data. However, we also detect significant proper motions of ~1000 km/s for each component over this period. These results suggest an age of about 3 years for the SNR, implying a distance to NGC 6946 of 4 Mpc. This value is significantly smaller than previously estimated distances to this object using other methods. Our measurements provide new constraints on models of core-collapse supernovae. \n \n Keywords: Supernova remnants",
        "watermark_text": "We create 8 . 4 GHz Very Long Baseline Interferometry ( VLBI ) images and light angles for the supernova remnant ( SNR ) associated with the Type IIb supernova SN2004et , which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1 . The radio emission is dominated by two bright components differentiated by ~ 0 . 5 arcsec at all epochs observed between 2005 January and 2007 December .We see that both components are growing with velocities of ~ 5000 kilometres / s , consistent with previous estimates based on single - dish data . However , we also observe significant normal motions of ~ 1000 kilometers / s for each component over this time .These data suggest an age of about 3 years for the SNR , suggests a proximity to NGC 6946 of 4 Mpc . This value is significantly less than previously estimated distances to this body using other methods .Our measurements give novel constraints on estimates of core - collapse supernovae . Keywords : Supernova remnants",
        "ori-fast-z-score": -0.6509445549041194,
        "water-fast-z-score": 4.727031582950012
    },
    {
        "original_text": "We present an ab initio study of the structure, energetics, and dynamics of water adsorbed on the MgO(001) surface in the submonolayer regime using density functional theory with van der Waals corrections. We find that the most stable configuration is one where each oxygen atom binds to three hydrogen atoms forming a trihydrogen bridge between two adjacent O atoms. The binding energy per molecule for this configuration is 1.6 eV. This value agrees well with previous theoretical results obtained within the generalized gradient approximation but disagrees significantly with experimental values which are typically larger by about 0.5-0.7 eV. Our calculations show that the discrepancy can be attributed mainly to the neglect of dispersion interactions in earlier studies. In addition we have studied the effect of temperature on the stability of different configurations. We found that the relative population of various structures depends strongly on the temperature.",
        "watermark_text": "We present an ab initio investigation of the composition , energetics , and dynamics of water adsorbed on the MgO ( 001 ) surface in the submonolayer regime using density functional theory with van der Waals corrections . We see that the most stable configuration is one where each oxygen element connects to three hydrogen atoms forming a trihydrogen bridge between two adjacent O atoms .The binding energy per molecule for this configuration is 1 . 6 eV . This value agrees well with previous conceptual conclusions derived within the generalized gradient formulation but disagrees substantially with theoretical values which are typically greater by about 0 . 5 - 0 . 7 eV .Our calculations show that the discrepancy can be due mainly to the neglect of dispersion interactions in earlier methods . In addition we have researched the impact of temperature on the stability of different configurations .We determined that the relative population of several structures varies strongly on the temperature .",
        "ori-fast-z-score": 0.8551861104941365,
        "water-fast-z-score": 5.497624996033735
    },
    {
        "original_text": "We study the sound propagation through a one-dimensional (1D) Bose-Einstein condensed gas trapped by an optical lattice potential and interacting with each other via contact interactions. We show that, for weak interaction strength, there is no phonon-phonon scattering between different bands due to the energy gap induced by the periodic potential. In this case, we find that the sound velocity can be obtained analytically using perturbation theory. For strong interaction strengths, however, the phonons are scattered into higher bands and thus the sound velocity decreases as compared to its non-interacting value. The results agree well with numerical calculations based on the Gross-Pitaevskii equation. PACS numbers: 03.75.Dg, 05.30.Jp, 37.10.Gh \nI. INTRODUCTIO N\nThe properties of superfluid helium have been studied extensively since it was discovered more than half century ago  1  . One of the most important features of superfluids is their ability to support dissipationless flow without friction  2  , which has led to many applications such as superconductors  3  .\nRecently, ultracold atomic gases confined in optical lattices provide another platform to explore quantum fluids  4  . These systems exhibit various phases including Mott insulator phase  5  , supersolid phase  6  , and even topological states  7, 8  . Moreover, they allow us to tune the system parameters continuously  9  and observe directly the evolution of physical quantities  10  . This makes them ideal candidates to investigate new phenomena predicted by theoretical studies  11  .\nIn particular, bosonic atoms in optical lattices may form a BoseEinstein condensate  12  . It is known that these condensates behave like superfluids  13  . Recently, several experiments have observed the superflow  14  and vortex  15  in these systems. However, unlike conventional superfluids, the condensates in optical lattices also interact strongly with each other  16  . Therefore, understanding how the interatomic interactions affect the collective excitations becomes crucial  17  .\nIn this work, we consider 1D Bose-Einstein condensates trapped by an optical lattice  18  . By solving the",
        "watermark_text": "We test the music transmission through a one - dimensional ( 1D ) Bose - Einstein condensed gas trapped by an optical lattice potential and evolving with each other via contact interactions . We see that , for weak interaction strength , there is no phonon - phonon absorption between various groups owing to the power gap induced by the periodic potential .In this situation , we find that the audio speed can be obtained analytically using perturbation theory . For strong coupling strengths , however , the phonons are scattered into greater bands and therefore the audio speed reduces as compared to its non - interacting function .The results agree well with numerical measurements based on the Gross - Pitaevskii equation . PACS quantities : 03 . 75 . Dg , 05 . 30 . Jp , 37 . 10 . Gh I . INTRODUCTIO N The properties of superfluid helium have been studied thoroughly since it was known more than quarter century ago 1 .One of the most important features of superfluids is their ability to support dissipationless flow without tension 2 , which has led to many applications such as superconductors 3 . Recently , ultracold atomic fluids confined in laser lattices offers another platform to study quantum fluids 4 .These systems exhibit several stages namely Mott insulator stage 5 , supersolid phase 6 , and even topological states 7 , 8 . Moreover , they allow us to balance the process variables continuously 9 and observe directly the evolution of physical quantities 10 .This gives them ideal candidates to examine novel processes proposed by theoretical experiments 11 . In particular , bosonic atoms in optical lattices might form a BoseEinstein condensate 12 .It is known that these condensates behave like superfluids 13 . Recently , various observations have noted the superflow 14 and vortex 15 in these systems .However , unlike conventional superfluids , the condensates in laser lattices additionally interact heavily with each other 16 . Therefore , studying how the interatomic interactions impact the collective excitations remains crucial 17 .In this study , we solve 1D Bose - Einstein condensates trapped by an optical lattice 18 . By solving the",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.736345975703701
    },
    {
        "original_text": "We present an analysis of the gravitational waveforms emitted by two neutron stars orbiting each other, and show that they can be used to detect violations of Lorentz invariance (LI). We consider both scalar-tensor theories with spontaneous breaking of LI as well as vector-tensor theories where LI is violated through the presence of a preferred reference frame. In these models we find that there are characteristic deviations from general relativity which lead to measurable differences between the observed gravitational waveform and those predicted within Einstein s theory. \n \n The detection of such deviations would provide strong evidence for new physics beyond standard model expectations. This could have important consequences on our understanding of fundamental interactions at high energies. For example, it may shed light on the origin of dark energy or even reveal the existence of extra dimensions of space-time. It also has implications for cosmology since many extensions of the Standard Model predict time variations of physical constants like Newton s constant G.",
        "watermark_text": "We present an assessment of the gravitational waveforms emitted by two neutron stars orbiting each other , and find that they can be used to identify violations of Lorentz invariance ( LI ) . We consider both scalar - vector models with spontaneous breaking of LI as well as vector - vector models where LI is enforced through the presence of a preferred source frame .In these models we find that there are characteristic deviations from general relativity which lead to measurable differences between the expected gravitational waveform and those predicted within Einstein s theory . The diagnosis of such deviations might give strong evidence for future physics beyond standard theory expectations .This might have important implications on our knowing of fundamental interactions at high energies . For instance , it could cast light on the origin of dark energy or actually expose the existence of extra dimensions of space - time .It additionally has implications for cosmology since several extensions of the Standard Model predict time variations of physical constants like Newton s constant G .",
        "ori-fast-z-score": -0.4588314677411235,
        "water-fast-z-score": 5.505977612893481
    },
    {
        "original_text": "We present the chemical properties (metallicity, abundance ratios) for a sample of dwarf galaxies in the Local Volume with known distances and star formation histories. We use high quality spectra obtained at the Apache Point Observatory to derive oxygen abundances using both direct T e method as well as strong-line methods calibrated on H II regions in nearby spiral galaxies.  The derived metallicities range between 12+log(O/H)=7.6-8.2 dex. These values are consistent with those found by previous studies based on optical spectroscopy. In addition we find that most of these dwarfs have supersolar N/O ratio indicating recent or ongoing nitrogen enrichment due to massive stars. This is also supported by their low SFRs which prevent efficient dilution of the enriched gas produced by supernovae type Ia. Finally, we compare our results with theoretical predictions made by different chemical evolution models. Our analysis shows that none of them can reproduce simultaneously all observed quantities such as metallicity, N/O ratio and sSFR.",
        "watermark_text": "We present the chemical properties ( metallicity , abundance proportions ) for a sample of dwarf stars in the Local Volume with established altitudes and galaxy formation histories . We use large quality spectra obtained at the Apache Point Observatory to derive gas abundances using both direct T e method as also as bright - line methods calibrated on H II regions in nearby spiral clusters .The derived metallicities range between 12 + log ( O / H ) = 7 . 6 - 8 . 2 dex . These values are compatible with those shown by earlier surveys based on optical spectroscopy .In addition we find that most of these dwarfs have supersolar N / O ratio indicating new or ongoing nitrogen enrichment due to massive stars . This is also supported by their low SFRs which prevent efficient dilution of the enriched gas created by supernovae class Ia .Finally , we compare our findings with theoretical estimates made by various chemical evolution models . Our investigation reveals that none of them can predict simultaneously all observed properties such as metallicity , N / O ratio and sSFR .",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 4.612860393796698
    },
    {
        "original_text": "We present the Nobeyama CO (J=1-0) atlas for nearby spiral galaxies, which is based on our previous work by Kuno et al. (1995) . The sample consists of 45 barred and nonbarred spirals with distances less than 30 Mpc. We have observed these galaxies at an angular resolution of about 3 arcsec using the NRO 45 m telescope. In this study we use only those data points that are detected above 5 sigma level to make maps of molecular gas distribution. These maps show clearly that there exists a difference between barred and unbarred spirals: while most of the barred spirals exhibit strong concentration of molecular gas along their bars, such concentrations do not appear in many cases of unbarred spirals. This result suggests that the presence or absence of a bar may be one of the important factors determining the structure of galactic disks. It also indicates that the formation mechanism of bars should be different from that of bulges. \n \n\nThe authors acknowledge support from Grants-in-Aid for Scientific Research (No. 08540349), Ministry of Education, Science and Culture, Japan.",
        "watermark_text": "We present the Nobeyama CO ( J = 1 - 0 ) atlas for nearby spiral galaxies , which is based on our previous research by Kuno et al . ( 1995 ) .The sample consists of 45 barred and nonbarred spirals with distances lower than 30 Mpc . We have discovered these objects at an angular resolution of about 3 arcsec use the NRO 45 m observatory .In this study we using only those data points that are detected above 5 sigma level to make projections of molecular gas distribution . These surveys demonstrate obviously that there exists a difference between barred and unbarred spirals : while most of the barred spirals exhibit strong amount of molecular vapor along their bars , such concentrations do not appear in large cases of unbarred spirals .This result suggests that the presence or lack of a bar may be one of the important factors regulating the composition of galactic disks . It additionally indicates that the formation system of rings should be changed from that of bulges .The authors acknowledge support from Grants - in - Aid for Scientific Research ( No . 08540349 ) , Ministry of Education , Science and Culture , Japan .",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 4.365641250653994
    },
    {
        "original_text": "We present an analysis of the kinematics and dynamics of galaxies within galaxy clusters, using data obtained with the Hubble Space Telescope (HST). We use this information to measure the degree of radial bias in the distribution of cluster member velocities as well as their spatial correlation function. The results are compared against predictions made by cosmological N-body simulations that include both baryonic gas and collisionless dark matter particles. Our main conclusions are:  1) Galaxy clusters exhibit significant deviations from isotropic dynamical equilibrium; 2) These deviations can be explained if we assume that the dark matter component has a radially biased velocity dispersion tensor; 3) This result implies that the dark matter halos surrounding individual galaxies have similar shapes but different orientations relative to each other. In addition, our measurements provide new constraints on the mass-to-light ratio for galaxy clusters. Using HST observations of four nearby galaxy clusters, we find evidence that the dark matter component exhibits a strong radial bias in its velocity dispersion tensor.",
        "watermark_text": "We present an assessment of the kinematics and dynamics of clusters within galaxy clusters , using data acquired with the Hubble Space Telescope ( HST ) . We use this data to measure the degree of radial bias in the distribution of cluster member velocities as well as their spatial correlation function .The results are compared against models done by cosmological N - bodies simulations that include both baryonic gas and collisionless dark matter molecules . Our main results are : 1 ) Galaxy clusters exhibit substantial deviations from isotropic dynamical balance ; 2 ) These deviations can be described if we suppose that the dark matter component has a radially biased speed dispersion matrix ; 3 ) This result suggests that the dark matter halos adjoining individual stars have related shapes but different orientations relative to each other .In addition , our measurements give novel constraints on the mass - to - light percentage for galaxy regions . Using HST observations of four nearby galaxy galaxies , we find proof that the dark matter component displays a powerful radial bias in its velocity dispersion matrix .",
        "ori-fast-z-score": -0.44172610429938614,
        "water-fast-z-score": 6.184165460191406
    },
    {
        "original_text": "We present an exact solution to the classical equations of motion in two dimensions, which is interpreted as describing a rotating black hole with angular momentum J = M . The metric has the form ds2 = −dt2+(1+cosh2r)dθ2−r2dr2,\nwhere r and θ are polar coordinates on the plane. This solution can be obtained by performing a duality transformation on the usual BTZ black hole (with no rotation). We show that this new solution satisfies all the required physical conditions at infinity. In particular we find that it describes a regular black hole horizon located atr+ = √3M , where M is the mass parameter appearing in the original BTZ solution. Finally, we discuss some possible generalizations of our results. Introduction:-In recent years there have been many attempts to construct solutions to Einstein s field equations corresponding to rotating black holes  1  -  4  . One particularly interesting class of such solutions was found by Bañados, Teitelboim and Zanelli (BTZ), who showed how one could obtain a static black hole solution in three dimensional anti-de Sitter space-time  5  .\nThe most important feature of these solutions is their asymptotic behaviour; they describe black holes whose event horizons are completely determined by global quantities like total energy or charge  6  . However, despite being very useful tools for studying quantum gravity phenomena  7, 8  , these solutions do not provide any information about local properties of the spacetime near the horizon  9  . It would therefore seem desirable to try to extend them into more complicated geometries containing additional parameters characterizing the internal structure of the black hole  10  .\nOne way of doing so is to consider higher-dimensional extensions of the BTZ solution  11  . Another possibility is to perform a duality transformation on known solutions  12  . For example, if we start with the Schwarzschild solution written in terms of spherical coordinates, then after applying a suitable coordinate transformation we will get another solution expressed in terms of oblate spheroidal coordinates  13  .",
        "watermark_text": "We present an precise answer to the classical equations of movement in two dimensions , which is interpreted as representing a rotating black hole with angular velocity J = M . The metric has the form ds2 = −dt2 + ( 1 + cosh2r ) dθ2−r2dr2 , where p and θ are polar coordinates on the plane .This solution can be obtained by performing a duality conversion on the usual BTZ dark hole ( with no rotation ) . We see that this new solution satisfies all the necessary physical conditions at infinity .In particular we find that it describes a regular dark hole horizon located atr + = √3M , where M is the mass vector appearing in the previous BTZ solution . Finally , we explain some possible generalizations of our findings .Introduction : - In recent history there have been many efforts to build solutions to Einstein s field equations corresponding to spinning black holes 1 - 4 . One especially interesting class of such solve was seen by Bañados , Teitelboim and Zanelli ( BTZ ) , who demonstrated how one might obtain a static black hole solution in three dimensional anti - de Sitter space - time 5 .The most important feature of these solutions is their asymptotic behaviour ; they describe brown holes whose event horizons are completely determined by global quantities like total energy or charge 6 . However , despite being very useful techniques for studying quantum gravitational dynamics 7 , 8 , these solutions do not offer any info about local characteristics of the spacetime near the horizon 9 .It would therefore appear desirable to work to extend them into more complicated geometries containing extra constraints characterizing the internal structure of the dark hole 10 . One method of doing so is to consider higher - dimensional applications of the BTZ solution 11 .Another possibility is to conduct a duality conversion on known solutions 12 . For instance , if we start with the Schwarzschild solution written in terms of spherical coordinates , then after applying a suitable coordinate transformation we will get another solution expressed in terms of oblate spheroidal coordinates 13 .",
        "ori-fast-z-score": 1.150792911137501,
        "water-fast-z-score": 8.27424239724231
    },
    {
        "original_text": "The extraction of fresh water and energy from the atmosphere is proposed as an alternative to conventional sources, which are limited in supply or environmentally damaging.  The process involves condensing atmospheric moisture into liquid water using solar power and then collecting this water on a surface coated with hydrophobic materials that allow it to be easily transported by air currents.   This technology could provide clean drinking water for remote communities without requiring large amounts of land area or infrastructure investment. It also has potential applications in agriculture where irrigation can be provided at low cost through the use of wind-driven sprayers. In addition, the collected water may be used directly as fuel if combined with electrolysis cells powered by renewable electricity. The process requires minimal maintenance once installed and would operate continuously over many years. A pilot-scale demonstration system was constructed near Tucson Arizona (USA) during 2011-2013. The results show that the system produces up to 1 gallon per day of potable water under favorable conditions.",
        "watermark_text": "The extraction of fresh water and energy from the air is proposed as an alternative to conventional sources , which are limited in supply or environmentally destructive . The method means condensing ambient rainfall into liquid water use solar electricity and then collecting this water on a surface packed with hydrophobic materials that enable it to be easily carried by air waves .This system could supply fresh water freshwater for isolated communities without using big amounts of property area or structural capital . It additionally has potential applications in farming where irrigation can be provided at low cost through the using of wind - powered sprayers .In addition , the stored water may be used directly as fuel if combined with electrolysis panels driven by renewable energy . The method needs minimal repair once implemented and might run constantly over numerous years .A pilot - scale test system was constructed near Tucson Arizona ( USA ) during 2011 - 2013 . The results show that the scheme produces up to 1 gallon per day of potable liquid under favorable conditions .",
        "ori-fast-z-score": -0.8340576562282991,
        "water-fast-z-score": 7.715033320111767
    },
    {
        "original_text": "We have analyzed the redshifts of two samples of active galactic nuclei (AGNs) with different luminosities and found evidence for intrinsic redshift components in both cases.  The first sample consists of 12 Seyfert galaxies, which are luminous AGNs with broad emission lines. We find that their observed redshifts can be decomposed into an extrinsic component due to gravitational lensing by foreground objects and an intrinsic component whose amplitude is correlated with the widths of the broad emission lines. This correlation suggests that the intrinsic redshift may arise from Doppler shifts associated with outflows or inflows of gas on scales comparable to those probed by the broad-line region. The second sample contains low-luminosity quasars selected from the Sloan Digital Sky Survey Data Release 4 quasar catalog. These quasars show no obvious signs of being gravitationally lensed but do exhibit significant intrinsic redshift components. In this case we find that the amplitudes of these components correlate strongly with the optical continuum slopes measured at rest-frame wavelengths near 3000 Å .",
        "watermark_text": "We have analyzed the redshifts of two specimens of active galactic nuclei ( AGNs ) with varying luminosities and found proof for intrinsic redshift components in both cases . The first specimen consists of 12 Seyfert galaxies , which are luminous AGNs with broad absorption paths .We see that their observed redshifts can be decomposed into an extrinsic component due to gravitational lensing by foreground objects and an intrinsic component whose intensity is associated with the widths of the broad emission lines . This correlation suggests that the intrinsic redshift may arise from Doppler movements related with outflows or inflows of gas on scales similar to those probed by the broad - line region .The second survey features small - luminosity quasars chosen from the Sloan Digital Sky Survey Data Release 4 quasar catalog . These quasars exhibit no evident indication of being gravitationally lensed but do exhibit substantial intrinsic redshift components .In this situation we find that the amplitudes of these systems correlate strongly with the optical continuum curves observed at rest - mirror wavelengths near 3000 Å .",
        "ori-fast-z-score": 0.4923659639173309,
        "water-fast-z-score": 5.662208585049306
    },
    {
        "original_text": "The measurement calculus is an extension to the standard quantum mechanics formalism that allows for measurements on composite systems, and it has been used in several recent works as well as in this thesis.  The main idea behind the measurement calculus is to consider all possible outcomes of a measurement process as separate states of the system being measured instead of just one outcome (as done by von Neumann). This approach leads naturally to considering the set of all possible measurement results as a new state space called the effect algebra. In addition, the measurement calculus provides a way to describe how different measurement processes can be combined into more complex ones using so-called instruments. Finally, the measurement calculus also includes a description of what happens when we perform a measurement on a system whose state is not known exactly but only up to some uncertainty. The measurement calculus was first introduced by Aharonov et al., and since then there have been many papers written about its properties and applications.",
        "watermark_text": "The measurement calculus is an addition to the standard quantum mechanics formalism that enables for measurements on composite systems , and it has been used in multiple recent works as well as in this dissertation . The main idea behind the observation calculus is to consider all possible outcomes of a measurement process as separate states of the process being measured instead of just one outcome ( as done by von Neumann ) .This method results naturally to defining the group of all possible measurement results as a new state space termed the effect algebra . In addition , the observation calculus provides a way to explain how various measurement processes can be merged into more sophisticated ones utilizing so - called instruments .Finally , the observation calculus also contains a description of what happens when we perform a measurement on a system whose state is not known exactly but only up to some uncertainty . The measurement calculus was first developed by Aharonov et al . , and since then there have been many books written about its properties and use .",
        "ori-fast-z-score": 1.3093073414159544,
        "water-fast-z-score": 5.965587590013045
    },
    {
        "original_text": "We study nonequilibrium spin dependent transport properties of normal-metal-superconductor (NS) and ferromagnet-superconductor (FS) hybrid systems by using the quasiclassical theory for diffusive conductors with spin-orbit scattering. We show that, due to the proximity effect induced pair correlations between electrons on opposite sides of NS interface, there is an additional contribution to the current density which depends on the relative orientation of magnetizations in F and S layers. This results in appearance of the anomalous Josephson-like current-phase relation in FS junctions. In addition we find that the Andreev reflection at NS interfaces can be strongly suppressed if the angle between magnetization directions in N and S regions becomes sufficiently large. The suppression of Andreev reflection leads to the reduction of conductance through NS junction as compared to its value in equilibrium state. \n \n Finally, we discuss possible experimental realizations of our predictions.",
        "watermark_text": "We research nonequilibrium spin dependent transport properties of normal - copper - superconductor ( NS ) and ferromagnet - superconductor ( FS ) hybrid systems by using the quasiclassical principle for diffusive conductors with spin - orbit scattering . We see that , owing to the proximity effect induced pair correlations between electrons on opposite ends of NS interface , there is an additional contribution to the current density which depends on the relative position of magnetizations in F and S layers .This results in appearance of the anomalous Josephson - like current - phase connection in FS junctions . In addition we find that the Andreev reflection at NS interfaces can be highly suppressed if the angle between magnetization directions in N and S areas becomes enough large .The disruption of Andreev reflection results to the reduction of conductance through NS intersection as compared to its value in equilibrium state . Finally , we explain possible experimental realizations of our predictions .",
        "ori-fast-z-score": 1.3858697343671664,
        "water-fast-z-score": 5.417490779798923
    },
    {
        "original_text": "We study the cycle structure of elements in braid groups, and prove that any element can be written as a product of cycles whose lengths are bounded by some constant depending only on the number of strands. This is an extension to higher dimensions of results obtained for free groups by Magnus and Karrass-Solitar. \nTheorem 1 (Cycle decomposition). Let G = B_n(K) be a braid group with n strands over K. Then every g ∈ G has a unique expression as a product of disjoint cycles c_1, ..., c_k such that: \n1. The length of each cycle ci satisfies |ci| ≤ 2^{log_2 n} + 3.\n2. Each cycle ci contains at most one generator t_i which does not commute with its inverse.\n3. If there exists no generator t_i satisfying condition 2 then k = 0.\n4. No two generators appear simultaneously in different cycles.\n5. Every generator appears exactly once in each cycle it belongs to.\n6. For all i, |c_1 · ... · c_(i-1)| < |c_i|.",
        "watermark_text": "We research the cycle composition of elements in braid families , and prove that any element can be written as a product of cycles whose distances are bounded by some constant depending only on the number of strands . This is an addition to higher dimensions of findings obtained for free families by Magnus and Karrass - Solitar .Theorem 1 ( Cycle decomposition ) . Let G = B _ n ( K ) be a braid set with n chains over K . Then every g ∈ G has a unique expression as a product of disjoint paths c _ 1 , . . . , b _ k such that : 1 .The span of each cycle ci satisfies | ci | ≤ 2 ^ { log _ 2 n } + 3 . 2 .Each cycle ci comprises at most one generator t _ i which does not commute with its inverse . 3 .If there exists no generator t _ i satisfying condition 2 then k = 0 . 4 .No two generators appear separately in different cycles . 5 .Every generator appears precisely once in each cycle it belongs to . 6 .For all i , | c _ 1 · . . . · c _ ( i - 1 ) | < | c _ i | .",
        "ori-fast-z-score": -2.0768805540571886,
        "water-fast-z-score": 2.215646837627989
    },
    {
        "original_text": "The authors present an analysis of the stochasticity inherent to biochemical reactions, and its effects on metabolic networks. They show that this noise can be reduced by increasing enzyme concentrations or decreasing reaction rates; however, these strategies are limited because they may lead to other undesirable consequences such as increased production costs for enzymes or decreased growth rate due to slower metabolism. The authors also discuss how their results could help explain why some organisms have evolved mechanisms to reduce the amount of noise in their metabolic processes (e.g., gene regulation). Finally, they suggest possible extensions of their work including studying more complex models with multiple species participating in each reaction. This article is available from: http://arxiv.org/abs/1306.5481 . Stochastic fluctuations in metabolic pathways  Authors: Yi-Chun Chen , Shih-Chieh Hwang , Chia-Hui Wu , Yu-Ting Lin , Ming-Jerng Wang , Wen-Yuan Lee , Jyh-Ming Huang , Chin-Lung Chang , Yuan-Chao Tsai , Wei-Hsien Yang , Kuo-Feng Yeh , Chung-I Wu , Tzi-Chin Chan , Cheng-Yang Liu , Chao-Kuang Chiang , Chien-Nan Chu , Chien-Wen Lu , Chien-Chi Lai , Chien-Shuu Chen , Chien-Chi Hsieh , Chien-Chi Wu , Chien-Chi Hung , Chien-Chi Li , Chien-Chi Su , Chien-Chi Liao , Chien-Chi Chen , Chien-Chiang Wu , Chien-Chiang Tai , Chien-Chiang Liang , Chien-Chiang Sun , Chien-Chiang Wei , Chien-Chiang Chen , Chien-Chang Wu , Chien-Chang Tai , Chien-Chang Liang , Chien-Chang Sun , Chien-Chang Wei , Chien-Chang Chen , Chien-Cheng Wu , Chien-Cheng Tai , Chien-Cheng Liang , Chien-Cheng Sun , Chien-Cheng Wei , Chien-Cheng Chen , Chien-Ch",
        "watermark_text": "The authors present an assessment of the stochasticity inherent to biochemical reactions , and its consequences on metabolic networks . They show that this noise can be reduced by expanding substrate concentrations or decreasing reaction rates ; however , these schemes are limited because they may contribute to other undesirable consequences such as reduced production expenses for enzymes or improved development pace leading to slower metabolism .The authors additionally discuss how their results could assist explain why some organisms have adapted processes to reduce the quantity of noise in their metabolic processes ( e . g . , gene control ) . Finally , they propose could extend of their studies namely studying more sophisticated models with many taxa participating in each synthesis .This page is accessible from : www : / / arxiv . org / abs / 1306 . 5481 . Stochastic fluctuations in metabolic mechanisms Authors : Yi - Chun Chen , Shih - Chieh Hwang , Chia - Hui Wu , Yu - Ting Lin , Ming - Jerng Wang , Wen - Yuan Lee , Jyh - Ming Huang , Chin - Lung Chang , Yuan - Chao Tsai , Wei - Hsien Yang , Kuo - Feng Yeh , Chung - I Wu , Tzi - Chin Chan , Cheng - Yang Liu , Chao - Kuang Chiang , Chien - Nan Chu , Chien - Wen Lu , Chien - Chi Lai , Chien - Shuu Chen , Chien - Chi Hsieh , Chien - Chi Wu , Chien - Chi Hung , Chien - Chi Li , Chien - Chi Su , Chien - Chi Liao , Chien - Chi Chen , Chien - Chiang Wu , Chien - Chiang Tai , Chien - Chiang Liang , Chien - Chiang Sun , Chien - Chiang Wei , Chien - Chiang Chen , Chien - Chang Wu , Chien - Chang Tai , Chien - Chang Liang , Chien - Chang Sun , Chien - Chang Wei , Chien - Chang Chen , Chien - Cheng Wu , Chien - Cheng Tai , Chien - Cheng Liang , Chien - Cheng Sun , Chien - Cheng Wei , Chien - Cheng Chen , Chien - Ch",
        "ori-fast-z-score": 1.0392304845413263,
        "water-fast-z-score": 8.075839156533009
    },
    {
        "original_text": "We introduce the notion of covering homology, which is an extension of ordinary homology to infinite graphs and simplicial complexes. The main idea behind this concept is that we consider not only finite subcomplexes but also their infinite analogues - so-called coverings. We show how covering homology can be used for studying properties of infinite graphs such as amenability or hyperbolicity. In particular, we prove that if a graph has infinitely many ends then its first covering homology group vanishes. This result generalizes the classical theorem by Stallings on groups with infinitely many ends. Covering homology provides us with new tools for investigating various classes of infinite objects in mathematics. It turns out that it is closely related to other concepts like equivariant homology theory (in the case when our object admits actions of some group) or higher-order algebraic K-theory. Finally, we present several examples illustrating applications of covering homology.",
        "watermark_text": "We introduce the notion of covering homology , which is an extension of regular homology to infinite graphs and simplicial complexes . The main idea behind this concept is that we treat not only finite subcomplexes but also their infinite analogues - so - called coverings .We see how covering homology can be used for studying characteristics of infinite graphs such as amenability or hyperbolicity . In particular , we prove that if a diagram has infinitely many ends then its first covering homology group vanishes .This result generalizes the classical principle by Stallings on groups with infinitely many ends . Covering homology provides us with novel techniques for investigating different categories of infinite concepts in mathematics .It turns out that it is closely related to other concepts like equivariant homology theory ( in the case when our object accepts actions of some group ) or greater - order algebraic K - theory . Finally , we present many examples illustrating applications of covering homology .",
        "ori-fast-z-score": 0.9847319278346618,
        "water-fast-z-score": 3.8450767722654624
    },
    {
        "original_text": "We present new molecular opacity tables that include all relevant molecules in cool, carbon-rich stellar envelopes and are valid over a wide range of temperatures (T = 1000 - 10000 K), densities (ρ = 10 −10 -10 6 g/cm 3 ) and compositions (C/O=0.5-2). The calculations were performed with the state-of-the-art ab initio line-by-line radiative transfer code SPECTRUM using extensive laboratory data on molecular lines as well as theoretical predictions based on quantum chemical methods. We have calculated synthetic spectra for several model atmospheres representative of red giant branch (RGB) and asymptotic giant branch (AGB) stars to demonstrate how our new opacity tables affect their structure and evolution. Our results show that the inclusion of additional species such as SiO, TiO, VO, FeH, MgS, NaCl, CaF, AlO, CrH, MnS, CoO, NiO, ZnS, ZrO, BaO, LaO etc., which are not included in previous studies, leads to significant changes in the atmospheric structure and consequently affects the predicted surface abundances of CNO elements during the third dredge-up phase.",
        "watermark_text": "We create novel molecular opacity lists that include all relevant molecules in cold , carbon - rich stellar envelopes and are applicable over a broad variety of temperatures ( T = 1000 - 10000 K ) , densities ( ρ = 10 −10 - 10 6 g / cm 3 ) and compositions ( C / O = 0 . 5 - 2 ) . The calculations were performed with the state - of - the - art ab initio line - by - line radiative transfer code SPECTRUM combining extensive research data on chemical lines as well as conceptual predictions based on quantum chemical techniques .We have adjusted synthetic spectra for various model atmospheres representative of red dwarf branch ( RGB ) and asymptotic giant branch ( AGB ) stars to indicate how our new opacity tables affect their structure and evolution . Our results show that the inclusion of added species such as SiO , TiO , VO , FeH , MgS , NaCl , CaF , AlO , CrH , MnS , CoO , NiO , ZnS , ZrO , BaO , LaO etc . , which are not mentioned in earlier analyses , leads to significant improvements in the atmospheric composition and consequently affects the expected exterior abundances of CNO compounds during the third dredge - up process .",
        "ori-fast-z-score": -1.585187847802434,
        "water-fast-z-score": 4.755563543407302
    },
    {
        "original_text": "We present the relativistic second order perturbation theory for fluids in curved space-time with arbitrary number of components. We derive the general expression for the energy-momentum tensor at first order in perturbations as well as its trace-free part which is responsible for gravitational waves generation. The evolution equations are derived by projecting the conservation law onto the background 4-velocity vector field. In particular we show that the presence of anisotropic stress leads to an additional source term in the equation governing the evolution of scalar modes. Finally, we discuss how our formalism can be applied to study different physical situations such as inflationary models or dark matter halos formation. Cosmology has been revolutionized over the past decade thanks to precision measurements of temperature fluctuations in the cosmic microwave background (CMB) radiation  1  . These observations have provided us with detailed information about the early universe and allowed to test fundamental physics on very large scales  2  .\nThe standard model of cosmology assumes that the universe consists of several interacting components including cold dark matter (CDM), baryons, photons, neutrinos etc.. Each component evolves according to some set of hydrodynamical equations describing their dynamics  3  . However, these equations cannot be solved analytically even if one neglects all interactions between particles  4  , so numerical simulations are required  5  . On the other hand, analytical solutions exist only under certain approximations  6  . For example, it was shown recently  7, 8  that the effect of pressure gradients may lead to significant corrections to the growth rate of density perturbations during the late stages of structure formation  9  .",
        "watermark_text": "We introduce the relativistic second order perturbation theory for fluids in curved space - time with arbitrary number of components . We derive the general expression for the power - momentum tensor at first order in perturbations as well as its trace - free portion which is responsible for gravitational waves generation .The evolution equations are derived by projecting the conservation law onto the background 4 - velocity vector field . In particular we find that the presence of anisotropic stress leads to an additional source term in the equation regulating the evolution of scalar modes .Finally , we talk how our formalism can be applied to study various physical conditions such as inflationary theories or black particle halos formation . Cosmology has been revolutionized over the previous decade courtesy to accurate measurements of temperature fluctuations in the cosmic microwave background ( CMB ) radiation 1 .These measurements have provided us with comprehensive information about the early universe and enable to test fundamental theory on very huge scales 2 . The conventional model of cosmology assumes that the universe consists of several interacting components namely cold bright matter ( CDM ) , baryons , photons , neutrinos etc . . Each component evolves due to some setting of hydrodynamical equations explaining their mechanics 3 .However , these equations never be answered analytically even if one neglects all interactions between particles 4 , so numerical simulations are required 5 . On the other hand , analytical solutions arise only under certain approximations 6 .For instance , it was shown ago 7 , 8 that the impact of force gradients might lead to significant corrections to the development time of density perturbations during the late stages of formation formation 9 .",
        "ori-fast-z-score": -2.1213203435596424,
        "water-fast-z-score": 5.1946603473211805
    },
    {
        "original_text": "Dans cet article, nous donnons une nouvelle preuve de la classification bimeromorphee des varietes kahleriennes compactes en utilisant les orbifolds speciaux. Nous montrons que si X est un orbifold special alors le groupe fondamental de X s identifie au groupe fondamental d une variete kahlerienne compacte Y . _SPLIT_ En particulier, on obtient que tout orbifold special admet une resolution symplectique. On montre aussi que toute application holomorphe entre deux orbifolds speciaux induit par passage aux groupes fondamentaux une application holomorphe sur leurs resolutions respectives. Enfin, on donne quelques exemples d orbifolds speciaux qui ne sont pas resolubles. Keywords: Orbifoldes spéciaux, Variétés Kähleriennes Compactes, Groupes fondamentaux, Résolutions symplectiques. 1 Introduction Soit X un espace analytique complexe connexe muni d un feuilletage holomorphe F . Un tel objet sera appelé dans ce texte un orbifold spécial (voir  V ). Dans cette note, nous allons donner une nouvelle démonstration du théorème suivant dû à Verbitsky : Théorème 0.1. (Verbitsky) Tout orbifold spécial admet une résolution symplectique.",
        "watermark_text": "Dans cet article , nous donnons une nouvelle preuve de la classification bimeromorphee des varietes kahleriennes compactes en utilisant les orbifolds speciaux . Nous montrons que si X est un orbifold special alors la groupe fondamental de X s identifie au groupe fondamental d la variete kahlerienne compacte Y ._ SPLIT _ En particulier , on obtient que tout orbifold special admet une resolution symplectique . On montre aussi que toute application holomorphe entre deux orbifolds speciaux induit par passage des groupes fondamentaux la applied holomorphe sur leurs resolutions respectives .Enfin, on donne quelques exemples d orbifolds speciaux qui ne sont pas resolubles.Keywords: Orbifoldes spéciaux, Variétés Kähleriennes Compactes, Groupes fondamentaux, Résolutions symplectiques.1 Introduction Soit X un espace analytique complexe connexe muni d en feuilletage holomorphe F . Un tel objet sera appelé dans ce texte un orbifold spécial ( voir V ) .Dans cette report , nous allons donner à nouvelle démonstration du théorème suivant dû à Verbitsky : Théorème 0 . 1 . ( Verbitsky ) Tout orbifold spécial admet une résolution symplectique .",
        "ori-fast-z-score": -0.1690308509457033,
        "water-fast-z-score": 2.263009527424072
    },
    {
        "original_text": "We present an analysis of all known short-period cataclysmic variables (CVs) in which we find that most systems have orbital periods longer than 3 hrs and are dominated by SW Sex stars, while those with shorter periods tend to be AM Her binaries. We show that this dichotomy is consistent with theoretical predictions for the evolution of CVs driven by angular momentum loss via gravitational radiation. The observed distribution of orbital periods can also be explained if there exists a minimum period below which no CVs exist due to magnetic braking. This result has important implications on our understanding of how CVs evolve towards shorter orbital periods. Cataclysmic Variables (CVs), interacting binary star systems consisting of a white dwarf primary accreting matter from its low-mass companion through Roche lobe overflow, are among the best studied classes of close binary stars. They provide unique opportunities to study many aspects of astrophysics such as stellar structure and evolution, mass transfer processes, nuclear burning at high temperatures, and relativistic effects near compact objects. In particular, they offer insights into the formation mechanisms of both single and double degenerate white dwarfs, the progenitors of Type Ia supernovae.",
        "watermark_text": "We present an assessment of all known short - period cataclysmic variables ( CVs ) in which we find that most components have orbital periods longer than 3 hrs and are dominated by SW Sex stars , while those with shorter cycles seem to be AM Her binaries . We suggest that this dichotomy is compatible with theoretical estimates for the evolution of CVs caused by angular velocity loss via gravitational rays .The observed pattern of orbital periods can also be described if there exists a minimum period below which no CVs occur due to magnetic braking . This result has crucial consequences on our understanding of how CVs develop towards shorter orbital periods .Cataclysmic Variables ( CVs ) , interacting binary star systems composed of a white dwarf secondary accreting matter from its low - weight sister through Roche lobe overflow , are among the best researched groups of close binary stars . They offer distinct options to study many aspects of astrophysics such as stellar formation and evolution , mass transfer mechanisms , nuclear burning at high temperatures , and relativistic effects near compact galaxies .In particular , they give insights into the formation patterns of both single and double degenerate white dwarfs , the progenitors of Type Ia supernovae .",
        "ori-fast-z-score": 0.618852747755276,
        "water-fast-z-score": 5.982243228301002
    },
    {
        "original_text": "We present the results of an analysis of galaxy cluster data in terms of their gravitational lensing properties and X-ray emission, with particular emphasis on the comparison between observed and predicted values for the mass-to-light ratio M/L. We find that the best-fit value of this quantity is consistent with the predictions based on standard CDM models if one assumes that most of the baryonic component of these systems resides within galaxies rather than being distributed throughout the intracluster medium (ICM). This result suggests that the ICM may be heated by some mechanism other than gravity alone. \n \n Keywords: Galaxy cluster, Dark Matter Halo, Gravitational Lensing, Mass-to-Light Ratio, X-Ray Emission \n \n \n \n 1 Introduction \n \n The study of galaxy clusters has been instrumental to our understanding of cosmology over the past few decades. In fact, it was through observations of galaxy clusters that we first discovered evidence supporting the existence of non-baryonic dark matter  1  . Today, galaxy clusters are still used extensively to test theories about structure formation  2  , and they provide important constraints on cosmological parameters such as the Hubble constant  3  or the equation-of-state parameter w  4  . \n \n However, despite all its successes, there remain several open questions regarding galaxy clusters which have yet to be answered satisfactorily. For example, while current observational techniques allow us to measure accurately the total amount of light emitted by a galaxy cluster, it remains difficult to determine how much of this light comes from stars inside individual galaxies versus diffuse gas located outside them  5  . Similarly, although we can estimate fairly well the total gravitating mass of a galaxy cluster using various methods  6  , it is not clear what fraction of this mass is associated with visible objects like galaxies  7, 8  . Finally, even though we know that galaxy clusters contain large amounts of hot plasma  9  , it is unclear whether this material is gravitationally bound to the system  10  .\n \nIn order to address these issues, we will use two different datasets obtained from the Chandra Observatory  11  : the sample of galaxy clusters studied by Vikhlinin et",
        "watermark_text": "We present the conclusion of an assessment of galaxy cluster data in terms of their gravitational lensing behavior and X - ray radiation , with particular emphasis on the comparison between seen and anticipated readings for the mass - to - light value M / L . We see that the best - fitting value of this quantity is compatible with the estimates based on normal CDM models if one suppose that most of the baryonic core of these systems resides within stars rather than being dispersed throughout the intracluster medium ( ICM ) .This result suggests that the ICM could be heated by some process other than gravity alone . Keywords : Galaxy cluster , Dark Matter Halo , Gravitational Lensing , Mass - to - Light Ratio , X - Ray Emission 1 Introduction The investigation of galaxy galaxies has been instrumental to our understanding of cosmology over the previous few years .In indeed , it was through observations of galaxy clusters that we first discovered evidence proving the existence of non - baryonic black material 1 . Today , galaxy rings are still used heavily to test models about structure formation 2 , and they give important restrictions on cosmological factors such as the Hubble constant 3 or the equation - of - state variable f 4 .However , despite all its victories , there remain many open questions regarding galaxy clusters which have yet to be answered satisfactorily . For instance , while contemporary observational techniques permit us to measure correctly the total amount of light emitted by a galaxy cluster , it remains impossible to predict how many of this light originates from stars inside individual stars vs diffuse gas located outside them 5 .Similarly , although we can calculate fairly good the total gravitating mass of a galaxy cluster using numerous technique 6 , it is not clear what fraction of this mass is associated with visible objects like stars 7 , 8 . Finally , even though we know that galaxy regions include significant amounts of bright plasma 9 , it is uncertain whether this material is gravitationally bound to the system 10 .In order to meet these problems , we will use two different datasets obtained from the Chandra Observatory 11 : the sample of galaxy regions investigated by Vikhlinin et",
        "ori-fast-z-score": -1.5811388300841895,
        "water-fast-z-score": 8.171011693711216
    },
    {
        "original_text": "We present new maps of the circumstellar SiO (v=1, v=2) masers around the Mira variable R Leo obtained with the Very Long Baseline Array at 22 GHz and 43 GHz. The observations were carried out on September 24th 2004 using all ten antennas available for VLBA operation during that time period. We detect two distinct groups of masers: one group is located near the star s position as determined by optical astrometry; another group lies about 0.5 arcsec to the south-west of this location. Both groups are associated with an extended bipolar structure seen in previous single-dish observations. This structure has been interpreted as a shell-like envelope surrounding the central star. Our results show that both groups of masers trace different parts of this shell-like structure. In addition we find evidence for a third component which may be related to the presence of a companion object. \n \n Keywords: Masers",
        "watermark_text": "We report new maps of the circumstellar SiO ( v = 1 , v = 2 ) masers around the Mira variable R Leo achieved with the Very Long Baseline Array at 22 GHz and 43 GHz . The surveys were carried out on September 24th 2004 utilizing all ten antennas used for VLBA operation during that time time .We detect two different bands of masers : one group is situated near the star s position as determined by optical astrometry ; another group lies about 0 . 5 arcsec to the south - west of this location . Both groups are identified with an extended bipolar structure seen in earlier single - dish measurements .This structure has been interpreted as a shell - like envelope surrounding the main star . Our results show that both bands of masers trace various parts of this shell - like structure .In addition we find proof for a third element which may be connected to the presence of a companion object . Keywords : Masers",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.588005588008382
    },
    {
        "original_text": "We present an evolutionary algorithm for the problem of mesh numbering, which is to assign integers in the range  0, ..., n-1  to all vertices of a given graph G = (V, E) such that adjacent vertices have consecutive numbers and no two edges share the same pair of endpoints with the same order.  The proposed method uses a population-based approach where each individual represents a valid solution by means of a permutation vector. We show how this representation can be used to efficiently compute fitness values using only local information. In addition we propose several genetic operators to explore the search space. Finally, we report on preliminary results obtained by applying our method to some well-known benchmark instances. Keywords: Graphs, Optimization problems, Evolutionary algorithms, Genetic algorithms. 1 Introduction A common task when working with graphs is to label their nodes or edges with unique identifiers. This process is known as node or edge numbering respectively. For example, it may be required to number the nodes of a road network so that every path between any two points has a unique sequence of labels. Another application arises in circuit design, where one needs to assign unique addresses to components of electronic circuits.",
        "watermark_text": "We present an evolutionary algorithm for the question of mesh numbering , which is to assign integers in the range 0 , . . . , k - 1 to all edges of a given graph G = ( V , E ) such that adjacent vertices have consecutive numbers and no two edges occupy the same pair of endpoints with the same order . The proposed approach utilizes a population - based approach where each individual represents a valid answer by means of a permutation matrix .We see how this representation can be used to easily compute fitness values utilizing only local information . In addition we propose several genetic functions to examine the search space .Finally , we publish on preliminary results acquired by using our technique to some well - famous benchmark instances . Keywords : Graphs , Optimization problems , Evolutionary algorithms , Genetic algorithms .1 Introduction A typical task when dealing with graphs is to label their edges or edges with special identifiers . This process is known as node or edge numbering respectively .For instance , it could be required to count the nodes of a street system so that every path between any two points has a unique string of tags . Another application exists in circuit design , where one needs to give unique addresses to components of electronic circuits .",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 5.273697108112943
    },
    {
        "original_text": "We report on the experimental demonstration of frequency upshift in two colliding laser pulses using a relativistically flying mirror (RFM). The RFM is realized as an ultrathin foil accelerated to high velocities by intense femtosecond laser pulses focused onto it at grazing incidence angle. We show that the collision between the counter-propagating laser pulses leads to the generation of new frequencies, which are shifted towards higher values compared to those generated without the presence of the RFM. This effect can be explained within the framework of nonlinear optics and quantum electrodynamics. Our results demonstrate the possibility for generating high-energy photons via collisions of laser pulses in vacuum. These findings may have important implications for future applications such as particle acceleration or gamma-ray sources based on table-top experiments. \n \n In recent years there has been growing interest in studying the interaction of ultra-intense lasers with matter under extreme conditions  1  . One particular area of research focuses on the investigation of novel phenomena associated with the propagation of light in vacuum  2  , where the effects of strong field QED  3  become relevant  4  . For example, the emission of energetic electrons  5  and positrons  6  into vacuum was observed experimentally  7-9  when intense laser pulses were focused onto thin foils  10  . Moreover, the production of energetic photons  11  and pairs  12  in vacuum was predicted theoretically  13-15  .\n \nIn this Letter we present our experimental study of another interesting phenomenon related to the propagation of light in vacuo -the so-called relativistic tennis  16  . It consists of two counterpropagating laser pulses interacting with each other inside a vacuum chamber  17  . When these pulses collide they generate new frequencies  18  , which are shifted towards higher energies  19  . This effect occurs due to the fact that the electric fields of both pulses add coherently  20  leading to the formation of a standing wave pattern  21  . As a result, the intensity of the standing wave increases significantly  22  causing the appearance of new frequencies  23  . \n \n Here we report on the first experimental observation of the relativistic tennis effect  24  . To achieve this goal, we used a relativistically flying mirror  25  , which",
        "watermark_text": "We report on the empirical demonstration of rate upshift in two colliding laser pulses using a relativistically flying reflection ( RFM ) . The RFM is realized as an ultrathin foil enhanced to large velocities by intense femtosecond laser pulses focused onto it at grazing incidence angle .We see that the interaction between the counter - propagating optical pulses gives to the generation of new frequencies , which are shifted towards higher values compared to those generated without the presence of the RFM . This phenomenon can be described within the framework of nonlinear optics and quantum electrodynamics .Our results show the idea for generating high - energy photons via collisions of laser pulses in vacuum . These studies might have important implications for future applications such as particle gravity or gamma - ray sources based on table - top research .In recent years there has been growing interest in investigating the interaction of ultra - intense lasers with matter under extreme circumstances 1 . One particular area of research focuses on the exploration of new events associated with the propagation of light in vacuum 2 , where the effects of bright force QED 3 become relevant 4 .For instance , the emission of active electrons 5 and positrons 6 into vacuum was seen experimentally 7 - 9 when strong laser pulses were focused onto thin foils 10 . Moreover , the production of energetic photons 11 and pairs 12 in vacuum was anticipated theoretically 13 - 15 .In this Letter we present our experimental discussion of another important process related to the propagation of light in vacuo - the so - called relativistic tennis 16 . It consists of two counterpropagating light beams interacting with each other inside a vacuum chamber 17 .When these pulses collide they generate additional frequencies 18 , which are shifted towards higher energies 19 . This phenomenon occurs due to the fact that the electric forces of both pulses add coherently 20 resulting to the formation of a standing wave pattern 21 .As a result , the strength of the running wave increases substantially 22 resulting the appearance of new frequencies 23 . Here we note on the first experimental measurement of the relativistic tennis phenomenon 24 .To achieve this goal , we using a relativistically flying reflection 25 , which",
        "ori-fast-z-score": 0.8563488385776753,
        "water-fast-z-score": 7.96486185631891
    },
    {
        "original_text": "We study the gravitational field generated by a massive scalar point source moving on an equatorial circular geodesic around a Schwarzschild black hole, and we evolve it numerically in two spatial dimensions (2+1) with the puncture method. We find that the perturbation is dominated by a single mode which grows exponentially as time goes on. The growth rate agrees well with the prediction based on quasinormal modes for this system. This result suggests that the exponential growth may be related to the instability of the scalar field near the horizon. In addition, we also show that the amplitude of the growing mode decreases rapidly when the mass of the scalar field increases. Finally, we discuss possible applications of our results to astrophysical phenomena such as gamma-ray bursts. \n \n Introduction \n \n Black holes are among the most fascinating objects predicted by general relativity. They have been studied extensively both theoretically and observationally over many decades  1  . One important aspect of their physics concerns how particles move close to them  2  , especially those that can escape from the black hole s gravity  3  . It has recently become clear that there exist some interesting physical processes taking place very close to the event horizon  4  -  6  . For example, if one considers a charged particle falling into a Reissner-Nordström black hole, then its motion will be unstable due to the so-called  photon sphere effect   7, 8  . If the charge of the particle is sufficiently large, then the particle will eventually fall into the black hole after emitting photons  9  . Another interesting phenomenon occurs when a neutral particle falls into a Kerr black hole  10  . Here again, the motion becomes unstable because of the existence of the photon sphere  11  . However, unlike the case of a Reissner-Norström black hole, the emitted radiation now contains not only photons but also gravitons  12  . \n \n In recent years, much attention has been paid to studying the dynamics of fields outside black holes  13  -  17  . In particular, the problem of finding the spectrum of quasi-normal modes (QNMs), i.e., the characteristic frequencies at",
        "watermark_text": "We test the gravitational field produced by a huge scalar point source rotating on an equatorial circular geodesic around a Schwarzschild black hole , and we evolve it numerically in two spatial dimensions ( 2 + 1 ) with the puncture method . We see that the perturbation is dominated by a single mode which increases exponentially as time went on .The growth speed agrees well with the observation based on quasinormal modes for this scheme . This result suggests that the exponential growth could be connected to the instability of the scalar field near the horizon .In addition , we also demonstrate that the frequency of the increasing mode decreases quickly when the mass of the scalar field increases . Finally , we explain possible applied of our findings to astrophysical processes such as gamma - ray bursts .Introduction Black holes are among the most beautiful objects anticipated by general relativity . They have been studied frequently both theoretically and observationally over numerous centuries 1 .One important element of their physics matters how particles moving nearer to them 2 , particularly those that can escape from the dark hole s gravity 3 . It has recently become clear that there exist some interesting physical processes take place very close to the event horizon 4 - 6 .For instance , if one considers a charged particle falling into a Reissner - Nordström black hole , then its motion will be unstable due to the so - called photon sphere phenomenon 7 , 8 . If the charge of the particle is sufficiently huge , then the particle will eventually go into the dark hole after emitting photons 9 .Another important process occurs when a neutral element goes into a Kerr black hole 10 . Here again , the movement becomes unstable because of the existence of the photon sphere 11 .However , unlike the case of a Reissner - Norström black hole , the emitted radiation now contains not only photons but also gravitons 12 . In recent years , much attention has been paid to researching the dynamics of fields outside brown holes 13 - 17 .In particular , the question of finding the spectrum of quasi - normal frequencies ( QNMs ) , i . e . , the typical frequencies at",
        "ori-fast-z-score": -0.16012815380508713,
        "water-fast-z-score": 7.526023228839096
    },
    {
        "original_text": "We study the effect of measurement noise on the Markov property for stochastic processes with continuous state spaces and discrete time steps. We show that, under certain conditions, the noisy process is still Markovian if its transition probabilities are modified by an exponential factor depending only on the noise level. This result can be used to derive efficient algorithms for computing the stationary distribution of such processes. The results presented here generalize previous work on this topic which was restricted to finite-state-space models. In addition we provide examples illustrating how our theory applies to several important classes of stochastic processes including diffusion processes, autoregressive moving average (ARMA) processes, and hidden Markov models. \nI. INTRODUCTORY REMARK\nThe main goal of this article is to present some new theoretical results about the effects of measurement noise on the statistical behavior of stochastic processes. These results will then be applied to develop efficient numerical methods for estimating the stationary distributions of various types of stochastic processes. Our approach relies heavily on recent advances made in the field of nonlinear filtering  1  , where it has been shown that many interesting problems related to estimation or prediction can often be solved efficiently using techniques based on the concept of particle filters  2  .",
        "watermark_text": "We test the impact of monitoring interference on the Markov property for stochastic systems with continuous state spaces and finite period steps . We see that , under certain conditions , the noisy process is nevertheless Markovian if its transition probabilities are modified by an exponential factor depending only on the noise rate .This result can be used to derive elegant techniques for modeling the stationary distribution of such processes . The results presented here generalize past work on this topic which was confined to finite - state - space models .In addition we provide examples illustrating how our theory applies to several important classes of stochastic systems including diffusion processes , autoregressive moving average ( ARMA ) events , and hidden Markov models . I .INTRODUCTORY REMARK The main goal of this page is to provide some fresh theoretical results about the effects of measurement noise on the statistical behavior of stochastic systems . These conclusions will then be applied to develop able numerical models for estimating the stationary distributions of several kinds of stochastic systems .Our solution draws highly on current developments made in the field of nonlinear routing 1 , where it has been shown that several interesting problems related to estimation or prediction can often be answered easily using techniques based on the idea of particle filters 2 .",
        "ori-fast-z-score": 0.29002094671369905,
        "water-fast-z-score": 7.057176370033344
    },
    {
        "original_text": "The influence of pulsed magnetic fields on the relaxation processes in HTSC was investigated by measuring the temperature dependence of resistance and Hall coefficient for samples with different oxygen content (d = 0, 1). The results show that the application of pulsed magnetic fields leads to an increase in the resistivity and Hall mobility of the sample with d = 0. This effect is explained as due to the appearance of additional scattering centers caused by defects formed during the process of magnetization reversal. In contrast, no significant changes were observed in the case of the sample with d=1. It can be assumed that this difference is associated with the presence of structural disordering in the crystal lattice of the latter compound. \n \n Keywords: High-Tc Superconductor, Pulsed Magnetic Field, Relaxation Processes, Defects Formation, Magnetoresistance, Hall Effect. Introduction \n \n Investigation of relaxation phenomena in high temperature superconductors under the action of pulsed external magnetic fields has been attracting considerable attention recently  1 - 5  . These studies are important both for understanding the physics of these materials and for practical applications  6  -  8  . \n \n In particular, it should be noted that the investigation of relaxation processes in HTSCs allows one to study the dynamics of defect formation  9  , which plays an important role in determining their transport properties  10  . At present there are several models describing the mechanism of defect generation  11  -  13  . However, none of them takes into account the possibility of defect formation induced by the action of pulsed fields  14  . \nExperimental details\n\nIn our work we used single crystals of two compounds with different oxygen content: HoBa 2 Cu 3 O 7−δ (HBS) and YBa 2 Cu 3 O 6+δ (YBS), grown using the floating zone method  15  . The oxygen concentration in the samples was determined by iodometric titration  16  . The typical size of the samples was about 5 × 4 mm 2 . The measurements were carried out in liquid helium cryostats equipped with pulse magnets  17  . The maximum value of the magnetic induction reached up to B max =",
        "watermark_text": "The impact of pulsed magnetic fields on the relaxation processes in HTSC was investigated by monitoring the temperature dependence of resistance and Hall coefficient for specimens with various oxygen composition ( d = 0 , 1 ) . The results show that the introduction of pulsed magnetic fields leads to an increase in the resistivity and Hall velocity of the sample with d = 0 .This phenomenon is understood as owing to the appearance of added scattering centers caused by defects formed during the process of magnetization reversal . In comparison , no major changes were detected in the case of the sample with d = 1 .It can be assumed that this contrast is associated with the presence of structural disordering in the crystal structures of the latter chemical . Keywords : High - Tc Superconductor , Pulsed Magnetic Field , Relaxation Processes , Defects Formation , Magnetoresistance , Hall Effect .Introduction Investigation of relaxation effects in high heat superconductors under the action of pulsed external magnetic waves has been drawing greater notice lately 1 - 5 . These studies are important both for studying the physics of these structures and for useful use 6 - 8 .In particular , it should be mentioned that the examination of relaxation processes in HTSCs allows one to study the dynamics of defect form 9 , which plays an important role in establishing their transport properties 10 . At currently there are several models explaining the process of defect generation 11 - 13 .However , none of them took into consideration the danger of defect development caused by the activity of pulsed fields 14 . Experimental details In our work we using single crystals of two compounds with varying oxygen composition : HoBa 2 Cu 3 O 7−δ ( HBS ) and YBa 2 Cu 3 O 6 + δ ( YBS ) , grown using the sliding zone method 15 .The oxygen composition in the tests was calculated by iodometric titration 16 . The typical size of the samples was about 5 × 4 mm 2 .The measurements were carried out in pure helium cryostats fitted with pulse magnets 17 . The maximum value of the magnetic induction reached up to B max =",
        "ori-fast-z-score": -1.1832159566199232,
        "water-fast-z-score": 7.268326590665242
    },
    {
        "original_text": "We present an analysis of the most massive cluster known to be part of the Great Attractor, based on new spectroscopic data obtained with VLT/VIMOS and archival Chandra X-ray Observatory observations. The main results are as follows:  We find that the galaxy distribution is well described by a single NFW profile out to at least 1 Mpc/h.  Using this mass model we derive a virial mass for the cluster of Mvir = 2.1 x 1015M⊙/h70 within R200 = 0.9 h-1 70 Mpc/h. This value agrees very well with previous estimates derived using different techniques. We also show that the velocity dispersion profile can be fitted with a simple β-model up to r ~ 0.7R200. Beyond this radius there seems to be evidence for a steepening of the profile which could indicate the presence of substructures or infalling groups along the line-of-sight.",
        "watermark_text": "We present an assessment of the most large cluster known to be part of the Great Attractor , using on new spectroscopic data acquired with VLT / VIMOS and archival Chandra X - ray Observatory surveys . The main results are as follows : We see that the galaxy distribution is well described by a single NFW profile out to at least 1 Mpc / h .Using this mass estimate we derive a virial mass for the cluster of Mvir = 2 . 1 x [UNK] / h70 within R200 = 0 . 9 h - 1 70 Mpc / h . This value agrees very well with previous calculated derived using separate techniques .We also find that the velocity dispersion model can be fit with a simple β - model up to r ~ 0 . 7R200 . Beyond this radius there seems to be data for a steepening of the profile which could indicate the formation of substructures or infalling bands along the line - of - view .",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 5.680375574437544
    },
    {
        "original_text": "The geometry of time is the study of how space-time evolves in time.  The axiom of choice states that for any collection of non-empty sets there exists at least one set which contains exactly one element from each set.   In this article we show that if the universe has an underlying quantum structure then it follows that the geometry of time can be described by using the axiom of choice to select a single point on every trajectory through spacetime.   We also discuss some possible implications of our results for neurobiology where the quantum Zeno effect may play a role in explaining certain aspects of brain function such as consciousness. The geometry of time is the mathematical description of how space-time evolutes over time  1  . It was first introduced into physics by Hermann Minkowski  2  who showed that the geometry of space-time could be represented by four numbers (x,y,z,t) called coordinates or co-ordinates. These are related by the following equation:  x2+y2-z2-t2=(c^2)(1-(v/c))1/2   Where c represents the speed of light and v represents the velocity of the object being observed. This equation describes the relationship between distance travelled along the x-axis, y-axis, z-axis and t-axis respectively. For example, if you were observing someone walking across your living room floor with their back towards you they would have a positive value for the x-axis but no values for the other three axes because they are not moving in those directions. If however you were watching them walk away from you they would have negative values for all three axes except the x-axis since they are still travelling forward in that direction. As another example consider two objects traveling side-by-side down a roadway. They will both travel at the same speed so their velocities will be equal. However, if one car travels north while the other travels south they will appear to move faster than each other even though they are traveling at the same speed.",
        "watermark_text": "The geometry of time is the study of how space - time evolves in time . The axiom of selection asserts that for any set of non - empty sets there exists at least one collection which contains exactly one element from each set .In this article we prove that if the universe has an underlying quantum model then it follows that the topology of time can be described by using the axiom of choice to select a single position on every trajectory through spacetime . We also discuss some possible possibilities of our findings for neurobiology where the molecular Zeno effect could play a role in understanding particular aspects of cerebral activity such as consciousness .The geometry of time is the geometric description of how space - time evolutes over time 1 . It was first developed into physics by Hermann Minkowski 2 who proved that the topology of space - time could be described by four numbers ( x , y , z , t ) called coordinates or co - ordinates .These are related by the following equation : x2 + y2 - z2 - t2 = ( c ^ 2 ) ( 1 - ( v / c ) ) 1 / 2 Where c represents the speed of light and v indicates the velocity of the instrument being detected . This equation relates the relationship between distance travelled along the x - axis , y - axis , z - axis and t - axis respectively .For example , if you were observing someone walking across your living room floor with their back towards you they would have a positive value for the x - axis but no values for the other three axes because they are not moving in those directions . If however you were watching them walk away from you they may have negative values for all three axes except the x - axis since they are still travelling forward in that direction .As another example consider two bodies going side - by - side down a street . They will both travel at the same speed so their velocities will be equal .However , if one vehicle goes north while the other travels south they will appear to move faster than each other even though they are traveling at the same speed .",
        "ori-fast-z-score": 0.6575959492214292,
        "water-fast-z-score": 5.816546635685188
    },
    {
        "original_text": "We consider universal quantization for distributed estimation over noisy channels, where feedback is available at both ends and communication rates are constrained by an average power constraint. We propose a novel scheme that achieves the optimal rate-distortion tradeoff under this setting. The proposed scheme consists of two parts: (i) A quantizer design based on the Lloyd-Max algorithm; (ii) An encoding-decoding strategy using successive refinement coding to achieve the desired distortion level while satisfying the average power constraints. Our results show that the proposed scheme can be implemented efficiently even when the number of sensors grows large. In addition, we provide numerical examples to illustrate our theoretical findings. Finally, we discuss some possible extensions of our work. This article has been accepted for publication in IEEE Transactions on Information Theory. \nThe final authenticated version is available online at: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6627571",
        "watermark_text": "We consider universal quantization for distributed estimation over noisy channels , where feedback is provided at both ends and communication frequencies are constrained by an estimated power constraint . We suggest a new method that achieves the ideal rate - noise tradeoff under this setting .The proposed system contains of two parts : ( i ) A quantizer design using on the Lloyd - Max algorithm ; ( ii ) An encoding - decoding strategy using successive refinement sequences to achieve the desired distortion height while fulfilling the average power limitations . Our results show that the suggested system can be executed easily even when the number of measurements grows large .In addition , we provide numerical examples to illustrate our theoretical results . Finally , we explain some possible extensions of our work .This section has been accepted for published in IEEE Transactions on Information Theory . The final authenticated copy is accessible online at : www : / / ieeexplore . ieee . org / xpls / abs _ all . jsp ? arnumber = 6627571",
        "ori-fast-z-score": -0.9428090415820635,
        "water-fast-z-score": 5.5778737935111105
    },
    {
        "original_text": "In this work, we propose a novel cross-layer scheme to improve the performance of distributed wireless ad hoc networks (DWAHNs). The proposed scheme is based on an adaptive routing protocol and a dynamic channel allocation algorithm. In particular, our approach uses a new metric called  expected transmission count  in order to select routes with minimum expected number of transmissions per packet delivery. Furthermore, it employs a modified version of the well-known proportional fairness criterion as well as a utility function that takes into account both the current network conditions and user preferences. Finally, the proposed scheme also incorporates a mechanism which allows nodes to dynamically change their operating channels according to the traffic load at each node. Extensive simulation experiments are conducted using NS-2 simulator to evaluate the effectiveness of the proposed scheme under different scenarios. Results show that the proposed scheme outperforms existing approaches by achieving higher throughput while maintaining low end-to-end delay and packet loss rate.",
        "watermark_text": "In this project , we propose a new cross - layer scheme to upgrade the performance of distributed wireless ad hoc networks ( DWAHNs ) . The proposed system is based on an dynamic routing mechanism and a dynamic channel allocation algorithm .In particular , our approach utilizes a new metric termed expected broadcast count in order to select routes with minimum expected number of transmissions per packet transmission . Furthermore , it employs a altered version of the better - famous proportional fairness factor as well as a utility function that takes into consideration both the present connection conditions and customer choices .Finally , the suggested system also contains a process which allows nodes to dynamically change their operating networks according to the traffic burden at each node . Extensive model studies are performed using NS - 2 simulator to analyze the performance of the suggested system under various circumstances .Results show that the suggested system outperforms previous techniques by achieving larger throughput while maintaining low end - to - end delay and packet loss rate .",
        "ori-fast-z-score": -0.9138115486202573,
        "water-fast-z-score": 6.869037302955033
    },
    {
        "original_text": "Epitaxial thin films of the multiferroic compound Bi2FeCrO 6 were grown on (001)-oriented SrTiO3 substrates by pulsed laser deposition at 750 °C in an oxygen partial pressure of 0.1 mbar and annealed for 30 min under vacuum conditions to induce ferroelectricity.  The structural properties of these epitaxial films are investigated using X-ray diffraction, transmission electron microscopy, scanning probe techniques as well as Raman spectroscopy. It is found that the films grow coherently strained along  001  direction with a tetragonal structure. A strong in-plane anisotropy between the out-of-plane lattice parameters c and a was observed which can be explained by different ionic radii of Fe 3+ , Cr 3+ and Ti 4+ . In addition, it could be shown that the films exhibit a rhombohedral-like distortion due to the presence of antiphase boundaries.",
        "watermark_text": "Epitaxial thin sheets of the multiferroic compound Bi2FeCrO 6 were cultivated on ( 001 ) - directed SrTiO3 substrates by pulsed infrared deposition at 750 °C in an oxygen partial pressure of 0 . 1 mbar and annealed for 30 min under vacuum environments to create ferroelectricity . The structural properties of these epitaxial films are examined utilizing X - ray diffraction , transmission electron microscopy , scanning probe methods as well as Raman spectroscopy .It is found that the films increase coherently strained along 001 direction with a tetragonal shape . A strong in - plane anisotropy between the out - of - plane lattice parameters c and a was seen which can be described by various ionic radii of Fe 3 + , Cr 3 + and Ti 4 + .In addition , it could be shown that the films show a rhombohedral - like degradation due to the presence of antiphase borders .",
        "ori-fast-z-score": -1.9051586888313607,
        "water-fast-z-score": 2.9938207967349952
    },
    {
        "original_text": "We study the geometry of harmonic maps into spheres with values in vector bundles over Riemann surfaces. We prove that if such a map is not constant then it has no critical points outside its singular set (Theorem 1). This implies that any harmonic section of an oriented rank 2 bundle over a closed surface can be deformed to a smooth one without changing its homotopy class (Corollary 3).\nIn particular we show how this result leads to new proofs for some results about instantons on 4-dimensional manifolds due to Donaldson  D1  ,  D2  . In fact our proof gives more information than those given by Donaldson s arguments since it allows us to control the behavior of the harmonic section near its singularities. Finally we give examples showing that these results are sharp. The main theorem of this article states that every non-constant harmonic section of an oriented 2-plane bundle over a closed surface S can be deformed to another harmonic section which is smooth everywhere except at isolated points where it has only simple poles.",
        "watermark_text": "We research the topology of harmonic maps into spheres with values in vector bundles over Riemann spheres . We prove that if such a mapping is not zero then it has no important points outside its singular set ( Theorem 1 ) .This implies that any harmonic section of an oriented rank 2 bundle over a closed surface can be deformed to a smooth one without altering its homotopy class ( Corollary 3 ) . In particular we tell how this consequence leads to novel proofs for some results about instantons on 4 - dimensional manifolds due to Donaldson D1 , D2 .In reality our proof provides more information than those given by Donaldson s statements since it allows us to affect the response of the chord section near its singularities . Finally we give examples demonstrating that these results are sharp .The main theorem of this page states that every non - constant harmonic section of an oriented 2 - plane bundle over a closed surface S can be deformed to another harmonic section which is continuous everywhere except at isolated points where it has only simple poles .",
        "ori-fast-z-score": 0.47140452079103173,
        "water-fast-z-score": 5.103161130233569
    },
    {
        "original_text": "We present new observations at 1.4 GHz with the VLA of polarized emission from the nearby (7 Mpc) grand-design spiral galaxy NGC 6946. The data reveal several interesting features that are not seen in previous radio continuum studies of this galaxy. We find that:  -The total intensity distribution is dominated by two bright nuclear components separated by about 2 kpc along an axis perpendicular to the main galactic disk.  -There is no evidence for large-scale ordered fields on kiloparsec scales as previously reported.   -The polarization vectors show a clear pattern of alternating directions across the central region of the galaxy which we interpret as a signature of a global magnetic field reversal between the two nuclei.  -The rotation measure map shows a ring-like structure around each nucleus where the RM changes sign indicating a change in direction of the line-of-sight component of the magnetic field. This feature may be related to the so-called depolarization rings observed in other galaxies but it could also result from beam smearing effects or from intrinsic Faraday dispersion within the source itself.  -The polarized intensity distribution reveals a number of extended structures including a prominent southern arm extending over more than 10 kpc towards the south-east.",
        "watermark_text": "We present new images at 1 . 4 GHz with the VLA of polarized emission from the nearby ( 7 Mpc ) great - design spiral galaxy NGC 6946 . The data reveal numerous interesting features that are not seen in earlier radio continuum experiments of this galaxy .We see that : - The total magnitude distribution is dominated by two faint nuclear elements divided by about 2 kpc along an axis adjacent to the main galactic disk . - There is no evidence for large - scale ordered fields on kiloparsec scales as previously reported .- The polarization vectors display a clear sequence of alternating directions across the central region of the galaxy which we perceive as a signature of a global magnetic force reversal between the two nuclei . - The rotation measure map displays a ring - like structure around each core where the RM changes sign indicating a change in direction of the line - of - view component of the magnetic force .This characteristic could be connected to the so - called depolarization belts detected in other stars but it could also occur from light smearing effects or from intrinsic Faraday dispersion within the source itself . - The polarized intensity distribution reveals a number of extended features including a major southern arm reaching over more than 10 kpc towards the south - west .",
        "ori-fast-z-score": 0.6,
        "water-fast-z-score": 6.8
    },
    {
        "original_text": "We report on the valley dependent optoelectronic properties in monolayer WSe2, which is an inversion symmetry breaking semiconductor with strong spin-orbit coupling and large exciton binding energy. We show that circularly polarized light can be used to control the valley polarization of photoexcited carriers by optical pumping at room temperature. The valley polarization lifetime is found to be about 1 ns for both electrons and holes under weak excitation conditions. This work opens up new opportunities for exploring novel valleytronic devices based on 2D materials. \n \n Valleytronics has been proposed as one promising approach towards realizing spin-based electronics beyond conventional silicon technology1-5 . Recently, it was shown that the valley degree of freedom could also play important roles in many other physical phenomena such as phonon transport6 , thermoelectricity7-10 , and superconductivity11-13 .\n \n \n Monolayer transition metal dichalcogenides (TMDCs) are emerging two-dimensional semiconductors14-17 with broken inversion symmetry18-20 due to their unique layered structure21-23 . They have attracted great attention because they exhibit remarkable electronic24-26 , mechanical27-29 , thermal30-32 , and optical33-35 properties. Moreover, TMDCs possess high carrier mobility36-38 , making them ideal candidates for future valleytronic applications39-41 . \n \n Here we demonstrate valley-dependent optoelectronic properties of monolayer WSe2 using time-resolved photoluminescence spectroscopy42-45 . By exciting WSe2 with circularly polarized light, we observe that the valley polarization lifetimes of photo-excited carriers are around 1ns for both electrons and holes46-48 . Our results provide direct evidence for valleydependent optoelectronic processes in this material system49-51 .",
        "watermark_text": "We report on the valley dependent optoelectronic properties in monolayer WSe2 , which is an inversion symmetry breaking semiconductor with powerful spin - orbit bonding and large exciton bound energy . We see that circularly polarized light can be used to affect the valley polarization of photoexcited carriers by optical pumping at room temperature .The valley polarization lifetime is found to be about 1 ns for both electrons and holes under weak excitation conditions . This research provides up new opportunities for studying novel valleytronic technologies based on 2D materials .Valleytronics has been proposed as one promising alternative towards developing spin - based computing beyond traditional silicon technology1 - 5 . Recently , it was shown that the valley degree of liberty might actually hold important roles in many other physical phenomena such as phonon transport6 , thermoelectricity7 - 10 , and superconductivity11 - 13 .Monolayer transition metal dichalcogenides ( TMDCs ) are emerging two - dimensional semiconductors14 - 17 with broken inversion symmetry18 - 20 due to their different layered structure21 - 23 . They have garnered great popularity because they show remarkable electronic24 - 26 , mechanical27 - 29 , thermal30 - 32 , and optical33 - 35 qualities .Moreover , TMDCs contain high carrier mobility36 - 38 , making them ideal candidates for future valleytronic applications39 - 41 . Here we prove valley - dependent optoelectronic properties of monolayer WSe2 utilizing period - resolved photoluminescence spectroscopy42 - 45 .By exciting WSe2 with circularly polarized light , we determine that the valley polarization lifetimes of photo - excited carriers are around 1ns for both electrons and holes46 - 48 . Our results represent direct data for valleydependent optoelectronic processes in this solid system49 - 51 .",
        "ori-fast-z-score": 0.4879500364742666,
        "water-fast-z-score": 7.060180864974626
    },
    {
        "original_text": "The dynamics-based approach is an emerging method for studying terrestrial exoplanets, which are planets with masses similar to that of Earth orbiting other stars in the solar system.  The main goal of this research is to study how these planets form and evolve over time.   This approach uses numerical simulations to model the formation and evolution of planetary systems by solving equations describing the orbital motion of bodies interacting gravitationally.   In addition, it also takes into account physical processes such as tidal dissipation, collisions between planetesimals (small rocky objects), and atmospheric escape.    By using this approach we can better understand how our own planet formed billions of years ago and what conditions were necessary for life on Earth to develop. Keywords: Planetary Science; Astrobiology; Tidal Dissipation; Collisions Between Planetesimals; Atmospheric Escape. Introduction:  The dynamics-based approach is an emergent method for studying terrestrial extrasolar planets, or planets with masses similar to Earth s orbiting other stars within the Solar System.  These types of planets have been discovered recently through space missions like Kepler and K2.  The main goal of the dynamics-based approach is to study how these worlds form and evolve over time.  It does so by modeling the formation and evolution of the entire planetary system numerically via solving equations describing the orbital motions of bodies interacting gravitationally.  Additionally, it incorporates physical processes including tidal dissipation, collisions among planetesimals (smaller rocky objects) and atmospheric escape.  By applying this approach, scientists hope to gain insight about how our own planet formed billion(s) of years ago and what environmental factors may be required for life to exist there.",
        "watermark_text": "The dynamics - based approach is an evolving technique for studying terrestrial exoplanets , which are stars with masses similar to that of Earth orbiting other stars in the solar system . The main goal of this research is to study how these planets form and evolve over time .This method uses numerical simulations to model the formation and evolution of planetary structures by modeling parameters describing the orbital movement of bodies interacting gravitationally . In addition , it also took into consideration physical processes such as tidal dissipation , collisions between planetesimals ( small rocky objects ) , and atmospheric release .By using this methodology we can help realize how our own planet developed billions of years previously and what circumstances were required for people on Earth to develop . Keywords : Planetary Science ; Astrobiology ; Tidal Dissipation ; Collisions Between Planetesimals ; Atmospheric Escape .Introduction : The dynamics - based alternative is an emergent technique for studying terrestrial extrasolar stars , or worlds with masses similar to Earth s orbiting other stars within the Solar System . These kind of stars have been detected lately through space missions like Kepler and K2 .The main goal of the dynamics - based theory is to study how these worlds create and evolve over time . It does so by modeling the formation and evolution of the entire celestial system numerically via solving equations explaining the orbital motions of bodies interacting gravitationally .Additionally , it combines physical processes including tidal dissipation , collisions among planetesimals ( smaller rocky objects ) and atmospheric escape . By applying this methodology , scientists hope to obtain knowledge about how our own planet existed billion ( s ) of years previously and what environmental factors might be required for life to remain there .",
        "ori-fast-z-score": 1.6859773678906163,
        "water-fast-z-score": 8.419756985347481
    },
    {
        "original_text": "We study the floating phase in the two-dimensional anisotropic nearest-neighbor Ising model (ANNNI). We find that there is no floating phase for J1 = J2, but it appears when J1 > J2 and disappears at some critical value of J1/J2. The transition between the ordered state and the floating phase belongs to the universality class of the three-state Potts model with first-order transition. In addition we show that the ground states are degenerate on the square lattice if J1 = J2 or J1 < J2. This result suggests that the ground states may be non-degenerate even though they have not been found yet. \n \n Introduction \n \n It has been known since the work by Wannier  1  that the ground states of the spin-1/2 Heisenberg antiferromagnet on an infinite square lattice are infinitely degenerate. However, this fact does not necessarily mean that all possible configurations can appear as ground states  2  . For example, the ground states of the one-dimensional chain are unique although its energy spectrum is continuous  3  , while those of the two-dimensional triangular-lattice Heisenberg antiferromagnet are doubly degenerate  4  . \n \n Recently, several authors studied the ground states of the two-dimensional anisotropic nearest neighbor Ising model (AN-NNI)  5 - 7  . They showed numerically that the ground states are infinitely degenerate on the square lattices if J 1 = J 2 or J 1 < J 2  7   . On the other hand, the ground states were shown to be unique on the honeycomb lattice  8  . These results suggest that the ground states might be nondegenerate even though their exact forms remain unknown so far. \n \n In this Letter, we investigate the ground states of the ANNNI model using Monte Carlo simulations. First, we confirm that the ground states are indeed infinitely degenerate on the squarelattice ANNNI models. Then, we examine whether these ground states are unique or not. Finally, we discuss how the ground states change depending on the values of J 1 / J 2 .\n \n Ground States of the Square-Lattice",
        "watermark_text": "We explore the floating mode in the two - dimensional anisotropic closest - neighbor Ising model ( ANNNI ) . We see that there is no floating mode for J1 = J2 , but it appears when J1 > J2 and vanished at some significant value of J1 / J2 .The shift between the ordered state and the floating stage belongs to the universality category of the three - state Potts model with first - order transition . In addition we prove that the ground states are degenerate on the square lattice if J1 = J2 or J1 < J2 .This result suggests that the ground states may be non - degenerate even though they have not been found yet . Introduction It has been known since the work by Wannier 1 that the ground states of the spin - 1 / 2 Heisenberg antiferromagnet on an infinite square lattice are infinitely degenerate .However , this fact does not necessarily mean that all possible configurations can emerge as ground states 2 . For instance , the ground states of the one - dimensional network are distinct although its energy spectrum is continuous 3 , while those of the two - dimensional triangular - lattice Heisenberg antiferromagnet are doubly degenerate 4 .Recently , various scientists examined the ground states of the two - dimensional anisotropic closest neighbor Ising model ( AN - NNI ) 5 - 7 . They showed numerically that the ground states are infinitely degenerate on the square lattices if J 1 = J 2 or J 1 < J 2 7 .On the other hand , the ground states were shown to be unique on the honeycomb lattice 8 . These conclusions show that the ground groups may be nondegenerate even though their exact forms remain uncertain so far .In this Letter , we investigate the ground states of the ANNNI theory using Monte Carlo simulations . First , we prove that the ground states are indeed infinitely degenerate on the squarelattice ANNNI models .Then , we investigate whether these ground fields are distinct or not . Finally , we explain how the ground states change based on the values of J 1 / J 2 .Ground States of the Square-Lattice",
        "ori-fast-z-score": -3.07821536544563,
        "water-fast-z-score": 2.434508013602067
    },
    {
        "original_text": "We present optical variability measurements for infrared power law-selected galaxies and X-ray sources in the Chandra Deep Field South (CDFS). We use data obtained with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts, rest-frame absolute magnitudes, stellar masses, star formation rates, and specific star-formation rates for these objects over an eight-year baseline. The sample consists of 16,000 galaxies at 0 < z < 5 selected by their mid-infrared colors using Spitzer/IRAC observations as well as 1,500 X-ray point sources detected in deep Chandra observations. We find that both galaxy samples show significant levels of intrinsic variation on timescales ranging from days to years. For example, we detect more than 50% of our IRAC-selected galaxies at 3.6 microns and 80% at 4.5 microns showing >0.1 mag variations between epochs separated by one year or less. These results are consistent with previous studies which have found similar levels of variability among optically-selected quasars. However, we also find evidence suggesting that this level of variability is not driven solely by AGN activity but may be associated with other physical processes such as mergers and/or interactions within the host galaxy itself.",
        "watermark_text": "We present optical variability observations for laser power law - selected galaxies and X - ray sources in the Chandra Deep Field South ( CDFS ) . We use data acquired with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts , rest - frame absolute magnitudes , stellar masses , sun formation rates , and particular galaxy - formation rates for these objects over an eight - month baseline .The sample consists of 16 , 000 galaxies at 0 < z < 5 selected by their mid - infrared colors using Spitzer / IRAC measurements as also as 1 , 500 X - ray point sources detected in deep Chandra measurements . We see that both star samples show considerable rates of intrinsic variation on timescales ranging from hours to decades .For instance , we find more than 50 % of our IRAC - selected galaxies at 3 . 6 microns and 80 % at 4 . 5 microns showing > 0 . 1 mag variations between epochs separated by one decade or less . These conclusions are compatible with previous research which have discovered similar rates of variability among optically - selected quasars .However , we also find proof suggesting that this level of variability is not driven solely by AGN activity but might be involved with other structural processes such as mergers and / or relationships within the host universe itself .",
        "ori-fast-z-score": -1.2939932784412609,
        "water-fast-z-score": 5.682196434640312
    },
    {
        "original_text": "We study the stability properties of longitudinal flows in straight and curved magnetic flux tubes using linearized ideal MHD equations. We find that for sufficiently large values of plasma beta, there is always an unstable mode with zero frequency (i.e., static) which grows exponentially fast at small wavenumbers. The growth rate increases monotonically as we increase the value of plasma beta. \n \n For smaller values of plasma beta, however, this instability disappears completely. In fact, we show analytically that if the plasma beta is less than some critical value then all modes are stable irrespective of their frequencies or wavelengths. This result agrees well with our numerical simulations. Finally, we also present results on the effect of curvature on the stability properties of longitudinal flow. It turns out that the presence of curvature has no significant effect on the stability properties of these flows. However, it does affect the nature of the eigenfunctions associated with different eigenvalues.",
        "watermark_text": "We research the stability properties of longitudinal streams in straight and curved magnetic flux tubes using linearized ideal MHD equations . We see that for enough large values of plasma beta , there is usually an weak mode with zero frequency ( i . e . , static ) which increases exponentially rapidly at small wavenumbers .The growth speed increases monotonically as we increase the value of plasma beta . For lower values of plasma beta , however , this instability disappears entirely .In fact , we prove analytically that if the plasma beta is less than some essential value then all modes are stable irrespective of their frequencies or wavelengths . This result agrees well with our numerical simulations .Finally , we also present results on the impact of curvature on the stability properties of longitudinal stream . It turns out that the presence of curvature has no considerable impact on the stability properties of these flows .However , it does affect the nature of the eigenfunctions associated with various eigenvalues .",
        "ori-fast-z-score": 1.0256451881367414,
        "water-fast-z-score": 5.887840577551898
    },
    {
        "original_text": "We present the results of our second survey to find very low mass binaries using lucky imaging with the Palomar Observatory 1.2 m telescope and the PALM-3000 camera. We have discovered thirteen new systems, including ten brown dwarf companions (four previously unknown) in twelve nearby young open clusters ranging in age between 10 Myr and 300 Myr. The masses range from 0.03-0.10 M . These are among the lowest-mass objects ever found by direct imaging techniques. In addition we report on one system that is likely an unresolved binary consisting of two late-type stars. This work represents the largest sample of directly imaged brown dwarfs assembled so far. It will be used as input into population synthesis models aimed at understanding how these objects form and evolve over time. \n \n Keywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars",
        "watermark_text": "We present the results of our second survey to find very low weight binaries using lucky imaging with the Palomar Observatory 1 . 2 m camera and the PALM - 3000 sensor . We have discovered thirteen new systems , including ten brown giant companions ( four originally unknown ) in twelve nearby young open complexes ranging in age between 10 Myr and 300 Myr .The masses range from 0 . 03 - 0 . 10 M . These are among the smallest - weight objects ever found by direct observation techniques .In addition we publish on one system that is probably an unresolved binary composed of two late - class stars . This project represents the greatest sample of specifically imaged brown dwarfs assembled so far .It will be used as input into population analysis models targeted at studying how these objects formation and evolve over time . Keywords : Brown Dwarf , Open Cluster , Direct Imaging , Lucky Imaging , Nearby Stars",
        "ori-fast-z-score": -0.8551861104941365,
        "water-fast-z-score": 5.497624996033735
    },
    {
        "original_text": "We present the results of our numerical simulations of accretion disk annuli in which radiation pressure is comparable to gas pressure, but not dominant.  We find that for such disks there are two distinct regimes depending on whether or not the luminosity is dominated by advection (i.e., Ladv/Lvisc ≫ 1). In one regime we find that the temperature profile has a power-law form T ∝ r^{-(3/2)}, while in another it follows a more complicated dependence on radius. The latter case occurs when the luminosity is dominated either by viscous dissipation or by advection. For both cases, however, the radial velocity profiles have similar shapes. Finally, we show how these results can be used to explain observed properties of X-ray binaries. Subject headings: Black holes -accretion disks -X-ray binaries: general -Accretion, accretion disks",
        "watermark_text": "We present the results of our numerical simulations of accretion cone annuli in which radiation volume is analogous to liquid temperature , but not dominant . We see that for such disks there are two different regimes depending on whether or not the luminosity is dominated by advection ( i . e . , Ladv / Lvisc [UNK] 1 ) .In one regime we find that the temperature profile has a power - law form T [UNK] r ^ { - ( 3 / 2 ) } , while in another it takes a more complicated dependence on radius . The latter example happens when the luminosity is dominated either by viscous dissipation or by advection .For both cases , however , the radial speed profiles have parallel patterns . Finally , we show how these results can be used to explain observed properties of X - ray binaries .Subject headings : Black holes - accretion disks - X - ray binaries : general - Accretion , accretion disks",
        "ori-fast-z-score": -0.2773500981126146,
        "water-fast-z-score": 2.6605321596532185
    },
    {
        "original_text": "The book Nurturing Breakthroughs by James Watson and Peter Winkler is about how to create breakthroughs in science, technology, engineering or mathematics (STEM). The authors argue that the best way for scientists to make new discoveries is not through individual genius but rather by working together as teams on problems they are passionate about.  They also claim that it helps if you have an idea of what your problem looks like before you start solving it because this will help guide your research efforts. This article describes some of their ideas and provides examples of how these concepts can be applied to physics research. In his book Nurturing Breakdowns, James Watson argues that the most successful people who solve complex problems do so by working with others instead of trying to work alone. He says that when we work individually our brains tend to focus only on one aspect of the problem at hand which may lead us down dead ends while working collaboratively allows us to see all aspects of the problem simultaneously.",
        "watermark_text": "The book Nurturing Breakthroughs by James Watson and Peter Winkler is about how to create breakthroughs in science , technology , engineering or math ( STEM ) . The authors argue that the best method for researchers to make fresh findings is not through individual genius but rather by acting together as teams on problems they are loving about .They also claim that it assists if you have an idea of what your problem looks like before you start investigating it because this will assist guide your study efforts . This page describes some of their ideas and provides examples of how these concepts can be applied to physics studies .In his book Nurturing Breakdowns , James Watson says that the most talented people who solution complex challenges do so by working with others rather of trying to work alone . He said that when we study collectively our mind tend to reflect only on one element of the issue at hand which would guide us down dead ends while working collaboratively allows us to see all aspects of the issue simultaneously .",
        "ori-fast-z-score": -0.5773502691896257,
        "water-fast-z-score": 5.888972745734182
    },
    {
        "original_text": "We propose to probe the nature of dark energy by correlating the morphological properties of galaxies in the nearby universe (z < 0.1) as measured by the Sloan Digital Sky Survey (SDSS), with those at higher redshifts, z ~ 1, obtained from the Wilkinson Microwave Anisotropy Probe (WMAP). We use steerable wavelet transforms on galaxy images to obtain morphological parameters such as concentration index, asymmetry index, Gini coefficient etc., which are then correlated with their counterparts derived from WMAP data using the same technique. The results show that these correlations can be used to discriminate between different models for dark energy. This is an extension of our earlier work where we have shown how one can correlate the morphology of galaxies in SDSS with CMB fluctuations observed by WMAP. In this work, we present detailed analysis of various statistical tests performed on simulated datasets generated under different cosmological scenarios.",
        "watermark_text": "We suggest to probe the nature of dark energy by correlating the morphological properties of galaxies in the nearby universe ( z < 0 . 1 ) as measured by the Sloan Digital Sky Survey ( SDSS ) , with those at higher redshifts , z ~ 1 , obtained from the Wilkinson Microwave Anisotropy Probe ( WMAP ) . We use steerable wavelet transforms on star photographs to obtain morphological characteristics such as concentration index , asymmetry index , Gini coefficient etc . , which are then correlated with their counterparts obtained from WMAP information using the same technique .The results show that these correlations can be used to discriminate between various models for black energy . This is an extension of our earlier paper where we have shown how one can correlate the morphology of stars in SDSS with CMB fluctuations detected by WMAP .In this research , we present detailed analysis of several statistical tests administered on simulated datasets generated under various cosmological environments .",
        "ori-fast-z-score": 1.3363062095621219,
        "water-fast-z-score": 5.077963596336064
    },
    {
        "original_text": "The objective was to evaluate the potential use of Monoksa dorsiplana as an alternative biological control agent against Pseudopachymeria sp. (Bruchidae). The parasitoids were obtained in laboratory and released on P.sp. eggs laid by females collected at different locations in Brazil, Argentina and Paraguay. Egg parasitism ranged between 0.5 and 88% depending on location. Parasitized eggs hatched after 7 days under controlled conditions. Males emerged first followed by females. Female longevity varied according to temperature ranging from 11 to 21 days at 25 °C; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C. Females oviposited for up to three weeks when fed with honey solution. This species is considered highly suitable for mass production because it has high reproductive capacity and short life cycle. It can be used successfully in integrated pest management programs aimed at reducing damage caused by this insect pest.",
        "watermark_text": "The goal was to examine the possibilities application of Monoksa dorsiplana as an alternative bio control drug against Pseudopachymeria sp . ( Bruchidae ) .The parasitoids were obtained in laboratory and captured on P . sp . eggs laid by females collected at different places in Brazil , Argentina and Paraguay .Egg parasitism ranged between 0 . 5 and 88 % depending on location . Parasitized nests hatched after 7 days under regulated conditions .Males appeared first followed by females . Female longevity varied based to heat ranging from 11 to 21 weeks at 25 °C ; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C .Females oviposited for up to three weeks when fed with honey solution . This species is regarded highly suited for mass production because it has large sexual capacity and low life cycle .It can be used successfully in effective pest management projects designed at decreasing damage suffered by this insect pest .",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "We present an overview on supersymmetric grand unified theories (SUSY-GUT), their connection to neutrino masses via seesaw mechanisms as well as dark matter candidates in these models. We discuss how GUT scale physics can be probed at future colliders such as LHC or ILC. Finally we give some examples for specific realizations within SO(10) and E6 gauge groups. Supersymmetry is one of the most promising extensions beyond the Standard Model which addresses many open questions like the hierarchy problem between electroweak and Planck scales, unification of forces etc.. In addition it provides a natural candidate for cold dark matter -the lightest neutralino. The minimal supersymmetric standard model (MSSM) has been studied extensively over the last two decades but suffers from several shortcomings. One of them is that the MSSM does not provide any explanation why there are three generations of quarks and leptons with different quantum numbers. Grand Unified Theories (GUTs) address this issue by postulating that all known particles including those of the third generation belong to multiplets of larger symmetry group than SU(3)xSU(2)xU(1). This leads naturally to relations among coupling constants and fermion mass matrices. Another shortcoming of the MSSM is that it cannot explain small neutrino masses observed experimentally. However, if R-parity is broken then Majorana neutrinos may acquire tiny masses through see-saw mechanism. These new states could also contribute significantly to the relic density of dark matter.",
        "watermark_text": "We bring an overview on supersymmetric grand unified fields ( SUSY - GUT ) , their connection to neutrino masses via seesaw processes as well as dark matter candidates in these models . We discuss how GUT scale physics can be probed at possible colliders such as LHC or ILC .Finally we give some examples for specific realizations within SO ( 10 ) and E6 gauge bands . Supersymmetry is one of the most promising extensions beyond the Standard Model which answers many open questions like the hierarchy problem between electroweak and Planck scales , unification of forces etc . .In addition it gives a natural candidate for cold dark matter - the lightest neutralino . The minimal supersymmetric standard theory ( MSSM ) has been studied thoroughly over the last two decades but suffers from several shortcomings .One of them is that the MSSM does not offer any evidence why there are three generations of quarks and leptons with varying quantum numbers . Grand Unified Theories ( GUTs ) address this question by postulating that all known objects including those of the third generation belong to multiplets of bigger symmetry class than SU ( 3 ) xSU ( 2 ) xU ( 1 ) .This leads naturally to relations among coupling constants and fermion mass matrices . Another shortcoming of the MSSM is that it lacks explain little neutrino volumes discovered experimentally .However , if R - parity is shattered then Majorana neutrinos might acquire small masses through see - saw phenomenon . These new states could also contribute considerably to the relic volume of dark matter .",
        "ori-fast-z-score": 0.7258661863112977,
        "water-fast-z-score": 6.25846794771944
    },
    {
        "original_text": "The effect of silver and indium on the magnetic properties, electrical resistivity (ER) and Hall coefficient (R H ) has been investigated in La 2/3 Ca 1/3 Mn O 3 . The results show that ER decreases with increasing temperature for all samples while R H increases with decreasing temperature. It is found that both silver and indium doping decrease T C , increase J c and enhance pinning force density F p . Silver doped sample shows higher values of J c than indium doped one at low temperatures but lower value at high temperatures.  These results are explained by considering different effects of silver and indium ions on the microstructure as well as their influence on oxygen vacancies concentration. This work was supported by the National Natural Science Foundation of China under Grant No. 50571040. We would like to thank Prof. Y. M. Wu for his help during this research. Abstract: In this study we have prepared two series of La 2/3 Ca 1/3 MnO 3 :Ag and La 2/3 Ca 1/3 MnO3 :In polycrystalline composite materials using solid state reaction method. X-ray powder diffraction patterns confirm single phase formation without any impurity peaks. The structural parameters such as lattice constant, unit cell volume and bond length were calculated from XRD data. The dc magnetization measurements reveal that Curie temperature (Tc), critical current density (Jc) and pinning force density (Fp) decrease with increasing amount of silver or indium content.",
        "watermark_text": "The impact of silver and indium on the magnetic properties , thermal resistivity ( ER ) and Hall coefficient ( R H ) has been investigated in La 2 / 3 Ca 1 / 3 Mn O 3 . The results show that ER decreases with expanding temperature for all specimens while R H increases with varying temperature .It is found that both silver and indium doping change T C , enhance J c and enhance pinning power concentration F p . Silver doped specimen shows better levels of J c than indium doped one at low temperatures but smaller value at high temperatures .These data are explained by examining different impacts of silver and indium ions on the microstructure as also as their influence on oxygen vacancies density . This research was supported by the National Natural Science Foundation of China under Grant No .50571040.We would like to thank Prof. Y. M. Wu for his help during this research.Abstract : In this study we have formed two sequence of La 2 / 3 Ca 1 / 3 MnO 3 : Ag and La 2 / 3 Ca 1 / 3 MnO3 : In polycrystalline composite materials utilizing solid state process method . X - ray powder diffraction patterns indicate single phase form without any impurity peaks .The structural values such as structure constant , unit cell size and bond length were calculated from XRD information . The dc magnetization calculations reveal that Curie temperature ( Tc ) , vital current density ( Jc ) and pinning power concentration ( Fp ) decline with varying amount of silver or indium content .",
        "ori-fast-z-score": 0.8081220356417685,
        "water-fast-z-score": 7.677159338596802
    },
    {
        "original_text": "We study the properties of Bose-Einstein condensates (BECs) with an arbitrary number N of particles trapped by a harmonic oscillator and exposed to a disordered external potential. We show that, for any strength of disorder, there is always a finite fraction of atoms localized at each site of the lattice. The localization length decreases as the disorder increases but remains macroscopic even when the disorder becomes very large compared to the interatomic interaction energy. This result holds true both in one dimension and higher dimensions.  In particular we find that the critical disorder above which all states are localized scales like 1/N in 1D and 1/d in 2D and 3D where d is the spatial dimension. Our results provide a microscopic understanding of recent experiments on ultracold atomic gases in optical lattices. Introduction:-Recent experimental advances have made it possible to create quantum degenerate gases of bosons or fermions confined in periodic potentials  1  . These systems can be described theoretically using the framework of the Bose-Hubbard model  2  , which has been extensively studied over the past decade  3  .\nIn this work we consider the case of a gas of interacting bosons in a disordered potential. Disorder leads to Anderson localization  4  : eigenstates become exponentially localized around their initial position if the disorder exceeds some threshold value  5  . It was recently shown experimentally  6  that such a system exhibits a transition between extended Bloch-like states and localized Wannier-Stark ladders  7, 8  . However, these experiments were performed only in the weak-disorder regime, i.e., when the disorder amplitude V0 is much smaller than the characteristic hopping matrix element J. Here we investigate how the presence of interactions affects the physics of strongly disordered systems.",
        "watermark_text": "We explore the properties of Bose - Einstein condensates ( BECs ) with an arbitrary number N of atoms trapped by a harmonic oscillator and exposed to a disordered external potential . We see that , for any strength of disorder , there is usually a finite fraction of atoms confined at each site of the crystal .The localization width decreases as the disorder advances but continues macroscopic even when the disorder becomes very huge compared to the interatomic interaction power . This result holds true both in one dimension and upper dimensions .In particular we find that the fundamental disorder above which all states are localized scales like 1 / N in 1D and 1 / d in 2D and 3D where d is the spatial dimension . Our results present a microscopic understanding of recent experiments on ultracold atomic gases in optical lattices .Introduction : - Recent research developments have enabled it able to create quantum degenerate gases of bosons or fermions localized in periodic potentials 1 . These systems can be described theoretically utilizing the framework of the Bose - Hubbard theory 2 , which has been heavily explored over the previous decade 3 .In this research we study the case of a gas of interacting bosons in a disordered potential . Disorder leads to Anderson localization 4 : eigenstates grow exponentially localized around their early position if the disorder approaches some threshold parameter 5 .It was recently shown experimentally 6 that such a system displays a shift between advanced Bloch - like states and localized Wannier - Stark ladders 7 , 8 . However , these experiments were performed only in the weak - disturbance regime , i . e . , when the disorder amplitude V0 is much smaller than the typical hopping matrix element J .Here we investigate how the presence of interactions affects the physics of highly disordered systems .",
        "ori-fast-z-score": 0.09166984970282113,
        "water-fast-z-score": 6.937819061732104
    },
    {
        "original_text": "We study the statistical properties of surface fluctuations for different values of the lateral size L and height H of the system, using numerical simulations on square lattices with periodic boundary conditions. We find that the probability density function (PDF) of the local slope angle θ is well described by an exponential decay at large angles, while it displays power-law tails at small slopes. The crossover between these two regimes occurs around θ = 0.5π. In addition to this behavior, we observe that the PDFs are strongly dependent upon both L and H. This dependence can be explained as finite-size effects: when L or H becomes smaller than some characteristic length scale, the PDFs become broader due to the presence of more rare events. Finally, we show how our results compare favorably with experimental data obtained from scanning tunneling microscopy measurements performed on Si(111). PACS numbers: 68.35.Bs",
        "watermark_text": "We research the statistical characteristics of fluid fluctuations for different values of the longitudinal length L and elevation H of the system , using numerical simulations on square lattices with periodic border conditions . We see that the probability density function ( PDF ) of the local slope angle θ is well described by an exponential decay at large angles , while it displays power - law tails at small elevations .The crossover between these two regimes occurs around θ = 0 . 5π . In addition to this behavior , we find that the PDFs are strongly dependent upon both L and H . This reliance can be described as finite - length effects : when L or H becomes lower than some characteristic length range , the PDFs get broader owing to the presence of more unusual events .Finally , we prove how our findings compare favorably with experimental evidence derived from scanning tunneling microscopy observations performed on Si ( 111 ) . PACS codes : 68 . 35 . Bs",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 5.658135095031152
    },
    {
        "original_text": "The aim of this book is to provide an overview on the state-of-the-art in on-line condition monitoring and fault diagnosis for industrial processes, with special emphasis on computational intelligence techniques such as neural networks (NNs), fuzzy logic systems (FLS) or evolutionary algorithms (EAs). The book covers both theoretical aspects and practical applications of these methods. It also discusses some recent advances in intelligent sensor technologies that are essential for successful implementation of on-line condition monitoring schemes. This book will be useful not only for researchers but also for engineers who want to apply computational intelligence techniques into their own research work. Contents include:  Chapter 1: Introduction to On-line Condition Monitoring.  Chapter 2: Intelligent Sensors for On-line Condition Monitoring.  Chapters 3-7: Neural Networks for Fault Diagnosis.  Chapters 8-10: Fuzzy Logic Systems for Fault Diagnosis.   Chapters 11-13: Evolutionary Algorithms for Fault Diagnosis.   ...",
        "watermark_text": "The goal of this paper is to provide an overview on the state - of - the - art in on - line condition monitoring and failure detection for industrial systems , with special emphasis on computational intelligence techniques such as neural systems ( NNs ) , fuzzy logic systems ( FLS ) or ecological computers ( EAs ) . The text encompasses both theoretical components and useful users of these algorithms .It additionally outlines some latest advances in intelligent detection systems that are essential for successful implementation of on - line condition monitoring schemes . This book will be valuable not only for researchers but also for designers who desire to apply computational intelligence techniques into their own research effort .Contents comprise : Chapter 1 : Introduction to On - line Condition Monitoring . Chapter 2 : Intelligent Sensors for On - line Condition Monitoring .Chapters 3-7: Neural Networks for Fault Diagnosis.Chapters 8-10: Fuzzy Logic Systems for Fault Diagnosis.Chapters 11-13: Evolutionary Algorithms for Fault Diagnosis....",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 5.75
    },
    {
        "original_text": "We present results on interface widths in liquid-gas systems, obtained by molecular dynamics simulations with different potentials. We find that the potential should be able to reproduce both bulk properties (e.g., density) as well as surface tension at coexistence conditions simultaneously. The latter requirement is not fulfilled by standard Lennard-Jones or hard-sphere models. In order to overcome this problem we propose an alternative model which reproduces all relevant physical quantities within their experimental uncertainty. This new model can also be used to study other phenomena like capillary waves. \n \n Introduction \n \n Interfaces are ubiquitous in nature and play important roles in many processes ranging from phase separation  1  over wetting  2  to crystal growth  3  . They have been studied extensively using computer simulations  4  , but it has proven difficult to obtain reliable data due to finite size effects  5  . These arise because interfaces are typically only one particle thick  6  so that they cannot be simulated directly. Instead, periodic boundary conditions must be applied  7, 8  leading to artificial interactions between images of the same interface  9  . As a result, the measured interfacial width depends strongly on system size  10  .\n \nIn recent years there has been considerable progress towards understanding these finite-size effects  11  . It was shown that the dependence of the interfacial width w on the linear dimension L of the system follows a power law  12  :",
        "watermark_text": "We report findings on interface widths in liquid - gas systems , obtained by molecular mechanics simulations with various potentials . We see that the potential should be possible to capture both bulk properties ( e . g . , temperature ) as well as surface tension at coexistence situations simultaneously .The latter requirement is not satisfied by traditional Lennard - Jones or hard - sphere theories . In order to overcome this situation we undertake an additional model which reproduces all relevant physical components within their observation uncertainty .This new model can also be used to study other processes like capillary currents . Introduction Interfaces are ubiquitous in nature and play essential roles in multiple processes ranging from phase splitting 1 over wetting 2 to crystal growth 3 .They have been studied frequently using computer simulations 4 , but it has proven impossible to obtain reliable data due to finite diameter effects 5 . These occur because interfaces are typically only one particle thick 6 so that they cannot be simulated directly .Instead , periodic border conditions must be applied 7 , 8 causing to artificial interactions between images of the same interface 9 . As a consequently , the measured interfacial width depends strongly on system width 10 .In recent years there has been substantial advances towards studying these finite - length effects 11 . It was shown that the dependence of the interfacial width w on the linear dimension L of the system follows a power law 12 :",
        "ori-fast-z-score": 0.09245003270420485,
        "water-fast-z-score": 6.1941521911817246
    },
    {
        "original_text": "The discovery of the first X-ray pulsar, Scorpius X1 (Sco-X1), by Giacconi et al. (1962) opened up an exciting new field for astrophysics and led to the development of many important concepts such as accretion disks around compact objects.  The study of these systems has been revolutionized with the launch of Chandra and XMM-Newton observatories which have allowed us to probe their physical properties on unprecedented spatial scales.   In this review we will discuss some recent results obtained using these satellites that shed light on how neutron stars are formed and evolve within low-mass binary systems. We will also present our current understanding of the physics behind the formation of relativistic jets observed in several classes of X-ray binaries. Finally, we will briefly describe the prospects offered by future missions like XEUS or Constellation-X for studying these fascinating sources. Keywords: Accretion disk - Compact object - Relativistic jet -X-ray binary",
        "watermark_text": "The observation of the first X - ray pulsar , Scorpius X1 ( Sco - X1 ) , by Giacconi et al . ( 1962 ) opened up an exciting new area for astrophysics and led to the development of several important concepts such as accretion disks around compact galaxies .The investigation of these systems has been revolutionized with the launch of Chandra and XMM - Newton observatories which have permitted us to probe their physical properties on unprecedented spatial scales . In this review we will explore some latest findings obtained using these satellites that shed light on how neutron galaxies are created and evolve within low - weight binary complexes .We will also discuss our latest understanding of the physics behind the formation of relativistic jets discovered in multiple types of X - ray binaries . Finally , we will briefly outline the possibilities offered by future flights like XEUS or Constellation - X for studying these fascinating sources .Keywords : Accretion wheel - Compact object - Relativistic jet - X - ray binary",
        "ori-fast-z-score": 0.48507125007266594,
        "water-fast-z-score": 5.2532861073211246
    },
    {
        "original_text": "We have performed first-principles calculations to investigate the characteristics of phonon transmission across an epitaxial interface between Si and Ge, which are important for thermoelectric applications. We found that the phonon transmission is strongly suppressed at low frequencies due to the mismatch in acoustic impedance between two materials. The suppression becomes more significant as the thickness of Ge layer decreases. In addition, we observed that the phonon transmission exhibits strong anisotropy with respect to incident angle. These results suggest that it may be possible to control thermal transport by tuning the structure of epitaxial interfaces. Epitaxial interfaces play crucial roles in determining physical properties such as electrical conductivity  1  , optical reflectivity  2  , mechanical strength  3  , and thermal conductivity  4  . For example, recent studies on superlattices show that the thermal conductance can be reduced significantly compared to bulk values  5, 6  .\nIn this work, we focus on phonons because they dominate heat conduction in solids  7, 8  . Phonon scattering at epitaxial interfaces has been studied extensively using molecular dynamics (MD) simulations  9  or kinetic theory  10  . However, these approaches cannot provide detailed information about phonon transmission across interfaces since they do not take into account atomic interactions explicitly  11  . On the other hand, density functional theory (DFT), which describes electronic states based on quantum mechanics  12  , allows us to calculate phonon transmission coefficients directly  13  . Therefore, DFT-based methods are suitable for investigating phonon transmission across epi-",
        "watermark_text": "We have done first - principles measurements to examine the properties of phonon communication across an epitaxial connection between Si and Ge , which are important for thermoelectric use . We identified that the phonon communication is strongly restrained at low frequencies owing to the mismatch in sound impedance between two materials .The suppression gets more considerable as the height of Ge coating decreases . In addition , we reported that the phonon propagation displays good anisotropy with regard to incident angle .These data suggest that it could be possible to affect heat transport by tuning the structure of epitaxial interfaces . Epitaxial interfaces play crucial roles in determining physical properties such as mechanical conductivity 1 , optical reflectivity 2 , thermal strength 3 , and thermal conductivity 4 .For instance , recent studies on superlattices indicate that the thermal conductance can be reduced greatly compared to bulk values 5 , 6 . In this research , we focus on phonons because they govern heat conduction in solids 7 , 8 .Phonon splitting at epitaxial interfaces has been studied thoroughly using chemical mechanics ( MD ) simulations 9 or kinetic theory 10 . However , these perspectives cannot offer comprehensive information about phonon communication across interfaces since they do not take into consideration atomic interactions explicitly 11 .On the other hand , density functional theory ( DFT ) , which explains electronic states based on quantum mechanics 12 , allows us to estimate phonon communication equations directly 13 . Therefore , DFT - based methods are suitable for investigating phonon communication across epi -",
        "ori-fast-z-score": -0.7559289460184544,
        "water-fast-z-score": 7.878011364745742
    },
    {
        "original_text": "We present an exact expression for the pressure tensor of a fluid confined by any external potential, which is valid at all temperatures. The result can be obtained as a special case of the virial expansion for the grand canonical partition function. We show that this expression reduces to known results when applied to specific potentials such as harmonic traps or periodic lattices. Finally we apply our general formula to calculate the equation of state of a gas of fermions with attractive interactions in two dimensions. In particular, we find that the system undergoes a phase transition into a superfluid state below some critical temperature Tc. This work was supported by NSF grant PHY-0456747 (M.A.) . \nI. INTRODUCTORY REMARK\nThe thermodynamic properties of many-body systems are often studied using statistical mechanics methods  1  , where one considers ensembles of particles interacting via a given potential energy V(r). For example, if the particles interact through short-range forces only, then it is possible to derive expressions for various physical quantities like density profiles  2  , compressibility  3  , heat capacity  4  , etc., starting from the microscopic definition of entropy S = -k B ln Z, where k B is Boltzmann s constant and Z is the partition function defined as:",
        "watermark_text": "We introduce an precise representation for the pressure tensor of a fluid confined by any external potential , which is valid at all temperatures . The result can be obtained as a special case of the virial expansion for the grand canonical partition function .We see that this formula reduces to known results when applied to unique potentials such as vibration trapping or periodic lattices . Finally we apply our general formula to estimate the equation of state of a gas of fermions with interesting interactions in two dimensions .In particular , we find that the system undergoes a phase shift into a superfluid state below some significant heat Tc . This research was supported by NSF grant PHY - 0456747 ( M . A . ).I.INTRODUCTORY REMARK The thermodynamic properties of several - bodies systems are often researched employing statistical mechanics methods 1 , where one studies ensembles of molecules evolving via a given potential energy V ( r ) . For instance , if the atoms interact through short - range forces only , then it is possible to derive expressions for various mechanical parameters like density profiles 2 , compressibility 3 , temperature strength 4 , etc . , beginning from the microscopic definition of entropy S = - k B ln Z , where k B is Boltzmann s constant and Z is the partition function characterized as :",
        "ori-fast-z-score": 0.8251369970070347,
        "water-fast-z-score": 6.325405337855594
    },
    {
        "original_text": "We study the dependence of galaxy isophotal structure parameters, such as the Sersic index n, effective radius Re, axis ratio q, position angle PA, and surface brightness SB, on environment (local density) and nuclear activity (AGN luminosity). We use a sample of early-type galaxies selected by their colors from the Sloan Digital Sky Survey Data Release 6 (SDSS DR6), which contains about 1 million objects with spectroscopic redshifts between 0 < z < 0.3. The local density around each galaxy was estimated using its nearest neighbors within a projected distance rp = 20h-1 Mpc and a velocity difference |v| = 1000 km s-1. For our analysis we used only those galaxies that have no nearby companions brighter than them by more than one magnitude to avoid any possible contamination due to tidal interactions or mergers. \n \n In order to investigate how these structural properties depend on environment and nuclear activity, we divided our sample into four different subsamples based on the values of local density and AGN luminosity: low-density/low-luminosity active galactic nuclei (LLAGNs), high-density/high-luminosity active Galactic Nuclei (HLAGNs), low-density/high-luminous inactive galaxies (LHIGGs), and high-density/low-luminous inactive galaxies(HLIGGs). \n \n Our results show that LLAGNs are generally rounder and less concentrated compared to HLAGNs. This suggests that LLAGNs may be undergoing morphological transformations driven by environmental effects and/or internal processes associated with black hole growth. On average, LHIGGs appear to be rounder but slightly less concentrated than HLIGGs. However, there appears to be an overlap among all four samples for most of the structural parameters considered here.",
        "watermark_text": "We research the dependence of galaxy isophotal shape parameters , such as the Sersic index h , effective radius Re , axis proportion r , point angle PA , and surface brightness SB , on climate ( local concentration ) and nuclear activity ( AGN luminosity ) . We use a sample of early - class stars selected by their colors from the Sloan Digital Sky Survey Data Release 6 ( SDSS DR6 ) , which contains about 1 million bodies with spectroscopic redshifts between 0 < z < 0 . 3 .The local concentration around each galaxy was calculated using its closest neighbors within a projected diameter rp = 20h - 1 Mpc and a speed difference | v | = 1000 cm s - 1 . For our analysis we using only those galaxies that have no nearby friends brighter than them by more than one magnitude to eliminate any likely infection due to tidal interactions or mergers .In order to investigate how these structural properties depend on environment and nuclear activity , we divided our sample into four different subsamples based on the values of local density and AGN luminosity : low - density / low - luminosity active galactic nuclei ( LLAGNs ) , high - density / high - luminosity active Galactic Nuclei ( HLAGNs ) , low - density / high - luminous inactive galaxies ( LHIGGs ) , and high - density / low - luminous inactive galaxies ( HLIGGs ) . Our results show that LLAGNs are generally rounder and less concentrated compared to HLAGNs .This implies that LLAGNs might be experiencing morphological transformations motivated by ecological effects and / or internal mechanisms associated with black hole growth . On average , LHIGGs occur to be rounder but little less concentrated than HLIGGs .However , there seems to be an interchange among all four samples for most of the structural values discussed here .",
        "ori-fast-z-score": -1.6431676725154982,
        "water-fast-z-score": 5.363636363636363
    },
    {
        "original_text": "We present parallax measurements for four short-period (P orb < 80 min) AM CVn stars using the Fine Guidance Sensor on board HST, which are accurate to better than 1% in distance. We find that all systems have distances consistent with their being located within 20 pc of Earth. The derived absolute magnitudes range between MV = 12.5 and 14.1 mag, corresponding to luminosities of 1030 - 1600 L⊙ . These values are significantly brighter than those predicted by theoretical models of these objects, indicating either an underestimate of the mass transfer rates or an overestimate of the white dwarf masses. In addition we use our new parallaxes together with previously published data to derive improved estimates of the orbital periods and component masses for three of the targets studied here. Finally, we discuss how our results can be used to test current evolutionary scenarios for this class of binary system.",
        "watermark_text": "We present parallax observations for four short - duration ( P orb < 80 min ) AM CVn stars using the Fine Guidance Sensor on board HST , which are accurate to good than 1 % in distance . We see that all systems have distances consistent with their being located within 20 pc of Earth .The derived absolute magnitudes range between MV = 12 . 5 and 14 . 1 mag , corresponding to luminosities of 1030 - 1600 [UNK] . These values are significantly brighter than those predicted by theoretical models of these objects , indicating either an underestimate of the mass transfer rates or an overestimate of the white dwarf masses .In addition we utilize our new parallaxes together with former reported information to derive improved models of the orbital periods and component masses for three of the targets examined here . Finally , we explain how our findings can be used to test recent evolutionary scenarios for this class of binary system .",
        "ori-fast-z-score": 0.254000254000381,
        "water-fast-z-score": 3.556003556005334
    },
    {
        "original_text": "We introduce the concept of generalized conditional random fields (GCRFs) and show how they can be used to model arbitrary probability distributions over structured data sets, such as sequences or trees.  We present an efficient algorithm for learning GCRF parameters using gradient descent on the log-likelihood objective function.   Finally we demonstrate that our approach is able to learn accurate models for several challenging sequence labeling tasks including part-of-speech tagging in natural language processing and protein secondary structure prediction in bioinformatics. Conditional Random Fields (CRFs) (Lafferty et al., 2001 ) are undirected graphical models which have been successfully applied to many problems involving sequential data, e.g. (Sha & Pereira, 2003) . In this work, we propose Generalized Conditional Random Fields (GCRFs), a generalization of CRFs which allows us to represent any distribution over structured data sets like sequences or trees. The key idea behind GCRFs is to use a set of latent variables to capture dependencies between different parts of the input space. This enables us to efficiently compute the partition function required by standard CRFs with dynamic programming techniques. Furthermore, it also makes it possible to train GCRFs using gradient-based methods similar to those employed for Maximum Entropy Markov Models (MEMMs). To evaluate the performance of our method, we apply it to two important applications: part-of-speech taggin",
        "watermark_text": "We introduce the idea of generalized conditional random fields ( GCRFs ) and explain how they can be used to model arbitrary likelihood distributions over structured data sets , such as sequences or trees . We introduce an efficient algorithm for learning GCRF variables using gradient descent on the log - likelihood objective function .Finally we prove that our approach is ability to acquire precise models for numerous challenging gene labeling challenges including whole - of - voice tagging in natural language processing and protein secondary structure prediction in bioinformatics . Conditional Random Fields ( CRFs ) ( Lafferty et al . , 2001 ) are undirected numerical models which have been successfully applied to many difficulties involving sequential data , e . g .( Sha & Pereira , 2003 ) . In this research , we propose Generalized Conditional Random Fields ( GCRFs ) , a generalization of CRFs which allows us to model any distribution over structured data sets like sequences or trees .The main idea behind GCRFs is to use a setting of latent variables to capture dependencies between various parts of the input space . This enables us to easily compute the partition function required by traditional CRFs with dynamic programming tools .Furthermore , it also makes it able to train GCRFs using gradient - based methods similar to those utilized for Maximum Entropy Markov Models ( MEMMs ) . To assess the performance of our technique , we apply it to two essential applications : whole - of - voice taggin",
        "ori-fast-z-score": -0.4833682445228318,
        "water-fast-z-score": 6.735753140545634
    },
    {
        "original_text": "We present new radial velocity measurements for the short-period binary system WZ Sge, which show that its orbital period is decreasing at an average rate of  _ P = -1.3 x 10^(-7) d/s.  We use these data to derive dynamical mass estimates for both components and find M_1 = 0.85 ± 0.05M_sun and M_2 = 0.65 ± 0.04M_sun. The primary star has evolved off the main sequence but still retains some hydrogen in its atmosphere; it is therefore classified as a subdwarf B (sdB). Our results are consistent with previous determinations based on photometric observations. However, our analysis provides more accurate values because we have used higher quality spectroscopic data than were available previously. In addition, we have been able to determine the individual masses rather than just their ratio. This work was supported by NASA grant NAG5-13523.",
        "watermark_text": "We present new radial speed measurements for the short - period binary system WZ Sge , which show that its orbital period is decreasing at an average rate of _ P = - 1 . 3 x 10 ^ ( - 7 ) d / s . We use these information to derive dynamical mass estimates for both components and find M _ 1 = 0 . 85 ± 0 . 05M _ sun and M _ 2 = 0 . 65 ± 0 . 04M _ sun .The main star has evolution off the main sequence but still retains some hydrogen in its atmosphere ; it is consequently listed as a subdwarf B ( sdB ) . Our results are compatible with previous determinations based on photometric studies .However , our analysis provides more accurate figures because we have utilized higher reliability spectroscopic data than were offered previously . In addition , we have been able to predict the individual masses rather than just their ratio .This project was supported by NASA gift NAG5 - 13523 .",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "The intramolecular structure of polymers is studied by means of the molecular dynamics simulation method for several model systems with different chain lengths, degrees of branching, and types of interactions between monomers. It has been found that the intramolecular correlation function can be represented as a sum of two terms corresponding to short- and long-range contributions. The latter term describes the contribution of segments separated by distances larger than the average distance between neighboring chains. This term depends on the number density of chains and their length. In addition, it was shown that this term decreases exponentially at large separations. The dependence of the first four moments of the segmental size distribution on temperature and pressure are calculated using the results obtained previously. These dependences were compared with experimental data available in literature. Good agreement between theory and experiment is observed. \n \n Keywords: Polymer melt, Intramolecular structure, Correlation functions, Segmental size distribution",
        "watermark_text": "The intramolecular structure of polymers is studied by means of the molecular dynamics simulation method for numerous model models with various chain lengths , degrees of branching , and types of interactions between monomers . It has been shown that the intramolecular relationship value can be described as a sum of two terms corresponding to short - and long - range contributions .The latter term describes the contribution of segments apart by distances bigger than the average distance between neighboring lines . This term relies on the number density of chains and their length .In addition , it was shown that this term drops exponentially at large separations . The dependence of the first four moments of the segmental size distribution on temperature and pressure are measured using the results derived earlier .These dependences were compared with observation information available in literature . Good agreement between theoretical and experiment is observed .Keywords : Polymer melt , Intramolecular structure , Correlation properties , Segmental size distribution",
        "ori-fast-z-score": 0.7977240352174656,
        "water-fast-z-score": 4.817730411281796
    },
    {
        "original_text": "We present new results on the nature and geometry of the compact object in the gamma-ray binary system LS I +61 303, based on observations with the INTEGRAL satellite. We find that the source is variable at all wavelengths studied here (radio to hard X-rays), but shows no evidence for orbital modulation or eclipses. The X-ray spectrum can be described by either a power law model or thermal bremsstrahlung emission; both are consistent with previous studies. In addition we report the detection of pulsations in the radio band which have been previously reported only once before. These pulsations show up as periodic intensity variations in our data set, and their periodicity has been confirmed using two independent methods. Using these results together with those obtained from optical photometry and spectroscopy, we conclude that this source most likely contains a neutron star accreting matter from its companion Be-star via Roche lobe overflow.",
        "watermark_text": "We report new data on the nature and morphology of the compact body in the gamma - ray binary system LS I + 61 303 , based on observations with the INTEGRAL satellite . We see that the origin is varying at all wavelengths explored here ( radio to soft X - radiation ) , but gives no evidence for orbital modulation or eclipses .The X - ray signal can be described by either a power law description or heating bremsstrahlung emission ; both are compatible with previous research . In addition we study the observation of pulsations in the radio band which have been previously reported only once before .These pulsations appear up as periodic intensity variations in our information pool , and their periodicity has been confirmed using two independent methods . Using these results together with those acquired from optical photometry and spectroscopy , we determine that this source most likely contains a neutron star accreting matter from its companion Be - star via Roche lobe overflow .",
        "ori-fast-z-score": -0.36650833306891567,
        "water-fast-z-score": 5.2532861073211246
    },
    {
        "original_text": "We study the dynamics of an open system, which is composed by a two-level atom interacting with a single-mode cavity field and driven by a classical laser source. We show that this simple model can be used to describe the behavior of a quantum information processor (QIP) based on trapped ions or atoms coupled to optical cavities. In particular we find signatures of decoherence in QIPs due to spontaneous emission noise. The results are obtained using exact numerical solutions for the master equation describing our model. Quantum information processing has been proposed as one possible application of quantum mechanics  1  . A number of experimental realizations have already been achieved  2  , but it remains unclear how practical these devices will become  3  .\nIn order to understand better what kind of problems may arise when implementing such schemes experimentally, it would be useful to develop models that allow us to investigate the effects of different types of errors  4  . Here we consider a very simple model consisting of a two-level atom interacting resonantly with a single mode of an electromagnetic field inside a cavity  5  . This system could represent either a trapped ion  6  or an atom coupled to an optical cavity  7, 8  . It is well known that if there were no losses present then the state of the system at any time t > 0 would simply be given by |ψ(t) = e −iωat/2 cos ω c t + θ(0) / √ 2 where ω a and ω c are respectively the atomic and cavity frequencies  9  . However, in practice both the atom-cavity coupling strength g and the decay rate κ associated with the cavity field are finite so that the evolution of the system becomes more complicated  10  .",
        "watermark_text": "We explore the dynamics of an open network , which is composed by a two - level atom interacting with a single - mode cavity field and driven by a traditional beam source . We see that this straightforward model can be used to explain the response of a quantum information processor ( QIP ) based on trapped ions or atoms connected to laser cavities .In particular we find signatures of decoherence in QIPs due to spontaneous emission interference . The results are derived using correct mathematical solutions for the master equation representing our model .Quantum knowledge processing has been proposed as one possible application of quantum mechanics 1 . A variety of research realizations have already been achieved 2 , but it remains unsure how practical these machines will become 3 .In order to explain better what sort of problems might arise when executing such schemes experimentally , it would be beneficial to develop models that enable us to examine the effects of different kinds of errors 4 . Here we study a very simple study consisting of a two - level atom interacting resonantly with a single mode of an electromagnetic field inside a cavity 5 .This system could represent either a trapped ion 6 or an element coupled to an optical cavity 7 , 8 . It is well established that if there were no losses present then the state of the system at any time t > 0 would merely be described by | ψ ( t ) = e −iωat / 2 cos ω c t + θ ( 0 ) / √ 2 where α a and ω c are respectively the atomic and cavity frequencies 9 .However , in practice both the atom - cavity coupling strength g and the decay rate κ involved with the cavity field are finite so that the evolution of the system gets more complicated 10 .",
        "ori-fast-z-score": -0.25630729731502827,
        "water-fast-z-score": 6.46954963376649
    },
    {
        "original_text": "We study the unitarity properties of an effective field theory describing the interactions between gluons and quarks in QCD at high energies, where perturbation theory is not applicable anymore. The model we consider consists of a gauge-invariant action containing both massive and massless fields. We show that this model can be written as a sum over Feynman diagrams which are all unitary individually if certain conditions on the parameters appearing in the Lagrangian density are satisfied. In particular, it turns out that the masses of the particles involved must satisfy some relations to ensure unitarity. Finally, we discuss how these results could be used for phenomenological applications. PACS numbers: 11.10.Wx, 12.38.Qk, 13 .60.Hb \nI. INTRODUCTORY REMAR K S\nThe Standard Model (SM) describes successfully most experimental data available today  1  , but its validity has been tested only up to energies of about 1 TeV  2  . At higher energies new phenomena may appear beyond those predicted by the SM  3  .\nIn order to describe such effects one usually considers extensions of the SM  4  or models based on effective theories  5  . Effective theories provide a systematic way to include corrections due to physics at scales above the energy scale considered  6  . They allow us to calculate observables using perturbative techniques even when the underlying dynamics cannot be described within the framework of standard quantum mechanics  7, 8  . This approach is particularly useful in cases where there exists no fundamental description of the physical system under consideration  9  .\nOne example of an effective theory is Quantum Chromodynamics (QCD), the theory of strong interactions  10  . It predicts the existence of hadrons made of quarks and gluons  11  . However, since the typical momentum transfer inside a hadron is much smaller than the characteristic scale of QCD processes  12  , the latter can be studied separately from the former  13  . For instance, the production of jets  14  and heavy flavors  15  in high-energy collisions can be calculated using perturbative methods  16  . On the other hand, the interaction among partons  17 ",
        "watermark_text": "We explore the unitarity properties of an efficient field model explaining the interactions between gluons and quarks in QCD at high energies , where perturbation theory is not applicable nowadays . The model we treat consists of a gauge - invariant action incorporating both giant and massless fields .We see that this description can be written as a sum over Feynman diagrams which are all unitary individually if certain conditions on the variables appearing in the Lagrangian density are fulfilled . In particular , it turns out that the masses of the interactions involved must satisfy some relations to ensure unitarity .Finally , we explain how these results could be used for phenomenological purposes . PACS codes : 11 . 10 . Wx , 12 . 38 . Qk , 13 . 60 . Hb I .INTRODUCTORY REMAR K S The Standard Model ( SM ) presents successfully most empirical data available today 1 , but its authenticity has been tested only up to energies of about 1 TeV 2 . At higher energies new concepts might appear beyond those predicted by the SM 3 .In order to explain such effects one usually uses extensions of the SM 4 or models built on effective models 5 . Effective models seek a comprehensive way to consider corrections due to physics at scales above the energy scale discussed 6 .They allow us to estimate observables using perturbative methodology even when the fundamental dynamics cannot be described within the framework of standard quantum mechanics 7 , 8 . This method is especially suitable in cases where there exists no basic description of the physical system under consideration 9 .One example of an effective theory is Quantum Chromodynamics ( QCD ) , the model of strong interactions 10 . It predicts the existence of hadrons made of quarks and gluons 11 .However , since the typical velocity transfer inside a hadron is much smaller than the typical scale of QCD processes 12 , the latter can be analyzed separately from the former 13 . For instance , the production of jets 14 and dark flavors 15 in high - energy collisions can be determined use perturbative methods 16 .On the other hand , the interaction among partons 17",
        "ori-fast-z-score": -0.08481889296799709,
        "water-fast-z-score": 7.7754191435023525
    },
    {
        "original_text": "We present an exact expression for the pair correlation functions in terms of a free energy functional, valid both above and below the nematic transition temperature T_N. The functional is obtained by minimizing the grand potential with respect to all possible orientations of the director field n(r). We show that this approach leads to results which are consistent with those obtained using Onsager s theory at high temperatures (T_T>T_N), but also provides new insight into the structure of the nematic phase near its critical point. In particular we find that the orientational order parameter S exhibits a non-monotonic behavior as a function of density, while the positional correlations remain short ranged throughout the entire range of densities studied here. Finally, our analysis shows that the nematic phase can be viewed as a superposition of two different liquid phases characterized by distinct values of the orientational order parameter. PACS numbers: 64.70.Pq",
        "watermark_text": "We present an precise representation for the pair correlation functions in terms of a free energy functional , valid both above and below the nematic transition temperature T _ N . The functional is found by minimizing the grand potential with regard to all possible orientations of the director field n ( r ) .We see that this methodology leads to findings which are compatible with those achieved using Onsager s principle at high heating ( T _ T > T _ N ) , but also provides new insight into the formation of the nematic phase near its critical position . In particular we find that the orientational order parameter S exhibits a non - monotonic activity as a function of density , while the positional correlations remain small ranged throughout the entire range of densities explored here .Finally , our analysis shows that the nematic phase can be viewed as a superposition of two different fluid stages characterized by separate values of the orientational order parameter . PACS codes : 64 . 70 . Pq",
        "ori-fast-z-score": 0.3611575592573076,
        "water-fast-z-score": 4.780914437337574
    },
    {
        "original_text": "We study the dynamics of three agent games with two strategies each, where agents are connected by an underlying network and play pairwise interactions according to their strategy choices. We show that for any initial state there is always at least one absorbing state in which all agents have the same strategy choice. In addition we find that if the number of nodes with either strategy exceeds 1 then this state can be reached within finite time. Finally, we provide bounds on how fast such convergence occurs as well as conditions under which it will occur exponentially quickly. The results presented here generalize previous work done on two-agent evolutionary games to multi-agent systems. Evolutionary game theory has been used extensively over the past decade to model competition between different species or individuals competing for limited resources  1  . A common approach taken when modeling these types of problems is to consider a population consisting of many interacting agents who choose among several possible strategies  2  , and then use mathematical tools developed in statistical physics  3  to analyze the resulting system behavior  4  .\nIn recent years researchers have begun studying more complex models involving multiple populations  5  , spatial structure  6  , and heterogeneous environments  7, 8  . However, most existing research focuses only on two-player games  9  , while less attention has been paid to multi-agent systems  10  . Here we present new results showing that even simple multi-agent systems exhibit richer dynamical behaviors than previously thought  11  .",
        "watermark_text": "We explore the dynamics of three agent games with two strategies each , where agents are connected by an underlying network and play pairwise relationships according to their strategy choices . We see that for any initial state there is usually at least one absorbing state in which all agents have the same strategy selection .In addition we find that if the number of nodes with either strategy approaches 1 then this state can be reached within finite period . Finally , we provide bounds on how rapid such convergence occurs as well as conditions under which it will occur exponentially rapidly .The results presented here generalize past work done on two - agent evolutionary games to multi - agent systems . Evolutionary game theory has been used heavily over the previous decade to model competition between various populations or individuals competing for limited supplies 1 .A typical approach took when solving these kinds of problems is to consider a population consisting of several interacting agents who decide among various possible strategies 2 , and then use numerical tools developed in statistical physics 3 to analyze the resulting system interaction 4 . In recent years investigators have begun investigating more sophisticated models involving several populations 5 , temporal formation 6 , and heterogeneous environments 7 , 8 .However , most existing study emphasis only on two - player players 9 , while worse attention has been paid to multi - agent systems 10 . Here we present new data demonstrating that even basic multi - agent systems exhibit richer dynamical traits than previously thought 11 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.789028582272215
    },
    {
        "original_text": "We present an algorithm for the numerical evaluation of Feynman diagrams with arbitrary numbers of external particles and internal loops, which is based on the concept of  partonic subdiagrams . The method allows to perform calculations in QCD beyond leading order accuracy without any approximations or assumptions about the kinematics of the process under consideration. We demonstrate its applicability by calculating the next-to-leading-order corrections to the production cross section of heavy quarks at hadron colliders. In this talk we will discuss how one can gain analytic control over parton showers using the concept of  partons  as fundamental degrees of freedom. This approach has been developed recently within the framework of Soft-Collinear Effective Theory (SCET)  1  . It provides a systematic way to resum large logarithms associated with collinear splittings into multiple jets  2  , thereby improving our understanding of jet physics  3  .\nThe basic idea behind SCET is that physical observables are described by matrix elements involving soft and/or collinear fields only  4  . These fields have nontrivial transformation properties under boosts along the beam axis  5  . They allow us to separate hard interactions from soft radiation  6  . As a result, it becomes possible to systematically factorize contributions to scattering amplitudes into  hard functions  describing short-distance dynamics  7, 8  and  semi-hard functions  encoding information about the emission of soft gluons  9  .",
        "watermark_text": "We present an algorithm for the numerical identification of Feynman diagrams with arbitrary numbers of external particles and internal loops , which is based on the idea of partonic subdiagrams . The method enables to conduct measurements in QCD beyond trailing order accuracy without any approximations or assumptions about the kinematics of the process under consideration .We test its applicability by calculating the second - to - leading - order corrections to the production cross section of large quarks at hadron colliders . In this talk we will explore how one can obtain analytic control over parton showers using the idea of partons as essential degrees of liberty .This method has been constructed recently within the framework of Soft - Collinear Effective Theory ( SCET ) 1 . It provides a comprehensive way to resum big logarithms associated with collinear splittings into multiple jets 2 , thereby improving our appreciation of flight mechanics 3 .The basic idea behind SCET is that physical observables are explained by matrix elements featuring soft and / or collinear fields only 4 . These fields have nontrivial transformation qualities under boosts along the laser axis 5 .They allow us to separate hard interactions from soft light 6 . As a result , it becomes possible to deliberately factorize contributions to scattering amplitudes into hard functions describing short - distance dynamics 7 , 8 and semi - hard functions encoding information about the emission of deep gluons 9 .",
        "ori-fast-z-score": 0.5129891760425771,
        "water-fast-z-score": 6.874054958970533
    },
    {
        "original_text": "We present an alternative method to the usual Feynman path integral description for calculating the probability amplitudes in quantum walk models, based on the concept of scattering states and their associated S-matrix elements. We show that this new formalism allows us to obtain exact results for several interesting cases where standard methods fail or are not applicable. In particular we consider two different types of boundary conditions at one end of the chain (the origin) which lead to completely different behaviour of the system as time evolves. The first type is known as Dirichlet boundary condition, corresponding to reflecting particles back into the origin after they have left it once; while the second case corresponds to absorbing particles when they reach the origin. For both these cases we calculate exactly the evolution operator over all times t > 0 using our new method. Finally, by applying the inverse Fourier transform to the evolution operator we can recover the full probability distribution function of finding the walker at any position x along the chain at time t.",
        "watermark_text": "We introduce an additional method to the usual Feynman path integral description for determining the probability amplitudes in particle walk models , using on the idea of scattering states and their accompanying S - vector elements . We see that this new formalism allows us to obtain exact findings for numerous interesting cases where standard methods fail or are not applicable .In particular we define two different kinds of boundary conditions at one end of the chain ( the origin ) which lead to totally distinct behaviour of the system as time evolves . The first sort is known as Dirichlet boundary relation , corresponding to reflecting molecules back into the origin after they have left it once ; while the second case corresponds to absorbing particles when they reach the origin .For both these circumstances we estimate exactly the evolution function over all times t > 0 using our new method . Finally , by using the inverse Fourier integral to the evolution function we can extract the full probability distribution function of finding the walker at any point x along the chain at time t .",
        "ori-fast-z-score": 1.2649110640673518,
        "water-fast-z-score": 5.902918298980975
    },
    {
        "original_text": "We present the results for the equation of state (EoS) in hot Quantum Chromodynamics (QCD). We use two different approaches to solve numerically the lattice QCD EoS at finite temperature, namely the Taylor expansion method and the integral method. The latter is based on an exact representation of the pressure as a function of energy density using Padé approximants. In addition we also study the dependence of the EoS on the number of flavors Nf . Finally, we compare our numerical results with those obtained by other authors within various theoretical frameworks. Our main conclusions are that both methods give consistent results which agree well with previous calculations performed in the literature. Moreover, it turns out that the inclusion of strange quarks has only minor effects on the thermodynamic quantities considered here. \n \n Keywords: Equation of State; Heavy Ion Collisions; Lattice QCD; Relativistic Hydrodynamics",
        "watermark_text": "We present the results for the equation of state ( EoS ) in hot Quantum Chromodynamics ( QCD ) . We use two different methods to solve numerically the lattice QCD EoS at finite temperature , namely the Taylor expansion method and the integral method .The latter is based on an precise representation of the pressure as a function of energy density using Padé approximants . In addition we also study the dependence of the EoS on the quantity of flavors Nf .Finally , we compare our numerical findings with those achieved by other researchers within various theoretical frameworks . Our main results are that both approaches give consistent conclusions which agree well with previous analyses performed in the literature .Moreover , it turns out that the introduction of odd quarks has only minor impacts on the thermodynamic quantities considered here . Keywords : Equation of State ; Heavy Ion Collisions ; Lattice QCD ; Relativistic Hydrodynamics",
        "ori-fast-z-score": 0.13245323570650439,
        "water-fast-z-score": 4.03585624040554
    },
    {
        "original_text": "The authors present an evaluation framework to assess personal archiving strategies in the context of internet-based information, and apply it to two case studies. The first is based on a survey conducted among researchers at the University of Southampton; the second focuses on the activities of one individual researcher who has been collecting data about his research field over several years. Both cases are used to illustrate how different types of archives can be evaluated using this approach. This article was published as part of the Proceedings of the 1st International Conference on Digital Preservation (ICDP-1), held September 24-27, 2002 in New York City. It may be freely reproduced by anyone wishing to do so provided that proper credit is given to the author(s) and citation details are included. Copyright permission requests should be addressed to: RightsLink@copyright.gov. The authors present an evaluation framework which they use to assess personal archiving initiatives in the context of internet- based information. They then apply their method to two case studies - one focusing on a group of researchers at the University of Southamptonshire, UK, and another concentrating on the activities of one particular individual researcher.",
        "watermark_text": "The authors present an assessment framework to examine personal archiving strategies in the context of internet - based information , and application it to two case studies . The first is based on a survey conducted among researchers at the University of Southampton ; the second focuses on the actions of one individual scientist who has been collecting data about his scientific area over ten years .Both cases are applied to illustrate how various types of archives can be evaluated using this methodology . This section was publication as part of the Proceedings of the 1st International Conference on Digital Preservation ( ICDP - 1 ) , conducted September 24 - 27 , 2002 in New York City .It might be freely copied by anyone wishing to do so provided that proper credit is given to the writer ( s ) and citation notes are provided . Copyright permit applications should be addressed to : RightsLink @ copyright . gov .The authors present an assessment framework which they use to examine personal archiving activities in the context of internet - based information . They then use their method to two case studies - one focusing on a group of studies at the University of Southamptonshire , UK , and another concentrating on the actions of one particular individual scientist .",
        "ori-fast-z-score": 1.091089451179962,
        "water-fast-z-score": 8.292279828967711
    },
    {
        "original_text": "We present an extension of the Continuous Time Random Walk (CTRW) formalism to describe non-Markovian processes in terms of a stochastic Liouville equation with memory kernel. The latter is obtained by solving the corresponding Fokker-Planck equation for the probability distribution function, which can be done analytically only under certain conditions on the form of the memory kernel. We show that this problem can be overcome by introducing a new concept of  stochastic propagator , which allows us to obtain exact solutions even when the memory kernel does not have any particular functional dependence on time or space variables. Finally we discuss how our results are related to previous works based on fractional calculus techniques. In recent years there has been growing interest in studying systems whose dynamics cannot be described within the standard framework of Markovian processes  1  . This is mainly due to the fact that many physical phenomena exhibit complex temporal behavior characterized by power law relaxation  2  , aging  3  , intermittency  4  , etc., all of them being typical features of nonMarkovian processes  5  .\nIn order to deal with these problems it was proposed  6  to use the so-called Continuous Time Random Walk (CWTRW) formalism  7, 8  . Within such a description one considers a system evolving continuously in time according to some deterministic laws but interrupted at random times by jumps between different states. These jumps occur as a consequence of interactions with other degrees of freedom, e.g. phonons  9  , electrons  10  , photons  11  , etc.. As shown in Ref.  12  , the CWTRW formalism provides a very general description of non-Markovian dynamics since it includes both discrete state models  13  and fractional diffusion equations  14  as special cases. However, despite its great flexibility, the application of the CWTRW formal-",
        "watermark_text": "We introduce an extension of the Continuous Time Random Walk ( CTRW ) formalism to explain non - Markovian systems in terms of a stochastic Liouville equation with memory kernel . The latter is found by solving the analogous Fokker - Planck formula for the probability distribution function , which can be performed analytically only under certain conditions on the form of the storage kernel .We see that this question can be overcome by using a new notion of stochastic propagator , which allows us to obtain exact solutions even when the memory kernel does not have any specific functional dependence on time or space factors . Finally we explain how our findings are related to previous works based on fractional calculus techniques .In recent years there has been growing interest in investigating systems whose dynamics cannot be described within the standard structure of Markovian mechanisms 1 . This is mainly owing to the fact that several physical phenomena experience complex temporal activity described by power law contraction 2 , aging 3 , intermittency 4 , etc . , all of them being normal features of nonMarkovian mechanisms 5 .In try to deal with these problems it was suggested 6 to use the so - called Continuous Time Random Walk ( CWTRW ) formalism 7 , 8 . Within such a description one sees a system evolving continuously in time according to some deterministic laws but halted at random times by jumps between various states .These moves occur as a outcome of interactions with other degrees of freedom , e . g . phonons 9 , electrons 10 , photons 11 , etc . . As seen in Ref .12 , the CWTRW formalism gives a very general explanation of non - Markovian physics since it includes both discrete state models 13 and fractional diffusion expressions 14 as special cases . However , despite its great flexibility , the implementation of the CWTRW formal -",
        "ori-fast-z-score": -1.5787044347526527,
        "water-fast-z-score": 6.122759914971185
    },
    {
        "original_text": "We study the dynamics of hard-core bosons on an optical lattice with random disorder and nearest-neighbor hopping, using exact diagonalization techniques. We find that there is a crossover between two different regimes as we increase the strength of disorder. In one regime (weak disorder), the system shows Anderson localization behavior; while in another regime (strong disorder) it exhibits Bose glass behavior. The transition point depends strongly on the filling fraction of particles per site. For low fillings, this transition occurs at relatively small values of disorder strengths. However, for higher fillings, the transition to the Bose glass phase takes place only when the disorder becomes very strong. This suggests that the presence of interactions can significantly affect the nature of the ground state of the system even if they are weak compared to other energy scales such as the bandwidth or the disorder strength. \n \n Introduction \n \n Disorder plays an important role in determining many properties of condensed matter systems. It has been shown recently that disorder can lead to interesting phenomena like quantum Hall effect  1  , metal-insulator transitions  2  , and superconductivity  3  . One of the most studied models which incorporates both disorder and interaction effects is the so-called Anderson model  4  . In its simplest form, this model describes non-interacting electrons moving through a disordered medium. Although the original formulation was restricted to electronic degrees of freedom, it has also been extended to describe various physical situations involving interacting particles  5  -  8  .\n \nIn recent years, ultracold atoms have emerged as promising candidates for simulating complex quantum mechanical problems  9  -  11  . These experiments provide us with unprecedented control over all relevant parameters of the problem under consideration  12  -  14  . Moreover, these systems allow us to explore new physics beyond what is possible in conventional solid-state materials  15  -  17  . Ultracold atomic gases trapped in optical lattices offer unique opportunities to investigate the interplay between disorder and interactions  18  -  20  . Recently, several experimental groups  21  -  23  have observed signatures of Anderson localization  24  in cold atom systems by studying the transport properties of the gas across the lattice.",
        "watermark_text": "We research the dynamics of hard - core bosons on an optical lattice with random disorder and nearest - neighbor hopping , using exact diagonalization techniques . We see that there is a crossover between two different regimes as we increase the strength of disorder .In one regime ( weak disorder ) , the system displays Anderson localization behavior ; while in another regime ( strong disorder ) it displays Bose glass behavior . The transition point varies strongly on the filling portion of molecules per site .For low fillings , this shift occurs at fairly little values of disorder strengths . However , for greater fillings , the shift to the Bose glass phase takes place only when the disorder becomes very strong .This implies that the presence of interactions can significantly affect the nature of the ground state of the system especially if they are weak compared to other energy scales such as the bandwidth or the disorder strength . Introduction Disorder plays an important role in establishing many properties of condensed matter structures .It has been shown lately that disturbance can lead to unusual phenomena like quantum Hall impact 1 , metal - insulator transitions 2 , and superconductivity 3 . One of the most studied models which includes both disorder and interaction influences is the so - called Anderson model 4 .In its simplest version , this description assumes non - interacting electrons moved through a disordered material . Although the first formulation was confined to electronic degrees of liberty , it has additionally been extended to explain different mechanical problems concerning interacting molecules 5 - 8 .In recent years , ultracold atoms have developed as hopeful candidates for simulating complex quantum mechanical problems 9 - 11 . These studies provide us with tremendous control over all relevant variables of the issue under consideration 12 - 14 .Moreover , these systems allow us to examine novel physics beyond what is allowed in standard solid - state materials 15 - 17 . Ultracold atomic atoms trapped in laser lattices provides unique possibilities to examine the interplay between disorder and interactions 18 - 20 .Recently , various experimental groups 21 - 23 have discovered signatures of Anderson localization 24 in cold atom systems by examining the travel properties of the gas across the lattice .",
        "ori-fast-z-score": -0.8315218406202999,
        "water-fast-z-score": 7.140637266026874
    },
    {
        "original_text": "We present an analysis of archival XMM-Newton data for the Seyfert 1 galaxy, Mkr841 (NGC 4151). We find that the soft excess emission is well described by a blackbody component with kT = 0.16 keV and luminosity LBB ~ 1043 erg s-1. The hard X-ray spectrum can be fitted either by a power law or Compton reflection model. In both cases we detect strong relativistic Fe Kα lines at 6.4-6.7 keV which are broadened to FWHM ~ 1000 km/sec. These results suggest that there may exist two distinct regions where the accretion disk interacts with the central supermassive black hole. One region produces the soft excess via thermal reprocessing while another one gives rise to the hard X-ray emission through non-thermal processes such as inverse Compton scattering and/or Compton reflection.",
        "watermark_text": "We present an assessment of archival XMM - Newton data for the Seyfert 1 galaxy , Mkr841 ( NGC 4151 ) . We see that the soft excess emission is well described by a blackbody element with kT = 0 . 16 keV and luminosity LBB ~ 1043 erg s - 1 .The hard X - ray signal can be fit either by a power law or Compton absorption theory . In both cases we find strong relativistic Fe Kα bands at 6 . 4 - 6 . 7 keV which are broadened to FWHM ~ 1000 kilometers / sec .These data suggest that there may arise two separate areas where the accretion plasma interacts with the main supermassive black hole . One region delivers the deep excess via thermal reprocessing while another one offers rise to the hard X - ray radiation through non - thermal factors such as inverse Compton absorption and / or Compton absorption .",
        "ori-fast-z-score": -1.8203641092364127,
        "water-fast-z-score": 4.808326112068523
    },
    {
        "original_text": "Epitaxial growth is the process by which atoms are deposited on top of an existing crystal structure, forming new layers that grow in registry with each other.  Epitaxy can be used to produce thin films and superlattices for electronic devices.   Graphene epitaxy refers to the deposition of carbon atoms onto a substrate such as silicon carbide (SiC) or gallium nitride (GaN).   The resulting material has many properties similar to those of single-layered graphene but also exhibits some differences due to interactions between the different atomic planes.   ... Graphene epitaxy is the deposition of carbon atoms on a substrate such as SiC or GaN. This results in a material with many properties similar to those found in single layer graphene, but there are also important differences arising from interlayer interactions. In this review we discuss recent progress towards understanding these effects using scanning probe microscopy techniques including STM, AFM and Raman spectroscopy.",
        "watermark_text": "Epitaxial growth is the process by which elements are deposited on top of an established crystal composition , forming fresh layers that grow in registry with each other . Epitaxy can be used to produce thin films and superlattices for electronic systems .Graphene epitaxy refers to the precipitation of carbon atoms onto a substrate such as silicon carbide ( SiC ) or gallium nitride ( GaN ) . The produced material has numerous characteristics similar to those of double - layered graphene but also exhibits some variations owing to interactions between the different atomic planes .. . . Graphene epitaxy is the precipitation of carbon atoms on a substrate such as SiC or GaN . This results in a material with many properties similar to those shown in single surface graphene , but there are also important differences arising from interlayer bonding .In this review we discuss latest advances towards studying these phenomena using scan probe microscopy methods notably STM , AFM and Raman spectroscopy .",
        "ori-fast-z-score": 1.5650160901149996,
        "water-fast-z-score": 6.861993625888845
    },
    {
        "original_text": "We present an extension to the classical lubrication theory that accounts for shear thinning effects on both the fluid viscosity and the friction coefficient, which are assumed to be functions of local pressure only.  The resulting model is applied to study the effect of non-Newtonian rheology on the elastohydrodynamic (EHD) behavior of a circular contact between two elastic solids with different surface roughnesses under pure rolling conditions.  We show that the presence of shear thinning leads to significant changes in the predicted load-carrying capacity as well as the distribution of the normal stress across the contact area compared to those obtained using Newtonian models.  In particular, we find that the maximum value of the dimensionless pressure increases significantly when the fluids exhibit strong shear thinning characteristics.  Moreover, our results indicate that the inclusion of shear thinning effects can lead to substantial reductions in the magnitude of the dimensionless tangential stresses at the centerline of the contact region.  Finally, it should be noted that the proposed theoretical framework may also be used to investigate other important phenomena such as thermal effects or mixed lubrication regimes.",
        "watermark_text": "We introduce an extension to the classical lubrication theory that accounts for shear thinning effects on both the liquid viscosity and the tension factor , which are assumed to be functions of local pressure only . The resulting theory is applied to study the impact of non - Newtonian rheology on the elastohydrodynamic ( EHD ) behavior of a circular contact between two elastic solids with varying surface roughnesses under pure sliding conditions .We see that the presence of shear thinning leads to significant improvements in the expected load - holding capacity as well as the spread of the standard pressure across the contact area compared to those achieved using Newtonian methods . In particular , we find that the maximum value of the dimensionless tension increases substantially when the fluids show strong shear thinning characteristics .Moreover , our findings show that the introduction of shear thinning effects can lead to substantial reductions in the severity of the dimensionless tangential stresses at the centerline of the contact region . Finally , it should be mentioned that the suggested theoretical framework would also be used to examine other vital effects such as heat effects or mixed lubrication regimes .",
        "ori-fast-z-score": -0.6469966392206304,
        "water-fast-z-score": 6.539886462510548
    },
    {
        "original_text": "We study the propagation of surface waves in a layered medium with different signs of nonlinear coefficients and show that, under certain conditions, localized solutions exist which are similar to those known as gap solitons in periodic structures. The existence domain for these solutions is determined by solving an eigenvalue problem numerically. We also present results on the stability properties of such solutions against small perturbations. Surface wave localization can be observed experimentally using optical waveguide arrays or photonic crystals. In this work we consider the case when two layers have opposite signs of nonlinearities (e.g., one positive and another negative). This situation occurs naturally if the material parameters change sign across some interface between media. For example, it may happen near the boundary between materials with normal dispersion and anomalous dispersion. \n \n We demonstrate that there exists a class of localized solutions which resemble gap solitons in periodic systems. These solutions appear due to the interplay between linear and nonlinear effects. They exist only within a finite range of frequencies and decay exponentially away from their center point. Their amplitude depends strongly on the ratio of the amplitudes of the incident and reflected waves.",
        "watermark_text": "We test the propagation of surface waves in a layered medium with various signs of nonlinear coefficients and find that , under certain conditions , confined solutions arise which are comparable to those known as gap solitons in periodic complexes . The existence domain for these solutions is chosen by treating an eigenvalue problem numerically .We additionally report findings on the stability properties of such solutions against small perturbations . Surface wave localization can be viewed experimentally employing optical waveguide arrays or photonic clusters .In this research we imagine the case when two levels have different signs of nonlinearities ( e . g . , one positive and another negative ) . This condition occurs automatically if the material variables alter sign across some interface between media .For instance , it could happen near the boundary between materials with normal dispersion and anomalous dispersion . We suggest that there exists a class of localized solutions which mimic gap solitons in periodic systems .These solutions emerge due to the interplay between linear and nonlinear effects . They arise only within a finite range of frequencies and decay exponentially farther from their center position .Their amplitude depends strongly on the ratio of the amplitudes of the incident and reflected waves .",
        "ori-fast-z-score": -1.0425720702853738,
        "water-fast-z-score": 4.79583152331272
    },
    {
        "original_text": "We report the discovery and characterization of 33 new nearby white dwarf systems, including eight with trigonometric parallaxes measured by Gaia Data Release 2 (DR2). The sample includes six previously known binaries that were not included in DR2 because they are too faint for Gaia to resolve their components. We also present an analysis of the mass distribution of these newly discovered white dwarfs based on their photometric distances. This is the first time such a study has been performed using Gaia data alone. Our results show good agreement between our observed mass function and theoretical predictions. These findings demonstrate how Gaia can be used as a powerful tool to explore the local stellar population. Keywords: White dwarf - Galaxy - Parallax - Mass function - Gaia - Photometry - Binaries - Trigonometry - Distance scale - Astrometry - Stellar evolution - Galactic structure - Nearby stars",
        "watermark_text": "We report the discovery and identification of 33 new nearby white dwarf systems , including eight with trigonometric parallaxes measured by Gaia Data Release 2 ( DR2 ) . The sample comprises six formerly identified binaries that were not added in DR2 because they are too faint for Gaia to identify their components .We additionally offer an assessment of the mass distribution of these newly discovered white dwarfs based on their photometric ranges . This is the first time such a survey has been performed using Gaia data alone .Our results show good agreement between our measured mass behavior and theoretical estimates . These studies demonstrate how Gaia can be used as a powerful tool to examine the local stars community .Keywords : White dwarf - Galaxy - Parallax - Mass function - Gaia - Photometry - Binaries - Trigonometry - Distance scale - Astrometry - Stellar evolution - Galactic structure - Nearby stars",
        "ori-fast-z-score": 1.8073922282301278,
        "water-fast-z-score": 6.454972243679028
    },
    {
        "original_text": "We study the Wightman functions and vacuum densities on a Z_2-symmetric, thick brane embedded in an anti-de Sitter (AdS) space-time with one extra dimension. We find that there are two types of solutions to the corresponding equations depending on whether or not the bulk mass is zero. In both cases we show how these quantities can be expressed as sums over modified Bessel functions. The results obtained here may have applications in quantum field theory at finite temperature and/or density. PACS: 11.10.Kk, 12.20.Ds, 98.80.Cq Keywords: Vacuum expectation value, Anti-de Sitter space time, Thick brane, Modified Bessel function. 1 Introduction An interesting feature of string theories is their ability to incorporate gravity into the fundamental description of nature. This has led to renewed interest in studying gravitational backgrounds which admit supersymmetry  1  . One such class of spacetimes is given by the so-called warped product spaces  2  , where the metric takes the form ds2 = e2A(y)(ημνdxμ dxν + dy 2 ),\n(1)\nwhere y denotes the coordinate along the extra dimension, A(y) is called the warp factor and ημν is the Minkowski metric. For example, if we consider the five-dimensional case then this corresponds to the Randall-Sundrum model  3  .\nIn recent years it was shown  4  -  8  that the presence of a nontrivial warp factor leads to new features in the physics associated with fields propagating in the bulk. These include modifications to the standard dispersion relations  9  , spontaneous symmetry breaking  10  , fermion localization  11  , etc.. It turns out  12  that the effects due to the warp factor depend crucially upon its behaviour near the boundary of the extra dimension. If the warp factor vanishes sufficiently rapidly at infinity then all physical observables will be identical to those computed using ordinary flat-space techniques. However, if the warp factor does not vanish fast enough then some novel phenomena occur.",
        "watermark_text": "We explore the Wightman functions and vacuum densities on a Z _ 2 - symmetric , thick brane embedded in an anti - de Sitter ( AdS ) space - time with one extra dimension . We see that there are two forms of solutions to the associated equations depending on whether or not the liquid weight is zero .In both cases we give how these quantities can be shown as sums over modified Bessel functions . The results derived here may have applications in quantum field theory at finite cooling and / or density .PACS : 11 . 10 . Kk , 12 . 20 . Ds , 98 . 80 . Cq Keywords : Vacuum expectation point , Anti - de Sitter space time , Thick brane , Modified Bessel relation . 1 Introduction An interesting feature of string theories is their power to insert gravitational into the fundamental description of nature .This has led to renewed emphasis in investigating gravitational backgrounds which admit supersymmetry 1 . One such family of spacetimes is given by the so - called warped product spaces 2 , where the metric takes the form ds2 = e2A ( y ) ( ημνdxμ dxν + dy 2 ) , ( 1 ) where y denotes the coordinate along the extra dimension , A ( y ) is dubbed the warp factor and ημν is the Minkowski metric .For instance , if we treat the five - dimensional case then this corresponds to the Randall - Sundrum model 3 . In recent years it was shown 4 - 8 that the presence of a nontrivial warp factor leads to novel features in the physics associated with fields propagating in the bulk .These include changes to the standard dispersion relations 9 , spontaneous symmetry breaking 10 , fermion localization 11 , etc . . It turns out 12 that the effects due to the warp factor rely crucially upon its behaviour near the boundary of the extra dimension .If the warp factor vanishes sufficiently quickly at infinity then all physical observables will be identical to those computed using ordinary flat - space methods . However , if the warp factor does not vanish fast enough then some interesting phenomena arise .",
        "ori-fast-z-score": 0.8980265101338746,
        "water-fast-z-score": 6.2215204792052825
    },
    {
        "original_text": "We present dynamical models for the Milky Way halo that include an arbitrary number of spherical shells, each characterized by its own density and velocity dispersion profiles. The model is based on Jeans  theorem applied to the phase-space distribution function (DF) in order to obtain the DF as well as the projected surface mass density along any line-of-sight. We show how this approach can be used to fit observational data such as those obtained from kinematic tracers or gravitational lensing measurements. In particular we apply our method to two different sets of observations: 1) A sample of RR Lyrae stars observed towards the Galactic bulge; 2) Gravitational lensing measurements towards the Bullet Cluster. Our results are compared against previous works using similar techniques but assuming either constant anisotropies across all radii or simple power-law radial dependences. We find that these assumptions lead to significant biases when fitting the data.",
        "watermark_text": "We create dynamical models for the Milky Way halo that include an arbitrary number of spherical shells , each described by its own density and frequency dispersion patterns . The model is based on Jeans theorem applied to the phase - space distribution relation ( DF ) in order to obtain the DF as well as the projected surface weight concentration along any line - of - view .We see how this methodology can be used to fit observational data such as those acquired from kinematic tracers or gravitational lensing observations . In particular we apply our technique to two different sets of measurements : 1 ) A specimen of RR Lyrae stars observed towards the Galactic bulge ; 2 ) Gravitational lensing observations towards the Bullet Cluster .Our results are compared against prior studies use similar techniques but adopting either constant anisotropies across all radii or straightforward power - law longitudinal dependences . We see that these assumptions lead to significant biases when fitting the information .",
        "ori-fast-z-score": -0.6201736729460423,
        "water-fast-z-score": 4.589285179800713
    },
    {
        "original_text": "We present new near-infrared (NIR) observations and analysis of the young binary system UZ Tau E, which is composed of two T Tauri stars with masses ~0.8 M⊙ separated by 0. ′′ 4. The NIR light curves show periodic variations that are consistent with ellipsoidal modulation due to tidal distortion of each star s photosphere as it orbits its companion. We also find evidence for an additional component to this variability; we interpret these data as indicating that one or both components of the binary undergoes periodic episodes of enhanced mass loss at periastron passage. This interpretation is supported by our detection of excess emission in the K-band spectrum during periods when the photometric flux decreases. Our results suggest that the circumstellar disks around each member of the binary have been truncated by their mutual gravitational interaction. In addition, we detect significant changes in the shape of the Hα line profile over time scales of days to weeks. These changes can be explained if there exists a region of high density gas surrounding the binary orbiting on timescales similar to those observed in the NIR light curve.",
        "watermark_text": "We report new near - infrared ( NIR ) observations and investigation of the small binary system UZ Tau E , which is composed of two T Tauri stars with masses ~ 0 . 8 [UNK] connected by 0 . ′ ′ 4 .The NIR light curves show continuous shifts that are compatible with ellipsoidal modulation owing to tidal manipulation of each star s photosphere as it orbits its companion . We additionally find proof for an additional element to this variability ; we view these information as indicating that one or both components of the binary undergoes frequent bouts of enhanced mass loss at periastron passage .This interpretation is backed by our screening of excess emission in the K - band spectrum during moments when the photometric flux drops . Our results propose that the circumstellar disks around each member of the binary have been truncated by their mutual gravitational interaction .In addition , we perceive considerable changes in the shape of the Hα line profile over time ranges of weeks to weeks . These changes can be described if there exists a region of high density gas covering the binary orbiting on timescales similar to those observed in the NIR light curve .",
        "ori-fast-z-score": -0.32539568672798425,
        "water-fast-z-score": 5.378448739494827
    },
    {
        "original_text": "We report on four new quasars at redshifts z > 6, found in the Canada France Hawaii Telescope Legacy Survey (CFHTLS). The objects were selected as part of an ongoing survey for high-z quasars using photometric data obtained with CFHT and Spitzer Space Telescope. We present their optical to near-infrared SEDs, which are well fitted by composite quasar templates. Their luminosities range between 1.5 x 10^14 erg s-1 cm-2 and 2.1 x 10^15 erg s-1 cm-2 . These results show that there is still room for discovering very luminous quasars beyond redshift six. They also provide further evidence that supermassive black holes grew rapidly during this early phase of galaxy formation. Four quasars have been discovered at redshifts greater than 6 in the Canada France Hawaii telescope legacy survey (CFHTLS) by combining deep infrared observations taken with the Spitzer space telescope with optical data collected with the Canada France Hawaii telescope.",
        "watermark_text": "We report on four newest quasars at redshifts z > 6 , detected in the Canada France Hawaii Telescope Legacy Survey ( CFHTLS ) . The bodies were chosen as part of an continuing survey for high - z quasars using photometric data acquired with CFHT and Spitzer Space Telescope .We present their optical to near - infrared SEDs , which are well fitted by composite quasar templates . Their luminosities range between 1 . 5 x 10 ^ 14 erg s - 1 cm - 2 and 2 . 1 x 10 ^ 15 erg s - 1 cm - 2 .These data demonstrate that there is still space for producing very luminous quasars beyond redshift six . They also suggest further evidence that supermassive black holes grew rapidly during this earliest stage of galaxy formation .Four quasars have been detected at redshifts greater than 6 in the Canada France Hawaii telescope heritage survey ( CFHTLS ) by combining dark infrared observations made with the Spitzer space telescope with imaging information collected with the Canada France Hawaii telescope .",
        "ori-fast-z-score": -0.2672612419124244,
        "water-fast-z-score": 5.077963596336064
    },
    {
        "original_text": "We present an analysis of the effects that mergers may have on scaling relations between black holes (BHs), galaxies, and other gravitationally bound systems. We use cosmological simulations to study how BH mass is related to galaxy properties in different merger histories. Our results show that mergers can significantly affect these relationships by increasing scatter at fixed luminosity or stellar velocity dispersion. This effect is strongest for low-mass galaxies with high specific star formation rates. In addition, we find that mergers tend to increase the average BH-to-galaxy mass ratio as well as the fraction of active galactic nuclei (AGNs) among massive galaxies. These findings are consistent with observations of AGN host galaxies. Finally, our results suggest that the observed correlation between supermassive BH masses and bulge properties could be driven primarily by the fact that both grow during major mergers. Keywords: Galaxy evolution; Supermassive black hole",
        "watermark_text": "We present an assessment of the effects that mergers might have on scaling relations between black holes ( BHs ) , galaxies , and other gravitationally bound structures . We use cosmological simulations to study how BH mass is related to galaxy structures in different merger histories .Our results show that mergers can significantly affect these interactions by expanding scatter at fixed luminosity or stellar velocity dispersion . This phenomenon is greatest for low - density nuclei with high specific star formation rates .In addition , we find that mergers prefer to raise the average BH - to - star mass ratio as well as the fraction of active galactic nuclei ( AGNs ) among giant galaxies . These conclusions are consistent with observations of AGN host galaxies .Finally , our findings show that the seen correlation between supermassive BH masses and bulge properties might be motivated primarily by the fact that both expand during major mergers . Keywords : Galaxy evolve ; Supermassive black hole",
        "ori-fast-z-score": 0.35603449745815596,
        "water-fast-z-score": 5.5778737935111105
    },
    {
        "original_text": "We present the results of our study on bimodality in galaxies and active galactic nuclei (AGN). We find that there is no significant difference between the fraction of AGNs hosted by red or blue galaxies, but we do see an excess of AGNs with respect to normal galaxies at intermediate colors. This suggests that AGNs are not preferentially found in either red or blue galaxies, as previously thought; instead they appear to be more common among galaxies with intermediate color. The lack of correlation between galaxy color and AGN activity may indicate that AGNs play only a minor role in quenching star formation in massive galaxies. Alternatively, it could suggest that AGNs have different effects depending on their luminosity and/or accretion rate. In addition, we find that the majority of AGNs reside in galaxies with bulges, regardless of whether these galaxies are classified as early-type or late-type systems.",
        "watermark_text": "We present the conclusion of our research on bimodality in galaxies and active galactic nuclei ( AGN ) . We see that there is no major variation between the fraction of AGNs hosted by red or blue clusters , but we do saw an surplus of AGNs with regard to normal galaxies at intermediate colors .This implies that AGNs are not preferentially found in either blue or blue stars , as previously thought ; however they appear to be more common among clusters with intermediate color . The absence of correlation between galaxy color and AGN activity may indicate that AGNs serve only a minor importance in quenching star formation in massive galaxies .Alternatively , it could indicate that AGNs have different impacts depending on their luminosity and / or accretion rate . In addition , we find that the majority of AGNs occur in galaxies with bulges , regardless of whether these objects are classified as early - class or late - class systems .",
        "ori-fast-z-score": 0.8551861104941365,
        "water-fast-z-score": 6.305926250944657
    },
    {
        "original_text": "Magnetic separation is an important tool in biomedical research and clinical diagnostics, but it has been limited to macroscopic devices that are not suitable for point-of-care applications. Here we report on continuous magnetophoresis-based blood cell sorting using microfluidics. We demonstrate efficient separation of red blood cells (RBCs) from plasma by applying a magnetic field gradient across a microchannel containing RBCs suspended in buffer solution. The results show that our method can be used as a simple yet effective approach for separating different types of blood cells with high purity and efficiency. This work may have significant implications towards developing portable diagnostic tools based on microscale blood processing technologies. Magnetic separation techniques play an important role in many fields including medicine, biotechnology, environmental science, food industry etc.,  1  . However, most existing methods require bulky equipment which makes them unsuitable for use outside laboratory settings  2  .\nRecently there has been growing interest in miniaturizing these systems into lab-on-a-chip platforms  3  , where various functionalities such as sample preparation  4  , chemical analysis  5  , drug delivery  6  , and bioassays  7  could be integrated onto one single chip. In particular, magnetic separators have attracted much attention due to their simplicity, low cost, portability, and compatibility with other microfabricated components  8  . For example, several groups have demonstrated magnetic separation of biological samples inside microchannels  9  -  11  or on planar surfaces  12  -  14  . Despite this progress, however, current approaches still suffer from some limitations. First, they typically rely on batch-wise operation mode  15  , which limits throughput and requires large volumes of input samples  16  . Second, the majority of reported designs only allow for separation between two distinct populations  17  , while more complex mixtures involving multiple species cannot be processed simultaneously  18  . Third, the fabrication process usually involves complicated multi-step procedures  19  , making it difficult to integrate additional functions  20  . Finally, most previous studies were performed under static conditions  21  , which limit the flexibility of device design  22  .",
        "watermark_text": "Magnetic isolation is an important tool in biomedical research and medical diagnostics , but it has been limited to macroscopic devices that are not suitable for point - of - care applications . Here we study on rapid magnetophoresis - based blood cell sorting using microfluidics .We suggest efficient removal of red blood cells ( RBCs ) from fluid by using a magnetic current gradient across a microchannel containing RBCs held in buffer solution . The results show that our technique can be used as a simple yet effective methods for dividing different kinds of blood tissue with high purity and efficiency .This research could have considerable consequences towards developing portable diagnostic methods using on microscale blood extraction technologies . Magnetic isolation machines play an important role in multiple fields including medicine , biotechnology , environmental science , nutrition industry etc . , 1 .However , most existing techniques require bulky machinery which makes them unsuitable for use outside laboratory settings 2 . Recently there has been growing interest in miniaturizing these systems into lab - on - a - chip platforms 3 , where various functionalities such as specimen processing 4 , chemical analysis 5 , pharmaceutical production 6 , and bioassays 7 could be merged onto one single chip .In particular , magnetic separators have garnered considerable scrutiny due to their simplicity , low cost , portability , and compatibility with other microfabricated parts 8 . For instance , various groups have demonstrated magnetic separation of biological samples inside microchannels 9 - 11 or on planar materials 12 - 14 .Despite this progress , however , current approaches still suffer from some restrictions . First , they generally rely on batch - wise operation mode 15 , which reduces throughput and requires large quantities of input samples 16 .Second , the majority of reported prototypes only require for isolation between two separate populations 17 , while more sophisticated mixtures featuring multiple taxa unable be processed concurrently 18 . Third , the fabrication process usually includes complicated multi - phase techniques 19 , making it difficult to connect extra functions 20 .Finally , most prior studies were performed under static conditions 21 , which reduce the flexibility of device configuration 22 .",
        "ori-fast-z-score": 0.5261522196019802,
        "water-fast-z-score": 9.838699100999074
    },
    {
        "original_text": "We present Spitzer Infrared Spectrograph (IRS) observations of the nearby, interacting galaxy pair Mrk 297. The system consists of two galaxies separated by ~3 kpc in projection; one is an elliptical galaxy with a bright nuclear point source, while the other has a Seyfert 2 nucleus surrounded by extended emission lines. We detect several molecular hydrogen transitions including H$_2$ S(0), S(1), S(2), S(3), S(4), S(5), S(6), S(7), S(8), S(9), S(10), S(11), S(12), S(13), S(14), S(15), S(16), S(17), S(18), S(19), S(20). These are detected over a wide range of spatial scales ranging from <100 pc to >500 pc.",
        "watermark_text": "We present Spitzer Infrared Spectrograph ( IRS ) observations of the nearby , interacting galaxy pair Mrk 297 . The system contains of two galaxies linked by ~ 3 kpc in projection ; one is an elliptical galaxy with a bright nuclear point origin , while the other has a Seyfert 2 nucleus accompanied by extended emitted lines .We detect many molecular hydrogen changes including H $ _ 2 $ S ( 0 ) , S ( 1 ) , S ( 2 ) , S ( 3 ) , S ( 4 ) , S ( 5 ) , S ( 6 ) , S ( 7 ) , S ( 8 ) , S ( 9 ) , S ( 10 ) , S ( 11 ) , S ( 12 ) , S ( 13 ) , S ( 14 ) , S ( 15 ) , S ( 16 ) , S ( 17 ) , S ( 18 ) , S ( 19 ) , S ( 20 ) . These are detected over a broad variety of spatial scales extending from < 100 pc to > 500 pc .",
        "ori-fast-z-score": 0.5222329678670935,
        "water-fast-z-score": 4.351941398892446
    },
    {
        "original_text": "The Large Area Telescope (LAT) on the Fermi Gamma-ray Space Telescope will be launched in June 2008, with an expected launch date of August 7, 2007.  The LAT is designed to detect gamma rays between 20 MeV and 300 GeV over a large field-of-view (2 steradians), making it possible for the first time to study the entire sky at these energies every three hours. This talk will discuss how supernova remnants are likely to appear as sources of high-energy emission when observed by this new instrument. In particular I will focus on:  - How many remnants should we expect to see? - What types of remnants might show up? - What can we learn about particle acceleration mechanisms? - What can we do to prepare for the observations? - Other topics that may come up during discussion. The Large Area Telescope (L AT ) on the Fermi Gamma-ray Sp ace T elescope w ill b e la unched i n J une 2 008 , wi th an ex pected l aunch d ate o f A ugust 7 , 2 007 .",
        "watermark_text": "The Large Area Telescope ( LAT ) on the Fermi Gamma - ray Space Telescope will be launched in June 2008 , with an anticipated flight date of August 7 , 2007 . The LAT is designed to identify gamma radiation between 20 MeV and 300 GeV over a large field - of - view ( 2 steradians ) , making it able for the first time to study the entire sky at these frequencies every three years .This discussion will explore how supernova remnants are likely to appear as causes of high - energy emission when observed by this new instrument . In particular I will focus on : - How many ruins should we expect to see ?- What kinds of remnants may show up ? - What can we find about particle particle processes ?- What can we do to organize for the discoveries ? - Other topics that might come up during discussion .The Large Area Telescope ( L AT ) on the Fermi Gamma - ray Sp ace T elescope l ill b e la unched i n J une 2 008 , wi th an Ex pected w aunch d ate o g A ugust 7 , 2 007 .",
        "ori-fast-z-score": 1.5882027766319677,
        "water-fast-z-score": 6.893123494842633
    },
    {
        "original_text": "We report on spectropolarimetric observations of the M8+M9 binary star LHS 1070A,B (GJ 436) with ESPaDOnS at CFHT. The two stars are separated by only 0. ′′ 1 and have been known to be magnetically active for many years. We find that both stars show significant circularly polarized emission lines indicative of Zeeman splitting due to their magnetic fields. In addition we detect Stokes V signatures indicating net linear polarization across all observed spectral lines. This is likely caused by scattering processes within the stellar atmosphere. Using our new data set together with previously published photometric measurements we derive rotation periods of P A = 3.6 ± 0.1 days and P B = 4.2 ± 0.3 days for the primary and secondary component respectively. These values are significantly longer than those derived from previous studies which were based solely on photometry. Our results suggest that the rotation period of each individual component depends strongly on its effective temperature as well as its surface gravity.",
        "watermark_text": "We report on spectropolarimetric studies of the M8 + M9 binary star LHS 1070A , B ( GJ 436 ) with ESPaDOnS at CFHT . The two stars are apart by only 0 .′ ′ 1 and have been known to be magnetically active for thousands decades . We see that both stars show considerable circularly polarized emission lines indicative of Zeeman splitting due to their magnetic fields .In addition we perceive Stokes V signatures suggesting net linear polarization across all observed spectral lines . This is probably due by scattering mechanisms within the stars air .Using our new data set combined with previously reported photometric surveys we derive rotation periods of P A = 3 . 6 ± 0 . 1 months and P B = 4 . 2 ± 0 . 3 days for the primary and secondary component respectively . These measurements are greatly longer than those generated from previous analyses which were based primarily on photometry .Our results show that the rotation cycle of each individual component relies highly on its effective heat as well as its surface gravity .",
        "ori-fast-z-score": -1.3949716649258315,
        "water-fast-z-score": 4.216541329006604
    },
    {
        "original_text": "We present an analysis of ellipsoidal oscillations induced in main-sequence stars by their substellar companions, and discuss prospects for detecting such signals with the Kepler mission. We find that these effects are detectable over a wide range of orbital periods (from 1 to 1000 days) and companion masses (0.1-10 MJ). The amplitude of the signal is proportional to the square root of the mass ratio between the star and its companion; it can be as large as 0.1% of the total flux at optical wavelengths. For typical parameters expected among planet-hosting systems, we estimate that this effect should produce a peak-to-peak variation in brightness on the order of 10 mmag or less. This level of precision will require several months of continuous observations using the Kepler spacecraft s photometer. However, if detected, the presence of such a signal would provide strong evidence for the existence of a low-mass stellar or planetary companion orbiting the primary star. \n \n Keywords: Ellipsoidal variations, Planetary system",
        "watermark_text": "We present an assessment of ellipsoidal oscillations induced in major - sequence stars by their substellar companions , and consider prospects for detecting such signals with the Kepler expedition . We see that these phenomena are detectable over a broad variety of orbital periods ( from 1 to 1000 days ) and companion masses ( 0 . 1 - 10 MJ ) .The amplitude of the signal is proportional to the square root of the mass ratio between the star and its companion ; it can be as big as 0 . 1 % of the total flux at optical wavelengths . For common parameters predicted among planet - hosting systems , we estimate that this effect should produce a peak - to - peak change in intensity on the order of 10 mmag or smaller .This level of precision will take many months of simultaneous measurements using the Kepler satellite s photometer . However , if detected , the presence of such a signal might give strong evidence for the existence of a small - density stellar or planetary companion orbiting the primary star .Keywords : Ellipsoidal variations , Planetary system",
        "ori-fast-z-score": -1.62746694241347,
        "water-fast-z-score": 3.9524197172898554
    },
    {
        "original_text": "We study the dynamics of a probabilistic cellular automaton (PCA) with two species, prey and predators, which interact in an oscillatory way. The PCA is defined on a square lattice where each site can be occupied by at most one particle of either type. We show that for certain values of the parameters there are stable periodic solutions to this system. These results are obtained using a mean field approximation method. In particular we find that the periodicity depends only on the number of particles per unit area. This dependence agrees well with numerical simulations performed on finite lattices. Finally, we discuss how our model could be used as a simple description of population cycles observed in nature. Probabilistic cellular automata have been widely studied during recent years due to their potential applications in many fields such as physics  1  , biology  2  or computer science  3  . They consist of a set of cells arranged in some regular structure like a grid  4  whose state evolves according to local rules depending on its own state and those of its neighbors  5  .\nIn this work we consider a two-dimensional probabilistic cellular automaton  6  consisting of N sites located on a square lattice L = Z 2 . Each cell i ∈ L has four possible states denoted by 0, 1, 2 and 3 corresponding respectively to empty space, prey, predator and dead. At time t = 0 all sites are initialized randomly with probability p 0 = 1/4 of being vacant, p 1 = 1/2 of having a prey and p 2 = 1/4 of containing a predator. Then, the evolution rule consists of applying simultaneously the following transition probabilities between consecutive times t and t + 1:",
        "watermark_text": "We work the dynamics of a probabilistic cellular automaton ( PCA ) with two species , prey and predators , which interact in an oscillatory way . The PCA is characterized on a square lattice where each site can be occupied by at most one particle of either type .We see that for particular values of the variables there are stable periodic answers to this scheme . These conclusions are derived using a mean field approximation algorithm .In particular we find that the periodicity varies only on the quantity of particles per unit area . This dependence agrees well with numerical simulations conducted on finite lattices .Finally , we explain how our model could be used as a simple explanation of population trends studied in nature . Probabilistic cellular automata have been widely explored during recent months thanks to their potential applications in different fields such as science 1 , chemistry 2 or computer science 3 .They consist of a group of cells located in some regular structure like a network 4 whose state evolves due to local rules depending on its own state and those of its relatives 5 . In this research we study a two - dimensional probabilistic cellular automaton 6 consisting of N sites located on a square lattice L = Z 2 .Each cell i ∈ L has four possible states denoted by 0 , 1 , 2 and 3 relating respectively to empty space , prey , predator and dead . At time t = 0 all locations are initialized randomly with probability p 0 = 1 / 4 of being empty , p 1 = 1 / 2 of having a predators and p 2 = 1 / 4 of featuring a hunter .Then , the evolution rule involves of using concurrently the following transfer probabilities between successive times t and t + 1 :",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 6.15643073089126
    },
    {
        "original_text": "The solar cycle is an important phenomenon in space weather, which can have significant effects on Earth and its technological infrastructure. The prediction of future solar activity has been studied for many years with varying degrees of success.  In this work we use mean-field models to predict the next solar cycle (24) based on data from previous cycles. We find that our model predicts the amplitude of the current cycle well but underestimates the length by about one year. Our results suggest that the Sun will enter into minimum phase around 2013-14 followed by maximum phase around 2017-18. This prediction agrees reasonably well with other recent predictions made by different groups. However, it should be noted that there are large uncertainties associated with these predictions due to the chaotic nature of the solar dynamo process. Future observations may help reduce some of these uncertainties. Keywords: Space Weather, Solar Dynamo, Mean Field Modeling, Prediction",
        "watermark_text": "The solar cycle is an important feature in space weather , which can have considerable effects on Earth and its technological equipment . The prediction of potential solar activity has been studied for numerous years with varying degrees of progress .In this research we using mean - field estimates to predict the new sun cycle ( 24 ) based on evidence from previous periods . We see that our model predicts the frequency of the present cycle well but underestimates the length by about one year .Our results propose that the Sun will enter into minimum phase around 2013 - 14 followed by maximum phase around 2017 - 18 . This prediction agrees reasonably well with other recent predictions making by various groups .However , it should be mentioned that there are big uncertainties involved with these predictions attributed to the chaotic nature of the solar dynamo mechanism . Future discoveries may help decrease some of these uncertainties .Keywords: Space Weather, Solar Dynamo, Mean Field Modeling, Prediction",
        "ori-fast-z-score": -2.121320343559643,
        "water-fast-z-score": 5.185449728701349
    },
    {
        "original_text": "We present the results of our analysis on GRB 080916C, one of the most energetic bursts ever detected by Swift/BAT and Fermi/GBM. We find that this burst is consistent with being produced in an off-axis jet viewed at an angle θ ~ 60° to its axis. The observed light curve can be explained as emission from two components: (1) A bright component which peaks early during the prompt phase; it has a duration T90 = 1 s and a fluence Fγ = 2×10−6 erg cm−2. (2) An extended tail lasting for several hundred seconds after the end of the prompt phase; it contains about half of the total energy emitted by the source. Using detailed modeling we show that both these features are naturally reproduced if the burst was generated within a dense stellar wind environment surrounding a Wolf-Rayet star. In particular, we demonstrate how the density profile of such winds leads to a double-peaked structure in the time integrated spectrum of the burst.",
        "watermark_text": "We present the conclusion of our analysis on GRB 080916C , one of the most intense pulses ever observed by Swift / BAT and Fermi / GBM . We see that this burst is compatible with being produced in an off - axis jet viewed at an angle θ ~ 60° to its axis .The observed light spiral can be described as emission from two parts : ( 1 ) A bright component which peaks early during the prompt phase ; it has a duration T90 = 1 s and a fluence Fγ = 2×10−6 erg cm−2 . ( 2 ) An enhanced tail lasting for numerous hundred moments after the end of the prompt phase ; it contains about half of the total energy emitted by the source .Using detailed simulation we find that both these characteristics are naturally reconstructed if the explosion was generated within a dense stellar wind climate surrounding a Wolf - Rayet star . In particular , we prove how the density profile of such winds leads to a twin - peaked structure in the time integrated spectrum of the explosion .",
        "ori-fast-z-score": -0.3611575592573076,
        "water-fast-z-score": 4.541868715470696
    },
    {
        "original_text": "We present new near-infrared (NIR) observations for four Galactic bulge globular clusters: Terzan 5, Lilll1, UKS 1, and Terzan 4 obtained with the Near Infrared Camera and Multi-Object Spectrometer (NICMOS). The data were taken in two filters F160W and F222M during three orbits each at the Hubble Space Telescope (HST), as part of program GO-10775. We use these NIR images to derive accurate distances to all four clusters by comparing their observed magnitudes with those predicted using theoretical isochrones. Our results are consistent within uncertainties with previous distance estimates derived from optical photometric studies. For Terzan 5 we find d = 8.2 ± 0.3 kpc; for Liller 1: d = 7.7 ± 0.4 kpc; for UKS 1: d = 6.8 ± 0.5 kpc; and for Terzan 4: d = 9.0 ± 0.6 kpc.",
        "watermark_text": "We report new near - infrared ( NIR ) observations for four Galactic bulge globular complexes : Terzan 5 , Lilll1 , UKS 1 , and Terzan 4 obtained with the Near Infrared Camera and Multi - Object Spectrometer ( NICMOS ) . The data were took in two filters F160W and F222M during three orbits each at the Hubble Space Telescope ( HST ) , as part of series GO - 10775 .We use these NIR observations to derive exact distances to all four clusters by testing their observed magnitudes with those predicted using theoretical isochrones . Our results are compatible within uncertainties with previous diameter calculations derived from optical photometric studies .For Terzan 5 we find d = 8.2 ± 0.3 kpc; for Liller 1: d = 7.7 ± 0.4 kpc; for UKS 1: d = 6.8 ± 0.5 kpc; and for Terzan 4: d = 9.0 ± 0.6 kpc.",
        "ori-fast-z-score": 1.6666666666666667,
        "water-fast-z-score": 4.666666666666667
    },
    {
        "original_text": "The aim of this thesis is the study and development of computational methods for prolongation structures, which are used as tools in geometric analysis. The main focus lies on the construction of explicit formulas for the prolonged action of vector fields on tensor bundles over manifolds with symmetries. In particular we consider Lie groups acting by diffeomorphisms on Riemannian or pseudo-Riemannian manifolds. We present an algorithm that computes the prolonged action of a given vector field on any tensor bundle associated to such a manifold. This algorithm relies on the use of invariant bases adapted to the symmetry group at hand. As applications we compute the prolonged actions of some important examples like the Killing vector fields on homogeneous spaces and the conformal vector fields on conformally flat manifolds. Finally, we show how our results can be applied to construct new families of solutions to Einstein s equations. Keywords: Geometric Analysis, Manifold Symmetry Group",
        "watermark_text": "The goal of this dissertation is the development and evolution of computational procedures for prolongation structures , which are applied as tools in mathematical analysis . The main aim lies on the creation of explicit formulas for the prolonged operation of vector fields on tensor bundles over manifolds with symmetries .In particular we define Lie fields acted by diffeomorphisms on Riemannian or pseudo - Riemannian manifolds . We introduce an algorithm that computes the prolonged operation of a given tensor field on any tensor bundle corresponding to such a manifold .This method relies on the using of invariant bases adapted to the symmetry class at hand . As applications we compute the prolonged actions of some important examples like the Killing matrix fields on homogeneous spaces and the conformal vector spaces on conformally flat manifolds .Finally , we show how our findings can be applied to build modern classes of solutions to Einstein s equations . Keywords : Geometric Analysis , Manifold Symmetry Group",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 5.497624996033735
    },
    {
        "original_text": "We present an analysis of the distribution of gas, stars and dust in two nearby edge-on spirals with prominent bars (NGC 1365 and NGC 1530). We use high-resolution observations obtained by the Herschel Space Observatory to study the physical conditions of the interstellar medium along these systems. The main results are as follows:  - In both cases we find that the molecular hydrogen is concentrated on the leading edges of the bar, while atomic hydrogen follows closely the stellar light.  - The star formation rate peaks at the ends of the bar where the density of molecular hydrogen increases significantly. This suggests that the gravitational torques induced by the bar can trigger the collapse of dense clouds into new generations of young stars.  - The infrared emission associated with polycyclic aromatic hydrocarbons shows a clear correlation between the location of this component and the regions of active star formation. - The comparison of our data with hydrodynamical simulations indicates that the observed structure of the ISM may be explained if the bar potential has been able to drive significant amounts of cold gas towards its inner Lindblad resonance.",
        "watermark_text": "We present an assessment of the distribution of gas , stars and dust in two distant edge - on spirals with prominent bars ( NGC 1365 and NGC 1530 ) . We use large - resolution measurements obtained by the Herschel Space Observatory to study the physical conditions of the interstellar medium along these systems .The main results are as follows : - In both cases we find that the molecular hydrogen is confined on the led corners of the bar , while nuclear hydrogen takes closely the stellar radiation . - The galaxy formation rate peaks at the ends of the bar where the density of molecular hydrogen rises considerably .This implies that the gravitational torques induced by the bar can cause the decay of dense clouds into new generations of young stars . - The infrared absorption associated with polycyclic aromatic hydrocarbons indicates a clear correlation between the location of this constituent and the regions of active star formation .- The comparison of our information with hydrodynamical simulations indicates that the known composition of the ISM may be described if the bar potential has been able to drive considerable portions of cold gas towards its internal Lindblad resonance .",
        "ori-fast-z-score": 1.4924050144892729,
        "water-fast-z-score": 6.88998622004134
    },
    {
        "original_text": "The statistical behavior of domain systems is studied by using the concept of entropy and its associated quantities, such as information content and mutual information.  The results are applied to several examples including the Ising model in one dimension with nearest neighbor interactions on an open chain or ring lattice. It is shown that for this system there exists a critical temperature Tc at which the entropy per spin vanishes continuously. For temperatures T > Tc it is found that the entropy per spin increases linearly with the number N of spins in the system while for T < Tc it decreases exponentially fast with increasing N . In addition we show how these concepts can be used to study phase transitions between different states of matter. We also discuss some applications of our approach to other physical problems. PACS: 05.45.-a; 05.60.Fh; 05.70.Jc; 06.20.Hv; 62.25.Kx",
        "watermark_text": "The statistical behavior of domain systems is studied by using the idea of entropy and its attendant parameters , such as data content and mutual information . The results are applied to several examples including the Ising model in one dimension with nearest friend interactions on an open chain or ring lattice .It is seen that for this scheme there exists a critical temperature Tc at which the entropy per spin vanishes constantly . For temperatures T > Tc it is found that the entropy per spin increases linearly with the number N of spinning in the system while for T < Tc it reduces exponentially rapidly with expanding N .In addition we explain how these concepts can be used to study phase transitions between various states of matter . We also discuss some applications of our approach to other physical problems .PACS: 05.45.-a; 05.60.Fh; 05.70.Jc; 06.20.Hv; 62.25.Kx",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 3.8729833462074166
    },
    {
        "original_text": "We present new ultraviolet (UV) observations of star formation rates (SFRs) for galaxies within 10 Mpc using GALEX data and compare these to SFRs derived from optical emission lines, infrared luminosities, radio continuum fluxes, and UV-optical colors. We find that all methods agree well with each other when applied to normal star-forming galaxies but disagree significantly on low-luminosity dwarf galaxies where dust extinction is significant. The scatter between different estimators increases at lower luminosities due primarily to differences in how they treat dust extinction. In addition we show that there are systematic offsets among some of the estimators which can be explained by aperture effects or calibration uncertainties. Finally, we use our sample to examine the relationship between galaxy mass and specific star formation rate as measured by various techniques. Our results suggest that the most reliable estimates of SFR come from combining multiple indicators rather than relying solely on one method.",
        "watermark_text": "We create latest ultraviolet ( UV ) observations of galaxy formation rates ( SFRs ) for galaxies within 10 Mpc using GALEX data and compare these to SFRs generated from optical emission lines , infrared luminosities , television continuum fluxes , and UV - optical colors . We see that all techniques work better with each other when applied to normal star - creating stars but disagree significantly on small - luminosity dwarf stars where dust extinction is substantial .The scatter between various estimators increases at lower luminosities due primarily to differences in how they treat dust extinction . In addition we find that there are systematic offsets among some of the estimators which can be described by lens effects or calibration uncertainties .Finally , we utilize our sample to examine the relationship between galaxy mass and particular galaxy formation rate as measured by various methods . Our results show that the most accurate calculations of SFR come from combining multiple indicators rather than relying solely on one method .",
        "ori-fast-z-score": 1.7320508075688772,
        "water-fast-z-score": 6.653056282246291
    },
    {
        "original_text": "We have investigated how different assumptions about the velocity distribution function (VDF) affect the shape of the observed line profile in the solar corona, using an analytical model for the VDF that includes both isotropic thermal motions and anisotropic nonthermal motions. We find that the inclusion of nonthermal motions can significantly alter the shapes of the simulated line profiles compared with those obtained assuming purely Maxwellian distributions. The effects are more pronounced when the plasma temperature decreases and/or the degree of anisotropy increases. \n \n In particular, we show that the presence of nonthermal motions leads to significant asymmetries between the red-and blueshifted wings of the line profiles. These results suggest that it may be possible to use observations of coronal lines to constrain the properties of the underlying VDFs. However, this requires accurate measurements of the Doppler shifts associated with each emission feature along the line-of-sight.",
        "watermark_text": "We have analyzed how various assumptions about the velocity distribution relation ( VDF ) impact the morphology of the seen line profile in the sun corona , using an analytical theory for the VDF that contains both isotropic thermal motions and anisotropic nonthermal movements . We see that the introduction of nonthermal movements can significantly change the shapes of the simulated line profiles compared with those achieved assuming solely Maxwellian distributions .The effects are more pronounced when the plasma pressure drops and / or the degree of anisotropy changes . In particular , we find that the presence of nonthermal movements leads to significant asymmetries between the red - and blueshifted wings of the line profiles .These data suggest that it could be possible to use observations of coronal lines to constrain the properties of the intrinsic VDFs . However , this demands accurate measurements of the Doppler cycles identified with each emission feature along the line - of - view .",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 6.621221919717306
    },
    {
        "original_text": "We study the orbital evolution and stability properties of oligarchic co-orbitals in the Solar System, i.e., bodies with masses comparable to that of Jupiter which are trapped on orbits close to those of Neptune or Uranus for billions of years.  We show how these objects can be identified by their long-term dynamical behavior as well as by their current positions relative to Neptune s orbit. The existence of such bodies is confirmed by numerical integrations over timescales up to 10 billion years using the symplectic N-body code SyMBA. In addition we find that there exist at least two other stable regions where oligarchs may reside. These results suggest that the Solar System contains several dozen oligarchic co-orbitals:  - At least four known trans-Neptunian objects (Pluto, Charon, Haumea, Makemake) have been found to exhibit this type of dynamics; - There exists another region around 30 AU containing three additional bodies (Sedna, 2000 CR 105 , 2003 SQ 317 ); - Finally, our simulations indicate that there might also be an additional group of oligarchs located between 50-60 AU.",
        "watermark_text": "We research the orbital evolution and stability properties of oligarchic co - orbitals in the Solar System , i . e . , bodies with masses similar to that of Jupiter which are locked on orbits close to those of Neptune or Uranus for billions of years . We see how these objects can be identified by their long - term dynamical behavior as well as by their current positions close to Neptune s orbit .The formation of such objects is predicted by numerical integrations over timescales up to 10 billion years employing the symplectic N - bodies code SyMBA . In addition we find that there exist at least two other stable parts where oligarchs might live .These data suggest that the Solar System includes several several oligarchic co - orbitals : - At least four known trans - Neptunian planets ( Pluto , Charon , Haumea , Makemake ) have been seen to contain this form of dynamics ; - There exists another region around 30 AU holding three extra bodies ( Sedna , 2000 CR 105 , 2003 SQ 317 ) ; - Finally , our simulations confirm that there might additionally be an additional family of oligarchs located between 50 - 60 AU .",
        "ori-fast-z-score": -1.3643820804812932,
        "water-fast-z-score": 5.0854241181575475
    },
    {
        "original_text": "We study the phase structure of a surface model defined by an energy functional that consists of two competing terms, one favoring smooth surfaces and another penalizing their curvature fluctuations. The latter is modeled as a harmonic term in the local mean curvature. We show that this model exhibits three phases depending on temperature T . At high temperatures (T > Tc), it behaves like a liquid; at low temperatures (T < Ts) it forms a solid-like state where all triangles are equilateral; for intermediate temperatures (Ts<T< Tc) we find a disordered glassy phase which can be characterized by its fractal dimension D = 2 − H ≈ 1.7 ± 0.1. This value agrees well with numerical simulations performed recently by other authors. \n \n In addition to these results, our analysis also provides evidence for a first-order transition between the ordered and disordered states. Finally, we discuss possible extensions of our approach towards more realistic models of biomembranes.",
        "watermark_text": "We explore the phase composition of a surface model characterized by an energy functional that composed of two different terms , one favoring smooth surfaces and another penalizing their curvature fluctuations . The last is modeled as a harmonic term in the local average curvature .We see that this model shows three stages depending on temperature T . At high temperatures ( T > Tc ) , it behaves like a liquid ; at low temperatures ( T < Ts ) it creates a solid - like state where all triangles are equilateral ; for intermediate temperatures ( Ts < T < Tc ) we find a disordered glassy phase which can be described by its fractal dimension D = 2 − H ≈ 1 . 7 ± 0 . 1 .This value agrees well with numerical simulations conducted recently by other researchers . In addition to these results , our analysis even offers evidence for a first - order conversion between the ordered and disordered states .Finally , we discuss possible extensions of our approach towards more realistic descriptions of biomembranes .",
        "ori-fast-z-score": -0.24618298195866545,
        "water-fast-z-score": 4.031591663758072
    },
    {
        "original_text": "We consider an antenna combining scheme in which each user is equipped with multiple antennas and transmits its data to one base station (BS) using space-time coding techniques. The BS uses maximum ratio combining (MRC), zero forcing (ZF), or minimum mean square error (MMSE) receivers, depending on whether it has perfect channel state information (CSI). We derive closed-form expressions for the ergodic capacity achieved by this system under Rayleigh fading channels. Our results show that ZF performs better than MMSE when there are more users than transmit antennas at the BS; otherwise, MMSE outperforms ZF. In addition, we find that the performance gap between these two schemes decreases as the number of receive antennas increases. \n \n Keywords: Antenna combining, downlink channel, MIMO systems, Rayleigh fading channels, space time codes",
        "watermark_text": "We consider an radar combining system in which each user is furnished with many antennas and transmits its data to one base station ( BS ) used space - time coding techniques . The BS using maximum ratio combining ( MRC ) , zero forcing ( ZF ) , or lowest mean square error ( MMSE ) receivers , depending on whether it has good network state information ( CSI ) .We derive closed - form expressions for the ergodic strength achieved by this scheme under Rayleigh fading filters . Our results show that ZF performs better than MMSE when there are more users than receive antennas at the BS ; otherwise , MMSE outperforms ZF .In addition , we find that the performance difference between these two systems decreases as the quantity of receive antennas increases . Keywords : Antenna combining , downlink channel , MIMO systems , Rayleigh fading stations , space time codes",
        "ori-fast-z-score": 0.254000254000381,
        "water-fast-z-score": 4.572004572006858
    },
    {
        "original_text": "We present the results of our study on chemical composition, molecular line emission, dust properties, and thermal balance in dense cores with metallicities ranging between 1/100 solar to 1/10 000 solar. We find that the gas temperature decreases by about 10 K as the core density increases for all metallicities studied here (1/100-1/10 000 solar). The decrease is more rapid than predicted by current models which assume constant temperatures throughout the cloud evolution. This may be due to an increase in the importance of grain-surface chemistry relative to gas-phase reactions at higher densities. In addition we find evidence for significant depletion of carbon onto grains even at high metallicities such as Z = 1/10 000 solar. Our observations suggest that the critical density above which CO becomes optically thick depends strongly on metallicity. At lower metallicities this occurs at higher densities compared to higher metallicities. Finally, we show that the observed abundance ratios are consistent with those expected if the clouds were initially chemically enriched by supernovae type II explosions.",
        "watermark_text": "We present the conclusion of our research on chemical composition , molecular line emission , dust characteristics , and thermal balance in dense cores with metallicities ranging between 1 / 100 solar to 1 / 10 000 solar . We see that the gas temperature reduces by about 10 K as the core size grows for all metallicities researched here ( 1 / 100 - 1 / 10 000 solar ) .The reduction is more rapid than forecast by current scenarios which predict constant temperatures throughout the cloud evolution . This might be due to an increase in the importance of grain - boundary dynamics compared to liquid - phase processes at higher densities .In addition we find proof for significant depletion of carbon onto grains even at high metallicities such as Z = 1 / 10 000 solar . Our observations suggest that the critical mass above which CO becomes optically dense relies highly on metallicity .At lower metallicities this appears at higher densities compared to higher metallicities . Finally , we find that the seen concentrations proportions are compatible with those expected if the clouds were initially chemically enriched by supernovae class II explosions .",
        "ori-fast-z-score": 1.5652475842498528,
        "water-fast-z-score": 7.313071356019155
    },
    {
        "original_text": "We consider forward stagewise regression (FSR) for linear models with nonnegative coefficients, which is an iterative procedure that adds variables to the model one at a time until some stopping criterion is met.  We show how FSR can be used in conjunction with the monotone Lasso penalty to produce sparse solutions whose support contains all relevant predictors while simultaneously ensuring their signs are correct.  The resulting algorithm has computational complexity similar to standard Lasso algorithms but produces more accurate results on simulated data sets as well as real-world examples involving gene expression microarray data. Forward Stagewise Regression (FSR), introduced by Frank & Friedman  1  , is an iterative procedure where each iteration consists of adding a single variable into the current set of selected features based on its contribution to the objective function. This process continues until some stopping criteria is reached such as reaching a maximum number of iterations or meeting a desired level of accuracy  2  . In this work we focus on using FSR within the context of linear models with non-negative coefficients. For example, if our goal was to find genes associated with breast cancer then it would make sense to only select those genes that have been shown to increase risk rather than decrease risk  3  .\nThe main advantage of FSR over other greedy selection methods like stepwise regression  4  is that it does not require any tuning parameters  5  . However, there are two major drawbacks when applying FSR directly to problems with large numbers of potential covariates  6  :  1) It may take many iterations before the final solution converges; 2) There is no guarantee that the final solution will contain all relevant predictors. To address these issues, Tibshirani et al.  7  proposed the Least Absolute Shrinkage and Selection Operator (Lasso). Lasso solves the following optimization problem:",
        "watermark_text": "We consider forward stagewise regression ( FSR ) for linear models with nonnegative parameters , which is an iterative method that adds variables to the model one at a time until some stops criterion is reached . We see how FSR can be used in partnership with the monotone Lasso penalty to produce sparse scenarios whose support includes all relevant predictors while simultaneously ensuring their signs are correct .The resulting algorithm has computational efficiency comparable to standard Lasso techniques but generates more accurate conclusions on virtual data sets as well as real - time examples involving gene sequence microarray data . Forward Stagewise Regression ( FSR ) , invented by Frank & Friedman 1 , is an iterative method where each iteration consists of adding a single variable into the present set of chosen characteristics depending on its contribution to the objective function .This process proceeds until some stopping requirements is reached such as reaching a maximum number of iterations or meeting a desired level of precision 2 . In this research we focus on implementing FSR within the context of linear models with non - negative coefficients .For instance , if our goal was to find genes associated with breast tumors then it would work sense to only select those genes that have been shown to raise risk rather than decrease risk 3 . The main advantage of FSR over other greedy selection schemes like stepwise regression 4 is that it does not require any tuning variables 5 .However , there are two principal drawbacks when applying FSR directly to problems with large numbers of potential covariates 6 : 1 ) It might took many iterations before the finished problem converges ; 2 ) There is no guarantee that the finished problem will include all relevant predictors . To address these problems , Tibshirani et al .7 proposed the Least Absolute Shrinkage and Selection Operator ( Lasso ) . Lasso solves the following optimization problem :",
        "ori-fast-z-score": 1.30066495428618,
        "water-fast-z-score": 8.811457940929873
    },
    {
        "original_text": "We present the first measurement of single-transverse-spin asymmetries (SSA) for hadronic dijets produced at midrapidity in p+p collisions at sqrt(sNN) = 5.02 TeV using data collected by the CMS experiment during 2012 corresponding to an integrated luminosity of 2.3 fb-1 . The SSAs are extracted as functions of jet transverse momentum and rapidity, azimuthal angle between jets, and event centrality. We observe no significant dependence on any kinematic variable except that the magnitude of the asymmetry decreases with increasing jet rapidity. Our results are compared to theoretical predictions based on perturbative QCD calculations including higher-order corrections and parton distribution function uncertainties. \nThe measured values agree well within experimental and theoretical uncertainties. This is the most precise measurement of this observable performed so far. \n \n Introduction \n \n Single transverse-spin asymmetries have been observed in several processes involving polarized protons or neutrons  1  , such as inclusive pion production  2  , semi-inclusive deep-inelastic scattering  3  , Drell-Yan lepton pair production  4  , prompt photon production  5  , and direct photons  6  . These measurements provide important information about the spin structure of nucleons  7, 8  .\n \nIn particular, they can be used to test the validity of factorization theorems  9  which relate hard-scattering cross sections to partonic distributions inside the proton  10  . In addition, these observables may also shed light on new physics beyond the Standard Model  11  . \n \n For example, it has recently been suggested  12  that large single-spin asymmetries could arise due to the interference of two amplitudes describing different helicities of quarks emitted from longitudinally polarized gluons in high-energy pp collisions. Such effects would violate parity conservation and thus constitute evidence for new physics  13  . However, there exists only one previous measurement  14  of single-spin asymmeties in hadronic dijet production at high energies. That study was carried out at RHIC  15  where the center-of-mass energy per nucleon-nucleon collision √sNN=200 GeV is much lower",
        "watermark_text": "We present the first measurement of single - transverse - spinning asymmetries ( SSA ) for hadronic dijets created at midrapidity in p + p collisions at sqrt ( sNN ) = 5 . 02 TeV using data derived by the CMS experiment during 2012 corresponding to an unified luminosity of 2 . 3 fb - 1 . The SSAs are derived as functions of jet transverse momentum and rapidity , azimuthal angle between planes , and event centrality .We see no major dependence on any kinematic variable except that the magnitude of the asymmetry decreases with increasing jet rapidity . Our results are compared to theoretical estimates based on perturbative QCD calculations including higher - order corrections and parton distribution function uncertainties .The measured measures agree well within experimental and theoretical uncertainties . This is the most accurate calculation of this observable performed so far .Introduction Single transverse - spinning asymmetries have been observed in multiple processes involving polarized protons or neutrons 1 , such as inclusive pion production 2 , semi - inclusive dark - inelastic emission 3 , Drell - Yan lepton pair production 4 , prompt photon production 5 , and direct photons 6 . These measurements give important information about the spin composition of nucleons 7 , 8 .In particular , they can be used to test the legitimacy of factorization theorems 9 which compare hard - absorption cross sections to partonic distributions inside the proton 10 . In addition , these observables might additionally bring light on new science beyond the Standard Model 11 .For instance , it has recently been proposed 12 that wide single - spinning asymmetries may arise due to the interference of two amplitudes describing different helicities of quarks emitted from longitudinally polarized gluons in high - energy pp collisions . Such effects would violate parity conservation and therefore constitute evidence for recent science 13 .However , there exists only one previous measurement 14 of single - spinning asymmeties in hadronic dijet production at high energies . That experiment was carried out at RHIC 15 where the center - of - mass electricity per nucleon - nucleon collision √sNN = 200 GeV is much lower",
        "ori-fast-z-score": 0.43685202833051895,
        "water-fast-z-score": 7.077002858954407
    },
    {
        "original_text": "We consider the problem of finding an optimal first-order reduced basis space in the context of model reduction using Proper Orthogonal Decomposition (POD). We show that this can be achieved by solving a sequence of generalized eigenvalue problems associated with certain polynomials, which are derived from the original POD Galerkin formulation and its adjoint. The proposed approach is illustrated on two numerical examples. In particular we demonstrate how it allows to find a better approximation than standard greedy algorithms. This work was supported by EPSRC grant EP/K034494/1. Model reduction techniques have been widely used over recent years as efficient tools for reducing computational complexity when simulating complex physical systems governed by partial differential equations (PDEs)  1  . One popular class of methods relies on Proper Orthogonal Decompostion (POD), where one seeks to approximate the solution u(x, t) ∈ R N of a PDE system by projecting onto a low-dimensional subspace spanned by a set of orthonormal functions {φi(x)}Ni=1  2  , i.e.,",
        "watermark_text": "We consider the question of finding an efficient first - order reduced basis set in the context of model reduction using Proper Orthogonal Decomposition ( POD ) . We see that this can be obtained by handling a sequence of generalized eigenvalue difficulties related with certain polynomials , which are derived from the previous POD Galerkin approach and its adjoint .The proposed approach is depicted on two numerical examples . In particular we prove how it allows to find a better approximation than conventional greedy algorithms .This research was supported by EPSRC award EP / K034494 / 1 . Model reduction techniques have been widely using over recent years as efficient techniques for lowering computational difficulty when simulating complex physical networks defined by partial differential equations ( PDEs ) 1 .One popular family of methods relies on Proper Orthogonal Decompostion ( POD ) , where one seeks to approximate the solution u ( x , t ) ∈ R N of a PDE system by projecting onto a small - dimensional subspace covered by a group of orthonormal maps { φi ( x ) } Ni = 1 2 , i . e . ,",
        "ori-fast-z-score": 0.3418817293789138,
        "water-fast-z-score": 6.1942248145051675
    },
    {
        "original_text": "We report on our analysis of archival Chandra data for the galaxy cluster Sersic 159-03, which shows evidence for excess X-ray emission below 1 keV (the  soft-excess ). We find that this feature is not consistent with thermal bremsstrahlung or line emission associated with any known atomic species and conclude it must be due to some other process such as inverse Compton scattering by relativistic electrons. The observed spectrum can be fitted well using an absorbed power-law model plus a blackbody component at kT = 0.2 keV; however we show that this fit is statistically unacceptable when compared against more physically motivated models including a combination of Bremsstrahlung and inverse-Compton emission. In particular, we demonstrate that the inclusion of a second blackbody component improves the quality of the fits significantly over those obtained previously.  Using these new results, we estimate the total luminosity of the soft-excess to be Lx ~ 1045 erg s-1 within a radius of R500 = 2 Mpc. This value is comparable to the bolometric luminosities inferred for several nearby radio halos detected via their synchrotron emission.",
        "watermark_text": "We report on our analysis of archival Chandra data for the galaxy region Sersic 159 - 03 , which reveals proof for excess X - ray radiation below 1 keV ( the dark - excess ) . We see that this characteristic is not consistent with thermal bremsstrahlung or line emission associated with any observed atomic species and assume it must be due to some other mechanism such as inverse Compton absorption by relativistic electrons .The observed spectrum can be fitted well using an absorbed power - law model plus a blackbody component at kT = 0 . 2 keV ; however we show that this fit is statistically unacceptable when compared against more physically motivated models including a combination of Bremsstrahlung and inverse - Compton emission . In particular , we demonstrate that the inclusion of a second blackbody component improves the quality of the fits significantly over those obtained previously .Using these new data , we estimate the total luminosity of the soft - excess to be Lx ~ 1045 erg s - 1 within a diameter of R500 = 2 Mpc . This value is analogous to the bolometric luminosities inferred for numerous nearby radio halos detected via their synchrotron emission .",
        "ori-fast-z-score": -1.9629909152447274,
        "water-fast-z-score": 1.835325870964494
    },
    {
        "original_text": "The purpose of this study is to examine whether or not there are any differences between the distributions of firm size and profitability, using data on Japanese firms for the period from 1971 to 2000. The results show that both firm size and profitability follow a log-normal distribution with different parameters. In addition, it was found that the growth rate of firm size follows Gibrat s Law while that of profitability does not. This suggests that the relationship between firm size and profitability may be explained by the fact that they have different underlying processes. Finally, we find evidence supporting the hypothesis that the process generating firm size has changed over time. We also find some support for the hypothesis that the process governing profitability has changed over time. These findings suggest that the relationship between firm-size and profitability can change over time depending upon changes in their respective underlying processes. Keywords: Firm Size Distribution, Profitability Distribution",
        "watermark_text": "The purpose of this study is to examine whether or not there are any variations between the distributions of firm size and profitability , using data on Japanese businesses for the period from 1971 to 2000 . The results show that both firm height and profitability follow a log - normal distribution with various variables .In addition , it was shown that the growth probability of firm size follows Gibrat s Law while that of profitability does not . This implies that the relationship between firm scale and profitability could be explained by the fact that they have different intrinsic processes .Finally , we find proof confirming the notion that the process generating firm size has altered over time . We additionally find some evidence for the notion that the process governing profitability has altered over time .These studies demonstrate that the relationship between firm - structure and profitability can shift over time depending upon changes in their different underlying mechanisms . Keywords : Firm Size Distribution , Profitability Distribution",
        "ori-fast-z-score": -1.0834726777719228,
        "water-fast-z-score": 5.019960159204453
    },
    {
        "original_text": "We prove that if an operator is adjointable, then it has dense range in its domain.  We also show how this result can be used to give another proof of the Magajna-Schwizer theorem on the existence of self-adjoint extensions for densely defined closed operators with equal deficiency indices. Let H be a Hilbert space over C. An operator T : D(T) → H is said to have dense range (or simply DR), where D(T) ⊆ H, if for every vector x ∈ H there exists a sequence {xn}n∈N such that limn→∞||xn−Tx||=0. In other words, the image of T contains no proper subspace of H. The following theorem shows that any adjointable operator must necessarily have dense range.   THEOREM 1.1. If T:D(T)⊆H→H is adjointable, then R(T∗)=D(T).",
        "watermark_text": "We showed that if an operator is adjointable , then it has dense range in its domain . We also demonstrate how this fact can be used to give another proved of the Magajna - Schwizer theorem on the existence of self - adjoint extensions for tightly defined closed operators with equal deficiency indices .Let H be a Hilbert space over C . An operator T : D ( T ) → H is said to have dense range ( or simply DR ) , where D ( T ) ⊆ H , if for every matrix x ∈ H there exists a sequence { xn } n∈N such that limn→∞ | | xn−Tx | | = 0 . In other words , the image of T contains no complete subspace of H . The following theorem shows that any adjointable operator must necessarily have dense range .THEOREM 1.1.If T:D(T)⊆H→H is adjointable, then R(T∗)=D(T).",
        "ori-fast-z-score": 0.29488391230979427,
        "water-fast-z-score": 2.06418738616856
    },
    {
        "original_text": "We present new results on the X-ray spectrum and variability properties of Mrk 509, one of the brightest Seyfert galaxies observed by XMM-Newton. We find that its 0.5-10 keV continuum is well described by an absorbed power law with Γ = 2.1 ± 0.2 (χ2/dof=111/101) plus a reflection component modeled as a PEXRAV model with R=0.7-1.0 and NH=10-23×1022 cm-2. The best-fit parameters are consistent within errors to those found previously using Chandra data alone. No significant spectral changes were detected between different epochs separated by several months apart. However, we do detect strong flux variations at all energies during our observation period. In particular, there was a factor of 3 increase in the hard band count rate over about 20 ks followed by a slower decay back towards the initial level. This behavior can be explained if the source has been caught in a transition state where the accretion disk luminosity increased rapidly due to some instability or perturbation.",
        "watermark_text": "We report new data on the X - ray spectrum and variability properties of Mrk 509 , one of the brightest Seyfert galaxies studied by XMM - Newton . We see that its 0 . 5 - 10 keV continuum is well described by an absorption power law with Γ = 2 . 1 ± 0 . 2 ( χ2 / dof = 111 / 101 ) plus a mirror element modeled as a PEXRAV model with R = 0 . 7 - 1 . 0 and NH = 10 - 23×1022 centimetres - 2 .The best - fitting values are compatible within errors to those identified previously used Chandra data alone . No meaningful spectral changes were detected between various epochs separated by many months separated .However , we do discover powerful flux variations at all energies during our observation term . In particular , there was a factor of 3 shift in the hard band count rate over about 20 ks followed by a slower decay forward towards the first rate .This phenomenon can be understood if the source has been caught in a transfer state where the accretion disk luminosity increased rapidly due to some distortion or perturbation .",
        "ori-fast-z-score": -0.35603449745815596,
        "water-fast-z-score": 6.527299120066193
    },
    {
        "original_text": "We study the supersymmetry breaking patterns for vector multiplets transforming under non-adjoint representations of SO(N). We find that there are two distinct classes of theories, depending on whether or not the representation is real. In particular we show how to construct explicit examples with N = 1 and N = 2 supersymmetries which break all their supersymmetries spontaneously. Theories with adjoint matter fields can be obtained as special cases by taking appropriate limits. This work was supported in part by NSF grant PHY-0456735. Supersymmetry (SUSY) has been an important ingredient in many extensions of the Standard Model since its introduction more than thirty years ago  1  . It provides a natural solution to the hierarchy problem between the weak scale and the Planck scale  2  , while at the same time offering new ways to understand gauge coupling unification  3  .\nIn recent years it has become clear that SUSY must be broken if one wants to make contact with experiment  4  . However, despite much effort over several decades  5  -  8  , no fully satisfactory mechanism for spontaneous SUSY breaking exists yet  9  . One promising approach involves using supergravity  10  -  12  to generate soft terms  13  -  15  which then trigger SUSY breakdown  16  -  18  . Another possibility is to use extra dimensions  19  -  21  where SUSY is broken either explicitly  22  -  24  or spontaneously  25  -  27  via boundary conditions  28  -  30  . A third option is to consider models based on local symmetries  31  -  33  such as gauged  34  -  37  or global  38  -  41  SUSY.",
        "watermark_text": "We research the supersymmetry broken schemes for vector multiplets transforming under non - adjoint representations of SO ( N ) . We see that there are two different categories of theories , depending on whether or not the representation is real .In particular we prove how to build explicit examples with N = 1 and N = 2 supersymmetries which break all their supersymmetries spontaneously . Theories with adjoint matter varieties can be obtained as special cases by using appropriate restrictions .This project was supported in part by NSF grant PHY - 0456735 . Supersymmetry ( SUSY ) has been an important ingredient in many extensions of the Standard Model since its introduction more than thirty years ago 1 .It provides a natural solution to the ranking problem between the weakness scale and the Planck scale 2 , while at the same time providing new ways to comprehend gauge correlation unification 3 . In recent seasons it has become clear that SUSY must be broken if one wants to make contact with test 4 .However , despite much effort over numerous centuries 5 - 8 , no fully acceptable mechanism for premature SUSY broke exists yet 9 . One promising solution involves utilizing supergravity 10 - 12 to create soft terms 13 - 15 which then activate SUSY breakdown 16 - 18 .Another possibility is to use extra dimensions 19 - 21 where SUSY is beaten either explicitly 22 - 24 or spontaneously 25 - 27 via boundary rules 28 - 30 . A third possibility is to consider models built on local symmetries 31 - 33 such as gauged 34 - 37 or worldwide 38 - 41 SUSY .",
        "ori-fast-z-score": -0.2,
        "water-fast-z-score": 6.8657566124489255
    },
    {
        "original_text": "The Standard Model (SM) predicts the existence of new heavy particles, such as W and Z bosons that are responsible for weak interactions between quarks and leptons. The Large Hadron Collider experiments have searched for these particles in their data sets but no evidence has been found so far. In this work we present an analysis to look for heavy vector-like fermions decaying into pairs of charged or neutral gauge bosons using proton-proton collision data collected by ATLAS experiment during Run 1 period with center-of-mass energy √s=7 TeV corresponding to an integrated luminosity of 4.6 fb-1 . We consider two benchmark models where one is based on SU(2)LxU(1)Y gauge group while another model is based on SO(10). For both cases we perform a detailed simulation study to understand signal acceptance and background contributions. Using our results we set limits on production cross-section times branching ratio for different mass points ranging from 0.5 TeV to 3 TeV.",
        "watermark_text": "The Standard Model ( SM ) predicts the existence of new massive bodies , such as W and Z bosons that are responsible for weak interactions between quarks and leptons . The Large Hadron Collider experiments have searched for these ions in their information sets but no evidence has been detected so far .In this research we present an analysis to search for heavy vector - like fermions decaying into pairs of charged or neutral gauge bosons using proton - proton collision data taken by ATLAS program during Run 1 period with center - of - mass mass √s = 7 TeV corresponding to an integrated luminosity of 4 . 6 fb - 1 . We consider two benchmark versions where one is based on SU ( 2 ) LxU ( 1 ) Y gauge group while another model is based on SO ( 10 ) .For both cases we perform a detailed simulation study to explain signal availability and background contributions . Using our findings we setting limits on production cross - section times branching ratio for different mass points ranging from 0 . 5 TeV to 3 TeV .",
        "ori-fast-z-score": 0.8551861104941365,
        "water-fast-z-score": 4.677476657214644
    },
    {
        "original_text": "We study the stability of viscous shock waves for an ideal gas with viscosity and heat conduction, using the method of characteristics.  We show that if the initial data are sufficiently small then there exists a unique global solution to this problem which converges exponentially fast as t → ∞ towards the corresponding inviscid solution (the Rankine-Hugoniot condition). If the initial data have compact support we prove that the solution remains uniformly bounded on any finite time interval  0,T . Finally, under some additional assumptions about the initial data, we establish the exponential decay of solutions at infinity. The results obtained here generalize those known previously only for the case when the pressure p(ρ) = ρ γ , where 0 < γ ≤ 1.1. Viscous shock waves play important role in many physical phenomena such as combustion theory or plasma physics. In particular they appear in connection with the so-called Riemann problems describing the interaction between two different flows separated by a discontinuity surface. For example, one can consider the following problem:  Find a function u(x,t), x ∈ R n , t > 0 satisfying the system of equations",
        "watermark_text": "We research the stability of viscous blast currents for an suitable gas with viscosity and heat conduction , using the method of characteristics . We see that if the first data are sufficiently small then there exists a unique worldwide answer to this question which converges exponentially rapidly as t → ∞ towards the equivalent inviscid solving ( the Rankine - Hugoniot condition ) .If the first data have compact support we prove that the solve remains uniformly bounded on any finite time interval 0 , T . Finally , under some additional constraints about the initial data , we determine the exponential decay of solutions at infinity .The results derived here generalize those known previously only for the case when the pressure p ( ρ ) = ρ γ , where 0 < γ ≤ 1 . 1 . Viscous blast currents play important role in many mechanical phenomena such as combustion theory or plasma physics .In particular they appear in connection with the so - called Riemann problems regarding the interaction between two different flows divided by a discontinuity terrain . For instance , one can consider the following issue : Find a function v ( x , t ) , x ∈ R n , t > 0 satisfying the scheme of equations",
        "ori-fast-z-score": -1.078327732034384,
        "water-fast-z-score": 5.314796216557077
    },
    {
        "original_text": "We present an exact hierarchical description of the reduced state and dynamics of open quantum systems in terms of a set of coupled equations, which we call the Hierarchy of Density Tensors (HDT). The HDT is derived by applying the Nakajima-Zwanzig projection operator technique to the von Neumann equation describing the evolution of the total system. We show that this approach allows one to retrieve all relevant information about the environment-induced decoherence process on arbitrary timescales. In particular, it provides access to the full spectrum of relaxation rates characterizing the decay of off-diagonal elements of the reduced density matrix as well as the stationary states reached at late times. As an example, we apply our formalism to study the dissipative spin-boson model with Ohmic dissipation. Our results are compared against numerical simulations based on the Quantum Monte Carlo Wavefunction method. \nI. INTRODUCTORY REMARK\nThe understanding of how macroscopic objects behave under the influence of their environments has been a central issue in physics since its very beginning  1, 2  . This problem becomes particularly challenging when dealing with complex many-body systems such as condensed matter or biological ones  3, 4  , where the number of degrees of freedom involved can be extremely large. A powerful theoretical tool to tackle these problems consists in studying the dynamics of the reduced state of the system of interest S conditioned upon some specific measurement performed over the environmental degrees of freedom E  5, 6  .\nIn recent years there have been several attempts to develop efficient methods to describe the time-evolution of the reduced state  7, 8  . Among them, the so-called Hierarchy of Density Matrices (HDM)  9  represents a promising alternative to other approaches  10, 11  due to its ability to capture non-Markovian effects  12  . However, despite being able to provide accurate predictions for short-time evolutions  13  , the HDM fails to reproduce correctly the asymptotic behavior of the system  14  . To overcome this limitation, here we introduce a new formulation of the HDM, called Hierarchy of Density...",
        "watermark_text": "We create an precise hierarchical description of the reduced state and dynamics of open quantum systems in terms of a setting of coupled equations , which we call the Hierarchy of Density Tensors ( HDT ) . The HDT is calculated by using the Nakajima - Zwanzig projection operator technique to the von Neumann equation explaining the evolution of the total system .We see that this methodology allows one to locate all relevant information about the environment - caused decoherence process on arbitrary timescales . In particular , it gives access to the full range of relaxation frequencies characterizing the decay of off - diagonal elements of the reduced density matrix as well as the stationary states reached at late times .As an instance , we apply our formalism to study the dissipative spin - boson theory with Ohmic dissipation . Our results are compared against numerical simulations based on the Quantum Monte Carlo Wavefunction method .I . INTRODUCTORY REMARK The knowledge of how macroscopic objects react under the impact of their environments has been a central topic in physics since its very beginning 1 , 2 .This problem appears particularly challenging when dealing with difficult large - bodies systems such as condensed matter or biological ones 3 , 4 , where the quantity of degrees of freedom employed can be extremely huge . A good experimental tool to tackle these problems involves in examining the dynamics of the reduced state of the system of interest S conditioned upon some specific assessment performed over the environmental degrees of liberty E 5 , 6 .In past decades there have been numerous attempts to develop able methods to explain the period - progression of the reduced state 7 , 8 . Among them , the so - called Hierarchy of Density Matrices ( HDM ) 9 offers a successful approach to other methods 10 , 11 due to its able to capture non - Markovian effects 12 .However , despite being able to provide accurate forecast for short - time evolutions 13 , the HDM fails to predict correctly the asymptotic behavior of the system 14 . To solve this limitation , here we incorporate a new implementation of the HDM , entitled Hierarchy of Density . . .",
        "ori-fast-z-score": -0.40961596025952024,
        "water-fast-z-score": 7.675067860720625
    },
    {
        "original_text": "We present new spectroscopic observations for nine cataclysmic variable stars (CVs) obtained with the HIRES spectrograph on Keck I telescope in Hawaii, and compare them to previous results. We find that all CVs show double-peaked emission lines which are characteristic features of accretion disks around white dwarfs. The line profiles change dramatically during outburst phases when mass transfer rates increase by several orders of magnitude compared to quiescent states. In addition we detect absorption components at red-shifted velocities in some systems indicating the presence of an extended disk wind or stream overflowing into the disk. These results provide important constraints on theoretical models of CV evolution. \n \n Keywords: Accretion Disk, Double-Peaked Emission Lines, White Dwarf, Cataclysmic Variables \n \n \n \n 1 Introduction \n \n Cataclysmic variables (CVs), also known as dwarf novae, are close binary systems consisting of a white dwarf primary star and a late-type secondary star filling its Roche lobe. Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it forms an accretion disk surrounding the compact object. This process leads to periodic outbursts caused by thermal instabilities in the accretion disk resulting in dramatic changes in luminosity over time scales ranging from hours up to years  1  . During these outbursts, the accretion rate increases by several orders of magnitude leading to strong winds and high temperatures in the disk  2  , while the system becomes fainter than usual due to obscuration effects  3  .\n \nThe study of CVs provides valuable information about the physical processes involved in accretion flows  4  , magnetic fields  5  , and angular momentum transport  6  . Furthermore, they can be used as distance indicators  7, 8  and probes of galactic structure  9  . \n \n 2 Observations & Data Reduction \n \n Our sample consists of 9 CVs observed between 2004 and 2007 using the High Resolution Echelle Spectrometer (HIRES)  10  mounted on the 10 m Keck I telescope located on Mauna Kea",
        "watermark_text": "We introduce novel spectroscopic observations for nine cataclysmic variable stars ( CVs ) obtained with the HIRES spectrograph on Keck I telescope in Hawaii , and compare them to previous findings . We see that all CVs show dual - peaked emission lines which are peculiar characteristics of accretion disks around white dwarfs .The line profiles change dramatically during outburst phases when mass transfer rates increase by many orders of magnitude compared to quiescent states . In addition we perceive absorption elements at red - shifted velocities in some systems suggesting the presence of an extended disk dust or stream overflowing into the disk .These conclusions provide important restrictions on theoretical theories of CV evolution . Keywords : Accretion Disk , Double - Peaked Emission Lines , White Dwarf , Cataclysmic Variables 1 Introduction Cataclysmic variables ( CVs ) , sometimes called as dwarf novae , are open binary complexes consisting of a black dwarf secondary star and a early - class secondary star occupying its Roche lobe .Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it creates an accretion disk surrounding the compact body . This process results to periodic outbursts caused by temperature instabilities in the accretion disk resulting in spectacular changes in luminosity over time ranges ranging from hours up to days 1 .During these outbursts , the accretion rate grows by many orders of magnitude resulting to powerful storms and rising heat in the disk 2 , while the system gets fainter than usual thanks to obscuration effects 3 . The investigation of CVs provides valuable info about the physical processes responsible in accretion movements 4 , magnetic waves 5 , and spatial velocity transport 6 .Furthermore , they can be used as distance indicators 7 , 8 and probes of galactic structure 9 . 2 Observations & Data Reduction Our specimen consists of 9 CVs seen between 2004 and 2007 utilizing the High Resolution Echelle Spectrometer ( HIRES ) 10 installed on the 10 m Keck I telescope located on Mauna Kea",
        "ori-fast-z-score": -1.0215078369104984,
        "water-fast-z-score": 8.057794831959724
    },
    {
        "original_text": "We present an analysis of synthetic stellar libraries used to calibrate photometric surveys, such as Gaia and LSST. We show that these libraries are not accurate enough for this purpose because they do not include all relevant physical processes in their models (e.g., convection). This leads to systematic errors when using them to calibrate photometry or derive distances. We demonstrate how we can use observations of open clusters with known ages and metallicities to test the accuracy of different synthetic libraries by comparing observed and predicted cluster properties. Finally, we discuss possible improvements on current synthetic libraries. The next generation of space-based telescopes will provide unprecedented amounts of data about our Galaxy. These new datasets require large efforts to be analyzed properly. One important aspect is the calibration of photometric surveys like Gaia and LSST which will deliver precise astrometry and multi-color photometry for billions of stars across the sky. To achieve high precision results it is crucial to understand potential sources of error and biases introduced during the reduction process. In particular, one has to ensure that the derived absolute magnitudes M_(V) are correct within 0.01 mag over most of the color range covered by the survey. \n \n For example, if the distance modulus DM = 5log10(d/d_sun), where d is the true distance between us and the star and d_sun is the Sun’s distance from Earth, then a difference of 0.01 mag corresponds to a factor of 1.1 in distance. Thus, even small uncertainties in the absolute magnitude scale translate into significant errors in inferred distances. Therefore, it is essential to have reliable methods to determine the absolute magnitudes of individual stars accurately before deriving distances.  \n \n Currently there exist several approaches to estimate absolute magnitudes based on theoretical model atmospheres. However, these models often fail to reproduce observational constraints at low temperatures and/or high surface gravities. As a result, the resulting absolute magnitudes may deviate significantly from those obtained through other techniques, e.g., eclipsing binaries. Moreover, some of these models also suffer from incomplete",
        "watermark_text": "We present an assessment of synthetic astronomical collections useful to calibrate photometric surveys , such as Gaia and LSST . We suggest that these archives are not accurate sufficient for this objective because they do not include all relevant physical processes in their models ( e . g . , convection ) .This leads to systematic errors when using them to calibrate photometry or calculate distances . We showed how we can using observations of open nuclei with established periods and metallicities to test the accuracy of different synthetic databases by comparing observed and anticipated cluster structures .Finally , we discuss possible advances on current artificial libraries . The future wave of space - based telescopes will provide incredible amounts of data about our Galaxy .These new datasets take great efforts to be analyzed correctly . One important milestone is the calibration of photometric surveys like Gaia and LSST which will provide accurate astrometry and multi - color photometry for billions of stars across the sky .To achieve high clarity findings it is crucial to realize potential sources of mistake and biases created during the reduction step . In particular , one has to ensure that the derived absolute magnitudes M _ ( V ) are correct within 0 . 01 mag over most of the color spectrum encompassed by the poll .For instance , if the distance modulus DM = 5log10 ( d / d _ sun ) , where d is the true distance between us and the star and d _ sun is the Sun ’ s distance from Earth , then a difference of 0 . 01 mag corresponds to a factor of 1 . 1 in distance . Thus , even minor uncertainties in the absolute magnitude scale turn into considerable errors in inferred distances .Therefore , it is crucial to have reliable techniques to estimate the absolute magnitudes of individual stars accurately before deriving distances . Currently there remain many approaches to estimate absolute magnitudes based on theoretical model atmospheres .However , these models often fail to reproduce observational restrictions at low temperatures and / or large depth gravities . As a outcome , the resulting absolute magnitudes might deviate greatly from those achieved through other techniques , e . g . , eclipsing binaries .Moreover , some of these models even suffer from incomplete",
        "ori-fast-z-score": -1.784435632438388,
        "water-fast-z-score": 6.871842709362768
    },
    {
        "original_text": "The authors have used scanning tunneling microscopy to study the surface structure and electronic properties of single crystals of the high-temperature cuprate superconductor Bi2Sr2CaCu2O8+d (Bi-2212). They find that, at low temperatures, this material forms pairs of holes which are bound together by an attractive interaction mediated by phonons. The binding energy is found to be about 0.5 eV per hole pair. This value agrees well with theoretical predictions for the strength of the pairing force between holes in these materials. \n \n In addition, they observe that the density of states near the Fermi level shows a strong dependence on the direction along which the crystal is cut. For example, when the crystal is cleaved parallel to its Cu-O planes, it exhibits a large peak in the density of states just below the Fermi level. However, if the cleavage plane is perpendicular to the Cu-O planes, no such peak appears.",
        "watermark_text": "The authors have utilized scanning tunneling microscopy to study the surface structure and electronic properties of single crystals of the high - temperature cuprate superconductor Bi2Sr2CaCu2O8 + d ( Bi - 2212 ) . They find that , at low temperatures , this metal creates sets of holes which are bound together by an attractive interaction mediated by phonons .The interaction power is found to be about 0 . 5 eV per hole pair . This value agrees well with theoretical expectations for the strength of the pairing force between holes in these structures .In addition , they demonstrate that the density of states near the Fermi level exhibits a large dependence on the direction along which the crystal is cutting . For instance , when the crystal is cleaved parallel to its Cu - O planes , it displays a large peak in the density of states just below the Fermi level .However , if the cleavage plane is perpendicular to the Cu - O axes , no such peak appears .",
        "ori-fast-z-score": 2.75,
        "water-fast-z-score": 6.4007575309253015
    },
    {
        "original_text": "We present fitting formulae for the illumination of accretion disks by hot spots, as seen in Schwarzschild and rotating black holes (Kerr). The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton scattering. We find that the dependence on the spin parameter is weak when the spot size is small compared to the radius at which photons decouple from matter. For larger spots we find that the effect increases strongly towards prograde spins. Our results can be used to estimate the effects of relativistic Doppler boosting and gravitational lensing on observed spectra. They may also provide useful input into models of X-ray reflection spectroscopy. \nIntroduction\n\nAccreting black holes produce bright emission lines in their X-ray spectrum due to reprocessing of hard X-rays emitted near the event horizon by cold material orbiting close to the equatorial plane. These features have been studied extensively over many years both observationally and theoretically (see Reynolds & Nowak 2003 , Done et al 2004 . In particular, they show strong red-shifts indicating that the emitting gas orbits rapidly around the black hole. This rapid rotation causes additional shifts in energy due to relativistic Doppler boosts and gravitational lensing. Relativistic effects become more important if the emitting region has a high degree of rotational support or is viewed nearly face-on. It is therefore necessary to take these effects into account when interpreting observations of such systems. \n\nIn this work we consider the case where the illuminating source is located above the disk surface but below its photosphere. Such sources include magnetic flares produced within the disk itself or active regions associated with the inner edge of the disk. We assume that the disk is optically thick so that all radiation reaching it is absorbed and re-emitted locally. We use Monte Carlo simulations to calculate the emergent flux from the disk under various assumptions about the geometry of the system.\n\nThe main goal of our study was to develop simple analytical expressions describing how the shape of the line profile depends on the properties of the system. To do this we performed extensive numerical calculations covering a wide range",
        "watermark_text": "We present fitting formulae for the illumination of accretion disks by hot spots , as shown in Schwarzschild and rotating black holes ( Kerr ) . The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton absorption .We see that the dependence on the spin vector is weak when the spot size is tiny relative to the radius at which photons decouple from matter . For larger spots we find that the impact grows highly towards prograde spins .Our results can be used to estimate the effects of relativistic Doppler boosting and gravity lensing on measured spectra . They might additionally offer useful input into estimates of X - ray reflection spectroscopy .Introduction Accreting black holes create bright emission lines in their X - ray spectrum due to reprocessing of hard X - rays generated near the event horizon by cold matter orbiting close to the equatorial plane . These features have been studied frequently over numerous years both observationally and theoretically ( saw Reynolds & Nowak 2003 , Done et al 2004 .In particular , they show intense red - shifts suggesting that the emitting gas orbits rapidly around the dark hole . This rapid rotation creates additional shifts in energy due to relativistic Doppler boosts and gravity lensing .Relativistic effects become more essential if the emitting area has a high degree of rotational support or is viewed virtually face - on . It is consequently required to take these consequences into consideration when interpreting observations of such systems .In this research we imagine the case where the illuminating source is situated above the disk boundary but below its photosphere . Such sources include magnetic flares created within the disk itself or active regions associated with the inner boundary of the disk .We assume that the disk is optically dense so that all light reaching it is absorption and re - radiated locally . We use Monte Carlo simulations to estimate the emergent flux from the disk under various statements about the topology of the system .The main goal of our research was to develop primitive analytical expressions relating how the form of the line profile depends on the properties of the system . To do this we performed extensive numerical measurements encompassing a broad range",
        "ori-fast-z-score": -0.1543033499620919,
        "water-fast-z-score": 8.076923076923077
    },
    {
        "original_text": "We report the discovery and characterization of USco 1606-1935, an unusually wide low-mass triple system with two M-dwarfs orbiting each other in a ~2 year period at a distance of about 100 AU (~33 light years). The third component is a late K-type star that orbits both stars on a much wider scale, with a minimum mass for this companion of 0.7 solar masses. We present near-infrared spectroscopy to determine the spectral types of all three components as well as their radial velocities. Our results show that the inner binary has a total mass of only 0.3 solar masses, making it one of the lowest-mass binaries known. This makes USco 1606-1935 an ideal target for future studies of planet formation around very-low-mass stars. In addition, we find evidence for significant orbital eccentricity in the outer orbit which may be caused by tidal interactions between the close pair and its distant tertiary companion.",
        "watermark_text": "We report the discovery and characterization of USco 1606 - 1935 , an exceptionally wide low - mass triple system with two M - dwarfs orbiting each other in a ~ 2 week period at a distance of about 100 AU ( ~ 33 light years ) . The third component is a early K - class star that orbits both stars on a far larger scale , with a minimum mass for this companion of 0 . 7 solar masses .We present near - infrared spectroscopy to obtain the spectral classes of all three components as also as their radial velocities . Our results show that the inner binary has a total mass of only 0 . 3 solar masses , making it one of the smallest - energy binaries discovered .This gives USco 1606 - 1935 an suitable target for future research of planet development around very - low - weight stars . In addition , we find proof for significant orbital eccentricity in the exterior orbit which may be caused by tidal interactions between the close pair and its closest primary companion .",
        "ori-fast-z-score": -1.7320508075688772,
        "water-fast-z-score": 3.2118202741878643
    },
    {
        "original_text": "We present new photometry for the globular cluster NGC 1904, obtained with the Wide Field Camera 3 (WFC3) on board HST in four filters spanning the optical and near-infrared wavelength range. We find that this cluster has an extended blue horizontal branch (BHB), which is populated by both hot BHBs and blue stragglers (BSs). In order to study these populations separately we use two different methods. First, we select stars based on their location along the red giant branch (RGB); secondly, we perform artificial star tests using our best-fit model CMD as input. Both approaches yield consistent results. Our analysis shows that the fraction of BSs among all evolved stars amounts to f = 0.11 ± 0.01. This value agrees well with previous studies of other clusters. Using theoretical models we estimate the age of the cluster at t = 12 Gyr.",
        "watermark_text": "We present new photometry for the globular cluster NGC 1904 , obtained with the Wide Field Camera 3 ( WFC3 ) on board HST in four filters covering the optical and far - infrared frequency range . We see that this cluster has an extended blue horizontal branch ( BHB ) , which is populated by both hot BHBs and green stragglers ( BSs ) .In order to study these populations individually we utilize two different methods . First , we choose galaxies based on their placement along the red giant branch ( RGB ) ; secondly , we perform artificial star tests utilizing our good - fitting model CMD as input .Both approaches yield consistent conclusions . Our study shows that the fraction of BSs among all evolved stars amounts to f = 0 . 11 ± 0 . 01 .This value agrees well with previous research of other clusters . Using theoretical methods we estimate the age of the cluster at t = 12 Gyr .",
        "ori-fast-z-score": 1.3242443839434612,
        "water-fast-z-score": 5.093248125762992
    },
    {
        "original_text": "We study the structure of the stationary distribution for an asymmetric version of the Target Process (TP). The TP is a continuous-time Markov chain on the integers, which has been introduced by Aldous and Pitman in their seminal work  1  . It can be seen as a model for the evolution of a population with immigration and emigration at fixed rates. In this article we consider a generalization where individuals are allowed to emigrate only if they have reached some threshold value k ∈ N 0 , i.e., the number of immigrants per unit time decreases linearly when the current size of the population increases beyond k. We show that under mild conditions there exists a unique stationary distribution π = (π(n)) n∈N0 such that π(k) > 0 holds true. Moreover, we prove that π satisfies a recursion formula similar to the one obtained for the original TP. Finally, we provide explicit expressions for π(1), ..., π(k+1).\nKeywords: Asymmetric target process, Stationary distribution",
        "watermark_text": "We explore the structure of the stationary distribution for an asymmetric version of the Target Process ( TP ) . The TP is a continuous - time Markov chain on the integers , which has been proposed by Aldous and Pitman in their seminal study 1 .It can be viewed as a description for the evolution of a population with immigration and emigration at fixed rates . In this paragraph we imagine a generalization where persons are allowed to emigrate only if they have achieved some threshold quantity k ∈ N 0 , i . e . , the quantity of aliens per unit time decreases linearly when the present size of the population rises beyond k . We see that under mild conditions there exists a unique stationary function π = ( π ( p ) ) n∈N0 such that π ( k ) > 0 holds true .Moreover , we prove that π satisfies a recursion formula analogous to the one achieved for the original TP . Finally , we provide explicit expressions for π ( 1 ) , . . . , π ( k + 1 ) .Keywords: Asymmetric target process, Stationary distribution",
        "ori-fast-z-score": -0.8819171036881969,
        "water-fast-z-score": 3.810003810005715
    },
    {
        "original_text": "We study the zero temperature (ground state) properties of the two-dimensional spin-glass model with nearest-neighbor interactions using an evolutionary algorithm, called genetic embedded matching heuristic (GEMH). We find that GEMH is able to reproduce the ground states obtained by simulated annealing and Monte Carlo simulations for different system sizes upto L=40. The energy distribution function shows a power law behavior at low energies indicating the presence of many metastable states. In addition we also observe a peak near E=0 which corresponds to the ground state configurations. Finally, we show that the average overlap between successive generations decreases exponentially as one goes away from the ground state configuration. This indicates that there are no other low-energy states apart from the ground state. \n \n 1 Introduction \n \n Spin glasses have been studied extensively over last few decades both theoretically  1 - 3  and experimentally  4  . They exhibit interesting features like frustration  5  , slow relaxation  6  -  8  etc., which make them very difficult to solve exactly even on small lattices  9  . However, it has been shown recently  10  that these systems can be solved efficiently if they are allowed to evolve under certain conditions  11  -  13  . Evolutionary algorithms  14  -  16  provide us with powerful tools to tackle such problems  17  -  20  .\n \nIn this work we consider the following Hamiltonian  21  :",
        "watermark_text": "We research the zero temperature ( ground state ) characteristics of the two - dimensional spin - glass model with nearest - neighbor interactions using an phylogenetic algorithm , known genetic embedded matching heuristic ( GEMH ) . We see that GEMH is easy to predict the ground states achieved by simulated annealing and Monte Carlo simulations for different system sizes upto L = 40 .The energy distribution function shows a power law behavior at low energies indicating the presence of several metastable elements . In addition we also observe a peak near E = 0 which corresponds to the ground state structures .Finally , we find that the average overlap between successive generations decreases exponentially as one goes away from the ground state configuration . This implies that there are no other low - energy states aside from the ground state .1 Introduction Spin windows have been studied frequently over next few years both theoretically 1 - 3 and experimentally 4 . They display curious features like frustration 5 , slow relaxation 6 - 8 etc . , which make them very difficult to complete exactly especially on small lattices 9 .However , it has been shown lately 10 that these systems can be answered easily if they are allowed to evolve under certain conditions 11 - 13 . Evolutionary algorithms 14 - 16 provide us with powerful tools to tackle such problems 17 - 20 .In this study we consider the following Hamiltonian 21 :",
        "ori-fast-z-score": 0.9805806756909202,
        "water-fast-z-score": 5.952990444986052
    },
    {
        "original_text": "We present results on dust formation in primordial supernova remnants (SNRs) using three-dimensional hydrodynamic simulations with detailed chemical networks for gas-phase species, grains, and molecules. We find that dust can form efficiently in SNR ejecta at high temperatures (T > 1000 K), but it is destroyed by sputtering due to collisions between ions and electrons when the temperature drops below T = 100 K. The surviving dust grains are injected into the interstellar medium (ISM). Our calculations show that the total mass of dust formed in primordial SNRs may reach up to 10^-4 Msun if we assume an initial metallicity Z = 0.1Zsun. This value agrees well with observations of nearby young SNRs. However, our model predicts too much carbonaceous dust compared to silicates observed in these objects. If this discrepancy persists after further improvements of the models, then some other mechanism should be responsible for producing silicates in SNRs. \n \n Keywords: dust, supernova remnant",
        "watermark_text": "We report findings on dust development in primordial supernova remnants ( SNRs ) using three - dimensional hydrodynamic simulations with complete biological networks for gas - phase species , grains , and molecules . We see that matter can form efficiently in SNR ejecta at high temperatures ( T > 1000 K ) , but it is destroyed by sputtering due to collisions between electrons and electrons when the temperature falls below T = 100 K . The remaining powder grains are pumped into the interstellar medium ( ISM ) .Our calculations show that the total mass of dust formed in primordial SNRs might reach up to 10 ^ - 4 Msun if we suppose an initial metallicity Z = 0 . 1Zsun . This value agrees well with observations of distant new SNRs .However , our model predicts too much carbonaceous powder compared to silicates observed in these objects . If this discrepancy persists after further changes of the models , then some other mechanism should be responsible for producing silicates in SNRs .Keywords : dust , supernova remnant",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 4.737364557517151
    },
    {
        "original_text": "We present results for the chemical composition and temperature structure of two different models of dense molecular clouds, which are based on detailed microphysical calculations including gas-grain interactions. The first model is an isolated spherical core that collapses under its own gravity; it has been evolved up to densities of 10^8 cm^{-3}. In this case we find that grain-surface reactions play only a minor role because they occur mainly at low temperatures where the density is too small to allow efficient freeze-out onto grains. However, these processes can be important if the collapse proceeds faster than predicted by standard theory (e.g., due to magnetic fields). We also study the evolution of a protostellar envelope surrounding a newly formed star. Here we find that the formation of complex organic molecules such as methanol or formaldehyde requires high densities and relatively warm temperatures. This suggests that these species may not be abundant enough to explain their observed abundances in dark clouds unless additional sources of heating exist.",
        "watermark_text": "We present results for the chemical composition and heat composition of two different models of dense molecular clouds , which are based on extensive microphysical calculations including gas - grain interactions . The first theory is an exposed convex core that collapses under its own gravitational ; it has been evolved up to densities of 10 ^ 8 cm ^ { - 3 } .In this situation we find that grain - boundary reactions serve only a minor importance because they occur primarily at low temperatures where the density is too small to allow efficient freeze - out onto grains . However , these mechanisms can be crucial if the dissolution proceeds faster than expected by traditional physics ( e . g . , owing to magnetic fields ) .We also study the evolution of a protostellar envelope surrounding a newly established star . Here we find that the formation of complex organic particles such as methanol or formaldehyde involves large densities and fairly heated temperatures .This implies that these species may not be abundant enough to explain their observed abundances in dark clouds unless additional sources of heating exist .",
        "ori-fast-z-score": 1.0540925533894598,
        "water-fast-z-score": 6.041987916036252
    },
    {
        "original_text": "The equilibrium fluctuations in isolated systems are studied by using statistical mechanics and information theory. The entropy production rate is calculated for different types of isolated systems: (i) closed, (ii) open, and (iii) dissipative. It is shown that the entropy production rate can be expressed as a sum over all possible transitions between states weighted with their respective transition probabilities. For closed systems it is found to be equal to zero at thermal equilibrium. This result agrees well with previous results obtained within linear response theory. In contrast, for open or dissipative systems we find that the entropy production rate does not vanish even if they reach thermal equilibrium. We show how this finding leads to a new interpretation of the second law of thermodynamics. Finally, we discuss our findings in terms of fluctuation theorems. PACS: 05.45.Mt, 02.10.Yn, 03.65.Ta Keywords: Entropy Production Rate, Second Law of Thermodynamics",
        "watermark_text": "The balance fluctuations in isolated systems are studied by using statistical mechanics and information theory . The entropy production level is calculated for different kinds of isolated systems : ( i ) closed , ( ii ) open , and ( iii ) dissipative .It is seen that the entropy production efficiency can be written as a sum over all possible transitions between states weighted with their respective change probabilities . For closed systems it is found to be equal to zero at heat equilibrium .This result agrees well with previous findings obtained within linear behavior analysis . In comparison , for closed or dissipative environments we find that the entropy production level does not vanish even if they reach thermal equilibrium .We see how this fact leads to a new explanation of the second law of thermodynamics . Finally , we talk our findings in terms of fluctuation theorems .PACS: 05.45.Mt, 02.10.Yn, 03.65.Ta Keywords: Entropy Production Rate, Second Law of Thermodynamics",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 4.83735464897913
    },
    {
        "original_text": "We analyze the non-Gaussianity in the temperature fluctuations of the Wilkinson Microwave Anisotropy Probe (WMAP) first year sky maps using three different estimators, namely Minkowski Functionals (MF), genus curve and correlation functions. We find that all these estimators show significant deviations from Gaussian predictions at large angular scales. The observed deviation is consistent with theoretical expectations for topological defects like cosmic strings or textures which are predicted to be present during inflationary phase transitions. These results provide further support for the presence of primordial non-Gaussianities in CMB anisotropies. This work was supported by the Department of Atomic Energy under grant No. 06(B)/ST-IISc/04. The authors thank Sourav Chatterjee for useful discussions. PACS numbers: 98.80.Cq, 95.35.+d, 04.20.Jb  Keywords: Cosmic microwave background radiation",
        "watermark_text": "We evaluate the non - Gaussianity in the temperature fluctuations of the Wilkinson Microwave Anisotropy Probe ( WMAP ) first year sky mapping utilizing three different estimators , namely Minkowski Functionals ( MF ) , genus curve and correlation functions . We see that all these estimators exhibit substantial deviations from Gaussian predictions at large angular scales .The observed deviation is compatible with theoretical expectations for topological errors like cosmic strings or textures which are expected to be present during inflationary phase transitions . These data provide further evidence for the presence of primordial non - Gaussianities in CMB anisotropies .This project was supported by the Department of Atomic Energy under grant No . 06 ( B ) / ST - IISc / 04 .The authors praised Sourav Chatterjee for useful talks . PACS codes : 98 . 80 . Cq , 95 . 35 . + d , 04 . 20 . Jb Keywords : Cosmic microwave background radiation",
        "ori-fast-z-score": 0.5897678246195885,
        "water-fast-z-score": 5.013026509266503
    },
    {
        "original_text": "We study the representations of tame quivers with relations, which are finite-dimensional algebras over an algebraically closed field k. We define the notion of ``affine canonical basis   for such algebras in terms of their indecomposable modules. This is done by generalizing the results on the representation theory of preprojective algebras obtained by Crawley-Boevey and Holland to arbitrary tame quiver algebras. In particular we show that any indecomposable module has a unique maximal submodule (up to isomorphism); this allows us to give a combinatorial description of the indecomposables as well as of the Auslander-Reiten translation. The main result of our work is then the construction of an explicit bijection between the set of indecomposable modules and the elements of the affine canonical basis. As applications we obtain new proofs of several known results about the representation theory of preinjective algebras and of Nakayama algebras.",
        "watermark_text": "We research the representations of tame quivers with relations , which are finite - dimensional algebras over an algebraically shut field k . We define the notion of ` ` affine canonical representation for such algebras in terms of their indecomposable algebra . This is accomplished by generalizing the results on the representation theory of preprojective algebras achieved by Crawley - Boevey and Holland to arbitrary tame quiver algebras .In particular we prove that any indecomposable module has a unique maximal submodule ( up to isomorphism ) ; this enables us to give a combinatorial description of the indecomposables as well as of the Auslander - Reiten translation . The main consequence of our work is then the creation of an explicit bijection between the group of indecomposable modules and the elements of the affine canonical representation .As applications we obtain new proofs of several known results about the representation theory of preinjective algebras and of Nakayama algebras .",
        "ori-fast-z-score": 0.7293249574894728,
        "water-fast-z-score": 4.230084753438942
    },
    {
        "original_text": "We present an analysis of the correlation between radio sources in the southern sky with angular scales greater than 1 degree, and the temperature fluctuations observed by Wilkinson Microwave Anisotropy Probe (WMAP). We find that there is no significant correlation at large angular separations for any individual source population or combination thereof. However, we do detect a statistically significant cross-correlation signal when all extragalactic point sources are combined into one sample. The amplitude of this signal is consistent with theoretical predictions based on the Sunyaev-Zel dovich effect. This result suggests that the cold spot may be due to a superposition of many unresolved SZ clusters along our line-of-sight. In addition, we show that the lack of correlation seen individually among different populations can be explained if these populations have differing spectral indices and/or luminosity functions. Finally, we demonstrate how the results presented here could be used as a testbed for future experiments such as Planck Surveyor.",
        "watermark_text": "We present an assessment of the relationship between radio sources in the southern sky with angular scales greater than 1 degree , and the temperature fluctuations detected by Wilkinson Microwave Anisotropy Probe ( WMAP ) . We see that there is no considerable relationship at large angular separations for any individual source population or combination thereof .However , we do discover a statistically substantial cross - correlation signal when all extragalactic point bodies are united into one sample . The amplitude of this signal is compatible with theoretical estimates based on the Sunyaev - Zel dovich phenomenon .This result suggests that the cool spot may be due to a superposition of several unresolved SZ clusters along our line - of - seeing . In addition , we find that the lack of correlation seen individually among different populations can be described if these populations have differing brightness indices and / or luminosity functions .Finally , we prove how the papers presented here possible be used as a testbed for future research such as Planck Surveyor .",
        "ori-fast-z-score": 1.3242443839434612,
        "water-fast-z-score": 7.002011783343734
    },
    {
        "original_text": "We report on the discovery and analysis of XMM-Newton observations of an uncatalogued, extremely faint X-ray source (X-ray luminosity < 1031 erg s-1) in the Galactic plane at l = 28 deg., b = 0.5 deg.. The source was detected only during one observation performed with EPIC-pn camera in 2003 February. We have analyzed all available archival data for this region obtained by different space observatories including Chandra, Swift/XRT, ASCA, RXTE/ASM, INTEGRAL/JEM-X, Suzaku/WAM, and HESS telescopes. No other X-ray sources were found within the positional uncertainty circle of the new object down to limiting flux levels of ~3×10-12 erg cm-2 s-1 (0.2-10 keV). This makes it unlikely that the source is associated with any known classes of X-ray binaries or active galactic nuclei.",
        "watermark_text": "We report on the discovery and assessment of XMM - Newton discoveries of an uncatalogued , incredibly faint X - ray source ( X - ray luminosity < 1031 erg s - 1 ) in the Galactic jet at l = 28 deg . , b = 0 . 5 deg . . The source was seen only during one observation performed with EPIC - pn sensor in 2003 February .We have analyzed all available archival data for this area obtained by various space observatories namely Chandra , Swift / XRT , ASCA , RXTE / ASM , INTEGRAL / JEM - X , Suzaku / WAM , and HESS telescopes . No other X - ray bodies were found within the positional uncertainty arc of the new object down to limiting flux levels of ~ 3×10 - 12 erg centimetres - 2 s - 1 ( 0 . 2 - 10 keV ) .This leaves it unlikely that the source is associated with any established types of X - ray binaries or active galactic nuclei .",
        "ori-fast-z-score": -0.5897678246195885,
        "water-fast-z-score": 4.718142596956708
    },
    {
        "original_text": "We present an algorithm for unicast and multicast quality-of-service (QoS) routing in the Internet using soft constraint logic programming (SCLP). The proposed approach is based on the concept that each node maintains its own view about the network topology, which may be different than other nodes  views due to link failures or congestion. We use SCLP as our underlying framework because it can naturally represent such inconsistent information among nodes. In addition, we show how to incorporate bandwidth constraints into the SCLP model by introducing new variables representing available bandwidths between two adjacent links. Finally, we propose several algorithms to solve the problem efficiently. Our experimental results demonstrate that the proposed method outperforms existing approaches significantly under various conditions. Keywords: Quality-of-Service, Constraint Logic Programming, Bandwidth Allocation, Network Optimization, Link Failure, Congestion Control, Internet Service Provider, Unicast",
        "watermark_text": "We present an algorithm for unicast and multicast quality - of - service ( QoS ) routing in the Internet employing soft constraint logic programming ( SCLP ) . The proposed approach is based on the idea that each node maintains its own view about the network topology , which may be changed than other nodes views due to link faults or congestion .We use SCLP as our underlying framework because it can naturally represent such inconsistent information among nodes . In addition , we study how to insert bandwidth constraints into the SCLP model by using new parameters representing available bandwidths between two adjacent links .Finally , we present many algorithms to solve the issue quickly . Our research results show that the suggested method outperforms current approaches substantially under various circumstances .Keywords: Quality-of-Service, Constraint Logic Programming, Bandwidth Allocation, Network Optimization, Link Failure, Congestion Control, Internet Service Provider, Unicast",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "We report the first experimental demonstration of two-electron interference in an electron microscope, using a novel technique to produce and detect entangled pairs of spatially separated electrons. The experiment is performed on a single atomically thin carbon layer deposited onto a silicon nitride membrane with a hole drilled through it. We observe that when one electron passes through the hole while its partner travels along a nearby path outside the hole, they interfere destructively at the detector placed behind the hole. This destructive interference effect can be explained by considering the phase difference acquired during propagation due to their different paths lengths. Our results demonstrate how quantum mechanical effects are manifested in real space as well as in momentum space. \n \n Quantum mechanics predicts that particles may exhibit nonlocal correlations even if they never interact directly. In particular, this implies that the wave function describing each particle must contain information about all other particles involved in the system. Such nonlocality has been demonstrated for photons1–3 but not yet for massive particles such as electrons or atoms4–6. Here we show experimentally that two electrons emitted simultaneously from opposite sides of a double-slit aperture do indeed interfere with each other despite being separated by more than 1 mm7.",
        "watermark_text": "We report the first laboratory trial of two - atom interference in an electron microscope , using a innovative method to produce and locate entangled pairs of spatially separated electrons . The observation is conducted on a single atomically thin carbon coating collected onto a silicon nitride layer with a gap drilled through it .We see that when one particle goes through the hole while its partner travels along a adjacent path outside the hole , they interfere destructively at the detector put behind the hole . This damaging interference effect can be described by using the phase change received during propagation owing to their different paths distances .Our results show how quantum mechanical effects are manifested in real space as well as in momentum space . Quantum theory predicts that particles may exhibit nonlocal correlations even if they cannot engage specifically .In particular , this implies that the wave function covering each particle must include information about all other particles interested in the system . Such nonlocality has been shown for photons1 – 3 but not already for huge particles such as atoms or atoms4 – 6 .Here we prove experimentally that two electrons produced separately from opposite ends of a double - slit lens do actually interfere with each other despite being apart by more than 1 mm7 .",
        "ori-fast-z-score": -3.7625606633113624,
        "water-fast-z-score": 4.554678697692702
    },
    {
        "original_text": "We present an analysis of the ages derived by applying the gyrochronological method to a sample of open clusters with known ages (from literature) in order to assess its reliability as well as possible systematics associated with it. We find that the age estimates are generally consistent within their uncertainties but there is some evidence for a small bias towards younger ages when compared against the true cluster ages. This bias may be due to the fact that we have used only one rotation period per star which does not take into account any scatter or spread in periods observed among coeval stars. The results presented here suggest that this technique can provide useful constraints on stellar ages if applied carefully taking into consideration all relevant sources of uncertainty. Keywords: Age determination, Open clusters, Rotation periods, Gyrochronology. 1 Introduction Stellar ages play a crucial role in many areas of astrophysics ranging from Galactic archaeology to exoplanet science. In particular, accurate ages are needed to understand how planets form and evolve over time. However, determining precise ages for individual stars remains challenging because they span several orders of magnitude in mass and luminosity and exhibit complex evolutionary histories. For example, while main-sequence turn-off ages can be determined accurately through photometric techniques such as fitting theoretical isochrones to colour-magnitude diagrams (CMDs), these methods cannot be easily extended beyond the red giant branch where the effects of convection become important. Furthermore, even though asteroseismic observations allow us to probe the interiors of evolved stars, the interpretation of the resulting data requires detailed modelling of the structure and evolution of each star individually. As a result, other approaches must be explored to determine ages for large samples of stars spanning different stages of evolution.\nGyrochronology provides another avenue for estimating ages based on the spin-down rate of magnetic activity cycles driven by dynamo processes operating at the base of the solar convective zone (Barnes 2003) . It has been shown that the Rossby number R o , defined as the ratio between the rotation period P rot and the convective overturning timescale",
        "watermark_text": "We present an assessment of the years derived by using the gyrochronological method to a sample of open clusters with recorded ages ( from literature ) in order to examine its reliability as well as possible systematics associated with it . We see that the age totals are typically consistent within their uncertainties but there is some evidence for a small prejudice towards older ages when compared against the true cluster ages .This bias could be due to the fact that we have applied only one rotation cycle per star which does not take into consideration any scatter or spread in dates observed among coeval stars . The results presented here suggest that this methods can provide useful limitations on stellar ages if applied deliberately taking into consideration all relevant sources of uncertainty .Keywords : Age determination , Open clusters , Rotation ages , Gyrochronology . 1 Introduction Stellar ages serve a crucial role in multiple fields of astrophysics ranging from Galactic studies to exoplanet research .In particular , detailed years are needed to comprehend how planets form and evolve over time . However , determining exact ages for individual stars becomes challenging because they span many orders of magnitude in mass and luminosity and possess intricate evolutionary histories .For instance , while main - sequence turn - off ages can be determined accurately through photometric strategies such as fitting theoretical isochrones to colour - magnitude diagrams ( CMDs ) , these procedures cannot be easily applied beyond the red dwarf branch where the effects of convection become crucial . Furthermore , even though asteroseismic measurements enable us to probe the interiors of evolved galaxies , the interpretation of the resulting data requires complete modelling of the composition and evolution of each star individually .As a result , other methods require be investigated to estimate ages for large specimens of stars spanning varying stages of evolution . Gyrochronology offers another avenue for estimating years depending on the spin - down frequency of magnetic activity periods caused by dynamo mechanisms operating at the base of the solar convective zone ( Barnes 2003 ) .It has been shown that the Rossby number R o , defined as the proportion between the rotation period P rot and the convective overturning timescale",
        "ori-fast-z-score": 0.15075567228888181,
        "water-fast-z-score": 8.995554457619608
    },
    {
        "original_text": "We present an approach to dependability analysis that is hierarchical in nature, and can be applied to any cache-based storage architecture. The main idea behind our approach is the use of a set of models at different levels of abstraction to represent the system under study. We show how these models are used together with simulation experiments to perform dependability evaluation on a commercial cache-based RAID storage architecture. Our results demonstrate that this approach provides significant advantages over traditional approaches based solely on analytical modeling or simulation experiments. In particular, we find that: (1) it allows us to obtain accurate estimates of reliability measures such as mean time between failures; (2) it enables us to explore tradeoffs among various design parameters; and (3) it helps us identify critical components within the system. Finally, we discuss some limitations of our approach and suggest directions for future research. Caching has been widely adopted by modern computer systems to improve performance through reducing access latency. However, caching introduces new challenges related to data consistency management and fault tolerance. This article presents a novel approach to dependability analysis of cache-based storage architectures.",
        "watermark_text": "We present an perspective to dependability analysis that is hierarchical in nature , and can be applied to any cache - based memory architecture . The main idea behind our approach is the using of a setting of models at different grades of abstraction to model the process under research .We indicate how these models are using combined with modeling experiments to conduct dependability evaluation on a commercial cache - based RAID disk architecture . Our results show that this methodology offers substantial benefits over traditional techniques based primarily on theoretical modeling or modeling experiments .In particular , we find that : ( 1 ) it allows us to obtain precise estimates of quality measures such as average time between crashes ; ( 2 ) it allows us to examine tradeoffs among various design variables ; and ( 3 ) it allows us identify important components within the system . Finally , we explain some restrictions of our approach and suggest directions for future research .Caching has been widely adopted by current computer networks to upgrade performance through decreasing entry latency . However , caching brings additional challenges related to data compliance control and failure tolerance .This page presents a new approach to dependability analysis of cache - based memory architectures .",
        "ori-fast-z-score": -1.2809280616135812,
        "water-fast-z-score": 8.911327886790069
    },
    {
        "original_text": "We report on the detection of an X-ray source, which is spatially coincident with the radio galaxy 3C 452 (z = 0.084). The observed spectrum can be described by a power law model modified by photoelectric absorption and emission lines at energies around 1 keV. We find that this object shows significant variability between different observations performed over several years. In addition to these features we detect a soft excess below 2 keV. This feature cannot be explained by thermal plasma models or reflection components alone but requires additional contributions from ionized absorbers and/or partial covering neutral material. Using our best-fit model for the time-averaged data set we derive intrinsic luminosities of Lx(2-10keV)= 4 x 1043 erg s-1 and Lx(0.5-2keV)= 5 x 1044 erg s-1. These values are typical for powerful FR II radio galaxies.",
        "watermark_text": "We report on the detection of an X - ray source , which is spatially coincident with the radio galaxy 3C 452 ( z = 0 . 084 ) . The observed spectrum can be described by a power law model modified by photoelectric absorption and emission lines at energies around 1 keV .We see that this object displays substantial variability between various observations performed over several decades . In addition to these characteristics we find a soft excess below 2 keV .This characteristic cannot be described by thermal plasma theories or reflection elements alone but requires added contributions from ionized absorbers and / or partial covering neutral material . Using our better - fitting model for the period - averaged data set we derive intrinsic luminosities of Lx ( 2 - 10keV ) = 4 x 1043 erg s - 1 and Lx ( 0 . 5 - 2keV ) = 5 x 1044 erg s - 1 .These values are common for strong FR II radio nuclei .",
        "ori-fast-z-score": -1.61245154965971,
        "water-fast-z-score": 3.0
    },
    {
        "original_text": "The recent debate on the future availability of fossil fuels has focused attention on the possible implications of peak oil (the maximum rate at which economically viable quantities can be extracted) for global warming, particularly in relation to the Kyoto Protocol s emissions targets.  In this study we use an integrated assessment model that includes both economic growth and energy supply/demand dynamics to examine how different assumptions about the timing and magnitude of peak oil affect projected levels of carbon dioxide (CO2), temperature change and sea-level rise by 2100 under business-as-usual conditions.   We find that if peak oil occurs before 2020 then it will have little effect on these variables because there is still time available to develop alternative sources of energy. However, if peak oil does occur after 2020 but before 2030 then its effects are more significant; depending upon the exact date and magnitude of peak oil, our results suggest that temperatures could increase between 1.5°C and 3.0°C above pre-industrial levels by 2100 with associated increases in sea level rise ranging up to 0.7 metres.",
        "watermark_text": "The recent debate on the future availability of fossil fuels has concentrated emphasis on the possible implications of peak oil ( the maximum speed at which financially feasible quantities can be extracted ) for global climate , particularly in relation to the Kyoto Protocol s emissions goals . In this study we utilize an unified assessment plan that contains both economic growth and energy demand / demand behavior to examine how various expectations about the timing and magnitude of peak oil impact potential levels of carbon dioxide ( CO2 ) , temperature drop and sea - temperature rise by 2100 under commercial - as - normal environments .We see that if peak oil happens before 2020 then it will have less effect on these parameters because there is already time possible to develop new sources of energy . However , if peak oil does occur after 2020 but before 2030 then its consequences are more considerable ; depending upon the exact period and magnitude of peak oil , our findings show that temperatures may increase between 1 . 5°C and 3 . 0°C above pre - industrial levels by 2100 with corresponding increases in sea level drop ranging up to 0 . 7 metres .",
        "ori-fast-z-score": 0.10153461651336192,
        "water-fast-z-score": 7.552593373581466
    },
    {
        "original_text": "We present the second part of our study on non-metric gravity theory in which we find that there is no missing mass problem for quasars as claimed by some authors.  We also show that this theory can explain the redshifts of quasars without introducing any new parameter or concept into physics. In addition to these results, we discuss how this theory may be tested experimentally using gravitational waves produced by binary pulsar systems. The first part of this work has been published recently  1  . \nI. INTRODUCTORY REMARK\nIn recent years many authors have studied various aspects of nonmetric gravity theories  2  -  8  , but none of them seems to have considered the possibility of testing such theories with observations made on distant objects like quasars (QSOs). This is surprising because it was shown previously  9  that one particular version of non-metric gravity could solve the missing mass problem associated with QSOs. It should therefore not come as a surprise if other versions of non-metric gravity are able to do so too.",
        "watermark_text": "We present the second part of our research on non - metric gravity concept in which we find that there is no missing mass problem for quasars as asserted by some researchers . We also demonstrate that this theory can describe the redshifts of quasars without putting any new parameter or notion into physics .In addition to these results , we talk how this theory could be evaluated experimentally utilizing gravitational waves produced by binary pulsar systems . The first part of this research has been printed recently 1 .I . INTRODUCTORY REMARK In past decades several authors have researched several elements of nonmetric gravity fields 2 - 8 , but none of them appears to have thought the prospect of testing such theories with observations made on remote bodies like quasars ( QSOs ) .This is surprising because it was shown previously 9 that one certain version of non - metric gravity could answer the missing mass problem associated with QSOs . It should therefore not come as a surprise if other variants of non - metric gravity are able to do so too .",
        "ori-fast-z-score": 0.3333333333333333,
        "water-fast-z-score": 7.0
    },
    {
        "original_text": "We have performed molecular dynamics simulations to study the temperature dependence of tensile properties of single walled carbon nanotubes (SWCNTs). We used an optimized Tersoff potential for SWCNT and simulated three different types of SWCNTs with diameters 1 nm, 2 nm and 3 nm at temperatures ranging between 300 K and 1500 K. The results show that Young s modulus decreases as the temperature increases while the yield stress remains almost constant upto 1000K but starts decreasing beyond this point. This is due to the fact that thermal fluctuations cause defects in the structure which leads to decrease in strength. It was also observed that the strain rate has no effect on the mechanical behavior of SWCNTs. \n\n\nKeywords: Molecular Dynamics Simulations; Temperature Dependence; Tensile Strength; Carbon Nanotube Structures; Defects. Introduction: Carbon nanotubes are one dimensional structures made out of sp2 hybridized carbon atoms arranged into hexagonal rings  1  . Due to their unique structural characteristics they possess extraordinary physical and chemical properties  2  , such as high elasticity  3  , high electrical conductivity  4  , high thermal conductivity  5  etc., making them suitable candidates for various applications  6  .\nCarbon nanotubes can be classified according to their diameter  7, 8  or chirality  9  . Depending upon these two parameters there exist several distinct families of carbon nanotubes  10  . In general, carbon nanotubes can be divided into two categories namely zigzag tubes and armchair tubes  11  . Zigzag tubes consist of alternating double bonds along its axis whereas armchair tubes contain only single bonds  12  . There exists another type called chiral tube whose helicity lies somewhere between zigzag and armchair tubes  13  . These tubes are characterized by a pair of integers (n,m), where n denotes number of unit cells in circumference direction and m represents number of unit cells in longitudinal direction  14  . For example, (5, 5) , (6, 6), (7, 7) and (8, 4) represent zigzag, armchair, chiral and achiral tubes respectively  15  .",
        "watermark_text": "We have done molecular dynamics simulations to study the temperature dependence of tensile features of single walled carbon nanotubes ( SWCNTs ) . We utilized an optimized Tersoff potential for SWCNT and simulated three different kinds of SWCNTs with diameters 1 nm , 2 nm and 3 nm at conditions ranging between 300 K and 1500 K . The results show that Young s modulus drops as the temperature increases while the yield stress remains virtually constant upto 1000K but continues dropping beyond this point .This is due to the fact that heat fluctuations cause failures in the formation which results to decrease in stability . It was also observed that the strain frequency has no effect on the thermal properties of SWCNTs .Keywords : Molecular Dynamics Simulations ; Temperature Dependence ; Tensile Strength ; Carbon Nanotube Structures ; Defects . Introduction : Carbon nanotubes are one dimensional assemblies formed out of sp2 hybridized carbon atoms arranged into hexagonal layers 1 .Due to their specific structural traits they possess extraordinary physical and biological qualities 2 , such as great elasticity 3 , large electrical conductivity 4 , large heating conductivity 5 etc . , making them ideal candidates for various uses 6 . Carbon nanotubes can be categorized according to their shape 7 , 8 or chirality 9 .Depending upon these two parameters there reside several different families of carbon nanotubes 10 . In general , carbon nanotubes can be grouped into two genres namely zigzag tubes and armchair devices 11 .Zigzag tubes comprise of alternating double bonds along its axis whereas armchair pipes comprise only single bonds 12 . There exists another type named chiral tube whose helicity resides somewhere between zigzag and armchair tubes 13 .These tubes are characterized by a pair of integers ( n , m ) , where n represents number of unit cells in circumference direction and m reflects amount of unit cells in longitudinal direction 14 . For instance , ( 5 , 5 ) , ( 6 , 6 ) , ( 7 , 7 ) and ( 8 , 4 ) represent zigzag , armchair , chiral and achiral pipes respectively 15 .",
        "ori-fast-z-score": -1.7407765595569784,
        "water-fast-z-score": 6.156480783621252
    },
    {
        "original_text": "We study how the evolution of the Carter constant depends on the spin and mass ratio in binary systems with spinning black holes, using numerical relativity simulations. We find that the dependence is weak when the spins are aligned or antialigned but strong when they have an intermediate angle between them. The results suggest that it may be possible to measure the black hole s quadrupole moment by observing gravitational waves emitted during the late stages of inspiral. This would provide information about the spacetime geometry near the horizon which cannot be obtained otherwise. \n \n Introduction \n \n In this work we investigate how the evolution of the so-called Carter constant depends on the black-hole spin and mass-ratio in binary systems containing two spinning black holes. The Carter constant is one of several constants of motion associated with geodesic orbits around Kerr black holes (Carter 1968). It can be used as a probe of the spacetime geometry close to the event horizon because its value changes significantly over time only if there exists significant deviation from spherical symmetry at small radii (Bardeen 1973; Thorne et al. 1986 ). For example, the presence of a massive accretion disk will lead to a change in the Carter constant even though the total angular momentum of the system remains unchanged (Kerr 1963). \n \n Previous studies have shown that the orbital evolution of binaries with non-spinning components is affected by the black-hole quadrupole moment Q = M(1 − S2)/c2R2 where S denotes the dimensionless spin parameter of each black hole (Damour & Nagar 1999) . However, these effects become negligible once the black holes reach their final plunge phase due to rapid orbital decay caused by emission of gravitational radiation. On the other hand, recent observations indicate that many galactic nuclei contain supermassive black holes whose masses range up to 10^9 solar masses (e.g., Gebhardt et al. (2000)). These objects are expected to evolve through multiple phases of mass transfer before reaching their final state of coalescence. During such evolutionary processes, the black holes could acquire large amounts of angular momentum via tidal interactions and/or",
        "watermark_text": "We research how the evolution of the Carter constant depends on the spin and mass ratio in binary systems with twisting black holes , using numerical relativity simulations . We see that the dependence is weak when the spins are aligned or antialigned but weak when they have an intermediate inclination between them .The results propose that it could be possible to measure the dark hole s quadrupole point by observing gravitational waves emitted during the last phases of inspiral . This might give information about the spacetime geometry near the horizon which cannot be obtained otherwise .Introduction In this study we investigate how the evolution of the so - called Carter constant depends on the dark - hole spin and mass - ratio in binary systems surrounding two spin black holes . The Carter constant is one of several constants of movement associated with geodesic orbits around Kerr white holes ( Carter 1968 ) .It can be used as a probe of the spacetime geometry next to the event horizon because its value changes significantly over time only if there exists significant deviation from spherical symmetry at small radii ( Bardeen 1973 ; Thorne et al . 1986 ) .For instance , the presence of a huge accretion wheel will result to a change in the Carter constant even though the total angular velocity of the system stays unchanged ( Kerr 1963 ) . Earlier investigations have shown that the orbital evolution of binaries with non - spinning components is affected by the dark - hole quadrupole moment Q = M ( 1 − S2 ) / c2R2 where S indicates the dimensionless spin variable of each dark hole ( Damour & Nagar 1999 ) .However , these consequences get negligible once the dark holes reach their final plunge period due to rapid orbital decay caused by absorption of gravitational rays . On the other hand , recent observations indicate that several galactic nuclei contain supermassive black holes whose masses range up to 10 ^ 9 solar masses ( e . g . , Gebhardt et al .( 2000 ) ) . These bodies are expected to evolve through several stages of mass transfer before reaching their final position of coalescence .During such evolutionary processes , the dark holes could acquire large quantities of angular velocity via tidal interactions and / or",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 7.976435884012652
    },
    {
        "original_text": "We propose an alternative switching mechanism for spintronic devices based on domain walls (DWs). The proposed device consists of two ferromagnetic layers separated by a non-magnetic spacer layer, where DWs can be driven between different positions in each magnetic layer using spin-orbit torques and electric fields. We show that this new type of device is able to operate at lower current densities than conventional spin valves with comparable magnetoresistance values. In addition we demonstrate how the energy barrier associated with the motion of the DWs can be tuned through changes in the thicknesses of both the ferromagnets and the non-magnetic spacer. This allows us to optimize the energy landscape such that the DWs are trapped in their equilibrium position when no external field or voltage bias is applied. Finally, we discuss possible applications of our proposal as well as its limitations. Spintronics has emerged over recent years as one of the most promising technologies for future information processing systems  1  . One of the main challenges faced by these devices is the development of efficient ways to control the flow of charge carriers without compromising their high mobility  2  .\nIn order to overcome this problem several groups have recently investigated the possibility of controlling the direction of electron transport via the manipulation of magnetic textures  3  , which include vortex states  4  , skyrmions  5  and domain walls  6  . Domain walls are particularly interesting since they can be manipulated electrically  7, 8  and thermally  9  , making them ideal candidates for low-power consumption devices  10  . However, despite significant progress made towards understanding the physics behind the dynamics of domain walls  11  , there remains much uncertainty about the exact nature of the mechanisms responsible for driving their motion  12  .",
        "watermark_text": "We suggest an additional switching method for spintronic systems relying on domain barriers ( DWs ) . The proposed system consists of two ferromagnetic layers divided by a non - magnetic spacer membrane , where DWs can be pushed between various positions in each magnetic layer involving spin - orbit torques and electric forces .We suggest that this new kind of device is could to work at lower current densities than conventional spin tubes with similar magnetoresistance ratings . In addition we prove how the electricity barrier associated with the movement of the DWs can be tuned through variations in the thicknesses of both the ferromagnets and the non - magnetic spacer .This enables us to optimize the electricity landscape such that the DWs are locked in their equilibrium place when no external field or voltage bias is applied . Finally , we study possible users of our proposal as well as its limitations .Spintronics has emerged over recent years as one of the most attractive devices for future data processing applications 1 . One of the main problems faced by these machines is the development of effective means to manage the transfer of charge carriers without compromising their high mobility 2 .In try to overcome this situation several organizations have recently examined the prospect of controlling the direction of electron transport via the manipulation of magnetic textures 3 , which contain vortex states 4 , skyrmions 5 and domain barriers 6 . Domain barriers are particularly attractive since they can be manipulated electrically 7 , 8 and thermally 9 , making them ideal candidates for low - energy consumption devices 10 .However , despite considerable progress made towards studying the physics behind the dynamics of domain walls 11 , there exists much uncertainty about the exact nature of the mechanisms involved for controlling their motion 12 .",
        "ori-fast-z-score": -0.5980503604017327,
        "water-fast-z-score": 8.629012342939285
    },
    {
        "original_text": "The gamma-ray bursts (GRBs) are the most energetic explosions in the universe, but their origin is still unknown. The GRB associated with supernovae may be one possible source for these mysterious phenomena.  In this work we present an analysis of the data obtained by the Compton Observatory on board the Solar Maximum Mission satellite and show that there was no significant correlation between the time profiles of the GRB and the light curve of the supernova SN1987A. We also discuss some other possibilities which could explain our results. Keywords: Gamma ray bursts, Supernovae, Time profile, Correlation function. 1 Introduction   -Gamma Ray Bursts (GRBs), discovered more than twenty years ago  1  , have been studied extensively since then  2  . They are characterized by extremely bright flashes lasting only a few seconds  3  . Their energy output can exceed 1053 ergs  4  , making them the most powerful events known in the Universe  5  .\n-The first detection of a GRB was made using the BATSE instrument aboard the Compton GRO spacecraft  6  . Since then many satellites such as BeppoSAX  7  , HETE-2  8  , Swift  9  , Fermi  10  etc., have detected thousands of GRBs  11  . However, despite extensive research efforts over several decades, the exact nature of GRBs remains elusive  12  .",
        "watermark_text": "The gamma - ray clusters ( GRBs ) are the most intense explosions in the universe , but their source is already unclear . The GRB associated with supernovae might be one possible cause for these mysterious phenomena .In this research we present an assessment of the information obtained by the Compton Observatory on board the Solar Maximum Mission spacecraft and reveal that there was no major interaction between the period profiles of the GRB and the light curve of the supernova SN1987A . We also discuss some other possibilities which could explain our findings .Keywords : Gamma ray bursts , Supernovae , Time profile , Correlation constant . 1 Introduction - Gamma Ray Bursts ( GRBs ) , detected more than twenty years previously 1 , have been studied thoroughly since then 2 .They are characterized by extremely brilliant flashes lasting only a few seconds 3 . Their energy output can exceed 1053 ergs 4 , making them the most intense objects known in the Universe 5 .- The first measurement of a GRB was done utilizing the BATSE instrument aboard the Compton GRO shuttle 6 . Since then many satellites such as BeppoSAX 7 , HETE - 2 8 , Swift 9 , Fermi 10 etc . , have discovered thousands of GRBs 11 .However , despite extensive research efforts over numerous generations , the exact nature of GRBs remains elusive 12 .",
        "ori-fast-z-score": -0.4588314677411235,
        "water-fast-z-score": 5.584068246522259
    },
    {
        "original_text": "We present an analysis of the kinematics, metallicity distribution function (MDF), and chemical abundances in the outer halo of our Galaxy using data obtained with the Subaru Telescope for two fields along the leading arm of the Magellanic stream. We find that the MDFs are well represented by three Gaussian components centered at  Fe/H  = -1.7, -0.9, and +0.2 dex, respectively. The metal-poor component is found to be associated with the Galactic thick disk/halo population, while both intermediate- and high-metallicity populations show significant differences between the two fields. In particular, we detect a large fraction of high-alpha stars in one field but not in another located farther away from the center of the LMC. These results suggest that the origin of these streams may have been triggered by tidal interactions between the Milky Way and its satellite galaxies such as the Sgr dwarf galaxy and/or the LMC.",
        "watermark_text": "We present an assessment of the kinematics , metallicity distribution relation ( MDF ) , and biological abundances in the exterior halo of our Galaxy using data acquired with the Subaru Telescope for two fields along the led limb of the Magellanic stream . We see that the MDFs are best represented by three Gaussian components centered at Fe / H = - 1 . 7 , - 0 . 9 , and + 0 . 2 dex , respectively .The metal - weak component is found to be correlated with the Galactic thick disk / halo population , while both intermediate - and large - metallicity populations display significant variations between the two fields . In particular , we find a large fraction of high - alpha objects in one field but not in another situated closer back from the center of the LMC .These data suggest that the origin of these streams may have been caused by tidal interactions between the Milky Way and its satellite galaxies such as the Sgr dwarf galaxy and / or the LMC .",
        "ori-fast-z-score": -1.0504514628777804,
        "water-fast-z-score": 4.464418717230567
    },
    {
        "original_text": "The production of particles with large transverse momenta is studied in the fragmentation region for gluons and quarks produced by photons, Z bosons or W bosons.  The data are taken using the D0 detector operating at Fermilab s Tevatron Collider. Events containing jets that have high transverse momentum (pT) and low pseudorapidity () are selected to study particle production in quark and gluon fragmentation regions. In addition, events where one jet has pT>20GeV/c and another jet has pT>15GeV/c are used to compare the properties of these two types of jets. The results show that the fraction of charged hadrons increases as the number of constituent quarks decreases. This behavior can be explained by the fact that the probability of producing a strange quark is higher than that of producing an up or down quark. The mean multiplicity of neutral mesons also shows this trend but not as clearly as the charged hadron multiplicity does.",
        "watermark_text": "The production of nuclei with large transverse momenta is studied in the fragmentation area for gluons and quarks produced by photons , Z bosons or W bosons . The data are took using the D0 probe operating at Fermilab s Tevatron Collider .Events containing jets that have high vertical momentum ( pT ) and low pseudorapidity ( ) are chosen to study ion production in quark and gluon fragmentation areas . In addition , events where one jet has pT > 20GeV / c and another plane has pT > 15GeV / c are using to study the properties of these two kind of jets .The results show that the fraction of charged hadrons increases as the quantity of component quarks decreases . This activity can be described by the fact that the probability of creating a weird quark is higher than that of creating an up or down quark .The mean multiplicity of neutral mesons also shows this decline but not as clearly as the charged hadron multiplicity does .",
        "ori-fast-z-score": 0.13245323570650439,
        "water-fast-z-score": 5.514870180108347
    },
    {
        "original_text": "We study the internal state of an isotropic packing of frictionless spherical particles under compression, decompression and cyclic loading by means of numerical simulations using molecular dynamics (MD). We find that the volume fraction increases with increasing applied stress in all cases studied here. The increase of the volume fraction during unloading is smaller than for loading at similar stresses. This hysteresis effect becomes more pronounced as the number of load-unload cycles increases. In addition to this we observe that the distribution function of contact forces changes significantly between different stages of the process. These results are discussed within the framework of elastic-plastic models of granular materials. Granular matter can be found everywhere around us; it forms the basis of many natural phenomena such as avalanches or landslides on mountainsides  1  , mudflow  2  , sedimentation  3  , soil mechanics  4  , earthquakes  5  . It also plays an important role in industrial processes like powder metallurgy  6  , pharmaceutical industry  7  , food processing  8  , etc.. Despite its ubiquity there still exist open questions about how granular systems behave mechanically  9  .\nIn recent years much effort has been devoted to understanding the mechanical behavior of granular media  10  -  12  . One of the most interesting problems concerns the response of granular material to external loads  13  -  16  . For example, one may ask what happens if you compress a sample of sand? What will happen when you release the pressure again?\nThe aim of our work presented below was to investigate these issues numerically  17  . To do so we used Molecular Dynamics (MD)  18  which allows us to simulate large samples consisting of thousands of grains  19  .",
        "watermark_text": "We explore the internal state of an isotropic packing of frictionless spherical objects under compression , decompression and cyclic loading by means of computational simulations using molecular dynamics ( MD ) . We see that the density fraction increases with increasing applied strain in all situations examined here .The expansion of the volume fraction during unloading is smaller than for loading at comparable stresses . This hysteresis effect gets more pronounced as the number of load - unload cycles rises .In addition to this we determine that the distribution relation of touch forces shifts significantly between various phases of the process . These conclusions are discussed within the framework of elastic - plastic models of granular materials .Granular material can be found everywhere around us ; it becomes the foundation of several physical phenomena such as avalanches or landslides on mountainsides 1 , mudflow 2 , sedimentation 3 , soil engineering 4 , earthquakes 5 . It additionally serves an important role in industrial systems like powder metallurgy 6 , pharmaceutical manufacturing 7 , meat mining 8 , etc . .Despite its ubiquity there still appear open questions about how granular structures react mechanically 9 . In recent years much effort has been focused to discovering the mechanical behavior of granular material 10 - 12 .One of the most important problems involves the response of granular material to external loads 13 - 16 . For instance , one may question what happens if you compress a sample of sand ?What will occur when you release the pressure again ? The goal of our work shown below was to examine these problems numerically 17 .To do so we using Molecular Dynamics ( MD ) 18 which allows us to simulate large specimens contained of thousands of grains 19 .",
        "ori-fast-z-score": -1.1917080461366747,
        "water-fast-z-score": 6.937819061732104
    },
    {
        "original_text": "We study the transverse momentum dependence of J/ψ and Υ production cross sections at RHIC energies within an effective field theory approach, which includes both elastic scattering off quarks as well as inelastic processes such as dissociation into open charm or bottom hadrons.  We find that the observed suppression pattern can be reproduced by including only elastic scattering for pT < 2 GeV/c while additional contributions are needed to describe data points with larger values of pT . The latter turn out to be dominated by inelastic processes like dissociation into open heavy flavor mesons. In particular we show that the inclusion of these effects leads to a significant reduction of the predicted nuclear modification factor RAA(pT ) compared to previous calculations based on purely elastic interactions. \nPACS numbers: 12.38.Mh, 25.75.-q, 11.10.Kk \nI. INTRODUCTORY REMAR K\nThe measurement of charmonium (J/ψ) and bottomonium (Υ) production is one of the most promising probes to investigate properties of hot and dense matter created in relativistic nucleus-nucleus collisions  1  . It has been suggested that the interaction between the produced quarkonia and the surrounding medium may lead to their partial melting  2  , i.e., to a decrease of the bound state masses due to color screening  3  .\nIn this work we present results obtained within an effective field theory framework  4  , where the relevant degrees of freedom are quarks and gluons rather than individual hadronic states. This allows us to calculate the total cross section for quarkonium production in terms of elementary partonic subprocesses involving light quarks q = u, d, s and gluons g. These include elastic scattering off quarks and gluon-gluon fusion leading to the formation of quarkonia via the creation of a virtual qq pair  5  . Furthermore, inelastic processes such as quarkonium dissociation into open heavy-flavor hadrons  6  have also been included  7, 8  .",
        "watermark_text": "We study the transverse momentum dependence of J / ψ and [UNK] production cross sections at RHIC energies within an effective field theory approach , which includes both elastic scattering off quarks as well as inelastic processes such as dissociation into open charm or bottom hadrons . We find that the observed suppression pattern can be reproduced by including only elastic scattering for pT < 2 GeV / c while additional contributions are needed to describe data points with larger values of pT .The latter turn out to be dominated by inelastic reactions like dissociation into open heavy flavor mesons . In particular we prove that the introduction of these influences result to a substantial decreased of the expected nuclear modification factor RAA ( pT ) compared to previous analyses based on purely elastic interactions .PACS codes : 12 . 38 . Mh , 25 . 75 . - q , 11 . 10 . Kk I . INTRODUCTORY REMAR K The measurement of charmonium ( J / ψ ) and bottomonium ( [UNK] ) production is one of the most attractive probes to examine properties of hot and dense materials captured in relativistic nucleus - nucleus collisions 1 .It has been proposed that the interaction between the produced quarkonia and the nearby medium may contribute to their partial melting 2 , i . e . , to a reduction of the bound state masses due to color screening 3 . In this research we present results derived within an efficient field model formulation 4 , where the appropriate degrees of liberty are quarks and gluons instead than individual hadronic states .This enables us to estimate the total cross section for quarkonium production in terms of elementary partonic subprocesses involving light quarks g = w , d , s and gluons g . These include elastic scattering off quarks and gluon - gluon fusion led to the formation of quarkonia via the creation of a virtual qq couple 5 . Furthermore , inelastic reactions such as quarkonium dissociation into open heavy - flavor hadrons 6 have also been used 7 , 8 .",
        "ori-fast-z-score": -0.08606629658238704,
        "water-fast-z-score": 5.115948820192307
    },
    {
        "original_text": "We present optical spectroscopic observations for the sample of 14 extreme high energy peaked BL Lac objects (EHBLs) selected by Costamante et al. (2013) . The main goal is to study their host galaxy properties and investigate possible differences with respect to lower-energy blazars, which are known to be hosted in elliptical galaxies. We find that all EHBLs have redshifts between 0.1 and 1.0, consistent with previous results on this class of sources. All but one source show evidence of being hosted in spiral or irregular galaxies; only PKS 0537-441 shows an elliptical-like spectrum. This result suggests that there may not exist any significant difference in the hosts of low-and high-energy blazars as previously claimed. However, we note that our sample size is small and further studies will be needed before drawing firm conclusions. \n \n Keywords: Blazar, Host Galaxy",
        "watermark_text": "We present optical spectroscopic observations for the sample of 14 extreme high energy peaked BL Lac objects ( EHBLs ) selected by Costamante et al . ( 2013 ) .The main goal is to study their host universe characteristics and probe possible variations with regard to smaller - energy blazars , which are known to be hosted in elliptical galaxies . We see that all EHBLs have redshifts between 0 . 1 and 1 . 0 , consistent with previous findings on this class of sources .All but one source demonstrate proof of being hosted in spiral or irregular stars ; only PKS 0537 - 441 shows an elliptical - like spectrum . This result suggests that there may not occur any large change in the hosts of high - and low - energy blazars as previously reported .However , we note that our sample volume is tiny and further studies will be needed before drew solid results . Keywords : Blazar , Host Galaxy",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.165514464459439
    },
    {
        "original_text": "We report on experimental measurements of spatial correlation functions for the dynamics of supercooled liquids at different temperatures, using confocal microscopy and single particle tracking techniques to probe the motion of colloidal particles suspended in glycerol. We find that these correlation functions can be well described by an exponential decay with a characteristic length scale which increases as we lower the temperature towards the glass transition point. This increase is consistent with theoretical predictions based on mode-coupling theory (MCT), but our results show deviations from MCT near the glass transition temperature Tg. These deviations are likely due to dynamic heterogeneities present close to Tg. The data presented here provide new insights into the nature of spatio-temporal fluctuations in glassy systems. Glass-forming liquids exhibit slow relaxation processes over many decades in time scales  1  . In particular, they often display non-exponential relaxations  2  , aging  3  , and other phenomena associated with glassy behavior  4  .\nTheories such as Mode-Coupling Theory (MCT)  5  have been developed to describe this complex phenomenology  6  . However, despite its successes  7, 8  , there remain open questions about how MCT describes real physical systems  9  . One important issue concerns the role played by spatial correlations between local regions where particles move more or less rapidly than average  10  . Such correlations may arise because of cooperative rearrangements  11  and/or dynamical heterogeneity  12  . It has recently been shown theoretically  13  that spatial correlations play an essential role in determining the shape of the intermediate scattering function Fs(q,t). Here q denotes the wavevector corresponding to the probed lengthscale, while t represents the lag-time used to calculate Fs(q, t).\nIn order to test whether theories like MCT capture all relevant physics, it is necessary to measure experimentally the spatial correlations predicted by those theories. Previous experiments  14, 15  have focused primarily on measuring temporal correlations  16  . Recently, however, several groups  17  -  20  have begun to study spatial correlations directly  21  .",
        "watermark_text": "We report on research studies of spatial correlation functions for the dynamics of supercooled liquids at different conditions , using confocal microscopy and single molecule tracking technology to probe the movement of colloidal particles suspended in glycerol . We see that these correlation functions can be well described by an exponential decay with a typical duration scale which increases as we lower the temperature towards the glass transition point .This increase is compatible with theoretical estimates based on mode - correlation theory ( MCT ) , but our findings show deviations from MCT near the glass transition temperature Tg . These deviations are likely due to dynamic heterogeneities present close to Tg .The data provided here provide fresh insights into the nature of spatio - temporal fluctuations in glassy systems . Glass - creating liquids exhibit slow relaxation processes over numerous centuries in time ranges 1 .In particular , they frequently exhibit non - exponential relaxations 2 , aging 3 , and other processes associated with glassy behavior 4 . Theories such as Mode - Coupling Theory ( MCT ) 5 have been constructed to explain this complex phenomenology 6 .However , despite its victories 7 , 8 , there remain open questions about how MCT represents real natural systems 9 . One important concern concerns the importance played by spatial correlations between local regions where ions move more or less rapidly than average 10 .Such correlations might arise because of joint rearrangements 11 and / or dynamical heterogeneity 12 . It has recently been shown theoretically 13 that spatial correlations serve an essential part in determining the form of the intermediate absorption system Fs ( q , t ) .Here q indicates the wavevector corresponding to the probed lengthscale , while t refers the lag - time used to estimate Fs ( q , t ) . In order to test whether models like MCT convey all relevant physics , it is required to measure experimentally the spatial correlations expected by those theories .Previous experiments 14 , 15 have concentrated mostly on measuring temporal correlations 16 . Recently , however , various groups 17 - 20 have begun to study spatial correlations directly 21 .",
        "ori-fast-z-score": 0.24743582965269675,
        "water-fast-z-score": 8.001666493091715
    },
    {
        "original_text": "We introduce monoids that are generalizations of the classical groups of Richard Thompson, and we show how to construct these monoids using finite automata.  We also give an explicit description for all elements in terms of their normal forms with respect to the monoid generators.   Finally, we prove that our monoids have decidable word problems by showing that they can be embedded into free inverse monoids. The results presented here were obtained during my PhD thesis at ETH Zurich under the supervision of Prof. Dr. Peter Schupp (ETH Zurich) and Prof. Dr. Michael Steinert (University of Hamburg).    Keywords: Group theory, Monoids, Automata, Decidability, Word problem, Free inverse monoids, Finite automata, Computational complexity theory, Groups generated by finite automata, Generalized Thompson groups, Elementary amenable groups, Group actions on trees, Group actions on graphs",
        "watermark_text": "We introduce monoids that are generalizations of the classical categories of Richard Thompson , and we give how to build these monoids using finite automata . We also get an explicit description for all members in terms of their normal forms with regard to the monoid generators .Finally , we prove that our monoids have decidable word difficulties by showing that they can be embedded into free inverse monoids . The results presented here were obtained during my PhD thesis at ETH Zurich under the guidance of Prof . Dr . Peter Schupp ( ETH Zurich ) and Prof . Dr . Michael Steinert ( University of Hamburg ) .Keywords : Group logic , Monoids , Automata , Decidability , Word problem , Free inverse monoids , Finite automata , Computational complexity analysis , Groups generated by finite automata , Generalized Thompson groups , Elementary amenable groups , Group activities on forests , Group activities on graphs",
        "ori-fast-z-score": 0.4685212856658182,
        "water-fast-z-score": 4.6291004988627575
    },
    {
        "original_text": "We present an exact expression for the energy density functional in terms of the local electronic charge and spin densities, which is valid for any number N of electrons on a two-dimensional jellium surface with arbitrary spin-orbit interaction strength. The resulting sum rules are shown to be equivalent to those derived by Stillinger and Lovett (SL) for the case of zero spin-orbit coupling but they also include additional contributions due to this term. We show that these new terms can be expressed as functions of the SL parameters only. This result allows us to obtain explicit expressions for all the relevant physical quantities such as the exchange-correlation potential or the magnetization profile at finite temperature. Finally we discuss how our results could be used to improve existing approximations within Density Functional Theory. PACS: 71.10.Pq - Energy-densities; 72.20.Fd - Energy-density functionals; 73.40.Gk - Spin-polarized systems",
        "watermark_text": "We present an precise representation for the power density functional in terms of the local electronic charge and spin densities , which is valid for any number N of electrons on a two - dimensional jellium surface with arbitrary spin - orbit interaction strength . The resulting sum rules are shown to be analogous to those developed by Stillinger and Lovett ( SL ) for the case of zero spin - orbit bonding but they still provide additional contributions due to this term .We see that these new terms can be described as functions of the SL parameters only . This result allows us to obtain precise expressions for all the appropriate physical components such as the transfer - correlation potential or the magnetization profile at finite temperature .Finally we talk how our findings may be used to improve established approximations within Density Functional Theory . PACS : 71 . 10 . Pq - Energy - densities ; 72 . 20 . Fd - Energy - density functionals ; 73 . 40 . Gk - Spin - polarized systems",
        "ori-fast-z-score": -0.3721042037676254,
        "water-fast-z-score": 3.6927447293799815
    },
    {
        "original_text": "In this work, we study the diversity-multiplexing tradeoff (DMT) for amplify-andforward multihop relay channels with multiple-input and multiple-output (MIMO). We first derive an upper bound on DMT by using the cut-set theorem. Then, based on the derived upper bound, we propose two schemes to achieve the optimal DMT performance in different scenarios. In particular, when all relays have full-duplex capability, our proposed scheme achieves the optimal DMT at high multiplexing gain region; while if only half-duplex relays are available, then our proposed scheme can still achieve the optimal DMT except that it is achieved at low multiplexing gain region instead. Finally, simulation results show that both proposed schemes outperform existing ones significantly. Index Terms-Diversity-Multiplexing Tradeoff, Multiple-Input MultipleOutput, Amplify-and-Forward",
        "watermark_text": "In this research , we study the diversity - multiplexing tradeoff ( DMT ) for amplify - andforward multihop relay channels with many - input and multiple - output ( MIMO ) . We first derive an upper bound on DMT by using the cutting - set theorem .Then , using on the derived upper bound , we propose two strategies to achieve the ideal DMT performance in different scenarios . In particular , when all relays have whole - duplex capability , our proposed system achieves the ideal DMT at high multiplexing gain area ; while if only whole - duplex relays are available , then our proposed system can also obtain the ideal DMT except that it is achieved at low multiplexing gain area instead .Finally , simulation data reveal that both proposed methods outperform established ones considerably . Index Terms - Diversity - Multiplexing Tradeoff , Multiple - Input MultipleOutput , Amplify - and - Forward",
        "ori-fast-z-score": 0.9271726499455306,
        "water-fast-z-score": 6.118878816098722
    },
    {
        "original_text": "We have read with interest the recent preprint  1  . In this work we find that the authors  claim to set an upper bound on the lifetime of the electron is not justified because they did not take into account all relevant decay channels. \n \n We would like to comment briefly on their treatment of backgrounds as well as their choice of cuts used to select events. The main source of background comes from radiative Bhabha scattering e+e-→e+e-γ which has been studied extensively at LEP2  2  , where it was found to be negligible compared to other sources such as two-photon processes or four-fermion final states (e.g., W pair production). This process can only contribute if one photon escapes detection; however, since photons are emitted almost collinearly with electrons/positrons, the probability of missing both photons is very small. Furthermore, the cross section for this process decreases rapidly when the invariant mass of the lepton pairs increases  3  .\n \nThe authors also use a cut on the total energy of the event, Evis>10 GeV, which removes most of these events. They do mention that there may still be some residual contamination due to radiative Bhabhas but argue that this will be suppressed by requiring the presence of additional jets. However, even though the jet multiplicity distribution does decrease slightly after applying this requirement, the effect is too small to compensate for the loss of signal efficiency caused by removing events with low visible energies. \n \nIn addition, the authors state that the contribution from radiative Bhabhas should be included in the systematic uncertainty estimate. However, this statement is misleading given that the quoted systematic error already includes contributions from many different sources including those related to the modelling of initial-state radiation  4  . \n\n\nFinally, we note that the authors present results obtained using Monte Carlo simulations performed with PYTHIA 6  5  . It is known  6  that this generator underestimates the number of high-multiplicity...",
        "watermark_text": "We have read with importance the recent preprint 1 . In this research we find that the writers claim to setting an upper bound on the life of the electron is not justified because they did not take into consideration all relevant degradation channels .We would like to comment briefly on their handling of backgrounds as also as their choosing of cuts needed to select events . The main origin of background comes from radiative Bhabha scattering e + e - →e + e - γ which has been studied thoroughly at LEP2 2 , where it was shown to be negligible compared to other sources such as two - photon processes or four - fermion final states ( e . g . , W pair production ) .This process can only contribute if one photon escapes detection ; however , since photons are emitted virtually collinearly with electrons / positrons , the probability of missing both photons is very small . Furthermore , the cross area for this process reduces rapidly when the invariant mass of the lepton pairs increases 3 .The authors also use a cutting on the total energy of the event , Evis > 10 GeV , which eliminate most of these events . They do mention that there may still be some remnant contamination owing to radiative Bhabhas but suggest that this will be suppressed by requiring the presence of added jets .However , even though the jet multiplicity distribution does decrease slightly after applying this requirement , the effect is too small to compensate for the losing of signal efficiency created by removing events with lowered visible frequencies . In addition , the writers state that the impact from radiative Bhabhas should be included in the systematic uncertainty estimate .However , this statement is misleading given that the quoted systematic error also contains contributions from many various sources including those related to the modelling of initial - state radiation 4 . Finally , we note that the writers present results acquired using Monte Carlo simulations conducted with PYTHIA 6 5 .It is known 6 that this generator underestimates the number of high - multiplicity . . .",
        "ori-fast-z-score": 0.9863939238321437,
        "water-fast-z-score": 7.127317708515653
    },
    {
        "original_text": "We study the glass transition of an ensemble of adhesive hard spheres with repulsive interactions decaying as 1/r6, where r is distance between particles. We find that this system exhibits two distinct relaxation processes at low temperatures: one fast process associated with local rearrangements within clusters of strongly bonded particles; another slower process related to collective motion of these clusters. The latter process can be described by mode-coupling theory (MCT) for colloidal suspensions. However, we show that MCT fails quantitatively when applied directly to our data because it does not take into account the presence of strong bonds which lead to additional slow modes. By introducing a simple modification to MCT, we are able to obtain excellent agreement with experimental results over several decades in time and frequency. This modified version of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg. Our work shows how quantitative tests of theoretical predictions may help improve their accuracy and applicability range.",
        "watermark_text": "We test the glass transition of an ensemble of adhesive solid surfaces with repulsive interactions decaying as 1 / r6 , where r is distance between particles . We see that this scheme exhibits two different relaxation processes at low temperatures : one fast process associated with local rearrangements within clusters of highly bonded particles ; another slower process related to collective motion of these complexes .The latter system can be described by mode - coupling theory ( MCT ) for colloidal suspensions . However , we prove that MCT fails quantitatively when applied directly to our information because it does not take into consideration the presence of stable bonds which lead to extra slow modes .By introducing a simple change to MCT , we are able to obtain excellent compliance with experimental results over numerous years in time and frequency . This amended variant of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg .Our research shows how standardized tests of theoretical estimates may improve improve their accuracy and applicability range .",
        "ori-fast-z-score": -0.43133109281375365,
        "water-fast-z-score": 5.965587590013045
    },
    {
        "original_text": "The purpose of this research is to develop an integrated approach for sharing product information in the supply chain using Web services technology, which will allow companies to collaborate with each other more effectively by exchanging data over the Internet. The proposed system consists of three main components: (1) Product Information Management System, (2) Supply Chain Collaboration Framework, and (3) Web Services Technology. In addition, we have developed a prototype system that demonstrates how these technologies can be used together to facilitate collaboration between different organizations involved in the same supply chain network. This article presents our work on developing such a system. We believe that it has great potential as a tool for improving business processes across various industries. Keywords: Supply chain management, web service, product information management system, collaboration framework. 1 Introduction With the rapid development of e-commerce applications, there are increasing demands for efficient ways to manage products throughout their life cycles  1  . Companies need to cooperate closely with suppliers and customers so they can respond quickly to market changes  2  .\nIn order to achieve better coordination among partners along the supply chain, many researchers have been working towards integrating existing systems into one common platform  3  , where all parties could access relevant information about products at any time  4  . However, most current approaches focus only on providing technical solutions without considering the organizational issues associated with implementing them  5  . Therefore, it becomes important to understand both technological aspects and social dimensions when designing new e-business models  6  .\nThis study aims to address some of these challenges by proposing a novel method for managing product information in the supply",
        "watermark_text": "The purpose of this research is to develop an unified approach for distributing product information in the supply chain using Web services technology , which will provide firms to collaborate with each other more effectively by exchanging data over the Internet . The proposed system includes of three principal portions : ( 1 ) Product Information Management System , ( 2 ) Supply Chain Collaboration Framework , and ( 3 ) Web Services Technology .In addition , we have developed a prototype system that indicates how these innovations can be used together to enable collaboration between various organizations involved in the same supply chain chain . This page presents our work on developing such a system .We believe that it has tremendous ability as a platform for improving business processes across different industries . Keywords : Supply chain control , web service , product information management system , partnership template .1 Introduction With the fast development of electronic - trade applications , there are growing requirements for efficient methods to manage products throughout their history cycles 1 . Companies need to engage tightly with producers and customers so they can respond rapidly to market shifts 2 .In order to achieve improve coordination among partners along the supply chain , many scientists have been pushing towards combining existing solutions into one common platform 3 , where all parties could access relevant information about goods at any time 4 . However , most current approaches focus only on providing technical solutions without examining the institutional issues associated with implementing them 5 .Therefore , it becomes crucial to realize both economic aspects and social dimensions when designing new online - business systems 6 . This study aims to overcome some of these problems by proposing a unique technique for controlling product information in the supply",
        "ori-fast-z-score": 0.7423074889580903,
        "water-fast-z-score": 9.434707130066995
    },
    {
        "original_text": "We present an analysis of the photometric data for all known transiting planets discovered by microlensing surveys, including OGLE-II (Udalski et al., 2002) , MOA (Bond et al., 2001) and MACHO (Alcock et al., 1997) . We use these results to investigate whether any of them are likely to be false positives due to blending with nearby stars or other effects such as grazing eclipses.  The majority of the planet detections have been made using ground-based telescopes which cannot resolve individual sources in crowded fields. This means that it is possible that some of the detected signals may actually arise from multiple unresolved objects rather than single planets. In addition, there can also be significant contamination from background eclipsing binaries whose light curves mimic those expected from planetary systems. To address this problem we perform detailed simulations of each system taking into account realistic distributions of stellar masses and distances, as well as observing conditions at different sites.",
        "watermark_text": "We publish an assessment of the photometric data for all known transiting planets discovered by microlensing observations , including OGLE - II ( Udalski et al . , 2002 ) , MOA ( Bond et al . , 2001 ) and MACHO ( Alcock et al . , 1997 ) . We use these results to examine whether any of them are likely to be false positives due to mixing with nearby planets or other effects such as grazing eclipses .The majority of the planet detections have been achieved using ground - based telescopes which inability resolve individual sources in dense fields . This implies that it is suggested that some of the emitted signals might actually emerge from multiple unresolved objects rather than separate planets .In addition , there can also be considerable exposure from background eclipsing binaries whose light patterns mimic those expected from planetary components . To address this challenge we perform comprehensive simulations of each system take into consideration realistic distributions of stars masses and altitudes , as also as monitoring conditions at different places .",
        "ori-fast-z-score": -0.808290376865476,
        "water-fast-z-score": 6.119912853410033
    },
    {
        "original_text": "In this note, we present an elementary proof for the following theorem due to Pappus:\nTheorem 1 (Pappus  theorem). Let $ABC$ be any triangle and let $D$ be its incenter. Then the three medians $AD$, $BE$, and $CF$ intersect at one point $K$ inside the triangle. \nProof. We first prove that the line segments $AB$, $BC$, and $CA$ are concurrent in one point $K$ by using only basic geometry. The idea is as follows. Consider the circle $C_1$ centered at $A$ with radius $AC$. Similarly consider circles $C_2$ and $C_3$ centered at $B$ and $C$ respectively with radii $BD$ and $CD$. Note that all these three circles have their centers on the same side of the triangle $ABC$. Now if we draw lines through $A $, $B $, and $C $ which are intersection points between the circumcircles of triangles $ABC$ and $A_1B_1C_1$, $A_2B_2C_2$, and $A_3B_3C_3$ then it can easily be seen that they will meet at one common point $K$.",
        "watermark_text": "In this note , we present an elementary proof for the following theorem according to Pappus : Theorem 1 ( Pappus principle ) . Let $ ABC $ be any triangle and take $ D $ be its incenter .Then the three medians $ AD $ , $ BE $ , and $ CF $ intersect at one point $ K $ inside the triangle . Proof .We first establish that the line segments $ AB $ , $ BC $ , and $ CA $ are simultaneous in one point $ K $ by using only basic geometry . The idea is as follows .Consider the circle $ C _ 1 $ focused at $ A $ with diameter $ AC $ . Similarly consider circles $ C _ 2 $ and $ C _ 3 $ focused at $ B $ and $ C $ respectively with radii $ BD $ and $ CD $ .Note that all these three circles have their centers on the same side of the circle $ ABC $ . Now if we draw lines through $ A $ , $ B $ , and $ C $ which are intersection points between the circumcircles of triangles $ ABC $ and $ A _ 1B _ 1C _ 1 $ , $ A _ 2B _ 2C _ 2 $ , and $ A _ 3B _ 3C _ 3 $ then it can easily be saw that they will meet at one common point $ K $ .",
        "ori-fast-z-score": 0.7453559924999299,
        "water-fast-z-score": 3.464101615137755
    },
    {
        "original_text": "We introduce the notion of an algebra over a monoidal category and show that it is equivalent to the notion of a coalgebra in the dual category, which we call a comonoid.  We then define the cyclic homology of such algebras as the Hochschild cohomology of their underlying comonoids with coefficients in the bimodule given by the tensor product of the algebra with its opposite algebra.  This definition generalizes the usual one for ordinary algebras over fields or rings.   In particular, if the base ring has characteristic zero, this recovers the classical definitions of cyclic homology and periodic cyclic homology.  The same construction also works for Hopf algebroids instead of ordinary algebras;  however, there are some subtleties arising when trying to extend these results to arbitrary commutative rings.    Finally, we give several examples illustrating our constructions. Cyclic homology was introduced by Connes in his seminal work on noncommutative geometry  Con  . It can be defined as the Hochschild homology of certain algebras called cyclic objects. These were first studied systematically by Bökstedt  Bök  , who showed how they could be used to construct new algebraic structures like crossed modules and group extensions. Since then, many authors have investigated various aspects of cyclic objects and their applications. For example, see  Fri1  ,  Fri2  ,  Koc  ,  Lau  ,  Maz  ,  Nee  ,  Sta  .\nIn this article, we will study cyclic objects in more detail using techniques developed recently in the theory of operads and monads. Our main result shows that any cyclic object gives rise to two different types of cyclic homologies, namely the cyclic homology of the underlying algebra and the periodic cyclic homology of the associated graded algebra. Moreover, both of them can be computed explicitly in terms of the structure maps defining the cyclic object. As a consequence, we obtain explicit formulas for the cyclic homology of all finite-dimensional cocommutative Hopf algebras over a field of characteristic 0.",
        "watermark_text": "We introduce the notion of an ring over a monoidal category and know that it is analogous to the notion of a coalgebra in the dual category , which we call a comonoid . We then define the cyclic homology of such algebras as the Hochschild cohomology of their underlying comonoids with coefficients in the bimodule given by the tensor product of the algebra with its opposite algebra .This definition generalizes the usual one for regular algebras over fields or rings . In particular , if the base ring has characteristic zero , this recovers the classical definitions of cyclic homology and regular cyclic homology .The same construction also works for Hopf algebroids rather of simple algebras ; however , there are some subtleties emerging when trying to apply these results to arbitrary commutative rings . Finally , we give numerous instances illustrating our concepts .Cyclic homology was introduced by Connes in his seminal study on noncommutative geometry Con . It can be written as the Hochschild homology of certain algebras called cyclic objects .These were first examined carefully by Bökstedt Bök , who demonstrated how they could be used to build modern algebraic structures like crossed varieties and group extensions . Since then , various papers have researched several topics of cyclic objects and their applications .For instance , see Fri1 , Fri2 , Koc , Lau , Maz , Nee , Sta . In this article , we will explore cyclic objects in more depth employing approaches developed lately in the notion of operads and monads .Our main result suggests that any cyclic object gives rise to two different kinds of cyclic homologies , namely the cyclic homology of the underlying algebra and the periodic cyclic homology of the associated graded module . Moreover , both of them can be computed specifically in terms of the structure maps governing the cyclic object .As a consequence , we obtain formal formulas for the cyclic homology of all finite - dimensional cocommutative Hopf algebras over a field of characteristic 0 .",
        "ori-fast-z-score": -0.4583492485141057,
        "water-fast-z-score": 5.775200531277732
    },
    {
        "original_text": "We study the random spatial growth in two dimensions, where new sites are added to an initially empty square lattice at randomly chosen locations and grow into circular clusters if they do not hit any existing cluster or obstacle site.  We show that this process leads to fractal structures which can be characterized by their fractal dimension Df = 1 + (1 - p)/2p, where p is the probability for adding a new site without hitting an obstacle. The results agree well with numerical simulations. \nPACS numbers: 05.40.+j, 64.60.Cn, 68.35.-k \nI. INTRODUCTORY REMARK\nIn recent years there has been considerable interest in studying various aspects of the so-called Eden model  1  . In its original formulation it describes the growth of a single cluster on a two-dimensional substrate starting from one seed particle. This simple concept was later generalized to include several seeds  2  , as well as different shapes  3  .\nThe present work deals with another generalization of the Eden model: Instead of growing only one cluster we consider the simultaneous growth of many clusters competing for space  4  . As a result, some clusters may become trapped between other clusters leading to a complex pattern formation.",
        "watermark_text": "We research the random spatial growth in two dimensions , where new sites are adding to an initially vacant rectangular matrix at randomly picked areas and grow into circular groups if they do not hit any original cluster or obstacle site . We see that this process results to fractal structures which can be described by their fractal dimension Df = 1 + ( 1 - p ) / 2p , where p is the probability for adding a new site without hits an barrier .The results agree well with numerical simulations . PACS scores : 05 . 40 . + j , 64 . 60 . Cn , 68 . 35 . - k I .INTRODUCTORY REMARK In recent years there has been substantial interest in studying several elements of the so - called Eden model 1 . In its initial formulation it assumes the development of a single cluster on a two - dimensional substrate beginning from one seed particle .This basic concept was afterwards generalized to consider many seeds 2 , as well as varying shapes 3 . The present work deals with another generalization of the Eden model : Instead of growing only one cluster we define the concurrent development of several clusters battling for space 4 .As a result , some clusters might form trapped between other communities leading to a complex pattern formation .",
        "ori-fast-z-score": -0.20203050891044214,
        "water-fast-z-score": 6.464976285134148
    },
    {
        "original_text": "We present new optical and near-infrared images, as well as archival radio data for the polar ring galaxy AM1934-563 (NGC4650A). The main results are summarized below:  1) We confirm that this galaxy is an edge-on S0/a with a bright nuclear point source surrounded by a faint disk.  2) A prominent dust lane crosses the central region in the north-south direction.  3) There appears to be no evidence for any recent star formation activity within the ring or along its edges.  4) The kinematics of the gas component show two distinct components; one associated with the ring itself and another which follows closely the rotation curve of the underlying stellar body.  5) The total mass of the gaseous ring amounts to about 10^9 M_sol. 6) The observed properties of NGC4650A can be explained if it has undergone a major merger event between two galaxies at least 0.5 Gyr ago.",
        "watermark_text": "We release additional imaging and far - infrared images , as also as archival radio data for the polar belt star AM1934 - 563 ( NGC4650A ) . The main results are presented below : 1 ) We suggest that this star is an edge - on S0 / a with a bright nuclear point source surrounded by a dim disk .2 ) A prominent cloud lane crosses the main region in the north - south orientation . 3 ) There seems to be no evidence for any new star formation activity within the circle or along its edges .4 ) The kinematics of the gas component show two different components ; one linked with the circle itself and another which follows carefully the rotation curve of the underlying stars body . 5 ) The total mass of the gaseous ring reduces to about 10 ^ 9 M _ sol .6 ) The observed properties of NGC4650A can be understood if it has undergone a major collision activity between two galaxies at least 0 . 5 Gyr ago .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.289942788427422
    },
    {
        "original_text": "We present the first version of our new code, WHAM (Weno-Hybrid Arbitrary Mesh), which is based on the recently developed weighted essentially non-oscillatory (WENO) schemes for solving hyperbolic conservation laws in one dimension and multi-dimensions.  The main idea behind this method is to use high-order spatial reconstruction with an adaptive mesh refinement technique to achieve high accuracy at low computational cost. We have implemented several different versions of the WENO algorithm into our code including the fifth-order WENO-Z scheme as well as the third- and fifth-order WENO-JS schemes. In addition we also implement the fourth-order Runge-Kutta time integration scheme along with the Harten-Lax-van Leer contact discontinuity capturing scheme to handle discontinuities arising during hydrodynamic evolution. Our results show that all these algorithms are able to produce accurate solutions when compared against exact or reference solutions.",
        "watermark_text": "We introduce the first generation of our new code , WHAM ( Weno - Hybrid Arbitrary Mesh ) , which is based on the recently advanced weighted essentially non - oscillatory ( WENO ) schemes for solving hyperbolic conservation forces in one dimension and multi - dimensions . The main idea behind this algorithm is to use large - order spatial reconstruction with an adaptive mesh refinement technique to achieve high sensitivity at low numerical cost .We have integrated various different versions of the WENO algorithm into our code including the fifth - order WENO - Z plan as also as the third - and fifth - order WENO - JS schemes . In addition we also execute the third - order Runge - Kutta time integration scheme along with the Harten - Lax - van Leer contact discontinuity capturing scheme to manage discontinuities resulting during hydrodynamic evolution .Our results show that all these algorithms are able to produce accurate answers when compared against exact or reference solutions .",
        "ori-fast-z-score": 2.1652509527331207,
        "water-fast-z-score": 6.039910552360811
    },
    {
        "original_text": "We present PdBI observations at 1.3 mm wavelength of the protostellar jet associated with the young stellar object (YSO) HH212, which is one of the best examples for studying the formation process of bipolar outflows driven by YSOs. The main results are as follows:\n(1) We find that there exists an unresolved central source within the innermost region of the jet.\n(2) A bright knot appears to be located on each side of the central source along the jet axis. \n(3) The knots show blue-shifted emission lines compared to those of the ambient gas surrounding them. (4) The knots have a velocity width of ~100 km s-1 , while the ambient gas has a much broader linewidth up to 300 km s-1 . These facts suggest that the knots represent shocked regions where the jet interacts with the ambient medium. In addition, we found that the knots are surrounded by a shell-like structure whose radius ranges between 100 AU and 1000 AU.",
        "watermark_text": "We present PdBI data at 1 . 3 cm wavelength of the protostellar plane corresponding with the young stellar object ( YSO ) HH212 , which is one of the best cases for studying the formation transition of bipolar outflows driven by YSOs . The main results are as follows : ( 1 ) We see that there exists an unresolved primary source within the innermost region of the jet .( 2 ) A blue knot appears to be found on each side of the main source along the jet axis . ( 3 ) The knots exhibit blue - shifted emission lines relative to those of the atmospheric gas covering them .( 4 ) The knots have a speed width of ~ 100 km s - 1 , while the atmospheric gas has a far larger linewidth up to 300 kilometers s - 1 . These facts indicate that the knots represent shocked regions where the jet interacts with the atmospheric medium .In addition , we reported that the knots are surrounded by a shell - like structure whose radius varies between 100 AU and 1000 AU .",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We present new millimeter observations at 1.3 mm (230 GHz) with the Submillimeter Array (SMA), which resolve the dust continuum emission in the protoplanetary disk around the Herbig Ae star HD 163296 into two components, one located close to the central star and another farther out. The inner component is resolved by SMA for the first time and shows an elongated shape that can be fitted well by a Gaussian function with a FWHM size of 0. 34 ± . 01 × 0. 21 ± . 01. We also detect CO J=2-1 line emission toward this source using the SMA. By comparing our results with previous studies we find evidence for Keplerian rotation in both the gas and dust disks. Our data suggest that there are three distinct regions in the disk where different physical processes may take place: i) An optically thick region near the center of the disk; ii) a transition zone between the optically thin outer disk and the optically thick inner disk; iii) an extended optically thin region beyond 100 AU.",
        "watermark_text": "We present new millimeter discoveries at 1 . 3 cm ( 230 GHz ) with the Submillimeter Array ( SMA ) , which resolve the dust continuum emission in the protoplanetary disk around the Herbig Ae star HD 163296 into two parts , one located close to the main star and another farther out . The inner component is resolved by SMA for the first time and shows an elongated structure that can be fit well by a Gaussian constant with a FWHM diameter of 0 .34 ± . 01 × 0 .21 ± .01.We additionally observe CO J = 2 - 1 line emission toward this source using the SMA . By matching our findings with previous research we find proof for Keplerian rotation in both the gas and dust disks .Our data suggest that there are three separate areas in the disk where various physical processes must take place : i ) An optically dense zone near the center of the disk ; ii ) a transfer zone between the optically thin outer disk and the optically dense inner disk ; iii ) an extended optically thin region beyond 100 AU .",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "The colour reconnection (CR) model is used to describe how quarks and gluons rearrange themselves into hadrons after they are produced by hard scattering processes, such as those occurring during e+e-annihilation events.  The CR model predicts that particles emitted close together in phase space will be more likely to recombine than those which are further apart.  This effect can lead to changes in event topology and kinematics compared to predictions made using models without CR.  In this analysis we use data collected by the Delphi experiment operating at centre-of-mass energies between 189 GeV and 209 GeV corresponding to an integrated luminosity of 1.1 fb-1.  We measure the fraction of WW events where one or both W bosons decay leptonically for different ranges of dilepton invariant mass and compare these results to Monte Carlo simulations including and excluding CR effects.  Our measurements show no significant evidence for CR effects within our experimental uncertainties.",
        "watermark_text": "The colour reconnection ( CR ) model is utilized to explain how quarks and gluons rearrange themselves into hadrons after they are produced by hard scattering mechanisms , such as those occurring during e + e - annihilation processes . The CR theory predicts that particles emitted close together in phase space will be more likely to recombine than those which are further separated .This phenomenon can lead to changes in event topology and kinematics compared to forecast making using models without CR . In this analysis we utilize evidence generated by the Delphi experiment working at centre - of - mass energies between 189 GeV and 209 GeV corresponding to an unified luminosity of 1 . 1 fb - 1 .We estimate the fraction of WW occasions where one or both W bosons decay leptonically for different ranges of dilepton invariant mass and compare these results to Monte Carlo simulations using and excluding CR effects . Our measurements show no important proof for CR influences within our research uncertainties .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.905778905196061
    },
    {
        "original_text": "We present an analysis of photometric and spectroscopic data for SN 2003du, which was discovered on February 28th by R. Puckett at Mt. Wilson Observatory (Puckett et al., 2004) . The supernova is located in NGC 3190, a spiral galaxy with Hubble type Sb/Scd. It has been classified as a normal Type Ia supernova based on its light curve shape and spectral features. \n \n We find that the peak absolute magnitude of SN 2003du is -19.6 ± 0.1 mag, corresponding to a distance modulus of 34.7 ± 0.2 mag. This places it at a distance of about 50 Mpc (z = 0.0185). Using this distance we derive a total ejecta mass of 1.4 ± 0.3M⊙ and 56Ni yield of 0.09 ± 0.02M⊙ . \n \n \n \n In addition to our own observations, we have used archival data obtained through the CfA Supernova Archive, the SUSPECT archive maintained by the University of Hawaii, and the Wise Observatory archive.",
        "watermark_text": "We present an assessment of photometric and spectroscopic data for SN 2003du , which was discovered on February 28th by R . Puckett at Mt . Wilson Observatory ( Puckett et al . , 2004 ) .The supernova is situated in NGC 3190 , a spiral galaxy with Hubble class Sb / Scd . It has been classified as a normal Type Ia supernova based on its light curve size and spectral features .We determine that the maximum absolute magnitude of SN 2003du is - 19 . 6 ± 0 . 1 mag , equivalent to a distance modulus of 34 . 7 ± 0 . 2 mag . This places it at a distance of about 50 Mpc ( z = 0 . 0185 ) .Using this distance we derive a total ejecta mass of 1 . 4 ± 0 . [UNK] and 56Ni yield of 0 . 09 ± 0 . [UNK] . In addition to our own observations , we have utilized archival data acquired through the CfA Supernova Archive , the SUSPECT archive operated by the University of Hawaii , and the Wise Observatory collection .",
        "ori-fast-z-score": -0.7453559924999299,
        "water-fast-z-score": 2.1105794120443453
    },
    {
        "original_text": "We report an observation of a large coronal mass ejection (CME) associated with a halo-type flare that occurred in active region NOAA 10486 on 2006 December 13, which was observed by Solar TErrestrial RElations Observatory (STEREO). The CME speed is estimated to be about 1450 km/s at 1 AU using STEREO observations. We find that this CME originated from a complex magnetic structure consisting of two opposite-polarity flux systems connected by a filament channel. In addition, we found that there were several small-scale brightenings around the main sunspots before the onset of the flare/CME activity. These brightenings are identified as ephemeral regions (ERs), which are known to play important roles for triggering eruptions such as flares or CMEs. By analyzing high-resolution images taken by Hinode/SOT/SP, we show that one of these ERs interacted strongly with the surrounding magnetic field lines during its rapid rotation. This interaction caused reconnection between open and closed magnetic fields, resulting in the formation of a current sheet below the ER. Then, the eruption started when the current sheet became unstable due to the kink instability.",
        "watermark_text": "We report an observation of a large coronal mass ejection ( CME ) associated with a halo - class flare that occurred in active region NOAA 10486 on 2006 December 13 , which was seen by Solar TErrestrial RElations Observatory ( STEREO ) . The CME rate is predicted to be about 1450 km / s at 1 AU using STEREO images .We see that this CME originated from a complex magnetic formation consisting of two opposite - polarity flux systems connected by a filament channel . In addition , we saw that there were several small - scale brightenings around the main sunspots before the beginning of the flare / CME activity .These brightenings are identified as ephemeral regions ( ERs ) , which are known to take key roles for triggering eruptions such as flares or CMEs . By analyzing large - resolution photos taken by Hinode / SOT / SP , we find that one of these ERs interacted heavily with the nearby magnetic field lines during its rapid rotation .This coupling resulted reconnection between open and open magnetic waves , leading in the formation of a current sheet below the ER . Then , the volcano started when the current sheet became unstable due to the kink instability .",
        "ori-fast-z-score": -0.6974858324629157,
        "water-fast-z-score": 5.032769329433615
    },
    {
        "original_text": "The Solar Chromosphere is an important component in our understanding of how the Sun works and its influence on Earth, but it has been difficult to study because of its tenuous nature.  ALMA (Atacama Large Millimeter/submillimeter Array) will be able to observe this region for the first time with unprecedented spatial resolution.   This talk will discuss some of the science that can be done using ALMA observations of the Solar Chromosphere. The Solar Chromosphere is one of the most enigmatic regions of the Sun. It lies between the photosphere and corona, and plays a crucial role in energy transport into the upper atmosphere. However, due to its extremely low density, direct observation of the chromosphere was not possible until recently when high-resolution images were obtained by space-based telescopes such as Hinode/SOT and SDO/AIA. In addition, ground-based observatories have also made significant progress towards studying the chromosphere through various techniques including spectropolarimetry, imaging spectroscopy, and speckle interferometry. Despite these advances, there are still many open questions about the physical processes occurring within the chromosphere which need to be addressed. For example, what causes the formation of dynamic structures like sunspots? How do magnetic fields affect plasma dynamics in the chromosphere? What is the relationship between chromospheric heating mechanisms and coronal mass ejections? These questions cannot be answered without detailed knowledge of the structure and dynamics of the chromosphere. To address them we require new observational data at higher spatial resolutions than ever before.",
        "watermark_text": "The Solar Chromosphere is an important element in our understanding of how the Sun operates and its influence on Earth , but it has been difficult to study because of its tenuous nature . ALMA ( Atacama Large Millimeter / submillimeter Array ) will be possible to observe this area for the first time with incredible spatial resolution .This discussion will explore some of the science that can be performed using ALMA observations of the Solar Chromosphere . The Solar Chromosphere is one of the most enigmatic regions of the Sun .It lies between the photosphere and corona , and plays a crucial role in heat transport into the higher atmosphere . However , owing to its incredibly small abundance , direct observation of the chromosphere was not could until recently when high - resolution images were obtained by space - based telescopes such as Hinode / SOT and SDO / AIA .In addition , land - based observatories have already produced important development towards studying the chromosphere through numerous techniques including spectropolarimetry , optical spectroscopy , and speckle interferometry . Despite these developments , there are still many open questions about the physical processes arising within the chromosphere which require to be addressed .For instance , what causes the formation of dynamic systems like sunspots ? How do magnetic waves affect plasma dynamics in the chromosphere ?What is the relationship between chromospheric heating systems and coronal mass ejections ? These questions cannot be answered without precise understanding of the composition and dynamics of the chromosphere .To address them we require novel observational data at higher spatial resolutions than ever before .",
        "ori-fast-z-score": 1.4,
        "water-fast-z-score": 7.53778361444409
    },
    {
        "original_text": "MgSiO3 perovskite has been studied by first-principles calculations and the semi-empirical P-V-T equation of state (EOS). The calculated results show that MgSiO3 perovskites have high bulk modulus, low compressibility, large volume expansion coefficient at high temperature, and small thermal expansivity in comparison with other oxides. These properties are very important for understanding geophysics phenomena such as earthquakes and volcanic activities.  In addition to these physical properties, we also investigated the electronic structure of MgSiO3 perovskitie using density functional theory (DFT) method. We found that there exists a charge transfer between Si4+ ions and O2-ions which leads to the formation of Si-O bonds. This charge transfer causes the change of bond length and bond angle of Si-O-Si network. Finally, we discussed the effect of oxygen vacancy on the structural stability of MgSiO3 perovksite.",
        "watermark_text": "MgSiO3 perovskite has been studied by first - principles analysis and the semi - empirical P - V - T equation of state ( EOS ) . The measured conclusions show that MgSiO3 perovskites have high bulk modulus , low compressibility , large volume contraction coefficient at high heat , and tiny thermal expansivity in comparison with other oxides .These properties are very important for studying geophysics phenomena such as earthquakes and volcanic movements . In addition to these biological features , we also examined the electronic stability of MgSiO3 perovskitie using density functional theory ( DFT ) method .We showed that there exists a charge transfer between Si4 + ions and O2 - ions which results to the formation of Si - O bonds . This charge transfer causes the shift of bond length and bond angle of Si - O - Si channel .Finally , we explored the impact of oxygen vacancy on the structural structure of MgSiO3 perovksite .",
        "ori-fast-z-score": -0.24618298195866545,
        "water-fast-z-score": 4.520269441183293
    },
    {
        "original_text": "We present Very Long Baseline Array (VLBA) radio images and multi-epoch optical photometry for 7 blazars selected from the Roma-BZCAT catalog as candidates to be members of the Red Giants Branch (RGB). The sources are located at redshifts between 0.1 and 1, with luminosities ranging from 1045 erg/s to 1012 erg/s in the rest frame range 2-10 keV. We find that all but one source show compact cores on milliarcsecond scales; only RGB J0152+017 shows an extended structure. All these results suggest that most of our targets belong to the class of Flat Spectrum Radio Quasars rather than Blazar-like AGNs. In addition we report new spectroscopic data obtained by us or taken from literature which confirm this hypothesis. \n \n Keywords: Blazars, VLBI, Optical variability, X-ray emission, Red giants branch",
        "watermark_text": "We create Very Long Baseline Array ( VLBA ) broadcast photographs and multi - epoch optical photometry for 7 blazars chosen from the Roma - BZCAT catalog as candidates to be members of the Red Giants Branch ( RGB ) . The sources are situated at redshifts between 0 . 1 and 1 , with luminosities ranging from 1045 erg / s to 1012 erg / s in the rest frame range 2 - 10 keV .We see that all but one source demonstrate smooth cores on milliarcsecond intervals ; only RGB J0152 + 017 shows an extended structure . All these results show that most of our targets represent to the class of Flat Spectrum Radio Quasars rather than Blazar - like AGNs .In addition we publish new spectroscopic data received by us or taken from literature which confirm this hypothesis . Keywords : Blazars , VLBI , Optical variability , X - ray radiation , Red stars branch",
        "ori-fast-z-score": 0.15249857033260467,
        "water-fast-z-score": 4.320493798938573
    },
    {
        "original_text": "We calculate the two-loop beta function for the coupling constant of the AdS5xS5 superstring theory and show that it is proportional to the one-loop result, which implies that there are no non-trivial fixed points at any finite value of the string coupling constant.  We also find that the dilaton field has an imaginary part when we take into account the higher-order terms beyond the leading order approximation. This indicates that our results may be valid only within some limited region of the parameter space where the imaginary part of the dilaton can be neglected. The present work was motivated by the recent study on the gauge/gravity correspondence between N=4 super Yang-Mills (SYM) theories with 16 supercharges and type IIB strings on AdS5xS5G5 backgrounds  1  . In this context, the existence of nontrivial fixed points would correspond to the conformal invariance of the dual SYM theories  2  , while the imaginary part of the dilatonic scalar fields would indicate the instability of the corresponding solutions  3  .\nIn Ref.  4  , the authors have calculated the one-loop beta functions for both the metric tensor and the dilaton field using the Green-Schwarz formalism  5  . They found that these beta functions do not vanish even if they are evaluated at vanishing values of the string coupling constants. However, their calculations were performed under the assumption that all the fermionic contributions vanish identically  6  . It turns out that such an assumption does not hold true  7, 8  . Therefore, it seems necessary to perform more detailed analysis taking into account the effects due to the fermions as well as those coming from the bosons.",
        "watermark_text": "We calculate the two - loop beta function for the coupling constant of the AdS5xS5 superstring theory and find that it is proportional to the one - loop result , which implies that there are no non - trivial fixed points at any finite value of the string coupling constant . We additionally find that the dilaton field has an imaginary part when we took into consideration the higher - order terms beyond the led order approximation .This implies that our findings may be valid only within some restricted region of the parameter space where the imaginary part of the dilaton can be forgotten . The present work was motivated by the recent study on the gauge / gravity correspondence between N = 4 super Yang - Mills ( SYM ) theories with 16 supercharges and class IIB sequences on AdS5xS5G5 backgrounds 1 .In this situation , the existence of nontrivial fixed points would coincide to the conformal invariance of the dual SYM theories 2 , while the imaginary part of the dilatonic scalar fields might suggest the instability of the equivalent solutions 3 . In Ref .4 , the papers have predicted the one - loop beta functions for both the metric tensor and the dilaton field using the Green - Schwarz formalism 5 . They found that these beta distributions do not vanish even if they are evaluated at vanishing values of the string coupling constants .However , their analyses were performed under the assumption that all the fermionic contributions vanish identically 6 . It turns out that such an assume does not stand true 7 , 8 .Therefore , it appears necessary to conduct more precise analysis taking into consideration the effects due to the fermions as also as those coming from the bosons .",
        "ori-fast-z-score": -0.2847473987257497,
        "water-fast-z-score": 5.362108949786505
    },
    {
        "original_text": "We study the radiative breaking of flavor symmetry in models with three generations of Majorana neutrinos and no hierarchy between their masses. We show that, for generic values of the parameters, there is always an additional massless state which can be identified as a sterile neutrino. The presence of this extra light state has important consequences on leptogenesis and neutrinoless double beta decay experiments. \nPACS numbers: 11.10.Wx, 12.60.Jv, 13 .20.Hs \nI. INTRODUCTORY REMAR K\nThe Standard Model (SM) of particle physics describes all known fundamental interactions except gravity. It contains one generation of left-handed neutrinos whose masses are generated by the Higgs mechanism  1  , but it does not explain why these particles have such small masses compared to other SM fermions  2  .\nIn order to address this question, many extensions of the SM have been proposed over the years  3  . In particular, theories based on gauge groups larger than SU(3) C ×SU(2) L ×U(1) Y predict new states beyond those present in the SM  4  . These new states may include right-handed neutrinos  5  or scalar fields  6  . If they exist at low energies, they could lead to observable effects  7, 8  .\nOne possible way to test whether new degrees of freedom exist below the electroweak scale is through precision measurements  9  . Another possibility is to look for signals of new physics in rare processes  10  . Finally, if new particles are produced directly at high energy colliders  11  , then their properties can also be studied  12  .",
        "watermark_text": "We explore the radiative violation of flavor symmetry in models with three generations of Majorana neutrinos and no hierarchy between their masses . We see that , for generic values of the variables , there is usually an additional massless state which can be identified as a sterile neutrino .The appearance of this extra light state has valuable consequences on leptogenesis and neutrinoless double β decay research . PACS scores : 11 . 10 . Wx , 12 . 60 . Jv , 13 . 20 . Hs I .INTRODUCTORY REMAR K The Standard Model ( SM ) of particle science describes all known theoretical interactions except gravitational . It contains one generation of left - handed neutrinos whose masses are produced by the Higgs mechanism 1 , but it does not show why these ions have such tiny masses compared to other SM fermions 2 .In order to meet this question , various extensions of the SM have been proposed over the years 3 . In particular , theories based on gauge fields larger than SU ( 3 ) C ×SU ( 2 ) L ×U ( 1 ) Y expect new states beyond those present in the SM 4 .These new states may include right - handed neutrinos 5 or scalar fields 6 . If they exist at low energies , they may contribute to observable effects 7 , 8 .One could way to test whether new degrees of liberty exist below the electroweak scale is through precision observations 9 . Another possibility is to search for signals of new physics in rare processes 10 .Finally , if new objects are produced directly at high energy colliders 11 , then their characteristics can also be examined 12 .",
        "ori-fast-z-score": -0.5940885257860046,
        "water-fast-z-score": 4.752708206288037
    },
    {
        "original_text": "We present the first provably optimal cache-oblivious layouts for meshes with arbitrary aspect ratios and dimensions, which are based on recursive striping into rectangular tiles. Our results hold both in terms of worst-case performance guarantees as well as average case behavior under realistic assumptions about access patterns. We also show how to extend our techniques to handle more general data structures such as trees or graphs. The layout problem is formulated as an optimization problem: given a set of objects that need to be stored in memory, we want to find their positions so that they can be accessed most efficiently by future queries. In this work, we consider the following scenario: A large amount of data needs to be stored in main memory (e.g., a database). This data consists of many small objects (e.g., records) whose sizes vary greatly; some may even be larger than available space. To solve this problem, one could use a standard technique called blocking: each object is divided into blocks of equal size, and then these blocks are placed contiguously within the allocated storage area. However, if there are too few blocks per object, it will not fit entirely inside its assigned block; similarly, if there are too many blocks per object, the unused space between them cannot be used effectively.",
        "watermark_text": "We report the first provably ideal cache - oblivious layouts for meshes with arbitrary aspect ratios and dimensions , which are based on recursive striping into rectangular tiles . Our results hold both in terms of lowest - case performance assurance as well as average case behavior under rigorous constraints about connection schemes .We additionally understand how to expanded our approaches to treat more general data objects such as trees or graphs . The configuration problem is implemented as an optimization problem : given a setting of items that require to be transferred in memory , we try to find their positions so that they can be viewed most efficiently by future queries .In this research , we imagine the following situations : A vast number of data needs to be contained in central memory ( e . g . , a database ) . This data contains of several small items ( e . g . , records ) whose sizes differ significantly ; some may even be larger than provided area .To solve this situation , one might using a traditional technique called blocking : each object is separated into blocks of equal size , and then these blocks are arranged contiguously within the allocated storage space . However , if there are too few blocks per object , it will not fit completely inside its allocated block ; likewise , if there are too several blocks per object , the empty space between them cannot be used effectively .",
        "ori-fast-z-score": -2.5776089301153053,
        "water-fast-z-score": 6.313641498019764
    },
    {
        "original_text": "In this work, we study the distribution of the size of largest planar matching (LPM) and largest planar subgraph (LPS) in random bipartite graphs with n vertices on each side. We show that for any fixed integer k > 0, there exists an absolute constant ck such that if G is a random bipartite graph with n vertices on each part satisfying cn < p = e(G)/n < 1 − cn then LPM(G) has at least k components w.h.p.. Moreover, when p = 1/2 + o(1), we prove that LPS(G) contains a cycle of length Ω(log log n). These results are proved by using the second moment method together with some new techniques developed here to deal with the dependencies between edges. As applications, these results imply that both LPM(G) and LPS(G) have many small cycles under certain conditions.",
        "watermark_text": "In this research , we study the spread of the length of largest planar matching ( LPM ) and largest planar subgraph ( LPS ) in random bipartite graphs with n edges on each side . We see that for any fixed integer n > 0 , there exists an absolute constant ck such that if G is a random bipartite graph with n edges on each portion satisfying cn < p = e ( G ) / p < 1 − cn then LPM ( G ) has at least n parts w . h . p . .Moreover , when p = 1 / 2 + o ( 1 ) , we prove that LPS ( G ) contains a cycle of length Ω ( log log n ) . These conclusions are proved by using the second moment method together with some modern techniques introduced here to deal with the dependencies between edges .As applications , these results mean that both LPM ( G ) and LPS ( G ) have many small periods under certain conditions .",
        "ori-fast-z-score": 0.508000508000762,
        "water-fast-z-score": 4.318004318006477
    },
    {
        "original_text": "We present the clustering properties of star forming galaxies at z ~ 1, 2 & 3 in the GALEX Deep Imaging Survey (DIS) field using photometric redshifts derived by combining deep optical data from the Canada-France-Hawaii Telescope Legacy Survey (CFHTLS). We use two different methods to select our galaxy samples; one based on their observed NUV fluxes and another based on their intrinsic SFRs estimated from their UV luminosities. The results show that both these selection criteria yield similar clustering strengths for all three redshift bins considered here. However, we find evidence for evolution in the bias parameter between each redshift bin which is consistent with previous studies. In addition, we also study how this bias evolves as a function of stellar mass and UV luminosity. Our analysis shows that there are no significant differences in the bias values obtained when considering only those galaxies above or below a given threshold value of either stellar mass or UV luminosity.",
        "watermark_text": "We present the clustering behavior of galaxy producing galaxies at z ~ 1 , 2 & 3 in the GALEX Deep Imaging Survey ( DIS ) field using photometric redshifts collected by combining dark optical data from the Canada - France - Hawaii Telescope Legacy Survey ( CFHTLS ) . We use two different methods to select our galaxy collections ; one based on their observed NUV fluxes and another based on their intrinsic SFRs calculated from their UV luminosities .The results show that both these selection categories yield similar clustering strengths for all three redshift bins mentioned here . However , we find proof for evolution in the bias variable between each redshift bin which is compatible with previous research .In addition , we also study how this bias evolves as a function of stellar mass and UV luminosity . Our study shows that there are no considerable variations in the bias values achieved when examining only those galaxies above or below a given threshold amount of either stellar mass or UV luminosity .",
        "ori-fast-z-score": 0.1259881576697424,
        "water-fast-z-score": 5.08000508000762
    },
    {
        "original_text": "We present an assessment of the predictive power of galaxy formation models by comparing their predictions for rest-frame optical luminosity functions (LFs) with observations over the redshift range z=2-3. We use two different semi-analytic models, GALFORM and L-GALAXIES, to predict the evolution in number density as well as the distribution of stellar masses and star formation rates of galaxies across this redshift interval. The predicted LF is compared directly against observational data obtained using the Hubble Space Telescope s Advanced Camera for Surveys (ACS). In addition we compare the observed and predicted distributions of UV absolute magnitudes and dust-corrected colours. Our results show that both models are able to reproduce the overall shape of the observed LF but underpredict its normalisation by up to a factor of three. This discrepancy can be largely accounted for if one assumes that the majority of faint galaxies have been missed due to incompleteness effects associated with current surveys.",
        "watermark_text": "We present an assessment of the predictive capacity of galaxy formation models by comparing their expectations for rest - frame optical luminosity functions ( LFs ) with observations over the redshift range z = 2 - 3 . We use two different quasi - analytic models , GALFORM and L - GALAXIES , to predict the evolution in number density as well as the distribution of stars masses and sun formation rates of clusters across this redshift interval .The predicted LF is compared closely against observational data acquired using the Hubble Space Telescope s Advanced Camera for Surveys ( ACS ) . In addition we compare the seen and predicted distributions of UV absolute magnitudes and dust - corrected colours .Our results show that both models are able to predict the overall shape of the seen LF but underpredict its normalisation by up to a factor of three . This discrepancy can be largely accounted for if one suppose that the majority of distant galaxies have been missed due to incompleteness effects involved with current surveys .",
        "ori-fast-z-score": 0.8551861104941365,
        "water-fast-z-score": 4.677476657214644
    },
    {
        "original_text": "We propose an excitable convolutional neural network (CNN) model for solving the 2D path planning problem in this work. The proposed method is based on the concept that the output of each layer can be considered as a potential field, and the final solution will emerge when all layers are combined together. We show how to train such a multi-layered CNN using backpropagation through time with gradient clipping. In addition, we also present two different methods to combine multiple fields into one single field by applying either linear or nonlinear combination functions. Finally, we demonstrate our approach on several benchmark problems including maze navigation, robotics motion planning, and autonomous driving. Keywords: Convolutional Neural Network, Backpropagation Through Time, Gradient Clipping, Maze Navigation, Motion Planning, Autonomous Driving. 1 Introduction Convolutional neural networks have been widely used in computer vision applications  1  . Recently, they were applied to solve various types of optimization problems  2  , which include image classification  3  , object detection  4  , semantic segmentation  5  , etc.. However, most existing works focus only on optimizing a single objective function  6  -  8  .\nIn many real-world applications, there may exist more than one objective function  9  . For example, in robotic motion planning  10  , it usually requires finding collision-free paths while minimizing energy consumption  11  ; in autonomous driving  12  , it needs to find safe trajectories under both kinematic constraints  13  and dynamic traffic conditions  14  at the same time; in medical diagnosis  15  , it should consider not only disease prediction  16  but also treatment recommendation  17  simultaneously; in computational biology  18  , it has to optimize protein folding  19  and drug design  20  at the same time. Therefore, it becomes necessary to develop new algorithms to handle multi-objective optimization problems  21  .\nRecently, deep reinforcement learning  22  was introduced to address multiobjective optimization problems  23  . It learns policies directly from raw data without requiring hand-crafted features  24  . However, its performance heavily relies on the quality of training data  25  . Moreover, it often suffers from high sample complexity  26  due to the large number of",
        "watermark_text": "We suggest an excitable convolutional neural network ( CNN ) model for solving the 2D route planning problem in this project . The proposed approach is based on the idea that the output of each layer can be regarded as a potential field , and the finished problem will emerge when all layers are united together .We see how to train such a multi - layered CNN use backpropagation through time with gradient clipping . In addition , we also demonstrate two different methods to mix multiple fields into one single field by using either linear or nonlinear combination operations .Finally , we prove our approach on numerous benchmark problems namely maze navigation , robotics motion plan , and autonomous driving . Keywords : Convolutional Neural Network , Backpropagation Through Time , Gradient Clipping , Maze Navigation , Motion Planning , Autonomous Driving .1 Introduction Convolutional neural systems have been widely using in computer vision solutions 1 . Recently , they were applied to solve many kinds of algorithms problems 2 , which include image characterization 3 , object discovery 4 , semantic segmentation 5 , etc . .However , most existing works concentrate only on optimizing a single objective function 6 - 8 . In many real - time users , there may contain more than one objective function 9 .For instance , in robotic motion plan 10 , it generally needs finding collision - safe paths while minimizing electricity demand 11 ; in autonomous steering 12 , it must to find safe trajectories under both kinematic limits 13 and dynamic transportation conditions 14 at the same time ; in medical treatment 15 , it should consider not only disease prediction 16 but also treatment recommendation 17 simultaneously ; in computational genetics 18 , it has to optimize protein folding 19 and drug design 20 at the same time . Therefore , it becomes necessary to develop new algorithms to manage multi - goal optimization problems 21 .Recently , deep reinforcement testing 22 was introduced to address multiobjective optimization problems 23 . It learns policies directly from pure data without using hand - crafted functionality 24 .However , its reliability strongly depends on the performance of training data 25 . Moreover , it often suffers from high sample complexity 26 related to the huge amount of",
        "ori-fast-z-score": 0.6172133998483676,
        "water-fast-z-score": 9.14991421995628
    },
    {
        "original_text": "We report on the detection by Fermi Large Area Telescope (LAT) of prompt emission in gamma rays with energies above 100 MeV associated with GRB 080916C, one of the brightest bursts ever detected at high energy. The LAT data show that this emission is highly variable and peaks within 1 s after the onset of the burst. We find no evidence for spectral evolution during the first few hundred seconds following the trigger time. A simple power law fit to the LAT spectrum yields an index of -2.2 +/-.1 over the range 100 MeV - 10 GeV. This value is consistent with previous measurements made using Konus-Wind and AGILE satellites but differs significantly from those obtained by other instruments operating below 100 MeV. Our results are inconsistent with models which predict a softening of the photon spectrum as it evolves into the X-ray band. They also rule out scenarios where the high-energy photons originate solely from inverse Compton scattering off relativistic electrons accelerated in internal shocks. \n \n Keywords: Gamma-ray burst",
        "watermark_text": "We report on the discovery by Fermi Large Area Telescope ( LAT ) of prompt emission in gamma waves with energies above 100 MeV related with GRB 080916C , one of the brightest bursts ever observed at high energy . The LAT results show that this emission is strongly varied and spikes within 1 s after the beginning of the explosion .We see no evidence for spectral evolution during the first few hundred moments following the trigger time . A straightforward power law suited to the LAT spectrum gives an index of - 2 . 2 + / - . 1 over the range 100 MeV - 10 GeV .This value is compatible with previous measurements made using Konus - Wind and AGILE spacecraft but varies dramatically from those achieved by other satellites operating below 100 MeV . Our results are inconsistent with models which predict a softening of the photon spectrum as it evolves into the X - ray band .They even figure out situations where the high - energy photons arise solely from inverse Compton absorption off relativistic electrons accelerated in internal shocks . Keywords : Gamma - ray burst",
        "ori-fast-z-score": -0.5933908290969266,
        "water-fast-z-score": 5.815230125149881
    },
    {
        "original_text": "We present here a detailed discussion on the concept of allovalency, which is defined as the simultaneous binding to multiple sites in one molecule by different ligands (or receptors). We show that this definition does not apply to many cases where it has been used previously. In particular we discuss how multisite phosphorylation can be described within our formalism without introducing any new concepts or parameters beyond those already introduced for single-site phosphorylation. Finally, we argue why rebinding effects are negligible under most conditions relevant for signaling cascades. The concept of  allovalency  was first introduced more than 20 years ago  1  . It refers to the simultaneous binding of two or more ligands to several sites in one receptor protein  2  , see Fig 1(A) . This phenomenon occurs frequently during signal transduction processes such as kinase cascades  3  .\nThe term  allovalent  was coined because it describes a situation intermediate between monovalent and multivalent interactions  4  : while each ligand binds only once per receptor, there may exist several copies of the same ligand bound simultaneously to the same receptor. Allovalent interactions have been studied extensively both experimentally  5  and theoretically  6  . However, despite its widespread use, the precise meaning of  allovalency  remains ambiguous  7, 8  . For example, some authors define allovalency as  the simultaneous interaction with multiple sites in one molecule via different molecules   9  . Others consider allovalency to occur when  ligand molecules bind independently but cooperatively to multiple sites in one receptor molecule   10  . Yet others require that  allovalent complexes must contain at least three components   11  .",
        "watermark_text": "We see here a detailed discussion on the notion of allovalency , which is characterized as the concurrent binding to multiple sites in one molecule by various ligands ( or receptors ) . We see that this definition does not apply to many situations where it has been used earlier .In particular we explain how multisite phosphorylation can be described within our formalism without mentioning any new concepts or parameters beyond those already adopted for single - location phosphorylation . Finally , we explain why rebinding impacts are negligible under most situations relevant for pathway cascades .The concept of allovalency was first applied more than 20 years early 1 . It refers to the concurrent binding of two or more ligands to several sites in one receptor protein 2 , see Fig 1 ( A ) .This phenomenon occurs commonly during signal transduction processes such as kinase cascades 3 . The term allovalent was developed because it describes a situation intermediate between monovalent and multivalent interactions 4 : while each ligand binds only once per receptor , there may contain many versions of the same ligand attached simultaneously to the same receptor .Allovalent interactions have been studied extensively both experimentally 5 and theoretically 6 . However , despite its widespread using , the exact significance of allovalency remains ambiguous 7 , 8 .For instance , some writers define allovalency as the concurrent interaction with many sites in one molecule via different molecules 9 . Others consider allovalency to occur when ligand molecules interact independently but cooperatively to multiple sites in one receptor molecule 10 .Yet others require that allovalent complexes must include at least three components 11 .",
        "ori-fast-z-score": -0.4833682445228318,
        "water-fast-z-score": 6.538530488755173
    },
    {
        "original_text": "We report on the observation of an unusual temperature dependence of the resistive transition width and its scaling with the applied magnetic field for single crystals of MgB2 grown using chemical vapor transport (CVT). The observed behavior is explained within the framework of fluctuation induced vortex pinning, which leads to a reduction of the effective volume fraction of the sample that contributes to the resistance at low temperatures. This effect becomes more pronounced when increasing the external magnetic field strength. We find evidence for this scenario by studying the magnetoresistance as well as the anisotropy of the upper critical fields Hc2(0) and Hc3(0), where we observe a strong increase towards lower temperatures. Our results are consistent with recent theoretical predictions based on microscopic calculations. \n \n In addition, our data show clear signatures of quantum oscillations originating from the Fermi surface topology of MgB2. These observations provide further insight into the electronic structure of this material.",
        "watermark_text": "We report on the observation of an peculiar thermal relation of the resistive transition width and its scaling with the applied magnetic force for single crystals of MgB2 grown utilizing chemical vapor transport ( CVT ) . The observed behavior is studied within the framework of fluctuation induced vortex locking , which results to a reduction of the effective volume fraction of the sample that adds to the tolerance at low temperatures .This phenomenon grows more pronounced when increasing the external magnetic force power . We get data for this situation by examining the magnetoresistance as well as the anisotropy of the higher critical forces Hc2 ( 0 ) and Hc3 ( 0 ) , where we study a large rise towards cooler temperatures .Our results are compatible with recent theoretical estimates based on microscopic calculations . In addition , our statistics demonstrate strong signatures of quantum oscillations originating from the Fermi surface topology of MgB2 .These measurements give further insight into the electronic topology of this material .",
        "ori-fast-z-score": -0.5698028822981898,
        "water-fast-z-score": 6.039910552360811
    },
    {
        "original_text": "We present the results of subjective evaluation experiments conducted on forms designed for use within immersive environments, such as virtual reality (VR) and augmented reality (AR). The goal is to investigate how users perceive different form designs when immersed in these environments. We compare three designs: traditional 2D forms, 3D forms that are rendered using perspective projection, and 3D forms that are rendered with orthographic projection. Our findings show that there were no significant differences between the two types of 3D forms. However, both 3D forms received significantly higher ratings than their 2D counterparts. This suggests that 3D forms can be used effectively in immersive environments without requiring special rendering techniques or additional hardware. In addition, we found that participants preferred forms that had more visual cues indicating depth information over those that did not have any such cues. Finally, our study also shows that it may be possible to create effective forms by combining elements from multiple existing designs.",
        "watermark_text": "We present the results of subjective assessment research conducted on forms designed for use within immersive environments , such as virtual reality ( VR ) and augmented reality ( AR ) . The goal is to examine how people interpret different form shapes when immersed in these habitats .We contrast three models : traditional 2D forms , 3D shapes that are rendered using view projection , and 3D shapes that are rendered with orthographic projection . Our findings show that there were no considerable variations between the two forms of 3D shapes .However , both 3D shapes took significantly greater grades than their 2D counterparts . This shows that 3D shapes can be used effectively in immersive environments without using special graphics techniques or additional hardware .In addition , we concluded that participants favored forms that had more graphical cues implying depth knowledge over those that did not have any such cues . Finally , our research also shows that it could be possible to create effective forms by combining components from multiple older patterns .",
        "ori-fast-z-score": -1.1043152607484654,
        "water-fast-z-score": 7.067617668790178
    },
    {
        "original_text": "We revisit the foundations of quantum mechanics by introducing an alternative formulation to the standard Feynman path integral approach, which is based on the concept of dynamical phase transition (DPT). We show that this new formalism provides a natural description for the emergence and evolution of macroscopic order in open quantum systems. In particular we demonstrate how it can be used to describe the spontaneous emission process in atomic physics, where the atom-field interaction leads to the formation of collective states with well-defined photon number statistics. The proposed framework also allows us to study the dynamics of many-body interacting systems beyond mean field theory. Finally, we discuss possible applications of our results to condensed matter physics and quantum information science. Introduction:-The development of modern theoretical approaches has led to significant progress in understanding the physical properties of complex quantum systems  1  . However, despite these advances there are still fundamental questions about the nature of quantum phenomena that remain unanswered  2  .\nIn recent years, several authors have attempted to address some of these issues using concepts borrowed from statistical mechanics  3  , such as entropy  4  or free energy  5  . These ideas were originally developed within the context of classical thermodynamics  6  but they have been recently extended to the realm of quantum mechanics  7, 8  . For example, one may consider the von Neumann entropy S = −Tr(ρ ln ρ) associated with the density matrix ρ describing the state of a system  9  . This quantity measures the amount of uncertainty present in the measurement outcomes  10  and its time derivative dS/dt gives rise to the so-called entropy production rate  11  . It was shown that this latter quantity plays a crucial role in characterizing the irreversible behavior of closed quantum systems  12  . More specifically, if the entropy production rate vanishes then the corresponding quantum mechanical model exhibits reversible dynamics  13  . On the other hand, when the entropy production rate becomes positive the system undergoes a non-equilibrium phase transition  14  .",
        "watermark_text": "We revisit the foundations of quantum mechanics by offering an additional formulation to the standard Feynman path integral approach , which is based on the notion of dynamical phase change ( DPT ) . We suggest that this new formalism gives a natural explanation for the emergence and evolution of macroscopic order in open quantum systems .In particular we prove how it can be used to explain the spontaneous emission mechanism in nuclear physics , where the atom - field interaction results to the formation of collective states with good - defined photon number statistics . The proposed framework specifically allows us to study the dynamics of several - bodies interacting systems beyond mean field theory .Finally , we explain possible applied of our findings to condensed matter science and quantum information physics . Introduction : - The advance of modern conceptual approaches has led to significant progress in understanding the physical properties of complex quantum systems 1 .However , despite these developments there are still significant questions about the nature of quantum effects that continue unanswered 2 . In recent months , various published have tried to tackle some of these problems using concepts borrowed from statistical mechanics 3 , such as entropy 4 or free energy 5 .These concepts were formerly advanced within the context of classical thermodynamics 6 but they have been lately extended to the domain of quantum mechanics 7 , 8 . For instance , one may see the von Neumann entropy S = −Tr ( ρ ln ρ ) associated with the density function ρ describing the state of a system 9 .This value measures the extent of uncertainty found in the measurement processes 10 and its time derivative dS / dt gives rise to the so - called entropy production probability 11 . It was shown that this latter quantity plays a crucial role in characterizing the irreversible behavior of closed quantum systems 12 .More specifically , if the entropy production level vanishes then the associated quantum mechanical model shows reversible dynamics 13 . On the other hand , when the entropy production level gets positive the system undergoes a non - equilibrium phase change 14 .",
        "ori-fast-z-score": 1.5523010514126656,
        "water-fast-z-score": 9.615384615384615
    },
    {
        "original_text": "In this work, we study spin effect on resonant tunneling characteristics in double-barrier heterostructure under longitudinal stresses by using transfer matrix method and density functional theory (DFT). We find that the energy gap decreases with increasing stress for both majority-spin electrons and minority-spin holes. The decrease is more significant for minority-spin holes than for majority-spin electrons. In addition, the transmission coefficient increases with increasing stress at low bias voltage but decreases at high bias voltage. This behavior can be explained as follows. At low bias voltage, the increase of transmission coefficient results mainly from the reduction of barrier height due to compressive stress. However, at high bias voltage, the decrease of transmission coefficient comes from two factors: one is the increase of effective mass induced by tensile stress; another is the enhancement of electron-phonon interaction caused by tensile stress. Finally, it should be noted that our calculation shows that the spin-orbit coupling has little influence on the transport properties of the system considered here.",
        "watermark_text": "In this research , we study spin effect on resonant tunneling parameters in dual - barrier heterostructure under longitudinal strain by using transfer matrix method and density functional theory ( DFT ) . We see that the power gap falls with increasing stress for both majority - spinning electrons and minority - spinning holes .The reduction is more considerable for minority - spin holes than for majority - spinning electrons . In addition , the transmission coefficient increases with varying stress at low bias frequency but decreases at high bias voltage .This phenomenon can be understood as follows . At small bias power , the increase of transmission coefficient proceeds primarily from the reduction of barrier height owing to compressive stress .However , at high bias voltage , the decrease of transmission coefficient happens from two factors : one is the improvement of effective mass induced by tensile tension ; another is the enhancement of electron - phonon interaction resulting by tensile tension . Finally , it should be mentioned that our calculation demonstrates that the spin - orbit interaction has little influence on the travel properties of the system discussed here .",
        "ori-fast-z-score": 0.5129891760425771,
        "water-fast-z-score": 6.668859288553502
    },
    {
        "original_text": "We present results from direct cosmological hydrodynamic simulations that follow the formation of supermassive black holes (SMBHs) in galactic nuclei, their subsequent evolution through mergers with other SMBHs, and the associated feedback on galaxy properties. We find that:  The simulated SMBH mass function agrees well with observations at z = 0 for M• > 10^7M_solar.  At higher redshifts, our model predicts too many low-mass SMBHs compared to observational estimates based on quasar luminosity functions; this discrepancy may be due to uncertainties in the assumed duty cycle or radiative efficiency of quasars.  Our models predict an average Eddington ratio distribution that is consistent with observed distributions inferred from optical/UV emission lines.  In addition, we show that the predicted relation between BH mass and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass.",
        "watermark_text": "We present results from direct cosmological hydrodynamic simulations that take the formation of supermassive black holes ( SMBHs ) in galactic nuclei , their ensuing evolution through mergers with other SMBHs , and the associated feedback on star dynamics . We see that : The simulated SMBH weight distribution agrees well with observations at h = 0 for M • > 10 ^ 7M _ solar .At higher redshifts , our model predicts too many lowest - weight SMBHs compared to observational projections based on quasar luminosity functions ; this discrepancy may be due to uncertainties in the expected duty cycle or radiative efficiency of quasars . Our models predict an estimated Eddington density distribution that is compatible with observed distributions inferred from optical / UV absorption lines .In addition , we prove that the expected relation between BH weight and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass .",
        "ori-fast-z-score": -0.508000508000762,
        "water-fast-z-score": 4.318004318006477
    },
    {
        "original_text": "The search is performed using data collected by the BABAR experiment at SLAC in 1999-2000, corresponding to an integrated luminosity of about 40 fb-1 . No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair.  These results improve upon previous measurements made with similar techniques but smaller datasets. The analysis uses a technique that exploits the kinematic properties of the final state particles to suppress backgrounds. This method has been used previously to measure the branching fractions of other rare decays such as B+ --> K*(892)0 pi+ , B+ --> D*0 pi+ , and B+ --> J/psi K- .\nPACS numbers: 11.30.Er, 12.15.Hh, 13.20.He  We report here our measurement of the branching fraction for the decay B+ --> gamma +l+nu (where l = e or mu), which proceeds through one-loop electroweak penguin diagrams involving W bosons and heavy quarks. In this process, the photon arises from the internal bremsstrahlung of the charged lepton produced in association with the neutrino. The Standard Model predicts a branching fraction of 1.1 x 10-6  1  . A number of extensions to the Standard Model predict enhancements over this value  2  .  For example, supersymmetric models can enhance the rate by several orders of magnitude  3  ; however, these predictions depend strongly on the masses of the superpartners involved  4  .",
        "watermark_text": "The survey is conducted using data taken by the BABAR study at SLAC in 1999 - 2000 , corresponding to an integrated luminosity of about 40 fb - 1 . No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair .These conclusions build upon recent observations made with similar method but smaller datasets . The analysis involves a technique that exploits the kinematic effects of the finished state particles to suppress patterns .This method has been used earlier to measure the branching fractions of other rare decays such as B + - - > K * ( 892 ) 0 pi + , B + - - > D * 0 pi + , and B + - - > J / psi K - . PACS scores : 11 . 30 . Er , 12 . 15 . Hh , 13 . 20 . He We report here our measurement of the branching percentage for the decay B + - - > gamma + l + nu ( where l = e or mu ) , which goes through one - ring electroweak penguin diagrams featuring W bosons and light quarks .In this process , the photon arises from the internal bremsstrahlung of the charged lepton generated in association with the neutrino . The Standard Model predicts a branching fraction of 1 . 1 x 10 - 6 1 .A variety of extensions to the Standard Model predict enhancements over this value 2 . For instance , supersymmetric theories can increase the rate by many orders of magnitude 3 ; however , these predictions rely highly on the masses of the superpartners involved 4 .",
        "ori-fast-z-score": -2.0855209398041166,
        "water-fast-z-score": 4.2808061395979236
    },
    {
        "original_text": "We study the effect of interactions on the transport properties of double quantum dot systems with Rashba spin-orbit coupling using numerical renormalization group (NRG) calculations. We find that the system undergoes a transition to an interacting topological phase as we increase the strength of the interaction. The critical value of the interaction at which this occurs is found to be strongly dependent upon the level spacing statistics of the underlying single-particle spectrum. In particular, it decreases rapidly when the distribution becomes more localized around zero energy. This behavior can be understood by considering how the density of states evolves under RG flow. Finally, we show that the fluctuations in the local magnetic moment are suppressed near the transition point due to the formation of singlet pairs. DOI: 10.1063/1.5015481\nI. INTRODUCTORY REMARkS\nThe recent discovery of Majorana fermions has led to renewed interest in studying non-abelian anyons in condensed matter physics  1  . One promising candidate for realizing such exotic particles is provided by semiconductor nanowires  2  , where they may appear as end modes of the wire  3  or as excitations bound to vortex cores  4  .\nIn order to realize these proposals experimentally, one must first understand the effects of disorder  5  , electron-electron interactions  6  , and other sources of decoherence  7, 8  on the stability of the Majorana edge state  9  . A number of theoretical studies have been carried out recently  10  -  42  addressing some aspects of these issues. However, many open questions remain regarding the interplay among various physical mechanisms responsible for the appearance of Majoranas in realistic experimental setups.\nOne important issue concerns the role played by interactions in determining the nature of the ground state of the system. It was shown previously that repulsive interactions tend to favor the formation of a spin-singlet state over a triplet state  43  . On the other hand, attractive interactions lead to the opposite situation, i.e., the formation of a spin-triplet state instead of a singlet state  44  . These results were obtained",
        "watermark_text": "We research the impact of coupling on the transport properties of double quantum dot systems with Rashba spin - orbit interaction using numerical renormalization group ( NRG ) techniques . We see that the system undergoes a shift to an interacting topological phase as we increase the strength of the interaction .The essential value of the interaction at which this appears is found to be highly dependent upon the level spacing statistics of the underlying single - particle spectrum . In particular , it decreases quickly when the distribution gets more localized around zero energy .This phenomenon can be understood by examining how the density of states evolves under RG flow . Finally , we find that the fluctuations in the local magnetic point are suppressed near the shift point due to the formation of singlet pairs .DOI : 10 . 1063 / 1 . 5015481 I . INTRODUCTORY REMARkS The recent discovery of Majorana fermions has led to renewed interest in investigating non - abelian anyons in condensed matter science 1 .One promising candidate for realizing such unconventional particles is provided by semiconductor nanowires 2 , where they may present as end modes of the wire 3 or as excitations bound to vortex cores 4 . In order to realize these proposals experimentally , one must first realize the effects of disorder 5 , electron - atom bonding 6 , and other sources of decoherence 7 , 8 on the stability of the Majorana edge state 9 .A variety of theoretical experiments have been carried out recently 10 - 42 exploring some elements of these problems . However , many open questions remain regarding the interplay among various physical mechanisms involved for the emergence of Majoranas in ideal empirical setups .One important concern regards the part played by interactions in shaping the nature of the ground state of the system . It was shown ago that repulsive effects tend to prefer the formation of a spin - singlet state over a triplet state 43 .On the other hand , attractive interactions result to the opposite condition , i . e . , the formation of a spin - triplet state rather of a singlet state 44 . These conclusions were obtained",
        "ori-fast-z-score": -0.48989794855663565,
        "water-fast-z-score": 6.740358479519649
    },
    {
        "original_text": "We present exact solutions for the electromagnetic field in the presence of spherical particles with arbitrary dielectric functions, including both metals and insulators. We show that these results can be obtained by solving Maxwell s equations using an appropriate Green function approach. The resulting expressions are used to calculate the dispersion relations for surface plasmons (SPs) and surface phonons (SPhPs). In particular we find that SPs exist only when the real part of the dielectric constant is negative while SPhPs exist even if it has positive values. Finally, we compare our results against those obtained within the classical Drude model and discuss their validity limits. Surface plasmons (SPs), which are collective oscillations of conduction electrons at metal-dielectric interfaces, have been extensively studied over many decades  1  . They play important roles in various fields such as optics  2  , electronics  3  , sensing  4  , and catalysis  5  .\nRecently there has also been growing interest in studying surface phonon-polaritons (SPhPs), which are analogous excitations associated with longitudinal acoustic waves  6  . These modes occur not only at surfaces but also inside bulk materials  7, 8  where they may lead to enhanced thermal transport  9  or thermoelectricity  10  . Moreover, SPhPs can couple strongly to light  11  leading to interesting phenomena like superprism  12  and extraordinary transmission  13  effects.",
        "watermark_text": "We present precise solutions for the electromagnetic field in the presence of spherical objects with arbitrary dielectric functions , including both metals and insulators . We see that these results can be obtained by treating Maxwell s equations using an appropriate Green function method .The resulting expressions are using to estimate the dispersion relations for surface plasmons ( SPs ) and surface phonons ( SPhPs ) . In particular we find that SPs occur only when the real part of the dielectric constant is zero while SPhPs exist even if it has negative values .Finally , we compare our findings against those achieved within the classical Drude theory and consider their efficacy limits . Surface plasmons ( SPs ) , which are collective oscillations of conduction electrons at metal - dielectric connections , have been heavily explored over numerous years 1 .They play essential roles in different fields such as optics 2 , electronics 3 , sensing 4 , and catalysis 5 . Recently there has especially been growing interest in investigating surface phonon - polaritons ( SPhPs ) , which are analogous excitations associated with longitudinal acoustic waves 6 .These modes happen not only at surfaces but also inside bulk surfaces 7 , 8 where they may contribute to heightened thermal transport 9 or thermoelectricity 10 . Moreover , SPhPs can close intensely to light 11 contributing to curious phenomena like superprism 12 and exceptional transmission 13 phenomena .",
        "ori-fast-z-score": -0.8164965809277261,
        "water-fast-z-score": 6.25846794771944
    },
    {
        "original_text": "We present new results on the kinematics and dynamics of the circumnuclear region (CNR) of NGC 1097, based on integral field spectroscopy with SINFONI at VLT/UT4. We find that the CNR is dominated by two components: an inner disk-like structure extending to about 1 kpc radius, and a fast outflowing component along PA∼45°extending up to 5 kpc distance from the nucleus. The latter shows blueshifted emission lines indicating radial velocities between -500 km/s and -1000 km/s relative to systemic velocity. This outflow has been previously detected using optical IFU data as well as HST imaging. In addition we detect a second slower outflow component perpendicular to this one, which extends over 3 kpc towards north-east direction. Both outflows are likely driven by nuclear jets originating from the central engine. Using simple models for the gas distribution and kinematics, we estimate mass inflow rates into the CNR ranging from 0.1 M⊙ yr-1 to several solar masses per year.",
        "watermark_text": "We report new data on the kinematics and dynamics of the circumnuclear portion ( CNR ) of NGC 1097 , using on integral field spectroscopy with SINFONI at VLT / UT4 . We see that the CNR is dominated by two parts : an inner disk - like structure extending to about 1 kpc radius , and a slow outflowing component along [UNK] up to 5 kpc length from the nucleus .The latter shows blueshifted emission lines suggesting radial velocities between - 500 km / s and - 1000 kilometers / s relative to systemic speed . This outflow has been previously observed using optical IFU data as well as HST scanning .In addition we perceive a second smaller outflow portion parallel to this one , which extends over 3 kpc towards north - eastward direction . Both outflows are likely generated by nuclear jets arising from the main motor .Using simple methods for the gas distribution and kinematics , we estimate mass inflow rates into the CNR ranging from 0 . 1 [UNK] yr - 1 to several solar masses per year .",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 5.498051602938211
    },
    {
        "original_text": "We present the two-loop corrections to nuclear matter within an effective field theory approach based on chiral perturbation theory and relativistic mean-field theory. The calculation is performed using dimensional regularization, minimal subtraction at one loop order and the modified minimal subtraction scheme at higher orders. We find that the results are consistent with previous calculations obtained by other methods such as Feynman diagrams or dispersion relations. In addition we show how our method can be used to calculate the energy density functional up to next-to-next-to-leading order. This work was supported by the U.S. \n\n\nDepartment of Energy under Contract No. DE-AC02-05CH11231. PACS: 11.10.Kk, 12.38.Gc, 14.20.Dh, 25 .75.-q, 26.60.+z, 27.40.-n, 27.70.+f, 28.30.-j",
        "watermark_text": "We present the two - loop corrections to nuclear material within an efficient field model approach based on chiral perturbation theory and relativistic mean - field theory . The calculation is conducted using dimensional regularization , minimal subtraction at one loop order and the modified minimal subtraction scheme at higher orders .We see that the results are compatible with previous calculations obtained by other methods such as Feynman diagrams or dispersion relations . In addition we prove how our technique can be used to estimate the power concentration functional up to next - to - next - to - leading order .This project was supported by the U . S . Department of Energy under Contract No . DE - AC02 - 05CH11231 .PACS : 11 . 10 . Kk , 12 . 38 . Gc , 14 . 20 . Dh , 25 . 75 . - q , 26 . 60 . + z , 27 . 40 . - h , 27 . 70 . + f , 28 . 30 . - j",
        "ori-fast-z-score": 0.282842712474619,
        "water-fast-z-score": 3.394112549695428
    },
    {
        "original_text": "We report the discovery of a new satellite galaxy, dubbed  A pair of bootes  (ApoBootes), orbiting around our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of 1.5 x 10^10 M_sun . ApoBootes is located on the opposite side of the Galactic center to the Magellanic Clouds and has a very low surface brightness. We have used deep near-infrared images taken by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this object. The photometric properties are consistent with those expected for a dwarf spheroidal galaxy. This work was supported by the Australian Research Council Discovery Project funding scheme under grant DP130104011. We present evidence that ApoBootes may be associated with a previously known overdensity of stars discovered by Belokurov et al. (2007) using SDSS data.",
        "watermark_text": "We report the discovery of a new satellite galaxy , nicknamed A couple of bootes ( ApoBootes ) , orbiting around our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of 1 . 5 x 10 ^ 10 M _ sun . ApoBootes is situated on the opposite end of the Galactic center to the Magellanic Clouds and has a very low exterior brightness .We have utilized deep near - infrared images obtained by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this body . The photometric properties are compatible with those expected for a dwarf spheroidal galaxy .This research was supported by the Australian Research Council Discovery Project grant program under grant DP130104011 . We present evidence that ApoBootes might be identified with a previously known overdensity of stars found by Belokurov et al .( 2007 ) used SDSS information .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.437601569801833
    },
    {
        "original_text": "The book is intended as an introduction to the physics and mathematics underlying the problem of how proteins fold into their native three-dimensional structures.  The main topics covered are statistical mechanics, molecular dynamics simulations, energy landscapes, phase transitions in complex systems, and self-organization phenomena. It also contains several examples illustrating these concepts using simple models of proteins. This book will be useful not only for graduate students studying biophysics but also for researchers interested in interdisciplinary problems such as pattern formation or self-assembly processes. Contents:  Preface 1 Introduction 2 Statistical mechanics 3 Energy landscape 4 Phase transition 5 Self-organization 6 Molecular dynamics 7 Protein folding 8 References 9 Index 10 Appendix A 11 Appendix B 12 Bibliography 13 Acknowledgements 14 Glossary 15 Answers to selected exercises 16 Solutions to selected exercises 17 Sample chapters 18 Sample solutions 19 Sample data 20 Sample programs 21 Sample animations 22 Sample movies 23 Sample figures",
        "watermark_text": "The text is intended as an intro to the physics and mathematics underlying the question of how proteins turn into their natural three - dimensional shapes . The main fields examined are mathematical mechanics , molecular biology simulations , energy landscapes , phase transitions in complex systems , and self - assembly processes .It additionally contains several examples illustrating these concepts using simple models of proteins . This book will be valuable not only for college students studying biophysics but also for researchers interested in interdisciplinary problems such as sequence development or self - assembly processes .Contents : Preface 1 Introduction 2 Statistical mechanics 3 Energy landscape 4 Phase transition 5 Self - agreement 6 Molecular dynamics 7 Protein folding 8 References 9 Index 10 Appendix A 11 Appendix B 12 Bibliography 13 Acknowledgements 14 Glossary 15 Answers to selected exercises 16 Solutions to selected exercises 17 Sample chapters 18 Sample solutions 19 Sample information 20 Sample programs 21 Sample animations 22 Sample videos 23 Sample figures",
        "ori-fast-z-score": 1.2309149097933272,
        "water-fast-z-score": 5.662208585049306
    },
    {
        "original_text": "We report on an imaging survey carried out in 2004-05 using speckle differential imager (SDI) at the Very Large Telescope (VLT) and Multiple Mirror Telescope (MMT). We have detected no companions down to ~5 AU projected separation within 50 mas of 45 young stars. The detection limits are estimated by injecting fake planets into real data sets and recovering them through PSF subtraction techniques. Our results suggest that there is little or no excess number of close-in giant planets orbiting these nearby young stars compared to field stars. This result may be explained if most extrasolar planets form beyond 5 AU but migrate inward during their formation process. Alternatively, it could also mean that planet formation is suppressed near the central star due to photoevaporation and/or tidal effects.  These results will provide important constraints on models of planet migration as well as planet formation theories. Keywords: Planet search; Nearby stars",
        "watermark_text": "We report on an imaging survey conducted out in 2004 - 05 combining speckle differential imager ( SDI ) at the Very Large Telescope ( VLT ) and Multiple Mirror Telescope ( MMT ) . We have discovered no companions down to ~ 5 AU estimated separation within 50 mas of 45 young stars .The detection limits are estimated by injecting fake stars into real information sets and recovering them through PSF subtraction techniques . Our results show that there is much or no excess amount of close - in massive planets orbiting these nearby young galaxies compared to field stars .This result may be understood if most extrasolar stars create beyond 5 AU but migrate inward during their formed mechanism . Alternatively , it could also mean that planet development is suppressed near the main star due to photoevaporation and / or tidal issues .These data will provide important restrictions on predictions of planet migration as well as planet development explanations . Keywords : Planet search ; Nearby stars",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 5.578319375835658
    },
    {
        "original_text": "We present an analytical model for the magneto-rotational instability (MRI) in protoplanetary disks, which is based on the assumption that the disk can be divided into two regions with different physical properties and dynamics. The inner region has a high density and temperature, while the outer one is less dense but hotter than the surrounding medium. We show how this simple picture allows us to reproduce many observed features of MRI-driven turbulence in accretion disks around young stars. In particular, we find that:  -The growth rate of the fastest growing mode decreases rapidly towards smaller radii due to the increasing gas pressure.  -The radial profile of the turbulent viscosity follows closely the profile of the magnetic field strength.  -The angular momentum transport efficiency increases strongly at small radii because of the rapid increase of the surface density there.  -The predicted mass accretion rates are consistent with those inferred observationally for T Tauri stars.",
        "watermark_text": "We present an analytical theory for the magneto - rotational instability ( MRI ) in protoplanetary disks , which is based on the assumption that the disk can be broken into two zones with varying material structures and dynamics . The outer sector has a high density and heat , while the inner one is greater dense but brighter than the nearby medium .We see how this straightforward photo lets us to depict many observed features of MRI - driven turbulence in accretion balls around early stars . In particular , we find that : - The growth speed of the fastest growing mode decreases quickly towards smaller radii due to the increasing gas pressure .- The radial profile of the chaotic viscosity follows carefully the profile of the magnetic force strength . - The angular velocity transport rate grows heavily at small radii because of the quick expansion of the surface volume there .- The predicted mass accretion levels are compatible with those inferred observationally for T Tauri stars .",
        "ori-fast-z-score": -1.2535663410560174,
        "water-fast-z-score": 5.8119893994415355
    },
    {
        "original_text": "We present near-infrared (NIR) polarimetry and spectroscopy for the bipolar reflection nebula IRAS 19312; 1950 . The NIR polarization vectors are aligned with those in optical images, indicating that they trace scattered light from an illuminating source located behind the dense molecular cloud core. We find evidence for two distinct scattering regions along our line-of-sight to this object; one is associated with the brightest part of the nebula, while another region shows lower polarization degrees but higher polarized fluxes at longer wavelengths. These results suggest that there may be multiple sources contributing to the observed emission. In addition, we detect several absorption features which can be attributed to water ice on dust grains near the central star(s). Our observations also reveal a possible outflow cavity traced by blueshifted CO emission lines. This work was supported by NASA through grant number HST-GO-11775.0-A from STScI, operated under NASA contract NAS5-26555.",
        "watermark_text": "We use near - infrared ( NIR ) polarimetry and spectroscopy for the bipolar reflection nebula IRAS 19312 ; 1950 . The NIR polarization vectors are aligned with those in imaging photographs , showing that they trace stray light from an illuminating source located behind the deep molecular mist center .We see evidence for two separate scattering regions along our line - of - seeing to this body ; one is associated with the brightest part of the nebula , while another region shows lesser polarization degrees but higher polarized fluxes at shorter wavelengths . These conclusions propose that there may be several sources responsible to the seen emission .In addition , we find various absorption properties which can be due to liquid ice on dust grains near the primary star ( s ) . Our observations also confirm a possible outflow cavity identified by blueshifted CO radiation patterns .This project was supported by NASA through grant number HST - GO - 11775 . 0 - A from STScI , operated under NASA contract NAS5 - 26555 .",
        "ori-fast-z-score": -0.9701425001453319,
        "water-fast-z-score": 6.305926250944657
    },
    {
        "original_text": "We present an analysis of the first two years (Feb 2005 -Jan 2007) of data taken by the Swift satellite, which has been designed to detect and study gamma ray bursts (GRBs). We find that GRB 050904 at z = 6.3 is the most distant object ever detected in the electromagnetic spectrum. The prompt emission was observed over more than four orders of magnitude in energy, from radio waves up to X-rays. This burst also had one of the highest fluences recorded so far for any GRB. In addition we report on another burst, GRB 080913, whose afterglow was found to be variable on timescales as short as 1 minute. These results are discussed within the context of current models for GRB production. Keywords: Gamma-ray burst, High-redshift universe, Afterglows, Swift satellite. Gamma-ray bursts (GRBs), intense flashes of high-energy radiation lasting only milliseconds, have now been discovered out to redshifts greater than six  1  . Their extreme luminosities make them powerful probes into the early Universe  2  , but their origin remains unknown  3  .\nSwift  4  , launched in November 2004, carries three instruments capable of detecting GRBs across the entire electromagnetic spectrum  5  : the Burst Alert Telescope  6  detects GRBs via their X-ray and/or optical emissions; the Ultraviolet/Optical Telescope  7  observes the afterglow through ultraviolet and visible light; and the X-ray telescope  8  monitors the afterglow s decaying flux. Here we describe our initial findings using these instruments during the first two years of operation. \nThe Burst Alert Telescope\n\nBurst Alert Telescope Observations of GRB 050904\nOn September 5 th , 2006, the Burst Alert Telescope triggered on a bright source located at RA=05h54m36.6s Dec=-69d21 59.6   9  . Follow-up observations revealed this event to be a new record holder among GRBs  10  . Its peak photon count rate reached 2 x 10 4 photons s -1 cm -2 in the 15-150 keV band  11  . It lasted about",
        "watermark_text": "We present an assessment of the first two years ( Feb 2005 - Jan 2007 ) of evidence gained by the Swift satellite , which has been designed to identify and track γ ray clusters ( GRBs ) . We see that GRB 050904 at z = 6 . 3 is the most distant object ever observed in the electromagnetic spectrum .The prompt emission was seen over more than four orders of magnitude in energy , from radio beams up to X - rays . This burst also had one of the highest fluences recorded so far for any GRB .In addition we paper on another burst , GRB 080913 , whose afterglow was shown to be varying on timescales as short as 1 minute . These conclusions are discussed within the context of recent versions for GRB development .Keywords : Gamma - ray flare , High - redshift universe , Afterglows , Swift satellite . Gamma - ray clusters ( GRBs ) , intense pulses of high - energy rays lasting only milliseconds , have now been detected out to redshifts greater than six 1 .Their intense luminosities give them potent probes into the early Universe 2 , but their source remains unidentified 3 . Swift 4 , launched in November 2004 , carries three devices capable of detecting GRBs across the entire electromagnetic spectrum 5 : the Burst Alert Telescope 6 detects GRBs via their X - ray and / or laser emissions ; the Ultraviolet / Optical Telescope 7 sees the afterglow through ultraviolet and visible radiation ; and the X - ray observatory 8 monitors the afterglow s decaying flux .Here we explain our first findings using these instruments during the first two years of operation . The Burst Alert Telescope Burst Alert Telescope Observations of GRB 050904 On September 5 th , 2006 , the Burst Alert Telescope triggered on a bright source located at RA = 05h54m36 . 6s Dec = - 69d21 59 . 6 9 .Follow - up observations showed this event to be a new record holder among GRBs 10 . Its peak photon number rate reached 2 x 10 4 photons s - 1 cm - 2 in the 15 - 150 keV band 11 .It lasted about",
        "ori-fast-z-score": 0.4703604341917986,
        "water-fast-z-score": 7.243550686553699
    },
    {
        "original_text": "We study the interplay between thermal percolating states and jammed states in disordered systems by using Monte Carlo simulations for dimers adsorbing onto binary alloy surfaces with different compositions. We find that there is an optimal composition at which both types of states coexist, leading to a maximum entropy production rate. The coexistence state has been observed experimentally as well. Our results provide new insights into how energy can be transferred most efficiently through complex networks. Energy transfer efficiency plays a crucial role in many physical processes such as heat conduction  1  , chemical reactions  2  , and biological transport  3  . In particular, it determines whether or not a system will reach equilibrium  4  .\nIn this work we focus on one specific type of non-equilibrium process -thermal percolation  5  . Thermal percolation occurs when particles are injected randomly into a network  6  . Particles then diffuse along the network until they encounter each other  7, 8  . When two particles meet, their energies combine irreversibly  9  . This leads to a cascade-like spreading of particle density  10  . As more particles are added, the number of clusters increases  11  . Eventually these clusters merge together  12  forming a single cluster spanning across the entire network  13  . At this point all particles have combined into a giant cluster  14  . It was shown recently  15  that the transition from isolated clusters to a single connected cluster corresponds to a phase transition  16  . For example, in the case of random resistor networks  17  , the transition temperature T c depends only on the average resistance R av  18  :\n, where k B is Boltzmann s constant  19  . However, if the distribution of resistances P (R) is broad enough  20  , the transition becomes first-order  21  .",
        "watermark_text": "We research the interplay between thermal percolating states and jammed states in disordered systems by using Monte Carlo simulations for dimers adsorbing onto binary alloy surfaces with various compositions . We see that there is an appropriate composition at which both types of states coexist , leading to a maximum entropy production speed .The coexistence state has been observed experimentally as also . Our results bring fresh insights into how energy can be transferred most efficiently through complex networks .Energy transfer efficiency plays a crucial role in different mechanical reactions such as heat conduction 1 , chemical processes 2 , and biological transport 3 . In particular , it determines whether or not a system will achieve optimal 4 .In this research we focus on one specific sort of non - equilibrium process - temperature percolation 5 . Thermal percolation occurs when molecules are pumped randomly into a network 6 .Particles then diffuse along the channel until they encounter each other 7 , 8 . When two particles contact , their energies combine irreversibly 9 .This leads to a cascade - like movement of particle concentration 10 . As more particles are adding , the total of clusters increases 11 .Eventually these complexes combined together 12 producing a single cluster spans across the entire system 13 . At this time all fragments have combined into a giant cluster 14 .It was shown recently 15 that the shift from separated clusters to a single connected cluster corresponds to a phase shift 16 . For instance , in the case of distributed resistor networks 17 , the transition rate T c varies only on the average resistance R av 18 : , where k B is Boltzmann s constant 19 .However , if the distribution of resistances P ( R ) is broad sufficiently 20 , the shift remains first - order 21 .",
        "ori-fast-z-score": -0.09016696346674323,
        "water-fast-z-score": 7.244860247099318
    },
    {
        "original_text": "We report on the controlled collision between an individual trapped atom and a singly charged ion in a Paul trap, where both particles are confined to different regions of space separated by several micrometers. The ions can be moved along the axis connecting them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber. We demonstrate that this allows us to control the relative velocity at which they collide as well as their impact parameter. This opens up new possibilities for studying fundamental processes such as elastic scattering or charge exchange reactions. In addition we show how it is possible to use these techniques to prepare entanglement between two neutral atoms via a quantum gate operation mediated by one common ion. Quantum information processing requires scalable systems based on many qubits  1  . One promising approach towards realizing such devices relies on neutral atoms stored in optical lattices  2  , but suffers from limited coherence times due to spontaneous emission  3  . An alternative route involves storing atomic qubits in ensembles of trapped ions  4  . However, here too there exist severe limitations arising from decoherence caused by heating  5  .\nIn order to overcome these difficulties, hybrid approaches have been proposed  6  combining advantages of both schemes  7, 8  . Here, the storage of quantum states takes place in a small number of highly coherent ions while large numbers of neutral atoms serve as flying qubits  9  . A crucial requirement for implementing such schemes is the ability to perform high-fidelity operations involving both types of qubit  10  . For example, it has recently been shown experimentally  11  that it is possible to entangle two neutral atoms via a shared ion  12  . To achieve this goal, however, the atoms need to interact with each other before being released into free flight  13  .",
        "watermark_text": "We report on the controlled collision between an individual captured molecule and a singly charged particle in a Paul cage , where both particles are localized to different regions of space separated by many micrometers . The atoms can be moved along the axis linking them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber .We suggest that this enables us to predict the relative velocity at which they collide as also as their impact parameter . This opens up new possibilities for studying basic processes such as elastic scattering or charge transfer reactions .In addition we show how it is easy to use these techniques to make entanglement between two neutral ions via a quantum gate action mediated by one common ion . Quantum electronic processing requires scalable systems based on various qubits 1 .One promising alternative towards developing such devices relies on neutral particles deposited in laser lattices 2 , but suffers from reduced coherence times due to spontaneous emission 3 . An alternative approach requires storing atomic qubits in ensembles of confined ions 4 .However , here too there remain considerable restrictions arose from decoherence caused by temperature 5 . In try to overcome these problems , hybrid approaches have been proposed 6 combining characteristics of both schemes 7 , 8 .Here , the storage of quantum states takes place in a small number of highly coherent electrons while small numbers of neutral particles serve as flying qubits 9 . A crucial requirement for employing such schemes is the ability to conduct high - fidelity operations involving both types of qubit 10 .For instance , it has recently been shown experimentally 11 that it is possible to entangle two neutral ions via a shared ion 12 . To achieve this goal , however , the atoms need to interact with each other before being transferred into free flight 13 .",
        "ori-fast-z-score": 1.3241694217637887,
        "water-fast-z-score": 8.765781549553733
    },
    {
        "original_text": "The chemical compositions of the type II Cepheid variables are investigated by using high-resolution spectra obtained with Subaru/HDS, Keck/HIRES, VLT/UVES, and McDonald/DEIMOS spectrographs.  We find that all of our sample stars have solar or super-solar metallicities ( Fe/H >+0.2). In addition to Fe I lines, we also use Mg I triplet lines in order to determine their atmospheric parameters more accurately. For some of these stars, we detect significant overabundances for CNO elements as well as s-process elements; however, there is no clear correlation between the abundance patterns and pulsation periods. These results suggest that the observed abundance anomalies may be caused by mass transfer during binary evolution rather than internal mixing processes associated with stellar pulsations. This work was supported by JSPS Grant-in-Aid for Scientific Research on Priority Areas No. 16071203.",
        "watermark_text": "The chemical compositions of the class II Cepheid variables are examined by using high - resolution spectra obtained with Subaru / HDS , Keck / HIRES , VLT / UVES , and McDonald / DEIMOS spectrographs . We see that all of our sample stars have solar or super - solar metallicities ( Fe / H > + 0 . 2 ) .In addition to Fe I lines , we also need Mg I triplet lines in order to predict their atmospheric parameters more accurately . For some of these stars , we perceive considerable overabundances for CNO elements as well as s - process elements ; however , there is no clear correlation between the abundance patterns and pulsation periods .These data suggest that the reported abundance anomalies may be caused by mass transfer during binary development rather than internal mix processes associated with stars pulsations . This research was supported by JSPS Grant - in - Aid for Scientific Research on Priority Areas No .16071203.",
        "ori-fast-z-score": 1.1920791213585393,
        "water-fast-z-score": 4.370956778314644
    },
    {
        "original_text": "We study the slow wave resonance (SWR) effect for periodically layered media with an arbitrary number N of anisotropic layers, each characterized by its own permittivity tensor and thickness. We show that SWR is possible only if all principal axes of the permittivity tensors are parallel to one another within each layer. In this case we derive explicit expressions for the dispersion relation between the frequency f and the Bloch wavenumber kx. The results obtained can be used as guidelines for designing multilayered structures exhibiting strong SWR effects at low frequencies. \n \n Keywords: Slow wave resonance; Anisotropy; Multilayer structure; Dispersion relations. 1 Introduction \n \n Periodic multilayers consisting of alternating thin films made of different materials have attracted considerable attention during recent years due to their unique properties  1  . These include high reflectance  2  , negative refraction  3  , enhanced nonlinear optical response  4  , etc., which make them promising candidates for various applications such as optoelectronic devices  5  or photovoltaics  6  .\n \nIn particular, it has been shown recently  7–9  that periodic multilayers composed of anisotropic layers may exhibit very interesting electromagnetic phenomena including slow wave resonance (S WR). This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium  10  . It leads to extremely large values of the effective refractive index n eff = c / v ph  11  where c is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode  12  . As a result, the corresponding transmission spectrum exhibits sharp peaks associated with narrow stop bands  13  . Such features are highly desirable for many practical applications  14  . \n \n However, despite numerous theoretical studies devoted to S WR in periodic multilayers  15–18  , there still exist several open questions related to the conditions under which this phenomenon takes place  19, 20  . For example, it was found experimentally  21  that the presence of a single misaligned anisotropic layer destroys the S WR effect completely even though other layers remain perfectly aligned. On the other hand, numerical simulations  22  suggest that",
        "watermark_text": "We explore the slow frequency resonance ( SWR ) effect for regularly layered media with an arbitrary number N of anisotropic layers , each described by its own permittivity matrix and thickness . We see that SWR is possible only if all primary directions of the permittivity tensors are connected to one another within each surface .In this situation we derive explicit expressions for the dispersion constant between the frequency f and the Bloch wavenumber kx . The results derived can be used as guidelines for constructing multilayered buildings presenting strong SWR effects at low frequencies .Keywords : Slow wave vibration ; Anisotropy ; Multilayer structure ; Dispersion relations . 1 Introduction Periodic multilayers consisting of alternating thin sheets formed of different materials have garnered considerable scrutiny during recent seasons due to their distinct characteristics 1 .These include high reflectance 2 , negative refraction 3 , enhanced nonlinear optical reaction 4 , etc . , which make them promising candidates for various uses such as optoelectronic technologies 5 or photovoltaics 6 . In particular , it has been shown ago 7 – 9 that periodic multilayers consisting of anisotropic surfaces may exhibit very interesting electrical processes including slow frequency resonance ( S WR ) .This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium 10 . It results to incredibly large values of the effective refractive index n eff = c / u ph 11 where p is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode 12 .As a result , the associated transmission spectrum exhibits severe spikes identified with narrow stop rings 13 . Such characteristics are extremely practical for numerous practical applications 14 .However , despite several theoretical experiments devoted to S WR in periodic multilayers 15 – 18 , there still appear several open questions related to the conditions under which this phenomenon happens place 19 , 20 . For instance , it was shown experimentally 21 that the presence of a single misaligned anisotropic surface destroys the S WR effect totally even though other layers remain perfectly aligned .On the other hand , numerical simulations 22 suggest that",
        "ori-fast-z-score": -0.15811388300841897,
        "water-fast-z-score": 8.432781346758377
    },
    {
        "original_text": "We present the results of our analysis on the mass-to-light ratio (M/L) of Lyman alpha emitters (LAEs), based on data obtained by Subaru/Suprime-Cam in the fields surrounding four quasars with redshifts 5.7 < zqso < 6.6. We use photometric redshift techniques to select LAE candidates within a narrow window around each quasar s emission line redshift. The M/L values are derived using SED fitting for individual galaxies as well as stacked samples. Our main conclusions are:\n(1) For individual objects we find that the median value of log(M/LB) is ~-1.8 dex over the range of luminosities probed here.  This result suggests that most LAEs have low stellar masses compared to typical LBGs.\n(2) Stacking analyses show that the average M/LB increases towards higher luminosity bins. In particular, the highest luminosity bin has an average log(M/LB ) = -1.3 ± 0.4 dex which corresponds to a factor of 3 lower than what would be expected if these systems were dominated by old stars alone.",
        "watermark_text": "We present the conclusion of our analysis on the mass - to - light percentage ( M / L ) of Lyman alpha emitters ( LAEs ) , using on evidence derived by Subaru / Suprime - Cam in the fields surrounding four quasars with redshifts 5 . 7 < zqso < 6 . 6 . We use photometric redshift methods to select LAE candidates within a small frame around each quasar s absorption system redshift .The M / L values are derived using SED fitting for individual galaxies as well as piled specimens . Our main results are : ( 1 ) For individual objects we find that the average value of log ( M / LB ) is ~ - 1 . 8 dex over the range of luminosities probed here .This result suggests that most LAEs have lowest stellar masses compared to normal LBGs . ( 2 ) Stacking calculations show that the average M / LB increases towards higher luminosity bins .In particular , the highest luminosity bin has an estimated log ( M / LB ) = - 1 . 3 ± 0 . 4 dex which equals to a factor of 3 lower than what would be anticipated if these systems were dominated by ancient stars alone .",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 5.093248125762992
    },
    {
        "original_text": "We report on results obtained by INTEGRAL observations during the 2005 outburst of the black hole candidate GRO J1655â€“40 (Nova Muscae 1991). The source was observed in the 20-100 keV range for about 100 days, starting at MJD 53000 and ending at MJD 53300. We have analyzed these data using both ISGRI and SPI instruments aboard INTEGRAL satellite. In addition to the main spectral component which is well described by a power law model modified by an exponential cutoff, we find that there are two additional components present in the spectrum. One of them has been previously reported by other authors but its origin remains unclear. Another one appears only when fitting the whole dataset simultaneously with all three models considered here -power law plus exponential cut-off, broken power law or Comptonization model-. This new feature can be interpreted either as a reflection hump produced by cold material surrounding the central X-ray source or as a broad iron line around 6.4 keV.",
        "watermark_text": "We report on findings obtained by INTEGRAL observations during the 2005 outburst of the dark hole member GRO J1655â€ “ 40 ( Nova Muscae 1991 ) . The source was seen in the 20 - 100 keV range for about 100 months , beginning at MJD 53000 and ending at MJD 53300 .We have analyzed these information using both ISGRI and SPI instruments aboard INTEGRAL satellite . In addition to the main spectral component which is well described by a power law description altered by an exponential cutoff , we find that there are two additional components available in the spectrum .One of them has been previously reported by other researchers but its identity remains unsure . Another one appears only when fitting the whole dataset jointly with all three models described here - energy law plus exponential cutting - off , broken power law or Comptonization model - .This new feature can be interpreted either as a absorption hump produced by cold matter surrounding the main X - ray source or as a broad iron line around 6 . 4 keV .",
        "ori-fast-z-score": 1.212678125181665,
        "water-fast-z-score": 6.305926250944657
    },
    {
        "original_text": "We study the remnants produced by merging two CO WDs with different masses and spin configurations, using fully general relativistic hydrodynamic simulations. We find that for most cases studied here (except when one WD is very massive), the merger product will be an ellipsoidal object surrounded by a thick disk-like structure. The final mass of this merged system ranges between 0.6-1.1 M⊙ depending on the initial conditions. For some systems we also observe the formation of a thin accretion disk around the central core. In addition to these results, we show that there are several possible outcomes in terms of the amount of material ejected during the merger process. Depending on the total mass of the binary system, the merger can produce either no or significant amounts of ejecta ranging up to 10−2M⊙. Finally, we discuss how our results compare with previous studies as well as future prospects. \n \n Keywords: White dwarfs",
        "watermark_text": "We research the remnants created by merging two CO WDs with various masses and spin configurations , using fully basic relativistic hydrodynamic simulations . We see that for most instances explored here ( except when one WD is very huge ) , the merger result will be an ellipsoidal object surrounded by a thick disk - like structure .The final weight of this fused core runs between 0 . 6 - 1 . 1 [UNK] depending on the early conditions . For some systems we also observe the formation of a thin accretion ring around the main core .In addition to these results , we find that there are several possible outcomes in terms of the amount of material displaced during the merger process . Depending on the total mass of the binary system , the merger can produce either no or significant amounts of ejecta ranging up to [UNK] .Finally , we explain how our findings compare with previous research as well as future prospects . Keywords : White dwarfs",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.103161130233569
    },
    {
        "original_text": "Erbium-doped fiber amplifiers (EDFAs) are widely used in the field of telecommunication and sensing applications due to their high gain, low noise figure, wide bandwidths and compatibility with silica fibers. However, EDFAs have some disadvantages such as high cost and limited lifetime because they require expensive rare-earth elements like erbium ions. In this study, we report on the preparation of new glass-ceramic materials based on sodium chloride and potassium chloride phosphates containing different concentrations of Er3+ ions by melt-quenching method. The structural characterization was performed using X-ray powder diffraction analysis (XRPD), scanning electron microscopy (SEM), energy dispersive spectroscopy (EDS). Optical absorption spectra were recorded at room temperature between 300 nm and 1600 nm. Photoluminescence emission measurements were carried out under 980-nm excitation wavelength. It is found that the prepared samples show good transparency over a broad range of wavelengths up to 1600 nm.",
        "watermark_text": "Erbium - doped cable amplifiers ( EDFAs ) are widely useful in the field of telecommunication and monitoring applications due to their high gain , low noise figure , large bandwidths and compatibility with silica fibers . However , EDFAs have some disadvantages such as great price and poor lifetime because they use cost rare - earth elements like erbium ions .In this study , we publish on the preparation of new glazed - glass compounds based on sodium salts and potassium chloride phosphates containing different amounts of Er3 + ions by melt - quenching procedure . The structural characterization was done utilizing X - ray powder diffraction assessment ( XRPD ) , scanning electron microscopy ( SEM ) , energy dispersive spectroscopy ( EDS ) .Optical absorption spectra were collected at room temperature between 300 nm and 1600 nm . Photoluminescence radiation observations were carried out under 980 - nm excitation wavelength .It is found that the prepared specimens display good transparency over a broad variety of wavelengths up to 1600 nm .",
        "ori-fast-z-score": 0.5852057359806528,
        "water-fast-z-score": 5.969098507002659
    },
    {
        "original_text": "We present new spectroscopic observations for the open cluster NGC 1883, which is located at a distance of about 1 kpc in the constellation Cassiopeia (α = 20 h 18 m , δ = +58°). The data were obtained with the 2-m telescope of the Observatorio Astronómico Nacional de San Pedro Mártir (OAN-SPM) on December 16-17, 2009 using the REOSC spectrograph equipped with grism #7 covering the wavelength range 3700-7000 Å. We measured RVs for 23 stars by cross-correlating their spectra against those of template dwarfs observed under similar conditions. Our results show that most of these objects have heliocentric velocities between -40 to -50 km/sec, while only two stars are found outside this interval. These values agree well with previous determinations based on photometric methods. \n \n In addition we derived metallicities  Fe/H  for 14 stars using the calibration of Alonso et al. (1999) . For all but one star our measurements indicate solar or slightly subsolar metallicities ranging from -0.10 dex up to +0.20 dex. Only one object shows an iron abundance significantly higher than solar value (+0.30 dex). \n \n Finally, we compared our results with previously published studies.",
        "watermark_text": "We report new spectroscopic observations for the open cluster NGC 1883 , which is situated at a distance of about 1 kpc in the constellation Cassiopeia ( α = 20 h 18 m , δ = + 58° ) . The data were obtained with the 2 - m observatory of the Observatorio Astronómico Nacional de San Pedro Mártir ( OAN - SPM ) on December 16 - 17 , 2009 using the REOSC spectrograph equipped with grism # 7 representing the frequency spectrum 3700 - 7000 Å .We calculated RVs for 23 stars by cross - correlating their spectra against those of template dwarfs observed under analogous conditions . Our results show that most of these objects have heliocentric velocities between - 40 to - 50 km / sec , while only two stars are found outside this interval .These quantities agree well with previous determinations based on photometric technique . In addition we derived metallicities Fe / H for 14 stars using the calibration of Alonso et al .( 1999 ) . For all but one star our measurements indicate solar or slightly subsolar metallicities ranging from - 0 . 10 dex up to + 0 . 20 dex .Only one element shows an metal density greatly higher than solar value ( + 0 . 30 dex ) . Finally , we compared our findings with previously reported surveys .",
        "ori-fast-z-score": 0.3779644730092272,
        "water-fast-z-score": 5.0
    },
    {
        "original_text": "We propose an explicit construction for a string model with gauge group SU(3)xSU(2)xU(1), three generations of quarks and leptons, right-handed neutrinos, and no exotic particles beyond those in the minimal supersymmetric standard model (MSSM). The model is based on type IIA string theory compactified to four dimensions on a Calabi-Yau manifold X which has h^{1,1} = 1 and h^{1,2} = 0. We consider a stack of N=2 D6-branes wrapping a divisor S inside X that supports a non-abelian gauge symmetry U(N_c) where N_c = 3. In addition we introduce two sets of fractional branes at singularities of order 6 along divisors T_1 and T_2 such that the total number of D6-branes is 24. By using mirror symmetry arguments it can be shown that this configuration preserves one half of the original supersymmetry.",
        "watermark_text": "We suggest an explicit construction for a string description with gauge group SU ( 3 ) xSU ( 2 ) xU ( 1 ) , three generations of quarks and leptons , right - handed neutrinos , and no exotic electrons beyond those in the reduced supersymmetric standard description ( MSSM ) . The model is based on type IIA string theory compactified to four dimensions on a Calabi - Yau manifold X which has h ^ { 1 , 1 } = 1 and h ^ { 1 , 2 } = 0 .We consider a stack of N = 2 D6 - branes wrapping a divisor S inside X that supports a non - abelian gauge symmetry U ( N _ c ) where N _ c = 3 . In addition we provide two sets of fractional branes at singularities of order 6 along divisors T _ 1 and T _ 2 such that the total number of D6 - branes is 24 .By using mirror symmetry arguments it can be shown that this configuration captures one part of the original supersymmetry .",
        "ori-fast-z-score": 1.1547005383792517,
        "water-fast-z-score": 3.464101615137755
    },
    {
        "original_text": "We present the results of spectral analysis for all Swift bursts with measured redshifts and durations longer than 2 s, using data obtained by the Burst Alert Telescope (BAT) on board Swift satellite. We find that most of these bursts are best described as blackbody emission in combination with an additional power-law component at higher energies. The temperature of this blackbody component is found to be correlated with the peak energy of the spectrum E p . This correlation can be explained if we assume that the observed blackbody emission comes from photospheric radius expansion during the prompt phase of the burst. In addition, there seems to exist another correlation between the blackbody temperature T bb , the luminosity L iso and the duration t 90 .\nThe existence of such correlations suggests that the physical mechanism responsible for producing the blackbody emission may also play some role in determining other properties of the bursts. \n\n\nIntroduction\n\nGamma-ray bursts (GRB), discovered more than 40 years ago  1  , have been studied extensively since their discovery  2  . However, many questions about them remain unanswered  3  . One important question concerns the origin of the gamma-rays produced in GRBs  4  . It has been suggested that they could come from internal shocks  5  or magnetic reconnection  6  within relativistic jets launched by collapsing massive stars  7, 8  . Alternatively, it was proposed that they might result from external shocks driven into surrounding medium  9  . Another open issue is whether GRBs are standard candles  10  . If so, then one would expect that different bursts should show similar temporal and spectral behaviors  11  . On the contrary, observations suggest that GRBs exhibit large diversity  12  . Finally, the nature of the progenitors of GRBs remains unknown  13  .",
        "watermark_text": "We present the conclusion of spectral study for all Swift bursts with recorded redshifts and durations greater than 2 s , using data acquired by the Burst Alert Telescope ( BAT ) on board Swift satellite . We see that most of these bursts are best described as blackbody emission in combination with an additional power - law component at higher energies .The temperature of this blackbody element is found to be correlated with the maximum energy of the spectrum E p . This variance can be understood if we suppose that the seen blackbody emission arises from photospheric radius expansion during the prompt phase of the explosion .In addition , there seems to arise another interaction between the blackbody altitude T bb , the luminosity L iso and the duration t 90 . The fact of such correlations indicates that the physical process used for producing the blackbody emission may even hold some role in determining other properties of the pulses .Introduction Gamma - ray bursts ( GRB ) , detected more than 40 years previously 1 , have been studied thoroughly since their discovery 2 . However , many issues about them remain unanswered 3 .One important question concerns the origin of the gamma - radiation generated in GRBs 4 . It has been proposed that they may come from internal shocks 5 or gravitational reconnection 6 within relativistic jets launched by collapsing large galaxies 7 , 8 .Alternatively , it was suggested that they may come from external shocks driven into surrounding medium 9 . Another open problems is whether GRBs are standard candles 10 .If so , then one would suggest that different bursts should exhibit similar temporal and spectral patterns 11 . On the contrary , observations suggest that GRBs exhibit great diversity 12 .Finally , the nature of the progenitors of GRBs remains unidentified 13 .",
        "ori-fast-z-score": 0.18257418583505536,
        "water-fast-z-score": 8.272727272727273
    },
    {
        "original_text": "We study numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating, which is known to be able to support stable levitation of drops in air.  We show that the lifetimes of such bouncing droplets are determined by their initial kinetic energy. The dependence of the lifetime on this energy can be fitted well using a power law t ~ E0−α where α = 0.5 ± 0.1 for both numerical simulations and experiments. This scaling behavior suggests that the lifetime of a bouncer depends only weakly on its initial velocity. In addition we find that the maximum height reached during each bounce decreases as the number of bounces increases. Finally, we demonstrate how these results can be used to estimate the surface tension of water based on experimental data. Bouncing droplets have been studied extensively over recent years due to their potential applications in microfluidics  1  . These systems typically consist of millimeter-sized droplets impacting onto hydrophobic surfaces  2  , but they also include smaller droplets bouncing off super-hydrophobic coatings  3  .\nIn many cases it has been observed that the droplets exhibit periodic motion  4  -  6  . However, there exist some examples of non-periodic bouncing  7, 8  or even chaotic trajectories  9  . It was shown recently  10  that the lifetimes (i.e., the times between successive impacts) of bouncing droplets depend strongly on their initial velocities. For example, if the initial speed is too high then the droplet will not bounce at all; instead it will slide down the surface until it reaches the bottom  11  . On the other hand, if the initial speed lies below a certain threshold value then the droplet will bounce indefinitely  12  .",
        "watermark_text": "We research numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating , which is known to be possible to support steady levitation of drops in air . We see that the lifetimes of such bouncing droplets are decided by their initial kinetic power .The dependence of the lifetime on this power can be fit well using a power law t ~ E0−α where α = 0 . 5 ± 0 . 1 for both numerical simulations and experiments . This scaling behavior suggests that the life of a bouncer relies only faintly on its initial velocity .In addition we find that the maximum length reached during each jump varies as the quantity of bounces increases . Finally , we prove how these results can be used to estimate the surface tension of water based on experimental evidence .Bouncing droplets have been studied frequently over recent history owing to their potential applications in microfluidics 1 . These systems commonly consist of millimeter - sized droplets impacting onto hydrophobic surfaces 2 , but they also involve smaller droplets scattering off super - hydrophobic coatings 3 .In many situations it has been observed that the droplets display periodic motion 4 - 6 . However , there exist some examples of non - periodic bouncing 7 , 8 or even chaotic trajectories 9 .It was shown recently 10 that the lifetimes ( i . e . , the periods between successive impacts ) of tumbling droplets depend greatly on their initial velocities . For instance , if the first velocity is too high then the droplet will not drop at all ; merely it will slide down the surface until it meets the bottom 11 .On the other hand , if the first velocity lies below a certain level level then the droplet will bounce indefinitely 12 .",
        "ori-fast-z-score": 0.3682298471593294,
        "water-fast-z-score": 7.118652518223773
    },
    {
        "original_text": "We propose an optical scheme for implementing the Gaussian valence bond (GVB) state, which is one of the most important classes of quantum states in condensed matter physics. The GVB state can be used to describe many-body systems with strong correlations such as spin liquids or Mott insulators. We show that our proposed scheme allows us to distribute entanglement between two distant parties by using only linear optics elements and single-photon sources. Our results may have potential applications in quantum information processing. \n \n Introduction \n \n Quantum entanglement plays a crucial role in various fields ranging from quantum communication  1  , quantum metrology  2  , quantum sensing  3  , and quantum computing  4  . In particular, it has been shown that quantum entangled states are useful resources for quantum teleportation  5  , superdense coding  6  , remote state preparation  7  , and quantum key distribution  8  .\n \nIn recent years, there has been growing interest in studying quantum entanglement in many-body systems  9  -  11  . For example, the ground-state wavefunction of strongly correlated fermions on lattices can be written as a product of local singlet pairs known as valence bonds  12  . This class of states is called valence-bond solid (VBS) states  13  . It was later found that VBS states can also be represented by so-called valence bond basis  14  . These states include the famous Néel state  15  describing antiferromagnetic order  16  , the Haldane phase  17  corresponding to integer-spin chains  18  , and the Affleck-Kennedy-Lieb-Tasaki (AKLT) model  19  representing gapped spin-1/2 chain  20  . \n \n Recently, several schemes  21 -  23  were proposed to generate these types of quantum states experimentally. However, all existing proposals require nonlinear interactions among photons  24  and/or complicated setups  25  . Therefore, they cannot be implemented easily in practice. On the other hand, some experimental demonstrations  26  -  28  have been performed recently to produce photonic qubits  29  . Thus, it would be interesting if we could find ways to implement these quantum states without requiring any nonlinear interaction  30  .",
        "watermark_text": "We suggest an optical scheme for incorporating the Gaussian valence bond ( GVB ) state , which is one of the most important classes of quantum states in condensed matter science . The GVB state can be used to define multiple - bodies systems with powerful correlations such as spin liquids or Mott insulators .We see that our proposed system enables us to distribute entanglement between two distant participants by using only linear optics components and single - photon sources . Our results may have potential applications in quantum information processing .Introduction Quantum entanglement plays a crucial role in different fields ranging from particle communication 1 , quantum metrology 2 , quantum sensing 3 , and quantum computing 4 . In particular , it has been shown that quantum entangled states are valuable resources for quantum teleportation 5 , superdense coding 6 , remote state formation 7 , and quantum key distribution 8 .In past decades , there has been growing interest in investigating quantum entanglement in large - bodies systems 9 - 11 . For instance , the ground - state wavefunction of highly correlated fermions on lattices can be written as a product of local singlet sets known as valence bonds 12 .This family of states is called valence - bond solid ( VBS ) states 13 . It was later known that VBS states can also be described by so - called valence bond basis 14 .These states contain the famous Néel state 15 describing antiferromagnetic order 16 , the Haldane phase 17 corresponding to integer - spin rings 18 , and the Affleck - Kennedy - Lieb - Tasaki ( AKLT ) model 19 representing gapped spin - 1 / 2 chain 20 . Recently , various strategies 21 - 23 were developed to produce these kinds of quantum states experimentally .However , all previous designs require nonlinear interactions among photons 24 and / or complicated setups 25 . Therefore , they cannot be deployed easily in practice .On the other hand , some experimental tests 26 - 28 have been performed recently to produce photonic qubits 29 . Thus , it would be exciting if we could discover ways to execute these quantum states without using any nonlinear interaction 30 .",
        "ori-fast-z-score": 0.4931969619160719,
        "water-fast-z-score": 7.6705107192336
    },
    {
        "original_text": "We present an analysis of pulsar observations to determine the magnetic field strength in the solar corona at heights between 1 and 3 R_Sun . We use data obtained with the Nançay Radio Telescope (NRT) for two different radio frequencies, 327 MHz and 1420 MHz, corresponding to emission heights of about 2 and 5 R_Sun , respectively. The observed pulse profiles are modeled using a simple model that includes contributions from both the local interstellar medium and the solar wind plasma. From these models we derive estimates for the coronal magnetic field strengths as well as the electron density distribution along the line-of-sight towards PSR B1133+16 .\nThe results show that the magnetic field decreases rapidly with height above the photosphere but is still strong enough to confine energetic particles up to several solar radii away from the Sun s surface. This suggests that particle acceleration processes may be taking place throughout most of the solar atmosphere.",
        "watermark_text": "We present an assessment of pulsar observations to estimate the magnetic force size in the solar corona at heights between 1 and 3 R _ Sun . We use data acquired with the Nançay Radio Telescope ( NRT ) for two different radio altitudes , 327 MHz and 1420 MHz , corresponding to emission heights of about 2 and 5 R _ Sun , respectively .The observed pulse profiles are modeled using a simple simulation that contains contributions from both the local interstellar material and the sun breeze plasma . From these models we derive estimates for the coronal magnetic field strengths as also as the electron concentration distribution along the line - of - view towards PSR B1133 + 16 .The results show that the magnetic force reduces rapidly with width above the photosphere but is nevertheless strong enough to confine energetic particles up to several solar radii away from the Sun s surface . This implies that particle acceleration processes possibly be taking place throughout most of the solar atmosphere .",
        "ori-fast-z-score": -0.35603449745815596,
        "water-fast-z-score": 4.780914437337574
    },
    {
        "original_text": "The Infrared Camera (IRC), one of the three instruments onboard the Astro-F satellite, is designed to perform imaging observations in four infrared bands centered at 2.4, 3.2, 4.1, and 12 micrometers with high sensitivity over wide fields-of-view ranging from 1 arcmin square to 10 degrees square. The IRC consists of two cameras; an optical camera equipped with a lens system having focal length of f = 50 mm and a near-infrared camera using a lens system with f = 100 mm. Both cameras are cooled down by liquid helium cryostats to temperatures below 5 K. A set of filters covering the entire wavelength range of each band is attached to both cameras. The performance of the IRC has been evaluated through laboratory measurements as well as in-orbit calibration experiments performed during the commissioning phase of the mission. The results show that the IRC meets all its design requirements.",
        "watermark_text": "The Infrared Camera ( IRC ) , one of the three devices onboard the Astro - F satellite , is designed to conduct imaging observations in four infrared bands centered at 2 . 4 , 3 . 2 , 4 . 1 , and 12 micrometers with high sensitivity over broad areas - of - view ranging from 1 arcmin square to 10 degrees square . The IRC contains of two lenses ; an optical camera equipped with a lens system having focal width of f = 50 mm and a far - infrared camera utilizing a lens system with h = 100 mm .Both instruments are heated down by liquid helium cryostats to altitudes below 5 K . A family of filters covering the entire wavelength range of each band is attached to both cameras . The reliability of the IRC has been examined through laboratory measurements as well as in - orbit calibration experiments conducted during the commissioning process of the mission .The results show that the IRC meets all its design criteria .",
        "ori-fast-z-score": 2.4618298195866544,
        "water-fast-z-score": 6.893123494842633
    },
    {
        "original_text": "We present new near-infrared (NIR) photometry and spectroscopy for the high-latitude star forming cloud, CG12. We find that this cloud is composed of two distinct populations; one population with ages <10 Myr and another older population with ages >100 Myr. Using N-body simulations we show that these clouds are likely to be remnants of tidally disrupted open clusters. This suggests that open cluster disruption may play an important role in the formation of isolated young stars at high latitudes. These results have implications on our understanding of how open clusters evolve into open clusters and open clusters into open clusters. Open clusters can also provide insight into the origin of open clusters themselves. In addition, open clusters can help us understand the evolution of open clusters as well as open clusters. Finally, open clusters can give us information about open clusters and open clusters. We use new infrared data obtained by the Wide Field Camera 3 (WFC3), Hubble Space Telescope (HST), and Spitzer Space Telescope (SST).",
        "watermark_text": "We report new near - infrared ( NIR ) photometry and spectroscopy for the high - latitude star producing storm , CG12 . We see that this cloud is composed of two separate populations ; one group with ages < 10 Myr and another older population with ages > 100 Myr .Using N - bodies simulations we find that these clouds are likely to be remnants of tidally disrupted open nuclei . This implies that open cluster disturbance may play an important role in the formation of isolated early stars at high latitudes .These data have consequences on our knowing of how open groups grow into open groups and open groups into open groups . Open clusters can also provide insight into the origin of open groups themselves .In addition , open groups can help us explain the evolution of open groups as well as open clusters . Finally , open groups can provide us information about open groups and open clusters .We use new infrared measurements obtained by the Wide Field Camera 3 ( WFC3 ) , Hubble Space Telescope ( HST ) , and Spitzer Space Telescope ( SST ) .",
        "ori-fast-z-score": -1.091089451179962,
        "water-fast-z-score": 5.45544725589981
    },
    {
        "original_text": "The electronic properties of solids are determined by their ground and excited state energies, which can be calculated using ab initio wave function-based approaches such as density functional theory (DFT). However, these calculations often suffer from an incomplete description of electron-electron interactions due to the use of approximate exchange-correlation potentials. In this work we present a method that allows us to correct DFT results for excited states with respect to exact many-body perturbation theory (MBPT) results. We apply our approach to calculate the optical absorption spectrum of MgO and compare it to experimental data. Our results show good agreement between experiment and theory over a wide range of photon energies. The presented methodology is applicable to any material where MBPT results exist or can be obtained within reasonable computational effort. This includes most semiconductors but also insulators like ionic compounds. \n \n Ab initio wave-function based methods have become standard tools for calculating the electronic properties of materials. These include ground-state total energy calculations  1 , phonon dispersion relations  2 , elastic constants  3 , magnetic moments  4 , and transport coefficients  5 . They are routinely used to predict structural phase transitions  6 , defect formation energies  7-9 , surface energies  10-12 , and chemical reactions  13-15 . Furthermore they provide insight into fundamental physical phenomena including superconductivity  16 , magnetism  17 , charge-density waves  18 , ferroelectricity  19 , and quantum critical points  20 . Finally, they allow one to study the effects of external perturbations on the electronic structure  21 , e.g., strain  22 , pressure  23 , electric fields  24 , temperature  25 , or doping  26 .",
        "watermark_text": "The electronic properties of solids are decided by their ground and excited state energies , which can be determined using ab initio wave function - based methods such as density functional theory ( DFT ) . However , these calculations often suffer from an incomplete description of electron - ion interactions due to the using of approximate transfer - correlation potentials .In this research we present a technique that enables us to correct DFT results for excited states with regard to exact large - bodies perturbation theory ( MBPT ) results . We use our approach to estimate the optical absorbed spectrum of MgO and compare it to experimental evidence .Our results show good agreement between experiment and theory over a broad variety of photon energies . The offered methodology is applicable to any material where MBPT results appear or can be obtained within reasonable numerical time .This encompasses most semiconductors but also insulators like ionic compounds . Ab initio wave - function independent methods have remain standard tools for determining the electronic properties of substances .These include ground - state total energy measurements 1 , phonon dispersion relations 2 , elastic constants 3 , electric moments 4 , and transport factors 5 . They are routinely used to predict structural phase transitions 6 , defect dissolution energies 7 - 9 , surface concentrations 10 - 12 , and biological enzymes 13 - 15 .Furthermore they give insight into fundamental physical phenomena including superconductivity 16 , magnetism 17 , charge - density waves 18 , ferroelectricity 19 , and quantum vital places 20 . Finally , they allow one to study the effects of external perturbations on the electronic system 21 , e . g . , stress 22 , pressure 23 , electric forces 24 , temperature 25 , or doping 26 .",
        "ori-fast-z-score": 0.7689218919450849,
        "water-fast-z-score": 7.545937746270389
    },
    {
        "original_text": "We present an analytic expression for the one-loop mass-less triangle Feynman integral in terms of generalized hypergeometric functions. The results are obtained by using Mellin-Barnes representation and contour integration techniques. We also provide numerical values for some special cases which can be used to check our analytical expressions. This work is motivated by recent interest on the study of higher order corrections to various physical processes, such as Higgs decay into two photons or gluons at next-to-leading-order (NLO) accuracy. \nI. INTRODUCTORY REMARK\nThe calculation of loop diagrams plays an important role in theoretical physics. In particular, it has been shown that the inclusion of radiative corrections leads to significant changes in the predictions of many observables  1  . For example, the NLO QCD correction to the decay widths of heavy quarks  2  , top quark pair production  3  , Higgs boson decays  4  etc., have been calculated recently with great success. However, there still remain several open problems related to the evaluation of multi-loop integrals  5  .\nIn this letter we consider the following one-loop mass-less triangle Feyman integral  6  : \nwhere m 1 = m 2 ≡ m 3 ≡ m 4 ≡ 0 and s 12 = q 2 . It should be noted here that I(q 2 ) vanishes when any three masses become equal i.e. m 1 = m 2 = m 3 = m 4 .",
        "watermark_text": "We introduce an analytic definition for the one - loop mass - less triangle Feynman integral in terms of generalized hypergeometric functions . The results are derived by using Mellin - Barnes representation and contour processing method .We additionally offer mathematical values for some particular instances which can be used to test our analytical expressions . This research is prompted by recent interest on the study of greater order corrections to several physical processes , such as Higgs decay into two photons or gluons at next - to - leading - order ( NLO ) accuracy .I . INTRODUCTORY REMARK The calculation of loop diagrams takes an important role in theoretical physics .In particular , it has been shown that the introduction of radiative corrections leads to significant improvements in the estimates of several observables 1 . For instance , the NLO QCD correction to the decay widths of hard quarks 2 , top quark pair production 3 , Higgs boson decays 4 etc . , have been measured recently with great success .However , there still continue several open problems related to the evaluation of multi - loop integrals 5 . In this letter we define the following one - loop mass - less triangle Feyman integral 6 : where m 1 = m 2 ≡ m 3 ≡ m 4 ≡ 0 and s 12 = q 2 .It should be mentioned here that I ( q 2 ) vanishes when any three masses become equal i . e . m 1 = m 2 = m 3 = m 4 .",
        "ori-fast-z-score": -0.10482848367219183,
        "water-fast-z-score": 5.421374765483944
    },
    {
        "original_text": "We present new exact half-BPS solutions to the low-energy effective action for type-IIB string theory in ten dimensions, which are supported by fluxes on an arbitrary number of intersecting D3-branes. These solutions can be viewed as generalizations of the single Janus solution presented in  1  . We also discuss some properties of these solutions that were not discussed previously. \n \n The first part of this work was published as: \n \n  2  C. A. Johnson et al., Phys. Rev. Lett. 106 (2011) 055005. DOI: 10.1103/PhysRevLett.106.055005. URL: http://arxiv.org/abs/1111.5389v2. URL: http://www.sciencedirect.com/science/article/pii/S0167971011000203. URL: https://inspirehep.net/record/126898/files/CAJohnson_et_al_PRL_2011_055005.pdf",
        "watermark_text": "We present new exact half - BPS treatments to the small - energy effective action for type - IIB string theory in ten dimensions , which are favored by fluxes on an arbitrary number of intersecting D3 - branes . These solutions can be viewed as generalizations of the single Janus solution offered in 1 .We addition explore some properties of these solutions that were not discussed earlier . The first part of this study was publication as : 2 C . A . Johnson et al . , Phys .Rev.Lett.106 (2011) 055005.DOI: 10.1103/PhysRevLett.106.055005.URL : http : / / arxiv . org / abs / 1111 . 5389v2 . URL : http : / / www . sciencedirect . com / science / article / pii / S0167971011000203 .URL : https : / / inspirehep . net / record / 126898 / files / CAJohnson _ et _ al _ PRL _ 2011 _ 055005 . pdf",
        "ori-fast-z-score": 0.7453559924999299,
        "water-fast-z-score": 2.897472836319489
    },
    {
        "original_text": "The effect of magnetic Reynolds number (Rm), Lundquist number (S) and plasma beta (β) on the efficiency of MRI-driven turbulence is investigated by means of direct numerical simulations in cylindrical geometry with periodic boundary conditions. The results show that Rm, S and β have significant effects on the saturation level of the Maxwell stress tensor as well as the growth rate of the kinetic energy density. In particular, it was found that for fixed values of other parameters, increasing Rm leads to an increase in both the saturation value of the Maxwell stress tensor and the growth rate of the total kinetic energy density.  Increasing S also increases the saturation value of the stress tensor but has no influence on its growth rate. On the contrary, decreasing β decreases the saturation value of the tensor while having little or no effect on its growth rate. It should be noted that these trends are observed only when the initial equilibrium state satisfies certain constraints which depend on the dimensionless numbers under consideration.",
        "watermark_text": "The impact of magnetic Reynolds number ( Rm ) , Lundquist number ( S ) and plasma beta ( β ) on the performance of MRI - driven turbulence is investigated by means of direct numerical simulations in cylindrical geometry with periodic boundary constraints . The results show that Rm , S and β have considerable effects on the saturation level of the Maxwell stress tensor as also as the development frequency of the kinetic power concentration .In particular , it was shown that for constant values of other parameters , increasing Rm leads to an increase in both the saturation value of the Maxwell stress tensor and the development rate of the total kinetic power concentration . Increasing S also increases the saturation value of the strain vector but has no impact on its rise rate .On the contrary , decreasing β decreases the saturation value of the tensor while having little or no effect on its increase time . It should be mentioned that these changes are observed only when the early equilibrium state satisfies certain constraints which depend on the dimensionless numbers under consideration .",
        "ori-fast-z-score": 2.2941573387056176,
        "water-fast-z-score": 6.882472016116853
    },
    {
        "original_text": "We present the first results for a new template family, called SEOBNRv4HM, which is designed to detect gravitational waves (GWs) emitted by comparable mass black hole binaries with total masses between 10 and 100 solar masses. We show that this template family can be used in searches for GW signals from binary black holes at current ground-based detectors such as Advanced LIGO/Virgo and KAGRA. In addition we demonstrate how these templates are useful for parameter estimation studies using simulated data sets. Finally, we discuss possible improvements on our work. Keywords: Binary black hole -Gravitational wave detector -Template family -Parameter estimation -SEOBNRv4HM -Advanced Virgo -LIGO -KAGRA -Black hole -Binary system -Gravitational wave signal -Gravitational wave astronomy -Gravitational wave source -Signal-to-noise ratio -Search algorithm -Simulation",
        "watermark_text": "We present the first findings for a new template family , known SEOBNRv4HM , which is designed to identify gravitational waves ( GWs ) emitted by similar mass black hole binaries with total masses between 10 and 100 solar masses . We see that this template family can be used in searches for GW signals from binary white holes at current ground - based detectors such as Advanced LIGO / Virgo and KAGRA .In addition we explain how these templates are helpful for parameter estimation studies employing simulated evidence sets . Finally , we explain possible advances on our work .Keywords : Binary white hole - Gravitational wave detector - Template family - Parameter estimation - SEOBNRv4HM - Advanced Virgo - LIGO - KAGRA - Black hole - Binary network - Gravitational wave noise - Gravitational wave astronomy - Gravitational wave source - Signal - to - noise ratio - Search algorithm - Simulation",
        "ori-fast-z-score": -1.1523319193960637,
        "water-fast-z-score": 3.2547227745205967
    },
    {
        "original_text": "The generalized twistor transform is an extension of the ordinary twistor transform to include particles with spin in arbitrary dimensions. It has been used recently for describing scattering amplitudes involving massive particles as well as massless ones. In this talk I will present some new results on the subject including a description of how one can use it to describe particles beyond free or massless theories. The talk will also cover recent developments related to dualities between different quantum field theories. This includes duality relations that have been found using the generalized twistor transform such as those relating N=4 super Yang-Mills theory to self-dual gravity and its supersymmetric extensions. Finally we will discuss how these ideas are connected to string theory. Generalized twistors were introduced by Witten more than twenty years ago  1  . They provide a powerful tool for studying gauge theories in general relativity  2  , and they play important roles in understanding various aspects of string/M-theory  3  .\nIn particular, the so-called Penrose limit  4  provides a way to relate scattering amplitudes in gauge/gravity theories at weak coupling to correlation functions in conformal field theories (CFTs) at strong coupling  5  . Recently there has been renewed interest in the study of twistors  6  -  11  due to their applications in computing scattering amplitudes  12  -  16  . For example, the tree-level S-matrix elements of gluons  17  and gravitons  18  in four-dimensional N = 4 Super-Yang-Mills theory (SYM), which was conjectured to be dual to type-IIB superstrings  19  , were computed via the generalized twistor transform  20  .",
        "watermark_text": "The generalized twistor transform is an extension of the ordinary twistor transform to consider objects with spin in arbitrary dimensions . It has been used lately for describing scattering amplitudes involving massive bodies as well as massless ones .In this talk I will present some different results on the subject including a description of how one can using it to explain objects beyond free or massless theories . The speech will also cover recent developments pertaining to dualities between various quantum field theories .This contains duality relations that have been seen using the generalized twistor transform such as those relating N = 4 super Yang - Mills theory to self - dual gravity and its supersymmetric extensions . Finally we will explore how these ideas are connected to string theory .Generalized twistors were introduced by Witten more than twenty years previously 1 . They offer a powerful tool for studying gauge fields in general relativity 2 , and they hold important roles in understanding various parts of string / M - theory 3 .In particular , the so - called Penrose limit 4 provides a way to relate scattering amplitudes in gauge / gravity fields at weak interaction to correlation functions in conformal field theories ( CFTs ) at weak correlation 5 . Recently there has been continued interest in the study of twistors 6 - 11 due to their applications in computing absorption amplitudes 12 - 16 .For instance , the tree - grade S - matrix elements of gluons 17 and gravitons 18 in four - dimensional N = 4 Super - Yang - Mills theory ( SYM ) , which was conjectured to be dual to type - IIB superstrings 19 , were computed via the generalized twistor transform 20 .",
        "ori-fast-z-score": 0.4622501635210242,
        "water-fast-z-score": 5.454551929548086
    },
    {
        "original_text": "In this article, we study cuspidal representations of general linear groups over discrete valuation rings. We prove that if the residue field is infinite and has characteristic zero then any irreducible representation which is unramified outside a finite set of primes is supercuspidal (Theorem 3). This result was previously known only for number fields. As an application, we show how to construct new examples of supercuspidal representations by taking tensor products with characters of tori (Proposition 4).\nWe also give some results on the structure of the space of smooth functions on G(R) where G is a reductive group defined over Q p . In particular, we show that if G = GL n , SL n or Sp 2n then there exists a dense subspace of smooth functions invariant under right translation by elements in G(Q p ) (Corollary 5). Finally, we use these results to compute the dimension of certain spaces of automorphic forms attached to cuspidal representations of GL 2 (A) (Propositions 6 and 7).",
        "watermark_text": "In this article , we study cuspidal forms of general linear categories over discrete valuation rings . We prove that if the residue field is infinite and has characteristic zero then any irreducible representation which is unramified outside a finite collection of primes is supercuspidal ( Theorem 3 ) .This result was formerly described only for number fields . As an application , we prove how to build new examples of supercuspidal representations by take tensor products with characters of tori ( Proposition 4 ) .We additionally give some results on the composition of the space of smooth functions on G ( R ) where G is a reductive group defined over Q p . In particular , we prove that if G = GL n , SL n or Sp 2n then there exists a dense subspace of smooth functions invariant under right translation by elements in G ( Q n ) ( Corollary 5 ) .Finally , we utilize these results to compute the dimension of certain spaces of automorphic forms assigned to cuspidal forms of GL 2 ( A ) ( Propositions 6 and 7 ) .",
        "ori-fast-z-score": -0.3841106397986879,
        "water-fast-z-score": 3.556003556005334
    },
    {
        "original_text": "We present the results of our investigation into how stellar evolution models are affected by individual element abundances in stars, focusing on the sensitivity to changes in helium abundance (Y). We use two different sets of evolutionary tracks with varying Y values for masses between 0.8 M⊙ and 8 M⊙ at solar metallicity. The first set is based on the Padova code while the second one uses the Geneva code. For each track we calculate synthetic spectra using the SPECTRUM code. These synthetic spectra are then used as input to determine the best-fit parameters of observed high-resolution optical spectra of Galactic open clusters. Our analysis shows that both codes produce similar results when fitting these cluster data. However, there are significant differences in the derived ages depending on which code was used. This discrepancy can be explained by the fact that the Padova tracks have been calculated without convective overshooting whereas the Geneva tracks include this effect.",
        "watermark_text": "We present the conclusion of our inquiry into how stellar evolution models are influenced by individual atom abundances in stars , concentrating on the sensitivity to changes in helium abundance ( Y ) . We use two different series of evolutionary tracks with varying Y readings for masses between 0 . 8 [UNK] and 8 [UNK] at solar metallicity .The first setting is based on the Padova code while the second one uses the Geneva code . For each track we estimate synthetic spectra using the SPECTRUM code .These synthetic spectra are then utilized as input to obtain the best - fitting characteristics of known high - resolution optical spectra of Galactic open clusters . Our study shows that both codes produce comparable results when fitting these cluster data .However , there are significant variations in the derived ages varying on which coding was used . This discrepancy can be reason by the fact that the Padova lines have been measured without convective overshooting whereas the Geneva tracks include this effect .",
        "ori-fast-z-score": 1.7556172079419585,
        "water-fast-z-score": 6.50986776965388
    },
    {
        "original_text": "We present new results on the detection rate, mass distribution, and orbital properties of hypervelocity stars (HVSs) in the Galactic halo based on spectroscopic observations with Keck II/DEIMOS over three years. We find that HVSs are detected at a rate of 0.5 +/- 0.2 per year within 100 pc of the Galactic center. The observed number density profile is consistent with an exponential fall-off with distance from the Galactic center. Our sample contains two HVSs with velocities greater than 1000 km/s; one has a heliocentric radial velocity of 1240 km/s and another has 1420 km/s. These high velocities suggest that these objects were ejected by gravitational slingshots during close encounters between massive black holes or neutron stars. In addition to the known population of HVSs near the Sun, we also detect a large number of high-velocity stars located farther away from the Galactic center which may be associated with other nearby supermassive black holes.",
        "watermark_text": "We report new data on the detection rate , mass distribution , and orbital properties of hypervelocity stars ( HVSs ) in the Galactic halo based on spectroscopic observations with Keck II / DEIMOS over three years . We see that HVSs are detected at a rate of 0 . 5 + / - 0 . 2 per month within 100 pc of the Galactic center .The observed number density profile is compatible with an exponential fall - off with distance from the Galactic center . Our specimen contains two HVSs with velocities greater than 1000 kilometers / s ; one has a heliocentric radial speed of 1240 km / s and another has 1420 km / s .These high velocities indicate that these objects were ejected by gravitational slingshots during close contacts between massive brown holes or neutron galaxies . In addition to the known community of HVSs near the Sun , we also observe a large number of high - speed stars situated closer back from the Galactic center which may be involved with other nearby supermassive black holes .",
        "ori-fast-z-score": 0.8682431421244593,
        "water-fast-z-score": 5.581563056514381
    },
    {
        "original_text": "The nucleon is described as an extended object with internal structure, which can be probed by elastic scattering experiments at high energies and small momentum transfers. The present work focuses on the investigation of chiral mechanisms leading to orbital quantum structures within the framework of effective field theory (EFT). In particular we study the role played by pionic degrees of freedom for the description of the nucleon s electromagnetic form factors. We show that the inclusion of explicit pions leads to significant improvements over previous calculations based solely on quark degrees of freedom. Furthermore, we demonstrate how the EFT approach allows one to systematically include higher-order corrections into the calculation of observables. Finally, we discuss possible extensions of our formalism towards the treatment of other hadronic systems such as nuclei or hypernuclei. The nucleon is described as a composite system consisting of quarks bound together via gluons. However, it has been known since the early days of QCD  1  , that this picture cannot fully explain all experimental observations  2  . For example, while the proton s electric charge radius agrees well with experiment  3  , its magnetic moment turns out to be about 30% larger than expected  4  .\nIn order to resolve these discrepancies between theoretical predictions and experimental data, it was suggested  5  that additional contributions arising from the presence of virtual mesonic fluctuations should be taken into account  6  . These so-called  meson-cloud  effects are particularly important when considering processes involving large momentum transfer  7, 8  . It has also been shown  9  that they play an essential role in describing the nucleon s electromagnetic properties  10  .",
        "watermark_text": "The nucleon is characterized as an extended object with internal structure , which can be probed by elastic scattering experiments at high energies and tiny velocity transfers . The present work emphasizes on the examination of chiral mechanisms leading to orbital quantum forms within the framework of effective field theory ( EFT ) .In particular we study the importance played by pionic degrees of liberty for the description of the nucleon s electromagnetic form factors . We see that the introduction of explicit pions contributes to significant improvements over past calculations based primarily on quark degrees of liberty .Furthermore , we explain how the EFT methodology allows one to deliberately involve higher - order corrections into the determination of observables . Finally , we investigate possible extend of our formalism towards the treatment of other hadronic models such as atoms or hypernuclei .The nucleon is depicted as a composite system consisting of quarks bound together via gluons . However , it has been known since the early days of QCD 1 , that this picture cannot fully describe all observation observations 2 .For instance , while the proton s electric charge radius agrees well with test 3 , its magnetic point seems out to be about 30 % greater than expected 4 . In order to overcome these discrepancies between theoretical estimates and theoretical data , it was suggested 5 that extra contributions arising from the presence of virtual mesonic fluctuations should be taken into consideration 6 .These so - called meson - cloud effects are particularly important when considering phenomena involving huge velocity transfer 7 , 8 . It has additionally been shown 9 that they serve an essential part in understanding the nucleon s electromagnetic properties 10 .",
        "ori-fast-z-score": 0.811502671200689,
        "water-fast-z-score": 8.746195456274092
    },
    {
        "original_text": "We study the charge ordering phenomena in one-dimensional solids by using the exact diagonalization method and density matrix renormalization group (DMRG) technique. We find that there are two types of charge orderings, i.e., stripe-like and checkerboard-like orders depending on the electron filling factor n. The former is realized for 0 < n < 1 while the latter appears at half-filling with spin degeneracy lifted. In addition to these ordered states we also observe an exotic state where electrons form pairs without any net charge. This paired state can be regarded as a precursor of superconductivity. Finally, we discuss possible experimental realizations of our results. Introduction:-In recent years much attention has been paid to the physics of low dimensional systems such as carbon nanotubes  1  , semiconductor nanowires  2  , quantum wires  3  etc.. These materials have attracted considerable interest because they provide us with unique opportunities to explore novel physical properties which cannot exist in conventional three-dimensional bulk materials  4  . For example, it was predicted theoretically  5  and observed experimentally  6  that carbon nanotubes show metallic behavior even though their diameter is comparable or smaller than the Fermi wavelength. Another interesting feature of low dimensional systems is that various kinds of electronic phases may appear due to strong correlation effects  7, 8  .\nOne of the most important issues in this field is how to control the electronic phase diagram of low dimensional systems. It should be noted here that the electronic structure strongly depends not only on the geometry but also on the chemical composition  9  . Therefore, if we could change the chemical composition of low dimensional systems, then we would expect new electronic phases to emerge. Recently, several groups succeeded in synthesizing low dimensional compounds whose chemical compositions were controlled precisely  10 -12  . As a result, many fascinating phenomena have been discovered  13 -19  .",
        "watermark_text": "We research the charge ordering phenomena in one - dimensional solids by using the exact diagonalization technique and density matrix renormalization group ( DMRG ) method . We see that there are two forms of charge orderings , i . e . , stripe - like and checkerboard - like orders depending on the electron filling factor n . The first is realized for 0 < n < 1 while the former presents at half - filling with spin degeneracy lifted .In addition to these organized states we also observe an exotic state where electrons form couples without any gross charge . This paired state can be regarded as a precursor of superconductivity .Finally , we explain possible experimental realizations of our findings . Introduction : - In recent years much attention has been paid to the physics of low dimensional devices such as carbon nanotubes 1 , semiconductor nanowires 2 , quantum wires 3 etc . .These substances have garnered considerable interest because they give us with special opportunities to examine novel physical properties which cannot appear in standard three - dimensional bulk materials 4 . For instance , it was anticipated theoretically 5 and detected experimentally 6 that carbon nanotubes exhibit metallic behavior even though their distance is identical or smaller than the Fermi wavelength .Another important feature of lowest dimensional systems is that various kinds of electronic phases often emerge due to powerful correlation effects 7 , 8 . One of the most important problems in this area is how to manage the electronic phase diagram of low dimensional systems .It should be mentioned here that the chemical structure strongly depends not only on the topology but also on the chemical composition 9 . Therefore , if we could shift the chemical composition of low dimensional systems , then we may expect fresh electronic phases to emerge .Recently , various groups succeeded in synthesizing low dimensional molecules whose chemical compositions were monitored precisely 10 - 12 . As a result , various fascinating experiments have been observed 13 - 19 .",
        "ori-fast-z-score": -0.8778955729143844,
        "water-fast-z-score": 7.741442779335935
    },
    {
        "original_text": "We present an optical and infrared study of the central region of the open cluster Sigma Orionis (Orion Nebula Cluster). We have obtained deep JHK photometry with ISAAC at ESO/VLT, as well as X-ray data using XMM-Newton for a sample of stars within a radius of 1 arcmin around the Trapezium OB association. The main results are summarized below:  - A total number of 16 new spectroscopic binaries were found among our targets.  - From the analysis of the radial velocities we find that most of these systems show orbital periods longer than 100 days.  - We also report on the discovery of two new pre-main sequence eclipsing binary candidates.  - In addition to this, we confirm the existence of several known spectroscopic binaries in the field studied here. - Finally, we discuss some interesting cases where the presence of circumstellar disks is inferred by their IR excess emission or by periodic variability.",
        "watermark_text": "We present an optical and infrared analysis of the inner region of the open chain Sigma Orionis ( Orion Nebula Cluster ) . We have achieved hot JHK photometry with ISAAC at ESO / VLT , as well as X - ray data utilizing XMM - Newton for a sample of stars within a diameter of 1 arcmin around the Trapezium OB association .The main results are presented below : - A total quantity of 16 new spectroscopic binaries were found among our objectives . - From the evaluation of the transverse velocities we find that most of these systems show orbital periods longer than 100 days .- We additionally report on the discovery of two new early - principal sequence eclipsing binary candidates . - In addition to this , we confirm the existence of several known spectroscopic binaries in the field studied here .- Finally , we talk some interesting cases where the presence of circumstellar disks is inferred by their IR excess emission or by periodic variability .",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 4.905778905196061
    },
    {
        "original_text": "We present new observations of the outflow driven by the young star cluster NGC 1333 IRAS 4A, located at the center of the Perseus molecular cloud (d = 235 pc). The data were obtained with the Submillimeter Array and include continuum emission at 1.3 mm as well as CO(2-1) line emission. We find that the outflow is highly collimated along an axis oriented NNE-SSW, which coincides with the direction to the nearby Herbig-Haro objects HH 7-11. The total mass of the outflowing gas is estimated to be ~0.1 Msun, while its kinetic energy amounts to ~10^50 ergs. These values are comparable to those found for other low-mass protostellar systems. However, we also detect significant differences between this system and others previously studied. In particular, our results suggest that the outflow may have been triggered recently due to the interaction of the central source with another object or structure within the dense core surrounding it.",
        "watermark_text": "We report new images of the outflow generated by the young star cluster NGC 1333 IRAS 4A , located at the center of the Perseus molecular storm ( d = 235 pc ) . The data were obtained with the Submillimeter Array and include continuum emission at 1 . 3 cm as well as CO ( 2 - 1 ) line emission .We see that the outflow is heavily collimated along an axis oriented NNE - SSW , which coincides with the direction to the nearby Herbig - Haro objects HH 7 - 11 . The total mass of the outflowing gas is expected to be ~ 0 . 1 Msun , while its kinetic power amounts to ~ 10 ^ 50 ergs .These measurements are comparable to those shown for other low - weight protostellar systems . However , we also observe significant variations between this scheme and others earlier studied .In particular , our findings show that the outflow could have been caused recently result to the interaction of the main source with another object or system within the dense core covering it .",
        "ori-fast-z-score": -1.1338934190276817,
        "water-fast-z-score": 5.165514464459439
    },
    {
        "original_text": "We present the results of an investigation into the evolution of dark matter halos and their substructure, using high-resolution cosmological N-body simulations with different mass resolutions. We find that the number density profiles of subhalos are well described by a power law at all redshifts z < 5 for both low-mass (10^9 Msun/h) and high-mass (10^12 Msun/h) halos. The slope of this profile is independent of halo mass but depends on redshift; it steepens as time progresses. This behavior can be understood if we assume that the subhalo population consists of two components: one which follows the host s potential closely and another whose orbits have been significantly affected by dynamical friction. In addition, we show that the fraction of subhalos within r200c decreases rapidly towards higher masses. Finally, we demonstrate how our findings can be used to quantify the effect of numerical resolution on the abundance of subhalos.",
        "watermark_text": "We present the conclusion of an research into the evolution of deep material halos and their substructure , using high - resolution cosmological N - bodies simulations with various mass resolutions . We see that the number density patterns of subhalos are better modeled by a power law at all redshifts z < 5 for both high - weight ( 10 ^ 9 Msun / h ) and low - density ( 10 ^ 12 Msun / h ) halos .The slope of this profile is independent of halo weight but relies on redshift ; it steepens as time progresses . This phenomenon can be understood if we suppose that the subhalo population contains of two parts : one which follows the host s potential closely and another whose orbits have been dramatically impacted by dynamical friction .In addition , we prove that the fraction of subhalos within r200c tends rapidly towards higher masses . Finally , we prove how our findings can be used to quantify the impact of statistical resolution on the availability of subhalos .",
        "ori-fast-z-score": -2.0,
        "water-fast-z-score": 4.5
    },
    {
        "original_text": "We present new observations made with the Cosmosoma experiment, which were designed to search for evidence of an excess in cosmic microwave background (CMB) temperature fluctuations above those predicted by standard cosmological models. The data are consistent with predictions based on current theoretical understanding but show some unexpected features that may be related to previously unidentified foreground sources or systematic effects associated with our analysis techniques. \n \n We have used these results to place limits on possible contributions from primordial gravitational waves and other exotic phenomena such as topological defects. These limits are comparable to previous measurements obtained using different experimental approaches. In addition we report the detection of a significant signal at frequencies below 10GHz, which is not expected within conventional cosmological models. This could represent either a new source of foreground contamination or a novel physical effect. Further investigation will require additional experiments to confirm this result and determine its origin. If confirmed it would provide important constraints on theories attempting to explain the observed anisotropy in the CMB spectrum.",
        "watermark_text": "We present new experiments done with the Cosmosoma study , which were built to search for indication of an amount in cosmic microwave background ( CMB ) temperature fluctuations above those predicted by traditional cosmological predictions . The data are compatible with predictions based on current theoretical knowledge but display some surprising characteristics that might be connected to formerly unidentified foreground sources or systematic effects involved with our analysis methods .We have utilized these results to place limits on potential contributions from primordial magnetic waves and other exotic processes such as topological defects . These restrictions are comparable to previous measurements obtained using separate observation approaches .In addition we report the finding of a substantial frequency at speeds below 10GHz , which is not anticipated within conventional cosmological predictions . This might represent either a new cause of foreground contamination or a novel physical impact .Further investigation will demand additional studies to confirm this result and establish its identity . If confirmed it would offer important restrictions on experiments pursuing to explain the observed anisotropy in the CMB spectrum .",
        "ori-fast-z-score": -1.0540925533894598,
        "water-fast-z-score": 7.233165373381237
    },
    {
        "original_text": "In this work, we study the problem of how many users to turn on for multi-antenna broadcast channels (MABCs). We first show that the optimal number of active users is equal to the rank of the channel matrix when all users have the same average signal-to-noise ratio (SNR) and there are no power constraints at the base station. Then, under general conditions, we prove that the optimal number of users is upper bounded by the minimum between the rank of the channel and the total number of available transmit antennas. Finally, we provide an algorithm which can find the exact solution within polynomial time complexity. The results obtained here may help us design more efficient MABC systems with reduced computational cost. In wireless communications, broadcasting refers to sending information simultaneously to multiple receivers over a shared medium such as radio waves or fiber optics. This type of communication has been widely used in various applications including digital television, video conferencing, data transmission, etc., where it is desirable to send messages to several users simultaneously  1  . However, due to limited resources, only a subset of these users will receive useful signals while others experience interference  2  .\nThe main challenge in designing broadcast systems lies in determining the best set of users who should be turned on so that each user receives its intended message without causing too much interference to other users  3  , i.e., finding the optimal user selection strategy  4  -  6  . For example, if one wants to maximize the sum rate of all users subject to individual power constraints, then the optimal user selection strategy depends not only on the channel state information but also on the power allocation policy  7  . Therefore, the joint optimization of user selection and power control becomes very complicated  8  .",
        "watermark_text": "In this research , we study the issue of how many users to turn on for multi - antenna broadcast channels ( MABCs ) . We first see that the ideal amount of active consumers is equal to the rank of the channel matrix when all users have the same average sound - to - noise proportion ( SNR ) and there are no power limitations at the base station .Then , under general circumstances , we prove that the ideal amount of subscribers is upper bounded by the limit between the rank of the channel and the total quantity of available transmit antennas . Finally , we provide an algorithm which can find the exact solution within polynomial time complexity .The results derived here perhaps allow us design more efficient MABC devices with decreased computational expensive . In telecommunications transmission , broadcasting refers to sent information continuously to multiple receivers over a shared medium such as radio pulses or fiber optics .This kind of communication has been widely useful in different environments including digital broadcasting , television conferencing , data broadcasting , etc . , where it is desirable to give communication to several users simultaneously 1 . However , owing to limited facilities , only a subset of these users will receive valuable inputs while others experience interference 2 .The main challenge in building transmitted schemes lies in selecting the best set of consumers who should be turned on so that each player receives its intended message without producing too little interference to other people 3 , i . e . , finding the ideal user choice strategy 4 - 6 . For instance , if one wants to maximize the sum frequency of all users subject to individual power limitations , then the ideal user choice strategy depends not only on the channel state information but also on the power distribution policy 7 .Therefore , the joint optimization of customer preference and power control makes very complicated 8 .",
        "ori-fast-z-score": 0.8669214468630108,
        "water-fast-z-score": 10.324246321732218
    },
    {
        "original_text": "We present an analysis of the Swift/BAT light curve for GRB 060912, which is one of only two bursts to have been classified as both a  long-soft  (LS) and a  short-hard  (SH) event by the BAT team.  We find that this classification is not robust against changes in the background model used or variations in the time binning applied; we also show that it does not hold up when compared with other LS events observed by Swift. In addition, we demonstrate that the spectral evolution seen during the prompt phase cannot be explained within either the SH or LS models. Finally, we argue that the most likely explanation for these observations is that GRB 060912 was actually a single pulse lasting several hundred seconds, rather than being composed of multiple pulses separated by quiescent intervals. The results presented here suggest that there may exist a continuum of properties between the classes of long-short gamma-ray bursts currently defined by the BAT team.",
        "watermark_text": "We present an assessment of the Swift / BAT light curve for GRB 060912 , which is one of only two pulses to have been classified as both a long - hard ( LS ) and a short - hard ( SH ) event by the BAT crew . We see that this classification is not stable against shifts in the background model used or variations in the period binning applied ; we also demonstrate that it does not stand up when compared with other LS events observed by Swift .In addition , we prove that the spectral evolution seen during the prompt stage cannot be described within either the SH or LS models . Finally , we claim that the most likely explanation for these observations is that GRB 060912 was actually a single signal lasting several hundred moments , rather than being composed of multiple pulses divided by quiescent intervals .The results presented here suggest that there may contain a continuum of properties between the classes of large - short gamma - ray bursts currently defined by the BAT group .",
        "ori-fast-z-score": 0.601929265428846,
        "water-fast-z-score": 5.093248125762992
    },
    {
        "original_text": "We present an analysis of the worst-case time complexity for inserting n elements into a binary search tree using the Fibonacci-heap data structure, which is based on the so-called  Young-Fibonacci insertions . We show that this algorithm has O(n log n) worst-case running time and thus improves upon previous results by Chan et al., who showed that it takes at least Ω(n2/3) time to perform these operations in the worst case. The main idea behind our proof is to use amortized analysis techniques to bound the number of times we have to update the heap s size during each step of the algorithm. This allows us to prove that the total cost incurred over all steps is bounded by O(n log n). In addition, we also provide experimental evidence showing that our theoretical bounds are tight up to constant factors. \nIntroduction\n\nThe Fibonacci-heap data type was introduced by Fredman and Tarjan  FT86  as part of their work on efficient algorithms for finding minimum spanning trees (MSTs), shortest paths, and other related problems. It consists of a rooted binary tree with two additional fields associated with every node: its parent pointer and its rank value. Every node stores pointers to its left child and right child nodes; however, unlike ordinary binary trees, there can be more than one node with the same key stored under any given node. Each node maintains a counter called its rank, which indicates how many keys equal to or less than the key of the current node exist below it; if no such key exists then the rank field contains zero. \n \n For example, consider the following Fibonacci-heap storing the values 1 through 5:",
        "watermark_text": "We present an assessment of the worst - case time complexity for inserting n elements into a binary find tree using the Fibonacci - heap data structure , which is based on the so - called Young - Fibonacci insertions . We see that this algorithm has O ( n log n ) worst - case ran time and therefore improves upon recent results by Chan et al . , who demonstrated that it takes at least Ω ( n2 / 3 ) time to conduct these functions in the worst case .The main idea behind our proof is to use amortized analysis methods to bound the quantity of twice we have to update the heap s size during each step of the method . This enables us to prove that the total cost incurred over all stairs is bounded by O ( n log n ) .In addition , we also provide empirical evidence showing that our theory bounds are strict up to constant factors . Introduction The Fibonacci - heap data type was introduced by Fredman and Tarjan FT86 as part of their work on effective methods for finding minimum spanning trees ( MSTs ) , shortest trails , and other related problems .It consists of a rooted binary tree with two added fields associated with every node : its father pointer and its rank value . Every node stores pointers to its right son and left baby nodes ; however , unlike ordinary binary forests , there can be more than one node with the same key contained under any certain vertex .Each node maintains a counter termed its rank , which reflects how many keys equivalent to or smaller than the key of the present node reside below it ; if no such key exists then the rank field contains zero . For instance , consider the following Fibonacci - heap counting the numbers 1 through 5 :",
        "ori-fast-z-score": -0.6713450866373513,
        "water-fast-z-score": 5.706433236417486
    },
    {
        "original_text": "We present the results of observations made by the Multiband Imaging Photometer for Spitzer (MIPS) in 24 and 70 micron bands toward the Serpens cloud core. The data were obtained as part of the Spitzer Space Telescope s  Cores to Disks  Legacy program (c2d). We have detected more than 100 infrared sources within an area of 0.5 square degrees centered on the Serpens South region. Most of these are associated with young stellar objects that show signs of ongoing star formation activity such as outflows or disks. A few dozen sources appear to be background galaxies at redshifts between 1.2 and 3.6. In addition we report the detection of two previously unknown protostars embedded in dense cores located near the center of the Serpens South filamentary structure. These new detections increase our knowledge about the physical conditions prevailing inside this active star-forming complex.",
        "watermark_text": "We present the conclusion of measurements made by the Multiband Imaging Photometer for Spitzer ( MIPS ) in 24 and 70 micron bands toward the Serpens cloud core . The data were obtained as part of the Spitzer Space Telescope s Cores to Disks Legacy project ( c2d ) .We have discovered more than 100 infrared sources within an area of 0 . 5 square degrees centered on the Serpens South region . Most of these are related with young stellar bodies that display signs of ongoing galaxy formation activity such as outflows or disks .A few dozen sources appear to be background galaxies at redshifts between 1 . 2 and 3 . 6 . In addition we publish the observation of two formerly unidentified protostars embedded in dense cores located near the center of the Serpens South filamentary complex .These new detections increase our information about the physical conditions prevailing inside this active star - creating complex .",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 4.27617987059879
    },
    {
        "original_text": "We report on the fabrication and characterization of charge qubits based on self-assembled InAs quantum dots (QDs) embedded in GaAs/AlGaAs heterostructures. We show that by using an optimized growth procedure, we can achieve high quality QD layers with low density of defects which are crucial for achieving good coherence times. The samples were grown by molecular beam epitaxy at 600 °C under As-rich conditions to minimize the formation of threading dislocations. A single layer of self-assembled InAs/GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm thick Al0.3Ga0.7As barrier layer. Finally, a 20 nm thick GaAs capping layer was deposited. The sample structure is shown schematically in Figure 1 . The photoluminescence spectrum shows emission peaks centered around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states associated with charged excitons.",
        "watermark_text": "We report on the fabrication and description of charge qubits based on self - assembled InAs quantum dots ( QDs ) integrated in GaAs / AlGaAs heterostructures . We suggest that by using an optimized growth technique , we can attain high quality QD layers with minimal concentration of flaws which are important for achieving better coherence times .The samples were cultivated by molecular wave epitaxy at 600 °C under As - rich conditions to minimize the formation of threading dislocations . A single mesh of self - assembled InAs / GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm wide Al0 . 3Ga0 . 7As barrier layer .Finally , a 20 nm deep GaAs capping layer was extracted . The sample structure is displayed schematically in Figure 1 .The photoluminescence spectrum displays emission levels focused around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states correlated with charged excitons .",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 4.213504858001922
    },
    {
        "original_text": "We investigated the dominant aerosol processes in the atmosphere using ground-based remote sensing and chemical analysis data collected at Kashiwa, Chiba Prefecture (Chiba), Japan, between September 2009 and March 2010 under severe air pollution conditions caused by anthropogenic emissions. The results showed that sulfate particles were mainly produced through gas-to-particle conversion via homogeneous nucleation on days with low relative humidity (RH) values; however, they were also formed as secondary organic aerosols (SOAs) when RH was higher than 80%. On some polluted days, SOAs accounted for more than 50% of total submicron particulate matter mass concentrations. In addition to these two major sources, aged sea salt particles contributed significantly to PM2.5 mass concentration levels. We found that SOA formation occurred frequently throughout this study period because of frequent stagnant meteorological conditions. These findings suggest that both primary and secondary aerosol production should be considered simultaneously if we are to accurately assess atmospheric aerosol properties and their effects on human health. \n \n Keywords: Aerosol process, Remote sensing, Chemical composition",
        "watermark_text": "We researched the dominant aerosol processes in the air using ground - based remote sensing and chemical analysis evidence generated at Kashiwa , Chiba Prefecture ( Chiba ) , Japan , between September 2009 and March 2010 under extreme aerial contamination conditions caused by anthropogenic emissions . The results suggested that sulfate gases were mainly created through gas - to - particle conversion via homogeneous nucleation on days with lowest relative humidity ( RH ) values ; however , they were also formed as secondary organic aerosols ( SOAs ) when RH was lower than 80 % .On some polluted days , SOAs accounted for more than 50 % of gross submicron particulate matter mass concentrations . In addition to these two principal sources , aged ocean water particles contributed significantly to PM2 . 5 mass abundance levels .We showed that SOA structure occurred frequently throughout this study era because of frequent stagnant meteorological conditions . These conclusions show that both primary and secondary aerosol production should be evaluated concurrently if we are to correctly examine atmospheric aerosol characteristics and their impacts on human health .Keywords : Aerosol process , Remote sensing , Chemical composition",
        "ori-fast-z-score": 1.2375966910186262,
        "water-fast-z-score": 7.313071356019155
    },
    {
        "original_text": "We present an analysis of galaxy clusters selected by their red-sequence galaxies (Gladders & Yee 2005) from the Sloan Digital Sky Survey Data Release 4 (DR4). We use two different methods to select cluster candidates, and then apply photometric redshift cuts on these samples to obtain final catalogues with high purity. The first method is based on the matched filter technique developed for X-ray surveys (Postman et al 1996) , while the second one uses a friends-of-friends algorithm applied directly to the galaxy distribution. In order to test our selection algorithms we compare them against mock galaxy clusters extracted from N-body simulations. Our main results are as follows:  1. Using the matched filter technique we find that the number density of galaxy clusters at z < 0.5 is n(z<0.5) = 3.6 +/- 0.2 x 10-3 h3 Mpc-3 . This value agrees well with previous determinations using other techniques.  2. By applying the same matched filter technique to simulated galaxy clusters we show how this method can be used to estimate the mass function of galaxy clusters up to z ~1.0.",
        "watermark_text": "We present an assessment of galaxy regions selected by their red - sequence galaxies ( Gladders & Yee 2005 ) from the Sloan Digital Sky Survey Data Release 4 ( DR4 ) . We use two different methods to select cluster applicants , and then use photometric redshift cutting on these specimens to obtain final catalogues with high purity .The first method is based on the matched filter technique developed for X - ray observations ( Postman et al 1996 ) , while the second one uses a enemies - of - friends method applied directly to the galaxy distribution . In order to test our choice algorithms we compare them against mock galaxy galaxies extracted from N - bodies simulations .Our main results are as follows : 1 . Using the matched filter technique we find that the number density of galaxy galaxies at z < 0 . 5 is n ( z < 0 . 5 ) = 3 . 6 + / - 0 . 2 x 10 - 3 h3 Mpc - 3 .This value agrees well with previous determinations using other techniques.2.By applying the same matched filter technique to modeled galaxy galaxies we find how this algorithm can be used to estimate the mass value of galaxy galaxies up to z ~ 1 . 0 .",
        "ori-fast-z-score": 1.4924050144892729,
        "water-fast-z-score": 5.9696200579570915
    },
    {
        "original_text": "We show that the non-Gaussian distributions observed in financial returns are due to microscopic interactions between traders and their environment, which lead to non-trivial correlations among different time scales. We present an analytical model for these correlations based on random matrix theory (RMT), which is able to reproduce all statistical properties of real market data with high accuracy. \n \n The distribution of stock prices has been studied extensively over many decades  1  . It was found that this distribution can be well approximated by a Gaussian function  2  , but deviations have also been reported  3  . In particular, it has been shown recently  4  that the tails of the return distribution follow a power law decay P(r) ~ r−α with α = 3 ± 0.1. This finding contradicts the predictions of standard models such as Black-Scholes  5  or Heston  6  , where the tail exponent should be equal to 2  7, 8  .\n \nIn order to explain the origin of these deviations we propose here a new approach based on Random Matrix Theory  9  . RMT describes the statistics of complex systems whose dynamics depend on a large number N of degrees of freedom  10  . For example, RMT has successfully been applied to describe the fluctuations of energy levels  11  , wave functions  12  , spin states  13  , quantum transport  14  , and chaotic scattering  15  . Recently, RMT has also been used to study the statistical properties of stock markets  16  -  22  . Here we will focus on the so-called Dyson Brownian motion  23  , which describes the evolution of a system under the influence of white noise.",
        "watermark_text": "We see that the non - Gaussian distributions found in financial returns are owing to microscopic interactions between traders and their environment , which lead to non - simple correlations among different time ranges . We present an analytical theory for these correlations based on random matrix theory ( RMT ) , which is easy to capture all statistical characteristics of real trading information with high clarity .The function of stock rates has been studied thoroughly over much generations 1 . It was shown that this distribution can be well approximated by a Gaussian distribution 2 , but deviations have also been reported 3 .In particular , it has been shown recently 4 that the tails of the return distribution observe a power law decay P ( r ) ~ r−α with α = 3 ± 0 . 1 . This fact contradicts the estimates of standard models such as Black - Scholes 5 or Heston 6 , where the tail exponent should be equal to 2 7 , 8 .In order to explain the origin of these deviations we undertake here a new approach based on Random Matrix Theory 9 . RMT describes the statistics of complex systems whose dynamics depend on a large number N of degrees of freedom 10 .For instance , RMT has successfully been used to explain the fluctuations of power states 11 , wave systems 12 , spin states 13 , quantum transport 14 , and chaotic scattering 15 . Recently , RMT has additionally been used to study the statistical characteristics of financial traders 16 - 22 .Here we will focus on the so - called Dyson Brownian moving 23 , which explains the evolution of a system under the effects of white sound .",
        "ori-fast-z-score": -1.044073795327749,
        "water-fast-z-score": 5.789863774090244
    },
    {
        "original_text": "We present the results of our numerical simulations of magnetized accretion disks in which we solve the mean-field magnetohydrodynamic equations for an axisymmetric disk with a prescribed radial distribution of angular momentum and mass fluxes, using the shearing-box approximation.  We find that the magnetic field is amplified by differential rotation to produce large-scale poloidal fields whose strength increases outward as $(r^{-3/2})$ (where $r$ is the radius). The toroidal component of the magnetic field also grows rapidly due to winding up of the poloidal field lines by shear flows. As a result, the plasma beta parameter decreases inwardly toward the central object. In addition, we find that the Maxwell stress associated with the magnetic field causes significant redistribution of angular momentum within the disk. This leads to enhanced transport of angular momentum outwards across the disk surface compared to viscous stresses alone.",
        "watermark_text": "We present the conclusion of our numerical simulations of magnetized accretion disks in which we solve the mean - field magnetohydrodynamic equations for an axisymmetric disk with a prescribed radial distribution of angular velocity and mass fluxes , using the shearing - box method . We see that the magnetic force is amplified by differential rotation to produce wide - scale poloidal fields whose strength changes outward as $ ( r ^ { - 3 / 2 } ) $ ( where $ r $ is the radius ) .The toroidal portion of the magnetic force thus rises frequently due to winding up of the poloidal field lines by shear flows . As a result , the plasma beta factor decreases inwardly toward the main object .In addition , we find that the Maxwell stress involved with the magnetic force produces significant redistribution of angular velocity within the disk . This leads to heightened transport of angular velocity outwards across the disk boundary compared to viscous stresses alone .",
        "ori-fast-z-score": 2.223781796726481,
        "water-fast-z-score": 6.4372630957871815
    },
    {
        "original_text": "We present near-infrared (NIR) spectroscopy obtained with Subaru/HDS on day +16 after explosion for the peculiar type Ib supernova SN2006jc, which shows prominent dust formation in its dense shell. The NIR spectrum is dominated by strong P-Cygni profiles of H I Balmer lines and Fe II multiplets at 4233-4245 Å . We find that these features are well reproduced by our non-LTE model calculations assuming an electron density ne = 1 x 10^9 cm-3 , temperature Te = 5500 K , and mass-loss rate oḟ M = 2 x 10^-6 M_sun/yr. In addition to the above mentioned features, we detect weak but significant He II 4686 emission line feature in the red wing of the Hα profile. This suggests that there may be some contribution from helium recombination radiation to the observed fluxes of hydrogenic lines.",
        "watermark_text": "We use near - infrared ( NIR ) spectroscopy acquired with Subaru / HDS on week + 16 after explosion for the unusual type Ib supernova SN2006jc , which shows significant dust form in its dense shell . The NIR spectrum is dominated by strong P - Cygni profiles of H I Balmer bands and Fe II multiplets at 4233 - 4245 Å .We see that these characteristics are better illustrated by our non - LTE model calculations assuming an electron concentration ne = 1 x 10 ^ 9 centimeters - 3 , temperature Te = 5500 K , and mass - loss rate [UNK] M = 2 x 10 ^ - 6 M _ sun / yr . In addition to the above mentioned properties , we perceive slight but significant He II 4686 absorption line feature in the red wing of the Hα profile .This implies that there may be some influence from helium recombination emission to the seen fluxes of hydrogenic lines .",
        "ori-fast-z-score": -1.4832396974191326,
        "water-fast-z-score": 4.08248290463863
    },
    {
        "original_text": "The magnetization, susceptibility, and specific heat measurements were performed on the single crystals of TbFe3( BO3 )4 . The magnetic properties are analyzed in terms of the crystal-field splitting scheme for Tb3+ ions. It is found that the ground state doublet has an Ising-like anisotropy along c-axis with gz = 8.0 ± 0.1 , which leads to the large spontaneous polarization ( Ps ~ 1μC/cm2 ). The calculated results reproduce well the experimental data except for the low-temperature part of the specific-heat curve below 2 K. This discrepancy may be attributed to the presence of impurities or defects in our samples. \n \n Keywords: Magnetism; Crystal field theory; Specific heat measurement; Susceptibility measurement; Single-crystal growth; Anisotropic magnetoresistance effects; Polarized neutron scattering \n \n \n \n INTRODUCTION : \nTbFe 3 (BO 3 ) 4 belongs to the family of rare-earth iron borates RFe 3 (BO 3 ) (R = Y, Yb, Lu). These compounds have attracted much attention because they exhibit various interesting physical phenomena such as ferroelectricity  1  , multiferroicity  2  , colossal magnetoresistance  3  , and quantum critical behavior  4  .\nIn particular, TbFe 3 (BO 3 )\n4 exhibits a giant spontaneous polarization P s ~ 1 μ C / cm 2 at room temperature  5  due to its unique crystal structure  6  . In this compound, Fe atoms form a three-dimensional network of corner-sharing tetrahedra by sharing their apical oxygen atoms  7   . On the other hand, Tb atoms occupy two different sites, i.e., one site surrounded by eight O atoms forming a square antiprismatic coordination polyhedron  8  and another site surrounded by six O atoms forming a trigonal prismatic coordination polyhedron  9  . As shown in Figs. 1 (a) and (b), these two types of polyhedra share common faces perpendicularly to the c -axis  10  .",
        "watermark_text": "The magnetization , susceptibility , and particular heat measurements were performed on the single crystals of TbFe3 ( BO3 ) 4 . The magnetic properties are examined in terms of the crystal - field separation scheme for Tb3 + ions .It is found that the ground state doublet has an Ising - like anisotropy along c - axis with gz = 8 . 0 ± 0 . 1 , which results to the big induced polarization ( Ps ~ 1μC / cm2 ) . The measured data reproduce well the laboratory information except for the high - temperature half of the specific - temperature curve below 2 K . This discrepancy may be due to the presence of impurities or flaws in our specimens .Keywords : Magnetism ; Crystal field description ; Specific temperature measurement ; Susceptibility measurement ; Single - crystal growth ; Anisotropic magnetoresistance effects ; Polarized neutron scattering INTRODUCTION : TbFe 3 ( BO 3 ) 4 belongs to the group of rare - earth iron borates RFe 3 ( BO 3 ) ( R = Y , Yb , Lu ) . These compounds have garnered great popularity because they demonstrate several interesting physical phenomena such as ferroelectricity 1 , multiferroicity 2 , colossal magnetoresistance 3 , and quantum fundamental behavior 4 .In particular , TbFe 3 ( BO 3 ) 4 displays a giant spontaneous polarization P s ~ 1 μ C / cm 2 at room temperature 5 due to its unique crystal formation 6 . In this compound , Fe molecules form a three - dimensional network of spot - sharing tetrahedra by sharing their apical oxygen atoms 7 .On the other hand , Tb molecules occupy two different places , i . e . , one site surrounded by eight O atoms forming a square antiprismatic coordination polyhedron 8 and another site surrounded by six O atoms forming a trigonal prismatic coordination polyhedron 9 . As seen in Figs .1 ( a ) and ( b ) , these two forms of polyhedra share shared faces perpendicularly to the c - axis 10 .",
        "ori-fast-z-score": 1.4110813025753959,
        "water-fast-z-score": 7.748271696689158
    },
    {
        "original_text": "We prove that for any surface S of general type, the action of its absolute Galois group G(S) on the set of connected components of the modulis space M_g(S) is faithful.  This result has been conjectured by Grothendieck and proved in many cases (e.g., when g = 0 or 1).  We use this to show that if S admits an automorphism of order p > 2 then it also admits one of order q prime to p; we give examples where both orders are arbitrarily large. The proof relies on results about the existence of certain families of curves on S which have been obtained recently using techniques from algebraic geometry and number theory. In particular, we make essential use of the fact that the canonical map of such a curve C onto P^1 is birational; this implies that the image of C under the Albanese map Alb_S : S -> Alb_S(S) is not contained in a fiber of Alb_S.",
        "watermark_text": "We prove that for any manifold S of general kind , the operation of its absolute Galois group G ( S ) on the group of connected parts of the modulis space M _ g ( S ) is faithful . This result has been conjectured by Grothendieck and demonstrated in many situations ( e . g . , when g = 0 or 1 ) .We use this to see that if S gives an automorphism of order q > 2 then it also admits one of order q prime to p ; we give instance where both orders are arbitrarily big . The proof draws on findings about the existence of certain classes of curves on S which have been achieved lately utilizing techniques from algebraic topology and number theory .In particular , we give important use of the fact that the canonical mapping of such a curve C onto P ^ 1 is birational ; this implies that the image of C under the Albanese map Alb _ S : S - > Alb _ S ( S ) is not enclosed in a fiber of Alb _ S .",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 5.08000508000762
    },
    {
        "original_text": "In this work, we propose an algorithm for blind identification (BI) of distributed antenna systems (DASs). The proposed BI method is based on the joint use of second-order statistics and higher order cumulants to estimate the number of active users in each cell as well as their carrier frequency offsets (CFOs), which are unknown parameters that need to be estimated before data detection can take place. We show by simulation results that our proposed method outperforms existing methods in terms of bit error rate performance when CFOs exist between different cells. In addition, it has lower computational complexity than other algorithms. \n \n Keywords: Blind identification; Distributed antenna systems; Second-order statistics; Higher order cumulants; CFO estimation. 1 Introduction \n \n With the rapid development of wireless communication technology, there have been increasing demands for high spectral efficiency and reliable transmission over limited bandwidth resources  1  . To meet these requirements, multi-antenna techniques such as multiple-input-multiple-output (MIMO)  2  , massive MIMO  3  -  5  , cooperative relaying  6  , and cognitive radio  7  have attracted much attention recently. Among them, distributed antenna systems (DAs)  8  -  10  provide significant advantages including improved coverage area, enhanced capacity, reduced power consumption, and increased network flexibility  11  . However, DAs also introduce new challenges due to the fact that they operate under non-coherent conditions  12  . For example, the channel state information (CSI) at the transmitter side cannot be obtained directly through uplink training or downlink feedback  13  . Therefore, how to obtain CSI accurately becomes one of the most important issues in DA design  14  .\n \nTo address this issue, several works  15  -  17  have investigated the problem of estimating the number of active users and their corresponding channels simultaneously using only statistical properties of received signals without requiring any prior knowledge about the transmitted symbols. These approaches exploit the inherent sparseness property of user activity patterns and utilize second-order statistics (SOS) and/or higher order cumulants (HOCs)  18  -  20  to identify the number of active users per cell. Then, the channel coefficients associated with",
        "watermark_text": "In this research , we propose an algorithm for blind analysis ( BI ) of distributed antenna devices ( DASs ) . The proposed BI approach is based on the joint use of second - order statistics and larger class cumulants to estimate the quantity of active consumers in each cell as also as their carrier signal offsets ( CFOs ) , which are unknown parameters that require to be assessed before data diagnosis can take occur .We suggest by simulation data that our proposed method outperforms current methods in terms of bit error rate capacity when CFOs arise between multiple cells . In addition , it has less computational complexity than other methods .Keywords : Blind identity ; Distributed antenna devices ; Second - order analysis ; Higher class cumulants ; CFO estimation . 1 Introduction With the increasing growth of radio communication techniques , there have been growing requirements for high spectral capacity and reliable transmission over limited bandwidth supplies 1 .To address these requirements , multi - antenna techniques such as multiple - input - multiple - output ( MIMO ) 2 , large MIMO 3 - 5 , joint relaying 6 , and cognitive television 7 have garnered considerable notice lately . Among them , dispersed antenna technologies ( DAs ) 8 - 10 provide significant advantages including increased coverage space , enhanced capacity , enhanced capacity consumption , and increased communication flexibility 11 .However , DAs additionally introduce novel challenges related to the fact that they operate under non - coherent environments 12 . For instance , the channel state information ( CSI ) at the broadcasting side cannot be obtained immediately through uplink conditioning or downlink feedback 13 .Therefore , how to obtain CSI correctly becomes one of the most important problems in DA design 14 . To address this question , various papers 15 - 17 have researched the issue of estimating the total of active participants and their corresponding networks simultaneously employing only statistical characteristics of received transmissions without using any earlier knowledge about the received symbols .These approaches exploit the intrinsic sparseness property of customer activity patterns and use second - order statistics ( SOS ) and / or greater order cumulants ( HOCs ) 18 - 20 to identify the total of active participants per cell . Then , the channel coefficients identified with",
        "ori-fast-z-score": -3.047505999613382,
        "water-fast-z-score": 9.53595439531399
    },
    {
        "original_text": "The production of light elements in the early universe is one of the most important unsolved problems in astrophysics, cosmology, nuclear physics and particle physics. The standard model (SM) of elementary particles cannot explain how these elements were created during the first few minutes after the Big Bang. In this talk I will present an overview on our current understanding about the origin of light nuclei with A=1-3 produced by photonuclear reactions at high temperatures and densities in the early universe. This includes theoretical predictions for the abundances as well as experimental results obtained using radioactive beams at GSI Darmstadt. Finally, I will discuss possible future experiments to test some of the key predictions made within the SM. Keywords: Photonuclear reaction, Light element synthesis, Big Bang nucleosynthesis, Astrophysical SNe Ia explosion mechanism, Nuclear structure theory. 1 Introduction.\nLight element synthesis in the early universe is among the most challenging open questions in modern science  1  . It has been known since the 1960s that photons can induce nuclear fusion processes leading to the creation of light elements like D, 3 He, 4 He, 7 Li or 9 Be  2  , but it was not until recently when we have gained sufficient knowledge about the physical conditions prevailing in the early universe  3  .\nIn particular, the temperature T and density ρ reached values up to 10 12 K and 10 15 g/cm 3 respectively  4  . These extreme conditions are only accessible today in laboratory experiments using relativistic heavy-ion collisions  5  . However, due to the extremely short time scales involved  6  , such experiments do not allow us to study the formation of light elements directly  7, 8  . Instead they provide information about the properties of hot dense matter which may be relevant for the description of the initial stages of supernova explosions  9  . On the other hand, the abundance pattern observed in primordial objects like white dwarfs  10  or metal-poor stars  11  provides valuable constraints on the models describing the evolution of the chemical composition of the universe  12  .",
        "watermark_text": "The production of light elements in the early universe is one of the most important unsolved issues in astrophysics , cosmology , nuclear science and particle science . The typical model ( SM ) of primary atoms cannot explain how these objects were created during the first few hours after the Big Bang .In this talk I will present an overview on our new understanding about the origin of light nuclei with A = 1 - 3 created by photonuclear reactions at high temperatures and densities in the early universe . This contains theoretical estimates for the abundances as well as research results derived using nuclear beams at GSI Darmstadt .Finally , I will explore possible future research to test some of the key predictions produced within the SM . Keywords : Photonuclear reaction , Light element synthesis , Big Bang nucleosynthesis , Astrophysical SNe Ia explosion mechanism , Nuclear structure hypothesis .1 Introduction . Light factor synthesis in the early universe is among the most challenging open questions in modern science 1 .It has been known since the 1960s that photons can induce nuclear fusion mechanisms leading to the creation of light elements like D , 3 He , 4 He , 7 Li or 9 Be 2 , but it was not until recently when we have achieved sufficient knowledge about the physical conditions prevailing in the early universe 3 . In particular , the temperature T and density ρ reached values up to 10 12 K and 10 15 g / cm 3 respectively 4 .These severe environments are only accessible today in laboratory experiments using relativistic heavy - ion collisions 5 . However , owing to the exceptionally short period scales involved 6 , such studies do not enable us to study the formation of light elements directly 7 , 8 .Instead they give information about the properties of bright heavy material which may be crucial for the description of the first phase of supernova explosions 9 . On the other hand , the density trend detected in primordial objects like white dwarfs 10 or metal - poor stars 11 provides valuable constraints on the models explaining the evolution of the chemical composition of the universe 12 .",
        "ori-fast-z-score": 1.8842334171937931,
        "water-fast-z-score": 8.818163074019441
    },
    {
        "original_text": "We report the discovery of an eclipsing binary system HS1857+5144, which is composed of two white dwarfs with masses 0.6 M⊙and 0.8M⊙respectively. The orbital period of this system is 1.5 hours. We find that the mass ratio q = M2/M1=0.84 ±0.04 for this system by using the method of spectral disentangling. This value indicates that it may be in the stage before the final merger into one single degenerate star. In addition to its short orbital period, we also found that the temperature difference between these two components is very large (∼10000K). These results suggest that this system has just evolved out of common envelope phase. \n \n Keywords: Hot subdwarf B stars; Eclipsing; Pre-Cataclysmic Variables; White Dwarfs; Spectral Disentangling",
        "watermark_text": "We report the discovery of an eclipsing binary system HS1857 + 5144 , which is composed of two white dwarfs with masses 0 . 6 [UNK] 0 . [UNK] . The orbital period of this system is 1 . 5 hours .We see that the mass ratio q = M2 / M1 = 0 . 84 ±0 . 04 for this system by using the method of spectral disentangling . This value indicates that it could be in the stage before the last collapse into one single degenerate star .In addition to its short orbital period , we also found that the temperature difference between these two components is very large ( [UNK] ) . These results suggest that this system has just evolved out of common envelope phase .Keywords : Hot subdwarf B stars ; Eclipsing ; Pre - Cataclysmic Variables ; White Dwarfs ; Spectral Disentangling",
        "ori-fast-z-score": 0.5773502691896258,
        "water-fast-z-score": 1.3127849234810511
    },
    {
        "original_text": "We present an algorithm for the evaluation of Hankel determinants that is almost as efficient as the product formula, but avoids numerical instability problems associated with it.  The determinant of a matrix A = (aij)n×n can be written in terms of its minors as det(A) = ∏i=1^n∑j=0^ni−1j|aij|. We show how to compute this expression efficiently using O((n log n)(log log n)) arithmetic operations and storage space by combining fast polynomial multiplication algorithms with ideas from number theory.   Our approach relies on the fact that we are able to evaluate all minors simultaneously at any point x ∈  0, 1  using only O((n log n) (log log n))) arithmetic operations and storage space. This allows us to use fast polynomial multiplication techniques to reduce the problem of computing the determinant to one of evaluating polynomials at many points. Finally, we apply recent results from number theory to obtain our final running time bound.",
        "watermark_text": "We create an algorithm for the evaluation of Hankel determinants that is almost as efficient as the product formula , but avoids numerical instability problems related with it . The determinant of a matrix A = ( aij ) n×n can be written in terms of its minors as det ( A ) = [UNK] = 1 ^ [UNK] = 0 ^ ni−1j | aij | .We see how to compute this function easily using O ( ( n log k ) ( log log n ) ) arithmetic operations and storage space by combining fast polynomial multiplication algorithms with ideas from number theory . Our solution relies on the fact that we are able to analyze all minors independently at any point x ∈ 0 , 1 using only O ( ( n log n ) ( log log n ) ) ) arithmetic operations and storage space .This enables us to use fast polynomial multiplication techniques to reduce the question of computing the determinant to one of evaluating polynomials at many points . Finally , we apply latest findings from number theory to obtain our final run time bound .",
        "ori-fast-z-score": 1.6059101370939322,
        "water-fast-z-score": 4.817730411281796
    },
    {
        "original_text": "We present an analysis of planet occurrence rates in binary systems, using spectroscopic observations to identify binaries among stars observed by Kepler for which we have obtained high-resolution imaging follow-up. We find that planets are less likely to be found around close visual doubles than single stars (<2 AU), but more likely to be found around wide visual doubles or triples (>20 AU). The difference between these two populations is statistically significant at greater than 3-sigma confidence level. These results suggest that stellar multiplicity may play some role in shaping planetary system architectures. However, our sample size is small compared to other studies, so further investigation will be needed before firm conclusions can be drawn. \n \n Keywords: Binary star - Planets - Multiplicity - Kepler - Visual double - Triple star - Planet formation - Circumstellar disk - Star formation - Exoplanet - Circumbinary disk - Double-lined spectroscopic binary",
        "watermark_text": "We present an assessment of planet existence rates in binary systems , using spectroscopic observations to identify binaries among stars observed by Kepler for which we have received high - resolution imaging follow - up . We see that planets are less likely to be found around tight visual doubles than single stars ( < 2 AU ) , but more likely to be found around wide visual twins or triples ( > 20 AU ) .The difference between these two communities is statistically substantial at greater than 3 - sigma confidence rate . These data suggest that stellar multiplicity may play some role in shaping planetary system architectures .However , our sample volume is tiny relative to other studies , so further investigation will be needed before firm conclusions can be drawn . Keywords : Binary star - Planets - Multiplicity - Kepler - Visual double - Triple star - Planet formation - Circumstellar disk - Star formation - Exoplanet - Circumbinary disk - Double - lined spectroscopic binary",
        "ori-fast-z-score": 1.3438638879193574,
        "water-fast-z-score": 5.335783750799325
    },
    {
        "original_text": "In this work, we propose an evolutionary neural gas model for input categorization and clustering in the context of self-organizing networks. The proposed algorithm is based on the concept that each neuron can be considered as a cluster center with its own weight vector. In addition to updating their weights according to the standard NG learning rule, neurons are also allowed to evolve by applying genetic operators such as crossover and mutation. We show through experiments conducted on benchmark data sets that our approach outperforms other state-of-the-art algorithms including SOMs, GNGs, and EBGs. Finally, we demonstrate how the proposed method can be used to solve real-world problems such as text classification and image segmentation. Keywords: Evolutionary Computation, Self-Organizing Networks, Clustering, Genetic Algorithms, Text Classification, Image Segmentation. 1 Introduction Self-organizing maps (SOMs), originally introduced by Kohonen  1  , have been widely applied in many fields ranging from pattern recognition  2  , speech processing  3  , computer vision  4  , bioinformatics  5  , etc.. However, one major drawback of traditional SOMs lies in the fact that they require users to specify the number of clusters beforehand  6  . To overcome this problem, several extensions of SOMs were developed  7, 8  .\nAmong these extensions, growing neural gas (GNG)  9  has attracted much attention due to its ability to automatically determine the optimal number of clusters during training  10  . Nevertheless, it should be noted that most existing models of self organizing network suffer from two main limitations. First, all nodes in the network share the same set of parameters which makes them unable to capture different characteristics of various categories  11  . Second, there lacks any mechanism to prevent overfitting when dealing with high-dimensional data  12  .",
        "watermark_text": "In this research , we propose an evolved brain gas model for input categorization and clustering in the context of self - organizing organizations . The proposed algorithm is based on the idea that each neuron can be regarded as a cluster center with its own weight vector .In addition to updating their weights based to the standard NG learning principle , neurons are also allowed to evolve by using genetic operators such as crossover and mutation . We see through experiments conducted on benchmark data sets that our approach outperforms other state - of - the - art algorithms including SOMs , GNGs , and EBGs .Finally , we prove how the suggested method can be used to solve real - global difficulties such as text classification and image segmentation . Keywords : Evolutionary Computation , Self - Organizing Networks , Clustering , Genetic Algorithms , Text Classification , Image Segmentation .1 Introduction Self - organizing maps ( SOMs ) , previously introduced by Kohonen 1 , have been widely applied in diverse fields ranging from pattern recognition 2 , speech logic 3 , computer vision 4 , bioinformatics 5 , etc . . However , one major drawback of typical SOMs rests in the fact that they allow users to define the number of clusters beforehand 6 .To solve this situation , various extensions of SOMs were developed 7 , 8 . Among these extensions , growing cognitive gas ( GNG ) 9 has garnered considerable scrutiny due to its able to automatically identify the ideal amount of clusters during training 10 .Nevertheless , it should be mentioned that most existing models of self organizing system emerge from two principal constraints . First , all users in the organization share the same list of constraints which makes them unable to capture unique characteristics of several classes 11 .Second , there lacks any mechanism to minimize overfitting when dealing with high - dimensional data 12 .",
        "ori-fast-z-score": 0.8838834764831843,
        "water-fast-z-score": 8.824410972276484
    },
    {
        "original_text": "We present the results on the spatial distribution of galaxies in the vicinity (<5 Mpc) of a bright quasar at redshift 5.2, using deep near-infrared imaging data taken with Subaru/Suprime-Cam. We find that there is an apparent segregation between Lyman break galaxies (LBGs), which are selected by their rest-frame UV colors, and Lyman alpha emitters (LAEs). The LBGs show a clear overdensity toward the quasar position while LAEs do not have such a concentration. This result suggests that the physical conditions for star formation may be different between these two populations. \n \n Keywords: galaxy evolution, quasars, clustering, infrared observations, high-z universe, Lyman break galaxies, Lyman alpha emitters \n \n \n \n 1 Introduction \n \n Quasars play important roles as probes to study the early Universe because they can provide us information about the intergalactic medium through absorption lines observed in their spectra. In addition, quasars themselves emit strong radiation over wide wavelength ranges, so we can use them as background sources to investigate the properties of surrounding objects. For example, it has been suggested that quasars trigger starburst activities in nearby galaxies via intense ultraviolet (UV) radiation and/or gravitational interactions (e.g., Hopkins et al. 2006) . \n \n Recently, several studies have investigated the environments of high-redshift quasars based on multi-wavelength surveys. These include optical/near-infrared spectroscopy (e.g., Adelberger & Steidel 2005; Venemans et al. 2007) , radio continuum emission (e.g., Carilli et al. 2007; Overzier et al. 2008 ) and X-ray emission (e.g,. Brandt et al. 2002; Gilli et al. 2003 ) . However, most previous works focused only on relatively small scales (<1 Mpc) due to limited angular resolution or sensitivity of telescopes used. On larger scales, some authors reported possible evidence for large-scale structures associated with quasars (e.g., Kurk et al. 2000; Pentericci et al",
        "watermark_text": "We present the results on the spatial distribution of stars in the vicinity ( < 5 Mpc ) of a bright quasar at redshift 5 . 2 , using deep near - infrared imaging information taken with Subaru / Suprime - Cam . We see that there is an apparent segregation between Lyman break galaxies ( LBGs ) , which are chosen by their rest - frame UV colors , and Lyman alpha emitters ( LAEs ) .The LBGs see a clear overdensity toward the quasar state while LAEs do not have such a density . This result suggests that the physical conditions for star formation might be different between these two communities .Keywords : universe progression , quasars , clustering , infrared observations , low - z galaxy , Lyman break galaxies , Lyman alpha emitters 1 Introduction Quasars serve useful roles as probes to study the early Universe because they can provide us information about the intergalactic medium through absorption patterns observed in their spectra . In addition , quasars themselves emit strong radiation over broad wavelength ranges , so we can using them as background sources to examine the properties of surrounding objects .For instance , it has been proposed that quasars activate starburst interactions in nearby galaxies via intense ultraviolet ( UV ) rays and / or gravitational interactions ( e . g . , Hopkins et al . 2006 ) .Recently , various surveys have explored the conditions of high - redshift quasars based on multi - wavelength analyses . These include optical / near - infrared spectroscopy ( e . g . , Adelberger & Steidel 2005 ; Venemans et al .2007 ) , radio continuum emission ( e . g . , Carilli et al . 2007 ; Overzier et al .2008 ) and X - ray radiation ( e . g , . Brandt et al .2002 ; Gilli et al . 2003 ) .However , most prior papers focused only on relatively small scales ( < 1 Mpc ) resulting to limited radial resolution or sensitivity of telescopes used . On larger scales , some writers published possible evidence for large - scale structures involved with quasars ( e . g . , Kurk et al .2000; Pentericci et al",
        "ori-fast-z-score": 0.50709255283711,
        "water-fast-z-score": 6.6530001764255
    },
    {
        "original_text": "We present new observations of the outflows driven by massive protostars using the Submillimeter Array (SMA) at 1.3 mm, which are compared with previous results obtained with single-dish telescopes. We find that the SMA data reveal more compact structures than those seen previously; this is likely due to missing flux and/or resolution effects. The total mass loss rates inferred for these sources range between 10^-4 and 10^-3 Msun/yr, while their momentum flux ranges between 10^-2 and 10^1 Lsun/c/s. These values are similar to those found for low-mass Class 0 objects but higher than expected if scaled up according to the luminosity-to-mass ratio. This suggests that there may be additional mechanisms driving the outflows besides radiation pressure on dust grains. \n \n In addition we report the detection of infalling gas toward two of our targets. For G35.20-1.74NW, we detect an inward motion of ~0.5 km/s over a distance of ~1000 AU. For IRAS 18162-2048, we see evidence for both inward motions as well as outward motions along different lines-of-sight.",
        "watermark_text": "We present new images of the outflows driven by massive protostars utilizing the Submillimeter Array ( SMA ) at 1 . 3 millimetres , which are compared with previous findings obtained with single - dish telescopes . We see that the SMA data reveal more compact systems than those shown previously ; this is probably due to missing flux and / or resolution influences .The total mass loss rates inferred for these sources range between 10 ^ - 4 and 10 ^ - 3 Msun / yr , while their momentum flux ranges between 10 ^ - 2 and 10 ^ 1 Lsun / c / s . These figures are comparable to those observed for low - mass Class 0 bodies but higher than expected if scaled up according to the luminosity - to - mass ratio .This implies that there may be additional mechanisms pushing the outflows besides radiation stress on dust grains . In addition we monitor the observation of infalling gas toward two of our objectives .For G35 . 20 - 1 . 74NW , we perceive an inward movement of ~ 0 . 5 kilometres / s over a distance of ~ 1000 AU . For IRAS 18162 - 2048 , we find proof for both eastward movements as well as outward movements along various lines - of - view .",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 5.4349297638940595
    },
    {
        "original_text": "We study satellites in simulated galaxies with different masses at z = 0 using high-resolution cosmological hydrodynamic simulations (the Millennium Run). We find that there is no significant difference between the number density profiles of satellite galaxies around central galaxies with different luminosities or halo masses. The radial distribution of satellites shows an excess over the predictions based on the subhalo abundance matching technique for r < 30 kpc/h. This excess can be explained by tidal stripping of satellites before they are accreted onto the main galaxy. In addition, we show that the fraction of surviving satellites decreases rapidly as a function of distance from the center of host halos. Finally, we investigate how the properties of satellites depend on those of their hosts. Our results suggest that the majority of faint satellites may have been destroyed through mergers and/or tidal disruption during infall into larger systems. These findings provide important constraints on models of galaxy formation.",
        "watermark_text": "We research satellites in simulated galaxies with various masses at z = 0 using high - resolution cosmological hydrodynamic simulations ( the Millennium Run ) . We see that there is no major variation between the number density characteristics of satellite galaxies around central planets with various luminosities or halo masses .The radial distribution of satellites displays an excess over the estimates based on the subhalo abundance matching methodology for r < 30 kpc / h . This excess can be described by tidal stripping of satellites before they are accreted onto the main galaxy .In addition , we find that the fraction of surviving satellites decreases quickly as a function of distance from the center of host halos . Finally , we investigate how the properties of satellites depend on those of their hosts .Our results show that the majority of distant satellites would have been destroyed through mergers and / or tidal disruption during infall into larger systems . These conclusions provide important restrictions on estimates of galaxy formation .",
        "ori-fast-z-score": 0.6974858324629157,
        "water-fast-z-score": 5.579886659703326
    },
    {
        "original_text": "We report on an analysis of archival Chandra data for the central region of the nearby starburst galaxy M82 (NGC 3034). We find that there are two bright, point-like sources in this field which have been previously identified as ULXs (Ultra-Luminous X-Ray Sources) by Swartz et al. (2004) . The first source is located at RA = 12 h 54 m 55 s .6 and Dec = 69°59 45   with a count rate of 1.1 x 10^-3 counts sec-1. This source has a luminosity of 2 x 10^39 erg/sec assuming it lies at 8 kpc distance. The second source is located at RA=12h54m55s.7 and Dec=69°59 46   with a count rate 0.9 x 10^-3 countssec-1. It also has a luminosity of about 2 x 10^39erg/sec if it lies at 8kpc. Both these sources appear to be variable over timescales ranging between hours and days.  These results suggest that both sources may contain black holes accreting close to their Eddington limit.",
        "watermark_text": "We report on an assessment of archival Chandra data for the central region of the nearby starburst galaxy M82 ( NGC 3034 ) . We see that there are two faint , point - like sources in this field which have been previously described as ULXs ( Ultra - Luminous X - Ray Sources ) by Swartz et al .( 2004 ) . The first reference is found at RA = 12 h 54 m 55 s . 6 and Dec = 69°59 45 with a count rate of 1 . 1 x 10 ^ - 3 counts sec - 1 .This source has a luminosity of 2 x 10 ^ 39 erg / sec assuming it lies at 8 kpc distance . The second source is situated at RA = 12h54m55s . 7 and Dec = 69°59 46 with a count rate 0 . 9 x 10 ^ - 3 countssec - 1 .It additionally has a luminosity of about 2 x 10 ^ 39erg / sec if it lies at 8kpc . Both these sources appear to be varying over timescales ranging between hours and days .These data suggest that both sources might represent dark holes accreting close to their Eddington limit .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.328201177351375
    },
    {
        "original_text": "We report on the observation and characterization of two-dimensional defect modes in optically-induced photonic crystals (OIPCs). The OIPC is formed by periodic modulation of refractive index using femtosecond laser pulses focused into fused silica glass. We show that the defect mode can be tuned over a wide range of wavelengths, which are determined by the periodicity of the lattice structure as well as the size of the defects. This work opens up new possibilities for designing optical devices based on these structures. \n \n Photonic crystal slabs have attracted considerable attention recently because they provide an excellent platform to study light-matter interactions at the nanoscale  1  . In particular, it has been shown that three-dimensional photonic crystals with point or line defects exhibit localized states within their bandgap  2  , leading to many interesting applications such as lasers  3  , filters  4  , sensors  5  , nonlinear optics  6  , etc.. However, fabrication of three-dimensional photonic crystals requires sophisticated techniques  7, 8  , making them difficult to integrate with other micro/nano-structures. Recently, several groups have demonstrated two-dimensional photonic crystals  9  -  11  fabricated directly inside transparent materials via direct laser writing  12  -  14  . These 2D photonic crystals offer advantages including ease of fabrication, flexibility in design, and compatibility with existing technologies  15  .\nIn this Letter we demonstrate the formation of defect modes in opticallyinduced photonic crystals (OPC)  16  . The OPC consists of periodically modulated refractive index created by focusing femtosecond laser pulses into fused silica glass  17  . By introducing defects into the lattice structure, we observe localized defect modes within the stopband of the OPC. Furthermore, we show that the defect mode wavelength can be continuously tuned across the entire stopband simply by changing the lattice spacing and/or the size of the defects. \nThe experimental setup used to create the OPC is illustrated schematically in Fig. 1(a) . A Ti:Sapphire regenerative amplifier system operating at 800 nm was employed to generate 100 fs duration pulses at a repetition rate of 1 kHz. The beam diameter after passing through a spatial filter",
        "watermark_text": "We report on the observation and identification of two - dimensional defect modes in optically - mediated photonic crystals ( OIPCs ) . The OIPC is formed by periodic modulation of refractive index utilizing femtosecond laser pulses focused into fused silica glass .We see that the defect mode can be tuned over a broad variety of wavelengths , which are chosen by the periodicity of the lattice structure as also as the height of the defects . This research raises up new possibilities for constructing optical devices based on these structures .Photonic crystal slabs have garnered considerable interest lately because they give an excellent platform to study light - matter processes at the nanoscale 1 . In particular , it has been shown that three - dimensional photonic materials with point or line defects exhibit localized states within their bandgap 2 , leading to many interesting applications such as lasers 3 , filters 4 , devices 5 , nonlinear optics 6 , etc . .However , fabrication of three - dimensional photonic particles needs specialized techniques 7 , 8 , making them harder to integrate with other micro / nano - materials . Recently , various groups have demonstrated two - dimensional photonic particles 9 - 11 fabricated fully inside transparent materials via continuous optical writing 12 - 14 .These 2D photonic materials provide advantages including ease of fabrication , simplicity in design , and compatibility with existing devices 15 . In this Letter we prove the formation of defect modes in opticallyinduced photonic materials ( OPC ) 16 .The OPC composed of regularly modulated refractive index created by concentrating femtosecond laser pulses into fused silica glass 17 . By introducing defects into the lattice structure , we perceive localized failure modes within the stopband of the OPC .Furthermore , we find that the failure mode wavelength can be continuously tuned across the entire stopband solely by varying the crystal spacing and / or the size of the defects . The empirical setup used to create the OPC is depicted schematically in Fig .1 ( a ) . A Ti : Sapphire regenerative amplifier system operating at 800 nm was employed to produce 100 fs duration pulses at a repetition rate of 1 kHz .The beam diameter after passing through a spatial filter",
        "ori-fast-z-score": -0.3223291856101521,
        "water-fast-z-score": 7.526023228839096
    },
    {
        "original_text": "We present an analytic solution to the steady state distribution for the mechanistic home-range model developed by Moorcroft et al. (2006) that allows for efficient computation of home ranges using numerical integration methods. The new method is implemented as part of the R package adehabitatHR, which also includes functions for computing home ranges with the original algorithm (i.e., without the analytical solution). We demonstrate how our approach can be used to rapidly compute home ranges across large landscapes containing thousands of habitat patches. Our results show that the new method produces identical estimates compared to those obtained with the original algorithm but requires less computational time when estimating home ranges over large spatial extents. Analytical solutions are useful because they allow researchers to efficiently estimate home ranges on very large datasets or at fine resolutions. \n \n Home ranges have been widely studied since their introduction into ecology more than 50 years ago  1  . These areas represent the area within which individuals obtain all necessary resources  2  , such as food  3  , water  4  , shelter  5  , mates  6  , and cover  7  . In addition to being important for understanding animal behavior  8  , home ranges play key roles in conservation biology  9  , wildlife management  10  , epidemiology  11  , and disease transmission  12  .\n \nHome-range models typically assume that animals move through a landscape composed of discrete habitat patches  13  . Animals select among these patches based on some combination of patch attributes  14  , including resource availability  15  , vegetation structure  16  , predation risk  17  , and conspecific density  18  . This process continues until the animal reaches equilibrium between its movement rate and the quality of available habitats  19  . \n \n A number of different approaches exist for modeling animal movements  20  . One popular class of models uses random-walk theory  21  to describe animal movements  22  . Random walk models assume that animals make independent decisions about where to go next  23  . However, this assumption may not always hold true  24  . For example, if two neighboring patches contain similar levels of resources  25  , then it would be unlikely for an animal to switch back-and-forth between them  26  . To account for this type of behavioral response, Moorcro",
        "watermark_text": "We present an analytic solution to the stable state distribution for the mechanistic home - range system established by Moorcroft et al . ( 2006 ) that enables for efficient computation of home ranges using numerical integration methods .The new method is implemented as part of the R program adehabitatHR , which also contains functions for modeling home ranges with the previous algorithm ( i . e . , without the empirical approach ) . We suggest how our approach can be used to rapidly compute bedroom ranges across large landscapes containing thousands of environment patches .Our results show that the new method generates similar estimates compared to those achieved with the previous algorithm but requires fewer computational time when estimating bedroom ranges over large geographic extents . Analytical approaches are helpful because they allow scientists to easily assess home ranges on very huge datasets or at fine resolutions .Home ranges have been widely examined since their arrival into ecosystems more than 50 weeks ago 1 . These zones represent the territory within which adults obtain all necessary resources 2 , such as feed 3 , water 4 , protection 5 , mates 6 , and cover 7 .In addition to being important for explaining animal behavior 8 , home ranges represent crucial roles in wildlife dynamics 9 , conservation conservation 10 , epidemiology 11 , and illness transmission 12 . Home - range systems often assume that animals go through a landscape composed of linear habitat patches 13 .Animals select among these patches based on some mix of patch traits 14 , covering habitat availability 15 , vegetation system 16 , predation risk 17 , and conspecific density 18 . This process proceeds until the organism reaches stability between its movement rate and the performance of available environments 19 .A variety of different methods exist for modeling animal activities 20 . One popular family of models using random - walk models 21 to explain animal activities 22 .Random step models believe that individuals give independent choice about where to going next 23 . However , this assumption must not always hold false 24 .For instance , if two adjacent regions contain similar rates of assets 25 , then it would be impossible for an organism to shift back - and - forth between them 26 . To account for this form of behavioral reaction , Moorcro",
        "ori-fast-z-score": -1.7230995806825715,
        "water-fast-z-score": 10.625780747542525
    },
    {
        "original_text": "Reverberation is an important feature of brain function, but its role remains unclear. We show that reverberation can be generated by the interplay between calcium signaling and short-term plasticity (STP) at excitatory synapses. In our model, STP leads to bursts of spikes which are followed by periods of low firing rate due to depletion of neurotransmitter vesicles. The resulting slow recovery of transmitter release causes a build-up of residual calcium concentration  Ca  res , leading to facilitation of glutamate release during subsequent bursts. This positive feedback loop generates sustained reverberatory activity with multiple time scales. Our results suggest that reverberation may play a key role in information processing within neural circuits. Reverberation is one of the most prominent features of brain function  1  . It has been observed across different species  2  -  4  as well as in various brain areas including hippocampus  5  , neocortex  6  , thalamus  7  , striatum  8  , cerebellar cortex  9  , olfactory bulb  10  , and retina  11  .\nDespite its ubiquity, however, it still remains unknown what functional roles reverberation plays in the brain  12  . One possibility is that reverberation serves as a mechanism for memory storage  13  or retrieval  14  . Another hypothesis suggests that reverberation could serve as a substrate for working memory  15  . Yet another idea is that reverberation might provide a means for temporal coding  16  . Finally, some studies have suggested that reverberation may simply reflect ongoing spontaneous activity  17  .",
        "watermark_text": "Reverberation is an important feature of cerebral activity , but its significance remains unsure . We suggest that reverberation can be triggered by the interplay between calcium signaling and short - term plasticity ( STP ) at excitatory synapses .In our model , STP results to bursts of peaks which are preceded by periods of poor fired rate due to depletion of neurotransmitter vesicles . The resulting slow withdrawal of transmitter release forms a build - up of residual calcium concentration Ca res , leading to facilitation of glutamate production during later bursts .This positive feedback network generates sustained reverberatory behavior with various time ranges . Our results propose that reverberation may play a key importance in information processing within neural systems .Reverberation is one of the most notable features of cerebral function 1 . It has been observed across different species 2 - 4 as well as in different brain regions including hippocampus 5 , neocortex 6 , thalamus 7 , striatum 8 , cerebellar cortex 9 , olfactory bulb 10 , and retina 11 .Despite its ubiquity , however , it still remains obscure what functional functions reverberation plays in the brain 12 . One possibility is that reverberation acts as a system for memory processing 13 or retrieval 14 .Another hypothesis suggests that reverberation possibly provide as a substrate for working brain 15 . Yet another idea is that reverberation would offer a means for temporal coding 16 .Finally , some researchers have suggested that reverberation possibly simply reflect ongoing spontaneous activity 17 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.514430561703706
    },
    {
        "original_text": "We present the first results for atmospheric dynamics in short period extra-solar gas giant planets (EGPs) using 3D general circulation models with radiative transfer and realistic opacities. We find that the night-side temperature is strongly dependent on opacity, which determines how much energy can be transported to space by radiation. The day-night contrast increases as we decrease the opacity because less heat escapes through the nightside atmosphere. This effect is more pronounced at lower pressures where convection becomes inefficient. For low enough opacities, the planet cools down completely during its orbit resulting in an extremely cold night side. Our simulations show that EGPs are likely to have very different climates depending on their composition.  Keywords: General Circulation Modeling, Extrasolar Planetary Systems, Radiation Transfer, Climate, Atmosphere, Energy Transport, Convection, Cooling Rates, Day-Night Contrast",
        "watermark_text": "We present the first findings for atmospheric mechanics in small history additional - solar gas giant galaxies ( EGPs ) using 3D general circulation estimates with radiative transfer and realistic opacities . We see that the night - side temperature is strongly dependent on opacity , which determines how many heat can be transported to space by radiation .The day - night difference rises as we decrease the opacity because lighter thermal exits through the nightside environment . This phenomenon is more pronounced at lower pressures where circulation becomes inefficient .For low enough opacities , the planet cools down fully during its orbit producing in an incredibly cold evening side . Our simulations see that EGPs are likely to have very different climates based on their composition .Keywords: General Circulation Modeling, Extrasolar Planetary Systems, Radiation Transfer, Climate, Atmosphere, Energy Transport, Convection, Cooling Rates, Day-Night Contrast",
        "ori-fast-z-score": -0.2581988897471611,
        "water-fast-z-score": 4.905778905196061
    },
    {
        "original_text": "We present an analysis of Lyman alpha emitters (LAEs) selected by narrowband imaging with Subaru/Suprime-Cam and spectroscopic follow-up observations using VLT/VIMOS at z ~ 3.1, which is one of the most active epochs for galaxy formation. We find that LAEs are distributed over a wide range of environments; they exist both in isolated regions as well as in dense clusters. The clustering properties of LAEs depend on their luminosities. In particular, we found that bright LAEs show stronger clustering than faint ones do. This result suggests that bright LAEs may be more evolved systems compared to fainter ones. Furthermore, we investigated the dependence of clustering strength on the equivalent widths of Lyman-alpha emission lines. Our results suggest that strong clustering objects tend to have higher equivalent widths. These findings imply that there exists some evolutionary link between LAEs and LBGs. \n \n Keywords: Lyman alpha emitter",
        "watermark_text": "We present an assessment of Lyman alpha emitters ( LAEs ) selected by narrowband scanning with Subaru / Suprime - Cam and spectroscopic follow - up observations using VLT / VIMOS at z ~ 3 . 1 , which is one of the most stable epochs for galaxy formation . We see that LAEs are distributed over a broad variety of habitats ; they exist both in isolated regions as well as in dense clusters .The clustering qualities of LAEs depend on their luminosities . In particular , we identified that bright LAEs see better clustering than dim ones do .This result suggests that bright LAEs may be more evolved structures compared to fainter ones . Furthermore , we investigated the dependence of clustering strength on the equivalent widths of Lyman - alpha emission lines .Our results show that strong clustering objects prefer to have greater equivalent widths . These conclusions conclude that there exists some evolutionary link between LAEs and LBGs .Keywords: Lyman alpha emitter",
        "ori-fast-z-score": 0.5163977794943222,
        "water-fast-z-score": 4.816989706290483
    },
    {
        "original_text": "We report on the room-temperature ferromagnetism in Mn-doped ZnO thin films grown by pulsed laser deposition (PLD). The Curie temperatures are found to be around 300 K for all samples with different doping levels, which is much higher than that reported previously. We also find that the magnetization increases linearly as the applied field decreases and shows hysteresis loops at low fields. These results indicate that the observed ferromagnetic behavior may originate from exchange coupling between localized spins rather than intrinsic ferromagnetism. \n \n In recent years, there has been growing interest in developing new materials for spintronic applications such as nonvolatile memory devices or logic circuits based on the manipulation of electron spins instead of charge carriers1-5 . Among these materials, diluted magnetic semiconductors have attracted considerable attention because they can combine both electronic and magnetic functionalities into one material6-8 .\n \n\n\nZnO-based DMSs have been extensively studied due to their wide band gap energy (3.37 eV), large exciton binding energy (60 meV)9 , high transparency10-12 , and good chemical stability13-15 . However, it remains challenging to achieve room-temperature ferromagnetically ordered states in ZnO-based DMSs16-18 . Although several groups have recently demonstrated room-temperature ferromagnetic ordering in various types of ZnO-based DMS systems19-24 , most of them show relatively small saturation magnetizations25-27 . \n \n Here we report on the observation of room-temperature ferromagnetisms in Mn-doped ZnObased DMSs prepared using pulsed laser deposition28-30 . Our experimental data clearly demonstrate that the dopant concentration plays an important role in determining the Curie temperature31-33 . For example, our sample with x = 0.5% exhibits a Curie temperature of about 300 K while those with lower concentrations exhibit smaller values ranging from 150-250 K34-36 . Moreover, we observe that the magnetization increases almost linearly when decreasing the external magnetic field below 1 T and displays hysteretic behaviors at very low fields. This indicates that the observed ferr",
        "watermark_text": "We report on the room - temperature ferromagnetism in Mn - doped ZnO thin sheets grown by pulsed laser precipitation ( PLD ) . The Curie temperatures are found to be around 300 K for all specimens with various doping rates , which is much higher than that described earlier .We additionally find that the magnetization increases linearly as the applied field decreases and shows hysteresis loops at low areas . These conclusions show that the seen ferromagnetic activity may originate from exchange interactions between localized spins rather than intrinsic ferromagnetism .In past times , there has been growing interest in building new materials for spintronic use such as nonvolatile memory devices or logic devices using on the manipulation of electron spins rather of charge carriers1 - 5 . Among these materials , diluted magnetic semiconductors have garnered considerable scrutiny because they can mix both electronic and magnetic functionalities into one material6 - 8 .ZnO - based DMSs have been heavily explored thanks to their wide band gap energy ( 3 . 37 eV ) , large exciton activation energy ( 60 meV ) 9 , large transparency10 - 12 , and good molecular stability13 - 15 . However , it remains challenging to achieve room - temperature ferromagnetically ordered states in ZnO - based DMSs16 - 18 .Although several groups have recently shown room - temperature ferromagnetic sorting in different kinds of ZnO - based DMS systems19 - 24 , most of them show relatively small saturation magnetizations25 - 27 . Here we publish on the observation of room - temperature ferromagnetisms in Mn - doped ZnObased DMSs assembled utilizing laser optical deposition28 - 30 .Our experimental records distinctly show that the dopant concentration plays an important role in distinguishing the Curie temperature31 - 33 . For instance , our sample with x = 0 . 5 % experiences a Curie temperature of about 300 K while those with higher concentrations display lesser values ranging from 150 - 250 K34 - 36 .Moreover , we determine that the magnetization increases almost linearly when decreasing the external magnetic force below 1 T and displays hysteretic behaviors at very low areas . This implies that the observed ferr",
        "ori-fast-z-score": 0.16666666666666666,
        "water-fast-z-score": 8.833333333333334
    },
    {
        "original_text": "We present the light-cone distribution amplitudes (DAs) for axial vector mesons in terms of their helicity components, which are determined by solving the Bethe-Salpeter equation with an instantaneous interaction kernel and applying the method developed recently to calculate DAs.  We find that the twist-2 DA is dominated by its first Gegenbauer moment, while higher moments contribute significantly only at large momentum fractions x > 0.7. The twist-3 DA has two independent functions, one of them being proportional to the second Gegenbauer moment. Our results show that the twist-4 contribution is negligible compared to those of lower twists. These findings will be useful for studying exclusive processes involving axial vector mesons such as B-decays into charmonium plus photon or pion pair. \nI. INTRODUCTIO N\nThe study of hadronic structure plays an important role in understanding strong interactions between quarks and gluons inside hadrons. In particular, the investigation on the parton distributions provides us valuable information about how quarks and gluon are distributed within hadrons  1  . Recently, there have been great interests in exploring the internal structures of hadrons beyond the leading-twist level  2  , especially the transverse-momentum dependent parton distributions  3  .\nIn this work we focus our attention on another type of nonperturbative objects -the light-cone distribution amplitudes(DAs). They describe the probability amplitude of finding a quark-antiquark pair with certain longitudinal momentum fraction and transverse separation at some fixed light-like distance  4  . It was shown that they play crucial roles in describing various hard exclusive reactions  5  . For example, the decay constants fBπ and fBs can be expressed in terms of the lowest-order DAs  6  ; the form factors of semileptonic decays B→πlν l and B→Klν l depend on both the lowest-and next-to-lowest order DAs  7, 8  . Furthermore, it was found that the heavy-to-light transition form factor FV(q 2 ) of B→V transitions depends",
        "watermark_text": "We introduce the light - cone distribution amplitudes ( DAs ) for axial vector mesons in terms of their helicity components , which are decided by solving the Bethe - Salpeter equation with an instantaneous interaction kernel and using the method developed lately to estimate DAs . We see that the twist - 2 DA is dominated by its initial Gegenbauer moment , while greater moments contribute considerably only at large velocity fractions x > 0 . 7 .The twist - 3 DA has two independent functions , one of them being equal to the second Gegenbauer moment . Our results show that the twist - 4 contribution is negligible compared to those of lower bends .These studies will be valuable for studying exclusive mechanisms using axial vector mesons such as B - decays into charmonium plus photon or pion pair . I . INTRODUCTIO N The investigation of hadronic structure serves an important role in understanding strong interactions between quarks and gluons inside hadrons .In particular , the investigation on the parton distributions offers us valuable info about how quarks and gluon are distributed within hadrons 1 . Recently , there have been big efforts in investigating the internal structures of hadrons beyond the led - twist level 2 , particularly the transverse - momentum dependent parton distributions 3 .In this research we focus our focus on another type of nonperturbative objects - the light - cone distribution amplitudes ( DAs ) . They define the probability amplitude of finding a quark - antiquark pair with certain horizontal momentum fraction and longitudinal separation at some fixed light - like distance 4 .It was shown that they serve vital part in understanding various hard exclusive reactions 5 . For instance , the decay constants fBπ and fBs can be stated in terms of the lowest - order DAs 6 ; the form factors of semileptonic decays B→πlν l and B→Klν l depend on both the highest - and last - to - lowest order DAs 7 , 8 .Furthermore , it was shown that the heavy - to - light shift form parameter FV ( q 2 ) of B→V transitions depends",
        "ori-fast-z-score": 1.044465935734187,
        "water-fast-z-score": 8.181649829917799
    },
    {
        "original_text": "We present an analysis of the mass function (MF) of active black holes (BHs), based on the sample of quasars with redshifts z < 0.5 and luminosities L > 10^44 erg/s, selected by Shen et al. (2007). We use two different methods to estimate BH masses for this sample - virial method and continuum-fitting method. The MF is constructed using both these estimates separately as well as their combination. Our results are compared against previous studies which used similar samples but different techniques to determine BH masses. We find that our best fit Schechter parameters agree within errors with those obtained previously. However, we also find evidence for a possible excess at low-mass end when we combine all three data sets together. This excess could be due to incompleteness or biases in the selection criteria adopted here. In addition, we compare our results with theoretical predictions made by Hopkins et al. (2006a) and Shankar et al. (2009b) .",
        "watermark_text": "We present an assessment of the mass distribution ( MF ) of active black holes ( BHs ) , using on the sample of quasars with redshifts z < 0 . 5 and luminosities L > 10 ^ 44 erg / s , selected by Shen et al . ( 2007 ) .We use two different methods to estimate BH masses for this sample - virial technique and continuum - fitting technique . The MF is built using both these estimates separately as well as their combination .Our results are compared against prior studies which employed identical specimens but different methods to identify BH masses . We see that our better matched Schechter parameters agree within errors with those acquired previously .However , we also find proof for a possible excess at low - weight end when we merge all three statistics sets together . This excess could be due to incompleteness or biases in the selection standards adopted here .In addition , we compare our findings with theoretical estimates made by Hopkins et al . ( 2006a ) and Shankar et al .(2009b) .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "The author considers the problem of gravitational interaction between bodies in terms of their informational content. The main idea is that the gravitational field can be considered as an ensemble of gravitons which carry information about the source body. Gravitational waves are treated as carriers of information on the state of motion of gravitating objects. It is shown how this approach allows one to explain some phenomena observed in astrophysics (the Pioneer anomaly) and cosmology (dark energy). In addition, it is proposed to use the concept of  information potential  for describing the evolution of the universe. This article was published by the journal Classical and Quantum Gravity Volume 27, Issue 14, pages 5993-6010, November 2010. DOI: 10.1088/0264-9381/27/14/05993/abstract. The following text is taken directly from the original publication. \n \n Abstract \n \n We consider the problem of gravitational interaction among bodies in terms of their information content. The main idea here is that the gravitational field may be viewed as an ensemble of gravitons/quanta carrying information about the source body; gravitational waves are then seen as carriers of information regarding the state of motion of the gravitating objects. This viewpoint enables us to provide explanations for certain phenomena observed in astrophysical settings (e.g., the Pioneer anomaly), as well as in cosmological contexts (e.g., dark energy). Moreover, we propose using the notion of “information potential” to describe the evolution of the Universe.",
        "watermark_text": "The author considers the issue of gravitational interaction between bodies in terms of their informational content . The main idea is that the gravitational field can be regarded as an ensemble of gravitons which carry information about the origin body .Gravitational waves are treated as carriers of information on the state of movement of gravitating objects . It is demonstrated how this methodology allows one to explain some phenomena observed in astrophysics ( the Pioneer anomaly ) and cosmology ( darkness energy ) .In addition , it is proposed to use the notion of information possibilities for describing the evolution of the universe . This section was publication by the journal Classical and Quantum Gravity Volume 27 , Issue 14 , pages 5993 - 6010 , November 2010 .DOI : 10 . 1088 / 0264 - 9381 / 27 / 14 / 05993 / abstract . The following text is taken directly from the original published .Abstract We consider the question of gravitational interaction among bodies in terms of their information content . The main idea here is that the gravitational field might be viewed as an ensemble of gravitons / quanta carrying information about the source body ; gravitational waves are then considered as transports of information regarding the state of movement of the gravitating structures .This perspectives permits us to provide explanations for particular phenomena observed in astrophysical contexts ( e . g . , the Pioneer anomaly ) , as also as in cosmological contexts ( e . g . , darkness energy ) . Moreover , we propose utilizing the notion of “ information potential ” to explain the evolution of the Universe .",
        "ori-fast-z-score": 2.116950987028628,
        "water-fast-z-score": 6.735753140545634
    },
    {
        "original_text": "We propose that the metallic enhancement observed for some post T Tauri stars (PTTS) may be due to an accretion of planetesimals during their formation phase, which is followed by rapid planet formation and subsequent ejection of planets into space.  We show that this scenario can explain both the high metallicity found among PTTS as well as the low abundance ratios between refractory elements such as Mg/Si or Al/Si compared with those expected if these objects formed through standard core-accretion processes. The proposed mechanism also explains why there are no known close-in giant planets around PTTSs despite the fact that they have already passed their protoplanetary disk stage. This model predicts that most PTTS should host at least one Jupiter mass planet on wide orbits beyond 1 AU. In addition we predict that many PTTS will exhibit infrared excesses caused by dusty debris disks produced by collisions between planetary bodies.",
        "watermark_text": "We suggest that the metallic enhancement detected for some post T Tauri planets ( PTTS ) may be due to an accretion of planetesimals during their formed phase , which is preceded by rapid planet development and subsequent ejection of stars into space . We suggest that this situation can describe both the high metallicity observed among PTTS as well as the poor abundance proportions between refractory objects such as Mg / Si or Al / Si compared with those expected if these objects created through conventional core - accretion cycles .The proposed process also explains why there are no known close - in massive planets around PTTSs despite the fact that they have already completed their protoplanetary disk stage . This theory predicts that most PTTS should accommodate at least one Jupiter mass planet on wide orbits beyond 1 AU .In addition we estimate that several PTTS will exhibit infrared excesses caused by dusty dust belts generated by collisions between planetary body .",
        "ori-fast-z-score": -1.116312611302876,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "We present the first mid-infrared phase curve observations for an extrasolar planet, WASP-121b (1SWASP J140747.93-394542.7), using Spitzer/IRAC at 3.6 and 4.5 microns. The data were taken in two epochs separated by one year to allow us to search for any changes in the system s properties over time. We find that the amplitude of the phase variation is consistent with previous measurements made in the optical but we detect no significant change between our two epochs. This suggests that there are no large variations in the temperature structure or composition of this planet as it orbits its host star. Our results also show that the planet has a very high albedo in both bands which may be due to clouds and/or haze. These findings have important implications for understanding how planets form and evolve. \n \n Keywords: exoplanet, infrared",
        "watermark_text": "We present the first mid - infrared phase curve measurements for an extrasolar planet , WASP - 121b ( 1SWASP J140747 . 93 - 394542 . 7 ) , using Spitzer / IRAC at 3 . 6 and 4 . 5 microns . The data were took in two epochs separated by one month to allow us to search for any alterations in the system s features over time .We see that the frequency of the phase change is compatible with previous measurements made in the optical but we perceive no major shift between our two epochs . This implies that there are no large changes in the temperature structure or composition of this planet as it orbits its host star .Our results also demonstrate that the planet has a very high albedo in both bands which may be due to clouds and / or haze . These conclusions have important implications for explaining how planets form and evolve .Keywords: exoplanet, infrared",
        "ori-fast-z-score": 0.5252257314388902,
        "water-fast-z-score": 4.727031582950012
    },
    {
        "original_text": "We present new measurements of 3 He+ and 3 He++ column densities toward eight nearby stars, using data obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE). The results are compared to previous observations made by Copernicus and IUE satellites as well as FUSE. We find that our values for N(3 He+)/N(H+), which range between 0.0015-0.0125, agree within uncertainties with those measured previously at high latitudes but disagree significantly with lower latitude measurements. Our results suggest that there is an additional source of ionization near the Galactic plane not accounted for by cosmic rays or X-rays. This could be due to shocks driven into the interstellar medium by supernovae remnants and/or winds associated with massive OB associations. \n \n Keywords: Helium abundance, Interstellar medium, Shocks, Supernova remnant, Winds, Cosmic ray",
        "watermark_text": "We present new surveys of 3 He + and 3 He + + column densities toward eight distant stars , using data acquired with the Far Ultraviolet Spectroscopic Explorer ( FUSE ) . The results are compared to previous images conducted by Copernicus and IUE missions as well as FUSE .We see that our values for N ( 3 He + ) / N ( H + ) , which range between 0 . 0015 - 0 . 0125 , agree within uncertainties with those observed previously at high latitudes but disagree significantly with higher latitude observations . Our results propose that there is an additional source of ionization near the Galactic jet not accounted for by cosmic rays or X - radiation .This might be due to shocks driven into the interstellar medium by supernovae fragments and / or winds related with massive OB interactions . Keywords : Helium abundance , Interstellar medium , Shocks , Supernova remnant , Winds , Cosmic ray",
        "ori-fast-z-score": -0.42857142857142855,
        "water-fast-z-score": 4.428571428571429
    },
    {
        "original_text": "We study adiabatic charge transport across an interacting quantum dot coupled to two leads, where one lead is driven by a time-dependent gate voltage and the other remains grounded. We show that this setup can be used as a pump for electrons when the driving frequency matches twice the energy difference between the singlet and triplet states of the dot. In particular we find that the pump current exhibits sharp peaks whenever the Fermi level crosses a bound state inside the gap induced by the Coulomb interaction on the dot. The height of these peaks increases with increasing temperature T , which allows us to use our system as a thermometer. Finally, we discuss how our findings are modified if the driving amplitude becomes comparable or larger than the charging energy U . \nI. INTRODUCTORY REMARK\nIn recent years there has been growing interest in using periodically-driven systems as sources of coherent radiation  1  . This idea was first proposed more than twenty years ago  2  but only recently it became possible to realize such devices experimentally  3  .\nOne particularly interesting class of periodically-driven systems consists of those whose properties depend strongly on their internal degrees of freedom  4  . These so-called  quantum impurity models  have attracted considerable attention over the past few decades because they provide a simple description of many physical phenomena ranging from single-electron transistors  5  to heavy fermion compounds  6  . Recently, several groups have studied theoretically the possibility of using quantum dots  7, 8  and carbon nanotubes  9  as pumps for electrons  10  . However, most theoretical studies so far focused on non-interacting particles  11  while experiments typically involve strong interactions  12  . It would therefore be desirable to extend existing theories beyond the weak-coupling limit  13  .\nThe purpose of this work is to investigate the effect of electron correlations on the performance of a pump based on a quantum dot (QD)  14  . To do so, we consider a QD connected to two leads via tunnel barriers  15  . One lead is driven out of equilibrium by applying a periodic gate voltage V g (t), whereas the second lead serves as a reference electrode  16  . As shown schematically in Fig. 1(",
        "watermark_text": "We explore adiabatic charge flow across an interacting quantum dot connected to two leads , where one lead is powered by a time - based gate voltage and the other remains grounded . We see that this configuration can be used as a pump for electrons when the driving frequency matches times the power change between the singlet and triplet states of the dot .In particular we find that the pump charge shows sharp peaks whenever the Fermi level crosses a bound state inside the gap induced by the Coulomb interaction on the dot . The height of these spikes varies with expanding temperature T , which allows us to use our system as a thermometer .Finally , we explain how our findings are modified if the driving amplitude becomes comparable or larger than the charging power U . I .INTRODUCTORY REMARK In past decades there has been growing interest in utilizing continuously - fueled materials as sources of coherent emission 1 . This idea was first suggested more than twenty years previously 2 but only lately it becoming necessary to realize such devices experimentally 3 .One especially interesting class of regularly - fueled schemes includes of those whose characteristics rely highly on their internal degrees of freedom 4 . These so - called quantum impurity models have garnered considerable scrutiny over the previous few years because they give a simple explanation of several physical phenomena ranging from double - ion transistors 5 to heavy fermion compounds 6 .Recently , various groups have researched theoretically the prospect of using quantum dots 7 , 8 and carbon nanotubes 9 as pumps for electrons 10 . However , most theoretical researchers so far concentrate on non - interacting molecules 11 while experiments usually include strong interactions 12 .It would therefore be desirable to extend previous theories beyond the weak - interaction threshold 13 . The purpose of this research is to examine the impact of electron correlations on the performance of a pump based on a quantum dot ( QD ) 14 .To do so , we imagine a QD connected to two leads via underground walls 15 . One lead is caused out of equilibrium by using a periodic gate current V g ( t ) , whereas the second lead serves as a reference electrode 16 .As depicted schematically in Fig . 1 (",
        "ori-fast-z-score": -1.3568010505999364,
        "water-fast-z-score": 8.04261249963027
    },
    {
        "original_text": "We study the effect of cascades initiated by ultra-high energy cosmic rays (UHECRs) in intergalactic space, and their contribution to the diffuse gamma-ray emission observed at Earth. We find that cascade photons can be produced over cosmological distances with energies up to 10 TeV or more. The resulting flux is strongly suppressed for sources located beyond redshifts z > 0.5 due to absorption effects caused by pair production interactions between cascade photons and infrared radiation fields associated with galaxies. For nearby source models we show that this suppression leads to an upper limit on the photon fraction fγ < 10% − 20% depending on the UHECR injection spectrum assumed. This constraint is consistent with current measurements of the diffuse gamma-ray background as well as recent results obtained using Fermi/LAT data. In addition, our analysis shows that cascade photons are likely to dominate the total diffuse gammaray emission below 1 GeV if they originate within a distance of about 100 Mpc around us.",
        "watermark_text": "We research the impact of cascades created by ultra - large energy cosmic rays ( UHECRs ) in intergalactic space , and their contribution to the diffuse γ - ray radiation observed at Earth . We see that cascade photons can be obtained over cosmological distances with energies up to 10 TeV or more .The resulting flux is strongly restrained for sources located beyond redshifts h > 0 . 5 due to absorption effects caused by pair production interactions between cascade photons and infrared light fields associated with galaxies . For nearby source models we find that this suppression results to an upper limitation on the photon fraction fγ < 10 % − 20 % based on the UHECR injection range assumed .This constraint is compatible with current observations of the diffuse γ - ray background as well as recent results acquired using Fermi / LAT results . In addition , our analysis shows that cascade photons are likely to dominate the total diffuse gammaray radiation below 1 GeV if they originate within a distance of about 100 Mpc around us .",
        "ori-fast-z-score": 0.7071067811865476,
        "water-fast-z-score": 5.976143046671968
    },
    {
        "original_text": "We present an algorithm for generating new solutions to the coupled Einstein-scalar field equations, starting from vacuum solutions and adding scalar fields in such a way that the resulting solution is minimally coupled.  The method can be used to generate exact solutions which are not known explicitly or only implicitly as functions of some parameters (e.g., by solving algebraic equations). We illustrate our approach on several examples including Schwarzschild-de Sitter black holes, Reissner-Nordström-anti-de Sitter black holes, Kerr-Newman-AdS black holes, and charged dilatonic black holes. In particular we show how one can obtain explicit expressions for the massless limit of these black hole solutions. Our results may also have applications beyond gravity theory, e.g., in quantum mechanics where they could provide insight into the structure of bound states. Introduction: Exact solutions play an important role in theoretical physics because they allow us to test various physical ideas against concrete predictions. However, finding exact solutions to physically interesting problems often turns out to be very difficult. For example, it took more than 100 years after the discovery of general relativity before the first exact black hole solutions were found  1-3 . Even today there exist many open questions about black holes  4  . One reason why finding exact solutions is so challenging is that most theories of interest do not admit any simple analytic solutions. Another problem arises when trying to find solutions describing systems with multiple interacting components like black holes surrounded by matter or other fields. Here one usually has to solve complicated differential equations numerically which makes it hard to find all possible solutions even if their existence was guaranteed theoretically. This situation becomes particularly severe if one wants to study phenomena at strong coupling since then numerical methods become less reliable due to large corrections arising from higher orders in perturbation theory.",
        "watermark_text": "We present an algorithm for generating new answers to the coupled Einstein - scalar field equations , beginning from vacuum solutions and adding scalar fields in such a way that the resulting solve is minimally coupled . The method can be used to create precise solutions which are not described specifically or only implicitly as functions of some parameters ( e . g . , by modeling algebraic equations ) .We illustrate our approach on numerous instances including Schwarzschild - de Sitter dark holes , Reissner - Nordström - anti - de Sitter dark holes , Kerr - Newman - AdS red holes , and charged dilatonic black holes . In particular we give how one can obtain precise expressions for the massless maximum of these black hole solutions .Our results may even have applications beyond gravitational theory , e . g . , in quantum mechanics where they may provide insight into the formation of bound states . Introduction : Exact solutions play an important role in theoretical physics because they allow us to test various mechanical concepts against concrete expectations .However , finding exact treatments to physically exciting issues often comes out to be very difficult . For instance , it takes more than 100 years after the discovery of general relativity before the first accurate black hole problems were found 1 - 3 .Even nowadays there remain many open questions about black holes 4 . One reason why seeking precise solutions is so difficult is that most models of importance do not admit any straightforward analytic solutions .Another difficulty arises when trying to find solutions involving systems with various interacting components like grey holes populated by matter or other fields . Here one usually has to solve complicated differential equations numerically which makes it difficult to find all possible solutions even if their existence was assured theoretically .This problem arises increasingly severe if one wants to study phenomena at strong coupling since then numerical models become fewer reliable resulting to large corrections resulting from greater orders in perturbation theory .",
        "ori-fast-z-score": 0.30499714066520933,
        "water-fast-z-score": 8.387421368293257
    },
    {
        "original_text": "We study the statistical properties of Barkhausen noise generated by an Ising spin system with random fields and competing interactions at its surface, using wavelets to analyze the time series produced by this model.  We find that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space. The stretching exponent depends on both temperature T and magnetic field H. In particular, we show how the stretching exponent can be used as a measure of the degree of disorder in the sample under investigation. Finally, we discuss possible extensions of our work to other types of systems exhibiting avalanche dynamics. Barkhausen noise (BN) has been studied extensively since it was first observed experimentally more than 100 years ago  1  . It consists of bursts of magnetization reversals which occur when a ferromagnetic material is driven through successive metastable states  2  , and is believed to play an important role in determining the coercive force of such materials  3  .\nThe statistics of BN have attracted considerable interest recently  4  -  8  due to their potential application in non-destructive testing  9  . However, despite many experimental studies  10  -  12  there are still open questions about the origin of these fluctuations  13  . For example, while some authors claim that they arise from thermally activated processes  14  others argue that they result from collective effects  15  or even quantum tunneling  16  . A number of theoretical models  17  -  20  have also been proposed to explain the physics behind BN but none of them seems able to reproduce all features simultaneously  21  .",
        "watermark_text": "We research the statistical characteristics of Barkhausen interference generated by an Ising spin body with random fields and competing interactions at its surface , using wavelets to analyze the time series formed by this model . We see that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space .The extension exponent depends on both heat T and magnetic force H . In particular , we explain how the stretching exponent can be used as a measure of the degree of disorder in the sample under research . Finally , we explain possible extend of our work to other types of models displaying avalanche dynamics .Barkhausen interference ( BN ) has been studied frequently since it was first observed experimentally more than 100 years early 1 . It consists of flashes of magnetization reversals which occur when a ferromagnetic material is accelerated through consecutive metastable levels 2 , and is suspected to hold an important role in establishing the coercive force of such substances 3 .The data of BN have garnered considerable interest recently 4 - 8 due to their potential application in non - destructive testing 9 . However , despite many experimental studies 10 - 12 there are still open questions about the origin of these fluctuations 13 .For instance , while some writers claim that they occur from thermally activated processes 14 others argue that they occur from collective effects 15 or maybe quantum tunneling 16 . A several of theoretical theories 17 - 20 have also been proposed to explain the physics behind BN but none of them appears able to predict all characteristics simultaneously 21 .",
        "ori-fast-z-score": -0.09166984970282113,
        "water-fast-z-score": 7.425257825928512
    },
    {
        "original_text": "We present new results on the asteroseismic analysis of the primary component in the binary system Alpha Centari, based on data obtained with the HARPS spectrograph at La Silla Observatory (Chile). We find evidence for two independent frequencies that are likely to be associated with rotationally split modes. The observed frequency pattern is consistent with theoretical predictions and suggests an inclination angle between 40°and 60°for this star. \n \n Keywords: Asteroseismology, Rotation, Binary stars, Oscillations, Frequency analysis, High-precision radial velocities, Alpha Centari ABSTRACT \n \n We report new results on the asterioseismic analysis of the main-sequence F-type star Alpha Centari A, which forms part of a close double system with its cooler companion B. Our study was carried out using high-precision radial-velocity measurements collected over more than four years by the HARPS instrument installed at ESO s 3.6-m telescope at La Silla Observatory (Chilean Andes), together with photometric observations made simultaneously with the CoRoT space mission. By applying standard techniques used in asteroseismology we have detected several periodicities in both datasets, including one signal whose periodicity corresponds exactly to the orbital period of the system. This finding confirms previous suggestions that the pulsational behaviour of this star may be influenced by tidal effects induced by its companion. In addition, our analysis reveals another set of signals corresponding to periods ranging from about 1 day up to almost 2 days. These signals can be explained as being due to rotationally split p-mode oscillations excited in the convective envelope of the star. Their presence provides strong support for the hypothesis that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo processes operating within the convection zone.",
        "watermark_text": "We report new data on the asteroseismic study of the primary component in the binary system Alpha Centari , using on evidence derived with the HARPS spectrograph at La Silla Observatory ( Chile ) . We see evidence for two independent frequencies that are likely to be involved with rotationally split periods .The observed frequency trend is compatible with theoretical estimates and suggests an inclination angle between 40°and 60°for this star . Keywords : Asteroseismology , Rotation , Binary stars , Oscillations , Frequency assessment , High - precision radial velocities , Alpha Centari ABSTRACT We report new data on the asterioseismic study of the main - sequence F - class star Alpha Centari A , which forms part of a close double system with its warmer companion B .Our study was carried out utilizing large - precision radial - speed measurements collected over more than four years by the HARPS instrument located at ESO s 3 . 6 - m observatory at La Silla Observatory ( Chilean Andes ) , combined with photometric surveys made independently with the CoRoT space expedition . By applying traditional techniques employed in asteroseismology we have discovered numerous periodicities in both datasets , notably one signal whose periodicity corresponds exactly to the orbital period of the system .This finding indicates past proposals that the pulsational response of this star may be altered by tidal impacts generated by its companion . In addition , our analysis reveals another set of signals relating to periods ranging from about 1 day up to approximately 2 days .These transmissions can be understood as being related to rotationally split p - mode oscillations excited in the convective envelope of the star . Their presence provides strong evidence for the notion that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo mechanisms operating within the convection zone .",
        "ori-fast-z-score": -0.9838699100999074,
        "water-fast-z-score": 6.887089370699352
    },
    {
        "original_text": "We present simultaneous observations with the Rossi X-ray Timing Explorer (RXTE) Proportional Counter Array, Swift Burst Alert Telescope (BAT), X-Ray Telescope (XRT), Ultraviolet/Optical Telescope (UVOT), and Radio Extension for Multi-wavelengths Observatory (REM). The data were obtained during an active state of the source on February 18-20, 2005 . We find that the spectral energy distribution is consistent with synchrotron self-Compton emission from relativistic electrons accelerated by magnetic reconnection events occurring within the jet. This interpretation is supported by the detection of rapid variability at all wavelengths observed simultaneously. In addition to this flaring activity we also detect significant flux variations over longer timescales which are likely due to changes in the Doppler boosting factor caused by bulk motion of plasma along the jet. These results demonstrate how multi-wavelength campaigns can be used to study the physical processes responsible for the production of non-thermal radiation in AGN jets.",
        "watermark_text": "We report concurrent observations with the Rossi X - ray Timing Explorer ( RXTE ) Proportional Counter Array , Swift Burst Alert Telescope ( BAT ) , X - Ray Telescope ( XRT ) , Ultraviolet / Optical Telescope ( UVOT ) , and Radio Extension for Multi - wavelengths Observatory ( REM ) . The data were obtained during an active state of the source on February 18 - 20 , 2005 .We see that the spectral power distribution is compatible with synchrotron self - Compton absorption from relativistic electrons accelerated by magnetic reconnection events resulting within the jet . This interpretation is backed by the discovery of rapid variability at all wavelengths observed concurrently .In addition to this flaring activity we also observe significant flux variations over longer timescales which are likely due to changes in the Doppler boosting factor resulting by bulk movement of plasma along the jet . These data demonstrate how multi - wavelength campaigns can be used to study the physical processes responsible for the production of non - cooling emission in AGN planes .",
        "ori-fast-z-score": 0.13018891098082389,
        "water-fast-z-score": 5.337745350213779
    },
    {
        "original_text": "Quantum repeaters are proposed to overcome the loss in quantum communication channels by using entangled photons and linear optics elements such as beam splitters, phase shifters, and single-photon detectors.  In this work we present an experimental demonstration of a quantum repeater with two distant nodes connected via a 50 km fiber link. The system consists of three parts: (1) generation, (2) transmission, and (3) detection of photon pairs at each node; (4) Bell-state measurement between the two nodes; and (5) feed-forward operation on the received qubits based on the result of Bell-state measurement. We have successfully demonstrated all these parts except the feed-forward operation which is currently under development. Our results show that our current setup can generate high quality entanglement over a distance up to 50 km. This experiment paves the way towards practical implementation of quantum networks. Quantum repeaters are proposed to solve the problem caused by channel losses in quantum communication systems  1  . They use entangled photons generated locally or remotely  2  , and linear optical elements such as beam splitters; phase shifters; and single-photon detectors  3  .\nIn this Letter, we report an experimental demonstration of a long-distance quantum repeater  4  consisting of four main components: (1) generation, ( 2 ) t r ansmission , ( 3 ) d etection , and ( 4 ) B ell -state m easurement o f pho ton pairs at eac h n ode ; ( 5 ) feed-foward operations on the received qubits according to the outcome of Bell-state measurements   Figs. 1(a) , 1(b), and 2 . A pair of polarization-entangled photons was produced through spontaneous parametric down-conversion (SPDC). One photon acted as signal while another one served as idler. After passing through different paths, they were combined together at a beam splitter (BS) and sent into a 50-km-long fiber-optic line. At both ends of the fiber-optic line, photon-number resolving avalanche photodiodes (APDs) detected the",
        "watermark_text": "Quantum repeaters are proposed to overcome the loss in quantum communication channels by using entangled photons and linear optics components such as beam splitters , wave shifters , and single - photon detectors . In this research we present an demonstration demonstration of a quantum repeater with two distant nodes linked via a 50 km fiber link .The system contains of three parts : ( 1 ) production , ( 2 ) propagation , and ( 3 ) detection of photon pairs at each node ; ( 4 ) Bell - state measurement between the two nodes ; and ( 5 ) feed - forward operation on the received qubits based on the result of Bell - state measurement . We have successfully shown all these parts except the feed - forward operation which is currently under development .Our results show that our new configuration can generate strong quality entanglement over a length up to 50 km . This study paves the way towards practical implementation of quantum networks .Quantum repeaters are proposed to tackle the issue caused by channel losses in quantum communication devices 1 . They use entangled photons generated locally or remotely 2 , and linear optical units such as beam splitters ; phase shifters ; and single - photon detectors 3 .In this Letter , we publish an experimental demonstration of a long - distance quantum repeater 4 consisting of four main components : ( 1 ) production , ( 2 ) t r ansmission , ( 3 ) d etection , and ( 4 ) B ell - state m easurement o h pho ton pairs at eac h h ode ; ( 5 ) feed - foward operations on the received qubits according to the result of Bell - state measurements Figs . 1 ( a ) , 1 ( c ) , and 2 .A couple of polarization - entangled photons was produced through spontaneous parametric down - transfer ( SPDC ) . One photon worked as signal while another one served as idler .After passing through different paths , they were paired together at a laser splitter ( BS ) and sent into a 50 - kilometres - length fiber - optic line . At both sides of the fiber - optic line , photon - number resolving avalanche photodiodes ( APDs ) detected the",
        "ori-fast-z-score": 0.26211121699831136,
        "water-fast-z-score": 5.613171323564988
    },
    {
        "original_text": "We study the elasticity of thin films with periodic microstructure, which are constrained to lie on an underlying substrate. We show that such systems can exhibit anomalously large values for their Young s moduli as well as Poisson ratios. The origin of these effects is traced back to the presence of phonon soft modes associated with the periodicity along the film normal direction. These results have implications for the design of novel materials with tailored elastic properties. \n \n In recent years there has been growing interest in understanding how confinement affects the physical behavior of matter at the nanoscale  1  . This problem arises naturally when considering thin films or nanowires embedded within bulk materials; however it also applies more generally whenever a system is restricted to occupy only part of its available phase space  2  . For example, this situation occurs frequently during crystal growth where defects may be introduced into the lattice structure by impurities  3  , or when studying colloidal suspensions  4  .\n \nIn this work we consider the case of a thin film with periodic microstructure, whose thickness h lies between two length scales L and d (see Fig 1) . Here L represents the typical size of the unit cell while d denotes the characteristic spacing between adjacent layers; both quantities are assumed to be much smaller than the in-plane dimensions of the sample. Such structures arise commonly in nature, e.g., in layered compounds like graphite  5  , transition metal dichalcogenides  6  , and hexagonal boron nitride  7  . They are also used extensively in technological applications ranging from photovoltaics  8  to optoelectronics  9  . \n \n Figure 1: Schematic illustration of our model geometry. A thin film with periodic microstructures is confined to lie on top of a rigid substrate.",
        "watermark_text": "We test the elasticity of thin films with periodic microstructure , which are constrained to lay on an underlying substrate . We see that such complexes can exhibit anomalously high values for their Young s moduli as well as Poisson ratios .The origin of these phenomena is traced back to the presence of phonon soft modes associated with the periodicity along the film regular direction . These results have consequences for the creation of new materials with tailored elastic properties .In past decades there has been growing interest in understanding how confinement impacts the physical activity of matter at the nanoscale 1 . This problem arises readily when considering thin films or nanowires attached within bulk objects ; however it also applies more generally whenever a system is restricted to fill only part of its allocated phase space 2 .For instance , this situation occurs commonly during crystal growth where defects could be applied into the lattice structure by impurities 3 , or when examining colloidal suspensions 4 . In this research we define the case of a thin glass with periodic microstructure , whose thickness g lies between two width scales L and d ( see Fig 1 ) .Here L represents the typical size of the unit cell while d indicates the typical spacing between neighboring layers ; both quantities are expected to be much smaller than the in - plane dimensions of the sample . Such structures appear often in nature , e . g . , in layered compounds like graphite 5 , transition copper dichalcogenides 6 , and hexagonal boron nitride 7 .They are also used heavily in technological use ranging from photovoltaics 8 to optoelectronics 9 . Figure 1 : Schematic illustration of our model topology .A narrow film with periodic microstructures is confined to lying on top of a rigid coating .",
        "ori-fast-z-score": -1.3926212476455828,
        "water-fast-z-score": 6.614950926316518
    },
    {
        "original_text": "In this talk, we will discuss the relationship between loop spaces and Langlands parameters in terms of their connections to representation theory.  We will begin by recalling some basic facts about loop spaces and their relation with infinite-dimensional Lie groups (e.g., loop groups).  Next, we ll recall how one can associate a certain type of infinite-dimensional Lie group called an affine Hecke algebra to any reductive algebraic group over a field k of characteristic 0.   Finally, we ll explain how these two ideas are related via the notion of a Harish-Chandra bimodule. The main result is that if G is a connected semisimple complex algebraic group defined over Q then there exists a natural isomorphism between the category of finite-dimensional representations of G(Q) and the category of Harish-Chandra modules for its associated affine Hecke algebra. This work was done jointly with David Vogan at Harvard University during my postdoctoral fellowship.",
        "watermark_text": "In this talk , we will explore the relationship between loop spaces and Langlands parameters in terms of their connections to representation theory . We will start by examining some fundamental details about loop spaces and their connection with infinite - dimensional Lie fields ( e . g . , loop spaces ) .Next , we ll remember how one can associate a certain type of infinite - dimensional Lie category called an affine Hecke algebra to any reductive algebraic ring over a field k of characteristic 0 . Finally , we ll explain how these two ideas are related via the notion of a Harish - Chandra bimodule .The main consequence is that if G is a connected semisimple complex algebraic ring defined over Q then there exists a natural isomorphism between the category of finite - dimensional representations of G ( Q ) and the category of Harish - Chandra modules for its associated affine Hecke algebra . This research was done jointly with David Vogan at Harvard University during my postdoctoral fellowship .",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 4.913538149119954
    },
    {
        "original_text": "The Large Area Telescope (LAT) is one of two instruments aboard NASA s Fermi Gamma-ray Space Telescope, launched in June 2008. The LAT consists of an array of silicon strip trackers and cesium iodide calorimeters that detect gamma rays with energies between 20 MeV to more than 300 GeV. This document describes a novel method used by the LAT collaboration to monitor the performance of its detector system during flight using cosmic ray data taken over several months prior to launch. We show how this method can be applied to characterize the response function of each individual tracker module as well as the overall energy resolution of the entire LAT. These results are compared against ground calibration measurements performed before launch. Finally we demonstrate how these techniques have been successfully employed to identify problems with some modules after launch which were subsequently fixed through software updates. The Large Area Telescope (L AT ) is one of two instruments flown on NASA s Fermi Gamma-Ray Space Telescope  1  . Launched into space in June 2008, it has detected thousands of sources of high-energy photons since then  2  .\nIn order to perform such observations, the L AT must accurately measure the direction and energy of incoming photons. To accomplish this task, the L AT uses a combination of silicon strip detectors and CsI(Tl) scintillators arranged in four layers around a central tungsten converter foil  3  , see Figure 1 . Each layer contains 16 towers, or  trajectory segments , consisting of 4 silicon strips oriented at different angles relative to the incident photon trajectory  4  . In addition there are 8  strips  per tower located behind the silicon sensors but outside of the active volume of the calorimeter  5  . Together they form a total of 56 independent tracking channels  6  .",
        "watermark_text": "The Large Area Telescope ( LAT ) is one of two instruments aboard NASA s Fermi Gamma - ray Space Telescope , launched in June 2008 . The LAT consists of an ensemble of silicon strip trackers and cesium iodide calorimeters that detect beta particles with energies between 20 MeV to more than 300 GeV .This text explains a new method employed by the LAT collaboration to study the performance of its detector network during mission utilizing cosmic ray data taken over several months previously to launch . We indicate how this technology can be applied to characterize the response function of each individual tracker module as also as the overall energy resolution of the entire LAT .These data are compared against ground calibration measurements completed before flight . Finally we prove how these procedures have been successfully utilized to identify issues with some modules after launch which were later resolved through technology updates .The Large Area Telescope ( L AT ) is one of two instruments flown on NASA s Fermi Gamma - Ray Space Telescope 1 . Launched into space in June 2008 , it has detected many of sources of high - energy photons since then 2 .In order to conduct such observations , the L AT requires properly study the direction and energy of incoming photons . To accomplish this objective , the L AT employs a combination of silicon strip detectors and CsI ( Tl ) scintillators grouped in four layers around a central tungsten converter foil 3 , see Figure 1 .Each layer contains 16 towers , or path sectors , consisting of 4 silicon patches aligned at different angles relative to the incident photon trajectory 4 . In addition there are 8 layers per tower situated behind the silicon detector but outside of the active volume of the calorimeter 5 .Together they create a total of 56 independent tracking channels 6 .",
        "ori-fast-z-score": 0.3682298471593294,
        "water-fast-z-score": 7.425257825928512
    },
    {
        "original_text": "We propose that the energy release process in coronal mass ejections (CMEs) is due to two different physical mechanisms, magnetic reconnection and catastrophic loss of equilibrium driven by ideal magnetohydrodynamic (MHD) instabilities.  The first mechanism releases free magnetic energy stored in the corona into kinetic energy of plasma flows during solar eruptive events such as flares or CMEs. This mechanism has been studied extensively using numerical simulations based on resistive MHD models with various levels of complexity ranging from simple two-dimensional configurations to more realistic three-dimensional ones. In this work we focus our attention on the second mechanism which involves rapid conversion of magnetic field energy into thermal energy through an explosive reconfiguration of the magnetic topology. We show how this mechanism can be modeled analytically within the framework of ideal MHD theory. Our results suggest that both processes are likely to operate simultaneously but at different stages of evolution of the erupting flux rope.",
        "watermark_text": "We suggest that the electricity release process in coronal mass ejections ( CMEs ) is due to two different mechanical pathways , electric reconnection and catastrophic loss of equilibrium caused by ideal magnetohydrodynamic ( MHD ) instabilities . The first mechanism transfers loose magnetic energy stored in the corona into kinetic power of plasma flows during solar eruptive events such as flares or CMEs .This mechanism has been studied frequently using numerical simulations based on resistive MHD models with various amounts of complexity including from basic two - dimensional shapes to more realistic three - dimensional ones . In this research we focus our focus on the second process which includes rapid transfer of magnetic field energy into heat power through an explosive reconfiguration of the magnetic topology .We indicate how this mechanism can be described analytically within the framework of optimal MHD model . Our results show that both processes are likely to work simultaneously but at different stages of evolution of the erupting flux rope .",
        "ori-fast-z-score": 0.6793662204867574,
        "water-fast-z-score": 7.0201176116964925
    },
    {
        "original_text": "In this article we study the structure of smooth foliations on closed manifolds, which are given by submersions whose fibers have only Morse singularities (i.e., they look like graphs over their tangent spaces). We prove that such foliations can be approximated in the C 1 -topology by regular ones and give an explicit bound for the approximation error. This result is used to show that any leafwise Riemannian metric on these foliations has bounded geometry. The main tool here is the theory of harmonic maps into Hilbert spaces developed by Eells-Elworthy-Malliavin. In particular, we use the fact that every harmonic map into a Hilbert space is weakly conformal. As another application of our results, we obtain some estimates for the volume growth rate along leaves of such foliations. Finally, using the above mentioned bounds for the approximation error, we also get lower bounds for the number of critical points of generic functions on closed manifolds.",
        "watermark_text": "In this article we study the composition of smooth foliations on closed manifolds , which are given by submersions whose strands have only Morse singularities ( i . e . , they look like graphs over their tangent spaces ) . We conjecture that such foliations can be approximated in the C 1 - topology by regular ones and giving an explicit bound for the approximation error .This result is utilized to say that any leafwise Riemannian metric on these foliations has finite geometry . The main tool here is the notion of harmonic maps into Hilbert spaces introduced by Eells - Elworthy - Malliavin .In particular , we utilize the fact that every harmonic mapping into a Hilbert space is mildly conformal . As another application of our findings , we obtain some measurements for the density expansion speed along leaves of such foliations .Finally , using the above mentioned bounds for the approximation error , we also get lower bounds for the number of important points of generic functions on shut manifolds .",
        "ori-fast-z-score": -1.6378460497066512,
        "water-fast-z-score": 3.25
    },
    {
        "original_text": "The Very Large Array (VLA) is an array of 27 radio telescopes located in New Mexico, USA. The VLA has been upgraded to operate at higher frequencies and with better sensitivity than ever before. In this talk I will describe how we have developed new techniques for operating the system at 74 MHz using digital beamforming technology. This work was done as part of my PhD thesis under the supervision of Prof. David Diamond. My research interests are in developing software systems that can be used by astronomers to analyse data produced by large observational facilities such as the VLA. I am currently working towards a postdoctoral position at Harvard-Smithsonian Center for Astrophysics where I hope to continue my research into advanced signal processing algorithms for astronomy applications. Keywords: Radio Astronomy, Digital Signal Processing, Software Engineering, Data Analysis, Beamforming Algorithms, Very Large Array, 74 MHz",
        "watermark_text": "The Very Large Array ( VLA ) is an array of 27 radio telescopes located in New Mexico , USA . The VLA has been upgraded to work at higher speeds and with improved accuracy than ever before .In this talk I will explain how we have developed novel techniques for running the device at 74 MHz using digital beamforming technology . This project was done as part of my PhD thesis under the guidance of Prof . David Diamond .My research interests are in building software applications that can be used by astronomers to analyse information produced by large observational facilities such as the VLA . I am currently working towards a postdoctoral position at Harvard - Smithsonian Center for Astrophysics where I aim to pursue my research into advanced information processing algorithms for astronomy applications .Keywords : Radio Astronomy , Digital Signal Processing , Software Engineering , Data Analysis , Beamforming Algorithms , Very Large Array , 74 MHz",
        "ori-fast-z-score": -0.282842712474619,
        "water-fast-z-score": 5.091168824543142
    },
    {
        "original_text": "The Standard Model is in excellent agreement with all current experimental data, but it leaves many questions unanswered and fails to provide an explanation for some phenomena observed experimentally.  The muon magnetic moment anomaly provides one such example where there are significant discrepancies between theory predictions and experiment measurements that cannot be explained within the Standard Model framework.   In this talk I will present the physics case for the new g-2 experiment at Fermilab which aims to measure the anomalous magnetic moment of the muon more accurately than ever before by using a novel technique based on laser cooling and trapping techniques developed over recent years.   ... This talk presents the physics case for the proposed new measurement of the muon s anomalous magnetic moment at Fermilab. It describes how the use of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous experiments. A number of other topics related to the project are also discussed including the status of the R&D program towards the goal of measuring the muon magnetic moment to 0.5 parts per million accuracy.",
        "watermark_text": "The Standard Model is in good agreement with all recent experimental evidence , but it leaves many issues unanswered and fails to provide an reason for some phenomena observed experimentally . The muon magnetic point anomaly gives one such example where there are significant discrepancies between theoretical estimates and observation observations that cannot be described within the Standard Model framework .In this talk I will present the physics case for the new g - 2 study at Fermilab which aims to measure the anomalous magnetic motion of the muon more accurately than ever before by using a innovative method based on laser cooling and trapping techniques established over recent generations . . . .This discussion presents the physics case for the suggested novel measurement of the muon s anomalous magnetic force at Fermilab . It details how the using of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous study .A variety of other topics related to the project are also discussed including the status of the R & D program towards the objective of calculating the muon magnetic moment to 0 . 5 parts per million accuracy .",
        "ori-fast-z-score": 1.5096588248481377,
        "water-fast-z-score": 7.701031252562294
    },
    {
        "original_text": "The origin of the most massive stars is still an open question in astrophysics, as well as their role in shaping galactic evolution. In this talk I will present recent results on how we can use observations to constrain theoretical models for the formation of these objects.  The first part of my talk will focus on the observational properties of young massive clusters (YMCs) that are found at high redshift z>6-7. These YMCs have masses up to 10^8 Msun and sizes of ~1kpc. They appear to be very compact compared with local starburst galaxies such as Arp 220 or M82 which typically contain much less dense stellar populations. We find that the observed size-mass relation of these distant YMCs agrees remarkably well with predictions based on numerical simulations of turbulent gas clouds collapsing under self-gravity. This suggests that turbulence plays an important role during the early stages of cluster formation. However, it remains unclear whether all massive stars form in such large clusters like those seen at high redshifts.",
        "watermark_text": "The origin of the most large objects is still an open question in astrophysics , as well as their role in shaping galactic progression . In this talk I will present recent results on how we can using observations to constrain theoretical theories for the formation of these objects .The first part of my talk will focus on the observational properties of young massive clusters ( YMCs ) that are found at high redshift z > 6 - 7 . These YMCs have masses up to 10 ^ 8 Msun and dimensions of ~ 1kpc .They seem to be very small compared with local starburst clusters such as Arp 220 or M82 which commonly feature considerably less dense stellar groups . We see that the observed height - mass balance of these distant YMCs follows perfectly well with predictions based on numerical simulations of turbulent gas clouds collapsing under self - gravity .This implies that turbulence plays an important role during the early stages of cluster structure . However , it remains unsure whether all huge objects create in such large clusters like those observed at high redshifts .",
        "ori-fast-z-score": 0.7875615306482168,
        "water-fast-z-score": 6.340751391209736
    },
    {
        "original_text": "We report on the optical and near-infrared afterglows of the short-hard burst GRB 050802 detected by Swift/BAT on May 2nd, 2005 at 07:55:06 UT (T0). The prompt emission was followed by an X-ray flare peaking at T0+500 s in the rest frame. We find that both components are well described by power laws with decay indices α1 = 1.2 ± 0.3 for t < 10 ks and α2 = 2.5 ± 0.4 for t > 10 ks. A break is observed between these two regimes around t0 + 20 ks. No evidence for spectral evolution or extinction has been found within each component. Our results suggest that this event may be similar to GRB 021004 which also showed a double-power law behaviour but without any significant spectral evolution across the break time. This suggests that the physical mechanism responsible for the late-time steepening could be related to the one producing the early shallow decline. \n \n Keywords: Gamma-ray burst",
        "watermark_text": "We report on the optical and far - infrared afterglows of the short - hard burst GRB 050802 detected by Swift / BAT on May 2nd , 2005 at 07 : 55 : 06 UT ( T0 ) . The prompt emission was followed by an X - ray flare peaking at T0 + 500 s in the rest frame .We see that both components are better characterised by power laws with decay indices α1 = 1 . 2 ± 0 . 3 for t < 10 ks and α2 = 2 . 5 ± 0 . 4 for t > 10 ks . A break is observed between these two regimes around t0 + 20 ks .No support for spectral evolution or extinction has been shown within each component . Our results propose that this event may be similar to GRB 021004 which also demonstrated a double - energy law evolution but without any considerable brightness progression across the break time .This implies that the physical process cause for the late - time steepening could be connected to the one generating the early shallow collapse . Keywords : Gamma - ray burst",
        "ori-fast-z-score": 0.6401843996644799,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "We present the results of a numerical study on the relaxation dynamics of an initially straight contact line in a two-dimensional geometry, which is driven by surface tension and viscous dissipation at the moving interface between liquid and gas phases.  We solve the Navier-Stokes equations for incompressible fluids with free-slip boundary conditions using a spectral element method to simulate the flow field around the evolving droplet shape. The initial condition consists of a circular droplet sitting on top of a flat substrate that has been perturbed slightly away from its equilibrium position. As time evolves, we observe the formation of capillary waves along the contact line as well as the development of small satellite drops near the main droplet due to pinching off events. In addition, we find that the contact angle decreases continuously during this process until it reaches zero degrees when the entire droplet detaches from the substrate. Finally, we compare our simulation results against experimental data obtained from high-speed video microscopy measurements performed by other researchers.",
        "watermark_text": "We present the conclusion of a numerical investigation on the relaxation behavior of an initially parallel contact line in a two - dimensional topology , which is generated by surface friction and viscous dissipation at the moved junction between liquid and gas phases . We calculate the Navier - Stokes equations for incompressible gases with loose - slipping border conditions utilizing a spectral component process to simulate the flow field around the evolving droplet shape .The initial condition consists of a circular droplet standing on top of a flattened substrate that has been perturbed slightly apart from its stable position . As period evolves , we monitor the formation of capillary currents along the contact line as also as the development of tiny satellite flows near the main droplet thanks to pinching off events .In addition , we find that the contact angle decreases continuously during this process until it meets zero degrees when the entire droplet detaches from the substrate . Finally , we compare our modeling results against empirical data received from high - speed tape microscopy observations performed by other researchers .",
        "ori-fast-z-score": -0.7592566023652966,
        "water-fast-z-score": 7.267170336924982
    },
    {
        "original_text": "We study the effect of rounding on the dynamics of complex networks with first-order phase transition (FPT). We show that FPTs can be rounded by adding or removing nodes, which leads to an increase in the number of cooperators at equilibrium. The results are obtained for both static and dynamic models of evolution of cooperation. In particular, we find that the presence of FPTs is necessary but not sufficient condition for high levels of cooperation. Finally, we propose a simple strategy for finding the best possible roundings leading to maximal level of cooperation. Rounding of first-order phase transistions and optimal cooperation in scale free networks. P. Krawczyk 1 , A. Szolnoki 2 . \n1 Institute of Physics, University of Warsaw, Poland; krawczykp@wip.waw.pl .\n2 Department of Mathematics, University of Warsaw, Warsaw, Poland; aszolnok@wip. waw.pl .\nIn this work we investigate how the presence of first order phase transitions affects the evolution of cooperation in social dilemmas. First, we introduce two new concepts -the minimal and the maximal cooperative states-which describe the range of values of parameters where cooperation prevails over defection. Then, using these definitions, we prove that any system with first order phase transition has its own unique value of parameter corresponding to the maximum fraction of cooperators. Next, we consider the problem of optimizing cooperation in such systems. To do so, we define the concept of  rounding  of first order phase transitions, i.e., changing their shape into smooth curves without affecting the position of the point of maximum fraction of cooperators within the interval  0, 1 . Using numerical simulations, we demonstrate that the rounding procedure increases the fraction of cooperators at equilibrium in all studied cases. Finally, we present a method allowing one to determine the optimal rounding of given phase transition curve.",
        "watermark_text": "We research the impact of rounding on the dynamics of complex networks with first - order phase shift ( FPT ) . We see that FPTs can be rounded by added or removing nodes , which results to an increase in the proportion of cooperators at equilibrium .The results are derived for both static and dynamic theories of evolution of cooperation . In particular , we find that the presence of FPTs is required but not sufficient condition for high levels of cooperation .Finally , we propose a simple plan for finding the best possible roundings led to maximal level of partnership . Rounding of initial - order phase transistions and optimal cooperation in scale free networks .P. Krawczyk 1 , A. Szolnoki 2 .1 Institute of Physics, University of Warsaw, Poland; krawczykp@wip.waw.pl .2 Department of Mathematics, University of Warsaw, Warsaw, Poland; aszolnok@wip.waw.pl .In this research we investigate how the presence of first order phase transitions affects the evolution of agreement in social dilemmas . First , we provide two new concepts - the reduced and the maximal cooperative states - which describe the range of values of parameters where cooperation prevails over defection .Then , using these concepts , we prove that any system with first order phase change has its own unique value of parameter relating to the maximum amount of cooperators . Next , we study the question of optimizing cooperation in such systems .To do so , we define the notion of rounding of first order phase transitions , i . e . , changing their shape into smooth paths without affecting the orientation of the point of maximum fraction of cooperators within the period 0 , 1 . Using numerical simulations , we prove that the rounding procedure increases the fraction of cooperators at equilibrium in all observed situations .Finally , we present a technique allowing one to estimate the ideal rounding of given transition transition curve .",
        "ori-fast-z-score": 0.6211495565912797,
        "water-fast-z-score": 6.779471978707304
    },
    {
        "original_text": "We study the fractal dimension of domain walls (DWs) in two dimensional Ising spin glasses with nearest neighbor interactions and random bonds using Monte Carlo simulations at finite temperatures. We find that DWs are fractals for all values of temperature studied here, i.e., T = 0.5J/kB to 1.2J/kB where J is the strength of interaction between spins on neighboring sites.  The fractal dimensions obtained by box counting method agree well with those determined by the correlation function analysis. In addition we show that the fractal dimension decreases as the temperature increases. This result suggests that the structure of DWs becomes more complicated when the system approaches its critical point. Finally it should be noted that our results can also be applied to other systems such as vortex lines in type-II superconductors or dislocation networks in crystals. Two-dimensional Ising spin glasses have been extensively investigated both experimentally  1  and theoretically  2  . It has been shown that these models exhibit many interesting phenomena including phase transitions  3  , spin-glass states  4  , and glassy dynamics  5  .\nIn this work we focus on one particular aspect of the model which is the fractal nature of domain walls  6  . Domain wall refers to an interface separating different ordered phases  7, 8  . For example, in ferromagnetic materials there exist two types of domains; up and down magnetization  9  . These domains are separated by interfaces called domain walls  10  . Similarly, in antiferromagnets  11  , there exists four possible orientations of magnetic moments  12  ; three of them form triangular sublattices while the fourth forms a square lattice  13  . Therefore, there will be six types of domain walls  14  .",
        "watermark_text": "We research the fractal dimension of domain walls ( DWs ) in two dimensional Ising spin glasses with nearest neighbor interactions and random bonds using Monte Carlo simulations at finite temperatures . We see that DWs are fractals for all values of temperature described here , i . e . , T = 0 . 5J / kB to 1 . 2J / kB where J is the strength of coupling between spins on nearby locations .The fractal sizes obtained by box counting method comply better with those determined by the correlation function analysis . In addition we prove that the fractal dimension decreases as the temperature increases .This result suggests that the composition of DWs changes more complicated when the process approaches its critical position . Finally it should be mentioned that our findings can also be applied to other structures such as vortex lines in type - II superconductors or dislocation networks in crystals .Two - dimensional Ising spin glasses have been heavily examined both experimentally 1 and theoretically 2 . It has been shown that these models exhibit several interesting phenomena including phase transitions 3 , spin - glass states 4 , and glassy dynamics 5 .In this research we focus on one special aspect of the model which is the fractal nature of domain barriers 6 . Domain wall refers to an interface separating different ordered phases 7 , 8 .For instance , in ferromagnetic metal there exist two forms of residues ; up and down magnetization 9 . These residues are separated by interfaces called domain barriers 10 .Similarly , in antiferromagnets 11 , there exists four possible orientations of magnetic moments 12 ; three of them form square sublattices while the fifth forms a square lattice 13 . Therefore , there will be six kinds of domain walls 14 .",
        "ori-fast-z-score": 0.9205746178983234,
        "water-fast-z-score": 6.812252172447593
    },
    {
        "original_text": "We present new HST photometric data on halo stars in the nearby elliptical galaxy NGC 3377, obtained with the Wide Field Planetary Camera 2 (WFPC2). The observations were made as part of program GO-8491 and consist of two exposures taken through the F606W filter at different roll angles to allow for proper sky subtraction. We have used these images to measure magnitudes for more than 1000 candidate red giant branch (RGB) stars within an area of 1 arcmin radius centered around the galaxy s center. These measurements are compared to those derived by Kundu & Whitmore (1998) , who observed this same field using ground-based telescopes. Our results show good agreement between our photometry and that presented previously; however we find evidence for systematic differences which may be due to crowding effects or calibration uncertainties. \n \n Keywords: Red Giant Branch, Galaxy, WFPC2",
        "watermark_text": "We report new HST photometric data on halo stars in the nearby elliptical galaxy NGC 3377 , obtained with the Wide Field Planetary Camera 2 ( WFPC2 ) . The images were made as part of series GO - 8491 and consist of two exposures took through the F606W filter at different roll axes to allow for correct sky subtraction .We have utilized these images to measure magnitudes for more than 1000 candidate red giant line ( RGB ) stars within an area of 1 arcmin radius centered around the universe s center . These measurements are compared to those derived by Kundu & Whitmore ( 1998 ) , who studied this same field using ground - based telescopes .Our results show good agreement between our photometry and that presented previously ; however we find proof for systematic differences which may be due to crowding effects or calibration uncertainties . Keywords : Red Giant Branch , Galaxy , WFPC2",
        "ori-fast-z-score": 1.4832396974191326,
        "water-fast-z-score": 4.449719092257398
    },
    {
        "original_text": "We prove that there exists an open set of initial data such that the corresponding solution to the rapidly rotating shallow water (RSW) or Euler equations is globally smooth in space-time, provided it stays sufficiently close to some equilibrium state. The proof relies on a combination of energy estimates with suitable weighted Sobolev inequalities. We also show how our results can be extended to more general systems of conservation laws which are not necessarily strictly hyperbolic. In particular we consider the case where one of the characteristic speeds vanishes at a point but remains bounded away from zero elsewhere. \nIntroduction\n\nThe purpose of this work is twofold. First, we establish global regularity properties for the rapidly rotating shallow water system and its generalization to arbitrary dimension. Second, we provide new insights into the structure of these models by showing how they fit within a larger class of nonlinear dispersive partial differential equations. Our main result reads as follows: \nMain Theorem 1 Let u 0 ∈ H s , s > n/2 + 2, then there exist constants C = C(n), K = K(n) such that if",
        "watermark_text": "We prove that there exists an open set of initial data such that the equivalent solve to the rapidly spinning shallow water ( RSW ) or Euler equations is globally smooth in space - time , provided it remains reasonably close to some equilibrium state . The proof uses on a combination of power estimates with suitable weighted Sobolev inequalities .We additionally understand how our findings can be generalized to more general systems of conservation laws which are not necessarily strictly hyperbolic . In particular we define the case where one of the characteristic velocity vanishes at a place but stayed defined far from zero elsewhere .Introduction The purpose of this study is twofold . First , we obtain global regularity properties for the rapidly spinning shallow water structure and its generalization to arbitrary dimension .Second , we provide fresh insights into the formation of these models by showing how they fit within a greater category of nonlinear dispersive partial differential equations . Our main consequence reads as follows : Main Theorem 1 Let v 0 ∈ H s , s > n / 2 + 2 , then there exist constants C = C ( n ) , K = K ( n ) such that if",
        "ori-fast-z-score": -1.091089451179962,
        "water-fast-z-score": 4.1461399144838555
    },
    {
        "original_text": "We present an analysis of chemical equilibrium and disequilibrium processes occurring in the atmospheres of substellar mass objects (SMBOs). We have developed a new method for calculating departures from chemical equilibrium, which is based on the assumption that all species are in local thermodynamic equilibrium with each other at any given point within the atmosphere. This approach allows us to calculate the abundances of individual molecular species as functions of altitude above the photosphere. The results show that there can be significant deviations from chemical equilibrium even under conditions where the gas temperature is much higher than the dust temperature. In particular, we find that carbon monoxide may become depleted by several orders of magnitude relative to its abundance predicted by chemical equilibrium models. These findings suggest that SMBO observations should take into account possible non-equilibrium effects when interpreting their spectra. \n \n Keywords: Chemical equilibrium; Dust grains; Local thermodynamic equilibrium",
        "watermark_text": "We present an assessment of chemical equilibrium and disequilibrium phenomena occurring in the atmospheres of substellar mass bodies ( SMBOs ) . We have developed a new method for calculating departures from molecular equilibrium , which is based on the assumption that all species are in local thermodynamic equilibrium with each other at any certain point within the atmosphere .This method enables us to estimate the abundances of different molecular species as functions of altitude above the photosphere . The results show that there can be considerable deviations from molecular balance especially under environments where the gas temperature is much higher than the dust temperature .In particular , we find that carbon monoxide might appear depleted by many orders of magnitude compared to its availability predicted by molecular balance models . These studies imply that SMBO observations should take into consideration likely non - equilibrium impacts when interpreting their spectra .Keywords: Chemical equilibrium; Dust grains; Local thermodynamic equilibrium",
        "ori-fast-z-score": -1.3242443839434612,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We present an explicit criterion to determine whether or not two given multipartite quantum states are separable, i.e., can be written as convex combinations of product states. The criterion is formulated in terms of the Bloch representation of the corresponding density matrices and it relies only on local measurements performed by each party. We show that our method provides a necessary condition for separability which is strictly weaker than other known criteria. Finally we illustrate its usefulness with some examples. Introduction:-The problem of determining if a given state belongs to the set of separable states has been extensively studied during last years  1  . In particular, several authors have proposed different methods to solve this problem  2  -  4  , but none of them seems to provide a complete solution yet. Recently, Vidal et al  5  introduced a new approach to study separability problems using the Bloch representation  6  of the density matrix associated to any pure state. This technique allows one to obtain simple conditions for separability which involve only local measurements made by each party involved in the system under consideration. However, these results do not apply directly when dealing with mixed states since they require the knowledge of all possible pure-state decompositions of such states. Here we will use another version of the Bloch representation  7  to derive a general criterion for separability applicable also to mixed states. Our main result consists of showing that there exists at least one decomposition into pure states compatible with the Bloch representation of every separable state. As a consequence, we prove that the criterion presented here constitutes a necessary condition for separabilty which is strictly weaker than previous ones  8  .\nPreliminaries:-In what follows we consider N-partite systems described by Hilbert spaces H 1 ,H 2 ...H N . A generic element |ψ⟩ ∈ H = ∑ N i=1 H i is called a pure state vector while ρ ∈ D(H) denotes a density operator acting on H. Any density operator can always be expressed in terms of its spectral decomposition  9  \nwhere {|λ⟩} λ=1,...,d is an orthonormal basis of eigenvectors of ρ and p λ ≥ 0 (p",
        "watermark_text": "We present an explicit criterion to measure whether or not two given multipartite quantum states are separable , i . e . , can be written as convex combinations of product states . The requirement is formulated in terms of the Bloch representation of the resulting density matrices and it rely only on local observations performed by each party .We see that our system provides a necessary condition for separability which is strictly weaker than other established parameters . Finally we explain its usefulness with some examples .Introduction : - The question of determining if a given state belongs to the group of separable states has been heavily examined during last years 1 . In particular , various papers have proposed different methods to treat this question 2 - 4 , but none of them appears to provide a complete solved yet .Recently , Vidal et al 5 invented a new approach to study separability phenomena using the Bloch representation 6 of the density graph identified to any pure state . This method enables one to obtain simple conditions for separability which require only local observations made by each party involved in the scheme under consideration .However , these results do not apply directly when dealing with mixed states since they demand the knowledge of all possible pure - state decompositions of such states . Here we will use another version of the Bloch representation 7 to derive a general criterion for separability applied also to mixing states .Our main consequence consists of finding that there exists at least one decomposition into pure states compatible with the Bloch representation of every separable state . As a consequence , we prove that the criterion presented here constitutes a necessary condition for separabilty which is strictly weaker than prior ones 8 .Preliminaries : - In what follows we define N - partite structures described by Hilbert spaces H 1 , H 2 . . . H N . A generic element | ψ ⟩ ∈ H = [UNK] N i = 1 H i is called a pure state vector while ρ ∈ D ( H ) denotes a density operator acting on H . Any density operator can always be stated in terms of its spectral transformation 9 where { | λ ⟩ } λ = 1 , . . . , d is an orthonormal basis of eigenvectors of ρ and p λ ≥ 0 ( p",
        "ori-fast-z-score": 1.5713484026367723,
        "water-fast-z-score": 7.496340570653091
    },
    {
        "original_text": "We present the first exact local solution to the equations of motion for type II B supergravity in AdS 5 × S 5 . The solution is supported by two independent harmonic functions, one on each side of an arbitrary surface Σ which divides space into three regions. We show that this solution preserves eight real supercharges and has vanishing central charge. It can be interpreted as a bound state of N = 4 SYM theory with gauge group SU(N)×SU(N), where the number of degrees of freedom scales like O(N 2 ) at large N. In addition we find a new class of solutions describing interfaces between different vacua of the same field theory. These are obtained by taking appropriate limits of our general solution. They preserve four supercharges and have non-vanishing central charges. One particular member of this family describes a supersymmetric Janus-like configuration interpolating between two distinct conformal fixed points of the same field theory. \nIntroduction\n\nThe study of holographic duals of strongly coupled quantum systems has been greatly advanced over recent years through the use of string/M-theory  1, 2  . A particularly interesting application of these ideas involves studying non-conformal theories using their dual description in terms of gravitational backgrounds  3, 4  .\nIn order to construct such models it is necessary to solve the equations of motion associated with the relevant supergravity or gauged supergravity theory. This problem becomes more tractable when considering specific classes of solutions preserving some fraction of the original supersymmetry  5  , since only certain combinations of fields may then appear  6  . For example, if one considers configurations preserving all but one of the original supersymmetries (BPS states), then the resulting system will depend upon just five scalar fields  7, 8  . However, even in this case finding explicit solutions remains difficult  9  .\nOne approach to solving BPS-type problems is to consider special cases where the geometry admits additional symmetries  10  . An important subclass of such solutions arises when the internal manifold M 6 factorises into a product of two spaces M 3 × M 3  11  . In this",
        "watermark_text": "We introduce the first accurate local solution to the coefficients of movement for type II B supergravity in AdS 5 × S 5 . The solving is supported by two independent harmonic functions , one on each side of an arbitrary surface Σ which splits space into three areas .We see that this solution preserves eight real supercharges and has vanishing central charge . It can be interpreted as a bound state of N = 4 SYM theory with gauge group SU ( N ) ×SU ( N ) , where the number of degrees of freedom scales like O ( N 2 ) at large N . In addition we find a new category of solutions describing interfaces between various vacua of the same field theory .These are derived by giving suitable limits of our general solution . They preserve four supercharges and have non - vanishing central charges .One particular part of this class describes a supersymmetric Janus - like configuration interpolating between two separate conformal fixed points of the same field theory . Introduction The investigation of holographic duals of highly coupled quantum systems has been greatly expanded over recent years through the using of string / M - theory 1 , 2 .A notably important use of these ideas includes studying non - conformal models using their dual description in terms of gravitational backgrounds 3 , 4 . In order to build such theories it is required to solve the equations of movement associated with the appropriate supergravity or gauged supergravity models .This problem arises more tractable when examining specific groups of solutions maintaining some fraction of the original supersymmetry 5 , since only certain combinations of fields may then appear 6 . For instance , if one looks configurations preserving all but one of the original supersymmetries ( BPS states ) , then the resulting system will depend upon just five scalar fields 7 , 8 .However , even in this instance finding explicit solved remains challenging 9 . One approach to solving BPS - class problems is to consider special cases where the topology admits extra symmetries 10 .An key subclass of such solutions arises when the internal manifold M 6 factorises into a product of two spaces M 3 × M 3 11 . In this",
        "ori-fast-z-score": -0.48989794855663565,
        "water-fast-z-score": 7.568232666571783
    },
    {
        "original_text": "We show that correlation clustering is NP-hard to approximate within any constant factor, even for graphs with maximum degree three and clusters of size at most four.  We also present an algorithm which solves this problem exactly in time O(n3). Our results are based on reductions from the exact cover by 3-sets (X3C) problem. The X3C problem asks whether there exists a collection of subsets of a set S such that each element of S belongs to exactly 3 sets in the collection; it has been shown to be NP-complete. For more information about our work see http://arxiv.org/abs/1206.0571 . \nCorrelation clustering is one of several problems studied under the umbrella of  clustering ; these include k-means clustering, spectral clustering, and graph partitioning. It was introduced independently by Bansal et al., Blum et al., and Dasgupta et al. as follows.   Given a weighted undirected graph G = (V, E), where V denotes the vertices and E denotes the edges, we say that two vertices u, v ∈ V are adjacent if they share an edge e ∈ E. A cluster C ⊆ V is defined as a subset of nodes whose pairwise distances satisfy some threshold t > 0. More formally, given a distance function d : V × V → R+ , let dist(u,v) denote the shortest path between u and v; then, C is said to be a valid cluster if and only if for all pairs of nodes u, v ∈ C:  dist(u,v)  ≤ t",
        "watermark_text": "We see that correlation clustering is NP - hard to approximate within any constant factor , even for graphs with maximum degree three and clusters of diameter at most four . We also demonstrate an algorithm which solves this situation exactly in time O ( n3 ) .Our results are based on reductions from the exact cover by 3 - sets ( X3C ) question . The X3C problem questions whether there exists a family of subsets of a space S such that each element of S belongs to exactly 3 sets in the collection ; it has been shown to be NP - full .For more information about our work see http : / / arxiv . org / abs / 1206 . 0571 . Correlation clustering is one of several problems studied under the umbrella of clustering ; these include k - means clustering , spectral clustering , and graph partitioning .It was introduced independently by Bansal et al . , Blum et al . , and Dasgupta et al . as follows .Given a weighted undirected graph G = ( V , E ) , where V denotes the edges and E denotes the edges , we write that two vertices u , v ∈ V are adjoining if they share an vertex e ∈ E . A cluster C ⊆ V is characterized as a subset of vertices whose pairwise distances satisfy some threshold t > 0 . More generally , given a distance relation d : V × V → R + , let dist ( v , v ) define the longest route between u and v ; then , C is said to be a valid cluster if and only if for all pairs of vertices u , v ∈ C : dist ( v , v ) ≤ t",
        "ori-fast-z-score": -1.0945409092309881,
        "water-fast-z-score": 3.482630165734962
    },
    {
        "original_text": "We present the results of our analysis of high-resolution optical spectra obtained with HST/STIS for four nearby (z<0.1), X-ray selected, Type Ib/c SNe in order to study their progenitor systems. We find that all four objects show evidence for dense CSM surrounding them at distances ranging between 0.01-0.2 pc. The presence of such material is consistent with theoretical expectations for post-low-velocity-bulge (post-LBV) Wolf-Rayet star winds. In addition we detect narrow emission features which are likely due to interaction between SN ejecta and this wind. These observations provide strong constraints on the nature of the progenitor systems: they require massive WR stars as well as binary companions capable of producing significant mass loss prior to explosion. This work was supported by NASA grant NAG5-10842. We have analyzed high resolution STIS/HST data for 4 nearby (z<0.1; Xray-selected) type Ibc supernovae in an attempt to determine the properties of their progenitor systems. All four objects exhibit dense circumstellar matter (CSM; nH>1020 cm-3 ) within 0.01-0.20 parsecs of the supernova site. Such densities are expected if these explosions occur following the ejection of a low velocity  bulge  during late stages of stellar evolution. Furthermore, we observe narrow emission features which may be associated with shock-heating of the CSM by the expanding supernova remnant. Our findings suggest that these events result from the deaths of massive Wolf Rayet stars surrounded by close binaries.",
        "watermark_text": "We present the conclusion of our analysis of high - resolution optical spectra obtained with HST / STIS for four nearby ( z < 0 . 1 ) , X - ray selected , Type Ib / c SNe in order to study their progenitor structures . We see that all four bodies exhibit indication for thick CSM circling them at distances ranging between 0 . 01 - 0 . 2 pc .The presence of such material is compatible with theoretical expectations for post - low - speed - bulge ( post - LBV ) Wolf - Rayet star winds . In addition we find narrow radiation properties which are likely due to contact between SN ejecta and this wind .These measurements give strong restrictions on the nature of the progenitor structures : they use massive WR galaxies as well as binary companions capable of producing significant mass loss prior to explosion . This research was supported by NASA gift NAG5 - 10842 .We have analyzed high resolution STIS / HST results for 4 nearby ( z < 0 . 1 ; Xray - selected ) type Ibc supernovae in an trying to estimate the properties of their progenitor structures . All four bodies exhibit thick circumstellar matter ( CSM ; nH > 1020 cm - 3 ) within 0 . 01 - 0 . 20 parsecs of the supernova center .Such densities are expected if these fires occur following the ejection of a small velocity bulge during late stages of stars evolution . Furthermore , we study narrow radiation properties which may be involved with shock - heating of the CSM by the evolving supernova remnant .Our findings show that these changes result from the deaths of large Wolf Rayet stars surrounded by tight binaries .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.807983207583857
    },
    {
        "original_text": "We study the generalized Dicke model with an arbitrary number N of two-level atoms interacting with one-mode radiation field, and show that it can be mapped to a spin-1/2 system by using the Holstein-Primakoff transformation. We then use the exact diagonalization method to calculate its ground state energy spectrum for different values of the coupling constant g and the number N . The results are compared with those obtained by other methods such as perturbation theory and numerical integration. It is found that our results agree well with previous ones when the coupling strength is small but deviate significantly from them if the coupling becomes strong. Finally we discuss some possible applications of this work. PACS: 03.65.Ud, 05.45.Mt, 11.10.Gh, 12.20.Dc, 13.25.Gv \nI. INTRODUCTIO N\nThe Dicke model  1  describes how many identical two-level atoms interact collectively with a single mode of electromagnetic field. In recent years there has been renewed interest in studying this model because of its potential application in quantum information processing  2  , quantum optics  3  , condensed matter physics  4  , etc.. For example, the collective spontaneous emission rate of the atomic ensemble depends on the total angular momentum J = N /2 (N being the number of atoms)  5  .\nIn fact, the Dicke model was originally proposed more than half century ago  6  . Since then various theoretical approaches have been developed to solve it  7 -10  . Among these approaches, the most successful one is probably the so-called HolsteinPrimakoff transformation  11  which maps the original problem into a spin-1/2 system  12  . This approach works very well at weak-coupling regime where the interaction between atom-field is relatively small. However, it fails completely at large-coupling limit since the mapping procedure breaks down due to the appearance of unphysical states  13  . Recently, several authors  14 -19  have tried to overcome this difficulty by introducing new transformations or approximations. Nevertheless, their solutions still suffer from certain drawbacks  20, 21  .",
        "watermark_text": "We explore the generalized Dicke model with an arbitrary number N of two - level atoms interacting with one - mode radiation field , and find that it can be mapped to a spin - 1 / 2 system by using the Holstein - Primakoff transformation . We then use the exact diagonalization technique to estimate its ground state energy spectrum for different values of the interaction factor g and the number N .The results are compared with those achieved by other methods such as perturbation theory and numerical integration . It is found that our findings agree well with previous ones when the interaction strength is tiny but deviate drastically from them if the interaction becomes strong .Finally we explain some possible use of this study . PACS : 03 . 65 . Ud , 05 . 45 . Mt , 11 . 10 . Gh , 12 . 20 . Dc , 13 . 25 . Gv I . INTRODUCTIO N The Dicke model 1 explains how many identical two - level atoms behave collectively with a single mode of electromagnetic field .In recent years there has been continued interest in investigating this model because of its potential application in quantum information processing 2 , quantum optics 3 , condensed matter science 4 , etc . . For instance , the collective spontaneous emission speed of the atomic ensemble depends on the total angular velocity J = N / 2 ( N being the number of atoms ) 5 . In reality , the Dicke concept was originally proposed more than quarter century ago 6 .Since then various theoretical methods have been constructed to solve it 7 - 10 . Among these method , the most popular one is probably the so - called HolsteinPrimakoff transformation 11 which maps the original problem into a spin - 1 / 2 system 12 .This method works very best at weak - interaction regime where the interaction between electron - field is fairly little . However , it fails totally at large - interaction range since the mapping method splits down due to the appearance of unphysical states 13 .Recently , various literature 14 - 19 have tried to overcome this challenge by using new transformations or approximations . Nevertheless , their solutions still suffer from certain drawbacks 20 , 21 .",
        "ori-fast-z-score": -0.16222142113076254,
        "water-fast-z-score": 6.8132996874920275
    },
    {
        "original_text": "We consider the problem of estimating an unknown function f from noisy measurements y = Af + w, where A is a linear operator and w is white noise with known covariance matrix Cw.  We assume that the operator A has been discretized on some grid (e.g., by using finite differences or spectral methods) so that it can be represented as a large matrix.  The goal is to find an estimatef such that Ef − f  2 is minimized subject to certain constraints on the smoothness off . \nIn this work we propose new numerical techniques based on needlets which are able to efficiently solve these constrained optimization problems.  In particular, our approach allows us to obtain accurate estimates even when the number N of available observations is much smaller than the dimension M of the space spanned by the columns of A. \nThe proposed method relies on two main ingredients:  First, we use a sparse representation of functions in terms of needlets.  Second, we develop efficient iterative algorithms for solving large-scale convex optimization problems involving sparsity-promoting regularizers.  These algorithms combine ideas from compressed sensing theory and recent results about the convergence rate of alternating direction method of multipliers (ADMM).",
        "watermark_text": "We consider the question of estimating an unknown function f from noisy measurements y = Af + f , where A is a linear operator and f is white sound with known covariance matrix Cw . We assume that the operator A has been discretized on some grid ( e . g . , by using finite differences or spectral algorithms ) so that it can be described as a large vector .The goal is to find an estimatef such that Ef − f 2 is minimized subject to specified constraints on the smoothness off . In this study we develop new numerical tactics based on needlets which are able to easily solution these constrained optimization problems .In particular , our approach allows us to obtain precise estimates even when the number N of available observed is much smaller than the dimension M of the space spanned by the rows of A . The proposed approach consists on two principal ingredients : First , we utilize a sparse representation of functions in terms of needlets .Second , we develop optimal iterative techniques for solving large - scale convex optimization problems concerning sparsity - promoting regularizers . These methods combine developments from compressed sensing theory and recent results about the convergence speed of alternating path method of multipliers ( ADMM ) .",
        "ori-fast-z-score": 0.9233805168766388,
        "water-fast-z-score": 6.807380225308036
    },
    {
        "original_text": "We present new results on the contribution of BL Lacs (blazars) to the extragalactic gamma-ray background based on data collected by the Fermi Large Area Telescope between August 2008 and December 2010, corresponding to an effective exposure time of 1.6 yr for each source in our sample. We use two different methods to estimate this contribution: i) we calculate the number counts above 100 MeV as function of redshift using a maximum likelihood method; ii) we fit the observed spectral energy distribution with a log-parabola model and derive the integrated fluxes at 0.1 GeV and 10 TeV energies. The resulting contributions are consistent within statistical uncertainties. Our best-fit value is F(>100 MeV) = 2.2 x 10^{−8} ph cm−2 s−1 sr−1 which corresponds to ~20% of the measured EGB intensity. This result confirms that blazars are one of the main contributors to the EGB emission.",
        "watermark_text": "We report new data on the contribution of BL Lacs ( blazars ) to the extragalactic gamma - ray background based on evidence generated by the Fermi Large Area Telescope between August 2008 and December 2010 , corresponding to an effective exposure time of 1 . 6 yr for each source in our sample . We use two different methods to estimate this contribution : i ) we determine the number counts above 100 MeV as function of redshift using a maximum likelihood technique ; ii ) we fit the observed spectral power distribution with a log - parabola simulation and derive the integrated fluxes at 0 . 1 GeV and 10 TeV energies .The resulting contributions are compatible within statistical uncertainties . Our best - fitting value is F ( > 100 MeV ) = 2 . 2 x 10 ^ { −8 } ph cm−2 s−1 sr−1 which equals to ~ 20 % of the measured EGB brightness .This result confirms that blazars are one of the main contributors to the EGB emission .",
        "ori-fast-z-score": -0.40451991747794525,
        "water-fast-z-score": 2.8316394223456167
    },
    {
        "original_text": "We consider the statistical properties of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions, power spectra, and probability density functions (PDFs). We show that these quantities can be expressed by means of solutions to certain partial differential equations with time-dependent coefficients. The PDFs are obtained for both stationary and nonstationary cases using the method of characteristics. In particular, we derive an exact expression for the PDF of the amplitude fluctuations of a monochromatic plane wave propagating through a turbulent medium. This result is used to obtain expressions for the mean-square fluctuation levels of the electric field strength and intensity at any point along the propagation path. Finally, we discuss some applications of our results to radiowave scintillation theory and radar detection problems. PACS: 42.65.Tg, 43.20 .Fx, 47.55.+q, 47.60.+j",
        "watermark_text": "We consider the statistical characteristics of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions , power spectra , and likelihood density functions ( PDFs ) . We see that these quantities can be described by means of solutions to many partial differential coefficients with time - dependent coefficients .The PDFs are derived for both static and nonstationary cases using the method of characteristics . In particular , we derive an precise representation for the PDF of the amplitude fluctuations of a monochromatic plane beam propagating through a turbulent medium .This result is utilized to obtain definitions for the mean - square fluctuation concentrations of the electric field intensity and intensity at any point along the propagation path . Finally , we explain some applications of our findings to radiowave scintillation physics and radar detection difficulties .PACS : 42 . 65 . Tg , 43 . 20 . Fx , 47 . 55 . + q , 47 . 60 . + j",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.417490779798923
    },
    {
        "original_text": "We present the spectroscopic follow-up observations for eight galaxy clusters at redshifts z=0.6-0.9 selected in the Red-Sequence Cluster Survey (RCS). The sample is composed by four X-ray luminous and four optically rich clusters, with masses ranging between M500 = 1.5 × 1014 - 2.7 × 1014 h70M⊙ . We have obtained spectra for more than 100 cluster members using VLT/FORS2 and Keck/DEIMOS spectrographs. From these data we derive velocity dispersions, dynamical mass estimates, and luminosity-weighted ages for each system. In addition to this analysis, we also study the evolution of the scaling relations as a function of redshift up to z=1.1. Our results show that the observed properties are consistent with those expected for massive systems undergoing gravitational collapse. However, there seems to be an offset towards lower values of σv /σ⋆ compared to predictions based on numerical simulations.",
        "watermark_text": "We present the spectroscopic follow - up observations for eight galaxy regions at redshifts z = 0 . 6 - 0 . 9 selected in the Red - Sequence Cluster Survey ( RCS ) . The sample is composed by four X - ray luminous and four optically abundant clusters , with masses vary between M500 = 1 . 5 × 1014 - 2 . 7 × 1014 [UNK] .We have derive spectra for more than 100 cluster elements using VLT / FORS2 and Keck / DEIMOS spectrographs . From these information we derive velocity dispersions , dynamical mass estimates , and luminosity - weighted ages for each system .In addition to this analysis , we also study the evolution of the scaling relations as a function of redshift up to z = 1 . 1 . Our results show that the seen characteristics are compatible with those expected for huge systems undergoing gravitational failure .However , there seems to be an offset towards decreased values of σv / [UNK] compared to measurements based on numerical simulations .",
        "ori-fast-z-score": 1.3363062095621219,
        "water-fast-z-score": 4.370956778314644
    },
    {
        "original_text": "We present new Chandra X-ray Observatory observations and optical spectroscopy for the galaxy cluster Abell 576, which is known to have two merging components separated by about 1 arcmin (about 700 kpc). The northern component has been previously studied as an example of a  line-of-sight bullet cluster ; it shows no evidence of significant substructure or shock heating along its line of sight but does show signs of recent merger activity on smaller scales. In contrast, we find that the southern component appears relaxed with little sign of disturbance; however, this may be due to projection effects since there are several galaxies at large projected distances from the center of the cluster whose redshifts indicate they lie behind the cluster core. We also detect diffuse emission extending beyond the virial radius of both clusters, possibly indicating ongoing accretion onto these systems. These results suggest that Abell 576 will evolve into a single massive system within a few Gyrs.",
        "watermark_text": "We present new Chandra X - ray Observatory surveys and imaging spectroscopy for the galaxy region Abell 576 , which is known to have two combining components split by about 1 arcmin ( about 700 kpc ) . The northern component has been previously examined as an instance of a line - of - view bullet cluster ; it displays no evidence of significant substructure or shock heating along its line of vision but does display signs of recent collision activity on smaller scales .In contrast , we find that the southern component appears relaxed with little sign of disruption ; however , this might be due to projection influences since there are several stars at large projected distances from the hub of the cluster whose redshifts indicate they exist behind the cluster core . We additionally observe diffuse emission stretching beyond the virial diameter of both clusters , possibly indicating continued accretion onto these systems .These data suggest that Abell 576 will evolve into a single giant body within a few Gyrs .",
        "ori-fast-z-score": -1.2701705922171767,
        "water-fast-z-score": 5.196152422706631
    },
    {
        "original_text": "We present an approach to modeling epidemic spread using synthetic populations generated by massively multiplayer online games (MMOGs). We use the population and mobility data collected for the City of Heroes MMOG, which has been played continuously since 2003 with over one million registered players worldwide. The game s persistent world is divided into regions that are connected via player movement between them. Each region contains a large number of individual households containing up to several hundred characters each. Our model uses this household-level information along with character-to-character contact rates inferred from the observed movements within the game to simulate disease transmission at both regional and global scales. We compare our results against epidemiological models based on real-world census data and find good agreement when we scale down the size of the simulated population appropriately. This suggests that large-scale virtual worlds such as MMOGs can be used to study epidemics without requiring access to sensitive personal health records or detailed demographic data.",
        "watermark_text": "We create an way to modeling disease spread using synthetic populations generated by massively multiplayer online games ( MMOGs ) . We use the population and connectivity data accumulated for the City of Heroes MMOG , which has been played continuously since 2003 with over one million registered participants globally .The player s persistent world is separated into regions that are connected via character movement between them . Each area contains a large number of individual families representing up to several hundred characters each .Our model takes this household - level data along with character - to - character connection rates inferred from the reported shifts within the gameplay to simulate illness transmission at both regional and international scales . We contrast our findings against epidemiological models using on real - time census data and find good agreement when we scale down the size of the imagined population appropriately .This implies that wide - scale virtual spaces such as MMOGs can be used to study epidemics without requiring access to accurate individual medical documents or accurate demographic statistics .",
        "ori-fast-z-score": 0.21320071635561041,
        "water-fast-z-score": 7.035623639735144
    },
    {
        "original_text": "We study shelling-type orderings on regular cell complexes, which are defined by an ordering of their cells such that each new face is attached to exactly one old face in its boundary. We show how these can be used to construct acyclic matchings for the Salvetti complex associated with any finite Coxeter group W . This yields a combinatorial proof of the fact that the Poincaré polynomial of this complex satisfies P(t) = (1 − t)(1 + w∈W t l(w) ), where l denotes the length function on W .\nThe results presented here were obtained during my PhD thesis at ETH Zurich under the supervision of Prof. Dr. Jürg Stadler. I would like to thank him as well as Prof. Dr. Peter Schmitt for many helpful discussions. The research leading to these results has received funding from the European Research Council under the European Union s Seventh Framework Programme (FP/2007-2013 Grant Agreement n o 325928).",
        "watermark_text": "We research shelling - class orderings on regular cell complexes , which are established by an ordering of their cells such that each new side is attached to exactly one old face in its boundary . We see how these can be used to build acyclic matchings for the Salvetti complex associated with any finite Coxeter class W .This yields a combinatorial proving of the fact that the Poincaré polynomial of this complex satisfies P ( t ) = ( 1 − t ) ( 1 + w∈W t l ( v ) ) , where l represents the length function on W . The results presented here were obtained during my PhD thesis at ETH Zurich under the guidance of Prof . Dr . Jürg Stadler .I would like to thank him as also as Prof . Dr . Peter Schmitt for numerous helpful talks . The studies leading to these results has obtained support from the European Research Council under the European Union s Seventh Framework Programme ( FP / 2007 - 2013 Grant Agreement n o 325928 ) .",
        "ori-fast-z-score": 0.42008402520840293,
        "water-fast-z-score": 5.181036310903636
    },
    {
        "original_text": "We study the dynamics and emission properties of advection dominated accretion flows (ADAFs) in which viscosity is caused by magnetic reconnections between field lines anchored to differentially rotating black holes. We find that, for reasonable values of parameters, such ADAFs can produce luminosities as high as those observed in quasars without violating any observational constraints on their mass inflow rates or temperatures at large radii. The main reason why our model works well is because it naturally produces an outflowing wind component whose kinetic energy flux greatly exceeds its thermal energy flux. This wind carries away most of the angular momentum so that the flow becomes nearly Keplerian near the black hole horizon. In addition, we show that this wind also provides enough pressure support against gravity to prevent the gas density from becoming too low there. Our results suggest that the winds produced by magnetized ADAF models may be responsible for driving powerful radio jets in active galactic nuclei.",
        "watermark_text": "We research the dynamics and emission behavior of advection dominated accretion currents ( ADAFs ) in which viscosity is caused by magnetic reconnections between field lines anchored to differentially rotating black holes . We see that , for reasonable values of parameters , such ADAFs can generate luminosities as great as those observed in quasars without violating any observational restrictions on their mass inflow rates or temperatures at large radii .The main explanation why our model works well is because it naturally produces an outflowing breeze component whose kinetic power flux considerably exceeds its thermal energy flux . This wind carries away most of the angular velocity so that the flow turns almost Keplerian near the dark hole horizon .In addition , we indicate that this wind additionally offers enough pressure support against gravity to prohibit the gas density from getting too low there . Our results propose that the storms produced by magnetized ADAF machines could be responsible for driving strong radio jets in active galactic nuclei .",
        "ori-fast-z-score": 0.22086305214969307,
        "water-fast-z-score": 5.521576303742327
    },
    {
        "original_text": "The book is intended for students who have completed the first year course in control theory and are interested to learn more about discrete-time systems, digital controllers and computer-based control techniques. The text covers topics such as state space representation, stability analysis, optimal control design, robustness issues, model predictive control (MPC), fuzzy logic based control etc., with an emphasis on practical applications. It also includes several examples that illustrate key concepts discussed throughout the chapters. \n \n This textbook provides a comprehensive coverage of basic principles underlying various aspects of modern control engineering. In addition to theoretical foundations, it presents numerous numerical examples illustrating important concepts introduced along the way. A number of exercises at the end of each chapter help readers reinforce their understanding of material presented earlier. Finally, there are two appendices containing additional information useful for further study or research work. \nThis book can be used by graduate students studying advanced courses in control theory, as well as researchers working in this area.",
        "watermark_text": "The text is intended for students who have completed the first year course in control theory and are concerned to teach more about discrete - time systems , digital controllers and computer - based control methods . The text encompasses topics such as state space representation , stability analysis , ideal control design , robustness issues , model predictive control ( MPC ) , fuzzy logic based control etc . , with an emphasis on technical applications .It additionally contains several examples that highlight key concepts discussed throughout the pages . This treatise provides a comprehensive treatment of fundamental principles governing several elements of modern control engineering .In addition to theoretical foundations , it presents several mathematical models illustrating major concepts adopted along the way . A variety of tests at the end of each volume help viewers reinforce their understanding of content presented earlier .Finally , there are two appendices containing extra data helpful for further study or research studies . This book can be used by graduate candidates pursuing advanced degrees in control theory , as well as scientists studying in this area .",
        "ori-fast-z-score": 0.4879500364742666,
        "water-fast-z-score": 6.993258208972302
    },
    {
        "original_text": "We study the effect of Rashba spin-orbit interaction on the spin Hall conductivity (SHC) for an interacting two-dimensional electron system with parabolic dispersion and Zeeman splitting in presence of a uniform external magnetic field applied normal to the plane of motion. We show that SHC is independent of temperature, chemical potential and strength of disorder provided the Fermi energy lies within the Zeeman gap. The results are obtained by using the Kubo formula combined with the self-consistent Born approximation. It has been shown recently that the spin current can be generated without any net charge flow when electrons move through a nonmagnetic material under the influence of spin-orbit coupling  1  . This phenomenon known as spin Hall effect was first predicted theoretically  2  , and later observed experimentally  3  .\nThe origin of this effect is due to the fact that the spin-orbit interaction causes a transverse force which deflects the trajectories of moving particles leading to a finite spin polarization at the edges  4  . In recent years there have been several theoretical studies devoted to understand various aspects of spin Hall effect  5  -  8  . However most of these works were done either in absence or weak magnetic fields where the Landau levels do not play significant role  9  . On the other hand it is well known that the Landau level quantization plays important role in determining many physical properties such as magnetoresistance  10  , optical absorption  11  etc., especially near the quantum limit  12  . Therefore it would be interesting to investigate how the Landau levels affect the spin Hall effect.",
        "watermark_text": "We explore the impact of Rashba spin - orbit interaction on the spin Hall conductivity ( SHC ) for an interacting two - dimensional electron structure with parabolic dispersion and Zeeman splitting in presence of a consistent external magnetic current applied normal to the plane of movement . We see that SHC is independent of temperature , chemical potential and strength of disorder provided the Fermi energy rests within the Zeeman gap .The results are derived by using the Kubo formula coupled with the self - stable Born algorithm . It has been shown lately that the spin current can be formed without any gross charge flow when nuclei move through a nonmagnetic material under the effects of spin - orbit bonding 1 .This phenomenon known as spin Hall phenomenon was first expected theoretically 2 , and later observed experimentally 3 . The origin of this effect is due to the fact that the spin - orbit interaction produces a transverse force which deflects the trajectories of moving particles leading to a finite spin polarization at the edges 4 .In past decades there have been numerous conceptual research devoted to study various parts of spin Hall phenomenon 5 - 8 . However most of these works were done either in absence or strong magnetic fields where the Landau concentrations do not play substantial role 9 .On the other hand it is well established that the Landau level quantization takes key importance in establishing much mechanical parameters such as magnetoresistance 10 , optical reflection 11 etc . , particularly near the quantum limit 12 . Therefore it would be interesting to examine how the Landau concentrations influenced the spin Hall phenomenon .",
        "ori-fast-z-score": -0.2683281572999747,
        "water-fast-z-score": 7.723027987151322
    },
    {
        "original_text": "We study the ground state properties of frustrated spin-1/2 Heisenberg models on square lattices with different types of interlayer couplings, including both homogeneous and inhomogeneous ones. We show that frustration can be suppressed by introducing an additional ferromagnetic coupling between layers which leads to formation of inhomogeneous magnetic states characterized by spatially modulated magnetization profiles. The obtained results are discussed within the framework of the recently developed concept of ``inverse condensation  . Introduction: In recent years there has been growing interest in studying strongly correlated systems where competing interactions lead to complex phase diagrams exhibiting various exotic phases such as valence bond solids (VBS), charge density waves (CDW) or supersolids  1-3 . One of the most interesting examples is provided by layered quantum antiferromagnets  4  . These compounds consist of weakly coupled planes of spins arranged into a regular lattice structure. Due to strong geometrical frustration caused by competing nearest-neighbor exchange interactions J1 along the chain direction and J2 across the chains, these materials exhibit a rich variety of physical phenomena ranging from conventional Néel order at low temperatures down to disordered paramagnetic phases  5  .\nIn this work we consider two prototypical representatives of this class of materials: CuGeO3  6  , where each plane consists of edge-sharing tetrahedra forming a honeycomb-like network  7, 8  , and BaCo2As2  9  , where the planes are made up of corner-sharing triangles  10  . Both compounds have attracted considerable attention due to their unusual magnetic behavior  11, 12  . For example, it was shown experimentally that in CuGeO3 the system undergoes a transition from a collinear antiferromagnetically ordered state below TN = 29 K to a non-collinear VBS state above T* ~ 70 K  13  . On the other hand, for BaCo2As2 the situation seems more complicated since several experimental studies suggest coexistence of three different magnetic phases  14, 15  : a commensurate antiferromagnetically ordered phase below TC = 38 K; a helimagnetic",
        "watermark_text": "We research the ground state properties of frustrated spin - 1 / 2 Heisenberg machines on square lattices with various types of interlayer couplings , including both homogeneous and inhomogeneous ones . We see that frustration can be suppressed by creating an additional ferromagnetic coupling between sheets which results to formation of inhomogeneous magnetic states characterized by spatially modulated magnetization profiles .The achieved findings are discussed within the framework of the recently established concept of ` ` inverse condensation . Introduction : In recent years there has been growing interest in investigating strongly interacting systems where competing interactions result to complex phase diagrams displaying various exotic phases such as valence bond solids ( VBS ) , charge density radiation ( CDW ) or supersolids 1 - 3 .One of the most important examples is provided by layered quantum antiferromagnets 4 . These compounds comprise of mildly coupled planes of spins arranged into a regular lattice structure .Due to heavy geometrical problems caused by differing nearest - neighbor exchange interactions J1 along the chain direction and J2 across the chains , these structures exhibit a rich range of physical phenomena ranging from standard Néel order at low temperatures down to disordered paramagnetic phases 5 . In this research we consider two prototypical representatives of this class of substances : CuGeO3 6 , where each plane consists of edge - sharing tetrahedra making a honeycomb - like network 7 , 8 , and BaCo2As2 9 , where the planes are making up of spot - sharing triangles 10 .Both compounds have garnered considerable scrutiny due to their extraordinary magnetic behavior 11 , 12 . For instance , it was shown experimentally that in CuGeO3 the system undergoes a shift from a collinear antiferromagnetically ordered state below TN = 29 K to a non - collinear VBS state above T * ~ 70 K 13 .On the other hand , for BaCo2As2 the situation appears more complicated since several experimental studies confirm coexistence of three different magnetic modes 14 , 15 : a commensurate antiferromagnetically ordered phase below TC = 38 K ; a helimagnetic",
        "ori-fast-z-score": 0.0854357657716761,
        "water-fast-z-score": 6.920297027505764
    },
    {
        "original_text": "We present Spitzer Space Telescope observations in the mid- to far-infrared (5.8 - 160 microns) for a sample of distant galaxies selected by their rest-frame ultraviolet luminosity density at 1600 angstroms, and compare these flux densities with those predicted using models that include dust extinction.  We find that the observed infrared emission is generally higher than expected based on the UV continuum slope alone; this excess emission can be explained if there are significant amounts of cold dust associated with star formation activity in these systems.   The results suggest that the majority of the energy produced by young stars may not escape into intergalactic space but instead is reprocessed by interstellar dust grains before being re-radiated in the infrared. This work was supported by NASA through grants NAG5-9998 and NAS8-38252 issued by JPL/Caltech under contract NAS8-39073. It has been assigned the following DOI: 10.1086/505283",
        "watermark_text": "We use Spitzer Space Telescope observations in the mid - to far - infrared ( 5 . 8 - 160 microns ) for a sample of distant galaxies determined by their rest - frame ultraviolet luminosity abundance at 1600 angstroms , and compare these flux densities with those predicted using models that include cloud extinction . We see that the seen infrared absorption is typically higher than expected based on the UV continuum curve alone ; this excess emission can be understood if there are significant amounts of cold powder associated with star formation activity in these systems .The results show that the majority of the power emitted by young galaxies may not escape into intergalactic space but instead is reprocessed by interstellar dust grains before being re - radiated in the infrared . This project was supported by NASA through programs NAG5 - 9998 and NAS8 - 38252 issued by JPL / Caltech under contract NAS8 - 39073 .It has been allocated the following DOI : 10 . 1086 / 505283",
        "ori-fast-z-score": 0.75,
        "water-fast-z-score": 5.5
    },
    {
        "original_text": "We present results on the composition of the eta-prime meson in terms of quarks and gluons, obtained by applying the QCD sum rule method to the correlation function of two pseudoscalars with different flavors.  We find that the eta prime is dominantly composed of strange quark pairs (ss) at low energies but becomes more nonstrange as energy increases. The mass difference between the eta and eta prime mesons can be explained if we assume that the eta prime contains an additional ss pair compared to the eta. This result supports our previous finding based on the analysis of the decay widths of these mesons into pions and kaons. \nPACS numbers: 11.10.Kk, 12.38.Gc, 13 .60.Hb  PACS number(s): 11.10.Kn, 12.38.Bx, 13 .60.Jz",
        "watermark_text": "We present results on the composition of the eta - prime meson in terms of quarks and gluons , obtained by using the QCD sum rule method to the correlation function of two pseudoscalars with varying flavors . We see that the eta prime is dominantly composed of odd quark combinations ( ss ) at low energies but gets more nonstrange as energy rises .The mass ratio between the eta and eta prime mesons can be described if we suppose that the eta prime forms an additional ss pair relative to the eta . This result confirms our previous finding based on the examination of the decay widths of these mesons into pions and kaons .PACS codes : 11 . 10 . Kk , 12 . 38 . Gc , 13 . 60 . Hb PACS number ( s ) : 11 . 10 . Kn , 12 . 38 . Bx , 13 . 60 . Jz",
        "ori-fast-z-score": -0.9258200997725514,
        "water-fast-z-score": 3.7032803990902057
    },
    {
        "original_text": "We present polarization observations made with the Australia Telescope Compact Array (ATCA) and Parkes radio telescopes towards the supernova remnant (SNR) G156.2+5. \n \n The ATCA data were taken in two observing runs, one on 1998 May 24-25 using the H214 array configuration and another on 1999 September 14-15 using the EW352 array configuration. These configurations provide baselines ranging between 15 m to 5 km. We observed for 3 hours per run, split into 12-minute scans interleaved by 10-second slews. The total bandwidth was 128 MHz centered around 1384 MHz. Data reduction followed standard procedures within MIRIAD. After flagging bad channels we produced Stokes Q and U maps which are shown in Figure 1 . \n \n Polarized intensity images were also created but these did not reveal any significant polarized emission above our noise level. This is consistent with previous single dish measurements that show no evidence for polarized emission associated with this source.",
        "watermark_text": "We present polarization images making with the Australia Telescope Compact Array ( ATCA ) and Parkes radio telescopes towards the supernova remnant ( SNR ) G156 . 2 + 5 . The ATCA results were took in two observing walks , one on 1998 May 24 - 25 using the H214 array configuration and another on 1999 September 14 - 15 use the EW352 array configuration .These modes provide baselines ranging between 15 m to 5 kilometres . We observed for 3 hours per run , separated into 12 - minute scans interleaved by 10 - second slews .The total bandwidth was 128 MHz centered around 1384 MHz . Data reduction followed standard methods within MIRIAD .After flagging bad channels we created Stokes Q and U maps which are shown in Figure 1 . Polarized intensity photos were also produced but these did not reveal any considerable polarized emission above our sound level .This is consistent with previous single dish measurements that demonstrate no evidence for polarized emission associated with this source .",
        "ori-fast-z-score": 1.3363062095621219,
        "water-fast-z-score": 5.528438872198585
    },
    {
        "original_text": "We present the results of cosmological hydrodynamic simulations that follow the evolution of dark matter haloes within different cosmic environments (clusters, filaments, sheets and voids). We find that:\n(i) The mass accretion histories of clusters are dominated by major mergers with other massive systems at high redshifts z > 1.\n(ii) In contrast to clusters, most of the growth of filamentary structures is driven by smooth gas accretion along their length.  This leads to an extended formation history for these objects which can be traced back to early times z < 5. (iii) Sheet-like structures form through the merger of smaller filaments into larger ones. They grow mainly via smooth gas accretion but also experience minor mergers with small groups or galaxies during their lifetime. (iv) Voids evolve almost exclusively due to smooth gas accretion. Their assembly time-scales are typically longer than those of clusters and filaments because they have less dense surroundings.",
        "watermark_text": "We present the conclusion of cosmological hydrodynamic simulations that take the evolution of dark matter haloes within various cosmic environments ( complexes , filaments , sheets and voids ) . We see that : ( i ) The mass accretion histories of clusters are dominated by major mergers with other giant bodies at high redshifts z > 1 .( ii ) In comparison to groups , most of the development of filamentary structures is caused by smooth gas accretion along their duration . This leads to an extended structure life for these objects which can be traced back to early years z < 5 .( iii ) Sheet - like structures develop through the merger of tiny filaments into larger ones . They develop principally via smooth gas accretion but also experience minor mergers with little groups or galaxies during their lifetime .( iv ) Voids evolve virtually primarily due to soft gas accretion . Their development time - scales are typically longer than those of clusters and filaments because they have less dense surroundings .",
        "ori-fast-z-score": -0.23904572186687872,
        "water-fast-z-score": 4.865804798594798
    },
    {
        "original_text": "We present near-infrared (NIR) observations of the central region of the Carina Nebulae obtained with ISAAC at the VLT in Chile, and compare them to previous optical studies by Smith et al. (2000) . The NIR data reveal new details on the structure of the nebular shell surrounding the open cluster Trumpler 16. We find that the brightest part of the shell is located between two dark lanes which are probably caused by dust extinction. In addition we detect several small knots embedded within the shell. These knots may be remnants of massive stars or protostars formed during an earlier phase of star formation activity in this region. Finally, we identify a number of Herbig-Haro objects associated with the open clusters Trumpler 14 and 15. Our results show that the Carina Nebulae is still actively forming stars today. This work was supported by the European Southern Observatory under programme ID 072.C-0488(B).",
        "watermark_text": "We take near - infrared ( NIR ) observations of the central region of the Carina Nebulae obtained with ISAAC at the VLT in Chile , and link them to previous optical images by Smith et al . ( 2000 ) .The NIR data reveal novel features on the composition of the nebular shell surrounding the open cluster Trumpler 16 . We see that the brightest part of the shell is situated between two darkened paths which are probably created by dust extinction .In addition we find various small knots embedded within the shell . These threads may be remnants of large planets or protostars produced during an previous process of star formation activity in this area .Finally , we identify a number of Herbig - Haro objects identified with the open spaces Trumpler 14 and 15 . Our results show that the Carina Nebulae is already actively creating stars today .This project was supported by the European Southern Observatory under series ID 072 . C - 0488 ( B ) .",
        "ori-fast-z-score": -0.12403473458920847,
        "water-fast-z-score": 6.154574548966636
    },
    {
        "original_text": "We study the phenomenological consequences of general speed of sound in brane inflationary models, where the inflaton is identified as the distance between two parallel branes moving on an extra dimension. We find that for small values of the speed of sound (cs < 0.1), there are no significant changes to the predictions made by standard slow-roll inflation. However, when cs > 0.1 we find that the tensor-to-scalar ratio r and the running of the spectral index dns/d ln k can be significantly enhanced compared to their usual values predicted within the context of single field slow roll inflation. In particular, if cs = 1 then r = 16(nT)2/5 and dns/d ln k = −8(nT)1/5, which may provide a possible explanation for recent observations of high value of nT reported by WMAP7 data combined with other CMB experiments.",
        "watermark_text": "We explore the phenomenological consequences of general velocity of noise in brane inflationary theories , where the inflaton is identified as the distance between two connected branes moving on an additional dimension . We see that for little values of the speed of noise ( cs < 0 . 1 ) , there are no major changes to the estimates made by traditional slow - roll inflation .However , when cs > 0 . 1 we find that the tensor - to - scalar ratio p and the running of the spectral index dns / d ln k can be substantially enhanced compared to their conventional estimates predicted within the context of double field fast roll inflation . In particular , if cs = 1 then r = 16 ( nT ) 2 / 5 and dns / d ln k = −8 ( nT ) 1 / 5 , which would offer a possible reason for recent observations of high value of nT reported by WMAP7 results coupled with other CMB experiments .",
        "ori-fast-z-score": -0.5163977794943222,
        "water-fast-z-score": 5.249512077248736
    },
    {
        "original_text": "The solar magnetic field is an important ingredient in many physical processes that take place on the Sun, such as coronal heating or solar wind acceleration. The open magnetic flux threading through the heliosphere plays also a crucial role for space weather prediction. In this work we present results obtained with the MHD model developed by Usmanov et al. (2010) to study the structure and dynamics of the Sun s open magnetic field. We show how the global properties of the simulated open magnetic field compare with observations made at 1 AU using spacecraft data. Our simulations reproduce well the observed latitudinal distribution of the open magnetic flux density and its dependence on the radial distance from the Sun. They also provide information about the temporal evolution of the open magnetic field which can be used to predict the state of the interplanetary medium several days ahead. This research was supported by NASA grants NNX10AC85G (PI: S. Riley), NNG09FA40C (PI: A. Schwadron), and NNM07AA01A (PI: J. McComas).",
        "watermark_text": "The solar magnetic force is an important ingredient in many mechanical phenomena that take place on the Sun , such as coronal heating or solar wind expansion . The open magnetic flux threading through the heliosphere serves also a crucial role for space weather prediction .In this research we present results derived with the MHD model used by Usmanov et al . ( 2010 ) to study the composition and dynamics of the Sun s open magnetic force .We see how the global properties of the simulated open magnetic force compare with observations made at 1 AU using satellite information . Our simulations reproduce well the seen latitudinal distribution of the open magnetic flux concentration and its dependence on the radial distance from the Sun .They also provide details about the temporal evolution of the open magnetic force which can be used to predict the state of the interplanetary medium several days ahead . This research was supported by NASA grants NNX10AC85G ( PI : S . Riley ) , NNG09FA40C ( PI : A . Schwadron ) , and NNM07AA01A ( PI : J . McComas ) .",
        "ori-fast-z-score": 0.7875615306482168,
        "water-fast-z-score": 5.062895554167108
    },
    {
        "original_text": "We present new space velocities for the nearest late-M, L-, and T-dwarf stars based on high-precision radial velocity measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile over an 8-year period (2003-2009). We find that all but one of these objects are members of young nearby open clusters or associations. The only exception is LP 944-20 which has been shown to be a member of the Hyades supercluster by its proper motion.  These results confirm previous suggestions that most brown dwarfs have ages less than 100 Myr. They also show that there may exist two populations among the very low-mass stars and brown dwarfs: those associated with open clusters/associations and those apparently not gravitationally bound to any cluster. This suggests that either some brown dwarfs form outside open clusters and/or they evaporate rapidly after formation. Finally we discuss possible explanations for the observed kinematics of the lowest mass stars and brown dwarfs.",
        "watermark_text": "We report new space velocities for the nearest late - M , L - , and T - giant galaxies using on wide - precision radial speed measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile over an 8 - year period ( 2003 - 2009 ) . We see that all but one of these objects are part of young nearby open complexes or associations .The only exception is LP 944 - 20 which has been shown to be a member of the Hyades supercluster by its proper motion . These data confirm previous suggestions that most brown dwarfs have ages less than 100 Myr .They also demonstrate that there may contain two communities among the very low - weight stars and green dwarfs : those associated with open complexes / associations and those presumably not gravitationally tied to any cluster . This implies that either some green dwarfs form outside open complexes and / or they evaporate rapidly after formed .Finally we talk proposed explanations for the known kinematics of the lowest mass stars and brown dwarfs .",
        "ori-fast-z-score": -0.48507125007266594,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We study the dynamics of an interacting Bose gas with repulsive contact interactions in one dimension, focusing on its relaxation to equilibrium after being quenched across the superfluid-Mott insulator transition. We show that this system exhibits universal behavior at late times which is characterized by power-law decaying correlations and algebraic growth of entanglement entropy. The exponents are determined analytically using a mapping onto a classical statistical mechanics problem for a driven diffusive system. This work was supported by NSF grant PHY-0960291 (M.S.) and DOE grants DE-FG03-92-ER40701 and DE-SC0012704 (A.K.). \nI. INTRODUCTORY REMARkS\n\nThe recent experimental realization of quantum degenerate gases has opened up new avenues towards understanding strongly correlated many-body systems  1  . In particular, ultracold atomic gases have been used as model systems to explore phenomena such as fermionization  2  , supersolidity  3  , and Mott-insulating states  4  .\nIn this article we consider a particularly interesting class of experiments where the properties of these systems can be probed through their response to sudden changes in parameters  5  . For example, if the strength of inter-particle repulsion or density of particles is suddenly changed then it takes some time before the system reaches thermal equilibrium  6  . During this nonequilibrium evolution, the system may exhibit novel features like dynamical scaling  7, 8  and non-thermal fixed points  9  . These effects are not only important for our fundamental understanding of quantum matter but also provide useful insights into possible routes to realizing novel phases of matter  10  .\nRecently there has been considerable interest in studying the nonequilibrium dynamics of bosonic systems  11  . A particularly well studied case is when the initial state corresponds to a highly excited state above the ground state  12  . It turns out that even though the initial state is far away from equilibrium, the system relaxes to a steady state described by a Gibbs ensemble  13  . However, if the initial state is prepared deep inside the ordered phase, then the system does not",
        "watermark_text": "We explore the dynamics of an interacting Bose gas with repulsive contact interactions in one dimension , concentrating on its relaxation to equilibrium after being quenched across the superfluid - Mott insulator transition . We see that this system displays universal behavior at late times which is characterized by power - law decaying correlations and algebraic growth of entanglement entropy .The exponents are estimated analytically using a mapping onto a traditional statistical mechanics problem for a driven diffusive system . This research was supported by NSF grant PHY - 0960291 ( M . S . )and DOE funds DE - FG03 - 92 - ER40701 and DE - SC0012704 ( A . K . ) . I .INTRODUCTORY REMARkS The recent experimental realization of quantum degenerate gases has opened up new avenues towards studying strongly interacting multiple - bodies systems 1 . In particular , ultracold nuclear gases have been used as model structures to examine processes such as fermionization 2 , supersolidity 3 , and Mott - insulating states 4 .In this article we imagine a particularly exciting group of studies where the properties of these systems can be probed through their response to unexpected changes in parameters 5 . For instance , if the strength of inter - atom repulsion or density of molecules is suddenly changed then it takes some time before the system reaches heat equilibrium 6 .During this nonequilibrium evolution , the system might exhibit new characteristics like dynamical scaling 7 , 8 and non - cooling fixed points 9 . These effects are not only important for our fundamental understanding of quantum matter but also provide useful insights into possible routes to realizing new phases of matter 10 .Recently there has been substantial interest in investigating the nonequilibrium dynamics of bosonic systems 11 . A notably well discussed case is when the first state corresponds to a highly excited state above the ground state 12 .It happens out that even though the first state is far back from equilibrium , the system relaxes to a steady state described by a Gibbs ensemble 13 . However , if the initial system is prepared deep inside the ordered phase , then the system does not",
        "ori-fast-z-score": 0.5773502691896257,
        "water-fast-z-score": 7.175639059928206
    },
    {
        "original_text": "We propose an experiment to entangle two independent photons in the time domain, using only linear optical elements and single-photon detectors.  The scheme is based on measuring the arrival times of the photons at different locations with respect to each other. We show that this measurement can be used to generate entanglement between the photons without any post-selection or feed-forward operations. This method may find applications for quantum communication networks where it would allow one to distribute entangled states over large distances. Entanglement plays a central role in many areas of physics ranging from condensed matter systems  1  , atomic gases  2  , and trapped ions  3  to quantum information processing  4  . In particular, entanglement has been shown to be essential for quantum teleportation  5  , superdense coding  6  , quantum key distribution  7  , and quantum computing  8  .\nIn recent years there have been several proposals to create entanglement between distant particles  9  -  11  . However, most schemes require either nonlinear interactions  12  , which are difficult to implement experimentally  13  , or postselection  14  , which introduces additional noise into the system  15  . Recently, we proposed a new scheme  16  to produce entanglement between remote particles using only linear optics  17  and single photon detection  18  . Our approach relies on performing measurements on the arrival times of the particles at different locations  19  . Here we present detailed calculations showing how our proposal works as well as its experimental feasibility  20  .  Figure 1 shows a schematic diagram of our setup. Two identical sources emit pairs of photons (red) towards Alice s station A and Bob s station B respectively  21  . Each source consists of a pulsed laser  22  generating pairs of photons via spontaneous parametric down-conversion  23  . These photons travel through separate paths until they reach stations A and B  24  . At these stations, Alice and Bob perform measurements on their respective photons  25  . They measure the arrival times tA and tB  26  of...",
        "watermark_text": "We suggest an project to entangle two independent photons in the time realm , using only linear optical elements and single - photon detectors . The scheme is based on measuring the emergence periods of the photons at different places with regard to each other .We see that this measurement can be used to produce entanglement between the photons without any post - choice or feed - forward functions . This method may see useful for quantum communication networks where it would enable one to distribute entangled states over large distances .Entanglement plays a central role in multiple fields of science ranging from condensed matter structures 1 , atomic atoms 2 , and trapped ions 3 to quantum information processing 4 . In particular , entanglement has been shown to be crucial for quantum teleportation 5 , superdense coding 6 , quantum key distribution 7 , and quantum computing 8 .In past decades there have been numerous ideas to create entanglement between distant particles 9 - 11 . However , most schemes need either nonlinear interactions 12 , which are hard to execute experimentally 13 , or postselection 14 , which introduces additional noise into the process 15 .Recently , we presented a new method 16 to produce entanglement between remote particles utilizing only linear optics 17 and single photon detection 18 . Our solution consists on making observations on the entry rates of the molecules at different places 19 .Here we present detailed calculations demonstrating how our proposal works as also as its empirical feasibility 20 . Figure 1 shows a schematic diagram of our setup .Two similar sources emit pairs of photons ( red ) towards Alice s station A and Bob s station B respectively 21 . Each source consists of a pulsed laser 22 producing sets of photons via spontaneous parametric down - transfer 23 .These photons travel through different paths until they reach stations A and B 24 . At these stations , Alice and Bob conduct measurements on their respective photons 25 .They measure the arrival times tA and tB 26 of . . .",
        "ori-fast-z-score": -0.5035088149780135,
        "water-fast-z-score": 6.88128713803285
    },
    {
        "original_text": "We present an analysis on the spatial and velocity distributions of the young (<10Myr) stars within 0.5pc of Sgr A*, based on our spectroscopic survey with Subaru/HDS. We find that these stars are distributed into two groups along the line-of-sight; one is located at ~0.1pc to the west side of Sgr A* and another is found at ~0.3pc to its east side. The former group has a mean radial velocity of -200km/sec while the latter shows +100km/sec. These results suggest that there exist two distinct populations of young stars around Sgr A*; one is associated with the clockwise disk-like structure seen in infrared images and the other may be related to the counter-clockwise rotating ring-like feature recently discovered by Genzel et al. (2003) . In addition we have identified several new candidate members for the clockwise disk population.",
        "watermark_text": "We present an assessment on the spatial and speed distributions of the young ( < 10Myr ) stars within 0 . 5pc of Sgr A * , using on our spectroscopic study with Subaru / HDS . We see that these stars are distributed into two groups along the line - of - view ; one is situated at ~ 0 . 1pc to the west end of Sgr A * and another is found at ~ 0 . 3pc to its east side .The first group has a mean radial speed of - 200km / sec while the former shows + 100km / sec . These data suggest that there exist two separate populations of young galaxies around Sgr A * ; one is associated with the clockwise disk - like structure seen in infrared images and the other may be connected to the counter - clockwise expanding box - like feature newly discovered by Genzel et al .( 2003 ) . In addition we have discovered numerous new likely groups for the clockwise disk population .",
        "ori-fast-z-score": -0.3841106397986879,
        "water-fast-z-score": 4.905778905196061
    },
    {
        "original_text": "We have studied the effect of masking out part of sky for CMB temperature fluctuations by using simulated data sets and found that it is important to take into account the effects of masked pixels when estimating angular power spectrum (APS) at large angles, especially for low multipoles l < 20. We also find that the APS estimated with the standard method based on spherical harmonics decomposition can be biased if there are significant correlations between masked and unmasked regions. In this work we propose an improved method which takes these effects into account. The new method has been applied to estimate the APS of the WMAP three-year data set after removing point sources detected above 5 mJy beam −1 . Our results show good agreement with those obtained directly from the full-sky map without any masking. \n \n Keywords: Cosmic microwave background radiation, Large angle anisotropy, Point source removal",
        "watermark_text": "We have researched the impact of masking out part of skies for CMB heat fluctuations by using modeled information sets and found that it is important to take into consideration the effects of masked pixels when estimating angular power spectrum ( APS ) at large angles , particularly for low multipoles l < 20 . We additionally find that the APS calculated with the standard method using on spherical harmonics decomposition can be biased if there are significant correlations between masked and unmasked areas .In this research we propose an better method which uses these changes into consideration . The revised formula has been used to estimate the APS of the WMAP three - year data set after removing point elements detected above 5 mJy beam −1 .Our results show good agreement with those acquired directly from the full - skies map without any masking . Keywords : Cosmic electromagnetic background radiation , Large angle anisotropy , Point source removal",
        "ori-fast-z-score": -0.36650833306891567,
        "water-fast-z-score": 5.2532861073211246
    },
    {
        "original_text": "We report on Suzaku observations for four active galactic nuclei (AGNs) detected by Swift/BAT survey, which are classified as  obscured AGNs  with column density larger than 10 24 cm-2 . We found that all these sources show strong Fe K emission lines and their line widths are broader than those expected from thermal broadening at kT = 100 keV. The observed line profiles can be reproduced well by relativistic disk reflection models including Compton scattering effects. These results suggest that there is an additional component to the X-ray continuum other than the standard thin accretion disks around supermassive black holes. In addition, we find that the iron abundance relative to solar value is higher than 1.5 times in three out of four objects. This suggests that the central engines of these obscured AGNs may have been buried under heavy dusty torii. Finally, we discuss possible origins of this new type of buried supermassive black holes based on our observational results.",
        "watermark_text": "We report on Suzaku measurements for four active galactic nuclei ( AGNs ) detected by Swift / BAT search , which are classified as obscured AGNs with column height larger than 10 24 mm - 2 . We showed that all these sources show light Fe K emission lines and their line widths are larger than those expected from radiation broadening at kT = 100 keV .The observed line profiles can be reproduced well by relativistic disk absorption theories including Compton scattering effects . These data suggest that there is an additional element to the X - ray continuum other than the standard narrow accretion disks around supermassive black holes .In addition , we find that the metal density relative to solar value is higher than 1 . 5 times in three out of four objects . This implies that the main engines of these obscured AGNs might have been trapped under heavy dusty torii .Finally , we explain possible origins of this new kind of hidden supermassive black holes using on our observational results .",
        "ori-fast-z-score": 0.11867816581938533,
        "water-fast-z-score": 6.128258770283413
    },
    {
        "original_text": "We present the results of our analysis of cosmic ray data collected by the PAMELA experiment in 2008 and 2009, which show an excess over background at energies between 1-10 GeV/nucleon that is consistent with being produced by particles accelerated in nearby supernova remnants (SNRs). We find that this signal can be explained if we assume that SNR RX J1713-3946 accelerates protons up to 10 TeV energy per nucleon. The observed fluxes are also compatible with those expected for other known sources such as pulsars or active galactic nuclei. However, these alternative scenarios cannot explain all features seen in the data set. In particular, they do not predict any significant anisotropy in arrival directions on angular scales below ~10 degrees. This prediction is confirmed by observations made using the Tibet ASγ air shower array. Finally, we discuss possible implications of our findings for models of particle acceleration in relativistic shocks.",
        "watermark_text": "We present the conclusion of our analysis of cosmic ray data taken by the PAMELA study in 2008 and 2009 , which show an amount over background at energies between 1 - 10 GeV / nucleon that is compatible with being produced by particles advanced in nearby supernova remnants ( SNRs ) . We see that this signal can be described if we suppose that SNR RX J1713 - 3946 accelerates protons up to 10 TeV power per nucleon .The observed fluxes are also consistent with those expected for other known sources such as pulsars or active galactic nuclei . However , these alternative situations cannot explain all characteristics found in the information pool .In particular , they do not predict any slight anisotropy in arrival angles on spatial scales below ~ 10 degrees . This prediction is confirmed by observations made using the Tibet ASγ air rain system .Finally , we explain possible possibilities of our findings for models of particle acceleration in relativistic shocks .",
        "ori-fast-z-score": -0.8819171036881969,
        "water-fast-z-score": 4.913538149119954
    },
    {
        "original_text": "The gamma ray emission in the energy range 100 MeV to 10 GeV is studied using data taken by EGRET on board CGRO during its first four years of operation (1991) (1992) (1993) (1994) . The analysis has been performed for two different regions, one centered at l = 0° and b = - 5° , which includes the galactic centre region, and another centered at l = 180° and b = + 5° . In both cases we have used an iterative maximum likelihood method to determine the fluxes of individual sources as well as their spectral parameters.  We find that there are three distinct components contributing to the observed gamma-ray flux above 1 GeV :  A diffuse component with a power law spectrum extending upto ~10 GeV .\nA point source located near Sgr A* with a power law spectrum .\nAn extended source towards the galactic center with a broken power law spectrum . \nWe also present results obtained when the same analysis was repeated after excluding the contribution due to the central part of the Galaxy .",
        "watermark_text": "The gamma radiation emission in the power range 100 MeV to 10 GeV is studied utilizing information taken by EGRET on board CGRO during its initial four seasons of operation ( 1991 ) ( 1992 ) ( 1993 ) ( 1994 ) . The studies has been performed for two different regions , one located at l = 0° and b = - 5° , which includes the galactic centre region , and another focused at l = 180° and b = + 5° .In both cases we have utilized an iterative limit probability technique to estimate the fluxes of different sources as also as their spectral parameters . We see that there are three different components contributing to the emitted beta - ray flux above 1 GeV : A diffuse component with a power law spectrum stretching upto ~ 10 GeV .A point source located near Sgr A * with a power law spectrum . An extended source towards the galactic center with a cracked power law spectrum .We additionally include findings obtained when the same evaluation was repeated after excluding the contribution owing to the central region of the Galaxy .",
        "ori-fast-z-score": -1.62746694241347,
        "water-fast-z-score": 4.88240082724041
    },
    {
        "original_text": "We have studied the pulse-to-pulse intensity variations in two pulsars, PSR B0826-34 and PSR B1133+16, using data obtained with the Parkes radio telescope at 1.4 GHz (92cm) and 2.7GHz(36cm). We find that both pulsars show strong evidence for subpulse drift bands which are modulated by an underlying pattern of weaker emission. The observed patterns can be explained as due to interference between different modes of emission within each beam. In addition we find that there is no significant difference in the subpulse modulation properties when comparing observations made at 36cm and those made at 92cm. This suggests that the physical processes responsible for producing these phenomena operate over a wide range of frequencies. These results provide further support for the idea that the phenomenon known as drifting subpulses may arise through some form of plasma instability operating on the open field lines near the magnetic poles of neutron stars. \n \n Keywords: Pulsar",
        "watermark_text": "We have researched the signal - to - pulse intensity variations in two pulsars , PSR B0826 - 34 and PSR B1133 + 16 , using data acquired with the Parkes radio telescope at 1 . 4 GHz ( 92cm ) and 2 . 7GHz ( 36cm ) . We see that both pulsars give strong evidence for subpulse slip lines which are modulated by an underlying pattern of weaker emission .The observed patterns can be described as owing to interference between various modes of emission within each light . In addition we find that there is no major variation in the subpulse modulation properties when matching observations made at 36cm and those conducted at 92cm .This implies that the physical processes responsible for producing these phenomena run over a broad variety of frequencies . These conclusions provide further evidence for the idea that the process known as drifting subpulses might arise through some kind of plasma instability working on the open field lines near the magnetic poles of neutron galaxies .Keywords: Pulsar",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 6.5484618759809905
    },
    {
        "original_text": "We present results for MHD simulations of the magneto-rotational instability (MRI) in a stratified, Keplerian disk threaded by an initially vertical magnetic field using the ZEUS-2D code. We consider both isothermal and adiabatic equations of state to examine how the MRI depends on the thermodynamics of the gas. In all cases we find that the growth rate of the fastest growing mode agrees well with linear theory predictions when normalized appropriately. However, there are significant differences between our runs depending upon whether or not they have reached steady-state equilibrium. For example, the saturated level of stress achieved at late times varies significantly among different models. This suggests that it may be difficult to accurately predict the saturation amplitude of the MRI unless one can perform very high resolution calculations which evolve over many orbital periods. Finally, we show that the inclusion of radiative cooling has little effect on the properties of the turbulence generated by the MRI.",
        "watermark_text": "We see results for MHD simulations of the magneto - rotational disturbance ( MRI ) in a stratified , Keplerian disk threaded by an initially vertical magnetic force using the ZEUS - 2D coding . We consider both isothermal and adiabatic equations of state to examine how the MRI depends on the thermodynamics of the gas .In all situations we find that the development frequency of the fastest growing mode agrees well with continuous theory expectations when normalized appropriately . However , there are significant variations between our runs depending upon whether or not they have achieved steady - state balance .For instance , the saturated amount of stress attained at late times changes significantly among different models . This implies that it could be impossible to correctly calculate the saturation amplitude of the MRI unless one can conduct very high resolution measurements which change over numerous orbital periods .Finally , we prove that the introduction of radiative cooling has little impact on the properties of the turbulence generated by the MRI .",
        "ori-fast-z-score": -1.1952286093343936,
        "water-fast-z-score": 5.737097324805089
    },
    {
        "original_text": "We report on the discovery of an unexpected ring-like dark matter structure at the center of galaxy cluster CL0024+17, which is located about 3 billion light years away and has been studied extensively by many observational techniques including gravitational lensing.  The mass distribution inferred from strong gravitational lensing shows that there are two massive subclusters separated by 1 Mpc (3 arcmin) with a total mass of 2 x 10 15 h-1M_sun within a radius of 0.5h-1Mpc around their centers. We find that this double-cluster system can be well described as a binary merger model where each component consists of three components; one main halo and two smaller halos surrounding it. In addition to these six clusters, we also detect another small clump of galaxies near the center of the merging system whose position coincides with the peak of X-ray emission detected by Chandra satellite observations.",
        "watermark_text": "We report on the discovery of an unexpected ring - like dark matter formation at the center of galaxy region CL0024 + 17 , which is situated about 3 billion light years far and has been studied significantly by many observational techniques including gravitational lensing . The mass distribution inferred from strong gravitational lensing indicates that there are two huge subclusters separated by 1 Mpc ( 3 arcmin ) with a total mass of 2 x 10 15 g - 1M _ sun within a diameter of 0 . 5h - 1Mpc around their regions .We see that this double - cluster system can be well described as a binary merger model where each core consists of three components ; one main halo and two smaller halos covering it . In addition to these six complexes , we also observe another tiny clump of stars near the center of the merging system whose position coincides with the maximum of X - ray radiation observed by Chandra satellite observations .",
        "ori-fast-z-score": 0.8682431421244593,
        "water-fast-z-score": 5.333493587335964
    },
    {
        "original_text": "We present an analysis of the distribution and properties of open clusters in the Galactic anticenter region, using data from the Two Micron All Sky Survey (2MASS). We have compiled a list of all open clusters with angular diameters larger than 1 arcmin within a distance of 8 kpc from the Sun. The total number is about 1000. This sample includes most known open clusters in this part of the Galaxy. Using photometric distances derived by fitting theoretical stellar evolutionary tracks to observed color-magnitude diagrams for each cluster we construct maps showing their spatial distributions as well as their luminosity functions. Our results show that there are two distinct populations of open clusters: one population located at galactocentric radii between 4 and 6 kpc which has ages less than 3 Gyr; another population located at galactocenric radii greater than 7 kpc which has ages older than 5 Gyr.",
        "watermark_text": "We publish an assessment of the distribution and features of open complexes in the Galactic anticenter region , using data from the Two Micron All Sky Survey ( 2MASS ) . We have published a list of all open complexes with angular diameters larger than 1 arcmin within a distance of 8 kpc from the Sun .The total number is about 1000 . This sample comprises most notable open objects in this area of the Galaxy .Using photometric distances derived by fitting experimental stellar evolutionary tracks to observed color - magnitude diagrams for each cluster we create maps showing their spatial distributions as well as their luminosity functions . Our results show that there are two different populations of open complexes : one community located at galactocentric radii between 4 and 6 kpc which has ages less than 3 Gyr ; another population located at galactocenric radii greater than 7 kpc which has ages younger than 5 Gyr .",
        "ori-fast-z-score": -0.6622661785325219,
        "water-fast-z-score": 3.9391929857916765
    },
    {
        "original_text": "We present new results on the age, metallicity and alpha-element abundance for galactic globular clusters (GGCs) based on single stellar population models with different prescriptions for convection theory. We find that the ages derived by using the classical mixing-length theory are systematically younger than those obtained by assuming overshooting or semiconvection in the red giant branch phase. The difference between these two sets of ages is about 0.5 Gyr at most. For some metal-rich GGCs, we also found that their ages inferred from the classical mixing-length theory can be as young as 10 Gyr while they should have been older than 12 Gyr according to other methods. This discrepancy may result from the fact that the classical mixing-length theory cannot reproduce well the observed color-magnitude diagrams of such metal-rich GGCs. Our results show that there exists no significant correlation between the cluster s age and its metallicity.  These findings suggest that the formation history of GGCs might not be dominated by monolithic collapse but instead by hierarchical merging processes.",
        "watermark_text": "We report new data on the age , metallicity and alpha - component availability for galactic globular complexes ( GGCs ) based on single stellar community theories with various prescriptions for convection hypothesis . We see that the periods derived by using the classical mixing - length theory are systematically younger than those generated by assuming overshooting or semiconvection in the red dwarf branch period .The difference between these two sets of periods is about 0 . 5 Gyr at most . For some metal - rich GGCs , we also discovered that their ages inferred from the theoretical mixing - length theory can be as early as 10 Gyr while they should have been older than 12 Gyr according to other methods .This discrepancy may arise from the fact that the classical mixing - length theory cannot reproduce well the known color - magnitude diagrams of such metal - rich GGCs . Our results show that there exists no important relationship between the cluster s age and its metallicity .These studies propose that the formation history of GGCs might not be dominated by monolithic collapse but instead by hierarchical merging cycles .",
        "ori-fast-z-score": -0.22360679774997896,
        "water-fast-z-score": 5.142956348249516
    },
    {
        "original_text": "We present an overview of the theory for vortices in trapped, dilute atomic gases at low temperatures. We discuss how these systems can be described by macroscopic wave functions and show that they are governed by nonlinear Schrödinger equations with external potentials. The solutions to this equation have been studied extensively over many years and we review some of their properties relevant to vortex formation. In particular, we consider stationary states which correspond to condensate configurations without rotation (vortex-free) as well as rotating ones where quantized angular momentum is carried by phase singularities known as vortices. Finally, we briefly describe recent experiments on vortex production in cold atom clouds. Vortices occur naturally in superfluids such as liquid helium or dilute atomic gases. They carry quantized angular momenta and play important roles in various physical phenomena including turbulence and quantum transport processes. Here we give an introduction into the theoretical description of vortices in trapped atomic gases.",
        "watermark_text": "We present an overview of the principle for vortices in trapped , dilute atomic materials at low temperatures . We discuss how these systems can be described by macroscopic wave distributions and explain that they are governed by nonlinear Schrödinger coefficients with external potentials .The solutions to this equation have been studied frequently over numerous years and we review some of their characteristics applicable to vortex structure . In particular , we investigate stationary states which refer to condensate configurations without rotation ( vortex - safe ) as well as rotating ones where quantized angular velocity is carried by phase singularities known as vortices .Finally , we briefly illustrate recent experiments on vortex production in cold atom clouds . Vortices arise naturally in superfluids such as fluid helium or dilute nuclear gases .They carry quantized angular momenta and play crucial roles in different mechanical phenomena including turbulence and quantum transport systems . Here we give an overview into the theoretical description of vortices in trapped atomic gases .",
        "ori-fast-z-score": -1.1470786693528088,
        "water-fast-z-score": 5.047146145152358
    },
    {
        "original_text": "We present deep imaging data for the nearby dwarf spheroidal galaxy, Hercules (dSph), obtained with the Large Binocular Telescope (LBT). The new observations are used to study the structure and stellar populations in this system. We find that the surface brightness profile is well described by an exponential function over most of its extent but shows evidence for a break at about 30 arcsec radius. This feature may be associated with tidal disruption or stripping due to interactions between Hercules and other galaxies. Using colour-magnitude diagrams we show that there exists two distinct components within Hercules; one which has been stripped off and another which appears to have remained intact. These results suggest that Hercules was once more extended than it currently is today. Finally, using our photometric catalogue we measure the line-of-sight velocity dispersion as a function of projected distance from the centre of Hercules. Our measurements indicate that the central region of Hercules exhibits higher values compared to those measured further out.",
        "watermark_text": "We present deep imaging information for the nearby dwarf spheroidal galaxy , Hercules ( dSph ) , obtained with the Large Binocular Telescope ( LBT ) . The newest observations are using to study the composition and stellar environments in this system .We see that the surface brightness profile is well described by an exponential function over most of its extent but shows proof for a break at about 30 arcsec radius . This phenomenon might be involved with tidal disruption or stripping due to interactions between Hercules and other stars .Using colour - magnitude diagrams we find that there exists two separate phases within Hercules ; one which has been stripped off and another which appears to have remained intact . These data suggest that Hercules was once more extended than it currently is presently .Finally , using our photometric catalogue we measure the line - of - view velocity dispersion as a function of projected distance from the centre of Hercules . Our measurements indicate that the main region of Hercules exhibits higher values compared to those observed further out .",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 4.478342947514801
    },
    {
        "original_text": "The concept of defects in crystals has been developed by the Russian school since the 1930s. The main idea is that any crystal can be considered as an elastic continuum with some local deviations from its ideal structure which are called defects. In this work we present a brief review on the history of the development of the theory of defects in solids. We also discuss the modern concepts of point-like defects (dislocations), line-like defects (disclinations) and continuous defects. Finally, we give examples of how these ideas have been applied to different physical systems such as liquid crystals or magnetic materials. Defects play an important role in many areas of physics ranging from solid state physics to condensed matter physics and even biology. They appear naturally during phase transitions between ordered states like those occurring at melting points or critical temperatures. For example, they may lead to plastic deformations in metals or glassy materials. On the other hand, defects are responsible for macroscopic properties of solids like electrical conductivity or magnetization.",
        "watermark_text": "The concept of flaws in crystals has been originated by the Russian school since the 1930s . The main idea is that any solid can be regarded as an elastic continuum with some local deviations from its ideal structure which are called flaws .In this research we present a brief review on the history of the development of the principle of flaws in solids . We especially examine the newer concepts of point - like defects ( dislocations ) , edge - like defects ( disclinations ) and continuous defects .Finally , we give evidence of how these ideas have been used to different physical structures such as fluid crystals or magnetic materials . Defects serve an important role in many fields of science ranging from solid state mechanics to condensed matter science and even biology .They arise naturally during phase transitions between ordered states like those occurring at melting points or critical temperatures . For instance , they may contribute to plastic deformations in metals or glassy materials .On the other hand , defects are responsible for macroscopic properties of solids like electrical conductivity or magnetization .",
        "ori-fast-z-score": 0.5555555555555556,
        "water-fast-z-score": 6.184165460191406
    },
    {
        "original_text": "We present an algorithm that systematically scans all possible 7-colourings of the grid, and report on its performance in terms of running time and memory consumption. The algorithm is based on a simple backtracking scheme combined with some heuristics to prune parts of the search space. We have implemented this algorithm using Java 1.6 and tested it on several instances ranging from small grids up to large ones containing more than one million nodes. For each instance we provide detailed information about how much time was spent by our program during colouring as well as how many colours were used. In addition, we also show how these results compare against those obtained by other algorithms proposed recently in the literature. \n \n Keywords: Coloring problems, Computational complexity theory, Graphs, Backtrack search, Heuristic methods, Grid graphs, Integer programming, Optimization problems, Search trees, Time-complexity analysis \n \n \n \n INTRODUCTION \n \n A graph G = (V, E) consists of two sets V and E where V denotes the set of vertices or nodes and E denotes the set of edges between pairs of nodes. An edge e=(u,v) connects node u ∈ V to v ∈ V . If there exists no such connection then e is not included in E. A path P is defined as a sequence of distinct nodes v1 , v2 , … , vn such that vi−1vi ∈ E for i = 2 , 3 , … , n . A cycle C is defined as a path whose first and last nodes are identical. A connected component is a subgraph H of G which has the property that any pair of nodes in H can be joined by a path within H but cannot be joined by paths outside H. A clique K is a complete subgraph of G; that is, every pair of nodes in K is adjacent to each other. A k-clique is a clique consisting of exactly k nodes. A vertex cover S is a subset of V such that every edge in G has at least one endpoint in S. A dominating set D is a subset of V",
        "watermark_text": "We create an algorithm that systematically scans all possible 7 - colourings of the grid , and report on its effectiveness in terms of running time and memory usage . The algorithm is based on a simple backtracking scheme coupled with some heuristics to prune parts of the search space .We have applied this algorithm using Java 1 . 6 and demonstrated it on numerous instances ranging from small grids up to large ones featuring more than one million nodes . For each instance we provide comprehensive information about how many time was spent by our software during colouring as also as how many colours were used .In addition , we also demonstrate how these results compare against those achieved by other methods suggested late in the literature . Keywords : Coloring questions , Computational complexity analysis , Graphs , Backtrack search , Heuristic methods , Grid graphs , Integer programming , Optimization problems , Search trees , Time - complexity analysis INTRODUCTION A graph G = ( V , E ) contains of two sets V and E where V denotes the set of vertices or nodes and E denotes the set of vertices between pairs of vertices .An path e = ( v , v ) links node e ∈ V to v ∈ V . If there exists no such connection then e is not added in E . A path P is given as a sequence of distinct nodes v1 , v2 , … , vn such that vi−1vi ∈ E for i = 2 , 3 , … , n .A cycle C is characterized as a path whose first and last nodes are equal . A linked component is a subgraph H of G which has the feature that any pair of vertices in H can be joined by a path within H but cannot be joined by tracks outside H . A clique K is a complete subgraph of G ; that is , every pair of vertices in K is adjoining to each other .A k - clique is a clique consisting of exactly k nodes . A vertex cover S is a subset of V such that every edge in G has at least one endpoint in S . A dominating setting D is a subset of V",
        "ori-fast-z-score": 0.8770580193070293,
        "water-fast-z-score": 7.367287362179046
    },
    {
        "original_text": "The Large Hadron Collider (LHC) is expected to produce new particles that could be dark matter candidates, such as supersymmetric partners of quarks or leptons.  In this talk I will discuss how these signatures can be searched for using data collected by the ATLAS experiment during Run 1 of the LHC. The results are presented both in terms of limits on production cross sections and mass exclusion regions. Finally, prospects for future searches with Run 2 data are discussed. This work was performed within the framework of the PhD thesis of M.A.M., supervised by A.S.. \nIntroduction\n\nDark Matter Candidates\n\nSupersymmetry\n\nATLAS Experiment\n\nRun 1 Results\n\nProspects for Run 2 Searches\n\nConclusions & Outlook \n\nReferences \n\n\nAcknowledgements\n\n\n\n\n\n- - - - - - - -- - - - - - --- - - - - - ---- - - - - - ----- - - - - - ------ - - - - - -------- - - - - - ---------- - - - - - ------------------ - - - - - -------------- - - - - - ----------------------------------- - - - - - ----------------------------------------------------- - - - - - ------------------------------------------------------------------------------------ - - - - -",
        "watermark_text": "The Large Hadron Collider ( LHC ) is expected to produce new objects that might be dark matter candidates , such as supersymmetric partners of quarks or leptons . In this talk I will explore how these signatures can be searched for utilizing information collected by the ATLAS experiment during Run 1 of the LHC .The results are presented both in terms of limits on production cross sections and mass isolation regions . Finally , prospects for future investigations with Run 2 data are discussed .This project was done within the framework of the PhD thesis of M . A . M . , overseen by A . S . . Introduction Dark Matter Candidates Supersymmetry ATLAS Experiment Run 1 Results Prospects for Run 2 Searches Conclusions & Outlook References Acknowledgements - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -",
        "ori-fast-z-score": 1.2977713690461004,
        "water-fast-z-score": 4.767570631855362
    },
    {
        "original_text": "We revisit the constraints imposed by Big Bang Nucleosynthesis (BBN) and Cosmic Microwave Background Radiation (CMBR) observations on the possible existence of massive, unstable neutrinos with lifetimes longer than 10^(10) s. We find that these limits are significantly weaker if one allows for non-standard interactions between neutrinos and photons in addition to standard weak interactions. In particular we show that BBN can be compatible with an unstable tau-neutrino mass as large as mtau = 1 TeV even when its decay rate is suppressed by a factor of 10^{10} compared to the Standard Model prediction. This result has important implications for models of leptogenesis which require heavy Majorana masses for right-handed neutrinos. The possibility of such light unstable particles also opens up new avenues for probing physics beyond the Standard Model at future colliders like LHC or ILC.",
        "watermark_text": "We revisit the limitations imposed by Big Bang Nucleosynthesis ( BBN ) and Cosmic Microwave Background Radiation ( CMBR ) observations on the possible existence of large , unstable neutrinos with lifetimes greater than 10 ^ ( 10 ) s . We see that these limits are greatly weaker if one permits for non - standard interactions between neutrinos and photons in addition to standard weak interactions . In particular we prove that BBN can be compatible with an volatile tau - neutrino mass as big as mtau = 1 TeV even when its degradation rate is suppressed by a factor of 10 ^ { 10 } compared to the Standard Model prediction .This result has important considerations for models of leptogenesis which require heavy Majorana masses for right - handed neutrinos . The possibility of such light unstable objects already opens up new avenues for probing dynamics beyond the Standard Model at possible colliders like LHC or ILC .",
        "ori-fast-z-score": 0.42008402520840293,
        "water-fast-z-score": 4.900980294098034
    },
    {
        "original_text": "The discovery that the universe is expanding at an accelerating rate has led to intense interest in dark energy as well as new ideas about fundamental physics. This talk will review some recent results on these topics including constraints on models for cosmic acceleration using supernovae data, measurements of the Hubble constant with Type Ia supernovae, and tests of general relativity using gravitational lensing statistics. The talk will also discuss how future surveys such as LSST can be used to further our understanding of dark energy and fundamental physics. I will conclude by discussing my own work on testing gravity theories beyond Einstein s theory using weak lensing observations. Keywords: Cosmology, Dark Energy, General Relativity, Weak Lensing, Supernovae, Gravitational Waves, Cosmic Microwave Background. Speaker: Adam Riess (Princeton University) Date: February 18, 2007 Time: 4:30pm - 5:15pm Location: Room B",
        "watermark_text": "The observation that the universe is evolving at an accelerating rate has led to intense interest in dark energy as well as fresh concepts about basic physics . This discussion will review some latest findings on these topics including constraints on estimates for cosmic acceleration using supernovae information , measurements of the Hubble constant with Type Ia supernovae , and experiments of general relativity employing gravitational lensing statistics .The speech will also discuss how potential experiments such as LSST can be used to further our knowing of deep energy and fundamental theory . I will conclude by reviewing my own research on proving gravity fields beyond Einstein s principle involving weak lensing observations .Keywords : Cosmology , Dark Energy , General Relativity , Weak Lensing , Supernovae , Gravitational Waves , Cosmic Microwave Background . Speaker : Adam Riess ( Princeton University ) Date : February 18 , 2007 Time : 4 : 30pm - 5 : 15pm Location : Room B",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 5.337745350213779
    },
    {
        "original_text": "We report on neutron scattering experiments performed to study spin fluctuations and magnetic correlations in the metallic phase of quasi-two-dimensional organic superconductor κ-(BEDT-TTF)2Cu N(CN)2 Br (κ-Br). We find that the temperature dependence of the static susceptibility χ0 is well described by the Curie-Weiss law with an antiferromagnetic Weiss constant θ = -26 K, indicating strong antiferromagnetic interactions between spins. The observed broadening of the elastic linewidth Γel at low temperatures indicates short-range spin-spin correlation lengths ξs ~ 5 nm. In addition we observe a large enhancement of the dynamic susceptibility χ′′(Q,ω), which can be attributed to the development of low-energy spin excitations below T* ~ 50 K. These results are consistent with theoretical predictions for two-dimensional systems close to quantum criticality. Our data suggest that the system undergoes a transition into a state where the Fermi surface becomes unstable against formation of electron-hole pairs leading to Cooper pairing. \n \n Introduction \n \n A number of recent studies have shown that many strongly correlated electronic materials exhibit unconventional properties such as high-temperature superconductivity or non-Fermi liquid behavior  1  . One important aspect of these phenomena is the presence of collective charge and/or spin degrees of freedom  2  , whose dynamics often give rise to characteristic features in the excitation spectrum  3  . For example, in cuprate-based high-temperature superconductors  4  , it has been suggested that the pseudogap regime  5  may arise due to competing orders  6  originating from different regions of the Brillouin zone  7, 8  . Similarly, in iron pnictide compounds  9  , the appearance of a spin-density wave order parameter  10  leads to a suppression of the density-of-states near the Fermi level  11  resulting in a partial gap opening  12  . Finally, in heavy fermion metals  13  , the hybridization of localized f-electrons  14  gives rise to a nontrivial momentum structure of the self-energy  15  .\n \nIn this work, we present detailed measurements of the spin fluctuation spectrum in the metallic phase of the quasi",
        "watermark_text": "We report on neutron scattering experiments conducted to study spin fluctuations and magnetic correlations in the metallic phase of quasi - two - dimensional organic superconductor κ - ( BEDT - TTF ) 2Cu N ( CN ) 2 Br ( κ - Br ) . We see that the temperature dependence of the static susceptibility χ0 is well described by the Curie - Weiss law with an antiferromagnetic Weiss constant θ = - 26 K , showing strong antiferromagnetic interactions between spins .The observed broadening of the elastic linewidth Γel at low temperatures indicates short - range spin - spin correlation distances ξs ~ 5 nm . In addition we study a large enhancement of the dynamic susceptibility χ ′ ′ ( Q , ω ) , which can be due to the development of high - energy spinning excitations below T * ~ 50 K . These conclusions are compatible with theoretical estimates for two - dimensional systems close to quantum criticality .Our data suggest that the system undergoes a shift into a state where the Fermi surface gets unstable against development of electron - hole couples leading to Cooper coupling . Introduction A couple of recent studies have shown that several highly correlated optical materials exhibit unusual characteristics such as high - temperature superconductivity or non - Fermi solid behavior 1 .One important feature of these phenomena is the presence of collective charge and / or spin degrees of liberty 2 , whose dynamics often give rise to distinctive features in the excitation spectrum 3 . For instance , in cuprate - based high - temperature superconductors 4 , it has been proposed that the pseudogap regime 5 may arise due to competing orders 6 resulting from different regions of the Brillouin zone 7 , 8 .Similarly , in metal pnictide molecules 9 , the appearance of a spin - density wave order parameter 10 results to a suppression of the density - of - states near the Fermi level 11 producing in a partial gap opening 12 . Finally , in heavy fermion metals 13 , the hybridization of localized f - ions 14 makes rise to a nontrivial momentum arrangement of the self - energy 15 .In this research , we present detailed observations of the spin fluctuation spectrum in the metallic phase of the quasi",
        "ori-fast-z-score": 1.0441851275732486,
        "water-fast-z-score": 7.574735861838574
    },
    {
        "original_text": "We study the energy transfer in a network of coupled nonlinear oscillators with time delay, which is motivated by the dynamics of biological systems such as neural networks and genetic regulatory networks. We show that there exists an optimal coupling strength for each individual oscillator to achieve maximum energy transfer efficiency among all other oscillators. The results are obtained through numerical simulations on both small-scale and large-scale networks. In particular, we find that the energy transfer efficiency decreases when the number of nodes increases beyond a certain threshold value. This phenomenon can be explained by the fact that the total amount of available energy per node decreases rapidly due to the increase of the number of nodes. Finally, we discuss possible applications of our findings to real-world problems. Energy transfer plays important roles in many natural phenomena including brain activity  1  , heartbeat  2  , and gene regulation  3  . It has been shown recently that efficient energy transfer may also exist in complex networks  4  -  6  .\nIn this work, we consider a system consisting of N identical nonlinear oscillators connected via delayed couplings (see Fig.   1 ). Each oscillator i = 1; 2; ...; N is described bẏ \nwhere x i 2 R n denotes its state vector, f : R n ! R n describes the local dynamics of each oscillator, c ij > 0 represents the coupling strength between two oscillators i and j, and h(t) is the transmission delay satisfying h max < h(t) < h min ; t 0:",
        "watermark_text": "We research the power transfer in a network of coupled nonlinear oscillators with time delay , which is motivated by the dynamics of biological systems such as neural systems and genome regulatory circuits . We see that there exists an appropriate coupling strength for each individual oscillator to achieve maximum energy transfer efficiency among all other oscillators .The results are derived through computational simulations on both small - scale and large - scale networks . In particular , we find that the power transfer efficiency decreases when the number of nodes increases beyond a certain threshold value .This phenomenon can be described by the fact that the total amount of available energy per node decreases quickly due to the increase of the number of nodes . Finally , we explain possible applied of our findings to real - time situations .Energy transfer plays important roles in multiple natural phenomena including brain activity 1 , heartbeat 2 , and gene control 3 . It has been shown lately that efficient energy flow would also exist in complex networks 4 - 6 .In this study , we study a system consisting of N identical nonlinear oscillators related via delayed couplings ( saw Fig . 1 ) .Each oscillator i = 1 ; 2 ; . . . ; N is described [UNK] where x i 2 R n denotes its state vector , f : R n ! R n describes the local dynamics of each oscillator , c ij > 0 represents the coupling strength between two oscillators i and j , and h ( t ) is the transmission delay satisfying h max < h ( t ) < h min ; t 0 :",
        "ori-fast-z-score": -0.5345224838248488,
        "water-fast-z-score": 4.09800570932384
    },
    {
        "original_text": "The availability of computer systems is an important aspect in the design, development and operation of any system. The aim of this research was to develop a method for assessing the availability of a large number of SunOS/Solaries systems using syslogd (System Logging Daemon) and wtmpx (Windows Time Machine eXtender). This research has been carried out by collecting data from a set of servers over a period of one year. A total of 1,000,000 records were collected during that time frame. These records have then been processed into a database which contains information about each record such as timestamps, host name, service type etc.. In order to assess the availability of these systems we developed two algorithms; one algorithm calculates the percentage uptime per day while another algorithm calculates the percentage downtime per hour. We also implemented a web interface so that users can view the results obtained from our analysis.",
        "watermark_text": "The availability of computer machines is an important element in the development , construction and operation of any program . The goal of this research was to develop a technique for evaluating the availability of a large number of SunOS / Solaries machines combining syslogd ( System Logging Daemon ) and wtmpx ( Windows Time Machine eXtender ) .This research has been carried out by collecting data from a setting of servers over a period of one year . A total of 1 , 000 , 000 data were collected during that time frame .These data have then been processed into a computer which contains information about each record such as timestamps , host title , service size etc . . In order to analyze the availability of these systems we developed two strategies ; one algorithm calculates the percentage uptime per month while another algorithm calculates the percentage downtime per hour .We additionally introduced a web application so that users can view the results derived from our analysis .",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "We study the entanglement between two atoms trapped inside an optical cavity, each interacting with one mode of the electromagnetic field. We consider both resonant and nonresonant interactions for different initial states of the system. In particular we show that it is possible to generate maximally entangled Bell-like states by using only local operations on the atomic subsystem. The results are obtained by solving numerically the Schrödinger equation describing the evolution of the system. Entanglement plays a crucial role in quantum information processing  1  . It has been shown  2  , however, that even if all parties involved share maximal entanglement at some point during their communication protocol they may not be able to perform any useful task due to decoherence effects  3  .\nIn this work we investigate how entanglement can be generated among two atoms trapped inside an open optical cavity  4  . Each atom interacts locally with its own photon mode which is coupled to another external photon mode via a mirror (see Fig.  1 ). This model describes many physical systems such as semiconductor microcavities  5  or cold atoms  6  . For example, in Ref.  7  it was proposed to use a Bose-Einstein condensate confined within a high-finesse Fabry-Perot cavity  8  to produce single photons  9  . These photons could then be used to entangle distant qubits  10  .",
        "watermark_text": "We explore the entanglement between two atoms trapped inside an optical cavity , each interacting with one mode of the electromagnetic field . We consider both resonant and nonresonant interactions for different initial states of the system .In particular we prove that it is easy to create maximally entangled Bell - like states by using only local operations on the atomic subsystem . The results are derived by solving numerically the Schrödinger equation explaining the evolution of the system .Entanglement plays a crucial role in quantum information processing 1 . It has been shown 2 , however , that even if all parties involved share maximal entanglement at some time during their transmission protocol they may not be possible to complete any useful job due to decoherence effects 3 .In this research we investigate how entanglement can be formed among two atoms trapped inside an open optical cavity 4 . Each electron interacts locally with its own photon mode which is linked to another external photon mode via a mirror ( see Fig .1 ) . This theory presents many physical structures such as semiconductor microcavities 5 or cold atoms 6 .For instance , in Ref . 7 it was suggested to use a Bose - Einstein condensate concentrated within a high - finesse Fabry - Perot cavity 8 to produce single photons 9 .These photons may then be used to entangle distant qubits 10 .",
        "ori-fast-z-score": 0.21566554640687682,
        "water-fast-z-score": 4.528976474544414
    },
    {
        "original_text": "We study the SLE (Schramm-Loewner Evolution) process for the scaling limit of interfaces between different phases in the two-dimensional Ising model with nearest-neighbor interactions on an arbitrary planar graph, and its generalization to higher dimensions. We show that the interface is described by a chordal Schramm-Löwner evolution if the underlying lattice has no loops or multiple edges; otherwise it is described by a radial Schramm-Löwner evolutions. The results are obtained using conformal field theory techniques. In particular we use the fact that the partition function of these models can be written as a correlation function of primary fields in some rational conformal field theories. This allows us to obtain explicit formulas for the probability distribution functions of various geometric quantities associated with the interfaces such as their winding numbers around vertices etc.. \nIntroduction\n\nThe Schramm-Loewner Evolutions (SLE)\nprocesses were introduced by Schramm  Sch00  , who showed that they provide a natural description of the scaling limits of interfaces in statistical mechanics systems at criticality. These processes have been studied extensively since then both theoretically and numerically. For example, see  KSS02, SS04a, SS04b, RS05, Sch06, CS07, KS08, KSV09, KM10, MS11, MZ12, BMS13, BS14, LW15, GKS16, GM17, GK18, HJ19, HK20, JPS20  . A comprehensive review of this subject may be found in  Smi01, Sta03, Joh10  .\nIn this work we consider the SLE process for the scaling limit in two dimensions of interfaces separating different phases in the following class of models:  Let G = (V, E) be any finite connected planar graph without loops or multiple edges. Consider the Ising model with nearest neighbor interaction defined on G. That is, let {σv}v∈V denote a collection of random variables taking values +1 and −1, where each σv represents the state of vertex v ∈ V . Then",
        "watermark_text": "We work the SLE ( Schramm - Loewner Evolution ) process for the scaling maximum of interfaces between various phases in the two - dimensional Ising model with nearest - neighbor interactions on an arbitrary planar graph , and its generalization to higher dimensions . We see that the interface is characterized by a chordal Schramm - Löwner evolution if the underlying lattice has no loops or multiple edges ; otherwise it is characterized by a radial Schramm - Löwner evolutions .The results are derived using conformal field model approaches . In particular we utilize the fact that the splitting function of these models can be written as a correlation function of primary fields in some rational conformal field theories .This enables us to obtain precise formulas for the probability distribution functions of several geometric variables identified with the interfaces such as their winding numbers around vertices etc . . Introduction The Schramm - Loewner Evolutions ( SLE ) processes were introduced by Schramm Sch00 , who demonstrated that they give a natural characterization of the scaling limits of interfaces in statistical mechanics systems at criticality . These mechanisms have been studied frequently since then both theoretically and numerically .For instance , see KSS02 , SS04a , SS04b , RS05 , Sch06 , CS07 , KS08 , KSV09 , KM10 , MS11 , MZ12 , BMS13 , BS14 , LW15 , GKS16 , GM17 , GK18 , HJ19 , HK20 , JPS20 . A full study of this subject may be found in Smi01 , Sta03 , Joh10 .In this research we define the SLE method for the scaling limit in two dimensions of interfaces separating different stages in the following category of models : Let G = ( V , E ) be any finite connected planar graph without loops or multiple edges . Consider the Ising model with nearest neighbor behavior defined on G . That is , let { σv } v∈V denote a collection of random vectors take values + 1 and −1 , where each σv represents the state of vertex v ∈ V .Then",
        "ori-fast-z-score": 1.3750477455423171,
        "water-fast-z-score": 6.875238727711585
    },
    {
        "original_text": "We present the results of an X-ray study of supernova remnant (SNR) G299.2-2.9 using data obtained with Chandra and XMM-Newton observatories. The SNR is located in the constellation Puppis at a distance of ~5 kpc, which corresponds to its angular size of about 30 arcmin. We find that the spectrum of this object can be described by two thermal components with temperatures T1=7×10^6 K and T2=2×10^6 K. In addition, we detect non-thermal emission above 10 keV. Using these parameters, we estimate the age of the SNR as t=4000 yr. This value agrees well with the characteristic time for the expansion of the shell into the surrounding medium. Based on our analysis, we conclude that the observed morphology of the SNR is consistent with the model of a spherical explosion expanding into a uniform interstellar medium.",
        "watermark_text": "We present the conclusion of an X - ray study of supernova remnant ( SNR ) G299 . 2 - 2 . 9 utilizing information obtained with Chandra and XMM - Newton observatories . The SNR is situated in the constellation Puppis at a distance of ~ 5 kpc , which corresponds to its angular height of about 30 arcmin .We see that the spectrum of this body can be described by two thermal parts with temperatures T1 = 7×10 ^ 6 K and T2 = 2×10 ^ 6 K . In addition , we identify non - temperature emission above 10 keV . Using these parameters , we estimate the age of the SNR as t = 4000 yr .This value agrees well with the typical moment for the advance of the shell into the nearby medium . Based on our analysis , we determine that the seen morphology of the SNR is compatible with the model of a spherical explosion expanding into a regular interstellar medium .",
        "ori-fast-z-score": -0.14002800840280097,
        "water-fast-z-score": 5.091168824543142
    },
    {
        "original_text": "The design and kinematics analysis of parallel kinematic machine tools (PKMTs) is presented in this work using kinetic-static performance criteria. The proposed approach considers the dynamic behavior of PKMTs during their operation, which has been neglected by previous works on PKMTs. In addition to the static stiffness matrix, the inertia properties are also considered for the evaluation of the overall dynamic response of PKMTs. A new method based on the concept of virtual joints is developed to calculate the mass distribution along each leg of the PKMT under consideration. This information can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis. Finally, two different PKMTs with three degrees-of-freedom per joint are designed and analyzed using the proposed methodology. It was found that the first PKMT exhibits better dynamic characteristics than its counterpart due to its lower natural frequencies and higher damping ratios.",
        "watermark_text": "The design and kinematics analysis of parallel kinematic machine tools ( PKMTs ) is detailed in this work using kinetic - static performance criteria . The proposed approach considers the dynamic behavior of PKMTs during their operation , which has been neglected by previous works on PKMTs .In addition to the static stiffness matrix , the inertia characteristics are also considered for the evaluation of the overall dynamic response of PKMTs . A modern algorithm based on the idea of virtual joints is developed to estimate the mass distribution along each leg of the PKMT under consideration .This knowledge can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis . Finally , two different PKMTs with three degrees - of - independence per joint are built and evaluated using the suggested methodology .It was shown that the first PKMT displays better dynamic characteristics than its predecessor due to its lower natural bandwidth and larger damping ratios .",
        "ori-fast-z-score": 1.6059101370939322,
        "water-fast-z-score": 5.27656187902292
    },
    {
        "original_text": "The geochemical behavior of uranium (U) and thorium (Th), which are radioactive elements, is discussed in relation to their influence on the origin and evolution of the crust of earth as well as biological evolution.  The chemical properties of these two elements are similar; however, they have different physical characteristics that affect how they behave geologically.  Uranium has an atomic number of 92 with a half-life of 4.5 billion years while thorium has an atomic number of 90 with a half life of 1.4 billion years.   Both elements occur naturally throughout the Earth s crust but at varying concentrations depending upon the rock type.  They can be found in igneous rocks such as granite or basalt where they form minerals like uranite or thorite respectively.  These minerals may also contain other trace metals including lead, silver, gold, copper, zinc, arsenic, selenium, molybdenum, cadmium, mercury, bismuth, antimony, tellurium, cobalt, nickel, manganese, iron, vanadium, chromium, tungsten, titanium, zirconium, niobium, tantalum, hafnium, rhenium, osmium, iridium, platinum, palladium, rhodium, ruthenium, and iridium.  Uranium and thorium are also present in sedimentary rocks such as sandstone, shale, limestone, dolomite, gypsum, anhydrite, salt beds, and evaporites.  Sedimentary rocks are formed by weathering processes when water erodes...",
        "watermark_text": "The geochemical behavior of uranium ( U ) and thorium ( Th ) , which are radioactive elements , is mentioned in relation to their influence on the origin and evolution of the crust of earth as well as biological evolution . The chemical properties of these two compounds are comparable ; however , they have different biological traits that affect how they react geologically .Uranium has an atomic number of 92 with a half - life of 4 . 5 billion decades while thorium has an atomic number of 90 with a half lifetime of 1 . 4 billion decades . Both compounds occur readily throughout the Earth s crust but at different amounts depending upon the stone type .They can be found in igneous rocks such as granite or basalt where they create minerals like uranite or thorite respectively . These rocks could also contain other trace metals including lead , silver , gold , copper , zinc , arsenic , selenium , molybdenum , cadmium , mercury , bismuth , antimony , tellurium , cobalt , nickel , manganese , iron , vanadium , chromium , tungsten , titanium , zirconium , niobium , tantalum , hafnium , rhenium , osmium , iridium , platinum , palladium , rhodium , ruthenium , and iridium .Uranium and thorium are also occur in sedimentary formations such as sandstone , shale , marble , dolomite , gypsum , anhydrite , salt beds , and evaporites . Sedimentary stones are created by weathering reactions when water erodes . . .",
        "ori-fast-z-score": -1.4814874939752933,
        "water-fast-z-score": 4.216541329006604
    },
    {
        "original_text": "The response prediction of structural system subject to earthquake motions is very important for the design and construction of buildings in seismic areas, especially when it comes to high-rise building structures. In this study, an artificial neural network (ANN) model was developed by using data obtained through nonlinear dynamic analysis on reinforced concrete frame structure subjected to earthquake ground motion records. The ANN model consists of three layers; input layer, hidden layer with 10 neurons, output layer with one neuron representing maximum inter-story drift ratio. Input variables used are peak ground acceleration, duration time, number of stories, story height, mass density per unit floor area, damping coefficient, yield strength of steel bar, elastic modulus of steel bar, shear wall stiffness, and moment capacity of beam-column joint. To verify the accuracy of the proposed ANN model, results predicted by the ANN were compared with those calculated by nonlinear dynamic analysis program. It can be concluded that the ANN model has good performance in predicting the maximum inter-story drift ratios under various earthquake ground motions.",
        "watermark_text": "The behavior analysis of structural structure exposed to earthquake motions is very important for the design and build of structures in seismic areas , particularly when it comes to large - rising building structures . In this study , an synthetic neural network ( ANN ) model was developed by using data derived through nonlinear dynamic analysis on concrete cement frame building exposed to earthquake ground motion records .The ANN system contains of three layers ; input layer , hidden surface with 10 neurons , output layer with one neuron representing maximum inter - story drag ratio . Input variables utilized are peak ground acceleration , duration time , number of floors , story height , mass density per unit floor area , damping coefficient , yield strength of steel bar , elastic modulus of steel bar , shear floor stiffness , and moment capacity of beam - column joint .To verify the accuracy of the suggested ANN theory , results predicted by the ANN were compared with those estimated by nonlinear dynamic analysis project . It can be assumed that the ANN theory has good success in predicting the maximum inter - story drag ratios under various earthquake ground motions .",
        "ori-fast-z-score": 1.0536089137432665,
        "water-fast-z-score": 6.800566625070174
    },
    {
        "original_text": "We present the results on the interband, intraband and excitonic transitions for Si and Ge nanocrystals (NCs) embedded into Al2O3 matrix by using first-principles calculations based on density functional theory within local-density approximation. The NC size is varied between 1 nm to 5 nm with an interval of 0.5 nm. We find that the optical gap decreases as we increase the NC size due to quantum confinement effect. In addition, we observe that the lowest energy peak shifts towards higher energies when increasing the NC size which can be attributed to the surface states. Furthermore, our calculated results show that the oscillator strength increases significantly at smaller sizes while it decreases rapidly at larger sizes. Finally, we also investigate the influence of strain on the electronic structure of these systems. Our findings are expected to provide useful information about the design of optoelectronic devices such as solar cells or photodetectors. \n \n Keywords: Silicon Nanocrystal, Germanium Nanocrystal, Optical properties",
        "watermark_text": "We present the conclusion on the interband , intraband and excitonic transitions for Si and Ge nanocrystals ( NCs ) integrated into Al2O3 matrix by using first - principles measurements based on density functional theory within local - density algorithms . The NC size is varied between 1 nm to 5 nm with an interval of 0 . 5 nm .We see that the optical gap decreases as we increase the NC size owing to quantum confinement phenomenon . In addition , we determine that the lowest energy peak changes towards higher energies when increasing the NC size which can be due to the surface states .Furthermore , our calculated results show that the oscillator strength changes significantly at lower dimensions while it varies dramatically at larger dimensions . Finally , we also investigate the impact of strain on the electronic stability of these systems .Our findings are expected to provide useful details about the development of optoelectronic elements such as sun cells or photodetectors . Keywords : Silicon Nanocrystal , Germanium Nanocrystal , Optical properties",
        "ori-fast-z-score": -0.23249527748763857,
        "water-fast-z-score": 5.114896104728048
    },
    {
        "original_text": "We present the results of our study on super star clusters (SSCs) in which we have found that SSCs can be divided into two categories, namely, those having a single mode and those having a double-mode solution for their density profiles. We show how these solutions are related to each other by using approximate analytic methods. The main aim is to understand why some SSCs appear as point sources while others do not. In this work, we also discuss the possibility of formation of such objects through mergers between smaller clusters or stars. Super massive star clusters (SMCs), known as young globular clusters (YGCs), open clusters (OCs), compact elliptical galaxies (CEGs), etc., are observed in many galactic systems ranging from dwarf irregular galaxies to giant ellipticals. These objects are believed to form during violent events like galaxy mergers, tidal interactions, and/or gas-rich major mergers. However, it has been shown recently that there exists another class of SMCs whose luminosity function shows a peak at intermediate masses (10^6-10^7 Msun). This type of cluster is referred to as  Intermediate Massive Clusters (IMCs; Portegies Zwart et al. (2010)). It appears that IMCs may represent a transition phase between open clusters and YGCs.",
        "watermark_text": "We present the conclusion of our research on super star clusters ( SSCs ) in which we have discovered that SSCs can be grouped into two genres , namely , those having a single mode and those having a twin - mode solution for their density characteristics . We see how these solutions are related to each other by using numerical analytic techniques .The main aim is to explain why some SSCs appear as point sources while many do not . In this research , we also discuss the prospect of formation of such objects through mergers between smaller clusters or stars .Super massive star clusters ( SMCs ) , known as early globular complexes ( YGCs ) , close complexes ( OCs ) , compact elliptical galaxies ( CEGs ) , etc . , are observed in many galactic structures ranging from giant irregular clusters to massive ellipticals . These structures are said to form during violent reactions like galaxy mergers , tidal interactions , and / or gas - rich major mergers .However , it has been shown lately that there exists another class of SMCs whose luminosity function shows a peak at intermediate masses ( 10 ^ 6 - 10 ^ 7 Msun ) . This kind of cluster is referred to as Intermediate Massive Clusters ( IMCs ; Portegies Zwart et al .( 2010 ) ) . It suggested that IMCs might represent a transfer stage between open complexes and YGCs .",
        "ori-fast-z-score": -1.58999682000954,
        "water-fast-z-score": 5.270462766947299
    },
    {
        "original_text": "We present an analysis of the temperature dependence of thermally stimulated luminescent (TSL) glow curves in terms of the nonstationary electron-phonon relaxation theory, which does not assume that the system is close to equilibrium at any time during its evolution.  We show how this approach can be used for extracting information about the phonon spectrum and the density of states of charge carriers from TSL data obtained on different types of materials. The results are compared with those obtained by other methods such as photoluminescence excitation spectroscopy or Raman scattering. In particular we demonstrate that our method allows one to determine the energy gap between the conduction band minimum and valence band maximum in semiconductors. This work was supported by Russian Science Foundation grant No. 14-50-00040. DOI: 10.1063/1.4935190 \nI. INTRODUCTORY REMARK\nThe study of luminescence phenomena has been attracting considerable attention over many years because it provides valuable information about electronic structure and optical properties of solids  1  . Thermal stimulation luminescence (TSL), also known as optically stimulated luminescence (OSL), is particularly useful since it enables us to probe the distribution function of electrons excited into the conduction band  2  .\nIn recent decades there have been numerous attempts to develop theoretical models describing various aspects of luminescence processes  3  , including thermal stimulation luminescence  4  -  8  . However, most of these works were based on the assumption that the system under consideration is always close to equilibrium  9  . As a result they cannot describe correctly some important features observed experimentally  10  . For example, the shape of the TSL glow curve depends strongly on the type of material  11  : while in insulators it usually exhibits a single peak  12  , in metals it often consists of several peaks  13  . Moreover, even within the same class of materials, e.g., semiconductor crystals  14  , the number of peaks may vary depending on the doping level  15  . These observations cannot be explained using existing theories  16  .",
        "watermark_text": "We present an assessment of the temperature dependence of thermally stimulated luminescent ( TSL ) glow curves in terms of the nonstationary electron - phonon relaxation hypothesis , which does not assume that the system is close to equilibrium at any time during its evolve . We see how this methodology can be used for extracting information about the phonon spectrum and the density of states of charge carriers from TSL information obtained on various types of substances .The results are compared with those achieved by other methods such as photoluminescence excitation spectroscopy or Raman absorption . In particular we prove that our technique permits one to estimate the electricity gap between the conduction band minimum and valence band maximum in semiconductors .This project was supported by Russian Science Foundation gift No . 14 - 50 - 00040 .DOI : 10 . 1063 / 1 . 4935190 I . INTRODUCTORY REMARK The investigation of luminescence effects has been drawing tremendous attention over numerous years because it gives valuable info about electronic properties and electronic properties of solids 1 .Thermal stimulation luminescence ( TSL ) , sometimes called as optically stimulated luminescence ( OSL ) , is especially useful since it allows us to probe the distribution behavior of electrons excited into the conduction band 2 . In recent generations there have been numerous attempts to develop conceptual models explaining various parts of luminescence events 3 , notably heat stimulation luminescence 4 - 8 .However , most of these works were based on the assumption that the process under consideration is usually nearly to equilibrium 9 . As a result they cannot describe correctly some important features discovered experimentally 10 .For instance , the form of the TSL flicker curve varies strongly on the kind of material 11 : while in insulators it generally exhibits a single peak 12 , in metals it often consists of several peaks 13 . Moreover , even within the same category of substances , e . g . , semiconductor crystals 14 , the number of peaks may differ depending on the doping level 15 .These measurements cannot be understood using existing models 16 .",
        "ori-fast-z-score": -2.3664319132398464,
        "water-fast-z-score": 7.437357441610946
    },
    {
        "original_text": "We introduce the notion of intersection bodies in arbitrary dimensions, generalizing the classical concept for dimension two to higher dimensions. We show that intersection bodies are characterized by their Fourier transforms which we call generalized cosine transforms (GCT). The GCTs can be used as an alternative tool to study intersection bodies. In particular, we prove that intersection bodies have positive volume if and only if they are convex. This is done using a new characterization of intersection bodies via their support functions. Finally, we give some examples of intersection bodies in three dimensions. Keywords: Intersection body; Support function; Convexity; Volume; Fourier transform; Three-dimensional space. 1 Introduction Let K n denote the set of all origin-symmetric convex bodies in R n . For any K ∈ K n , let V(K) = |K|/|B n 2 | where | · | denotes Lebesgue measure on R n . Then V : K n →  0, 1  is called the volume functional. A compactly supported continuous function f : S n−1 → C with unit integral will be called a spherical harmonic of degree m. If f has no zeros then it is uniquely determined up to multiplication by a constant. It follows immediately that every spherical harmonic of degree m satisfies the following properties:\n(1) |f (x)| ≤ 1; (2) f (−x) = f (x), x ∈ S n−1 ; (3) (Spherical harmonics form an orthonormal basis.) Definition 1. An origin-symmetric convex body K ∈ K n is said to be an intersection body if there exists a non-negative real number λ such that its surface area measure σ K satisfies",
        "watermark_text": "We introduce the notion of junction bodies in arbitrary dimensions , generalizing the classical concept for dimension two to higher dimensions . We see that intersection bodies are characterized by their Fourier functions which we call generalized cosine transforms ( GCT ) .The GCTs can be used as an additional tool to study junction bodies . In particular , we prove that intersection bodies have positive volume if and only if they are convex .This is accomplished using a new definition of junction bodies via their support functions . Finally , we give some examples of intersection bodies in three dimensions .Keywords : Intersection body ; Support function ; Convexity ; Volume ; Fourier integral ; Three - dimensional space . 1 Introduction Let K n denote the group of all origin - symmetric convex body in R n .For any K ∈ K n , let V ( K ) = | K | / | B n 2 | where | · | indicates Lebesgue measure on R n . Then V : K n → 0 , 1 is called the volume functional .A compactly backed continuous function f : S n−1 → C with unit integral will be called a spherical harmonic of degree m . If g has no zeros then it is uniquely determined up to multiplication by a constant . It follows instantly that every spherical harmonic of degree m satisfies the following properties : ( 1 ) | h ( x ) | ≤ 1 ; ( 2 ) f ( −x ) = g ( x ) , x ∈ S n−1 ; ( 3 ) ( Spherical harmonics form an orthonormal basis . )Definition 1 . An origin - symmetric convex body K ∈ K n is said to be an intersection body if there exists a non - negative real number λ such that its surface area measure σ K satisfies",
        "ori-fast-z-score": 0.19069251784911848,
        "water-fast-z-score": 3.8138503569823694
    },
    {
        "original_text": "In this work, we study the problem of clustering co-occurrences of maximal frequent patterns (MFP) in streams. We propose an algorithm that clusters MFPs based on their occurrences and then uses these clusters to build a compact representation for each pattern. The proposed approach is efficient both in terms of space consumption as well as time required to process new data points. Our experimental results show that our method outperforms state-of-the-art algorithms by up to two orders of magnitude while achieving high accuracy. In addition, it can be easily parallelized using existing frameworks such as MapReduce or Spark. Keywords: Data stream mining, Cluster analysis, Frequent itemset mining, Association rule learning, Time series prediction. 1 Introduction Mining large volumes of streaming data has become increasingly important over recent years due to its wide range of applications including sensor networks  20, 21  , social media analytics  22  , fraud detection  23  , network intrusion detection  24  , etc.. However, processing massive amounts of streaming data poses several challenges since traditional batch-based approaches are not applicable anymore  25  . For example, if one wants to detect anomalies in a continuous flow of tweets, he needs to continuously monitor all incoming messages and identify those which deviate significantly from normal behavior  26  .\nTo address these issues, researchers have developed various techniques for analyzing data streams  7, 8, 27  . An emerging area within data stream mining focuses on discovering interesting patterns from data streams  28  . A common task in this context is finding frequent items/patterns in data streams  29  . Another popular research direction involves identifying correlations between different attributes  30  . These tasks are often performed jointly with classification  31  and/or regression  32  problems.",
        "watermark_text": "In this research , we study the question of clustering co - occurrences of maximal frequent patterns ( MFP ) in streams . We suggest an algorithm that clusters MFPs based on their occurrences and then uses these clusters to build a compact form for each pattern .The proposed approach is efficient both in terms of space requirements as well as space required to collect new data sets . Our research results show that our technique outperforms state - of - the - art algorithms by up to two orders of magnitude while reaching large accuracy .In addition , it can be easily parallelized using existing frameworks such as MapReduce or Spark . Keywords : Data stream analysis , Cluster processing , Frequent itemset searching , Association control learning , Time series modeling .1 Introduction Mining huge volumes of streaming information has become rapidly interesting over recent years owing to its large variety of applications notably sensor networks 20 , 21 , social media analytics 22 , fraud detection 23 , network intrusion detection 24 , etc . . However , processing massive sums of streaming information poses various challenges since traditional batch - based methods are not applicable today 25 .For instance , if one wants to identify anomalies in a rapid stream of tweets , he requires to constantly watch all outgoing messages and locate those which deviate substantially from normal behavior 26 . To address these problems , researchers have developed various methods for studying data loops 7 , 8 , 27 .An developing region within information stream mined focuses on discovering interesting trends from information streams 28 . A prevalent problem in this environment is identifying significant items / patterns in data streams 29 .Another common study trend includes identifying correlations between various qualities 30 . These tasks are often worked collectively with classification 31 and / or regression 32 questions .",
        "ori-fast-z-score": -1.655211777204736,
        "water-fast-z-score": 9.26918595234652
    },
    {
        "original_text": "We present the results of an extensive study of gas dynamics, star formation activity, dust extinction, stellar populations, and black hole accretion properties for a strongly lensed galaxy (A1689-zD1) at redshift 3.07. The lensing magnification factor is ~30Â±5. We use deep near-infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high spatial resolution. Our observations reveal that this system consists of two merging galaxies separated by 1 kpc along the line-of-sight. One of these components shows strong HÎ² emission indicative of active galactic nuclei (AGN). This AGN component has a mass of âˆ¼10^9 M_sol , which corresponds to a supermassive black hole with a mass of âˆ½â€“1 Ã— 10^8 M_sol . Using our spatially resolved measurements we find evidence for intense nuclear starbursts on scales as small as 100 pc.",
        "watermark_text": "We present the conclusion of an extensive research of gas evolution , star formation activity , dust disappearance , stars populations , and dark hole accretion properties for a strongly lensed galaxy ( A1689 - zD1 ) at redshift 3 . 07 . The lensing magnification factor is ~ 30Â±5 .We use deep near - infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high visual resolution . Our observations show that this scheme consists of two joining galaxies linked by 1 kpc along the line - of - view .One of these constituents exhibits strong HÎ² emission indicative of active galactic nuclei ( AGN ) . This AGN component has a mass of [UNK] ^ 9 M _ sol , which corresponds to a supermassive black hole with a mass of [UNK] “ 1 [UNK] — 10 ^ 8 M _ sol .Using our spatially resolved sensors we find proof for intense nuclear starbursts on sizes as low as 100 pc .",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 5.505585837114527
    },
    {
        "original_text": "The ultimate fate of the universe is one of the most important questions in physics and cosmology today, but it has been difficult to answer because quantum mechanics (QM) cannot be applied directly to macroscopic systems such as the whole universe.  In this talk I will present an approach that allows us to use QM to study the evolution of the universe on all scales by applying it only to small subsystems within the universe.   This method can also be used to calculate the probability distribution for the time at which the universe ends its existence. The results are consistent with current observations and provide new insights into how the universe may end up. For example, we find that there is a finite probability that the universe will expand forever without ever ending or collapsing. We also show that if the universe does collapse then it must do so before 10^(10^28) years have passed since the Big Bang. Finally, we discuss some possible implications of these results for the future of humanity.",
        "watermark_text": "The ultimate fate of the universe is one of the most important questions in science and cosmology today , but it has been difficult to ask because physics dynamics ( QM ) unable be applied directly to macroscopic systems such as the whole universe . In this talk I will present an perspective that enables us to use QM to study the evolution of the universe on all scales by application it only to small subsystems within the universe .This method can also be used to estimate the probability distribution for the period at which the universe ends its existence . The results are compatible with current observations and bring fresh insights into how the universe might end up .For instance , we find that there is a finite probability that the universe will expand forever without ever ending or falling . We also prove that if the universe does explode then it must do so before 10 ^ ( 10 ^ 28 ) years have passed since the Big Bang .Finally , we explain some possible possibilities of these results for the tomorrow of humanity .",
        "ori-fast-z-score": 2.5927248643506746,
        "water-fast-z-score": 7.607674567748488
    },
    {
        "original_text": "We study the evolution of cosmic strings in an expanding universe, focusing on their formation mechanism and subsequent growth. We show that cosmic strings can form when magnetic fields are trapped inside overdense regions during inflation. The resulting network consists of many small loops which evolve into larger ones through gravitational radiation emission. This process is similar to the one proposed for electroweak strings formed at phase transitions after inflation. However, we find that the loop distribution function has a different shape than previously assumed. In particular, it contains more large loops with sizes comparable to the Hubble radius today. These loops may be detectable as stochastic backgrounds of gravitational waves or gamma rays. Cosmic strings have been predicted to exist since the early 1980s  1, 2  . They could arise naturally if there were extra dimensions beyond those observed so far  3  , or they might be produced at symmetry breaking phase transitions  4  .\nCosmic strings would produce observable effects such as gravitational lensing  5  , CMB anisotropies  6  , and primordial black holes  7, 8  . Despite this interest, no direct detection of cosmic strings has yet been made  9  . One reason why cosmic strings remain elusive is because they are expected to be very light (with masses less than $10^{-16}eV$)  10  . Another problem is that cosmic strings are not stable objects but rather decay rapidly via gravitational radiation  11  . Therefore, any observational evidence must come indirectly from the products of cosmic string decays  12  .\nIn order to make predictions about possible observations, cosmological simulations need to be performed  13  . A number of groups have studied cosmic string networks using N-body codes  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64",
        "watermark_text": "We research the evolution of universe strings in an increasing universe , concentrating on their development process and subsequent proliferation . We suggest that cosmic strings can form when magnetic waves are locked inside overdense regions during inflation .The resulting system consists of several small curves which turn into larger ones through gravity radiation emission . This process is related to the one proposed for electroweak strings generated at phase transitions after inflation .However , we find that the loop distribution map has a different shape than previously predicted . In particular , it contains more massive loops with sizes comparable to the Hubble diameter today .These patterns could be detectable as stochastic backgrounds of gravitational waves or gamma radiation . Cosmic strings have been predicted to arise since the early 1980s 1 , 2 .They could occur readily if there were extra dimensions beyond those observed so far 3 , or they may be formed at symmetry breaking phase transitions 4 . Cosmic strings would create observable effects such as gravity lensing 5 , CMB anisotropies 6 , and primordial black holes 7 , 8 .Despite this interest , no close observation of universe strings has yet been achieved 9 . One reason why cosmic strings remain elusive is because they are expected to be very light ( with masses fewer than $ 10 ^ { - 16 } eV $ ) 10 .Another question is that cosmic strings are not stable objects but rather decay frequently via gravitational rays 11 . Therefore , any observational evidence needs go indirectly from the products of cosmic string decays 12 .In order to make predictions about likely observations , cosmological simulations need to be performed 13 . A variety of groups have researched cosmic string systems use N - body symbols 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64",
        "ori-fast-z-score": 0.7689218919450849,
        "water-fast-z-score": 8.342314001435737
    },
    {
        "original_text": "We consider the effective inverse spectral problems (EISP) associated with rational Lax matrices, which are generalizations of classical EISP in terms of Jacobi matrices. We show that these new EISPs can be reduced to some special cases of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix. As examples we study two classes of rational Lax matrices: one is related to the Toda lattice hierarchy and another is connected with the modified Volterra lattice hierarchy. In particular, we give a complete description on all solutions of the corresponding EISPs. Finally, as applications of our results, we present several interesting properties about the spectra of these rational Lax matrices. The research was supported by NSFC under Grant No.11571040. Keywords: Effective inverse spectral problem; Rational Lax matrices; Toda lattice hierarchy; Modified Volterra lattice hierarchy",
        "watermark_text": "We consider the effective inverse spectral questions ( EISP ) associated with rational Lax matrices , which are generalizations of classical EISP in terms of Jacobi matrices . We see that these new EISPs can be reduced to some general cases of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix .As instance we study two groups of rational Lax matrices : one is related to the Toda lattice hierarchy and another is linked with the modified Volterra lattice hierarchy . In particular , we give a complete overview on all solutions of the associated EISPs .Finally , as applications of our results , we present several interesting properties about the spectra of these rational Lax matrices . The research was supported by NSFC under Grant No . 11571040 .Keywords : Effective inverse spectral problem ; Rational Lax matrices ; Toda lattice hierarchy ; Modified Volterra lattice hierarchy",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 2.6887744785908154
    },
    {
        "original_text": "We report on the detection by Swift/BAT and Konus-Wind of gamma-ray burst (GRB) 060927, which is one of only two events detected with redshifts greater than five to date.  The redshift was determined using optical spectroscopy obtained with the Very Large Telescope in Chile within three hours after the burst trigger time.  We find that this event has an extremely hard spectrum, similar to other high-redshift bursts observed previously.  Using our current understanding of the physics behind these phenomena we can estimate the total energy released during the prompt emission phase of the burst to be ~10^53 erg.  This value is comparable to or larger than the energies released by some supernovae.  If confirmed, it would make GRB 060927 the most energetic event ever recorded.  In addition, if the host galaxy mass function evolves similarly to what is seen locally, then the progenitor system responsible for producing such an energetic explosion must have been hosted by a very massive galaxy.  These results are consistent with theoretical predictions made about the progenitors of high-z GRBs.  Finally, we discuss how future observations of this object may help us understand the end of cosmic reionization.",
        "watermark_text": "We report on the discovery by Swift / BAT and Konus - Wind of gamma - ray burst ( GRB ) 060927 , which is one of only two events discovered with redshifts greater than five to date . The redshift was calculated using optical spectroscopy acquired with the Very Large Telescope in Chile within three hours after the explosion trigger time .We see that this event has an incredibly hard range , comparable to other high - redshift bursts observed previously . Using our contemporary understanding of the physics behind these phenomena we can calculate the total energy released during the prompt emission stage of the explosion to be ~ 10 ^ 53 erg .This value is analogous to or larger than the energies released by some supernovae . If confirmed , it would call GRB 060927 the most intense phenomenon ever recorded .In addition , if the host star mass distribution evolves likewise to what is seen locally , then the progenitor system responsible for producing such an energetic explosion could have been hosted by a very huge galaxy . These conclusions are compatible with theoretical calculations made about the progenitors of high - z GRBs .Finally , we explain how possible measurements of this body may assist us explain the end of universe reionization .",
        "ori-fast-z-score": -0.6546536707079772,
        "water-fast-z-score": 6.764754597315764
    },
    {
        "original_text": "We report on the first simultaneous infrared (IR) and X-ray observations of Sgr A*, made with the Chandra X-Ray Observatory and the Spitzer Space Telescope in 2007-2008. We find that the IR emission is consistent with being produced by dust heated to temperatures between 100 K and 1000 K; this temperature range corresponds to an observed flux density at 8 microns ranging from 0.1 mJy to 1 Jy. The spectral index of the IR emission does not change significantly during these variations. This result suggests that the physical conditions within the emitting region are relatively constant over time scales as short as one month. These results also suggest that the IR emission may be dominated by optically thin thermal bremsstrahlung rather than synchrotron radiation. \n \n Keywords: black hole physics, infrared astronomy, radio source variability, space telescopes, X-ray astronomy \n \n \n \n Black holes have been predicted to produce intense electromagnetic fields near their event horizons. However, direct observational evidence has remained elusive because of the extreme environment surrounding such objects. One possible way to detect such fields would be through the detection of polarized light emitted close to the horizon. Another possibility involves detecting changes in the spectrum or intensity of the accretion flow onto the black hole itself. Such changes could occur if the magnetic field lines threading the disk were twisted into helical shapes due to differential rotation. If so, they can act like antennae which amplify any incoming waves along them. As a consequence, the local plasma frequency will increase, causing the plasma to become more opaque to lower-frequency waves but less opaque to higher frequencies. Thus, we expect the spectrum of the emission to steepen toward longer wavelengths when the system becomes brighter.",
        "watermark_text": "We report on the first simultaneous infrared ( IR ) and X - ray observations of Sgr A * , made with the Chandra X - Ray Observatory and the Spitzer Space Telescope in 2007 - 2008 . We see that the IR emission is consistent with being produced by dust cooled to temperatures between 100 K and 1000 K ; this heat range corresponds to an seen flux concentration at 8 microns ranging from 0 . 1 mJy to 1 Jy .The spectral index of the IR emission does not change considerably during these changes . This result suggests that the physical conditions within the emitting area are fairly stable over time ranges as short as one month .These data therefore suggest that the IR emission may be dominated by optically thin thermal bremsstrahlung instead than synchrotron emission . Keywords : brown hole physics , infrared astronomy , television source variability , space telescopes , X - ray observations Black holes have been predicted to produce intense gravitational waves near their event horizons .However , direct observational evidence has remained elusive because of the severe environment neighboring such objects . One likely way to identify such fields might be through the observation of polarized light emitted far to the horizon .Another possibility requires detecting changes in the spectrum or intensity of the accretion flow onto the dark hole itself . Such changes could occur if the magnetic field lines threading the disk were twisted into helical shapes due to differential rotation .If so , they can operate like antennae which amplify any incoming signals along them . As a consequence , the local plasma frequency will expand , forcing the plasma to become more opaque to smaller - frequency waves but less opaque to higher frequencies .Thus , we expect the spectrum of the emission to steepen toward longer wavelengths when the system gets stronger .",
        "ori-fast-z-score": 1.153563462240948,
        "water-fast-z-score": 7.659922885032927
    },
    {
        "original_text": "We study the problem of finding an optimal schedule for data transmission over multiple channels with interference constraints, where each channel is assigned to one transmitter-receiver pair and transmissions on different pairs are subject to mutual interference. We consider two models: (i) The first model assumes that all transmitters have fixed power levels. (ii) In the second model we assume that transmitters can adjust their powers dynamically. For both cases, we show how to find an optimal schedule by solving a sequence of linear programs. Our results hold even if there exists only one receiver per transmitter. This work was supported by NSF grant CCF-0430018. 1 Introduction Wireless networks consist of many nodes communicating via radio signals. Each node has limited range and thus cannot communicate directly with every other node. Instead, it communicates indirectly through intermediate nodes called relays or routers. A fundamental question in this context is: How should these relays be placed?",
        "watermark_text": "We explore the question of finding an appropriate schedule for information transmission over multiple channels with interference constraints , where each channel is allotted to one transmitter - receiver set and signals on separate pairs are subject to mutual interference . We consider two models : ( i ) The first theory requires that all transmitters have fixed power rates .( ii ) In the second theory we suppose that transmitters can adjust their powers dynamically . For both cases , we show how to find an appropriate schedule by solving a sequence of linear programs .Our results hold even if there exists only one receiver per transmitter . This work was supported by NSF grant CCF - 0430018 .1 Introduction Wireless networks consist of several nodes communicating via radio signals . Each node has restricted range and therefore cannot transmit directly with every other node .Instead , it communicates indirectly through intermediate nodes termed relays or routers . A basic issue in this situation is : How should these relays be placed ?",
        "ori-fast-z-score": -1.0256451881367414,
        "water-fast-z-score": 3.623286509262706
    },
    {
        "original_text": "We have studied by means of molecular dynamics simulations how the dynamic behavior of silver atoms deposited on gold (100) is affected when the substrate temperature and the coverage are varied in such a way that the average number of nearest neighbors per atom changes between 1 to 4. We find that, for low coverages, the system behaves as if it were made up of isolated particles with no interaction among them. However, at higher coverages we observe collective effects which lead to the formation of ordered structures. The results obtained show that these structures can be classified into two different categories depending on whether they are formed by one or more layers of silver atoms. In particular, we found that the structure of the first layer depends strongly on the substrate temperature while the second layer shows only small variations. Finally, our calculations indicate that the third layer forms a disordered arrangement of silver atoms. This work was supported by DGESIC under project PB98-0443-C02-01",
        "watermark_text": "We have researched by means of molecular dynamics simulations how the dynamic behavior of silver atoms deposited on gold ( 100 ) is affected when the substrate temperature and the coverage are varied in such a way that the average number of nearest neighbors per atom shifts between 1 to 4 . We see that , for low coverages , the system behaves as if it were made up of isolated molecules with no activity among them .However , at higher coverages we study collective effects which lead to the formation of ordered systems . The results collected show that these structures can be categorized into two different categories depending on whether they are created by one or more bands of silver atoms .In particular , we reported that the composition of the first layer relies highly on the substrate temperature while the second layer exhibits only tiny variations . Finally , our calculations suggest that the third layer makes a disordered arrangement of silver atoms .This project was supported by DGESIC under contract PB98 - 0443 - C02 - 01",
        "ori-fast-z-score": 1.2701705922171767,
        "water-fast-z-score": 6.1942248145051675
    },
    {
        "original_text": "We study the fractional charge and statistics of elementary excitations in quantum spin systems with frustration, using exact diagonalization techniques for small clusters up to 12 sites. We find that the ground state is always gapped and has no degeneracy. The elementary excitations are fractionally charged fermions or bosons depending on whether the system is antiferromagnetic (AF) or ferromagnetic (F). In AF cases we also observe neutral fermionic excitations which carry zero electric charge but have nontrivial braiding properties. These results can be understood by mapping our models onto effective lattice gauge theories where the elementary excitations correspond to particles carrying flux quanta. Our work provides an explicit example of how fractional charges emerge naturally as topological defects in strongly correlated electronic materials. Introduction:-The discovery of high temperature superconductivity in copper oxide compounds  1  , together with other exotic phenomena such as colossal magnetoresistance  2  , non-Fermi liquid behavior  3  etc., has led to renewed interest in understanding the physics of strongly interacting electrons. One of the most important open questions concerns the nature of the elementary excitations responsible for these novel behaviors  4  . It was suggested early on  5  that the elementary excitations may be described by some kind of collective modes known as spin waves  6  . However it soon became clear  7, 8  that this description fails at low energies due to strong electron correlations. More recently there has been considerable progress towards developing theoretical descriptions based on new concepts like fractionalized quasiparticles  9  , emergent gauge fields  10  , and topological order  11  .\nIn particular, recent experiments  12  suggest that the elementary excitations in the cuprates might indeed be described by some form of fractionalized quasiparticle  13  . This raises many interesting questions about their physical properties including their charge  14  , statistics  15  , and interactions  16  . Unfortunately, despite enormous efforts  17  , a complete microscopic theory describing all these aspects remains elusive  18  . A promising approach involves studying simplified model Hamiltonians  19, 20  whose low-energy limit captures essential features of the original problem  21  .",
        "watermark_text": "We research the fractional charge and statistics of primary excitations in particle spin systems with frustration , using accurate diagonalization techniques for little complexes up to 12 locations . We see that the ground state is usually gapped and has no degeneracy .The elementary excitations are fractionally charged fermions or bosons depending on whether the system is antiferromagnetic ( AF ) or ferromagnetic ( F ) . In AF instances we also observe neutral fermionic excitations which carry zero electric charge but have nontrivial braiding properties .These data can be understood by map our models onto effective lattice gauge theories where the elementary excitations relate to particles carrying flux quanta . Our research provides an explicit instance of how fractional charges emerge readily as topological flaws in highly correlated electronic materials .Introduction : - The observation of high heat superconductivity in copper oxide molecules 1 , combined with other exotic processes such as colossal magnetoresistance 2 , non - Fermi solid behavior 3 etc . , has led to renewed concern in understanding the physics of highly bonding electrons . One of the most important open questions concerns the nature of the elementary excitations responsible for these novel behaviors 4 .It was suggested early on 5 that the elementary excitations might be described by some kind of collective modes referred as spin waves 6 . However it soon became clear 7 , 8 that this description fails at low energies due to large electron correlations .More recently there has been substantial development towards developing theoretical descriptions based on new concepts like fractionalized quasiparticles 9 , emergent gauge fields 10 , and topological order 11 . In particular , recent experiments 12 suggest that the elementary excitations in the cuprates might actually be described by some kind of fractionalized quasiparticle 13 .This poses various exciting questions about their natural characteristics notably their charge 14 , statistics 15 , and interactions 16 . Unfortunately , despite enormous efforts 17 , a complete microscopic theory explaining all these aspects remains elusive 18 .A good approach requires studying simplified theory Hamiltonians 19 , 20 whose low - energy maximum reflects vital features of the previous problem 21 .",
        "ori-fast-z-score": 0.7905694150420948,
        "water-fast-z-score": 7.533990064322369
    },
    {
        "original_text": "The present work is devoted to the study of photon wave mechanics in terms of position eigenvectors, which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy spectrum. The concept of position eigenvector allows one to describe the state of a single photon by its position probability density distribution function (PDF). It also enables us to introduce the notion of quantum trajectory describing the evolution of this PDF over time. In particular, we show that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations. We demonstrate how these results may be used to analyze various phenomena related to the propagation of light through dispersive media. Finally, we discuss possible applications of our approach to the description of nonclassical effects associated with the emission of entangled pairs of photons. DOI: 10.1088/1742-6596/aa5e20\nI. INTRODUCTORY REMARkS\n\nIn recent years there has been considerable interest in developing new approaches to studying the properties of light fields based on the concepts of quantum optics  1–3  . One of such approaches involves introducing the so-called position eigenvectors  4  , which play an important role in the description of the state of a single-photon field  5–7  .\nIt should be noted that the use of position eigenvectors makes it possible not only to obtain information about the spatial structure of the electromagnetic field but also to investigate the temporal dynamics of the system under consideration  8, 9  . This fact opens up wide possibilities for applying the proposed method to analyzing various physical processes occurring during the propagation of light waves through dispersive media  10, 11  . \n \n In addition, the introduction of position eigenvectors into the theory of light fields leads to the possibility of using them to describe certain nonclassical effects associated",
        "watermark_text": "The present work is devoted to the study of photon wave theory in terms of position eigenvectors , which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy wavelength . The concept of position eigenvector allows one to define the state of a single photon by its position probability distribution distribution function ( PDF ) .It additionally permits us to introduce the notion of quantum path describing the evolution of this PDF over time . In particular , we prove that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations .We suggest how these results may be used to analyze numerous phenomena related to the propagation of light through dispersive media . Finally , we explain possible use of our approach to the description of nonclassical effects involved with the emission of entangled pairs of photons .DOI : 10 . 1088 / 1742 - 6596 / aa5e20 I . INTRODUCTORY REMARkS In recent years there has been sustained interest in developing new approaches to studying the properties of light fields based on the concepts of quantum optics 1 – 3 .One of such perspectives involves introducing the so - called position eigenvectors 4 , which take an important role in the description of the state of a single - photon field 5 – 7 . It should be mentioned that the using of position eigenvectors makes it necessary not only to obtain knowledge about the spatial shape of the electromagnetic field but also to examine the temporal properties of the system under consideration 8 , 9 .This fact offers up broad opportunities for applying the suggested method to investigating different physical processes arising during the propagation of light beams through dispersive media 10 , 11 . In addition , the introduction of position eigenvectors into the physics of light fields leads to the prospect of using them to explain certain nonclassical effects associated",
        "ori-fast-z-score": 2.6293856820079102,
        "water-fast-z-score": 8.227432617895719
    },
    {
        "original_text": "We study the Catalan numbers in connection with the number of ways to realize a given triangulation as an ordered sequence of its diagonals, or equivalently, as a set of non-crossing diagonals. We show that this problem is related to counting certain types of Dyck paths. In particular we prove that for any positive integer n there are exactly C(n) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides. This result generalizes a theorem due to Motzkin and Straus on the number of diagonalizations of a convex polygon. \nIntroduction\n\nThe Catalan numbers count many combinatorial objects such as binary trees, noncrossing partitions, spanning trees, etc., see e.g.   1, 2  . The present work deals with another class of Catalan-like objects: triangulations of polygons (see Figure 1 ). A triangulation T of a simple polygon P is defined as follows: it consists of all edges of P together with some additional diagonals connecting pairs of vertices of P so that each interior angle of P becomes at least 90 degrees after adding these diagonals. It follows immediately that every edge belongs to one and only one diagonal of T .\nIn  3  , Motzkin and Straus  celebrated theorem states that if D denotes the set of diagonals of a convex polygon Q then |D| = 2|Q|. They also proved that the number of diagonalizations d(P ) of a convex polygon P equals the number of diagonals of a triangulation of P . \nIt was shown recently  4  that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the number of diagonals needed to diagonalize the quadrilateral. Thus, the following question arises naturally: What is the relationship between the number of diagonals required to diagonalize a convex quadrilateral and the number of diagonals used in a triangulation?",
        "watermark_text": "We explore the Catalan numbers in connection with the number of ways to realize a given triangulation as an ordered sequence of its diagonals , or equivalently , as a group of non - crossing diagonals . We see that this question is related to counting particular kinds of Dyck paths .In particular we prove that for any positive integer n there are exactly C ( n ) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides . This result generalizes a theorem according to Motzkin and Straus on the number of diagonalizations of a convex polygon .Introduction The Catalan numbers count many combinatorial objects such as binary forests , noncrossing partitions , covering trees , etc . , see e . g . 1 , 2 .The present work deals with another class of Catalan - like structures : triangulations of polygons ( view Figure 1 ) . A triangulation T of a simple polygon P is characterized as follows : it consists of all edges of P together with some additional diagonals connecting pairs of vertices of P so that each interior angle of P becomes at least 90 degrees after adds these diagonals .It follows instantly that every edge belongs to one and only one diagonal of T . In 3 , Motzkin and Straus celebrated conjecture states that if D denotes the group of diagonals of a convex polygon Q then | D | = 2 | Q | .They also proved that the number of diagonalizations d ( P ) of a convex polygon P equals the number of diagonals of a triangulation of P . It was shown later 4 that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the quantity of diagonals needed to diagonalize the quadrilateral .Thus , the following issue arises readily : What is the relationship between the number of diagonals needed to diagonalize a convex quadrilateral and the proportion of diagonals used in a triangulation ?",
        "ori-fast-z-score": 0.9805806756909202,
        "water-fast-z-score": 5.5448262406693765
    },
    {
        "original_text": "We present an algorithm to construct the reduced basis space in the context of nonlinear problems with multiple solutions, which is based on the concept of quasi-equilibrium grid (QEG). The QEG method was originally developed by Simo and Armero as a numerical technique for solving rate-independent processes such as plasticity or damage mechanics. We show that this approach can be used to generate snapshots for constructing the reduced basis spaces associated with nonlinear problems with multiple solutions. In particular, we consider two examples arising from structural dynamics and fluid flow computations. Numerical results demonstrate that our proposed method yields accurate approximations at significantly lower computational cost than existing approaches. Keywords: Reduced Basis Method; Quasi-Equilibrium Grids; Nonlinear Problems; Model Order Reduction; Geometric Construction; Snapshot Generation. 1 Introduction.\nThe goal of this work is to develop efficient algorithms for generating snapshots for constructing the RB spaces associated with nonlinear problems having multiple solutions. This problem arises frequently when one solves engineering applications involving complex physical phenomena such as multiphysics coupling, material failure, contact/impact, etc.. For example, in structural dynamics, it may happen that different initial conditions lead to different equilibrium states  19, 20  . Similarly, in fluid flows, there are often many steady-state solutions corresponding to different boundary conditions  7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18  .\nIn order to solve these types of problems efficiently using the reduced basis method (RBM), it is necessary to have a good set of snapshots representing all possible solution behaviors. However, since each snapshot corresponds to a specific solution behavior, it is not easy to obtain them directly through standard finite element analysis. Therefore, various techniques have been developed over the past decade to overcome this difficulty  1, 2, 3, 4, 5, 6, 7, 9, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40",
        "watermark_text": "We present an algorithm to build the reduced basis space in the context of nonlinear issues with many solutions , which is based on the idea of quasi - equilibrium grid ( QEG ) . The QEG method was originally developed by Simo and Armero as a numerical technique for solving rate - based processes such as plasticity or damage mechanics .We see that this methodology can be used to create snapshots for constructing the reduced basis sets associated with nonlinear issues with many solutions . In particular , we define two examples arising from functional dynamics and fluid stream computations .Numerical results show that our proposed approach produces accurate approximations at significantly reduced theoretical cost than existing techniques . Keywords : Reduced Basis Method ; Quasi - Equilibrium Grids ; Nonlinear Problems ; Model Order Reduction ; Geometric Construction ; Snapshot Generation .1 Introduction . The goal of this project is to develop fast algorithms for generating snapshots for constructing the RB spaces related with nonlinear issues having many solutions .This problem arises often when one solves engineering applications requiring complex physical phenomena such as multiphysics coupling , structure crash , touch / explosion , etc . . For instance , in structural physics , it could happen that different initial conditions lead to different equilibrium states 19 , 20 . Similarly , in flow flows , there are often many steady - condition solutions corresponding to different boundary rules 7 , 8 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 .In order to solve these kinds of problems easily using the reduced basis method ( RBM ) , it is required to have a good collection of snapshots describing all possible solution behaviors . However , since each snapshot belongs to a certain solve behavior , it is not straightforward to obtain them directly through conventional finite element extraction .Therefore , various methods have been used over the previous decade to overcome this obstacle 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40",
        "ori-fast-z-score": -1.5888598190134724,
        "water-fast-z-score": 8.0
    },
    {
        "original_text": "We study the critical behavior of the 3D RFIM with Gaussian distributed disorder by means of Monte Carlo simulations and finite-size scaling analysis. We find that the system undergoes a continuous phase transition at zero temperature, which is characterized by an infinite correlation length but no divergent susceptibility. The results are compared to those obtained for the pure 3D Ising model as well as other models with quenched disorder. In particular we show how our findings can be understood within the framework of the droplet picture. \nPACS numbers: 64.60.Cn, 64.60.J-, 64.60.Nz \nI. INTRODUCTORY REMARkS\nThe Random Field Ising Model (RFIM) has been introduced more than 50 years ago  1  . It describes a ferromagnetic material where each spin interacts only with its nearest neighbors via exchange interactions J ij , while it also feels an external magnetic field h i randomly oriented on different sites  2  .\nIn recent years there have been many studies devoted to this problem both experimentally  3  -  6  and theoretically  7  -  12  . This interest was triggered mainly by the fact that the RFIM shares some features with real systems such as diluted antiferromagnets or spin-glasses  13  -  15  . For example, the presence of quenched disorder leads to frustration effects  16  similar to those observed in spin-glass materials  17  . Moreover, the RFIM displays a rich variety of phases depending on the strength of the applied magnetic field  18  . At low fields one finds a paramagnetic phase, whereas above a certain threshold value H c = O(J), the spins align along the direction of the local magnetic field leading to a ferromagnetic state  19  . Finally, if the magnitude of the external field exceeds another threshold value H t > H c , the magnetization becomes discontinuous  20  . These three regimes are separated by two second-order transitions occurring at T c1 < 0 and T c2 > 0  21  . However, despite these analogies between the RFIM and experimental systems  22  , the exact nature of the phase diagram remains controversial  23  .",
        "watermark_text": "We research the significant behavior of the 3D RFIM with Gaussian distributed disorder by means of Monte Carlo simulations and finite - length scaling processing . We see that the system undergoes a continuous phase shift at zero temperature , which is characterized by an endless correlation length but no divergent susceptibility .The results are compared to those achieved for the pure 3D Ising model as well as other models with quenched disease . In particular we show how our findings can be understood within the framework of the droplet picture .PACS codes : 64 . 60 . Cn , 64 . 60 . J - , 64 . 60 . Nz I . INTRODUCTORY REMARkS The Random Field Ising Model ( RFIM ) has been proposed more than 50 centuries earlier 1 .It describes a ferromagnetic material where each spin interacts only with its closest neighbors via transfer interactions J ij , while it also feels an external magnetic force h i randomly oriented on various places 2 . In recent seasons there have been many research devoted to this question both experimentally 3 - 6 and theoretically 7 - 12 .This interest was sparked mainly by the fact that the RFIM shares some features with real systems such as diluted antiferromagnets or spin - glasses 13 - 15 . For instance , the presence of quenched instability leads to frustration effects 16 comparable to those observed in spinning - glass materials 17 .Moreover , the RFIM displays a rich multitude of components varying on the strength of the applied magnetic force 18 . At small fields one gets a paramagnetic phase , whereas above a certain threshold factor H c = O ( J ) , the spins align along the direction of the local magnetic force leading to a ferromagnetic state 19 .Finally , if the magnitude of the external field exceeds another threshold quantity H t > H c , the magnetization becomes discontinuous 20 . These three regimes are split by two second - order transitions happening at T c1 < 0 and T c2 > 0 21 .However , despite these analogies between the RFIM and experimental systems 22 , the exact structure of the phase diagram remains disputed 23 .",
        "ori-fast-z-score": -0.7986208584745025,
        "water-fast-z-score": 7.0164641544562345
    },
    {
        "original_text": "We present an approach for self-organization in networks based on multi-agent systems (MAS). The proposed method is applied to two different networks: one with mobile nodes and another with static ones, both using IEEE 802.11b as their communication protocol. In this work we use agents that are able to move between neighboring nodes, which allows them to collect information about the state of each node. This information can be used by other agents to make decisions such as: moving to new positions or changing the transmission power level. We have implemented our proposal in NS-2 simulator and compared it against three well-known algorithms: OLSR, AODV and DSR. Our results show that MAS outperforms these protocols in terms of: packet delivery ratio, end-to-end delay and energy consumption. Keywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio",
        "watermark_text": "We present an approach for self - organization in networks based on multi - agent systems ( MAS ) . The proposed approach is applied to two different organizations : one with mobile connections and another with static ones , both using IEEE 802 . 11b as their networking protocol .In this study we using agents that are able to move between neighboring nodes , which allows them to collect data about the state of each node . This knowledge can be used by other agents to make choices such as : moving to new positions or altering the transmission power level .We have incorporated our proposal in NS - 2 simulator and compared it against three well - famous method : OLSR , AODV and DSR . Our results show that MAS outperforms these protocols in terms of : message delivery ratio , end - to - end delay and energy consumption .Keywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio",
        "ori-fast-z-score": 1.6378460497066512,
        "water-fast-z-score": 4.913538149119954
    },
    {
        "original_text": "The National Institutes of Health (NIH) is the largest funder of biomedical research in the United States, but it also supports non-biomedical research through its extramural program.  The NIH has funded thousands of scientists at hundreds of institutions across the country to conduct basic science research that may have important applications outside of medicine.   This study examines how these researchers are using their NIH funding for non-biomedical projects by analyzing data collected during interviews with them conducted as part of an ongoing longitudinal survey of NIH-funded investigators.  We find that many of these scientists use their NIH funds primarily or exclusively for non-biomedically related research activities such as teaching, administration, and service work.  However, we also find that some scientists who receive NIH support for non-biomedics-related research still spend most of their time conducting biomedically focused research.  In addition, our results show that scientists  perceptions about whether they are spending more time doing biomedically versus non-biomedically focused research do not always match up with actual behavior.",
        "watermark_text": "The National Institutes of Health ( NIH ) is the greatest funder of biomedical research in the United States , but it also supports non - biomedical research through its extramural program . The NIH has funded thousands of research at hundreds of organizations across the nation to conduct basic science research that might have important use outside of medicine .This study examines how these investigators are using their NIH funding for non - biomedical projects by analyzing data derived during surveys with them conducted as part of an continuing longitudinal survey of NIH - financed researchers . We see that several of these investigators use their NIH grants mainly or mainly for non - biomedically relevant academic operations such as teaching , administration , and service work .However , we also find that some scientists who receive NIH backing for non - biomedics - specific study still spend most of their hours pursuing biomedically focused research . In addition , our findings show that scientists perceptions about whether they are spent more work doing biomedically versus non - biomedically focused research do not always match up with actual behavior .",
        "ori-fast-z-score": 2.0124611797498106,
        "water-fast-z-score": 7.888888888888889
    },
    {
        "original_text": "We present the results on diffuse optical light (DOL) correlations with cluster properties for a sample of galaxy clusters observed by the Hubble Space Telescope Advanced Camera for Surveys and Spitzer Infrared Array Camera. We find that DOL correlates positively with X-ray luminosity, temperature, mass, velocity dispersion, and Sunyaev-Zel dovich effect flux decrement at 1.4 GHz. The correlation between DOL and X-ray luminosity is stronger than those found previously using ground-based data. These results suggest that DOL traces hot gas in galaxy clusters. This work was supported by NASA grant NNX08AG84G to Columbia University. We thank J. Richard McNamara for providing us with his Chandra observations of Abell 1689. We also acknowledge useful discussions with A. Vikhlinin. \n \n Keywords: Diffuse optical light; Galaxy clusters; Dark matter halos",
        "watermark_text": "We present the conclusion on diffuse optical light ( DOL ) correlations with cluster properties for a sample of galaxy galaxies studied by the Hubble Space Telescope Advanced Camera for Surveys and Spitzer Infrared Array Camera . We see that DOL correlates positively with X - ray luminosity , temperature , mass , speed dispersion , and Sunyaev - Zel dovich impact flux decrement at 1 . 4 GHz .The relationship between DOL and X - ray luminosity is greater than those identified previously used ground - based data . These data suggest that DOL marks hot gas in galaxy regions .This project was supported by NASA gift NNX08AG84G to Columbia University . We praise J . Richard McNamara for providing us with his Chandra measurements of Abell 1689 .We additionally note useful talks with A . Vikhlinin . Keywords : Diffuse optical light ; Galaxy clusters ; Dark matter halos",
        "ori-fast-z-score": -0.8660254037844387,
        "water-fast-z-score": 5.484827557301445
    },
    {
        "original_text": "We study the properties of strong peak points in Banach spaces, which are defined as follows.  Let X be a real or complex normed space with dual space X*. A point x # X is called a strong peak point if there exists an f # S(X) such that |f (x)| = sup{|f (y)| : y # X}. We prove that every separable reflexive Banach space has a dense set of strong peak points. As applications we show that every separable reflexivizable Banach space contains a copy of c 0 , and that every separable superreflexive Banach space contains a subspace isomorphic to l p for some 1 < p < + . In this note we study the properties of strong peaks points in Banach spaces. The concept was introduced by J. Lindenstrauss  L  who proved that every separable reflexible Banach space has a nonempty set of strong peak points; see also  JL1  .\nIn Section 2 we give several equivalent characterizations of strong peak points. In particular, it turns out that a point x # X is a strong peak point if and only if there exist two sequences (a n ) and (b n ) in R satisfying lim n Ä a n = lim n Ä b n = 1 and lim n Ä a n &1Â2 b n = 0 such that the sequence (a n b n ) converges weakly to zero but not strongly. This characterization enables us to prove our first main result on the density of strong peak points in separable reflexive BanACH spaces. \nTheorem 3. Every separable reflexive BanACH space has a dense set SP(X) of strong peak points.\n\nAs immediate consequences of Theorem 3 we obtain the following results. (i) Every separable reflexivizable space contains a copy of c0.\n(ii) Every separable superreflexive space contains a subspace isomorphic",
        "watermark_text": "We research the properties of stable peak points in Banach spaces , which are given as follows . Let X be a real or complex normed space with dual collection X * .A point x # X is dubbed a strong peak point if there exists an f # S ( X ) such that | f ( x ) | = sup { | f ( y ) | : y # X } . We say that every separable reflexive Banach space has a dense setting of strengthened peak points .As applications we prove that every separable reflexivizable Banach space includes a copy of c 0 , and that every separable superreflexive Banach space includes a subspace isomorphic to l p for some 1 < p < + . In this note we study the properties of strong peaks points in Banach spaces .The concept was introduced by J . Lindenstrauss L who proved that every separable reflexible Banach space has a nonempty set of strong peak points ; hear also JL1 . In Section 2 we give numerous equivalent characterizations of strong peak points .In particular , it turns out that a point x # X is a strong peak point if and only if there exist two sequences ( a n ) and ( b n ) in R satisfying lim n Ä a n = lim n Ä b n = 1 and lim n Ä a n & 1Â2 b n = 0 such that the sequence ( a n b n ) converges weakly to zero but not strongly . This formulation enables us to prove our first major result on the density of strengthened peak points in separable reflexive BanACH spaces .Theorem 3 . Every separable reflexive BanACH space has a dense setting SP ( X ) of stable peak points .As obvious effects of Theorem 3 we obtain the following results . ( i ) Every separable reflexivizable set contains a copy of c0 .( ii ) Every separable superreflexive space includes a subspace isomorphic",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 3.3093806066996887
    },
    {
        "original_text": "We present new results on the color magnitude distribution (CMD) of field galaxies in the redshift range 0<z<3, based on deep optical imaging data obtained with Subaru/Suprime-Cam at the prime focus telescope of National Astronomical Observatory of Japan. We use two different samples for our analysis; one is a sample of about 12000 spectroscopically confirmed galaxies selected from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7), which covers an area of ~10deg2 around the North Galactic Pole (NGP). The other is a sample of about 10000 photometrically selected galaxies over an area of ~30deg2 centered on the Hubble Deep Field South (HDF-S).\nThe CMD shows that there are three distinct galaxy populations in terms of their rest-frame colors as well as luminosities. These are: red-sequence early-type galaxies, green valley late-type galaxies, and blue cloud star-forming galaxies. In addition we find that the fraction of blue cloud galaxies increases towards higher redshifts up to z~2.5-3.0, while it decreases again beyond this epoch. This trend can be explained by the fact that most massive galaxies have already formed stars before z~3, so they become redder than less-massive ones afterwards; therefore more massive galaxies dominate the red-sequence population at high-z. On the other hand, less-massive galaxies continue forming stars until today, resulting in larger fractions of blue cloud galaxies at lower redshifts.",
        "watermark_text": "We report new data on the color magnitude distribution ( CMD ) of field galaxies in the redshift region 0 < z < 3 , using on soft imaging scanning data acquired with Subaru / Suprime - Cam at the prime focus telescope of National Astronomical Observatory of Japan . We use two different samples for our analysis ; one is a sample of about 12000 spectroscopically confirmed galaxies drawn from the Sloan Digital Sky Survey Data Release 7 ( SDSS DR7 ) , which covers an area of ~ 10deg2 around the North Galactic Pole ( NGP ) .The other is a sample of about 10000 photometrically selected galaxies over an area of ~ 30deg2 centered on the Hubble Deep Field South ( HDF - S ) . The CMD indicates that there are three separate universe groups in terms of their rest - frame colors as well as luminosities .These are : green - sequence earliest - class stars , green valley late - class objects , and green cloud star - creating galaxies . In addition we find that the fraction of blue forest objects increases towards higher redshifts up to z ~ 2 . 5 - 3 . 0 , while it reduces again beyond this epoch .This trend can be explained by the fact that most giant galaxies have already formed stars before z ~ 3 , so they become redder than less - massive ones afterwards ; therefore more massive galaxies represent the red - sequence population at high - z . On the other hand , less - massive galaxies continue forming stars until today , resulting in larger fractions of blue cloud galaxies at lower redshifts .",
        "ori-fast-z-score": 2.416841222614159,
        "water-fast-z-score": 7.057176370033344
    },
    {
        "original_text": "The polaron problem is one of the most important problems in condensed matter physics, and has been studied extensively for many years.  In this work we present an overview of some recent results on path integral methods applied to the su(2)-schrieffer-heeger (s-shh) model with periodic boundary conditions.   We first review how the s-shh hamiltonian can be written as a sum over spinless fermions using the Jordan-Wigner transformation.  Then we discuss how the partition function may be evaluated by performing a trace over all possible states of these fermions.  Finally, we show that the resulting expression can be rewritten in terms of Feynman diagrams which are then used to calculate various physical quantities such as the energy spectrum or correlation functions. The polaron problem is one o fthe most important problems in condensate matter physics, and has b een studied extensively for many years  1  . It describes a single electron moving through a lattice of atoms interacting via phonons  2  , where the electron-phonon interaction leads to the formation of a bound state known as a polaron  3  .\nIn this work w epresent an overview of some recent resul ts on path integral m ethods applied t o th e su(2)-schr iefer -heeg er (s-shh ) model  4  wit h p eriodic bo undary condit ions  5  .  W e first r evie w ho w th e shh h amiltonia n ca n be wr it ten as a sum ov er sp inl ess fermi ons usin g th e J ordan-Wign er transfor mat ion  6  .  Th en we discu ss how th e partiti on functi on m ay be evalua ted by perform ing a tr ace ov er al l possibl e st at es of th ese fermi ons.  Fina ll y, we sho w tha t th e resul tin g ex pressio n ca n be rewrite n in term s of Feyn man di agrams wh ich ar e th en u",
        "watermark_text": "The polaron problem is one of the most important problems in condensed matter theory , and has been studied thoroughly for hundreds years . In this research we present an overview of some latest findings on path integral methods applied to the su ( 2 ) - schrieffer - heeger ( s - shh ) model with periodic boundary constraints .We first review how the s - shh hamiltonian can be written as a sum over spinless fermions using the Jordan - Wigner transformation . Then we explain how the partition function could be evaluated by performing a trace over all possible states of these fermions .Finally , we prove that the resulting expression can be rewritten in terms of Feynman diagrams which are then used to estimate various physical components such as the power spectrum or correlation functions . The polaron problem is one o fthe most important problems in condensate matter mechanics , and has b een discussed heavily for many years 1 .It describes a single electron moving through a lattice of atoms interacting via phonons 2 , where the electron - phonon interaction results to the formation of a bound state known as a polaron 3 . In this study w epresent an overview of some latest resul ts on path integral m ethods applied t o th e su ( 2 ) - schr iefer - heeg er ( s - shh ) model 4 wit n p eriodic bo undary condit ions 5 .W e first r evie w ho w th e shh n amiltonia n ca n be wr it ten as a sum ov er sp inl ess fermi ons usin g th e J ordan - Wign er transfor mat ion 6 . Th en we discu ss how th e partiti on functi on m ay be evalua ted by perform ing a tr ace ov er al l possibl e st at en of th ese fermi ons .Fina ll y , we sho l tha t th e resul tin g ex pressio n ca n be rewrite n in word s of Feyn man di agrams wh ich ar e th en u",
        "ori-fast-z-score": 1.4419211804559506,
        "water-fast-z-score": 5.448041796855991
    },
    {
        "original_text": "The authors describe how they have created an artificial life form that self-assembles into a structure similar to the fruiting body of the Dictyostelium discoideum, or  dictyos  for short.  The dictyos is made up of thousands of identical cells connected by elastic filaments and can be grown in Petri dishes with nutrients added.   It has been shown to grow and divide indefinitely without any external control signals (such as hormones).   This work was done at Harvard University s Wyss Institute for Biologically Inspired Engineering.   ... Self-assembly refers to the spontaneous organization of matter into ordered structures such as crystals, snowflakes, and living organisms like bacteria colonies and animal tissues. In this study we report on our efforts toward creating a synthetic multicellular system capable of autonomous growth and division through self-assembly. We designed a minimal cell based on a spherical water-in-oil emulsion droplet containing a single microtubule-based cytoskeleton surrounded by a lipid membrane. These cells are able to attach to each other via flexible polymeric tethers and assemble into three-dimensional aggregates called “dictyos” which resemble the fruiting bodies formed by the social amoeba Dictyostelium discoidium. Our results demonstrate that these simple cellular units can autonomously organize themselves into complex 3D shapes reminiscent of natural systems.",
        "watermark_text": "The authors report how they have created an artificial life form that self - assembles into a structure similar to the fruiting bodies of the Dictyostelium discoideum , or dictyos for short . The dictyos is made up of millions of identical cells connected by elastic filaments and can be grown in Petri dishes with minerals added .It has been shown to expand and divide indefinitely without any external regulating signals ( such as hormones ) . This research was done at Harvard University s Wyss Institute for Biologically Inspired Engineering .. . . Self - assembly describes to the spontaneous organization of matter into organized objects such as bubbles , snowflakes , and live organisms like bacteria populations and human flesh . In this study we review on our work toward building a artificial multicellular system efficient of automatic development and division through self - assembly .We built a minimal cell based on a spherical water - in - oil emulsion droplet containing a single microtubule - based cytoskeleton enclosed by a lipid membrane . These cells are able to connect to each other via flexible polymeric tethers and arrange into three - dimensional aggregates called “ dictyos ” which mimic the fruiting bodies produced by the social amoeba Dictyostelium discoidium .Our results show that these simple cellular divisions can autonomously arrange themselves into complex 3D shapes reminiscent of natural units .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.7461923416925424
    },
    {
        "original_text": "The structural relaxation and the local vibrational modes (LVMs) are investigated by first-principles calculations for the substituted system Mg1-xCrxAl2-xO4 with x=0, 0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0 at%. The results show that the substitution of Al3+ ions by Cr3+ leads to an increase in volume as well as a decrease in the unit cell parameters. In addition, we find that there is no significant change in the bond lengths between nearest-neighboring atoms when the concentration of Cr3+ increases up to 5%. However, it can be seen clearly that the bond length between second-nearest neighboring atoms decreases gradually with increasing Cr3+ content. Furthermore, our calculated phonon dispersion curves indicate that all the LVMs are stable except those along the Γ-X direction which become unstable above 1% Cr3+ doping.",
        "watermark_text": "The mechanical relaxation and the local vibrational modes ( LVMs ) are examined by first - principles calculations for the substituted solution Mg1 - xCrxAl2 - xO4 with x = 0 , 0 . 25 , 0 . 5 , 1 . 0 , 2 . 0 , 3 . 0 , 4 . 0 , 5 . 0 at % . The results show that the replacement of Al3 + ions by Cr3 + leads to an increase in volume as well as a reduction in the unit cell dimensions .In addition , we find that there is no considerable shift in the bond lengths between nearest - neighboring atoms when the quantity of Cr3 + increases up to 5 % . However , it can be shown clearly that the bond length between second - nearest adjacent molecules decreases slowly with rising Cr3 + content .Furthermore , our derived phonon dispersion parameters indicate that all the LVMs are stable except those along the Γ - X orientation which become unstable above 1 % Cr3 + doping .",
        "ori-fast-z-score": 0.5443310539518174,
        "water-fast-z-score": 5.258758927213289
    },
    {
        "original_text": "We present an efficient method for computing the vacuum energy and force between two parallel plates using only standard numerical electromagnetism methods, without resorting to any approximations or special treatments such as analytic continuation into complex frequencies. The key idea is that we can use the Feynman-Kac formula to express the vacuum expectation value of the stress tensor at finite temperature T = 1/β (where β is the inverse temperature) in terms of the corresponding quantity at zero temperature but with one additional term involving the time evolution operator over a period of length β . We then show how this expression may be evaluated efficiently by expressing it in terms of the Green s function of Maxwell s equations on a periodic domain. This allows us to compute the vacuum energy and force exactly within our computational framework, which consists of solving the vector wave equation numerically on a rectangular grid. Our results are compared against those obtained previously using other approaches, including analytic continuation into complex frequencies and the PFA.",
        "watermark_text": "We present an efficient approach for calculation the vacuum energy and force between two connected sheets utilizing only conventional numerical electromagnetism methods , without resorting to any approximations or particular treatments such as analytic continuation into complex frequencies . The main idea is that we can using the Feynman - Kac formula to derive the vacuum expectation value of the strain vector at finite temperature T = 1 / beta ( where β is the inverse temperature ) in terms of the equivalent quantity at zero temperature but with one additional word regarding the period evolution operator over a period of length β .We then show how this formula may be evaluated efficiently by expressing it in terms of the Green s function of Maxwell s equations on a periodic domain . This enables us to compute the vacuum energy and force exactly within our computational framework , which consists of calculating the linear wave equation numerically on a rectangular grid .Our results are compared against those achieved previously used other methods , notably analytic continuation into complex frequencies and the PFA .",
        "ori-fast-z-score": 0.6625891564490792,
        "water-fast-z-score": 5.444444444444445
    },
    {
        "original_text": "We present an analysis of the transition between first stars and second stars, which are formed by gravitational collapse of primordial gas clouds with masses ranging from 10^4 M_sol to 10^6 M_sol.  We show that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium (IGM). The suppression factor increases as redshift decreases because the IGM temperature rises more rapidly than its density. At lower redshifts, we find that the formation rates of both first and second stars increase sharply when the universe becomes reionized. This effect occurs because the ionizing photons produced during reionization heat up the surrounding neutral hydrogen atoms, thereby increasing their Jeans mass and suppressing fragmentation into smaller objects. Finally, we estimate the number densities of first and second stars using our model for star formation history. Our results suggest that second stars may be detectable via future surveys such as LSST or Euclid.",
        "watermark_text": "We present an assessment of the shift between first stars and second stars , which are created by gravitational decay of primordial liquid clouds with masses vary from 10 ^ 4 M _ sol to 10 ^ 6 M _ sol . We see that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium ( IGM ) .The suppression ratio increases as redshift decreases because the IGM temperature rises more swiftly than its density . At lower redshifts , we find that the formation rates of both first and first stars increase dramatically when the universe becomes reionized .This phenomenon occurs because the ionizing photons created during reionization heat up the nearby neutral hydrogen atoms , thereby expanding their Jeans mass and suppressing fragmentation into bigger objects . Finally , we estimate the number densities of early and first stars using our model for star formation history .Our results propose that second stars would be detectable via upcoming polls such as LSST or Euclid .",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "The purpose of this article is to give an overview of the theory of weight structures on triangulated categories developed by A. Bondal and M. Kapranov.  We will explain how it can be applied to construct new cohomology theories for algebraic varieties over finite fields or number fields.   In particular we will discuss the construction of motivic cohomology using weight structures on derived categories of mixed Tate motives.    The main results are due to J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, and others. This article was written as part of the author s Ph.D thesis at Utrecht University under supervision of Prof. Dr. Wim van der Kallen. It has been published online by the author with permission of the supervisor. For more information about the content see the introduction below.",
        "watermark_text": "The purpose of this page is to give an overview of the notion of weight spaces on triangulated categories established by A . Bondal and M . Kapranov . We will explain how it can be applied to build modern cohomology theories for algebraic fields over arbitrary fields or number fields .In particular we will explore the formation of motivic cohomology involving weight forms on derived categories of mixed Tate motives . The main results are due to J . Ayoub , D . Gaitsgory , R . Hain , S . Katzarkov , V . Lafforgue , C . Soulé , B . Stienstra , and others .This page was written as part of the writer s Ph . D degree at Utrecht University under supervision of Prof . Dr . Wim van der Kallen . It has been publication online by the writer with authorization of the supervisor .For more information about the content read the introduction below .",
        "ori-fast-z-score": -0.42008402520840293,
        "water-fast-z-score": 4.900980294098034
    },
    {
        "original_text": "The author describes how he has used the concept of  errors in thinking  to help students understand and learn about science, particularly physics.  He explains that this approach is based on his own experience as an undergraduate student at Harvard University where he was taught by Professor Richard Feynman.   The author suggests that it may be useful for teachers to use similar approaches when teaching other subjects such as mathematics or chemistry. The author also discusses some of the difficulties associated with using this method. This article appeared originally in Physics Today (Vol. 51 No. 1 January 1997). It can be downloaded from: http://arxiv.org/abs/physics/9701001v1.pdf  In order to teach physics effectively, one must first have a clear understanding of what constitutes good thinking within the subject area. Unfortunately, many people who are not trained scientists do not think like physicists; they tend to make mistakes which often lead them astray. For example, if asked whether two objects will fall together towards earth s center of mass, most people would say no because they believe that gravity acts only between bodies that touch each other. However, according to Newtonian mechanics, gravitational attraction does act upon all matter regardless of its position relative to another body. If you were to ask someone else why two objects don t fall together, she might answer that they are connected by a string so their weight cancels out. Although this explanation seems reasonable, it fails to take into account the fact that the force exerted by the string is negligible compared to the forces acting upon both objects individually. As a result, her reasoning is flawed.",
        "watermark_text": "The author explains how he has used the notion of errors in thinking to assist children understand and learn about science , particularly science . He describes that this methodology is based on his own experience as an undergraduate student at Harvard University where he was taught by Professor Richard Feynman .The author argues that it could be beneficial for schools to use similar method when taught other subjects such as mathematics or chemistry . The author also examines some of the problems involved with utilizing this process .This page appeared originally in Physics Today ( Vol . 51 No .1 January 1997 ) . It can be downloaded from : www : / / arxiv . org / abs / physics / 9701001v1 . pdf In order to teach physics successfully , one must first have a clear awareness of what constitutes better thinking within the subject area .Unfortunately , many people who are not trained experts do not thought like physicists ; they tend to make mistakes which frequently lead them astray . For instance , if asking whether two bodies will drop apart towards earth s center of mass , most people may think no because they believe that gravity works only between bodies that reach each other .However , according to Newtonian physics , gravity tension does operate upon all matter regardless of its position relative to another bodies . If you were to ask someone else why two bodies don t fall together , she might respond that they are connected by a string so their weight cancels out .Although this explanation seems rational , it fails to take into consideration the fact that the force exerted by the string is negligible compared to the forces working upon both elements individually . As a result , her reasoning is flawed .",
        "ori-fast-z-score": -0.1796053020267749,
        "water-fast-z-score": 8.017837257372731
    },
    {
        "original_text": "We present the discovery and analysis of two double neutron stars (DNSs) with masses in excess of 2 M_sun, PSR J0737-3039A/B and PSR B1913+16. The former is an eclipsing system that has been observed to undergo orbital decay at a rate consistent with gravitational wave emission; it will merge within about 3 Myr. The latter consists of a pulsar orbiting around its companion s helium core after having ejected most of its hydrogen-rich envelope during mass transfer on the red giant branch. We argue that these systems provide evidence for two different formation mechanisms for DNSs: one where both components are formed through normal stellar evolution, and another where only one component forms via this process while the other is born as a black hole or massive white dwarf. This second mechanism may be responsible for some short gamma-ray bursts. DOI: 10.1103/PhysRevD.76.084011",
        "watermark_text": "We present the discovery and evaluation of two double neutron stars ( DNSs ) with masses in excess of 2 M _ sun , PSR J0737 - 3039A / B and PSR B1913 + 16 . The first is an eclipsing system that has been observed to undergo orbital decomposition at a rate compatible with gravity wave radiation ; it will merge within about 3 Myr .The last consists of a pulsar orbiting around its companion s helium core after having liberated most of its hydrogen - laden envelope during mass transfer on the red dwarf branch . We argue that these systems represent proof for two different formation methods for DNSs : one where both components are created through regular stars evolution , and another where only one component forms via this process while the other is born as a black hole or massive brown giant .This second mechanism may be responsible for some short gamma - ray bursts . DOI : 10 . 1103 / PhysRevD . 76 . 084011",
        "ori-fast-z-score": 1.1338934190276817,
        "water-fast-z-score": 5.165514464459439
    },
    {
        "original_text": "We propose that the Standard Model gauge fields are pseudo-goldstone bosons associated with spontaneous breaking of local non-abelian symmetry, and show how this can be implemented in an effective field theory framework. We also discuss possible experimental signatures for such a scenario at future colliders. The Standard Model (SM) is one of the most successful theories ever developed to describe physics phenomena observed over many orders of magnitude ranging from subatomic particles to cosmological scales. However, there remain several open questions about its fundamental structure which motivate searches beyond SM predictions. In particular, it has been known since the early days of quantum mechanics that the SM Lagrangian does not respect all Poincaré symmetries  1  . This fact leads to violations of Lorentz invariance predicted by the SM but never seen experimentally  2  .\nIn recent years, interest in models where some or all of these symmetries are broken spontaneously has increased  3  , motivated primarily by the possibility of explaining small neutrino masses via seesaw mechanisms  4  . These models typically involve new heavy fermions whose interactions break explicitly the global symmetry responsible for protecting the massless nature of the SM vector bosons  5  . As a result, the latter acquire tiny masses through radiative corrections  6  while still preserving their longitudinal polarization states  7, 8  .",
        "watermark_text": "We suggest that the Standard Model gauge fields are pseudo - goldstone bosons involved with spontaneous breaking of local non - abelian symmetry , and suggest how this can be applied in an efficient field model formulation . We also discuss possible experimental signatures for such a situation at possible colliders .The Standard Model ( SM ) is one of the most popular theories ever proposed to explain physics phenomena observed over numerous orders of magnitude ranging from subatomic particles to cosmological scales . However , there remain various open questions about its essential structure which motivate searches beyond SM predictions .In particular , it has been known since the early days of quantum mechanics that the SM Lagrangian does not respect all Poincaré symmetries 1 . This fact leads to violations of Lorentz invariance predicted by the SM but never shown experimentally 2 .In recent years , activity in theories where some or all of these symmetries are broken spontaneously has increased 3 , driven mainly by the prospect of describing small neutrino masses via seesaw techniques 4 . These models usually include new massive fermions whose interactions break explicitly the global symmetry responsible for guarding the massless existence of the SM vector bosons 5 .As a result , the latter acquire small masses through radiative corrections 6 while nevertheless preserving their longitudinal polarization states 7 , 8 .",
        "ori-fast-z-score": -0.41256849850351734,
        "water-fast-z-score": 5.081063304179084
    },
    {
        "original_text": "We present the results of our study on the evolution of interstellar dust (ISD) in spiral and irregular galaxies with various morphologies, based on multiwavelength observations obtained by Spitzer Space Telescope (SST), Herschel Space Observatory (HSO), Chandra X-ray Observatory (CXO), Hubble Space Telescope (HST). We have used SED fitting to derive physical parameters such as stellar mass, star formation rate (SFR), age, extinction etc., for all sample galaxies using photometric data available at UV-optical-NIR wavelengths. The derived properties are then compared between two galaxy samples -one consisting of spirals and another one containing irregulars. Our main findings are:  1. Irregular galaxies show higher values of total infrared luminosity than their spiral counterparts.  2. Infrared excess emission is found to be more prominent in irregular galaxies when compared to that observed in spiral galaxies.  3. Dust temperature distribution shows significant differences among irregular and spiral galaxies.",
        "watermark_text": "We present the conclusion of our research on the evolution of interstellar dust ( ISD ) in spiral and irregular stars with various morphologies , using on multiwavelength surveys obtained by Spitzer Space Telescope ( SST ) , Herschel Space Observatory ( HSO ) , Chandra X - ray Observatory ( CXO ) , Hubble Space Telescope ( HST ) . We have utilized SED fitting to derive physical factors such as stellar mass , sun formation rate ( SFR ) , age , extinction etc . , for all sample objects utilizing photometric data available at UV - optical - NIR wavelengths .The derived properties are then analyzed between two galaxy samples - one consisting of spirals and another one containing irregulars . Our main results are : 1 .Irregular galaxies show higher values of gross infrared luminosity than their spiral rivals . 2 .Infrared excess emission is found to be more prominent in irregular galaxies when compared to that detected in spiral galaxies . 3 .Dust heating distribution shows significant variations among irregular and spiral galaxies .",
        "ori-fast-z-score": 0.12216944435630522,
        "water-fast-z-score": 4.275930552470682
    },
    {
        "original_text": "We present the results of dust formation calculations for supernova ejecta using a one-dimensional radiation hydrodynamics code coupled with an equilibrium chemistry network, including grain growth by accretion onto pre-existing grains as well as coagulation between grains. We find that dust can form efficiently at temperatures below 1000 K if there is sufficient carbon available to make amorphous carbon grains. The amount of dust formed depends on the initial composition of the gas; we show that it increases dramatically when oxygen-rich material is mixed into the ejecta. For typical conditions found in Type II SNe, we predict that 0.1 M⊙ of dust forms within 10 years after explosion. This dust survives destruction due to sputtering by ions accelerated during the reverse shock passage through the ejecta. Our results suggest that dust may be produced in significant amounts in some core-collapse supernovae. \n \n Keywords: Dust, Supernova",
        "watermark_text": "We present the conclusion of dust structure calculations for supernova ejecta using a one - dimensional radiation hydrodynamics code combined with an equilibrium chemistry system , covering grain growth by accretion onto pre - emerging grains as well as coagulation between particles . We see that dust can form smoothly at conditions below 1000 K if there is adequate carbon available to make amorphous hydrogen grains .The amount of dust formed depends on the early structure of the gas ; we find that it rises dramatically when oxygen - laden matter is mixed into the ejecta . For common temperatures found in Type II SNe , we expect that 0 . 1 [UNK] of dust occurs within 10 years after explosion .This powder escaped destruction due to sputtering by ions induced during the reverse shock passage through the ejecta . Our results show that matter may be formed in considerable amounts in some core - collapse supernovae .Keywords: Dust, Supernova",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 6.671345390179443
    },
    {
        "original_text": "We report scanning magnetoresistance microscopy (SMRM) measurements on an atom chip with gold wires and microtraps fabricated by focused ion beam milling. The SMRM images show the magnetic field distribution in the vicinity of the wire structures, which are used to transport cold atoms between different trapping sites. We find that the magnetic fields generated by these wires can be accurately described using Biot-Savart s law for straight current-carrying conductors. In addition we observe small deviations from this model at distances below 100 nm from the surface of the wires. These deviations may arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their surfaces. Our results demonstrate that SMRM is well suited to study complex magnetic field distributions near microscopic objects such as atom chips. Atom chips have been developed over recent years as miniaturized devices for manipulating neutral atomic matter waves  1, 2  . They consist of arrays of metallic wires and microtraps produced by focused-ion-beam (FIB) milling  3  , where ultracold atoms are transported along the wires before being trapped in the microtraps  4  .\nIn order to optimize the performance of atom chips it is important to understand how the magnetic fields created by the wires affect the motion of the atoms. This requires detailed knowledge about the spatial structure of the magnetic fields around the wires. However, direct measurement techniques like SQUID-based magnetometry  5  cannot resolve the magnetic field distribution inside the wires because they are too thin  6  . Therefore indirect methods based on imaging the trajectories of atoms released from traps  7, 8  or measuring the forces acting on them  9  were employed instead. Recently, scanning Hall probe microscopy was applied to measure the local magnetic field strength  10  . Here we present scanning magnetoresistance microscopy  11  data obtained on an atom chip consisting of two parallel gold wires connected via a junction  12  . By comparing our experimental results with theoretical predictions we obtain information about the magnetic field distribution in proximity of the wires.",
        "watermark_text": "We report scanning magnetoresistance microscopy ( SMRM ) observations on an atom chip with gold wires and microtraps fabricated by concentrated ion beam milling . The SMRM pictures show the magnetic field spread in the vicinity of the wire structures , which are applied to transport cold molecules between various trap places .We see that the magnetic waves generated by these cables can be correctly explained following Biot - Savart s law for straight current - transporting conductors . In addition we study small deviations from this description at distances below 100 nm from the surface of the wires .These deviations might arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their edges . Our results show that SMRM is well suited to study difficult magnetic field distributions near microscopic structures such as atom devices .Atom devices have been created over recent years as miniaturized devices for manipulating neutral atomic matter waves 1 , 2 . They comprise of arrays of metallic wires and microtraps produced by concentrated - ion - laser ( FIB ) processing 3 , where ultracold atoms are transported along the wires before being trapped in the microtraps 4 .In order to optimize the performance of atom devices it is important to realize how the magnetic waves created by the wires affect the movement of the atoms . This requires complete understanding about the spatial shape of the magnetic waves around the wires .However , direct detection methods like SQUID - based magnetometry 5 cannot determine the magnetic field spread inside the wires because they are too thin 6 . Therefore indirect approaches derived on observing the trajectories of atoms released from nets 7 , 8 or tracking the forces working on them 9 were utilized instead .Recently , scanning Hall probe microscopy was used to measure the local magnetic force force 10 . Here we present scan magnetoresistance microscopy 11 data derived on an molecular computer comprised of two connected gold wires coupled via a junction 12 .By matching our experimental results with theoretical predictions we obtain knowledge about the magnetic force density in proximity of the wires .",
        "ori-fast-z-score": -0.6923076923076923,
        "water-fast-z-score": 8.590007875090548
    },
    {
        "original_text": "We present an efficient algorithm for computing the sign function of a large sparse complex matrix, which is based on the Lanczos bidiagonalization process with partial reorthogonalization. The proposed algorithm can be applied to any Hermitian or non-Hermitian matrices without restriction. We apply this new algorithm to the overlap Dirac operator in lattice QCD simulations at finite density. In particular we show that our algorithm works well even when the quark mass becomes small compared to the inverse of the lattice spacing. This work was supported by Grants-in-Aid for Scientific Research (No. 20340040) from MEXT Japan. PACS numbers: 11.15.Ha, 12.38.Qk, 12.39.Fe, 14.20 .Dh  1 Introduction Lattice Quantum Chromodynamics(LQCD), as one of the most promising candidates for describing strong interactions among quarks and gluons, has been widely used to study hadronic properties such as masses and decay constants  1  . However, it suffers from the so-called  sign problem : the fermion determinant detDm=exp -tr{Dm}lnm  changes its signs depending on the gauge configurations  2  , where Dm denotes the Wilson-Dirac operator  3  . Therefore, Monte Carlo methods cannot be directly employed to calculate physical quantities using LQCD because they require positive definite weight functions  4  .\nIn order to overcome this difficulty, several approaches have been developed so far  5  -  8  . Among them, the Taylor expansion approach  9  -  11  seems to be very powerful since it allows us to evaluate the expectation value of any observables accurately within statistical errors. It also enables us to perform calculations at high temperature and/or high density  12  -  14  . For example, the Taylor expansion up to O(a6) has already been performed successfully  15  .",
        "watermark_text": "We present an efficient algorithm for calculation the sign function of a large sparse complex matrix , which is based on the Lanczos bidiagonalization process with partial reorthogonalization . The proposed algorithm can be applied to any Hermitian or non - Hermitian matrices without limitation .We use this new algorithm to the overlap Dirac operator in lattice QCD simulations at finite density . In particular we prove that our algorithm works well even when the quark mass becomes tiny relative to the inverse of the lattice spacing .This project was supported by Grants - in - Aid for Scientific Research ( No . 20340040 ) from MEXT Japan .PACS scores : 11 . 15 . Ha , 12 . 38 . Qk , 12 . 39 . Fe , 14 . 20 . Dh 1 Introduction Lattice Quantum Chromodynamics ( LQCD ) , as one of the most attractive candidates for describing strong coupling among quarks and gluons , has been widely using to study hadronic properties such as masses and decay constants 1 . However , it suffers from the so - called sign problem : the fermion determinant detDm = exp - tr { Dm } lnm varies its signs depending on the gauge modes 2 , where Dm denotes the Wilson - Dirac operator 3 .Therefore , Monte Carlo methods never be directly used to estimate mechanical numbers using LQCD because they use positive definite weight functions 4 . In order to overcome this obstacle , various approaches have been proposed so far 5 - 8 .Among them , the Taylor expansion method 9 - 11 seems to be very potent since it allows us to analyze the expectation value of any observables correctly within statistical errors . It additionally lets us to conduct measurements at high heat and / or large velocity 12 - 14 .For instance , the Taylor expansion up to O ( a6 ) has already been performed successfully 15 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.4835456068700275
    },
    {
        "original_text": "We present the first comprehensive study of visible spectroscopy for all known Jupiter trojans (JTs). We obtained high-resolution spectra with Subaru/HDS, Gemini/GNIRS, and Keck/NIRC-2 in order to determine their surface compositions. The sample includes 49 JTs including two new discoveries by our team. Our analysis shows that most JTs are S-complex asteroids or C-type asteroids. However, we found four objects which show unusual spectral features; one is an E-type asteroid, while three others have featureless red-sloped continuum. These objects may be primitive bodies such as carbonaceous chondrites. In addition, we find that some JTs belong to dynamically cold families. This suggests that these families were formed recently through catastrophic collisions among parent bodies. Finally, we discuss possible formation scenarios for JTs based on our findings. Keywords: Asteroids",
        "watermark_text": "We present the first comprehensive investigation of visible spectroscopy for all known Jupiter trojans ( JTs ) . We obtained high - resolution spectra with Subaru / HDS , Gemini / GNIRS , and Keck / NIRC - 2 in order to obtain their surface compositions .The sample comprises 49 JTs including two latest discoveries by our team . Our study shows that most JTs are S - complex asteroids or C - class asteroids .However , we identified four bodies which show peculiar spectral features ; one is an E - class asteroid , while three rest have featureless red - sloped continuum . These bodies may be ancient bodies such as carbonaceous chondrites .In addition , we find that some JTs belong to dynamically cold families . This implies that these families were created recently through catastrophic collisions among parent bodies .Finally , we explain possible formation scenarios for JTs based on our findings . Keywords : Asteroids",
        "ori-fast-z-score": 0.13483997249264842,
        "water-fast-z-score": 4.900769721140662
    },
    {
        "original_text": "We report on the detection of X-ray flares in low mass stars (0.5-0.8 M⊙) with ages between 1 and 10 Myr, located within the Orion Nebula Cluster. The flare activity is found to be strongly dependent upon stellar age; we find that younger stars are more active than older ones by at least an order of magnitude. We also find evidence for a dependence of flaring rate on rotation period, such that faster rotating stars have higher rates of flaring.  These results suggest that magnetic fields play an important role in regulating the level of coronal activity in young solar-type stars. This work was supported under NASA contract NAS8-39073. We thank J. Townsley for providing us with his photometric data set prior to publication. We acknowledge useful discussions with A. Feigelson, D. Getman, C. Hillenbrand, R. Herbst, S. Preibisch, B. Reipurth, T. Stassun, E. Wolff, and W. Zuckermann.",
        "watermark_text": "We report on the detection of X - ray flares in low weight stars ( 0 . 5 - 0 . 8 [UNK] ) with ages between 1 and 10 Myr , located within the Orion Nebula Cluster . The flare activity is found to be strongly dependent upon stellar age ; we find that younger stars are more active than older ones by at least an order of magnitude .We additionally find proof for a dependence of flaring speed on rotation history , such that faster rotating stars have greater rates of flaring . These data suggest that magnetic waves play an important role in controlling the degree of coronal action in young solar - class stars .This project was supported under NASA contract NAS8 - 39073 . We praise J . Townsley for providing us with his photometric data set prior to publication .We acknowledge useful talks with A . Feigelson , D . Getman , C . Hillenbrand , R . Herbst , S . Preibisch , B . Reipurth , T . Stassun , E . Wolff , and W . Zuckermann .",
        "ori-fast-z-score": -0.3779644730092272,
        "water-fast-z-score": 3.6536565724225296
    },
    {
        "original_text": "We consider the asymptotic behavior of the sample autocovariance function and spectral density functions of stationary processes with regularly varying marginal distributions, which are driven by an infinite order moving average process whose coefficients have regularly varying tails. We show that these quantities can be approximated by those of a finite order autoregressive-moving average (ARMA) model in the sense of weak convergence under some conditions on the tail behaviors of the ARMA parameters. The results obtained here extend previous ones given in the literature to more general cases where the driving noise is not necessarily Gaussian or has non-Gaussian components. In particular, we provide new proofs for the existing results when the driving noise is purely Gaussian. Our approach relies heavily on recent developments made in the theory of regular variation and stochastic calculus. As applications, we study two examples of duration-driven LRD models, namely the Cox-Ingersoll-Ross (CIR) model and the Vasicek model.",
        "watermark_text": "We consider the asymptotic activity of the sample autocovariance map and spectral density functions of stationary systems with regularly varying marginal distributions , which are driven by an endless order move average process whose coefficients have regularly varying tails . We see that these quantities can be approximated by those of a finite order autoregressive - moving average ( ARMA ) model in the sense of weak convergence under some conditions on the tail behaviors of the ARMA parameters .The results derived here extend previous ones given in the writings to more general instances where the driving signal is not necessarily Gaussian or has non - Gaussian components . In particular , we provide fresh proofs for the new results when the driving signal is purely Gaussian .Our perspective rely heavily on current developments developed in the theoretical of regular variation and stochastic equations . As applications , we study two examples of duration - based LRD models , namely the Cox - Ingersoll - Ross ( CIR ) model and the Vasicek theory .",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 4.302652729749464
    },
    {
        "original_text": "We present new distances for eight open clusters in the Large Magellanic Cloud (LMC) using near-infrared photometry and isochrone fitting techniques. The red clump giants are used as standard candles, with their absolute magnitudes determined by comparison with Galactic globular cluster data. We find that our results agree well with previous determinations based on other methods but have smaller uncertainties.  These new distance measurements will be useful for calibrating future surveys such as Gaia and LSST. They also provide an independent check on the accuracy of current estimates of the Hubble constant derived from Type Ia supernovae observations. This work was supported by NASA grant NNX10AD65G. The authors would like to thank Dr. J. Alves de Oliveira Jr., who provided us with his code for determining ages and metallicities of open clusters. We acknowledge support from NSF grants AST-0907892 and AST-1109897.",
        "watermark_text": "We create additional distances for eight open complexes in the Large Magellanic Cloud ( LMC ) using near - infrared photometry and isochrone fit techniques . The red clump giants are using as conventional candles , with their absolute magnitudes determined by analysis with Galactic globular cluster data .We see that our findings agree well with previous determinations based on other methods but have smaller uncertainties . These new distance measurements will be valuable for calibrating future surveys such as Gaia and LSST .They also perform an independent check on the accuracy of recent estimates of the Hubble constant calculated from Type Ia supernovae observations . This research was supported by NASA award NNX10AD65G .The authors would like to thank Dr . J . Alves de Oliveira Jr . , who provided us with his code for determining ages and metallicities of open clusters . We acknowledge support from NSF grants AST - 0907892 and AST - 1109897 .",
        "ori-fast-z-score": 1.4320780207890627,
        "water-fast-z-score": 5.598123172175427
    },
    {
        "original_text": "We present new near-infrared polarimetric observations of the equatorial ring surrounding the evolved star HD 163296 (HR 5171 A). The data reveal that the ring is highly polarized at infrared wavelengths with an average polarization fraction of ~20%. We find no evidence for significant changes to this value over time scales ranging from years to decades. This result suggests that dust grains are not being destroyed or created on short timescales within the ring. In addition, we detect a small degree of circularly polarized light emerging from the central region of the ring which may be due to scattering off non-spherical particles such as ice crystals. \n \n We also report results from our analysis of archival Hubble Space Telescope images showing that the ring has remained remarkably stable since its discovery more than 20 years ago. Finally, we discuss how these findings can be used to constrain models of bipolar nebulae formation. Keywords: Polarization; Circumstellar matter",
        "watermark_text": "We report new near - infrared polarimetric studies of the equatorial ring surrounding the evolved star HD 163296 ( HR 5171 A ) . The data reveal that the circle is strongly polarized at infrared wavelengths with an estimated polarization fraction of ~ 20 % .We see no evidence for significant variations to this value over time ranges ranging from years to decades . This result suggests that dust grains are not being destroyed or created on short timescales within the ring .In addition , we perceive a small level of circularly polarized light arriving from the main region of the circle which may be due to scattering off non - cylindrical ions such as ice particles . We additionally report findings from our analysis of archival Hubble Space Telescope images indicating that the circle has remained remarkably steady since its observation more than 20 decades ago .Finally , we explain how these results can be used to constrain models of bipolar nebulae formation . Keywords : Polarization ; Circumstellar matter",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.3804502135457675
    },
    {
        "original_text": "We present deep radio observations at 1.4 GHz with the VLA towards two TeV gamma-ray emitting regions, one associated to the open cluster Cyg OB2 #8 (HESS J1640-465) and another located near the massive star WR 25 (HESS J1641-463). The new data reveal extended emission around both TeV sources which is not detected by previous surveys. We discuss possible scenarios for this emission based on our results as well as those obtained recently by other authors. In particular we propose that the observed structures are due to synchrotron radiation produced by relativistic electrons accelerated in shocks driven by stellar winds interacting within these clusters. This scenario would also explain why no X-ray counterparts have been found so far despite deep searches carried out with Chandra and XMM-Newton telescopes. Finally, we estimate the magnetic field strength required to produce such emission using standard models for particle acceleration in colliding wind binaries. \nIntroduction\n\nThe Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° (  Fig.   1a ). It has been suggested that many of them could be members of binary systems or even multiple systems (e.g., Knödlseder 2000; Wright et al. 2010) . These objects can drive powerful winds into their surroundings creating strong shocks where particles may be accelerated up to very high energies. If some of these particles escape from the shock fronts they will interact with photons coming from the surrounding interstellar medium producing high-energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range. \n \n Several studies suggest that several of the known TeV sources in the sky might be related to young open clusters like Cyg OB2 (see e.g., Aharonian et al. 2005a ,b, 2007a . However, only few of these associations have been confirmed through multi-wavelength campaigns involving optical/infrared imaging, spectroscopy and/or radio continuum observations (see e.g. , Reimer & Böttcher 2006 , Castro-Tirado et al",
        "watermark_text": "We report deep radio observations at 1 . 4 GHz with the VLA towards two TeV gamma - ray emitting regions , one related to the open object Cyg OB2 # 8 ( HESS J1640 - 465 ) and another situated near the giant star WR 25 ( HESS J1641 - 463 ) . The revised data reveal extended emitted around both TeV sources which is not observed by earlier surveys .We discuss possible strategies for this emission based on our findings as also as those acquired previously by other researchers . In particular we propose that the seen features are due to synchrotron emission created by relativistic electrons accelerated in shocks driven by stellar winds interacting within these clusters .This scenario would also explain why no X - ray equivalent have been detected so far despite massive investigations carried out with Chandra and XMM - Newton telescopes . Finally , we estimate the magnetic force size needed to produce such emission utilizing typical models for electron acceleration in colliding weather binaries .Introduction The Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° ( Fig . 1a ) .It has been proposed that several of them could be members of binary systems or even multiple systems ( e . g . , Knödlseder 2000 ; Wright et al . 2010 ) .These particles can bring powerful storms into their environment forming violent shocks where ions may be advanced up to very high energies . If some of these ions survive from the shock fronts they will interact with photons coming from the nearby interstellar medium generating high - energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range .Several studies propose that several of the known TeV sources in the heavens would be connected to early open complexes like Cyg OB2 ( see e . g . , Aharonian et al . 2005a , b , 2007a .However , only few of these associations have been confirmed through multi - wavelength campaigns involving optical / microwave imaging , spectroscopy and / or radio continuum observations ( saw e . g . , Reimer & Böttcher 2006 , Castro - Tirado et al",
        "ori-fast-z-score": -0.8892972917998876,
        "water-fast-z-score": 7.185169912163989
    },
    {
        "original_text": "The Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider has recently reported evidence for a new particle with mass around 125 GeV, consistent with Standard Model expectations for the Higgs boson.  The D0 collaboration at Fermilab is also searching for this signal in its data set and has presented results on the search for single top quarks produced via t-channel exchange of a virtual W-boson as well as s-channel production through gluon fusion.   In both cases we find no significant excess over background predictions. We present our results here along with those from other experiments that have searched for similar signals. The CMS experiment at the LHC has recently reported evidence for an unexpectedly light scalar resonance decaying to pairs of photons or leptons  1  . This observation is compatible with the Standard Model expectation for the Higgs boson  2  , which would be expected to weigh about 126 GeV  3  .\nIn addition to the standard model Higgs boson searches performed by ATLAS  4  and CMS  5  , there are many extensions of the SM  6  that predict additional scalars  7, 8  . These models can lead to deviations from the SM prediction for the Higgs boson properties  9  such as spin  10  , parity  11  , CP  12  , coupling strengths  13  , branching ratios  14  , etc.. Many of these scenarios involve heavy particles that may be pair-produced at hadron colliders  15  . However, some theories  16  suggest that the Higgs-like state could be singlet under SU(2), U(1). Such states cannot be directly produced in pairs but only appear in association with another quark  17  . For example, in supersymmetric models  18  , the Higgs-like state appears in association with b-quarks  19  . Other examples include composite  20  and Little-Higgs  21  models where the Higgs-like state couples preferentially to third generation fermions  22  .",
        "watermark_text": "The Compact Muon Solenoid ( CMS ) experiment at the Large Hadron Collider has recently published evidence for a new particle with mass around 125 GeV , compatible with Standard Model expectations for the Higgs boson . The D0 consortium at Fermilab is also searching for this signal in its data set and has presented data on the hunt for single bottom quarks produced via t - channel exchange of a virtual W - boson as well as s - channel production through gluon fusion .In both cases we find no considerable excess over background predictions . We present our findings here along with those from other experiments that have searched for related systems .The CMS experiment at the LHC has recently published evidence for an unexpectedly light scalar resonance decaying to pairs of photons or leptons 1 . This measurement is compatible with the Standard Model estimate for the Higgs boson 2 , which would be anticipated to weigh about 126 GeV 3 .In addition to the standard model Higgs boson searches performed by ATLAS 4 and CMS 5 , there are many extensions of the SM 6 that forecast additional scalars 7 , 8 . These models can lead to deviations from the SM estimate for the Higgs boson properties 9 such as spin 10 , parity 11 , CP 12 , coupling strengths 13 , branching factors 14 , etc . .Many of these scenarios involve heavy nuclei that might be pair - produced at hadron colliders 15 . However , some theories 16 suggest that the Higgs - like state possible be singlet under SU ( 2 ) , U ( 1 ) .Such states cannot be directly produced in couples but only appear in association with another quark 17 . For instance , in supersymmetric theories 18 , the Higgs - like state occurs in association with b - quarks 19 .Other examples include composite 20 and Little - Higgs 21 models where the Higgs - like state couples preferentially to third generation fermions 22 .",
        "ori-fast-z-score": 0.9805806756909202,
        "water-fast-z-score": 5.439200829200679
    },
    {
        "original_text": "We consider the problem of optimal investment in a financial market when there is no upper bound on the investor s wealth, but his/her utility function exhibits decreasing absolute risk aversion (DARA). We show that under DARA preferences, the value function for this problem can be characterized as the unique solution to a nonlinear partial differential equation (PDE) which we call the Hamilton-Jacobi-Bellman-Isaacs PDE. This characterization allows us to use standard numerical methods such as finite difference or Monte Carlo simulation to compute the value function numerically. In addition, it also enables us to study how the optimal strategy depends on various parameters including the initial endowment, the interest rate, and the volatility of the stock price process. Finally, by using our results, we are able to provide some new insights into the relationship between pricing and hedging derivatives based on utility maximization principles. The main contributions of this work include:",
        "watermark_text": "We consider the question of optimal investment in a financial market when there is no upper bound on the investor s assets , but his / her utility function exhibits decreasing absolute price aversion ( DARA ) . We see that under DARA preferences , the value function for this question can be described as the unique solve to a nonlinear partial differential equation ( PDE ) which we call the Hamilton - Jacobi - Bellman - Isaacs PDE .This definition permits us to use conventional numerical technique such as finite difference or Monte Carlo simulation to compute the value function numerically . In addition , it also enables us to study how the ideal scenario depends on various variables including the early endowment , the interest rate , and the volatility of the stock price cycle .Finally , by using our findings , we are able to provide some fresh insights into the relationship between pricing and hedging derivatives using on utility maximization theories . The main contributions of this research include :",
        "ori-fast-z-score": 1.4142135623730951,
        "water-fast-z-score": 5.969098507002659
    },
    {
        "original_text": "The low energy effective theories for superstrings are supergravity and supersymmetric gauge theories in four dimensions, which can be obtained by compactifying the extra six spatial dimensions on a Calabi-Yau manifold.  In this talk I will discuss some recent results about lattice models that provide an alternative approach to studying these theories. The basic idea is to use Monte Carlo simulations to study supersymmetric field theories defined on a finite number of points (the sites) of a regular d-dimensional hypercubic lattice with periodic boundary conditions. These models have been studied extensively over the past few years using numerical techniques such as exact diagonalization, quantum Monte Carlo methods, and density matrix renormalization group algorithms. Recently we developed new Monte Carlo simulation techniques based on the worm algorithm that allow us to simulate large systems at very high temperatures where conventional Monte Carlo methods fail because they suffer from critical slowing down. We used our new method to calculate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang-Mills theory and the N = 1 supersymmetric U(1) gauge theory coupled to matter fields in various representations.",
        "watermark_text": "The lowest energy effective models for superstrings are supergravity and supersymmetric gauge fields in four dimensions , which can be obtained by compactifying the extra six spatial dimensions on a Calabi - Yau manifold . In this talk I will explore some latest findings about lattice models that provide an different approach to researching these theories .The basic idea is to use Monte Carlo simulations to study supersymmetric field theories specified on a finite number of points ( the sites ) of a regular d - dimensional hypercubic structure with periodic border conditions . These systems have been studied frequently over the previous few years employing mathematical techniques such as approximate diagonalization , quantum Monte Carlo methods , and density matrix renormalization group algorithms .Recently we developed novel Monte Carlo simulation method based on the worm algorithm that enable us to simulate large systems at very high altitudes where conventional Monte Carlo methods fail because they suffer from critical speed down . We utilized our new method to estimate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang - Mills theory and the N = 1 supersymmetric U ( 1 ) gauge theory connected to matter groups in different representations .",
        "ori-fast-z-score": 0.6255432421712244,
        "water-fast-z-score": 6.118014998909509
    },
    {
        "original_text": "We present the results of numerical simulations of magnetohydrostatic equilibrium for solar prominences embedded into non-potential, sheared and twisted coronal fields. The model is based on solving numerically the Grad-Shafranov equation with boundary conditions at both ends of the computational domain that are derived using an approximate analytical solution to this problem. We find that the resulting equilibria have shapes similar to those observed in white-light coronagraph images. In particular, we show how the shape of the prominence changes as its position relative to the underlying photospheric magnetic flux distribution varies. Our results also demonstrate that the presence of shear and/or twist leads to significant deviations from potential-field models commonly used in theoretical studies of prominences. These findings may be useful for interpreting observations of prominences made by space-based instruments such as SDO/AIA. \n \n Keywords: Solar prominence, Magnetohydrostatics",
        "watermark_text": "We present the conclusion of computational simulations of magnetohydrostatic equilibrium for solar prominences localized into non - potential , sheared and spun coronal fields . The model is based on solving numerically the Grad - Shafranov equation with boundary conditions at both sides of the theoretical domain that are derived using an approximate mathematical solution to this question .We see that the resulting equilibria have shapes parallel to those observed in white - light coronagraph images . In particular , we find how the form of the prominence changes as its position relative to the underlying photospheric magnetic flux flow varies .Our results also demonstrate that the presence of shear and / or twist contributes to significant deviations from potential - field methods commonly used in theoretical analyses of prominences . These conclusions could be suitable for interpreting observations of prominences made by space - based instruments such as SDO / AIA .Keywords : Solar prominence , Magnetohydrostatics",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.541868715470696
    },
    {
        "original_text": "We study the problem of finding an optimal set of points on the unit circle that are equidistant to each other and have minimum angular separation between them, known as the Costas array or Costas configuration.  We show how this problem can be formulated as a convex optimization problem with linear constraints over the space of probability measures supported by the unit circle. This formulation allows us to use tools from convex analysis for solving it efficiently. In particular we provide a polynomial time algorithm which computes an approximate solution within any desired accuracy. The proposed method is based on the Frank-Wolfe (FW) algorithm combined with the Sinkhorn-Knopp scaling technique. Finally, numerical experiments demonstrate the efficiency of our approach compared to existing methods. Keywords: Convex Optimization; Probability Measures; Frank Wolfe Algorithm; Scaling Technique; Unit Circle; Costas Array; Costas Configuration.",
        "watermark_text": "We explore the question of finding an appropriate collection of points on the unit circle that are equidistant to each other and have minimum spatial separation between them , known as the Costas array or Costas configuration . We see how this question can be formulated as a convex optimization problem with linear constraints over the space of likelihood measures supported by the unit circle .This formulation enables us to use tools from convex optimization for solving it easily . In particular we provide a polynomial period approximation which computes an approximate solve within any specified precision .The proposed approach is based on the Frank - Wolfe ( FW ) algorithm coupled with the Sinkhorn - Knopp scaling methodology . Finally , numerical studies demonstrate the performance of our approach relative to existing techniques .Keywords: Convex Optimization; Probability Measures; Frank Wolfe Algorithm; Scaling Technique; Unit Circle; Costas Array; Costas Configuration.",
        "ori-fast-z-score": -1.2909944487358056,
        "water-fast-z-score": 4.389381125701739
    },
    {
        "original_text": "The traveling salesman problem (TSP) is one of the most famous problems in combinatorial optimization, which asks for finding an optimal tour through all vertices of a given graph such that each edge is visited exactly once. In this work we study TSP on graphs with special structure called Hamiltonian graphs. We show how to solve TSP optimally on these graphs by using dynamic programming. Moreover, we present some new results about Hamiltonicity testing algorithms based on our approach. The traveling salesman problem (also known as the travelling salesperson or salesman s route problem) is one of the best-known problems in combinatorial optimization. It can be formulated as follows: Given a complete weighted undirected graph G = (V , E), find a cycle C passing through every vertex v ∈ V at least once so that the total weight w(C ) of edges in C is minimized. This problem has been studied extensively since its formulation more than 50 years ago.",
        "watermark_text": "The touring salesman problem ( TSP ) is one of the most famous difficulties in combinatorial algorithms , which asks for finding an efficient walk through all edges of a given graph such that each edge is attended exactly once . In this research we study TSP on graphs with special structure named Hamiltonian graphs .We see how to solve TSP optimally on these graphs by using dynamic programming . Moreover , we present some different results about Hamiltonicity testing algorithms based on our approach .The touring salesman problem ( also known as the travelling salesperson or salesman s route puzzle ) is one of the best - famous difficulties in combinatorial algorithms . It can be formulated as follows : Given a complete weighted undirected graph G = ( V , E ) , find a cycle C passing through every vertex v ∈ V at least once so that the total weight w ( C ) of vertices in C is minimized .This problem has been studied frequently since its formulation more than 50 years previously .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.865804798594798
    },
    {
        "original_text": "In this work, we study the throughput capacity region for multi-hop wireless networks with multiple transmitters and one receiver (MISO-MHWN). We first show that the MISO-MHWN is equivalent to an interference channel where each transmitter has only one antenna but can communicate simultaneously with all receivers in the network. Then, by using the concept of degrees-of-freedom (DoF), which characterizes how many parallel data streams are supported at high signal-to-noise ratio (SNR) regime, we derive outer bounds on the DoF region of the MISO-MHWNS. Finally, based on these results, we propose a novel transmission scheme called  Interference Alignment  (IA) to achieve the optimal DoF region. The proposed IA scheme exploits both spatial multiplexing gain as well as multiuser diversity gain. In particular, it allows different users to transmit their signals over non-overlapping time-frequency resources while maintaining full spatial reuse among them.",
        "watermark_text": "In this research , we study the throughput capacity area for single - hop wireless networks with many transmitters and one antenna ( MISO - MHWN ) . We first see that the MISO - MHWN is analogous to an interference channel where each antenna has only one antenna but can communicate simultaneously with all receivers in the channel .Then , by using the notion of degrees - of - independence ( DoF ) , which characterizes how many concurrent data feeds are implemented at high signal - to - noise ratio ( SNR ) regime , we derive upper limits on the DoF area of the MISO - MHWNS . Finally , based on these results , we undertake a new transmission strategy titled Interference Alignment ( IA ) to achieve the ideal DoF area .The proposed IA plan involves both temporal multiplexing gain as well as multiuser diversity gain . In particular , it allows different users to transmit their messages over non - overlapping period - frequency resources while maintaining full temporal reuse among them .",
        "ori-fast-z-score": -0.8307471607356973,
        "water-fast-z-score": 5.421151989096865
    },
    {
        "original_text": "The present work is devoted to the investigation of new possible nuclear properties using nonlinear methods, namely fractal dimension (FD) and recurrence quantification analysis (RQA). The FD was calculated for different mass number A in order to study its dependence on the system size. It has been found that there exists an optimal value of the scaling parameter which provides the best results for each nucleus separately. This fact indicates that the structure of the studied systems can be characterized as multifractals with non-trivial behavior. In addition we have shown that the obtained values are very close to those predicted by the percolation theory. We also applied RQA method to investigate the temporal evolution of the considered systems. Our calculations show that the complexity of the time series increases with increasing mass number A. Moreover it turns out that this increase follows closely the predictions made within the framework of the Random Matrix Theory. Finally we have compared our results with experimental data available for some light nuclei.",
        "watermark_text": "The present work is devoted to the exploration of new possible nuclear properties using nonlinear methods , notably fractal dimension ( FD ) and recurrence quantification analysis ( RQA ) . The FD was calculated for different mass quantity A in order to study its dependence on the system size .It has been determined that there exists an appropriate value of the scaling parameter which offers the best results for each particle separately . This fact suggests that the composition of the studied structures can be described as multifractals with non - simple properties .In addition we have shown that the achieved values are very close to those predicted by the percolation theory . We also used RQA approach to examine the temporal evolution of the considered systems .Our calculations show that the complexity of the time series increases with expanding mass quantity A . Moreover it turns out that this increase follows carefully the assumptions done within the framework of the Random Matrix Theory .Finally we have linked our findings with experimental evidence available for some light nuclei .",
        "ori-fast-z-score": -0.22360679774997896,
        "water-fast-z-score": 5.142956348249516
    },
    {
        "original_text": "We study how galactic discs warp in response to tidal forces exerted by dark matter haloes and intergalactic gas filaments, using high-resolution cosmological simulations with radiative cooling and star formation. We find that the majority (>80%) of simulated galaxies have significant warping at z = 0. The amplitude of the warp increases with decreasing galaxy mass, but is independent of redshift for massive galaxies. Warp amplitudes are typically less than 10 kpc, which agrees well with observations. Our results suggest that most observed warps can be explained as being caused by external gravitational torques on galactic discs. This implies that there may not exist any intrinsic mechanism within galactic discs themselves that causes warps. In addition, we show that the presence of an AGN does not significantly affect the shape or strength of the warp. Finally, we demonstrate that our model predicts a correlation between the direction of the warp and the angular momentum vector of the host halo.",
        "watermark_text": "We research how galactic discs warp in reaction to tidal forces exerted by black material haloes and intergalactic gas filaments , using high - resolution cosmological simulations with radiative cooling and galaxy formation . We see that the majority ( > 80 % ) of simulated galaxies have considerable warping at z = 0 .The amplitude of the warp increases with varying universe weight , but is independent of redshift for huge objects . Warp amplitudes are typically lower than 10 kpc , which agrees well with observations .Our results propose that most observed warps can be described as being affected by external gravitational torques on galactic discs . This implies that there may not exist any inherent mechanism within galactic discs themselves that creates warps .In addition , we prove that the presence of an AGN does not dramatically impact the form or strength of the warp . Finally , we prove that our model predicts a correlation between the direction of the warp and the angular velocity tensor of the host halo .",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 4.572004572006858
    },
    {
        "original_text": "We propose a model that describes the spontaneous formation of neuronal assemblies in terms of an unsupervised Hebbian learning rule with synaptic depression. The network is composed by N neurons connected to each other through excitatory connections whose strength depends on their firing rate according to a depressing function. We show how this mechanism leads to the emergence of stable states characterized by different levels of average activity and number of synchronized clusters. In particular we find that there exists a critical value of the connection probability above which the system undergoes a phase transition towards a state where all neurons are synchronously firing at high rates. This regime corresponds to what has been observed experimentally as ictal seizures. \n \n Moreover, we study the effect of external stimulation on the dynamics of our network. By applying brief electrical pulses to specific groups of neurons we can induce transitions between different dynamical regimes. Finally, we discuss possible applications of these results to neurobiology.",
        "watermark_text": "We suggest a theory that describes the spontaneous development of neuronal assemblies in terms of an unsupervised Hebbian learning principle with synaptic depression . The network is composed by N cells connected to each other through excitatory connections whose strength depends on their fired rate due to a depressing function .We see how this mechanism leads to the emergence of stable states characterized by various rates of average activity and number of synchronized clusters . In particular we find that there exists a critical factor of the connection probability above which the system undergoes a phase shift towards a state where all neurons are synchronously firing at high levels .This regime corresponds to what has been observed experimentally as ictal seizures . Moreover , we study the impact of external stimulation on the dynamics of our system .By applying short electrical pulses to individual groups of neurons we can induce changes between various dynamical regimes . Finally , we explain possible use of these results to neurobiology .",
        "ori-fast-z-score": 1.162476387438193,
        "water-fast-z-score": 5.969098507002659
    },
    {
        "original_text": "We present the results of an analysis to determine whether physical vetoes can be used as part of a pipeline to reduce false alarms in searches for gravitational waves (GWs) from binary black hole mergers and other astrophysical sources.  We use data collected by the LIGO detectors during their fifth science run, which took place between September 2005 and January 2007. The search pipeline is based on matched filtering with template waveforms that are generated using post-Newtonian expansions up to 3PN order. In addition to standard cuts applied to the signal-to-noise ratio (SNR), we also apply two different types of physical vetoes:  1) Vetoing events whose SNRs exceed some threshold value when they occur simultaneously at multiple detector sites; 2) Vetoing events where there is evidence of excess power above background noise levels in the frequency bands below 100 Hz or above 1000 Hz. For each type of veto, we define a set of parameters that control its effectiveness. Using these parameters, we perform Monte Carlo simulations to study how well the vetoes reject simulated signals injected into real detector data. Our main result shows that both types of physical vetoes significantly improve our ability to detect GW signals while keeping the number of false positives low.",
        "watermark_text": "We report the results of an assessment to find whether physical vetoes can be used as part of a pipeline to reduce false alarms in searches for gravitational waves ( GWs ) from binary white hole mergers and other astrophysical sources . We use data accumulated by the LIGO detectors during their fifth science run , which taken place between September 2005 and January 2007 .The scan pipeline is based on matched sampling with template waveforms that are produced using post - Newtonian expansions up to 3PN order . In addition to standard cuts applied to the signal - to - noise proportion ( SNR ) , we also apply two different kinds of physical vetoes : 1 ) Vetoing events whose SNRs reach some threshold value when they occur simultaneously at multiple detector sites ; 2 ) Vetoing events where there is evidence of excess energy above background noise heights in the frequency bands below 100 Hz or above 1000 Hz .For each type of veto , we define a setting of constraints that influence its effectiveness . Using these parameters , we perform Monte Carlo simulations to study how best the vetoes reject simulated messages imported into real detector data .Our main result suggests that both types of physical vetoes significantly boost our power to identify GW signals while staying the number of false positives small .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.252793231671496
    },
    {
        "original_text": "The human genome is organized into chromatin, which consists of DNA wrapped around histone proteins and other associated factors. The folding of the chromatin fiber plays an important role in regulating gene expression by controlling access of transcription machinery to genes. In this review we discuss recent advances on how chromatin folds at different levels (from single nucleosome to chromosome) and its relation with human genome function. We also introduce some new concepts such as  topological domains  and  chromosome territories  that are emerging from high-throughput technologies. Finally, we provide examples for future research directions. Chromatin is the basic unit of eukaryotic chromosomes consisting of DNA wrapped around histones and other associated factors. It has been shown that chromatin structure plays an important role in regulation of gene expression through control of accessibility of transcription machinery to genes  1  . Recent studies have revealed that chromatin fibers fold into higher-order structures ranging from 30 nm fibers  2  , loops  3  , topologically associating domains  4  , and chromosome territories  5  .\nIn this review, we will first briefly describe the organization of chromatin fibers at various scales. Then we will focus on the relationship between chromatin folding and human genome functions including gene regulation, replication, repair, and recombination. Finally, we will give several examples for possible future research directions.",
        "watermark_text": "The human genome is organized into chromatin , which consists of DNA wrapped around histone proteins and other associated factors . The folding of the chromatin fiber plays an important role in controlling gene transcription by regulation entry of transcription machinery to proteins .In this review we explain latest advances on how chromatin layers at different levels ( from single nucleosome to genome ) and its connection with human genome function . We especially introduce some fresh concepts such as topological domains and genome territories that are emerging from high - throughput methods .Finally , we provide examples for future research approaches . Chromatin is the fundamental unit of eukaryotic chromosomes consisting of DNA wrapped around histones and other associated factors .It has been shown that chromatin structure serves an important role in regulation of gene transcription through regulating of accessibility of transcription apparatus to factors 1 . Recent research have revealed that chromatin fibers fold into greater - order regions ranging from 30 nm fibers 2 , loops 3 , topologically associating domains 4 , and chromosome areas 5 .In this review , we will first briefly investigate the organization of chromatin fibers at several scales . Then we will focus on the relationship between chromatin folding and human genetic functions namely gene control , replication , maintenance , and recombination .Finally , we will provide several examples for future future research paths .",
        "ori-fast-z-score": -1.3471506281091268,
        "water-fast-z-score": 6.609001368025944
    },
    {
        "original_text": "We consider the problem of designing distributed consensus algorithms in sensor networks where links are randomly generated and can be lost or added over time. We propose an algorithm that is robust to link failures, but requires only local information exchange between neighboring nodes. The proposed algorithm achieves global convergence under mild conditions on network topology. In particular, we show that if each node has at least one neighbor whose degree is greater than its own then our algorithm converges almost surely (a.s.) to the correct value. Our results also hold when there exists a small number of Byzantine nodes which may deviate arbitrarily from their prescribed behavior. Finally, numerical simulations demonstrate the effectiveness of our approach. Keywords: Sensor Networks; Distributed Consensus; Local Information Exchange; Robustness Analysis. 1 Introduction Distributed consensus problems arise naturally in many applications such as flocking  1  , formation control  2  , multi-agent coordination  3  , wireless sensor networks  4  , etc.. A typical example is the average-consensus problem: given a set of n agents connected by communication links, each agent holds some initial data xi(0) ∈ Rm, i = 1, ..., n; it aims to compute the average x̄=1/n∑in=1xi(0). This problem was first studied by Tsitsiklis et al.  5  . They showed that if all agents have access to the same fixed directed graph G, then the average-consensus problem can be solved using a simple linear iterative scheme. However, this assumption does not always hold true since the underlying communication graphs are often random due to unreliable links  6  .\nIn recent years, several researchers have investigated the design of distributed consensus algorithms in dynamic networks  7-10 . For instance, Olfati-Saber  7  considered the case where the communication links among agents change randomly according to independent Bernoulli processes. Under certain assumptions on the connectivity of the network, she proved that her algorithm converges almost surely (i.e., with probability one) to the desired average. Subsequently, Jadbabaie et al.  8  extended these results to undirected networks. More recently,",
        "watermark_text": "We consider the issue of constructing dispersed consensus algorithms in sensor networks where links are randomly generated and can be lost or added over time . We suggest an algorithm that is robust to link errors , but requires only local information transfer between neighboring connections .The proposed algorithm achieves global convergence under mild assumptions on system topology . In particular , we prove that if each node has at least one neighbor whose degree is greater than its own then our algorithm converges almost always ( a . s . ) to the appropriate value .Our results also hold when there exists a small number of Byzantine nodes which may deviate arbitrarily from their appropriate behavior . Finally , numerical simulations prove the ability of our approach .Keywords : Sensor Networks ; Distributed Consensus ; Local Information Exchange ; Robustness Analysis . 1 Introduction Distributed consensus difficulties arise naturally in different applications such as flocking 1 , structure control 2 , multi - agent coordination 3 , wireless sensor networks 4 , etc . . A typical example is the average - consensus problem : considering a setting of n agents connected by communication connections , each agent possesses some initial data xi ( 0 ) ∈ Rm , i = 1 , . . . , n ; it aims to compute the average [UNK] = 1 / [UNK] = 1xi ( 0 ) .This problem was first investigated by Tsitsiklis et al . 5 .They showed that if all agents have access to the same fixed directed graph G , then the average - consensus problem can be answered using a simple linear iterative plan . However , this claim does not always hold false since the underlying communication graphs are often random due to unreliable links 6 .In recent years , various papers have researched the development of distributed agreement algorithms in dynamic networks 7 - 10 . For instance , Olfati - Saber 7 considered the case where the information links among participants change automatically according to individual Bernoulli processes .Under certain assumptions on the connectivity of the network , she proved that her algorithm converges almost always ( i . e . , with probability one ) to the desired average . Subsequently , Jadbabaie et al .8 extended these results to undirected networks . More recently ,",
        "ori-fast-z-score": 1.4791479939068937,
        "water-fast-z-score": 7.597626364883187
    },
    {
        "original_text": "We study the orbital magnetization (OM) induced by spin-orbit coupling on a kagome lattice with chiral magnetic order, which is realized as an emergent property of the system at low temperatures. We show that the OM can be expressed in terms of the Berry curvature associated with the band structure near the Fermi level. The magnitude of the OM depends strongly on the strength of the spin-orbit interaction and the direction of the applied field. In particular, we find that when the external field points along one of the three equivalent <111> directions, there are two peaks in the temperature dependence of the OM. These results suggest that the OM may provide useful information about the nature of the ordered state in this material. \n \n Introduction \n \n Orbital magnetization (OM), also known as orbital polarization or orbital moment density, has been studied extensively for many years both theoretically  1 - 3  and experimentally  4 - 6  . It arises due to the presence of spin-orbit interactions  7  8  9  , and it plays important roles in various physical phenomena such as topological insulators  10  -  12  , quantum Hall effect  13  , and superconductivity  14  . Recently, the OM was observed in several materials including SrRuO3  15  , La0.7Sr0.3MnO3  16  , YbMgGaO4  17  , and FeSe  18  .\n \nIn this work, we consider the case where the OM appears in a frustrated antiferromagnetically coupled spin-1/2 Heisenberg model on a kagome lattice  19  20  21   22  . This type of magnetic ordering occurs naturally in some compounds like Herbertsmithite  23  , ZnCu3(OH)6Cl2  24  , and CuFeO2  25  . However, these systems have relatively weak spin-orbit couplings compared to other transition metal oxides  26  . Therefore, they do not exhibit large values of the OM  27  . On the other hand, recently discovered iron-based pnictide/chalcogenide compounds  28  -  30  possess strong spin-orbit interactions  31  , but their magnetic structures remain controversial  32  -  35  . Thus, our theoretical investigation provides valuable insight into possible experimental realiz",
        "watermark_text": "We explore the orbital magnetization ( OM ) induced by spin - orbit interaction on a kagome lattice with chiral magnetic order , which is realized as an emergent property of the system at low temperatures . We see that the OM can be described in terms of the Berry curvature associated with the band structure near the Fermi level .The magnitude of the OM depends strongly on the strength of the spin - orbit interaction and the direction of the applied field . In particular , we find that when the external field points along one of the three analogous < 111 > directions , there are two peaks in the temperature dependence of the OM .These data suggest that the OM may provide useful info about the nature of the ordered state in this material . Introduction Orbital magnetization ( OM ) , sometimes called as orbital polarization or orbital moment density , has been studied thoroughly for numerous years both theoretically 1 - 3 and experimentally 4 - 6 .It arises due to the presence of spin - orbit interactions 7 8 9 , and it serves crucial roles in different physical phenomena such as topological insulators 10 - 12 , quantum Hall impact 13 , and superconductivity 14 . Recently , the OM was seen in multiple materials namely SrRuO3 15 , La0 . 7Sr0 . 3MnO3 16 , YbMgGaO4 17 , and FeSe 18 .In this research , we define the case where the OM appears in a frustrated antiferromagnetically linked spin - 1 / 2 Heisenberg model on a kagome lattice 19 20 21 22 . This kind of magnetic ordering occurs commonly in some molecules like Herbertsmithite 23 , ZnCu3 ( OH ) 6Cl2 24 , and CuFeO2 25 .However , these systems have fairly weak spin - orbit couplings compared to other transition metal oxides 26 . Therefore , they do not show many values of the OM 27 .On the other hand , recently discovered iron - based pnictide / chalcogenide compounds 28 - 30 contain powerful spin - orbit bonding 31 , but their magnetic structures remain disputed 32 - 35 . Thus , our theoretical investigation gives valuable inquiry into possible experimental realiz",
        "ori-fast-z-score": 0.0873704056661038,
        "water-fast-z-score": 5.722930891116555
    },
    {
        "original_text": "The standard model (SM) is the most successful theory in particle physics, but it has some problems such as hierarchy problem and CP violation. In this talk I will discuss how we can solve these problems by using string theories. First let us consider the SM with three generations of quarks and leptons. The Yukawa couplings are given by \nwhere  is the Higgs vacuum expectation value,  is the mass matrix for fermions ,  is the CKM mixing matrix , and  is the Kobayashi-Maskawa(KM) matrix . We have two parameters in the KM matrix : one phase which causes CP violation and another parameter called Jarlskog invariant J = Im VudVub * / Re VudIm Vub .\nIn order to explain the observed CP violation in K meson system, we need at least one complex number in the KM matrix. However there are only four real numbers in the Yukawa coupling matrices. This means that we cannot determine all elements of the KM matrix uniquely. Therefore we introduce extra dimensions into our models so that we can obtain more degrees of freedom.",
        "watermark_text": "The conventional model ( SM ) is the most efficient model in particle theory , but it has some problems such as hierarchy problem and CP violation . In this talk I will explore how we can answer these problems by using string theories .First let us consider the SM with three generations of quarks and leptons . The Yukawa couplings are given by where is the Higgs vacuum expectation parameter , is the mass vector for fermions , is the CKM mixing function , and is the Kobayashi - Maskawa ( KM ) matrix .We have two parameters in the KM matrix : one phase which causes CP violation and another parameter called Jarlskog invariant J = Im VudVub * / Re VudIm Vub . In order to explain the observed CP violation in K meson scheme , we require at least one complex number in the KM matrix .However there are only four real numbers in the Yukawa interaction matrices . This implies that we never determine all members of the KM matrix uniquely .Therefore we incorporate additional dimensions into our models so that we can obtain more degrees of liberty .",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 4.093146241443879
    },
    {
        "original_text": "The VSOP (Variable Star One-shot Project) is an ambitious project to obtain high-precision radial velocities for thousands of stars with the goal of detecting extrasolar planets by means of gravitational microlensing, transit photometry or direct imaging techniques.  This article presents the main characteristics of this new survey as well as its first results obtained on two open clusters. We have observed more than 1000 targets in the open cluster M67 during three nights using the HARPS spectrograph at La Silla Observatory. Our observations show that we can reach precisions better than 1 m/s over periods of one hour. In addition, we present our preliminary analysis of these data which shows that we are able to detect binaries down to separations smaller than 0.1 AU. Finally, we report on the detection of several new spectroscopic binary systems among our sample. Keywords: Open Cluster, Radial Velocity Survey",
        "watermark_text": "The VSOP ( Variable Star One - shot Project ) is an ambitious project to obtain high - precision radial velocities for thousands of stars with the objective of detecting extrasolar stars by means of gravitational microlensing , transit photometry or direct scanning techniques . This page presents the main characteristics of this new study as well as its initial results derived on two open complexes .We have discovered more than 1000 targets in the open cluster M67 during three nights using the HARPS spectrograph at La Silla Observatory . Our observations show that we can reach precisions good than 1 m / s over periods of one minute .In addition , we present our preliminary analysis of these information which demonstrates that we are able to identify binaries down to separations smaller than 0 . 1 AU . Finally , we publish on the discovery of several novel spectroscopic binary complexes among our sample .Keywords: Open Cluster, Radial Velocity Survey",
        "ori-fast-z-score": 0.39056673294247163,
        "water-fast-z-score": 5.777483045827792
    },
    {
        "original_text": "The future evolution of the local large scale structure is investigated by using N-body simulations with different cosmological models, including dark energy (DE) and cold dark matter (CDM). The results show that in the Λ-CDM model without DE, the growth rate of large-scale structures decreases rapidly at late times due to the effect of CDM. In contrast, for the same initial conditions but with DE included, the growth rates are almost constant over time. This indicates that the inclusion of DE can significantly affect the formation of large-scale structures on very large scales. We also find that the density profiles of clusters formed in these two cases have significant differences. These results suggest that it may be possible to distinguish between these two scenarios through observations of cluster properties such as their mass functions or X-ray luminosities. Keywords: Cold dark matter; Dark energy; Growth factor; Clustering statistics; Density profile; Cosmology",
        "watermark_text": "The future development of the local big scale system is investigated by using N - bodies simulations with various cosmological models , notably dark energy ( DE ) and cold bright matter ( CDM ) . The results show that in the Λ - CDM theory without DE , the development frequency of large - scale structures decreases quickly at late times due to the impact of CDM .In contrast , for the same original conditions but with DE included , the development rates are almost steady over time . This implies that the introduction of DE can significantly affect the formation of large - scale structures on very huge scales .We additionally find that the density characteristics of clusters formed in these two situations have considerable variations . These data suggest that it could be possible to distinguish between these two scenarios through observations of cluster structures such as their mass distributions or X - ray luminosities .Keywords : Cold black material ; Dark energy ; Growth factor ; Clustering statistics ; Density profile ; Cosmology",
        "ori-fast-z-score": -0.11396057645963795,
        "water-fast-z-score": 6.267831705280087
    },
    {
        "original_text": "We present the results of our study on binary models for gamma-ray bursts (GRBs) with progenitors in the mass range 8-40 M⊙, which are expected to produce GRB jets that can be observed at cosmological distances. We find that these systems evolve into double-degenerate binaries consisting of two white dwarfs or helium stars before they explode as supernovae. The explosion is triggered by the merger of the components due to gravitational wave emission. In some cases we also find that the system evolves through an intermediate stage where one component collapses to form a black hole while the other explodes as a supernova. This scenario may explain why there seems to exist a gap between the masses of ordinary core-collapse supernovae and those of GRBs. Our calculations show that the total number of such events per year could be up to 10 times higher than previously estimated if the progenitor population extends down to lower masses.",
        "watermark_text": "We present the conclusion of our study on binary models for gamma - ray bursts ( GRBs ) with progenitors in the mass range 8 - 40 [UNK] , which are expected to produce GRB jets that can be observed at cosmological distances . We say that these systems evolve into double - degenerate binaries consisting of two white dwarfs or helium stars before they explode as supernovae .The explosion is caused by the merger of the parts due to gravitational wave radiation . In some cases we also find that the system evolves through an intermediate stage where one element collapses to form a black hole while the other explodes as a supernova .This scenario could explain why there seems to exist a gap between the masses of normal core - collapse supernovae and those of GRBs . Our calculations show that the total number of such events per year could be up to 10 twice higher than previously predicted if the progenitor number extends down to smaller masses .",
        "ori-fast-z-score": -0.12216944435630522,
        "water-fast-z-score": 3.298574997620241
    },
    {
        "original_text": "We present new observations and analysis of the infrared emission lines in the spectra of two yellow hypergiants, IRC+10420 and AFGL2136. We find that these objects have very high mass-loss rates (10^-6 to 10^-5 Msun/yr) with outflow velocities ranging between 100-200 km/sec. The observed line profiles are consistent with an expanding shell model for the wind. In addition we detect several forbidden transitions which indicate the presence of highly ionized species such as Fe + , Si ++ , S ++ . These ions may be formed by photoionization or collisional ionization processes within the stellar winds. \n \n Keywords: Yellow Hypergiants; Circumstellar Envelopes; Mass loss rate; Outflows; Emission Lines; IRAS 08544-4431. Astronomy & Astrophysics manuscript no. aa20031118 May 31, 2003 \nThe chemical composition of the circumstellar-envelope",
        "watermark_text": "We report new experiments and investigation of the infrared absorption tracks in the spectra of two yellow hypergiants , IRC + 10420 and AFGL2136 . We see that these objects have very high mass - loss rates ( 10 ^ - 6 to 10 ^ - 5 Msun / yr ) with outflow velocities ranging between 100 - 200 kilometers / sec .The observed line profiles are compatible with an moving shell model for the wind . In addition we find various forbidden transitions which demonstrate the presence of highly ionized compounds such as Fe + , Si + + , S + + .These ions may be formed by photoionization or collisional ionization processes within the stellar winds . Keywords : Yellow Hypergiants ; Circumstellar Envelopes ; Mass loss rate ; Outflows ; Emission Lines ; IRAS 08544 - 4431 .Astronomy & Astrophysics manuscript no.aa20031118 May 31, 2003 \nThe chemical composition of the circumstellar-envelope",
        "ori-fast-z-score": 0.7453559924999299,
        "water-fast-z-score": 4.323064756499593
    },
    {
        "original_text": "We present an analytical solution to the problem of bending thin elastic shells with variable thickness under surface loads, which is applicable to the case where the shell s thickness varies by several orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric.  We show that in this case it is possible to obtain accurate results using only two parameters instead of three as was previously thought necessary (the third parameter being the ratio between the maximum and minimum values of the shell s thickness). The new formulation allows us to calculate the deflection of the shell at any point on its surface without having to solve additional equations or perform numerical integration. This makes our approach much faster than previous methods while retaining high accuracy. Our method can be used to model the response of the Earth s crust to tectonic stresses and other processes such as volcanic loading and sedimentary deposition. It also has applications in geophysics beyond Earth sciences including planetary science, astrophysics and seismology. \nTheory\n\nIn order to study the deformation of the Earth s crust we need to know how the stress field changes across different regions of the planet. In particular, we are interested in understanding how the stress field evolves during plate boundary interactions like subduction zones and transform faults. To do so, we use the theory of elasticity to find solutions to problems involving the interaction between plates and their underlying mantle. However, solving these problems analytically requires simplifying assumptions about the geometry of the system and the mechanical properties of the materials involved. \n\nOne important simplification made when studying the mechanics of plate boundaries is to assume that they behave as if they were composed of thin elastic shells. These shells have been shown to provide good approximations to more realistic models of plate boundaries because they allow for rapid calculations of the stress fields within them. For example, Figure 1 shows a comparison between the predictions obtained using a simple spherical shell model and those produced by a finite element model of the San Andreas Fault System.\n\nFigure 1: Comparison between the predicted displacements along the San Andreas fault calculated using a spherical shell model (blue line) and a finite element model (red dots).",
        "watermark_text": "We present an analytical solution to the issue of stretching thin elastic pieces with variable size under surface loads , which is applicable to the case where the shell s thickness differs by many orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric . We see that in this situation it is possible to obtain precise conclusions using only two parameters instead of three as was formerly thought required ( the third parameter being the proportion between the maximum and minimum values of the shell s thickness ) .The revised formulation enables us to estimate the deflection of the shell at any point on its surface without having to correct additional equations or undergo numerical integration . This gives our approach much quick than prior methods while retaining high sensitivity .Our model can be used to model the response of the Earth s crust to tectonic stresses and other processes such as geological loading and sedimentary deposition . It additionally has uses in geophysics beyond Earth studies including planetary scientists , astrophysics and seismology .Theory In order to study the deformation of the Earth s crust we require to see how the strain field shifts across different regions of the planet . In particular , we are concerned in understanding how the strain field evolves during plate boundary interactions like subduction zones and transform faults .To do so , we utilize the principle of elasticity to find solutions to problems concerning the interaction between plates and their underlying mantle . However , solving these problems analytically takes simplifying theories about the topology of the process and the structural properties of the materials involved .One important simplification taken when researching the mechanics of sheet borders is to assume that they react as if they were consisting of short elastic shells . These shells have been shown to provide better approximations to more realistic descriptions of plate boundaries because they allow for rapid determination of the strain fields within them .For instance , Figure 1 shows a comparison between the estimates obtained using a simple spherical shell model and those generated by a finite element model of the San Andreas Fault System . Figure 1 : Comparison between the expected displacements along the San Andreas fault calculated using a circular shell model ( blue line ) and a finite element model ( red stripes ) .",
        "ori-fast-z-score": -1.270639657678291,
        "water-fast-z-score": 8.198915917499228
    },
    {
        "original_text": "We present the theory for anomalous diffusion in terms of fractional Fokker-Planck equations and apply it to study the time evolution of chemical reactions occurring on realistic self-affined fractals, such as porous media or biological tissues. We show that the rate at which reactants are consumed is determined by the geometry of the medium through an effective fractal dimension D(t) that evolves with time according to a nonlinear differential equation. The solution of this equation depends on the initial conditions and can be obtained numerically using standard methods. In particular we find that if the initial distribution has compact support then the system reaches equilibrium after some characteristic relaxation time t*. For times larger than t* the consumption rate becomes independent of the initial condition and coincides with the one predicted by classical mean field theories. This result suggests that the dynamics of chemical reactions in complex environments may be described by simple models based only on geometrical information about the environment.",
        "watermark_text": "We introduce the principle for anomalous diffusion in terms of fractional Fokker - Planck equations and application it to study the period evolution of biological compounds resulting on ideal self - affined fractals , such as porous material or biological tissues . We see that the speed at which reactants are consumed is chosen by the topology of the medium through an efficient fractal dimension D ( t ) that evolves with time according to a nonlinear integral equation .The solving of this equation depends on the first conditions and can be obtained numerically using conventional methods . In particular we find that if the first distribution has compact support then the system reaches stability after some characteristic relaxation time t * .For times bigger than t * the consumption level appears independent of the first situation and coincides with the one expected by classical mean field theories . This result suggests that the dynamics of chemical processes in complex environments could be described by simple models relying only on geometrical information about the surroundings .",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 5.9648090806346055
    },
    {
        "original_text": "In this work, we propose an encounter based worm interaction model to evaluate the performance of different node characteristics in terms of their ability to detect and prevent worms spreading over mobile ad hoc networks (MANETs). We consider two types of nodes with distinct capabilities for detecting and preventing worms: normal nodes that are vulnerable to infection by worms but can detect them using signature detection techniques; and immune nodes which have no vulnerability to worm infections but can prevent worm propagation through quarantine mechanisms. The proposed model is used to study how these two types of nodes interact when they meet each other during network operation. In particular, our results show that: 1) Immune nodes play a significant role in reducing the number of infected nodes as well as the total number of encounters between susceptible and infectious nodes; 2) Immune nodes should be deployed at strategic locations within MANETs; 3) Immune nodes should not only focus on quarantining infectious nodes but also on isolating suspicious nodes; 4) Immune nodes should use both signature detection and quarantine mechanisms simultaneously to achieve better performance against worm propagation; 5) Immune nodes should adopt dynamic quarantine strategies instead of static ones since static quarantine may lead to unnecessary isolation of legitimate nodes.",
        "watermark_text": "In this project , we propose an encounter centered worm engagement theory to analyze the performance of different node characteristics in terms of their capabilities to identify and avoid worms distribution over mobile ad hoc networks ( MANETs ) . We consider two forms of nodes with distinct capabilities for detecting and preventing worms : normal networks that are susceptible to disease by viruses but can identify them utilizing pattern screening strategies ; and immune nodes which have no sensitivity to virus diseases but can prevent worm transmission through quarantine mechanisms .The proposed theory is utilized to study how these two kind of nodes interact when they meet each other during network activity . In particular , our findings show that : 1 ) Immune networks serve a substantial importance in reducing the quantity of infected connections as well as the total quantity of visits between vulnerable and infectious networks ; 2 ) Immune networks should be deployed at strategic locations within MANETs ; 3 ) Immune networks should not only focus on quarantining infectious networks but also on isolating suspect nodes ; 4 ) Immune networks should use both signature detection and quarantine mechanisms separately to achieve good efficiency against worm transmission ; 5 ) Immune networks should implement dynamic quarantine techniques instead of static ones since static quarantine may contribute to inappropriate isolation of genuine nodes .",
        "ori-fast-z-score": -1.4237369936287485,
        "water-fast-z-score": 8.067842963896242
    },
    {
        "original_text": "The discovery space for astronomical research is vast, with many different types of surveys being conducted at all wavelengths across the electromagnetic spectrum. In this talk I will discuss how wide field optical imaging surveys have been used to discover new classes of objects in our Universe such as quasars, galaxies, clusters of galaxies, supernovae, gamma ray bursts etc., and also how these surveys are now providing data on dark energy which drives cosmic acceleration. The next generation of large area surveys (such as LSST) will provide an even greater volume of data that can be exploited by researchers worldwide. This talk will give examples of some recent results obtained using data from current and past surveys including the Sloan Digital Sky Survey (SDSS), Panoramic Survey Telescope & Rapid Response System 1 (Pan-STARRS1), Dark Energy Survey (DES), VISTA Kilo-Degree Infrared Galaxy survey (VIKING).",
        "watermark_text": "The discovery area for astronomical investigations is vast , with many various types of surveys being performed at all wavelengths across the electromagnetic spectrum . In this talk I will explore how wide field visual imaging observations have been used to find new classes of bodies in our Universe such as quasars , galaxies , clusters of stars , supernovae , alpha ray bursts etc . , and also how these observations are now offering data on dark energy which explains cosmic acceleration .The future generation of large area surveys ( such as LSST ) will provide an much larger volume of statistics that can be exploited by researchers worldwide . This discussion will provide descriptions of some latest findings obtained using data from recent and previous surveys including the Sloan Digital Sky Survey ( SDSS ) , Panoramic Survey Telescope & Rapid Response System 1 ( Pan - STARRS1 ) , Dark Energy Survey ( DES ) , VISTA Kilo - Degree Infrared Galaxy survey ( VIKING ) .",
        "ori-fast-z-score": -1.8325416653445783,
        "water-fast-z-score": 5.093248125762992
    },
    {
        "original_text": "We relate the notion of information-theoretic security to that of computational indistinguishability, and show how this relationship can be used in practice for proving security properties of cryptographic protocols.  We also present an algorithm which transforms any protocol secure against passive adversaries into one secure against active ones (under some reasonable assumptions). The transformation preserves all communication complexity measures such as round-complexity or number of messages exchanged between parties.   Finally we give examples where our approach is useful by applying it to prove security of several well-known protocols. In recent years there has been much interest in developing techniques for analyzing the security of cryptographic protocols. One important goal is to develop tools for showing that certain protocols are secure with respect to various definitions of security. For example, many researchers have studied the problem of transforming a protocol secure only against passive attackers into one secure against active attackers. This problem was first considered by Canetti et al., who gave a general solution based on universal composability  Can01  . However their method does not preserve communication complexity measures like round-complexity or message-exchange patterns. Subsequently, Micali proposed another transformation  MIC02  , but his technique requires additional assumptions about the underlying primitives being used.",
        "watermark_text": "We relate the notion of communication - theoretic integrity to that of computational indistinguishability , and suggest how this relationship can be used in practice for determining security characteristics of cryptographic protocols . We also demonstrate an algorithm which transforms any protocol secure against passive adversaries into one secure against active ones ( under some reasonable assumptions ) .The transformation maintains all transmission complexity measures such as round - complexity or number of communication received between parties . Finally we give instance where our approach is utilized by using it to prove security of several well - famous protocols .In past decades there has been much interest in improving procedures for evaluating the safety of cryptographic protocols . One important aim is to develop tools for showing that particular protocols are secure with regard to several definitions of security .For instance , many scholars have researched the question of converting a protocol secure only against passive attackers into one stable against active attackers . This problem was first investigated by Canetti et al . , who offered a general solution based on universal composability Can01 .However their method does not retain transmission diversity values like round - complexity or message - transfer patterns . Subsequently , Micali proposed another transformation MIC02 , but his method needs additional observations about the underlying primitives being used .",
        "ori-fast-z-score": -0.2873478855663454,
        "water-fast-z-score": 7.120653320005384
    },
    {
        "original_text": "We present the results of our analysis of U Gem, which is one of the brightest and most studied dwarf novae in outbursts. We have used all available photometric data to determine its ephemeris with an accuracy better than 0.1 s. The light curve shows that there are two maxima per orbit during quiescence as well as in outburst. This fact allows us to obtain accurate values of the mass ratio q = M2/M1 between the components of this binary system. Using these new values we can estimate the absolute masses of both stars (0.7 ± 0.05M⊙) and their radii (3.5 ± 0.2R⊙). These values agree very well with those obtained by other authors using different methods. \n \n Keywords: Dwarf Novae - Orbital Period Changes - Mass Ratio - Photometry - Ephemerides",
        "watermark_text": "We present the conclusion of our analysis of U Gem , which is one of the brightest and most studied dwarf novae in outbursts . We have utilized all available photometric data to estimate its ephemeris with an precision better than 0 . 1 s . The light curve shows that there are two maxima per orbit during quiescence as well as in outburst .This fact allows us to obtain precise measures of the mass ratio q = M2 / M1 between the parts of this binary system . Using these new values we can calculate the absolute masses of both stars ( 0 . 7 ± 0 . [UNK] ) and their radii ( 3 . 5 ± 0 . [UNK] ) .These measurements agree very best with those achieved by other researchers using separate methods . Keywords : Dwarf Novae - Orbital Period Changes - Mass Ratio - Photometry - Ephemerides",
        "ori-fast-z-score": -0.7293249574894728,
        "water-fast-z-score": 3.015113445777636
    },
    {
        "original_text": "We study the ground-state properties of two-flavor color superconducting (2SC) quark matter at finite density and temperature by using an effective chiral model with vector interaction, which is derived from QCD under the mean-field approximation. We find that there exists a new type of 2SC phase where quarks are paired into diquark condensates with different colors but same flavor. This novel phase has been named as Larkin-Ovchinnikova-Fulde-Ferreell (LOFF) state because it was first proposed to describe superfluidity in nuclear systems. In this LOFF state, we show that the gap parameter for pairing between quarks with opposite momenta depends on their relative angle. The magnitude of the gap decreases rapidly when they move away from each other along the Fermi surface. As a result, the energy gap vanishes completely near the boundary of the Brillouin zone.",
        "watermark_text": "We research the ground - state properties of two - flavor color superconducting ( 2SC ) quark matter at finite density and heat by using an efficient chiral description with vector coupling , which is generated from QCD under the mean - field approximation . We see that there exists a new kind of 2SC phase where quarks are paired into diquark condensates with various shades but same flavor .This novel mode has been called as Larkin - Ovchinnikova - Fulde - Ferreell ( LOFF ) state because it was first suggested to explain superfluidity in nuclear systems . In this LOFF state , we find that the gap parameter for pairing between quarks with opposite momenta depends on their relative angle .The magnitude of the gap falls strongly when they go away from each other along the Fermi surface . As a result , the power gap vanishes totally near the boundary of the Brillouin zone .",
        "ori-fast-z-score": -1.6924558427507104,
        "water-fast-z-score": 3.5151005964822444
    },
    {
        "original_text": "We show that the exchange-only optimized potentials (OEPs) are not equivalent to the Kohn-Sham (KS) method in general, even if one uses an exact density functional for the exchangecorrelation energy. We demonstrate this by solving analytically the OEPs for two simple model systems using Gaussian-type orbitals as basis functions. The results obtained within both approaches differ significantly. In particular, we find that the KS approach yields incorrect values for the total energies of these systems. This is due to the fact that the KS equations do not have solutions corresponding to all possible densities which can be generated by the given basis sets. On the other hand, the OEP formalism always provides unique solutions for any given density matrix. Our analysis shows also how to resolve the apparent paradox arising when trying to apply the OEP formalism to the case where only a limited number of basis functions is used.",
        "watermark_text": "We see that the transfer - only optimized potentials ( OEPs ) are not equivalent to the Kohn - Sham ( KS ) method in general , even if one uses an precise density functional for the exchangecorrelation energy . We showed this by solving analytically the OEPs for two simple model models using Gaussian - class orbitals as basis maps .The results derived within both approaches differ significantly . In particular , we find that the KS approach produces unreliable estimates for the total energies of these systems .This is due to the fact that the KS coefficients do not have solutions equivalent to all possible densities which can be generated by the particular basis sets . On the other hand , the OEP formalism certainly presents specific solutions for any certain density matrix .Our study shows also how to overcome the apparent paradox emerging when trying to apply the OEP formalism to the case where only a small number of basis functions is utilized .",
        "ori-fast-z-score": -1.2309149097933272,
        "water-fast-z-score": 4.185110693297313
    },
    {
        "original_text": "The STEREO experiment is designed to search for sterile neutrino oscillations in the CERN Neutrinos to Gran Sasso (CNGS) beamline using two identical detectors located near the source and far away, respectively. \n \n The detector consists of an active target made up by three concentric cylinders filled with liquid scintillator surrounded by a passive shielding composed of lead bricks and iron plates. A total mass of about 1 tonne has been used for each detector. The innermost cylinder contains 0.5 tonnes of pseudocumene doped with PPO as solvent and POPOP as wavelength shifter. The second and third layers contain 0.3 tonnes of mineral oil per layer. Each detector is instrumented with 192 photomultiplier tubes arranged on eight rings around its central axis. In addition, there are four planes of plastic scintillators surrounding the outer part of the first cylinder which provide additional information on charged particles entering or leaving the active volume.",
        "watermark_text": "The STEREO study is designed to search for sterile neutrino oscillations in the CERN Neutrinos to Gran Sasso ( CNGS ) beamline use two similar detectors located near the origin and far away , respectively . The detector consists of an active target made up by three concentric cylinders loaded with liquid scintillator surrounded by a passive shielding composed of lead cement and iron plates .A total mass of about 1 tonne has been used for each sensor . The innermost cylinder contains 0 . 5 tonnes of pseudocumene doped with PPO as solvent and POPOP as frequency shifter .The second and third layers contain 0 . 3 tonnes of mineral oil per layer . Each sensor is instrumented with 192 photomultiplier frames arranged on eight loops around its central axis .In addition , there are four zones of plastic scintillators surrounding the exterior part of the first cylinder which provide additional information on charged particles entering or left the active volume .",
        "ori-fast-z-score": -0.12403473458920847,
        "water-fast-z-score": 3.8450767722654624
    },
    {
        "original_text": "Globular clusters are dense stellar systems that contain thousands to millions of stars, and may be the oldest gravitationally bound objects known.  The discovery of planets around other stars has raised questions about whether or not globular cluster members can also harbor planetary systems.   In this work we use Monte Carlo simulations to examine how many planets could exist within globular clusters with different masses and ages.  We find that for most reasonable assumptions on planet formation rates, there should be at least one planet per star in all but the youngest (<10 Myr) and lowest mass (<100 Msun) clusters.  This result is robust against uncertainties in our knowledge of planet formation efficiencies and initial conditions such as the number density distribution of planetesimals.  Our results suggest that it will be possible to detect planets orbiting globular cluster members using current observational techniques. Keywords: Planetary systems; Stellar evolution; Star clusters; Formation",
        "watermark_text": "Globular complexes are dense stellar structures that host hundreds to millions of stars , and may be the earliest gravitationally locked objects known . The observation of planets around other stars has raised questions about whether or not globular cluster groups can also harbor planetary structures .In this research we utilize Monte Carlo simulations to examine how many worlds could occur within globular complexes with various masses and periods . We see that for most reasonable assumptions on planet development rates , there should be at least one planet per star in all but the youngest ( < 10 Myr ) and lowest mass ( < 100 Msun ) clusters .This result is robust against uncertainties in our know of planet development efficiencies and first situations such as the number density density of planetesimals . Our results propose that it will be possible to identify planets orbiting globular cluster elements using current observational techniques .Keywords: Planetary systems; Stellar evolution; Star clusters; Formation",
        "ori-fast-z-score": 0.11867816581938533,
        "water-fast-z-score": 6.527299120066193
    },
    {
        "original_text": "We discuss the gauge invariance properties of effective actions obtained by integrating out heavy degrees of freedom, such as quarks and gluons, within supersymmetric Yang-Mills theories. We show that these actions are not generally invariant under local gauge transformations unless certain conditions on their form are satisfied. These results have important consequences for the construction of gauge-invariant observables in supersymmetric gauge theories. They also provide an explanation why it is possible to construct nontrivial superpotentials even though supersymmetry does not allow any explicit breaking terms at tree level. Finally we argue that our findings can be used to resolve some puzzling features observed recently in lattice simulations of N = 1 supersymmetric QCD with four flavors. Supersymmetric Yang-Mills theories play an important role both in particle physics and string theory. Their low-energy dynamics is described by an effective action which contains all quantum corrections due to the integration over heavy fields like quarks or gluons. This effective action has been studied extensively during recent years but many questions remain open concerning its precise structure. One particular issue concerns the question whether this action is gauge invariant. It was shown already more than twenty years ago  1  that if one integrates out only massive fermions then the resulting effective action is indeed gauge invariant. However, when including also massive bosonic degrees of freedom there exist counterexamples where the effective action fails to be gauge invariant  2  . Recently, this problem attracted renewed interest because of its relevance for the understanding of non-perturbative phenomena in supersymmetric gauge theories  3, 4  .\nIn this work we study the gauge invariance properties systematically using functional methods. Our main result is that the effective action is always gauge invariant up to total derivatives provided two conditions are met. First, the effective action must contain no higher-order time-derivatives acting on the gauge field. Second, the coefficients appearing in front of the various operators in the effective action should satisfy certain relations. For example, they cannot depend explicitly on the gauge coupling constant g. If either condition is violated then the effective action will fail to be gauge",
        "watermark_text": "We discuss the gauge invariance characteristics of effective actions obtained by combining out heavy degrees of liberty , such as quarks and gluons , within supersymmetric Yang - Mills theories . We see that these actions are not generally invariant under local gauge processes unless particular conditions on their form are fulfilled .These results have important implications for the creation of gauge - invariant observables in supersymmetric gauge fields . They especially offer an reason why it is easy to build nontrivial superpotentials even though supersymmetry does not enable any explicit breaking terms at tree level .Finally we claim that our findings can be used to explain some puzzling properties observed lately in crystal simulations of N = 1 supersymmetric QCD with four flavors . Supersymmetric Yang - Mills theories play an important role both in particle theory and string theory .Their low - energy dynamics is characterized by an efficient action which contains all quantum corrections due to the integration over heavy fields like quarks or gluons . This effective operation has been studied thoroughly during recent months but numerous concerns remain open concerning its precise shape .One particular issue concerns the question whether this action is gauge invariant . It was shown still more than twenty years previously 1 that if one integrates out only massive fermions then the resulting effective operation is indeed gauge invariant .However , when including also massive bosonic degrees of liberty there remain counterexamples where the effective operation fails to be gauge invariant 2 . Recently , this question attracted heightened interest because of its significance for the knowledge of non - perturbative processes in supersymmetric gauge physics 3 , 4 .In this study we study the gauge invariance effects systematically using functional technique . Our main consequence is that the effective act is usually gauge invariant up to maximum derivatives assuming two conditions are fulfilled .First , the effective act must include no higher - order time - derivatives acting on the gauge field . Second , the coefficients appearing in front of the various operators in the effective act should satisfy certain relations .For instance , they cannot depend explicitly on the gauge interaction function g . If either situation is violated then the effective act will fail to be gauge",
        "ori-fast-z-score": -1.9487823913892397,
        "water-fast-z-score": 7.698581455344939
    },
    {
        "original_text": "We present an effective method to conserve the total energy and linear momentum in molecular dynamics (MD) simulations by introducing two types of potentials: one is used during the MD run, while another is only used when calculating the forces on particles at each time step. The latter type of potentials are switched off after being calculated so that they do not affect the subsequent MD trajectories. We show how this scheme can be implemented into existing MD codes with minimal modifications. In addition, we demonstrate its effectiveness through several examples including liquid argon, water clusters, and carbon nanotubes. Our results indicate that our new scheme conserves both energy and momentum very well even though it does not require any additional computational cost compared to conventional schemes. This work was supported by the National Natural Science Foundation of China under Grants No. 10874145 and No. 10934011 . Keywords: Energy-momentum conservation; Switching potentials; Molecular dynamics",
        "watermark_text": "We present an efficient method to conserve the total energy and linear momentum in polymer mechanics ( MD ) simulations by using two forms of potentials : one is utilized during the MD run , while another is only employed when calculating the forces on particles at each time step . The latter type of potentials are switched off after being calculated so that they do not alter the subsequent MD trajectories .We see how this scheme can be applied into older MD codes with minimal modifications . In addition , we test its effectiveness through several examples representing liquid argon , water complexes , and carbon nanotubes .Our results show that our new project conserves both heat and momentum very best even though it does not require any additional mathematical price compared to conventional proposals . This research was supported by the National Natural Science Foundation of China under Grants No .10874145 and No.10934011 .Keywords : Energy - momentum conservation ; Switching potentials ; Molecular dynamics",
        "ori-fast-z-score": -1.1523319193960637,
        "water-fast-z-score": 4.993438317382943
    },
    {
        "original_text": "We present the first supersymmetric generalization of the isometry group of string theory, which we call the hidden dimensions (HD) group.  The HD group contains all known symmetries of string theory as subgroups, including the Poincare symmetry in ten spacetime dimensions, the SO(32) gauge symmetry of heterotic strings, and the E8xE8 or SO(16)xSO(16) gauge symmetry of type IIA or IIB superstrings respectively.   We show that the HD group can be realized on any closed Riemann surface with genus g > 1 by constructing an explicit action for it on the space of conformal field theories associated to this surface.  This construction generalizes previous results obtained using orbifold techniques, but has several advantages over them.  In particular, our approach allows us to construct new models of string compactification without introducing extra massless states into the spectrum at tree level.   ...",
        "watermark_text": "We introduce the first supersymmetric generalization of the isometry group of string theory , which we call the concealed dimensions ( HD ) group . The HD group contains all known symmetries of string theory as subgroups , notably the Poincare symmetry in twelve spacetime dimensions , the SO ( 32 ) gauge symmetry of heterotic strings , and the E8xE8 or SO ( 16 ) xSO ( 16 ) gauge symmetry of type IIA or IIB superstrings respectively .We see that the HD group can be realized on any closed Riemann surface with genus g > 1 by constructing an explicit act for it on the space of conformal field theories associated to this surface . This construction generalizes earlier findings obtained using orbifold techniques , but has various advantages over them .In particular , our approach allows us to build modern representations of string compactification without putting extra massless states into the spectrum at tree level . . . .",
        "ori-fast-z-score": -0.3841106397986879,
        "water-fast-z-score": 2.6887744785908154
    },
    {
        "original_text": "We study the semiclassical dynamics of electrons in magnetic fields, which are described by the Dirac equation with spin-orbit coupling and Zeeman splitting. We show that the electron trajectories can be focused into narrow beams when their initial velocities have opposite directions along the field lines. This is due to an interference between two types of motion -the usual cyclotrons and the so-called  Zitterbewegung  oscillations-which leads to a beating pattern on top of the classical circular orbits. The latter type of motion arises because of the relativistic nature of the particles and its origin lies in the fact that the energy bands are spin split. Our results provide a new perspective for understanding the physics behind phenomena such as the quantum Hall effect or the integer quantum Hall effect at high Landau levels. \nI. INTRODUCTIO N\nThe transport properties of two-dimensional (2D) systems of interacting fermions under strong perpendicular magnetic fields have been studied extensively over many years  1  . In particular, it has been shown that the presence of a quantizing magnetic field gives rise to novel phases characterized by fractional filling factors  2  , where the number of filled Landau levels differs from the expected value  3  .\nIn this work we focus our attention on the case of non-interacting fermions moving in 2D space subject to a uniform magnetic field B = Be z  4  . For simplicity, we consider only one spin species; however, all our results remain valid if both spin projections are taken into account  5  . In addition, we assume that the Fermi level lies within the conduction band  6  . Under these conditions, the low-energy excitations around the Fermi surface are well-described by the massless Dirac Hamiltonian  7, 8  \nwhere v F denotes the Fermi velocity, σ i=x,y,z denote Pauli matrices acting on the spinor wave function Ψ(r), p x = −i∂/∂x and p y = −i∂/(−i∂y). Hereafter, we seth = 1 and e = 1. It should be noted that Eq. (1) \nII. ELECT",
        "watermark_text": "We research the semiclassical dynamics of electrons in magnetic fields , which are explained by the Dirac formula with spin - orbit coupling and Zeeman splitting . We see that the electron trajectories can be focused into narrow beams when their initial velocities have different directions along the field lines .This is due to an interference between two forms of movement - the usual cyclotrons and the so - called Zitterbewegung oscillations - which results to a beating sequence on top of the classical circular orbits . The latter type of movement occurs because of the relativistic behavior of the atoms and its origin lies in the fact that the power groups are momentum separated .Our results bring a new insight for studying the physics behind processes such as the quantum Hall impact or the integer quantum Hall impact at high Landau concentrations . I . INTRODUCTIO N The transport properties of two - dimensional ( 2D ) complexes of interacting fermions under strong diagonal magnetic waves have been studied thoroughly over numerous years 1 .In particular , it has been shown that the presence of a quantizing magnetic force gives rise to novel phases characterized by fractional filling variables 2 , where the proportion of filled Landau concentrations differs from the expected value 3 . In this research we focus our focus on the case of non - interacting fermions moving in 2D space subject to a uniform magnetic force B = Be z 4 .For simplicity , we treat only one spin species ; however , all our findings remain correct if both spinning projections are took into consideration 5 . In addition , we suppose that the Fermi level sits within the conduction band 6 .Under these conditions , the small - energy excitations around the Fermi surface are better - described by the massless Dirac Hamiltonian 7 , 8 where v F denotes the Fermi velocity , σ i = x , y , z define Pauli matrices acting on the spinor wave function Ψ ( r ) , r x = −i∂ / ∂x and p y = −i∂ / ( −i∂y ) . Hereafter , we seth = 1 and e = 1 .It should be mentioned that Eq . ( 1 ) II .ELECT",
        "ori-fast-z-score": -1.007017629956027,
        "water-fast-z-score": 7.216959681351526
    },
    {
        "original_text": "We have performed ab initio molecular dynamics simulations to study the in-plane structure, order parameters, and surface tension of liquid Na(l) in contact with vacuum or solid NaCl (001). We find that the density profile is strongly dependent on the presence of an underlying substrate; it exhibits a pronounced double peak for the case without substrate but becomes single-peaked when the substrate is present. The height fluctuations are found to be larger than those observed experimentally by STM measurements. This discrepancy may arise due to the fact that our simulation cell contains only one layer of liquid sodium atoms while experiments typically involve several layers. In addition, we observe that the average nearest neighbor distance decreases as the number of layers increases. Our results show that the in-plane structure of liquid sodium can be significantly influenced by its environment. Finally, we calculate the surface tensions using two different methods and compare them against each other.",
        "watermark_text": "We have done ab initio polymer mechanics simulations to study the in - plane structure , order variables , and surface tension of liquid Na ( l ) in contact with vacuum or solid NaCl ( 001 ) . We see that the density profile is strongly dependent on the presence of an underlying substrate ; it displays a noticeable double peak for the case without substrate but appears single - peaked when the substrate is present .The altitude fluctuations are found to be larger than those observed experimentally by STM observations . This discrepancy may arise due to the fact that our modeling room contains only one layer of liquid sodium atoms while tests usually require many layers .In addition , we find that the average closest neighbor distance tends as the number of thickness increases . Our results show that the in - plane structure of liquid sodium can be greatly altered by its surroundings .Finally , we estimate the surface tensions use two different methods and contrast them against each other .",
        "ori-fast-z-score": 0.3333333333333333,
        "water-fast-z-score": 6.405028512341099
    },
    {
        "original_text": "We present an overview of our recent work on Bayesian methods for reconstructing the large scale structures in the universe using galaxy redshift surveys. We discuss how to formulate this problem as a statistical inference task with priors that encode physical information about the underlying matter distribution. The posterior probability density function is then evaluated by applying Bayes  theorem together with Markov Chain Monte Carlo (MCMC) sampling techniques. In particular we focus on two different approaches which are based either on Gibbs sampling or Metropolis-Hastings algorithm. Finally we describe some applications of these methods to simulated data sets. This research was supported by NSF grant AST-0707763. Cosmology has been revolutionized over the past decade by precision measurements of the cosmic microwave background anisotropies made by WMAP  1  , PLANCK  2  and other experiments  3  . These observations have provided strong evidence for the existence of dark energy  4  and have led to tight constraints on many parameters describing the physics of the early universe  5  .\nHowever, despite their successes there remain several open questions regarding fundamental aspects of the standard model of cosmology  6  . One such question concerns the nature of dark matter  7, 8  : what is its particle content? What is its mass? How does it interact with ordinary matter?\nAnswering these questions requires detailed knowledge of the spatial distribution of dark matter throughout space and time  9  . Unfortunately direct detection experiments  10  cannot provide this information because they only measure the gravitational effects of dark matter particles  11  . Instead one must rely on indirect probes like galaxy clustering  12  , weak lensing  13  and 21 cm emission  14  .",
        "watermark_text": "We present an overview of our latest work on Bayesian methods for reconstructing the huge scale structures in the universe using galaxy redshift surveys . We discuss how to formulate this question as a statistical inference job with priors that encode physical information about the underlying matter distribution .The posterior likelihood density function is then evaluated by using Bayes relation together with Markov Chain Monte Carlo ( MCMC ) filtering approaches . In particular we focus on two different methods which are based either on Gibbs filtering or Metropolis - Hastings algorithm .Finally we explain some applications of these systems to modeled information sets . This research was supported by NSF grant AST - 0707763 .Cosmology has been revolutionized over the previous decade by precision observations of the cosmic microwave background anisotropies made by WMAP 1 , PLANCK 2 and other experiments 3 . These measurements have provided strong evidence for the existence of deep energy 4 and have led to strict constraints on numerous variables describing the physics of the early world 5 .However , despite their successes there remain many open questions regarding essential aspects of the standard theory of cosmology 6 . One such problem concerns the nature of deep material 7 , 8 : what is its particle content ?What is its weight ? How does it behave with normal matter ?Answering these problems demands clear information of the spatial distribution of dark matter throughout space and time 9 . Unfortunately direct detection experiments 10 cannot offer this data because they only measure the gravitational impacts of dark matter grains 11 .Instead one must rely on indirect probes like galaxy clustering 12 , soft lensing 13 and 21 cm emission 14 .",
        "ori-fast-z-score": 0.9838699100999074,
        "water-fast-z-score": 8.131727983645296
    },
    {
        "original_text": "The in vivo behavior of looped DNA-protein complexes is investigated by using multiscale modeling and simulation techniques. The results show that the looping process can be divided into three stages, namely initiation, elongation, and termination. During the initiation stage, the protein binds to its recognition site on one end of the double helix; during the elongation stage, it slides along the double helix until reaching another recognition site at which point the complex terminates. These findings are consistent with experimental observations. Furthermore, we find that the sliding motion of the protein is driven by thermal fluctuations rather than Brownian diffusion. Finally, our simulations suggest that the formation of loops may play an important role in regulating gene expression. This article is part of a Special Issue entitled  Advances in Computational Science  guest edited by Professors S. J. Liou and C. Y. Wu. It has been accepted for publication in Journal of Physics A: Mathematical and Theoretical (JPhysA)",
        "watermark_text": "The in vivo behavior of looped DNA - protein complexes is investigated by using multiscale simulation and modeling techniques . The results show that the looping cycle can be categorized into three stages , namely initiation , elongation , and termination .During the initiation stage , the protein binds to its recognition location on one end of the double helix ; during the elongation phase , it slides along the double helix until reaching another recognition location at which point the complex terminates . These conclusions are compatible with experimental studies .Furthermore , we find that the sliding motion of the protein is caused by temperature fluctuations rather than Brownian absorption . Finally , our simulations confirm that the formation of loops might play an important role in controlling gene activity .This page is part of a Special Issue entitled Advances in Computational Science guest edited by Professors S . J . Liou and C . Y . Wu . It has been accepted for published in Journal of Physics A : Mathematical and Theoretical ( JPhysA )",
        "ori-fast-z-score": -0.25,
        "water-fast-z-score": 4.589285179800713
    },
    {
        "original_text": "We report on observations made with the Submillimeter Array and the Atacama Large Millimeter/submillimeter Array in order to study the kinematics of an outflow driven by the high-mass protostellar object, IRAS 18566+0408; this source is associated with a cluster of young stellar objects located at a distance of 3 kpc. The data reveal that there are two components along the line-of-sight; one component has a systemic velocity of ~10 km s-1 , while another component shows blueshifted emission up to -60 km s-1 . We find evidence for a collimated jet-like structure extending over ~0.5 pc. This suggests that the driving source may be deeply embedded within its natal cloud core. In addition, we detect several compact knots distributed along the flow axis which show blue-shifted velocities ranging between 10-60 km s-1 .\nThe mass-loss rate estimated from our observations ranges between 1×10-3 -1×10-2 M⊙ yr-1 .",
        "watermark_text": "We report on observations made with the Submillimeter Array and the Atacama Large Millimeter / submillimeter Array in order to study the kinematics of an outflow generated by the high - weight protostellar element , IRAS 18566 + 0408 ; this source is associated with a cluster of young stellar bodies located at a distance of 3 kpc . The data reveal that there are two systems along the line - of - view ; one component has a systemic speed of ~ 10 km s - 1 , while another component displays blueshifted emission up to - 60 km s - 1 .We see evidence for a collimated jet - like structure extending over ~ 0 . 5 pc . This implies that the driving source may be deeply lodged within its natal cloud core .In addition , we find various compact knots scattered along the flow axis which show blue - shifted velocities ranging between 10 - 60 km s - 1 . The mass - loss rate calculated from our observations runs between 1×10 - 3 - 1×10 - 2 [UNK] yr - 1 .",
        "ori-fast-z-score": 1.1338934190276817,
        "water-fast-z-score": 5.417490779798923
    },
    {
        "original_text": "We propose an efficient numerical scheme to solve the nonlinear dynamics of semiconductor microcavity lasers with arbitrary pumping profiles and cavity losses, which is based on the combination of two different truncation schemes. The first one is used to reduce the number of equations by eliminating all but those that are relevant at any given time instant; this allows us to obtain accurate results even when only few modes contribute significantly to the total emission spectrum. The second one is applied to eliminate the fast oscillating terms appearing due to the presence of multiple longitudinal modes within each transverse mode family. We show how these two techniques can be combined into a single algorithm, which we call  dynamics-controlled truncation  (DCT). Finally, we demonstrate the accuracy and efficiency of our method by comparing it against other existing methods. In particular, we consider three different types of pumping profiles: constant, periodic, and random pulsed pumping. \nI. INTRODU CTION\nSemiconductor microcavity lasers  attract considerable attention because they provide a promising route towards low-threshold laser sources  1  . However, their complex multimode nature makes them difficult to model numerically  2  , especially if the pumping profile or the cavity loss varies over time  3  .\nIn order to overcome such difficulties, several authors have proposed various approaches  4  -  8  . For example, in Ref.  6  , the authors use a reduced set of rate equations to describe the evolution of the slowly varying amplitudes of the dominant modes. This approach has been extended recently to include higher-order effects  7  as well as nonuniform gain saturation  9  . Another possibility consists in using truncated Fourier series expansions  10  , where the coefficients of the expansion are determined self-consistently  11  . Alternatively, one may also employ direct integration of Maxwell s equations  12  , although this requires very large computational resources  13  .",
        "watermark_text": "We suggest an efficient numerical system to solve the nonlinear dynamics of semiconductor microcavity lasers with arbitrary flow profiles and cavity costs , which is based on the combination of two different truncation schemes . The first first is utilized to reduce the number of equations by removing all but those that are applicable at any certain time instant ; this enables us to obtain precise conclusions even when only few modes contribute greatly to the total emission spectrum .The second one is applied to eliminate the fast oscillating terms appearing caused to the presence of multiple longitudinal frequencies within each transverse mode family . We see how these two procedures can be merged into a single method , which we call dynamics - controlled truncation ( DCT ) .Finally , we prove the accuracy and efficiency of our technique by comparing it against other existing techniques . In particular , we study three different kinds of flow profiles : constant , continuous , and random pulsed pumping .I . INTRODU CTION Semiconductor microcavity lasers draw great popularity because they give a viable path towards non - threshold beam sources 1 . However , their complex multimode nature making them harder to model numerically 2 , particularly if the pumping profile or the cavity gain varies over time 3 .In try to overcome such problems , various published have proposed several methods 4 - 8 . For instance , in Ref .6 , the papers use a reduced series of rate coefficients to explain the evolution of the slowly varying amplitudes of the dominant modes . This method has been extended recently to consider higher - order effects 7 as well as nonuniform gain saturation 9 .Another possibility consists in utilizing truncated Fourier series expansions 10 , where the coefficients of the integration are chosen self - consistently 11 . Alternatively , one may even employ direct combining of Maxwell s coefficients 12 , although this demands very huge computational resources 13 .",
        "ori-fast-z-score": -1.632993161855452,
        "water-fast-z-score": 8.110396013138502
    },
    {
        "original_text": "We report the observation of very weak electron-phonon coupling (EPC) in La0.7Sr0.3MnO3 thin films grown on SrTiO3 substrates by pulsed laser deposition, which is consistent with previous reports for bulk samples.  We also observe that EPC decreases as temperature increases up to 300 K. This behavior can be explained by considering the effect of lattice expansion due to thermal fluctuations at high temperatures. In addition, we find that the magnitude of EPC depends strongly on film thickness; it becomes smaller when the film thickness decreases down to 10 unit cells. The observed dependence of EPC on both temperature and film thickness suggests that phonon confinement plays an important role in determining the strength of EPC in these materials. Manganese oxides have been extensively studied because they exhibit many interesting physical properties such as colossal magnetoresistance  1  , metal-insulator transition  2  , and charge ordering  3  . Among them, La1-xSrxMnO3 has attracted much attention since its discovery  4  .\nIn this compound, Mn ions are located at two different sites, i.e., Mn3+(tetrahedral site) and Mn4+(octahedral site). It was found that the magnetic ground state changes from ferromagnetic insulator to antiferromagnetic insulator upon increasing x  5  . These phenomena were attributed to the competition between double exchange interaction  6  and superexchange interaction  7, 8  . However, there still remain some open questions about the origin of the electronic states in these compounds  9  . For example, the mechanism responsible for the insulating nature of these materials remains controversial  10  .",
        "watermark_text": "We report the observation of very weakened electron - phonon coupling ( EPC ) in La0 . 7Sr0 . 3MnO3 narrow bands grown on SrTiO3 substrates by pulsed infrared deposition , which is compatible with previous findings for bulk samples . We additionally observe that EPC changes as temperature increases up to 300 K . This activity can be described by using the impact of lattice increase due to heat fluctuations at high temperatures .In addition , we find that the severity of EPC depends strongly on film thickness ; it becomes weaker when the film thickness decreases down to 10 unit cells . The observed influence of EPC on both heat and film thickness implies that phonon confinement serves an important role in measuring the strength of EPC in these materials .Manganese oxides have been heavily explored because they demonstrate many interesting physical properties such as colossal magnetoresistance 1 , metal - insulator transition 2 , and charge ordering 3 . Among them , La1 - xSrxMnO3 has garnered considerable scrutiny since its observation 4 .In this compound , Mn ions are situated at two different places , i . e . , Mn3 + ( tetrahedral site ) and Mn4 + ( octahedral site ) . It was shown that the magnetic ground state changes from ferromagnetic insulator to antiferromagnetic insulator upon increasing x 5 .These phenomena were attributed to the competition between multiple transfer exchange 6 and superexchange interaction 7 , 8 . However , there still continue some open questions about the origin of the electronic states in these interactions 9 .For instance , the process responsible for the insulating behavior of these structures remains controversial 10 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.375262396202865
    },
    {
        "original_text": "We prove that the set of all polynomials in one variable with integer coefficients is uniquely representable as a sum of squares of rational functions, and we give an explicit algorithm for computing such representation.  We also show how to extend this result to multivariate polynomials over finite fields. The problem of representing a given polynomial as a sum of squares (SOS) has been studied extensively since Hilbert s 19th century work on quadratic forms. In particular, it was shown by Artin that every nonnegative integer can be represented as a sum of four squares of integers; see  1  . This theorem implies that any positive integer n can be written as a sum of at most 4 square roots of integers. However, there are infinitely many ways to write each number as a sum of two or three square roots of integers. For example, 1 = 2 + √ 3 , but also 1 = 2 − √ 3 .\nThe uniqueness question becomes more interesting when restricted to certain classes of polynomials. It turns out that if f ∈ Z x  is a monic polynomial whose Galois group G(f ) is solvable then f is uniquely representable as SOS  2  . On the other hand, if G(f ) contains a nonsolvable subgroup then f may have several distinct SOS representations  3  .",
        "watermark_text": "We establish that the group of all polynomials in one variable with integer coefficients is uniquely representable as a sum of squares of rational functions , and we give an explicit algorithm for generating such representation . We also demonstrate how to apply this result to multivariate polynomials over arbitrary fields .The question of representing a given polynomial as a sum of squares ( SOS ) has been studied frequently since Hilbert s 19th century study on quadratic forms . In particular , it was shown by Artin that every nonnegative integer can be represented as a sum of four squares of integers ; seeing 1 .This formula assumes that any positive integer n can be written as a sum of at most 4 square roots of integers . However , there are infinitely many ways to write each number as a sum of two or three square roots of numbers .For instance , 1 = 2 + √ 3 , but also 1 = 2 − √ 3 . The uniqueness problem arises more exciting when confined to different categories of polynomials .It turns out that if f ∈ Z x is a monic polynomial whose Galois group G ( f ) is solvable then f is uniquely representable as SOS 2 . On the other hand , if G ( f ) contains a nonsolvable subgroup then g may have several different SOS representations 3 .",
        "ori-fast-z-score": 0.32539568672798425,
        "water-fast-z-score": 4.364357804719848
    },
    {
        "original_text": "A slide-o-cam transmission is an alternative to conventional geared transmissions in which the input and output shafts are connected by means of cams that rotate on their own axes, with no gears or other mechanical elements between them.  The main advantages of this type of transmission are:  • No backlash due to tooth meshing; • High efficiency (up to 98%); • Low noise levels; • Reduced weight and volume compared to traditional gearboxes; • Easy assembly and disassembly; • Possibility of using different types of motors as inputs. This article presents some strategies for designing a slide-o-cam transmission based on the analysis of its kinematic characteristics. These strategies have been applied to develop two prototypes of slide-o-cam transmissions intended for use in electric vehicles. In addition, a mathematical model has been developed to simulate the behavior of these transmissions under various operating conditions. Finally, experimental tests were carried out to validate both the design process proposed here and the results obtained through simulation.",
        "watermark_text": "A slide - o - cam transmission is an alternative to conventional geared transmissions in which the input and input shafts are connected by means of cams that rotate on their own axes , with no gears or other hydraulic factors between them . The main benefits of this form of transmission are : • No backlash due to tooth meshing ; • Low reliability ( up to 98 % ) ; • Low sound levels ; • Reduced weight and mass compared to conventional gearboxes ; • Easy assembly and disassembly ; • Possibility of using multiple types of motors as output .This page presents some techniques for constructing a slide - o - cam transmission depending on the evaluation of its kinematic qualities . These strategies have been used to develop two models of slide - o - cam transmissions intended for use in electric vehicles .In addition , a mathematical description has been constructed to simulate the performance of these transmissions under various operating circumstances . Finally , experimental tests were carried out to validate both the design process described here and the results derived through simulation .",
        "ori-fast-z-score": -0.3464101615137754,
        "water-fast-z-score": 5.812381937190964
    },
    {
        "original_text": "The Web is an important source of information that can be used to support decision making processes and business intelligence applications. However, the Web contains heterogeneous sources with different structures and formats which makes it difficult to integrate them into existing databases or data warehouse systems. In this work we propose a new approach based on ontologies to model web data as well as their relationships. The proposed method uses semantic technologies such as RDF (Resource Description Framework) and OWL (Ontology Web Language). We also present how our approach can be integrated within a data warehouse system using ETL tools. Finally, we show some experimental results obtained by applying our approach to real world datasets. Keywords: Data Warehouse, Semantic Technologies, Ontology, Integration, Web Data Modeling. 1 Introduction With the rapid development of Internet technology, more and more organizations are collecting large amounts of data from various online resources. These data may include customer profiles, product catalogs, financial records, etc., all of which need to be stored and analyzed efficiently. This has led to the emergence of several research areas including data mining  1  , knowledge discovery  2  , and data warehousing  3  . A data warehouse  4  is a subject-oriented, integrated, time-variant collection of data in support of management s decisions. It provides users with fast access to historical data along with current operational data. As shown in Figure 1 , a typical data warehouse consists of three main components: OLTP (OnLine Transaction Processing), Extract-Transform-Load (ETL), and On-Line Analytical Processing (OLAP).\nFigure 1: Architecture of a data warehouse",
        "watermark_text": "The Web is an important source of information that can be used to support decision making systems and business intelligence applications . However , the Web includes heterogeneous sources with various structures and formats which makes it difficult to integrate them into older databases or data warehouse applications .In this project we attempt a new approach using on ontologies to model internet data as well as their connections . The proposed approach utilizes semantic methods such as RDF ( Resource Description Framework ) and OWL ( Ontology Web Language ) .We also demonstrate how our approach can be unified within a data warehouse system using ETL techniques . Finally , we give some experimental results derived by using our approach to real life datasets .Keywords : Data Warehouse , Semantic Technologies , Ontology , Integration , Web Data Modeling . 1 Introduction With the fast development of Internet technology , more and more organizations are collecting huge amounts of statistics from numerous web resources .These data may include customer lists , product catalogs , financial records , etc . , all of which require to be processed and studied accurately . This has led to the emergence of several study fields including data extraction 1 , knowledge creation 2 , and information warehousing 3 .A data warehouse 4 is a subject - oriented , integrated , time - variant collection of statistics in support of management s decisions . It provides users with fast access to historical data along with current operational statistics .As seen in Figure 1 , a typical database warehouse consists of three principal portions : OLTP ( OnLine Transaction Processing ) , Extract - Transform - Load ( ETL ) , and On - Line Analytical Processing ( OLAP ) . Figure 1 : Architecture of a data warehouse",
        "ori-fast-z-score": 0.09016696346674323,
        "water-fast-z-score": 7.483857967739688
    },
    {
        "original_text": "The purpose of this study is to investigate how privacy issues are perceived by users in Europe and what their attitude towards these issues is, when using online learning environments (OLE). The research questions are: \nWhat do students think about privacy?\nHow does student s perception change over time?\nWhich factors influence students  attitudes on privacy? How can we measure it? What are the implications for OLE developers? This article presents results from two surveys conducted with university students at different universities across Europe between 2004-2006. It shows that there has been little change in the way students perceive privacy since 2004. Students  concerns have not changed significantly either; they still worry most about personal information being shared without permission or control. However, some differences were found among countries. In addition, the findings show that gender plays a role as well as age. Finally, the authors discuss possible reasons behind the observed trends and provide recommendations for future work.",
        "watermark_text": "The purpose of this study is to examine how privacy issues are seen by users in Europe and what their attitude towards these problems is , when using internet learning habitats ( OLE ) . The survey problems are : What do students think about privacy ?How does student s perception shift over time ? Which variables influence pupils beliefs on privacy ?How can we measure it?What are the implications for OLE developers?This page presents scores from two polls conducted with university students at different schools across Europe between 2004 - 2006 . It demonstrates that there has been less shift in the way pupils understand privacy since 2004 .Students issues have not altered significantly either ; they still concern most about personal data being communicated without authorization or supervision . However , some differences were found among countries .In addition , the discoveries reveal that gender plays a role as well as aging . Finally , the articles discuss possible reasons behind the reported developments and include recommendations for future projects .",
        "ori-fast-z-score": -0.22360679774997896,
        "water-fast-z-score": 7.9881240965747695
    },
    {
        "original_text": "We study the existence, uniqueness and ergodicity of physical measures in some classes of infinite measure preserving transformations on probability spaces. We prove that if T is an infinite measure preserving transformation on (X, B(X), m) such that there exists a set A ∈ B(X) satisfying m(A) > 0 and m(T −1 A) = 0 then T has at least one physical measure which is unique up to scalar multiples. Moreover we show that any two physical measures are equivalent under suitable conditions. Finally we give examples showing how our results can be applied. The main motivation comes from the theory of infinite ergodic group actions where it was shown by Glasner and Weiss  GW  ,  GS1  that every infinite ergodic action of a countable amenable group G admits a unique invariant Radon measure µG . In this case the space X is taken as the dual group G equipped with its left Haar measure m.",
        "watermark_text": "We research the existence , uniqueness and ergodicity of physical measures in some categories of infinite measure retaining transformations on probability spaces . We prove that if T is an infinite measure preserving transformation on ( X , B ( X ) , m ) such that there exists a setting A ∈ B ( X ) satisfying m ( A ) > 0 and m ( T −1 A ) = 0 then T has at least one physical measure which is unique up to scalar multiples .Moreover we prove that any two physical measures are comparable under suitable conditions . Finally we give instance demonstrating how our findings can be applied .The main motivation arises from the principle of infinite ergodic group events where it was shown by Glasner and Weiss GW , GS1 that every infinite ergodic act of a countable amenable group G accepts a unique invariant Radon number µG . In this instance the space X is taken as the dual group G equipped with its leaving Haar measure m .",
        "ori-fast-z-score": -0.9113223768657671,
        "water-fast-z-score": 3.7754784184438925
    },
    {
        "original_text": "The article presents new data on the paleogeography and geodynamics of the Russian Arctic in the late Quaternary period, based on the results of field studies conducted by the authors over the past decade. The study area is located between the Lena River to the west and the Kolyma River to the east (Fig.  1) . It includes the northern part of Yakutia, the southern part of Chukotka Autonomous Okrug, and the western part of Magadan Oblast. In this region, the authors studied more than 100 sites with deposits of loess-like sediments that accumulated during the last glacial cycle. These are mainly sandy silts with an admixture of gravel particles up to 5 mm in diameter; they contain numerous mollusk shells, bones of terrestrial mammals, and other remains of biota. Based on these materials, we reconstructed the history of climatic fluctuations in the study area since the Last Glacial Maximum (LGM) until today.",
        "watermark_text": "The section offers latest data on the paleogeography and geodynamics of the Russian Arctic in the last Quaternary period , based on the results of field analyses conducted by the writers over the previous decade . The survey area is situated between the Lena River to the west and the Kolyma River to the west ( Fig .1 ) . It includes the northern part of Yakutia , the southern portion of Chukotka Autonomous Okrug , and the western part of Magadan Oblast .In this area , the authors studied more than 100 sites with formations of loess - like sediments that eroded during the last ice cycle . These are chiefly sandy silts with an admixture of sandy fragments up to 5 mm in width ; they contain many mollusk shells , fossils of terrestrial birds , and other remains of biota .Based on these resources , we analyzed the history of climatic fluctuations in the program field since the Last Glacial Maximum ( LGM ) until today .",
        "ori-fast-z-score": -2.516611478423583,
        "water-fast-z-score": 4.464418717230567
    },
    {
        "original_text": "We present new photometric and spectroscopic observations for two stars, HD 122563 (=HR 5171A) and BD+17°3248, which are suspected to be members of the proposed intermediate age population of helium-rich giants in the globular cluster Omega Cen.  We find that both stars have very similar atmospheric parameters as those found by previous studies for other candidate helium-rich giant candidates in Omega Cen: T eff = 8200 K; log g = 3.8;  Fe/H  = -1.0 dex. The observed spectra show no evidence for He II lines at 4686 Å or 5412 Å, but do exhibit strong Balmer line emission with equivalent widths ranging between -40 and -50 mÅ. These results suggest that these stars may not actually belong to this proposed class of objects. However, we cannot rule out the possibility that they are indeed helium-rich giants on the basis of our current data set alone.",
        "watermark_text": "We present new photometric and spectroscopic observations for two stars , HD 122563 ( = HR 5171A ) and BD + 17°3248 , which are known to be members of the suggested intermediate age population of helium - rich giants in the globular cluster Omega Cen . We see that both stars have very similar atmospheric parameters as those shown by earlier surveys for other candidate helium - rich giant finalists in Omega Cen : T eff = 8200 K ; log f = 3 . 8 ; Fe / H = - 1 . 0 dex .The observed spectra show no evidence for He II systems at 4686 Å or 5412 Å , but do exhibit strong Balmer line emission with corresponding widths ranging between - 40 and - 50 mÅ . These conclusions show that these stars must not actually belong to this possible category of bodies .However , we cannot judge out the suggestion that they are indeed helium - rich giants on the grounds of our latest data set alone .",
        "ori-fast-z-score": -2.1009029257555607,
        "water-fast-z-score": 3.2547227745205967
    },
    {
        "original_text": "We present the first results on clustering measurements for luminous red galaxies (LRGs) in the redshift range 0.5 <z<0.8, obtained with the Anglo-Australian Observatory s multi-object spectrograph AAOmega. We use data from the 2dF-SDSS LRG and QSO survey to measure the projected correlation function wp(rp). The observed clustering amplitude is consistent with that expected from linear theory predictions based on current cosmological models. This result provides an important test of these models over this redshift range where there are few other constraints available. In addition we find evidence for evolution in the galaxy bias parameter between our two samples separated by ~0.2 Gyrs. These results will be presented in detail elsewhere. \n \n Keywords: Luminous Red Galaxies; Clustering; Bias Evolution; Cosmology. 1 Introduction \n \n A number of recent studies have shown that luminous red galaxies (hereafter LRGs), selected via their optical colours or near-infrared photometry, provide powerful probes of large-scale structure out to high redshifts (e.g., Eisenstein et al. 2001; Wake et al. 2006; Padmanabhan et al. 2007; Blake et al. 2008; Ross et al. 2008) . Their large luminosities mean they can be detected efficiently even at relatively low redshifts, while their red colours make them easy to identify spectroscopically. They also tend to reside in massive dark matter haloes which evolve slowly through cosmic time, making them useful tracers of the underlying mass distribution. As such, they offer unique opportunities to study both the growth of structures as well as the nature of dark energy driving its accelerated expansion (see e.g., Percival & White 2009 , for a review). \n \n Here we report the first measurement of the spatial clustering properties of LRGs in the redshift range 0<z<0.8 made possible by combining data from the Sloan Digital Sky Survey (SDSS) (York et al. 2000) , the Two Degree Field Galaxy Redshift Survey (2dFGRS) (Colless et al.",
        "watermark_text": "We publish the first findings on clustering observations for luminous red objects ( LRGs ) in the redshift region 0 . 5 < z < 0 . 8 , obtained with the Anglo - Australian Observatory s multi - object spectrograph AAOmega . We use data from the 2dF - SDSS LRG and QSO studies to measure the projected relationship value wp ( rp ) .The observed clustering amplitude is compatible with that expected from linear theoretical estimates based on current cosmological models . This result provides an important test of these models over this redshift region where there are few other constraints offered .In addition we find proof for evolution in the galaxy bias variable between our two specimens divided by ~ 0 . 2 Gyrs . These conclusions will be shown in detail elsewhere .Keywords : Luminous Red Galaxies ; Clustering ; Bias Evolution ; Cosmology . 1 Introduction A variety of recent studies have shown that luminous red clusters ( hereafter LRGs ) , selected via their optical colours or near - infrared photometry , provide potent probes of large - scale organization out to large redshifts ( e . g . , Eisenstein et al .2001 ; Wake et al . 2006 ; Padmanabhan et al .2007 ; Blake et al . 2008 ; Ross et al .2008 ) . Their large luminosities guarantee they can be identified efficiently even at fairly little redshifts , while their red colours help them easy to identify spectroscopically .They also seem to live in massive dark matter haloes which evolution gradually through cosmic time , making them useful tracers of the ongoing mass distribution . As such , they give unique possibilities to study both the development of structures as also as the nature of bright energy causing its rapid increase ( saw e . g . , Percival & White 2009 , for a review ) .Here we publish the first measurement of the spatial clustering behavior of LRGs in the redshift region 0 < z < 0 . 8 made possible by combining information from the Sloan Digital Sky Survey ( SDSS ) ( York et al . 2000 ) , the Two Degree Field Galaxy Redshift Survey ( 2dFGRS ) ( Colless et al .",
        "ori-fast-z-score": -0.9610744623271417,
        "water-fast-z-score": 7.0164641544562345
    },
    {
        "original_text": "The aim of this study was to evaluate whether virtual ultrasound (US) puncture tracts can improve percutaneous renal access in patients with complex anatomy and difficult-to-visualize calices on fluoroscopy.  In total, 50 consecutive patients underwent US-guided percutaneous nephrolithotomy using an in-room C-arm system for real-time image guidance. The procedure was performed under general anesthesia or conscious sedation. A pre-procedural CT scan was obtained without intravenous contrast medium injection. Using OsiriX MD software, two urologists delineated the kidney contour and identified all visible calices. Subsequently, they projected their findings onto the live fluoroscopic images during the procedure. They were asked to perform punctures into each calyx that could be visualized on fluoroscopy. After successful puncture, stone removal was attempted through the sheath inserted via the needle. Successful puncture was defined as reaching at least one calix. Overall success rate was 88%. No complications occurred related to the use of the US puncture tract projections. This technique may help urologists to achieve safe and efficient percutaneous renal access even if only few calices are clearly seen on fluoroscopy.",
        "watermark_text": "The goal of this study was to examine whether digital ultrasound ( US ) puncture tracts can boost percutaneous renal entry in patients with difficult anatomy and difficult - to - visualize calices on fluoroscopy . In total , 50 consecutive patients received US - guided percutaneous nephrolithotomy employing an in - room C - arm network for real - time vision tracking .The technique was done under general anesthesia or conscious sedation . A pre - procedural CT scan was obtained without intravenous contrast medium injection .Using OsiriX MD software , two urologists delineated the kidney contour and identified all evident calices . Subsequently , they projected their findings onto the live fluoroscopic images during the surgery .They were asked to conduct punctures into each calyx that might be visualized on fluoroscopy . After successful puncture , stone extraction was attempted through the sheath inserted via the needle .Successful puncture was calculated as reaching at least one calix . Overall success percentage was 88 % .No complications caused associated to the using of the US puncture tract projections . This method may assist urologists to achieve safe and easy percutaneous renal entry even if only few calices are obvious saw on fluoroscopy .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.495752858199363
    },
    {
        "original_text": "The Next-to-Minimal Supersymmetric Standard Model (nMSSM) is an extension of the Minimal Supersymmetric Standard Model that includes additional Higgs doublets and singlet fields, as well as new vector-like quarks and leptons. The phenomenological consequences of this model are investigated in detail using state-of-the-art tools for precision calculations at both low energies and high energy scales. In particular we study the impact on dark matter searches, electroweak observables, flavour physics constraints, LHC signatures and direct detection experiments. We find that the nMSSM can accommodate all current experimental data with minimal fine-tuning while simultaneously providing viable candidates for cold dark matter particles. This talk will present our results. It was presented by Jens Hjorth-Jensen at EPS-HEP 2013 conference held in Vienna Austria between July 24-29th 2013. The slides used during the presentation are available here .",
        "watermark_text": "The Next - to - Minimal Supersymmetric Standard Model ( nMSSM ) is an extension of the Minimal Supersymmetric Standard Model that contains additional Higgs doublets and singlet fields , as well as additional vector - like quarks and leptons . The phenomenological consequences of this model are examined in detail using state - of - the - art tools for precision analysis at both high energies and low power scales .In particular we study the impact on dark matter surveys , electroweak observables , flavour physics requirements , LHC signatures and direct detection experiments . We see that the nMSSM can handle all recent experimental evidence with minimal fine - tuned while simultaneously offering viable candidates for cold bright matter ions .This discussion will present our findings . It was presented by Jens Hjorth - Jensen at EPS - HEP 2013 meeting held in Vienna Austria between July 24 - 29th 2013 .The slides seen during the lecture are available here .",
        "ori-fast-z-score": -1.270001270001905,
        "water-fast-z-score": 4.064004064006096
    },
    {
        "original_text": "We consider the linearization problem for the Painleve  equations PIII, PV and PVI in terms of their Lax pairs. We show that these problems are equivalent to certain reductions of the three-wave resonant system. The results obtained here can be regarded as an extension of those by Zakharov et al., who studied the reduction of the two-wave resonant system corresponding to the Painleve  II equation. In particular we prove that there is no non-trivial solution of the linearized PIII or PV equation which decays exponentially at infinity if one imposes some additional conditions on its asymptotic behavior near the origin. \nIntroduction\n\nThe Painleve  equations play important roles both in mathematics and physics (see e.g.   1  ,  4  ). They have been extensively investigated during last decades mainly due to their rich structures such as soliton solutions and Bäcklund transformations. Recently it has been shown that they also appear naturally in various physical models including nonlinear optics  2  . For example, the so-called NLS equation with cubic-quintic nonlinearity arises from the propagation of intense laser beams through Kerr media  3  .\nIn this article we study the linearization problem for several types of the Painleve s equations. More precisely let us consider the following systems of partial differential equations: \nwhere u = u(t, x) ∈ C n+1 , v = v(t, x) and w = w(t, x) are complex-valued functions of t > 0 and x ∈ R 1 . Hereafter subscripts denote differentiation with respect to variables indicated by them. It should be noted that all the above systems possess infinitely many conservation laws given by",
        "watermark_text": "We consider the linearization problem for the Painleve coefficients PIII , PV and PVI in terms of their Lax pairs . We see that these problems are comparable to certain reductions of the three - wave resonant system .The results derived here can be regarded as an extension of those by Zakharov et al . , who studied the reduction of the two - wave resonant system analogous to the Painleve II equation . In particular we prove that there is no non - trivial solution of the linearized PIII or PV function which decays exponentially at infinity if one imposes some additional conditions on its asymptotic evolution near the origin .Introduction The Painleve coefficients play essential roles both in math and physics ( saw e . g . 1 , 4 ) .They have been heavily explored during last decades mostly owing to their deep structures such as soliton solutions and Bäcklund interactions . Recently it has been shown that they also appear naturally in different physical theories including nonlinear optics 2 .For instance , the so - called NLS equation with cubic - quintic nonlinearity emerges from the propagation of aggressive laser beams through Kerr material 3 . In this page we study the linearization problem for various types of the Painleve s equations .More specifically let us consider the following systems of partial differential equations : where u = u ( t , x ) ∈ C n + 1 , v = v ( t , x ) and w = w ( t , z ) are complex - valued functions of t > 0 and x ∈ R 1 . Hereafter subscripts describe separation with regard to factors indicated by them .It should be mentioned that all the above schemes contain infinitely many conservation forces given by",
        "ori-fast-z-score": -1.2686700948330931,
        "water-fast-z-score": 6.079600189283705
    },
    {
        "original_text": "The Fermi Gamma-ray Space Telescope (formerly known as GLAST) is scheduled to launch in June 2008 and will be able to detect gamma rays with energies ranging from 20 MeV up to 300 GeV, covering an energy range that was previously unexplored by space-based instruments.  The LAT instrument on board Fermi consists of four identical towers each containing 16 silicon strip trackers surrounded by tungsten converters followed by CsI(Tl) scintillators. Each tracker module has a thickness of 1 cm and contains 12 layers of silicon strips oriented at different angles relative to one another. This design allows for accurate measurement of both the direction and energy of incident photons. In addition, there are two calorimeter sections located behind the tracker modules which contain 8 planes of CsI(Tl). These detectors provide excellent angular resolution and good energy resolution over most of the energy band. The main goal of this work is to develop a detailed understanding of the Galactic diffuse emission observed by the LAT detector so that it can be accurately modeled when analyzing data taken during its mission lifetime.",
        "watermark_text": "The Fermi Gamma - ray Space Telescope ( formerly called as GLAST ) is slated to launch in June 2008 and will be able to identify gamma radiation with energies ranging from 20 MeV up to 300 GeV , covering an energy range that was formerly unexplored by space - based instruments . The LAT instrument on board Fermi consists of four identical towers each featuring 16 silicon strip trackers flanked by tungsten converters followed by CsI ( Tl ) scintillators .Each tracker module has a length of 1 cm and comprises 12 rings of silicon sheets oriented at different angles relative to one another . This configuration allows for precise measurement of both the direction and energy of incident photons .In addition , there are two calorimeter sections housed behind the tracker modules which contain 8 planes of CsI ( Tl ) . These detectors allow excellent angular resolution and good energy resolution over most of the energy band .The main goal of this project is to develop a detailed understanding of the Galactic diffuse emission observed by the LAT detector so that it can be correctly modeled when examining data taken during its mission duration .",
        "ori-fast-z-score": 0.7977240352174656,
        "water-fast-z-score": 6.039910552360811
    },
    {
        "original_text": "We study the holographic entanglement entropy for three-dimensional de Sitter space with gravitational Chern-Simons term by using the replica trick and the covariant phase-space method. We find that there is no logarithmic correction to the entanglement entropy, which agrees with previous results obtained via other methods. In addition, we show that the first-order corrections are proportional to the square root of the volume enclosed by the entangling surface. Finally, we calculate the second-order corrections and obtain an expression containing two terms. One of them has been previously found in Ref.  Phys. Rev. D 98 (2018) 084011  while another one is new. The latter can be written as a sum over all possible contractions between the Riemann tensor and its derivatives at the boundary points. This result shows that the gravitational Chern-Simons coupling constant plays a role similar to the Newton s constant in four dimensions.",
        "watermark_text": "We explore the holographic entanglement entropy for three - dimensional de Sitter space with gravitational Chern - Simons term by using the replica trick and the covariant phase - space method . We see that there is no logarithmic correction to the entanglement entropy , which agrees with previous findings obtained via other methods .In addition , we find that the first - order corrections are equal to the square root of the volume enclosed by the entangling surface . Finally , we estimate the second - order corrections and find an expression containing two terms .One of them has been previously found in Ref.Phys.Rev.D 98 (2018) 084011  while another one is new.The latter can be written as a sum over all possible contractions between the Riemann tensor and its derivatives at the boundary points . This result suggests that the gravitational Chern - Simons correlation function plays a role similar to the Newton s constant in four dimensions .",
        "ori-fast-z-score": 1.1920791213585393,
        "water-fast-z-score": 3.474396144861517
    },
    {
        "original_text": "We study the stability properties of magnetized relativistic flows with helical symmetry, which are described by exact solutions to Einstein s field equations coupled to Maxwell s equations for an electromagnetic field that is purely electric or purely magnetic along each fluid line. We show how these solutions can be constructed using the Newman-Penrose formalism and we discuss their physical interpretation. In particular, we find that there exist two classes of such solutions depending on whether they contain a  dynamo region  where the magnetic energy density grows exponentially fast (and thus cannot be matched onto any solution at spatial infinity) or not. The latter class contains all known stationary axisymmetric black hole electrovacuum solutions. Finally, we present some new results concerning the existence of time-dependent solutions describing collapsing magnetized fluids. These solutions may have interesting applications to astrophysics. PACS numbers: 04.20.-q, 98.80.Cq",
        "watermark_text": "We research the stability properties of magnetized relativistic flows with helical symmetry , which are explained by precise solutions to Einstein s field equations linked to Maxwell s equations for an electromagnetic field that is purely electric or purely magnetic along each fluid line . We see how these solutions can be derived using the Newman - Penrose formalism and we explain their physical interpretation .In particular , we find that there exist two groups of such solutions based on whether they contain a dynamo region where the magnetic energy density grows exponentially rapidly ( and therefore cannot be matched onto any solution at spatial infinity ) or not . The latter group contains all known stationary axisymmetric black hole electrovacuum solutions .Finally , we present some new results relating the existence of time - dependent applications describing collapsing magnetized liquid . These solutions may have curious applications to astrophysics .PACS codes : 04 . 20 . - q , 98 . 80 . Cq",
        "ori-fast-z-score": -0.47809144373375745,
        "water-fast-z-score": 4.391092135317257
    },
    {
        "original_text": "We present new measurements of the baryonic mass fractions (f bar ) in early-type galaxies, based on spatially resolved kinematics for a sample of 12 nearby elliptical/S0 galaxies observed with integral field spectroscopy at optical wavelengths.  We use these data to measure f bar , as well as the total stellar masses M * . The results are compared against predictions from semi-analytic models of galaxy formation within the standard ΛCDM cosmology. Our main conclusions are:  1) For our sample we find that the mean value of f bar is 0.16 ± 0.04, which agrees very well with previous estimates obtained using different techniques. 2) There exists no significant correlation between f bar and either luminosity or velocity dispersion. 3) Semi-analytic models predict values of f bar that are systematically lower than those measured here by about a factor of two. 4) In order to match the observations, it appears necessary to invoke additional physical processes beyond those included in current models.",
        "watermark_text": "We report new studies of the baryonic mass fractions ( f bar ) in early - class stars , using on spatially resolved kinematics for a sample of 12 nearby elliptical / S0 galaxies studied with integral field spectroscopy at optical wavelengths . We use these information to measure f bar , as well as the total stellar ages M * .The results are compared against measurements from semi - analytic models of galaxy formation within the standard ΛCDM cosmology . Our main results are : 1 ) For our sample we find that the mean value of f bar is 0 . 16 ± 0 . 04 , which agrees very best with previous estimates obtained using separate techniques .2 ) There exists no considerable relationship between f bar and either luminosity or speed dispersion . 3 ) Semi - analytic models predict values of f bar that are routinely lower than those observed here by about a factor of two .4 ) In order to match the experiments , it appears necessary to invoke additional physical processes beyond those included in current systems .",
        "ori-fast-z-score": 2.49100947511811,
        "water-fast-z-score": 6.567206798038654
    },
    {
        "original_text": "The nonequilibrium steady states (NESS) of matrix product form are the focus of this work, which is intended to be useful for researchers in computational physics and chemistry who wish to solve problems with such NESSs using numerical methods.  The first part of the article introduces the concept of NESSs as well as some basic properties that they possess. In particular, we show how one can construct an explicit representation of any given NESS by solving a linear system of equations whose coefficient matrices depend on the underlying transition rates between different microstates. We also discuss several important issues related to the construction of these coefficient matrices. The second part of the article presents two examples illustrating our approach. Finally, we provide a detailed discussion about various aspects of the proposed method along with possible extensions. Nonequilibrium steady states (NESs), i.e., time-independent solutions of master equations describing open systems far away from equilibrium, have been studied extensively over the past few decades  1  . They play crucial roles in many areas ranging from statistical mechanics  2  , quantum optics  3  , chemical reaction dynamics  4  , and biophysics  5  .\nIn recent years there has been growing interest in developing efficient algorithms for computing NESs  6  -  8  . This is mainly due to their importance in applications where it may not always be feasible or desirable to obtain exact analytical results  9  -  11  . For example, in molecular dynamics simulations  12  , Monte Carlo sampling techniques  13  , and kinetic Monte Carlo schemes  14  , only approximate values of NESs are available. Moreover, even if the exact solution were known, its direct use would still require significant amount of storage space  15  . Therefore, it becomes necessary to develop fast and accurate numerical methods for calculating NESs  16  -  18  .\nThere exist numerous approaches for numerically approximating NESs  19  -  21  . Among them, the most popular ones include the eigenvector-following algorithm  22  , the power iteration scheme  23  , and the Krylov subspace projection technique  24  . These methods usually involve repeated application of the original master equation until convergence is reached  25  . However, since the number of...",
        "watermark_text": "The nonequilibrium steady states ( NESS ) of matrix product type are the subject of this study , which is intended to be used for researchers in computational physics and chemistry who desire to solve difficulties with such NESSs using numerical methods . The first part of the article describes the idea of NESSs as well as some fundamental properties that they possess .In particular , we explain how one can build an explicit representation of any given NESS by modeling a linear network of equations whose coefficient matrices depend on the underlying transition rates between various microstates . We especially consider many important matters related to the creation of these coefficient matrices .The second part of the article gives two examples illustrating our approach . Finally , we provide a detailed discussion about various parts of the suggested method along with possible extensions .Nonequilibrium steady states ( NESs ) , i . e . , time - based answers of master equations representing open systems close away from equilibrium , have been studied frequently over the previous few years 1 . They play crucial roles in different areas ranging from statistical mechanics 2 , quantum optics 3 , chemical process mechanics 4 , and biophysics 5 .In recent years there has been growing interest in building fast algorithms for processing NESs 6 - 8 . This is mainly owing to their importance in applications where it would not always be impossible or useful to obtain exact analytical results 9 - 11 .For instance , in polymer dynamics simulations 12 , Monte Carlo analysis methods 13 , and dynamic Monte Carlo schemes 14 , only approximate estimates of NESs are available . Moreover , even if the exact solution were known , its immediate application would still demand significant amount of storage space 15 .Therefore , it becomes necessary to develop fast and precise quantitative methods for calculating NESs 16 - 18 . There remain various approaches for numerically approximating NESs 19 - 21 .Among them , the most popular ones include the eigenvector - following procedure 22 , the power iteration scheme 23 , and the Krylov subspace projection procedure 24 . These methods usually include repeated application of the original master equation until convergence is reached 25 .However , since the quantity of . . .",
        "ori-fast-z-score": -0.8315218406202999,
        "water-fast-z-score": 8.390811300804845
    },
    {
        "original_text": "The lectures were given by David Gross at the Cargese Summer Institute in Corsica, France during August 2005.  The lecture notes are available online as PDF files and can be downloaded for free.   These lecture notes cover topics such as:  - Introduction to string theory - Gauge fields and gauge symmetries - Supersymmetry - Supergravity - String field theories - D-branes - Open strings - Closed strings - Tachyons - Bosonic open strings - Fermionic open strings - Vacuum expectation values - Energy-momentum tensors - Interactions between branes - General relativity - Gravity induced on a brane - Black holes - Cosmology - Time evolution - Conformal invariance - Renormalization group flow - Dualities - M-theory - Other approaches - Comments on future directions - References - Index   This is an excellent resource for learning about many aspects of modern theoretical physics including superstrings, supergravities, black holes, cosmology, time evolution, conformal invariance, renormalization group flows, dualities, M-theory, other approaches etc...",
        "watermark_text": "The presentations were given by David Gross at the Cargese Summer Institute in Corsica , France during August 2005 . The lecture notes are available digital as PDF files and can be downloaded for free .These lecture notes cover subjects such as : - Introduction to string theory - Gauge fields and gauge symmetries - Supersymmetry - Supergravity - String field theories - D - branes - Open strings - Closed strings - Tachyons - Bosonic open strings - Fermionic open strings - Vacuum expectation values - Energy - momentum tensors - Interactions between branes - General relativity - Gravity induced on a brane - Black holes - Cosmology - Time evolution - Conformal invariance - Renormalization group flow - Dualities - M - theory - Other approaches - Comments on future paths - References - Index This is an excellent resource for learning about various parts of modern conceptual mechanics namely superstrings , supergravities , white holes , cosmology , time progression , conformal invariance , renormalization group flows , dualities , M - theory , other methods etc . . .",
        "ori-fast-z-score": 2.54000254000381,
        "water-fast-z-score": 4.826004826007239
    },
    {
        "original_text": "The quantum electrodynamic (QED) effects on the dynamics and decoherence of semiconductor-based qubit systems are investigated in this work. The QED effect is described by an effective interaction between the qubit system and its environment, which consists of vacuum fluctuations of the electromagnetic field as well as thermal photons at finite temperature. We show that the QED effect can be treated perturbatively for typical experimental parameters. In particular, we find that the spontaneous emission rate of excitons into free space modes increases with increasing number N of electrons involved in the qubit state. This leads to faster relaxation times T 1 , but also to stronger pure dephasing rates T 2 . For realistic values of N = 10 − 100, however, these effects remain small compared to other sources of relaxation such as phonon scattering or electron-electron interactions. \n \n Introduction \n \n Quantum information processing has attracted considerable attention over recent years due to its potential applications in various fields ranging from communication technology  1  to metrology  2  . Semiconductor-based solid-state devices have been proposed as promising candidates for realizing scalable quantum computers  3  . Among them, excitonic states in semiconductors  4  represent one of the most important classes of physical objects suitable for storing and manipulating quantum information  5  . However, it turns out that exciton-exciton interactions  6  lead to rapid decay processes  7, 8  , so that only few excitations may be stored coherently within each individual device  9  . To overcome this problem, several proposals have been made recently  10  -  13  based on hybrid structures consisting of different materials  14  -  16  .\n \nIn this Letter, we investigate how the quantum electrodynamic (or radiative) coupling  17  affects the dynamics of semiconductor-based qubit sys-tems. As shown schematically in Fig. 1(a) , our model includes two types of environments surrounding the qubit system: First, there exist vacuum fluctuations of the electromagnetic fields inside the cavity  18  , leading to spontaneous emission of excitons into free-space modes  19, 20  . Second, there exists a bath of thermal photons  21 ",
        "watermark_text": "The quantum electrodynamic ( QED ) impacts on the dynamics and decoherence of semiconductor - based qubit systems are examined in this research . The QED effect is characterized by an efficient interaction between the qubit network and its climate , which consists of vacuum fluctuations of the electromagnetic field as well as heat photons at finite temperature .We see that the QED effect can be treated perturbatively for typical observation variables . In particular , we find that the spontaneous emission speed of excitons into free space modes increases with increasing quantity N of electrons involved in the qubit state .This leads to faster relaxation times T 1 , but also to higher basic dephasing speeds T 2 . For ideal values of N = 10 − 100 , however , these influences remain small relative to other sources of relaxation such as phonon absorption or electron - ion interactions .Introduction Quantum knowledge processing has garnered considerable scrutiny over recent history owing to its potential applications in different fields ranging from telephone technology 1 to metrology 2 . Semiconductor - based solid - state machines have been proposed as hopeful candidates for realizing scalable quantum computers 3 .Among them , excitonic states in semiconductors 4 constitute one of the most important classes of physical objects proper for storing and manipulating quantum information 5 . However , it turns out that exciton - exciton interactions 6 lead to rapid decay pathways 7 , 8 , so that only few excitations might be transferred coherently within each individual system 9 .To solve this question , various proposals have been made recently 10 - 13 based on hybrid structures consisting of different materials 14 - 16 . In this Letter , we investigate how the quantum electrodynamic ( or radiative ) bonding 17 affects the dynamics of semiconductor - based qubit sys - tems .As seen schematically in Fig . 1 ( a ) , our model includes two forms of experiences involving the qubit network : First , there remain vacuum fluctuations of the electromagnetic forces inside the cavity 18 , leading to spontaneous emission of excitons into free - space modes 19 , 20 .Second , there exists a pool of thermal photons 21",
        "ori-fast-z-score": -0.24743582965269675,
        "water-fast-z-score": 6.904757466825006
    },
    {
        "original_text": "We study the resonance phenomenon for an open-loop control problem in a nonlinear stochastic model describing interactions between phytoplankton (plants) and zooplankton (animals). The main goal is to find optimal values of parameters characterizing external periodic forcing, which maximize the growth rate of planktons. We show that this optimization problem can be reduced to finding solutions of some algebraic equations. In particular, we prove that there exists only one solution corresponding to maximum value of the objective function. Moreover, it turns out that the obtained results are robust with respect to small perturbations of initial conditions. Finally, numerical simulations illustrate our theoretical findings. \n \n Keywords: Stochastic differential equation, Periodic forcing, Resonance, Optimization problems, Nonlinear dynamics \n \n 1 Introduction \n \n Interactions among different species play important role in many natural ecosystems. For example, phytoplankton (algae or plants), living at the base of food chain, provide energy source for other organisms such as zooplankton (fishes or animals). Therefore, understanding how these two populations interact may help us better understand ecosystem functioning. Recently, several mathematical models have been proposed to describe population dynamics of phytoplankton- zooplankton systems  1–3  . These models include deterministic terms representing intrinsic growth rates of both populations and their interaction effects, as well as random fluctuations due to environmental factors. It has been shown that under certain assumptions on the coefficients of the model, its long-term behavior exhibits chaotic attractor  4  , which makes analysis of the system very difficult. On the other hand, if the effect of random fluctuations is neglected then the resulting deterministic model becomes much easier to analyze  5–7  .\n \nIn  8  , authors studied the following model:\n \n \n \n dX(t) = rX(t)(1 - X(t))dt + fX(t)sin(wt)dW(t),\n dY(t) = rY(t)(1 - Y(t))dt + fy(t)sin(w0t)dW(t).\n \n(",
        "watermark_text": "We research the resonance phenomenon for an open - loop control problem in a nonlinear stochastic model explaining interactions between phytoplankton ( plants ) and zooplankton ( animals ) . The main goal is to find optimal values of values characterizing external periodic forcing , which maximize the development time of planktons .We see that this optimization problem can be reduced to finding solutions of some algebraic equations . In particular , we prove that there exists only one solve corresponding to maximum value of the objective function .Moreover , it turns out that the achieved findings are robust with regard to small perturbations of initial conditions . Finally , numerical simulations highlight our theoretical results .Keywords : Stochastic integral equation , Periodic forcing , Resonance , Optimization problems , Nonlinear dynamics 1 Introduction Interactions among different species play attractive role in different biological environments . For instance , phytoplankton ( algae or plants ) , live at the base of eat chain , provide energy source for other species such as zooplankton ( fishes or organisms ) .Therefore , studying how these two communities interact may assist us better understand ecological functioning . Recently , various computational models have been proposed to explain population behavior of phytoplankton - zooplankton communities 1 – 3 .These models include deterministic terms representing intrinsic development rates of both populations and their interaction influences , as also as random fluctuations owing to environmental factors . It has been shown that under certain assumptions on the coefficients of the model , its long - term behavior presents dynamic attractor 4 , which makes study of the system very difficult .On the other hand , if the impact of random fluctuations is neglected then the resulting deterministic model seems far easy to analyze 5 – 7 . In 8 , authors explored the following model : dX ( t ) = rX ( t ) ( 1 - X ( t ) ) dt + fX ( t ) sin ( wt ) dW ( t ) , dY ( t ) = rY ( t ) ( 1 - Y ( t ) ) dt + fy ( t ) sin ( w0t ) dW ( t ) .(",
        "ori-fast-z-score": 2.482817665807104,
        "water-fast-z-score": 8.877545314489295
    },
    {
        "original_text": "We show that the coherence property for monadic second-order logic (MSO) over graphs is not equivalent to the existence of an MSO-unique normal form, answering a question raised by Courcelle and Engelfriet in 1990.  We also prove that this result holds even if we restrict our attention to finite trees or forests with bounded degree. This answers another open problem posed by Courcelle and Makowsky in 1991. Finally, we give examples showing that these results are optimal. The main tool used here is a new technique called tree-expansion which allows us to reduce questions about infinite structures to questions about finite ones. Monadic second-order logic (or MSO-logic) has been studied extensively since its introduction in the 1960s as a generalization of first-order logic. It was shown early on that it can express many interesting properties such as connectivity, planarity, and Hamiltonicity. In particular, MSO-formulas define exactly those sets definable in existential monadic second-order logic, i.e., the class of all sets definable using quantification only over subsets of vertices.",
        "watermark_text": "We see that the coherence property for monadic second - order logic ( MSO ) over graphs is not equivalent to the existence of an MSO - unique normal shape , answering a problem advanced by Courcelle and Engelfriet in 1990 . We additionally prove that this consequence holds even if we limit our focus to finite forests or forests with bounded degree .This addresses another open challenge posed by Courcelle and Makowsky in 1991 . Finally , we give examples demonstrating that these results are optimal .The main technique useful here is a new technique called tree - expansion which allows us to reduce problems about infinite structures to questions about finite ones . Monadic second - order calculus ( or MSO - reasoning ) has been studied frequently since its introduction in the 1960s as a generalization of second - order algebra .It was shown ago on that it can express many interesting properties such as connectivity , planarity , and Hamiltonicity . In particular , MSO - formulas define exactly those sets definable in existential monadic second - order calculus , i . e . , the class of all sets definable using quantification only over subsets of vertices .",
        "ori-fast-z-score": 0.3333333333333333,
        "water-fast-z-score": 5.366563145999495
    },
    {
        "original_text": "We present the first results on black hole accretion using our new numerical scheme, which is based on an implicit-explicit time integration method and uses adaptive mesh refinement (AMR). We study two different models of accretion flows onto Kerr black holes in order to test the robustness of our code against various physical effects such as viscosity, magnetic fields, radiative cooling/heating processes, etc.. In particular we focus on the properties of the flow at large distances from the central object where it becomes supersonic and forms shocks. Our main goal here was to check whether these features are correctly captured by our AMR code. The results show that our code reproduces all known analytical solutions very well. \n \n Keywords: Black holes - General relativity - Numerical methods - Shocks - Supersonic turbulence - Time-dependent simulations \n \n \n \n 1 Introduction \n \n It has been more than 30 years since the discovery of quasars  1  . Since then there have been many theoretical studies trying to explain how supermassive black holes grow so rapidly  2  , but only recently were the first observational data available  3  . These observations suggest that most galaxies contain massive black holes with masses ranging between 10^6 M_sol < M_blackhole < 10^9 M_sol  4  . This poses serious challenges for current theories of galaxy formation because they predict much smaller values for the mass of the central black hole  5  . \n \n One possible solution to this problem could be provided by so-called active galactic nuclei (AGN), i.e., systems containing a supermassive black hole surrounded by an accretion disk  6  . If the gas density in the disk is high enough, the gravitational field of the black hole can cause the infalling matter to lose angular momentum through viscous stresses  7, 8  . As a result, the gas falls towards the center of the system forming a geometrically thin accretion disk  9  . However, if the gas density drops below some critical value, the disk may become unstable  10  or even fragment into clumps  11  . Such instabilities lead to the development of large-scale",
        "watermark_text": "We publish the first findings on dark hole accretion use our new numerical system , which is based on an implicit - explicit time integration approach and using adaptive mesh refinement ( AMR ) . We research two different models of accretion flows onto Kerr white holes in order to test the robustness of our code against several physical effects such as viscosity , magnetic fields , radiative cooling / cooling systems , etc . .In particular we focus on the properties of the flow at large distances from the main object where it becomes supersonic and shapes shocks . Our main goal here was to examine whether these characteristics are correctly captured by our AMR code .The results show that our code reproduces all known theoretical solutions very best . Keywords : Black holes - General relativity - Numerical methods - Shocks - Supersonic turbulence - Time - dependent simulations 1 Introduction It has been more than 30 centuries since the discovery of quasars 1 .Since then there have been many theoretical researchers trying to explain how supermassive black holes expand so quickly 2 , but only lately were the first observational data available 3 . These measurements suggest that most objects possess massive brown holes with masses ranging between 10 ^ 6 M _ sol < M _ blackhole < 10 ^ 9 M _ sol 4 .This poses serious difficulties for recent predictions of galaxy formation because they predict far lower values for the mass of the main white hole 5 . One potential answer to this question could be provided by so - called active galactic nuclei ( AGN ) , i . e . , structures featuring a supermassive black hole accompanied by an accretion ring 6 .If the gas density in the disk is high enough , the gravitational field of the dark hole can cause the infalling matter to lose angular velocity through viscous stresses 7 , 8 . As a result , the gas drops towards the center of the system producing a geometrically thin accretion cone 9 .However , if the gas density decreases below some essential value , the disk might turn volatile 10 or maybe fragment into clumps 11 . Such instabilities lead to the development of large - scale",
        "ori-fast-z-score": 0.8835412617927487,
        "water-fast-z-score": 9.397666148159237
    },
    {
        "original_text": "The SIM PlanetQuest mission is the most promising near-term technique for detecting, finding masses, and determining three-dimensional orbits of nearby habitable planets.  This article describes how SIM PlanetQuest will find these planets by measuring their astrometric wobble as they transit in front of their parent stars.   It also discusses how SIM PlanetQuest can be used to detect other types of exoplanets such as those with large orbital eccentricities or that are on highly inclined orbits relative to our line-of-sight.    Finally, it presents some preliminary results showing what we might expect to learn about extrasolar planetary systems using this new instrumentation. Keywords: Extrasolar planet, Astrometry, SIM PlanetQuest, Transit detection, Mass measurement, Orbital determination. 1 Introduction   In recent years there has been an explosion in interest in discovering extra-solar terrestrial planets (exo-Earths) because of the possibility that one may harbor life like Earth does. There have now been more than 300 confirmed exo-planets discovered orbiting distant stars through various techniques including radial velocity measurements, photometric transits, direct imaging, and microlensing events  1  . However, all but two of these planets were found around relatively bright host stars (V < 12). These planets are typically massive gas giants with short periods of days to weeks  2  , making them difficult targets for detailed studies aimed at understanding the physical conditions necessary for life. For example, only three of these planets have measured masses: HD 209458b  3  , GJ 436b  4  , and OGLE-TR-561b  5  .  Of these, only HD 209458b has a radius determined directly  6  .\n2\n\nSIM PlanetQuest Mission Overview\nIn order to study the atmospheres and surfaces of smaller, cooler planets, which are likely candidates for hosting liquid water  7, 8  , astronomers need to find planets around fainter stars. To do so requires space-based observatories capable of obtaining high-precision astrometric data over many years. Such observations would allow us to measure the positions of thousands of faint stars simultaneously with precisions better than 0",
        "watermark_text": "The SIM PlanetQuest mission is the most exciting near - term technique for detecting , finding masses , and determining three - dimensional orbits of nearby habitable planets . This page describes how SIM PlanetQuest will locate these planets by monitoring their astrometric wobble as they travel in front of their father planets .It additionally outlines how SIM PlanetQuest can be used to locate other types of exoplanets such as those with large orbital eccentricities or that are on highly inclined planets relative to our line - of - sight . Finally , it presents some preliminary results showing what we may expect to find about extrasolar planetary structures using this new instrumentation .Keywords : Extrasolar planet , Astrometry , SIM PlanetQuest , Transit detection , Mass calculation , Orbital measurement . 1 Introduction In recent years there has been an explosion in interest in discovering extra - solar terrestrial worlds ( exo - Earths ) because of the prospect that one may harbor living like Earth does .There have now been more than 300 verified exo - planets discovered orbiting distant stars through several methods namely radial speed measurements , photometric transits , direct scanning , and microlensing events 1 . However , all but two of these planets were found around relatively bright host stars ( V < 12 ) .These worlds are typically massive gas giants with short periods of weeks to weeks 2 , making them difficult targets for detailed analyses aimed at studying the physical conditions crucial for life . For instance , only three of these planets have recorded masses : HD 209458b 3 , GJ 436b 4 , and OGLE - TR - 561b 5 .Of these , only HD 209458b has a diameter determined directly 6 . 2 SIM PlanetQuest Mission Overview In try to study the atmospheres and surfaces of tiny , cooler planets , which are likely candidates for hosting liquid water 7 , 8 , astronomers need to find planets around fainter stars .To do so requires space - based observatories capable of acquiring high - precision astrometric data over numerous years . Such observations would enable us to measure the places of thousands of distant stars simultaneously with precisions higher than 0",
        "ori-fast-z-score": 0.7373087284671365,
        "water-fast-z-score": 7.505553499465135
    },
    {
        "original_text": "We report on observations made with Chandra and XMM-Newton that reveal an X-ray flare from the magnetar CXOU J16 47 10 . 2-45 52 16 (hereafter, J1647) located within the open cluster Westerlund 1. The flare was detected by both observatories during their respective slews to point at another target; it lasted for about one hour before fading below detectability. We find no evidence for any significant change in the spin-down rate or period derivative of this source following its outburst. \n \n This is the first time such a large event has been observed from a magnetar; we estimate that the total energy released in the flare was ~3 x 10^44 erg. Our analysis shows that the flare occurred when the star s magnetic field lines were nearly perpendicular to our line-of-sight. In addition, we detect pulsations from J1647 during the flare which are consistent with those seen prior to the flare. These results suggest that the flaring activity may be due to reconnection events occurring along the closed loops of the stellar magnetic field.",
        "watermark_text": "We report on observations made with Chandra and XMM - Newton that indicate an X - ray flare from the magnetar CXOU J16 47 10 . 2 - 45 52 16 ( hereafter , J1647 ) located within the open cluster Westerlund 1 .The flare was noticed by both observatories during their separate slews to point at another target ; it persisted for about one evening before faded below detectability . We see no evidence for any considerable shift in the spin - down frequency or duration derivative of this source following its outburst .This is the first time such a large incident has been observed from a magnetar ; we estimate that the total energy released in the flare was ~ 3 x 10 ^ 44 erg . Our study shows that the flare originated when the star s magnetic field lines were roughly perpendicular to our line - of - view .In addition , we find pulsations from J1647 during the flare which are compatible with those observed earlier to the flare . These data suggest that the flaring activity may be due to reconnection events resulting along the shut rings of the stars magnetic force .",
        "ori-fast-z-score": -0.7171371656006361,
        "water-fast-z-score": 5.259005881071332
    },
    {
        "original_text": "We have analyzed new photometric data for two AM CVn-type systems, HP Librae (=PG 1336-018) and V803 Cen, obtained with the Kepler space telescope in order to determine their orbital periods more accurately than before.  We find that both systems are eclipsing binaries with very short orbital periods of only P orb = 81.6 min for HP Librae and P orb = 80.3 min for V803 Cen. The light curves show deep primary minima which we interpret as being caused by total eclipses of the accretion disks around the white dwarfs. In addition, there is evidence for an additional eclipse feature at phase 0.5-0.7 in the case of HP Librae. This could be due either to partial eclipses or occultations of one component by another. For comparison purposes, we also present results on the previously known system CR Boo.",
        "watermark_text": "We have analyzed new photometric data for two AM CVn - class systems , HP Librae ( = PG 1336 - 018 ) and V803 Cen , obtained with the Kepler space telescope in order to estimate their orbital periods more accurately than before . We see that both components are eclipsing binaries with very brief orbital periods of only P orb = 81 . 6 min for HP Librae and P orb = 80 . 3 min for V803 Cen .The light curves show deep primary minima which we view as being created by full eclipses of the accretion disks around the white dwarfs . In addition , there is evidence for an additional eclipse event at phase 0 . 5 - 0 . 7 in the case of HP Librae .This might be due either to partial eclipses or occultations of one part by another . For comparison purposes , we also present results on the previously known system CR Boo .",
        "ori-fast-z-score": -0.42857142857142855,
        "water-fast-z-score": 2.7142857142857144
    },
    {
        "original_text": "In this work, we propose the subjective information measure (SIM) to quantify the amount of information in an image or video sequence. The SIM is defined as the minimum number of bits required for lossless coding of the source data under some fidelity criterion. We show that the proposed SIM can be used to derive rate-distortion functions with high accuracy by using only one parameter. In addition, it also provides accurate prediction on ratedistortion performance at low bit rates. Finally, we demonstrate its effectiveness through experiments conducted on several test sequences. Index Terms -Information theory, Image compression, Video compression. 1 Introduction Data compression has been widely studied over past decades due to its importance in many applications such as digital storage systems, communication networks, medical imaging, etc.. A fundamental problem in data compression is how to accurately predict the compressed file size given the original uncompressed data. This problem is usually referred to as rate-distortion analysis  1  . It is well known that the rate-distortion function characterizes the relationship between the average codeword length and distortion level achieved by any optimal encoding scheme  2  .\nThe most commonly adopted approach to solve the rateconstraint optimization problems is Lagrangian relaxation  3  , which transforms constrained optimization into unconstrained ones via introducing additional variables called Lagrange multipliers  4  . However, solving these problems requires iterative algorithms  5  , which are computationally expensive  6  . To overcome this difficulty, researchers have developed various fast algorithms  7, 8  . Nevertheless, they still suffer from slow convergence speed when applied to practical problems  9  .",
        "watermark_text": "In this research , we develop the subjective information measure ( SIM ) to quantify the quantity of information in an image or image sequence . The SIM is calculated as the minimum amount of bits required for lossless coding of the input data under some fidelity criterion .We see that the suggested SIM can be used to derive rate - noise values with high clarity by using only one parameter . In addition , it also provides reliable prediction on ratedistortion behavior at low bit rates .Finally , we prove its effectiveness through experiments conducted on numerous test sequences . Index Terms - Information theory , Image compression , Video compression .1 Introduction Data compression has been widely research over past decades owing to its significance in multiple applications such as electronic storage systems , transport networks , medical imaging , etc . . A crucial problem in data encoding is how to correctly forecast the compressed file size given the actual uncompressed information . This problem is usually referred to as rate - degradation analysis 1 .It is well established that the rate - degradation relation characterizes the relationship between the average codeword height and distortion height accomplished by any optimal encoding scheme 2 . The most commonly implemented way to solve the rateconstraint optimization problems is Lagrangian relaxation 3 , which transforms constrained optimization into unconstrained ones via introducing additional parameters named Lagrange multipliers 4 .However , solving these problems demands iterative techniques 5 , which are computationally expensive 6 . To solve this challenge , researchers have developed various quick schemes 7 , 8 .Nevertheless , they still suffer from slow convergence speed when applied to practical difficulties 9 .",
        "ori-fast-z-score": -0.17407765595569785,
        "water-fast-z-score": 7.659900395832447
    },
    {
        "original_text": "We consider a spherically symmetric solution to Einstein s equations in five dimensions with an extra dimension compactified on S 1 /Z 2 . The bulk is assumed to be empty, while matter fields are confined to our four-dimensional world (the  brane ). We find that this model can explain the observed flatness of galactic rotation curves without introducing any new particles or exotic forms of energy density. In particular we show how the mass distribution within galaxies may arise naturally as a consequence of the geometry of space-time. This work was supported by NSF grant PHY-0456728. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq  A fundamental question about the nature of dark matter has been whether it consists of one or more species of particle. If so, what are their masses? What interactions do they have with ordinary matter? How much dark matter does each galaxy contain? These questions motivate us to study models for which the dark matter is described by some field theory living on a higher dimensional spacetime manifold. \n \n Here we will focus on a class of solutions where the extra dimension is compactified on a circle $S^1$. Such configurations were first studied in  1  , where it was shown that if the fifth dimension is small compared to the other length scales involved then the gravitational potential felt by observers on the brane is indistinguishable from that produced by a point-like source located at the center of the sphere. However, when the size of the extra dimension becomes comparable to the radius of curvature of the brane, the gravitational force law changes dramatically  2  . \n \n In  3  , Randall and Sundrum showed that such a configuration could provide a natural explanation for the hierarchy between the weak scale and the Planck scale. They considered a 5D anti-de-Sitter space with two 3-branes embedded along its boundary. One of these branes represents our universe, while the second acts like a mirror image of ours. Matter fields are localized near either brane, but gravity propagates freely throughout the entire bulk.",
        "watermark_text": "We consider a spherically invariant solution to Einstein s equations in five dimensions with an additional dimension compactified on S 1 / Z 2 . The bulk is expected to be empty , while matter fields are localized to our four - dimensional world ( the brane ) .We see that this description can describe the seen flatness of galactic rotation curves without introducing any new ions or exotic kinds of power concentration . In particular we explain how the mass distribution within stars would occur readily as a outcome of the topology of space - time .This project was supported by NSF grant PHY - 0456728 . PACS scores : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq A profound question about the nature of dark matter has been whether it consists of one or more species of particle .If so , what are their masses ? What encounters do they have with normal matter ?How much dark matter does each galaxy consist ? These questions motivate us to study models for which the dark matter is depicted by some field model living on a higher dimensional spacetime manifold .Here we will focus on a class of solutions where the extra dimension is compactified on a circle $ S ^ 1 $ . Such configurations were first explored in 1 , where it was shown that if the fifth dimension is tiny relative to the other length scales included then the gravitational potential felt by observers on the brane is indistinguishable from that created by a point - like source located at the center of the circle .However , when the height of the extra dimension becomes akin to the radius of curvature of the brane , the gravitational pressure law changes dramatically 2 . In 3 , Randall and Sundrum suggested that such a configuration could give a natural explanation for the hierarchy between the strong scale and the Planck scale .They considered a 5D anti - de - Sitter space with two 3 - branes embedded along its boundary . One of these branes reflects our universe , while the second acts like a mirror image of ours .Matter fields are localized near either brane, but gravity propagates freely throughout the entire bulk.",
        "ori-fast-z-score": 1.8593393604027364,
        "water-fast-z-score": 8.056141039648216
    },
    {
        "original_text": "We present an analysis of the kinematic properties of high velocity stars (HVSs) found by Brown et al. (2007a,b) . We find that these HVSs are consistent with being ejected from the Galactic center along orbits which have been perturbed by encounters with massive black holes at intermediate distances and possibly also by other mechanisms such as gravitational scattering off molecular clouds or globular clusters. The observed velocities of the HVSs can be reproduced if they were ejected between 0.5 and 1 Gyr ago on nearly radial orbits with eccentricities ranging from 0 to 0.9. This is consistent with theoretical predictions for the time scale over which dynamical friction causes the orbital decay of massive objects into the central regions of galaxies. \n \n Keywords: High-velocity star, Black hole, Galaxy evolution, Ejection mechanism, Dynamical friction, Halo shape \n \n Introduction \n \n Hypervelocity stars (HVSs; Brown et al., 2007a; Kenyon et al., 2008 ) are defined as those having space velocities exceeding 500 km/s relative to their local standard of rest. They may originate either from tidal disruption events involving compact remnants near the Galactic Center (GC; Hills 1988), or from binary systems where one component has been accelerated through strong interactions with another object (e.g., Yu & Tremaine 2003; Bromley et al. 2006 ). In addition, it was suggested recently that some HVSs could be produced via the interaction of a single star with a supermassive black hole (SMBH) located outside the GC (Yu & Madau 2007; Sesana et al. 2007 ) . It should be noted however that there exists no compelling evidence yet supporting this scenario .",
        "watermark_text": "We present an assessment of the kinematic qualities of high velocity stars ( HVSs ) found by Brown et al . ( 2007a , b ) .We see that these HVSs are compatible with being ejected from the Galactic center along orbits which have been perturbed by encounters with massive blue holes at intermediate distances and maybe also by other mechanisms such as gravity reflection off molecular clouds or globular galaxies . The observed velocities of the HVSs can be reproduced if they were ejected between 0 . 5 and 1 Gyr ago on nearly radial orbits with eccentricities ranging from 0 to 0 . 9 .This is compatible with theoretical estimates for the period scale over which dynamical friction produces the orbital decay of large objects into the main regions of stars . Keywords : High - speed star , Black hole , Galaxy migration , Ejection system , Dynamical friction , Halo shape Introduction Hypervelocity stars ( HVSs ; Brown et al . , 2007a ; Kenyon et al . , 2008 ) are specified as those having space velocities exceeding 500 kilometre / s relative to their nearby standard of rest .They might originate either from tidal disruption events concerning compact remnants near the Galactic Center ( GC ; Hills 1988 ) , or from binary complexes where one part has been accelerated through strong encounters with another object ( e . g . , Yu & Tremaine 2003 ; Bromley et al . 2006 ) .In addition , it was suggested later that some HVSs might be formed via the interaction of a single star with a supermassive black hole ( SMBH ) located outside the GC ( Yu & Madau 2007 ; Sesana et al . 2007 ) .It should be mentioned however that there exists no compelling evidence yet backing this scenario .",
        "ori-fast-z-score": -1.165543034828717,
        "water-fast-z-score": 5.757810430396346
    },
    {
        "original_text": "We study the phase diagram and critical behavior for the two component symmetric exclusion process (TCSEP) on an infinite one-dimensional lattice, where particles can hop to nearest neighbor sites only if they are empty. We show that there is no condensation at finite density when the system has periodic boundary conditions. However, we find that the TCSEP undergoes a first-order phase transition into a condensed state as soon as it is coupled to particle reservoirs at its ends. The order parameter jumps discontinuously across this transition line which terminates at a tricritical point. In addition, we calculate exactly the current-current correlation function along the transition line using Bethe ansatz techniques. Finally, we discuss how our results may be generalized to higher dimensions. PACS numbers: 05.40.+j, 64.60.Cn, 71.10.Jk \nI. INTRODUCTORY REMARK\nThe aim of this work is to investigate the properties of a simple model of interacting particles in contact with particle reservoirs. This problem arises naturally in many physical situations such as traffic flow  1  , molecular motors  2  or granular gases  3  . Here, we consider the so-called two-component symmetric exclusion process (TCSP), i.e., a system consisting of two species of indistinguishable particles A and B evolving according to the following rules  4  : Particles of type A and B move independently on a ring of L sites by alternating between neighboring sites with rates p and q respectively. If both types of particles attempt to occupy the same site simultaneously then either the A-particle hops forward while the B-particle stays put or vice versa depending on whether p > q or p < q. Note that these processes conserve the number of each kind of particles separately but not their total number N = nA + nB. Therefore, the dynamics of the TCSP is described by the master equation",
        "watermark_text": "We work the phase diagram and critical behavior for the two element symmetric exclusion cycle ( TCSEP ) on an endless one - dimensional lattice , where ions can jump to nearest neighbor sites only if they are empty . We see that there is no condensation at finite density when the system has periodic boundary rules .However , we find that the TCSEP undergoes a first - order phase shift into a condensed state as shortly as it is linked to particle reservoirs at its ends . The order parameter jumps discontinuously across this transition line which terminates at a tricritical position .In addition , we estimate exactly the present - current correlation function along the transfer path using Bethe ansatz techniques . Finally , we talk how our findings may be generalized to higher dimensions .PACS numbers : 05 . 40 . + j , 64 . 60 . Cn , 71 . 10 . Jk I . INTRODUCTORY REMARK The goal of this research is to examine the properties of a simple representation of interacting molecules in contact with particle tanks .This problem arises readily in different mechanical circumstances such as traffic flow 1 , molecular motors 2 or granular materials 3 . Here , we define the so - called two - component symmetric exclusion system ( TCSP ) , i . e . , a system consisting of two species of indistinguishable particles A and B evolving according to the following laws 4 : Particles of type A and B go independently on a ring of L locations by alternating between neighboring sites with levels p and q respectively .If both types of particles attempt to fill the same site jointly then either the A - particle hops forward while the B - particle stays put or vice versa varying on whether p > q or p < p . Note that these mechanisms conserve the number of each types of molecules individually but not their total value N = nA + nB .Therefore , the dynamics of the TCSP is modeled by the master equation",
        "ori-fast-z-score": -1.76851903423969,
        "water-fast-z-score": 5.747048932153913
    },
    {
        "original_text": "We have performed molecular dynamics simulations to investigate the dynamic crack propagation in an icosahedral AlPdMn quasicrystal and its periodic approximant, i-AlCuFe. The results show that both materials exhibit similar features for the crack growth process at low temperatures (T = 300 K). However, there are significant differences between them when T is increased up to 600 K. In particular, we find that the quasicrystal shows a higher resistance against crack propagation than the approximant under tensile loading conditions. This behavior can be explained by considering the different atomic structures of these two systems. \n \n We also studied how the temperature affects the mechanical properties of the quasicrystal. Our results indicate that increasing the temperature leads to a decrease in the elastic constants C11 and C44 as well as in the bulk modulus B. Moreover, our calculations reveal that the Young s moduli E decreases with increasing temperature.",
        "watermark_text": "We have done chemical dynamics simulations to examine the dynamic crack propagation in an icosahedral AlPdMn quasicrystal and its periodic approximant , i - AlCuFe . The results show that both materials exhibit similar features for the crack growth process at low temperatures ( T = 300 K ) .However , there are significant variations between them when T is expanded up to 600 K . In particular , we find that the quasicrystal demonstrates a higher resistance against fracture propagation than the approximant under tensile loading circumstances . This phenomenon can be described by analyzing the different atomic relationships of these two systems .We additionally investigated how the temperature changes the mechanical behavior of the quasicrystal . Our results show that raising the temperature leads to a reduction in the elastic constants C11 and C44 as well as in the bulk modulus B .Moreover , our calculations reveal that the Young s moduli E decreases with expanding temperature .",
        "ori-fast-z-score": 0.5252257314388902,
        "water-fast-z-score": 5.938574464184706
    },
    {
        "original_text": "We study the phenomenological consequences of supersymmetric models with gauge-mediated breaking, in which the Standard Model is extended by adding new vector-like matter fields and extra dimensions. We show that these models can be constructed such that they are free of any unnatural fine-tuning problems associated with the Higgs mass or flavor-changing neutral currents. In particular we find that:  1) The lightest scalar superpartner (the  Higgs  boson) has a mass at most around 300 GeV.  2) Flavor changing neutral current effects are suppressed to an acceptable level for generic values of parameters.  3) Gauge coupling unification occurs naturally within experimental uncertainties. 4) There exists a large parameter space where all sparticles have masses above 1 TeV while still satisfying constraints on electroweak symmetry breaking. 5) These models provide a natural explanation for why there may not yet exist evidence for supersymmetry at accelerator experiments.",
        "watermark_text": "We research the phenomenological consequences of supersymmetric theories with gauge - mediated breaking , in which the Standard Model is extended by added new vector - like matter fields and extra dimensions . We see that these models can be built such that they are free of any strange fine - tuned flaws associated with the Higgs mass or flavor - changing neutral currents .In particular we find that : 1 ) The lightest scalar superpartner ( the Higgs boson ) has a mass at most approximately 300 GeV . 2 ) Flavor shifting neutral current effects are suppressed to an acceptable level for generic values of values .3 ) Gauge coupling unification happens easily within experimental uncertainties . 4 ) There exists a large parameter room where all sparticles have masses above 1 TeV while already satisfying constraints on electroweak symmetry breaking .5 ) These models represent a natural explanation for why there may not already exist evidence for supersymmetry at accelerator studies .",
        "ori-fast-z-score": 0.7385489458759964,
        "water-fast-z-score": 5.908391567007971
    },
    {
        "original_text": "We present numerical simulations to study the formation, evolution, and collapse of quiescent cloud cores induced by dynamic compressions in turbulent molecular clouds. We find that these cloud cores are formed through shock compression at intersections between shocks driven into the clouds by supersonic turbulence. The cloud core masses range from 0.1 M⊙ to 1 M⊙ with typical sizes of about 1000 AU. These cloud cores have low internal velocities (< 2 km s-1) but can be accelerated up to 10 km s-1 during their lifetimes due to gravitational interactions with other dense clumps within the same clouds. Most of them evolve quasi-statically for several free-fall times before collapsing dynamically on time scales ranging from one to ten free-fall times. Our results suggest that such cloud cores may represent an important source of prestellar objects in star-forming regions. Keywords: Turbulence, Star Formation",
        "watermark_text": "We create numerical simulations to study the formation , emergence , and collapse of quiescent cloud cores induced by dynamic compressions in volatile molecular clouds . We see that these cloud cores are created through shock compression at intersections between shocks driven into the clouds by supersonic turbulence .The cloud core masses range from 0 . 1 [UNK] to 1 [UNK] with typical sizes of about 1000 AU . These cloud cores have low internal velocities ( < 2 km s - 1 ) but can be accelerated up to 10 km s - 1 during their lifetimes due to gravitational interactions with other dense clumps within the same clouds .Most of them evolve quasi - statically for multiple free - fall times before crashing dynamically on time ranges ranging from one to ten free - fall times . Our results propose that such cloud cores might represent an important source of prestellar objects in star - creating areas .Keywords: Turbulence, Star Formation",
        "ori-fast-z-score": 0.629940788348712,
        "water-fast-z-score": 3.75
    },
    {
        "original_text": "The quantum auction is an extension to the classical sealed-bid auction, where bidders can submit bids in superposition and the auctioneer announces the winning bid by measuring the state of the system.  The main advantage over classical auctions is that it allows for more efficient use of resources when there are many items being sold or many potential buyers.   In this work we study the problem of finding optimal strategies for both the seller and buyer in such an auction setting with multiple items and multiple buyers.   We show how to find the optimal strategy for the seller using linear programming techniques and provide bounds on the number of measurements required to determine the winner s identity.   For the case of two buyers competing for three items, our results imply that the seller should always announce one item as the winner at each round until only one buyer remains.   ... Quantum mechanics has been used to develop new types of auctions which allow sellers to make better decisions about what goods they want to sell and buyers to make better decisions about which goods they wish to purchase. These auctions have been shown to be useful even if all parties involved do not trust each other completely.",
        "watermark_text": "The quantum auction is an extension to the classical sealed - bid auction , where bidders can submit entries in superposition and the auctioneer announces the wins bidding by observing the state of the scheme . The main advantage over traditional auctions is that it allows for more efficient application of assets when there are many items being sold or many potential buyers .In this research we study the question of finding ideal options for both the seller and seller in such an auction setting with many items and multiple buyers . We see how to find the ideal scenario for the seller using linear programming tools and include bounds on the quantity of measurements required to obtain the winner s identity .For the case of two buyers competing for three goods , our findings mean that the seller should always announce one element as the winner at each round until only one owner stays . . . . Quantum theory has been used to develop new types of auctions which allow sellers to make better decisions about what goods they wish to sell and buyers to make better decisions about which goods they wish to buy .These auctions have been shown to be valuable even if all parties involved do not trust each other completely .",
        "ori-fast-z-score": 2.1105794120443453,
        "water-fast-z-score": 8.140806303599618
    },
    {
        "original_text": "We report on the optical investigation of single self-assembled InAs/GaAs quantum dots (QDs) in an external magnetic field applied along their growth direction. The QD emission line splits into two components with opposite circular polarization when the magnetic field is increased to about 1 T, which corresponds to the Zeeman splitting energy of 0.5 meV at 4 K. We observe that this splitting increases linearly as temperature decreases down to 20 mK and then saturates below 10 mK. This behavior can be explained by taking into account both electron-hole exchange interaction and phonon-assisted relaxation processes between different excitonic states within QDs. Our results show that the spin-flip time for electrons confined inside QDs is longer than 100 ns even under high magnetic fields up to 5 T. Quantum dot (QD), also known as semiconductor nanocrystal or artificial atom, has attracted much attention due to its unique physical properties such as size-tunable band gap  1  , strong confinement effect  2  , and large oscillator strength  3  . These features make it possible to use QDs as building blocks for various optoelectronic devices including light-emitting diodes  4  , lasers  5  , solar cells  6  , photodetectors  7  , and so forth  8  .\nIn recent years, there have been many efforts devoted to investigating the spin dynamics of carriers confined in QDs  9  -  11  . It was found that the carrier spins are very stable against decoherence caused by environmental noise  12  -  14  . However, the spin flip times were reported to vary widely depending on experimental conditions  15  -  17  . For example, the spin lifetimes of holes  18  and electrons  19  confined in QDs were measured to be several nanoseconds using pulsed excitation techniques. On the other hand, the spin lifetime of electrons  20  and holes  21  confined in QDs could reach microsecond level if continuous wave laser was used instead.",
        "watermark_text": "We report on the optical study of single self - assembled InAs / GaAs quantum dots ( QDs ) in an external magnetic current applied along their development path . The QD absorption system separates into two parts with opposite spherical polarization when the magnetic field is expanded to about 1 T , which corresponds to the Zeeman splitting energy of 0 . 5 meV at 4 K . We determine that this splitting changes linearly as temperature grows down to 20 mK and then saturates below 10 mK .This phenomenon can be described by take into consideration both electron - hole exchange behavior and phonon - aided vibration mechanisms between various excitonic states within QDs . Our results show that the spin - flip time for electrons trapped inside QDs is longer than 100 ns even under high magnetic waves up to 5 T . Quantum dot ( QD ) , sometimes called as semiconductor nanocrystal or artificial electron , has garnered considerable scrutiny due to its unique physical properties such as size - tunable band gap 1 , large confinement phenomenon 2 , and large oscillator strength 3 .These features make it able to use QDs as building blocks for various optoelectronic applications notably light - emitting diodes 4 , lasers 5 , solar cells 6 , photodetectors 7 , and so forth 8 . In recent seasons , there have been many efforts devoted to investigating the spin behavior of carriers restricted in QDs 9 - 11 .It was shown that the carrier spins are very stable against decoherence caused by environmental noise 12 - 14 . However , the spin flip times were reported to vary widely depending on experimental environments 15 - 17 .For instance , the spin lifetimes of holes 18 and electrons 19 restricted in QDs were calculated to be several nanoseconds using pulsed excitation techniques . On the other hand , the spin lifetime of electrons 20 and holes 21 confined in QDs might reach microsecond level if continuous wave beam was used instead .",
        "ori-fast-z-score": 0.9330078226479681,
        "water-fast-z-score": 7.209605902279753
    },
    {
        "original_text": "We study cascades on large blog graphs, where each node is an individual blogger and edges represent links between blogs. We propose a novel cascade model that captures the fact that people are more likely to read posts by their friends than random posts. Our main contributions are: (1) we develop efficient algorithms for computing the cascade size distribution under our model; (2) we show how to use these results to estimate the number of active users at any given time during a cascade; (3) we demonstrate the effectiveness of our approach using data collected from LiveJournal.com. The Web has become one of the most important communication channels today. In particular, social networks such as Facebook or Twitter have attracted millions of users who share information with others through online messages known as tweets or status updates. These messages can be seen by all followers of the user posting them, which may cause further propagation of the message within the network. This phenomenon is called viral marketing  1  , and it has been studied extensively over recent years  2  . However, despite its importance, there still remain many open questions about the dynamics of this process  3  .\nIn this work, we focus on studying cascades on large blogging communities, where each node represents an individual blogger and edges connect pairs of blogs written by the same person  4  . A cascade starts when some blogger writes a post containing a URL pointing to another blog s page. Then, if her readers click on the link, they will visit the other blog and possibly continue reading additional posts. As shown in Figure 1 , the resulting graph contains several connected components representing different topics discussed by the community members.",
        "watermark_text": "We research cascades on huge website graphs , where each node is an individual blogger and edges represent connections between blogs . We suggest a novel cascade model that captures the fact that individuals are more likely to see posts by their colleagues than random posts .Our main contributions are : ( 1 ) we develop fast algorithms for modeling the cascade size distribution under our model ; ( 2 ) we study how to use these results to estimate the total of active participants at any given time during a cascade ; ( 3 ) we prove the ability of our approach using data taken from LiveJournal . com . The Web has become one of the most important communication platforms today .In particular , social sites such as Facebook or Twitter have garnered millions of people who share data with others through online emails known as tweets or status updates . These messages can be saw by all supporters of the user sending them , which would cause further transmission of the message within the channel .This phenomenon is dubbed viral marketing 1 , and it has been studied thoroughly over recent years 2 . However , despite its significance , there still continue several open questions about the dynamics of this process 3 .In this research , we focus on studying cascades on huge blogging environments , where each node symbol an individual blogger and edges connect sets of blogs written by the same people 4 . A cascade starts when some blogger writes a post containing a URL pointing to another blog s page .Then , if her viewers flip on the link , they will access the other blog and maybe continue reading additional posts . As seen in Figure 1 , the resulting graph contains multiple connected elements representing different issues discussed by the community members .",
        "ori-fast-z-score": 0.42717882885838043,
        "water-fast-z-score": 8.799883874482637
    },
    {
        "original_text": "We present an analysis of X-ray data obtained with the Chandra X-Ray Observatory for a sample of galaxies selected to be bright at infrared wavelengths (Ks < 20) and located within the Chandra Deep Field-South survey region. We find that most of these objects are active galactic nuclei, but we also identify several cases where the observed X-ray emission is likely due to star formation activity. The majority of our sources have luminosities below 1043 erg s-1, which suggests they may represent a population of low-luminosity AGNs missed by previous surveys. In addition, we detect two heavily absorbed quasars whose optical counterparts were previously classified as reddened stars or galaxies. These results demonstrate how deep X-ray observations can provide new insights into galaxy evolution studies based on multiwavelength datasets. This work was supported under NASA Contract NAS8-38252. We thank the referee for useful comments. \n \n Keywords: Active Galactic Nuclei",
        "watermark_text": "We present an assessment of X - ray data received with the Chandra X - Ray Observatory for a sample of stars selected to be bright at infrared wavelengths ( Ks < 20 ) and located within the Chandra Deep Field - South search region . We see that most of these objects are active galactic nuclei , but we also identify several examples where the seen X - ray radiation is probably due to star formation activity .The majority of our sources have luminosities below 1043 erg s - 1 , which implies they may indicate a population of low - luminosity AGNs missed by earlier surveys . In addition , we find two heavily emitted quasars whose optical cousins were formerly designated as reddened stars or galaxies .These data demonstrate how deep X - ray observations can provide fresh insights into universe evolution investigations based on multiwavelength datasets . This effort was supported under NASA Contract NAS8 - 38252 .We praise the referee for useful comments . Keywords : Active Galactic Nuclei",
        "ori-fast-z-score": 0.24253562503633297,
        "water-fast-z-score": 6.5484618759809905
    },
    {
        "original_text": "We report on X-ray observations made with ASCA and Chandra of PSR B1257+12, which is in orbit around its companion star. The observed fluxes are consistent with those expected for an isolated neutron star heated by accretion from the stellar wind.  We find that the spectrum can be fit equally well using either blackbody or power-law models; however, we cannot rule out other spectral shapes such as thermal bremsstrahlung. In addition to the point source at the position of the pulsar, there appears to be diffuse emission surrounding it. This may arise from hot plasma trapped between the pulsar s magnetosphere and the stellar surface. If this interpretation is correct then our results suggest that the magnetic field lines connecting the two stars have been disrupted by tidal forces during their close passage through periastron. Finally, we discuss possible origins for the unusually high spin-down rate inferred for PSR B1257 + 12 based on radio timing measurements.",
        "watermark_text": "We report on X - ray observations made with ASCA and Chandra of PSR B1257 + 12 , which is in orbit around its daughter star . The observed fluxes are compatible with those expected for an small neutron galaxy heated by accretion from the stellar wind .We see that the spectrum can be fit similarly well using either blackbody or power - law models ; however , we cannot leave out other spectral patterns such as heat bremsstrahlung . In addition to the point origin at the orientation of the pulsar , there seems to be diffuse emission surrounding it .This might arise from hot plasma trapped between the pulsar s magnetosphere and the stellar surface . If this interpretation is accurate then our findings show that the magnetic force connections connecting the two stars have been disrupted by tidal forces during their close passage through periastron .Finally , we investigate possible origins for the unusually high spinning - down probability inferred for PSR B1257 + 12 based on radio timing measurements .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.5778737935111105
    },
    {
        "original_text": "We present an algorithm for the statistical flow inversion problem that is based on variational Bayesian inference and uses Gaussian processes to model the forward operator. The proposed method allows us to obtain posterior distributions over the unknown source parameters, which can be used as prior information in subsequent inverse problems or uncertainty quantification studies. We demonstrate our approach by applying it to two different test cases with synthetic data generated using the finite element method (FEM). Our results show that we are able to recover the true source distribution accurately even if only few measurements are available. Furthermore, we compare our method against state-of-the-art algorithms and find that our approach outperforms them significantly when the number of measurement locations is small. Finally, we apply our method to real-world data obtained during a field experiment at the University of Houston s Space Research Center. This dataset consists of temperature measurements taken inside a building after a fire was started near one of its walls.",
        "watermark_text": "We introduce an algorithm for the statistical flow inversion problem that is based on variational Bayesian inference and using Gaussian functions to model the forward operator . The proposed approach allows us to obtain posterior distributions over the unseen source parameters , which can be used as prior information in later inverse problems or risk quantification experiments .We suggest our approach by using it to two different test situations with artificial results derived using the finite element method ( FEM ) . Our results show that we are able to extract the true source distribution accurately even if only few measurements are available .Furthermore , we compare our technique against state - of - the - art algorithms and find that our approach outperforms them significantly when the proportion of measurement locations is tiny . Finally , we apply our technique to real - time measurements obtained during a field test at the University of Houston s Space Research Center .This dataset contains of temperature measurements taken inside a building after a fire was opened near one of its walls .",
        "ori-fast-z-score": 1.3251783128981585,
        "water-fast-z-score": 7.134676899329873
    },
    {
        "original_text": "We consider the scalar field theory on a noncommutative (NC) background with spherical symmetry and derive the NC generalization of the Klein-Gordon equation for such fields. We show that this equation can be written as an infinite set of coupled ordinary differential equations, which are equivalent to each other under certain conditions. The solutions of these equations describe different types of waves propagating along geodesics in the NC geometry. In particular we find exact solutions describing massless particles moving at the speed of light. These results may have important implications for quantum gravity phenomenology. Introduction -The idea that spacetime coordinates do not commute is one of the most intriguing concepts emerging from recent developments in string/M-theory  1  . It has been shown  2  , however, that if one considers only classical physics then it is impossible to construct a consistent model based on this concept because of the presence of ultraviolet divergences. This problem was solved by Snyder  3  who introduced a new type of coordinate transformations leading to a deformed Poincaré algebra  4  .\nIn order to study physical effects associated with the existence of a minimal length scale in nature, several authors considered various models where the commutator between two spatial coordinates  x i , x j   = ıθ ij depends on some parameters θ ij  5  . Such deformations lead to modifications of the standard dispersion relations  6  and also affect the propagation properties of matter fields  7, 8  . For example, it has recently been suggested  9  that the introduction of a minimal length scale into the description of gravitational interactions could resolve the black hole information paradox  10  . Another interesting possibility is related to the fact that the deformation parameter θ ij can be chosen so that its magnitude decreases rapidly when the distance r increases  11  . As a result, the effect of noncommutativity becomes negligible outside a small region around the origin  12  . Thus, it seems reasonable to assume that the noncommutativity of space affects only local phenomena while leaving global ones unchanged  13  .",
        "watermark_text": "We consider the scalar field theory on a noncommutative ( NC ) background with spherical symmetry and derive the NC generalization of the Klein - Gordon equation for such fields . We see that this equation can be written as an endless group of coupled ordinary differential coefficients , which are analogous to each other under certain conditions .The solutions of these equations describe varying kinds of waves propagating along geodesics in the NC geometry . In particular we find detailed solutions expressing massless molecules moving at the speed of light .These data may have important implications for quantum gravitational phenomenology . Introduction - The idea that spacetime directions do not commute is one of the most exciting concepts emerging from recent developments in string / M - theory 1 .It has been shown 2 , however , that if one uses only classical physics then it is unable to build a consistent model based on this concept because of the presence of ultraviolet divergences . This problem was solved by Snyder 3 who proposed a new kind of coordinate transformations giving to a deformed Poincaré algebra 4 .In order to study physical effects involved with the existence of a reduced long scale in nature , various authors considered many theories where the commutator between two spatial coordinates x i , x j = ıθ ij depends on some parameters θ ij 5 . Such deformations result to modifications of the standard dispersion relations 6 and also affect the propagation properties of matter spheres 7 , 8 .For instance , it has recently been proposed 9 that the introduction of a reduced distance scale into the description of gravitational interactions might resolve the dark hole information paradox 10 . Another important suggestion is related to the fact that the deformation vector θ ij can be chosen so that its magnitude decreases quickly when the distance r rises 11 .As a result , the impact of noncommutativity appears negligible outside a small area around the origin 12 . Thus , it appears justified to assume that the noncommutativity of space impacts only local phenomena while leaving international ones untouched 13 .",
        "ori-fast-z-score": 1.212678125181665,
        "water-fast-z-score": 8.327056459580765
    },
    {
        "original_text": "We report on observations made in March and April 2002 at 345 GHz using the Atacama Submillimiter Telescope Experiment (ASTE). We detected no significant emission associated with the host galaxy of the gamma-ray burst GRB 980425, which was discovered by BeppoSAX on Apr. 25, 1998 . The 3 sigma upper limit to the flux density is < 0.5 Jy beam-1 , corresponding to an integrated line intensity ICO< 1 x 10^9 K km s^-1 pc^2 or Mgas < 2 x 10^8 Msun .\nThe non-detection suggests that either the molecular gas mass is much lower than previously estimated or that it has been destroyed by the intense UV radiation field produced during the burst.  These results are consistent with those obtained recently by other groups who have searched for CO emission from this source. If our result can be confirmed then it will provide important constraints on models of the formation of massive stars.",
        "watermark_text": "We report on observations made in March and April 2002 at 345 GHz use the Atacama Submillimiter Telescope Experiment ( ASTE ) . We observed no major radiation associated with the target galaxy of the gamma - ray burst GRB 980425 , which was discovered by BeppoSAX on Apr .25 , 1998 . The 3 sigma higher limit to the flux concentration is < 0 . 5 Jy beam - 1 , equivalent to an integrated line intensity ICO < 1 x 10 ^ 9 K km s ^ - 1 pc ^ 2 or Mgas < 2 x 10 ^ 8 Msun .The non - discovery suggests that either the molecular gas mass is much lower than previously predicted or that it has been destroyed by the strong UV rays field produced during the explosion . These data are compatible with those acquired previously by other groups who have searched for CO radiation from this source .If our outcome can be verified then it will provide important restrictions on estimates of the formation of large stars .",
        "ori-fast-z-score": -1.9867985355975657,
        "water-fast-z-score": 4.106050306901635
    },
    {
        "original_text": "The MiniBooNE experiment has recently reported the observation of an excess in electron-neutrino-like events at low energies, which could be explained by sterile neutrinos with mass around 1 eV and mixing angle sin2(2θ) ~ 0.1. \n \n In this work we study how these results can be accommodated within the framework of three-flavor leptonic mixing using the latest global fits to experimental data on neutrino oscillation parameters as well as cosmological constraints on the sum of active neutrino masses. We find that the allowed parameter space is strongly constrained if one assumes that the observed excess corresponds to true neutrino oscillations into sterile states rather than being due to background systematics or statistical fluctuations. The best-fit values for the sterile neutrino mass splitting are found to be Δm32 = (0.5 - 2.3) meV and Δm2 = (0.4 - 3.6) meV, while the corresponding ranges for the mixing angles are θ23 = 42° - 50° , θ13 < 5° and θ12 > 40° .",
        "watermark_text": "The MiniBooNE experiment has recently noted the observation of an increase in electron - neutrino - like phenomena at low energies , which could be described by sterile neutrinos with mass around 1 eV and mixing angle sin2 ( 2θ ) ~ 0 . 1 . In this research we study how these results can be accommodated within the framework of three - flavor leptonic mixing using the latest global fits to experimental evidence on neutrino oscillation components as well as cosmological limitations on the sum of active neutrino masses .We see that the allowed parameter space is strongly constrained if one assumes that the reported amount corresponds to genuine neutrino oscillations into sterile states instead than being owing to background systematics or statistical fluctuations . The best - fitting values for the sterile neutrino mass separation are found to be Δm32 = ( 0 . 5 - 2 . 3 ) meV and Δm2 = ( 0 . 4 - 3 . 6 ) meV , while the equivalent ranges for the blending angles are θ23 = 42° - 50° , θ13 < 5° and θ12 > 40° .",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 4.106050306901635
    },
    {
        "original_text": "The electronic structure, the equilibrium geometry and the finite-temperature properties are investigated for sodium clusters with 39 to 55 atoms by using density functional theory within generalized gradient approximation. The results show that the ground state is always in C_sv symmetry except for Na_55 which has D_5h symmetry as its lowest energy configuration. For all these clusters, we find that there exists an odd-even effect on their structural parameters such as bond length, bond angle and dihedral angle. We also investigate the vibrational frequencies and infrared intensities of these clusters at room temperature. It turns out that the calculated values agree well with those obtained experimentally. Finally, we study the thermodynamic stability of these clusters. Our calculations indicate that most of them have high melting temperatures but some of them may be unstable against dissociation into smaller fragments. \n \n Keywords: Sodium cluster, Electronic structure, Vibrational frequency, Infrared intensity",
        "watermark_text": "The electronic structure , the equilibrium geometry and the finite - temperature properties are investigated for sodium clusters with 39 to 55 atoms by using density functional theory within generalized gradient approximation . The results show that the ground state is usually in C _ sv symmetry except for Na _ 55 which has D _ 5h symmetry as its lowest energy configuration .For all these complexes , we find that there exists an odd - even effect on their structural values such as bond length , bond angle and dihedral angle . We additionally probe the vibrational speeds and infrared intensities of these complexes at room temperature .It turns out that the derived values comply perfectly with those achieved experimentally . Finally , we study the thermodynamic stability of these complexes .Our calculations suggest that most of them have high cooling conditions but some of them may be unstable against dissociation into tiny pieces . Keywords : Sodium cluster , Electronic structure , Vibrational rate , Infrared intensity",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.3466401061363023
    },
    {
        "original_text": "We study the effects of selection biases in cluster samples, as well as covariance between observables, on scaling relations derived from X-ray data using mock galaxy clusters generated with the semi-analytic model GALFORM. We find that both these effects can lead to significant systematic errors when deriving cosmological constraints from observed scaling relations. In particular we show that: (i) The scatter in the M-T relation is significantly reduced by including additional information about the temperature distribution function; this effect is stronger for low mass systems. (ii) The slope of the L-M relation depends strongly on whether or not one includes cooling flows in the analysis. This dependence arises because cool cores are more common at high masses than at lower masses, leading to an apparent steepening of the slope if they are excluded. (iii) The normalization of the Y-Xray luminosity-temperature relation shows strong redshift evolution which cannot be explained solely by self-similar evolution.",
        "watermark_text": "We research the effects of selection biases in cluster specimens , as well as covariance between observables , on scaling relations derived from X - ray data utilizing simulated galaxy galaxies produced with the semi - analytic model GALFORM . We see that both these influences can lead to significant systematic errors when deriving cosmological limitations from observed scaling relations .In particular we prove that : ( i ) The scatter in the M - T relation is significantly reduced by including extra data about the temperature distribution function ; this effect is strengthened for low mass systems . ( ii ) The slope of the L - M relation depends strongly on whether or not one includes heating flows in the evaluation .This dependence occurs because cool cores are more common at high masses than at lower masses , leading to an apparent steepening of the slope if they are ignored . ( iii ) The normalization of the Y - Xray luminosity - temperature relation shows deep redshift development which cannot be described solely by self - similar development .",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 4.564604740649092
    },
    {
        "original_text": "We present new measurements of the mean and scatter in the velocity dispersion-optical richness relation (VRR) for galaxy clusters selected by their red-sequence galaxies using data from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7). We use two different methods to measure cluster velocities, one based on spectroscopic observations of member galaxies and another that uses photometric redshift estimates of all galaxies within a fixed aperture centered on each cluster s brightest cluster galaxy (BGG).\nThe results are consistent with previous studies at low-redshift but show significant differences when compared to recent work done at higher redshifts. The discrepancies between our results and those presented in earlier works may be due to systematic effects associated with the measurement techniques used or could indicate evolution in the VRR over time. In either case, these results highlight the need for further investigation into this relationship as well as other scaling relations involving galaxy clusters. \n \n Keywords: galaxy cluster, optical richness",
        "watermark_text": "We create additional measurements of the mean and scatter in the velocity dispersion - optical richness relation ( VRR ) for galaxy galaxies designated by their red - sequence galaxies using data from the Sloan Digital Sky Survey Data Release 7 ( SDSS DR7 ) . We use two different methods to measure cluster velocities , one based on spectroscopic observations of member galaxies and another that using photometric redshift estimates of all galaxies within a fixed aperture concentrated on each cluster s brightest cluster galaxy ( BGG ) .The results are compatible with previous research at low - redshift but demonstrate considerable variations when compared to recent work done at higher redshifts . The discrepancies between our findings and those offered in earlier works might be due to systematic effects involved with the measurement methods used or could indicate evolution in the VRR over time .In either case , these results emphasize the necessity for further investigation into this relationship as well as other scaling connections involving galaxy regions . Keywords : galaxy region , optical richness",
        "ori-fast-z-score": 1.835325870964494,
        "water-fast-z-score": 7.111887749987414
    },
    {
        "original_text": "The conformational space available to the side chains in proteins can be explored using molecular dynamics (MD) simulations, but this approach requires extensive computational resources for large systems. We have developed an alternative method that uses normal mode analysis (NMA), which has been shown previously to provide accurate predictions of protein motions at low computational cost.  In our new method we use NMA to calculate the free energy landscape associated with each side chain rotation angle. The resulting landscapes are then used as input into a statistical mechanical model that predicts the equilibrium distribution of rotamers observed experimentally. This method was tested on two small proteins containing multiple proline residues, where it correctly predicted the relative population of different rotameric states. It also accurately reproduced experimental results obtained by nuclear magnetic resonance spectroscopy (NMR). Finally, we applied this method to study the effect of mutations on the rotamer distributions of several amino acids. Our results show how changes in the local environment affect the rotamer preferences of these residues.",
        "watermark_text": "The conformational area available to the side groups in proteins can be investigated using molecular mechanics ( MD ) simulations , but this methodology demands vast computational resources for large systems . We have developed an additional method that using normal mode assessment ( NMA ) , which has been shown previously to provide accurate calculations of gene movements at low numerical cost .In our new method we utilize NMA to estimate the free energy landscape attributed with each side chain rotation angle . The resulting ecosystems are then used as input into a statistical mechanical model that predicts the equilibrium distribution of rotamers observed experimentally .This method was tested on two small proteins containing several proline proteins , where it correctly forecast the relative population of different rotameric states . It also accurately reproduced experimental results derived by nuclear magnetic resonance spectroscopy ( NMR ) .Finally , we applied this technology to study the impact of mutations on the rotamer distributions of several amino acids . Our results show how variations in the local ecosystem affect the rotamer preferences of these acids .",
        "ori-fast-z-score": 0.41256849850351734,
        "water-fast-z-score": 6.25846794771944
    },
    {
        "original_text": "We present an approach to the assimilation of magnetic field observations into numerical models using variational methods. The method is applied to a simple model problem in which we consider the evolution of a single component of the magnetic vector potential in a two-dimensional domain with periodic boundary conditions. We use this example as a testbed to explore how different choices of observation operator affect the quality of the resulting analysis fields. In particular, we compare results obtained by applying our algorithm directly on the state variable (the magnetic vector potential) against those obtained when it is first projected onto a set of basis functions that are chosen to be optimal for representing the solution at each time step. Our experiments show that both approaches yield similar results but that the latter can lead to significant computational savings. Finally, we demonstrate the utility of our approach by performing a series of twin experiments in which synthetic magnetometer measurements are used to update the initial condition of the simulation.",
        "watermark_text": "We present an approach to the assimilation of magnetic field observations into numerical models using variational techniques . The method is applied to a simple simulation problem in which we study the evolution of a single part of the magnetic vector potential in a two - dimensional domain with periodic boundary constraints .We use this example as a testbed to examine how various choosing of observation operator impact the performance of the resulting assessment fields . In particular , we compare findings obtained by using our technique directly on the state variable ( the magnetic vector potential ) against those achieved when it is initially projected onto a setting of basis functions that are chosen to be appropriate for describing the solution at each time step .Our experiments show that both approaches yield similar results but that the latter can lead to significant computational savings . Finally , we prove the utility of our approach by performing a sequence of twin tests in which synthetic magnetometer measurements are applied to modify the early condition of the model .",
        "ori-fast-z-score": -0.8528028654224417,
        "water-fast-z-score": 5.330017908890261
    },
    {
        "original_text": "We present new optical spectroscopic observations and archival X-ray data for the Seyfert 1 galaxy NGC 3783, which show that its nuclear activity is dominated by an obscured AGN with a luminosity of ~10^43 erg/s (2-10 keV). The observed spectral energy distribution suggests that this source has been undergoing rapid changes between two distinct states over the past decade or so; one where it appears to be radiating at close to Eddington limit and another where it is much fainter but still highly luminous. We argue that these variations are likely driven by fluctuations in the mass inflow rate onto the central black hole. This interpretation is supported by our analysis of the time delays between different emission lines as well as their line widths. In particular we find that the Hβ emission line lags behind other lines such as He ii λ4686Å and C iv λ1549Å by upto several hundred days during periods when the source was brightest.",
        "watermark_text": "We present new optical spectroscopic observations and archival X - ray data for the Seyfert 1 galaxy NGC 3783 , which show that its radioactive action is dominated by an obscured AGN with a luminosity of ~ 10 ^ 43 erg / s ( 2 - 10 keV ) . The observed spectral power distribution indicates that this source has been experiencing rapid variations between two separate states over the previous decade or so ; one where it appears to be pulsing at close to Eddington limit and another where it is much fainter but still strongly luminous .We argue that these changes are likely due by fluctuations in the mass inflow rate onto the central black hole . This interpretation is backed by our analysis of the period delays between various emission lines as also as their path widths .In particular we find that the Hβ emission band lags behind other lines such as He ii λ4686Å and C iv λ1549Å by upto many hundred days during periods when the source was brightest .",
        "ori-fast-z-score": -1.1523319193960637,
        "water-fast-z-score": 4.318004318006477
    },
    {
        "original_text": "We report the observation of measurement-induced dephasing in a Bose-Einstein condensate (BEC) using Ramsey interferometry and atom counting.  The experiment is performed by splitting a single trapped BEC into two spatially separated clouds, which are allowed to evolve for different times before being recombined on a beam splitter. We observe that the visibility of interference fringes decreases as we increase the number of atoms counted at one output port of the beam splitter. This effect can be explained by considering how repeated measurements affect the phase evolution of the system. Our results demonstrate that it is possible to use cold-atom experiments to study fundamental questions about quantum mechanics. Quantum mechanics predicts that any attempt to measure a physical quantity will disturb its value. In this work, we experimentally investigate such effects in a Bose-Einsteint Condensate (BEC). To do so, we perform Ramsey interferometry between two spatially separated regions of our sample. By varying the time spent evolving freely after splitting off part of the initial cloud, we control the relative phase accumulated during free evolution. After recombination, we count the number of atoms arriving at each output port of the beam-splitter and record their arrival-time distribution. As expected, we find that the visibility of the resulting interference pattern decreases when increasing the number of detected particles.",
        "watermark_text": "We report the observation of measurement - caused dephasing in a Bose - Einstein condensate ( BEC ) using Ramsey interferometry and electron searching . The observation is conducted by breaking a single trapped BEC into two spatially separated clouds , which are allowed to evolve for different times before being recombined on a laser splitter .We see that the visibility of interference fringes decreases as we increase the number of atoms counted at one output port of the light splitter . This phenomenon can be described by examining how repetitive measurements alter the phase evolution of the system .Our results show that it is easy to use cold - atom experiments to study essential problems about quantum mechanics . Quantum theory predicts that any attempt to measure a physical quantity will interrupt its value .In this research , we experimentally examine such interactions in a Bose - Einsteint Condensate ( BEC ) . To do so , we perform Ramsey interferometry between two spatially separated regions of our sample .By varying the period spending expanding freely after splitting off part of the first cloud , we control the relative phase accumulated during free evolution . After recombination , we list the quantity of atoms arriving at each output port of the laser - splitter and record their arrival - time distribution .As expected , we find that the visibility of the resulting interference pattern decreases when increasing the proportion of identified particles .",
        "ori-fast-z-score": 0.6897304947150052,
        "water-fast-z-score": 6.404640308067906
    },
    {
        "original_text": "We prove that the transitive powers of the so-called ``Young-Jucys-Murphy  (YJM) elements in any finite group G form an abelian subgroup of G, which is central if and only if G has no non-trivial normal subgroups. The YJM elements were introduced by Jucys and Murphy as generators for the center of the symmetric group S_n. We use this result to give a new proof of the fact that the center of the wreath product H ≀ S_n equals the direct sum of the centers of H and S_n. This also yields a simple proof of the fact that every element in the center of a finite group can be written as a linear combination of commutators with coefficients ±1. \nIntroduction\n\nLet G be a finite group. In their seminal work on the representation theory of the symmetric groups  Juc77  , Jucys and Murphy defined certain elements in the center Z(S_n) of the symmetric group S_n$ over the field F_q . These elements have been studied extensively since then; see e.g.   BW03,  BW04,   BZ08,   ?   .\nIn particular, it was shown in  BW03   that these elements generate all of the center of S_n when n > 2 or q = p^r where r > 1.   It follows immediately from this theorem that the center of S_n contains at least one noncentral element whenever n < 4 or q = p^1 .  However, it remained open whether there exist other examples of finite groups whose center does not contain any noncentral elements besides those already known such as cyclic groups, dihedral groups, alternating groups etc. . \nThe main goal of our present article is to answer this question affirmatively by proving the following result:",
        "watermark_text": "We prove that the transitive powers of the so - called ` ` Young - Jucys - Murphy ( YJM ) elements in any finite group G constitute an abelian subgroup of G , which is central if and only if G has no non - trivial normal subgroups . The YJM elements were introduced by Jucys and Murphy as generators for the center of the symmetric group S _ n .We use this result to give a new proof of the fact that the center of the wreath product H [UNK] S _ n represents the direct sum of the centers of H and S _ n . This also yields a simple proof of the fact that every element in the center of a finite group can be written as a linear combination of commutators with coefficients ±1 .Introduction Let G be a finite group . In their seminal study on the representation theory of the symmetric groups Juc77 , Jucys and Murphy defined certain elements in the center Z ( S _ n ) of the symmetric group S _ n $ over the field F _ q .These components have been studied frequently since then ; seeing e . g . BW03 , BW04 , BZ08 , ?. In particular , it was shown in BW03 that these elements generate all of the center of S _ n when n > 2 or p = p ^ q where p > 1 .It follows instantly from this theorem that the center of S _ n contains at least one noncentral element whenever n < 4 or p = p ^ 1 . However , it remained open whether there remain other instances of finite groups whose center does not include any noncentral groups besides those already established such as cyclic groups , dihedral groups , alternating groups etc .. The main goal of our present paragraph is to approach this question affirmatively by proving the following result :",
        "ori-fast-z-score": 0.8320502943378436,
        "water-fast-z-score": 4.345151537097628
    },
    {
        "original_text": "We present new near-infrared observations and analysis of the super star cluster (SSC) in the interacting galaxy pair NGC 1705, which is located at a distance of ~10 Mpc. The SSC has an age of ~30 Myr and contains several thousand massive stars with masses >20M☉ . We find that it exhibits many properties similar to those observed for young stellar clusters associated with gamma-ray bursts (GRBs). In particular, we detect a bright Wolf-Rayet population as well as evidence for ongoing mass loss via winds driven by evolved red supergiants. These results suggest that this system may be a local analogue to GRB progenitors. This work was supported by NASA grant NNX11AI18G issued through the Astrophysics Data Analysis Program. The authors wish to recognize and acknowledge the very significant cultural role and reverence that the summit of Mauna Kea has always had within the indigenous Hawaiian community. We are most fortunate to have the opportunity to conduct observations from this mountain.",
        "watermark_text": "We present new near - infrared observations and investigation of the super galaxy cluster ( SSC ) in the interacting galaxy pair NGC 1705 , which is situated at a distance of ~ 10 Mpc . The SSC has an age of ~ 30 Myr and hosts several thousand massive galaxies with masses > 20M☉ .We see that it displays many properties similar to those observed for young stellar clusters identified with gamma - ray clusters ( GRBs ) . In particular , we find a bright Wolf - Rayet population as well as proof for ongoing mass loss via winds driven by evolved red supergiants .These data suggest that this scheme may be a local precursor to GRB progenitors . This research was supported by NASA grant NNX11AI18G submitted through the Astrophysics Data Analysis Program .The authors wish to acknowledge and appreciate the very significant cultural importance and reverence that the summit of Mauna Kea has always had within the native Hawaiian population . We are most lucky to have the ability to conduct measurements from this mountain .",
        "ori-fast-z-score": -0.35603449745815596,
        "water-fast-z-score": 5.656854249492381
    },
    {
        "original_text": "We study the critical behaviour of irreversible reaction systems with mass-action kinetics in one dimension, using Monte Carlo simulations and mean-field theory. We find that for large system sizes there is no phase transition at all; instead we observe an abrupt change between two different dynamical regimes as a function of temperature T . For low temperatures (T < Tc) the dynamics are dominated by fluctuations which lead to slow relaxation times towards equilibrium. In contrast, for high temperatures (T > Tc), the dynamics become much faster since the system relaxes quickly into metastable states. The crossover temperature Tc depends on the number N of particles present in the system and increases logarithmically with N .\nThe results presented here can be understood within the framework of the recently developed concept of  active matter . Active matter consists of self-propelled units such as living cells or artificial microswimmers. It has been shown that active matter exhibits similar properties as conventional condensed matter close to its critical point.",
        "watermark_text": "We explore the important dynamics of irreversible synthesis systems with mass - action kinetics in one dimension , using Monte Carlo simulations and mean - field theory . We see that for large network types there is no phase shift at all ; instead we study an sudden difference between two different dynamical regimes as a function of temperature T .For lowest temperatures ( T < Tc ) the dynamics are dominated by fluctuations which cause to slow relax rates towards equilibrium . In comparison , for high temperatures ( T > Tc ) , the dynamics become considerably faster since the system relaxes quickly into metastable levels .The crossover temperature Tc depends on the number N of atoms existing in the system and varies logarithmically with N . The results presented here can be understood within the framework of the recently established concept of active material .Active material consists of self - propelled units such as living cells or artificial microswimmers . It has been shown that active material exhibits similar characteristics as conventional condensed matter close to its critical position .",
        "ori-fast-z-score": -1.5652475842498528,
        "water-fast-z-score": 4.555555555555555
    },
    {
        "original_text": "The rapid development in the field of intelligent transportation systems (ITS) has led to an increasing demand on wireless communications, which is expected to be fulfilled by using Code Division Multiple Access (CDMA). In this paper we present a novel CDMA-based ITS system that can provide high data rate and low latency services with improved security features compared to existing technologies such as Global Positioning Systems (GPS), Wireless Local Area Networks (WLANs), Bluetooth or ZigBee. The proposed system consists of three main components; namely, roadside units (RSUs), mobile vehicles equipped with on-board units (OBUs) and central servers located at traffic control centers (TCCs).\nWe first introduce the basic concepts behind the proposed system followed by describing its key characteristics. Then, we discuss some important issues related to the design of the proposed system including channel modeling, resource allocation algorithms, power consumption analysis and performance evaluation. Finally, simulation results are presented to demonstrate the effectiveness of our proposed system.",
        "watermark_text": "The rapid progress in the field of intelligent transportation devices ( ITS ) has led to an increasing demand on wireless communications , which is expected to be satisfied by using Code Division Multiple Access ( CDMA ) . In this paper we present a new CDMA - based ITS technology that can provide high data rate and low latency services with improved security features relative to existing technologies such as Global Positioning Systems ( GPS ) , Wireless Local Area Networks ( WLANs ) , Bluetooth or ZigBee .The proposed system contains of three principal portions ; namely , roadside centers ( RSUs ) , wireless trucks equipped with on - board units ( OBUs ) and central computers located at road control centers ( TCCs ) . We first introduce the fundamental concepts behind the suggested system followed by describing its essential aspects .Then , we explain some important problems related to the development of the suggested system namely channel modeling , resource sharing algorithms , power consumption evaluation and performance audit . Finally , simulation data are presented to indicate the performance of our proposed system .",
        "ori-fast-z-score": 1.8439088914585775,
        "water-fast-z-score": 7.3326285778338125
    },
    {
        "original_text": "The aim of this article is to present the basic concepts in Riemannian geometry that are needed for understanding the main results presented here.  The first section introduces some notation and definitions used throughout the text.   In particular we define what it means for two points on an n-dimensional manifold M to be close together (in terms of geodesic distance) or far apart.    We also introduce the concept of a local coordinate system at each point p ∈ M which allows us to describe any other point q near p by giving its coordinates with respect to these local charts.   Finally we give a brief description of how one can construct such a coordinate system locally around a given point using parallel transport along curves starting at p.    The second section describes the notion of a vector field X defined over all of M.   This is done by defining a map F : T M → R where T M denotes the tangent bundle of M.   Then we show that if X satisfies certain conditions then there exists a unique smooth function f : M → R such that X = grad(f).   Here grad(f) denotes the gradient of f.   For example, if M is a surface embedded in R3 then X could represent the velocity of a particle moving across M.   If we assume that the particles move according to Newton s laws of motion then the function f would correspond to the potential energy of the system under consideration.   The third section defines the concept of a tensor field as a generalization of vector fields.   Tensor fields allow us to associate several vectors...",
        "watermark_text": "The goal of this page is to provide the fundamental concepts in Riemannian topology that are needed for studying the main results presented here . The first section introduces some terminology and definitions found throughout the text .In particular we define what it means for two points on an n - dimensional manifold M to be close together ( in terms of geodesic length ) or far separated . We additionally introduce the notion of a local coordinate system at each point p ∈ M which allows us to define any other point q near r by giving its coordinates with regard to these local charts .Finally we give a brief description of how one can build such a coordinate system locally around a given point using parallel transport along curves beginning at p . The second chapter explains the notion of a vector field X defined over all of M . This is accomplished by constructing a mapping F : T M → R where T M denotes the tangent bundle of M . Then we prove that if X satisfies certain conditions then there exists a unique smooth function f : M → R such that X = grad ( f ) . Here grad ( f ) denotes the gradient of f . For instance , if M is a surface embedded in R3 then X could represent the velocity of a particle moving across M . If we suppose that the molecules moving according to Newton s rules of movement then the function r would correspond to the potential electricity of the system under consideration .The third chapter explains the idea of a tensor field as a generalization of vector spaces . Tensor varieties allow us to relate several vectors . . .",
        "ori-fast-z-score": -0.1781741612749496,
        "water-fast-z-score": 7.365059028153745
    },
    {
        "original_text": "We consider the problem of approximating an unknown function f in L^2(0,1) by a linear combination of orthonormal polynomials with respect to some weight function w on (0,1). We show that if we choose the weights so as to minimize the error between the approximation and the true solution then this leads to a system of equations which can be solved using spectral methods. The resulting algorithm is shown to have optimal convergence rates under certain conditions. In particular it has been proved recently that if the coefficients of the expansion are chosen optimally then the rate of convergence is O(N^{-2}), where N denotes the number of terms used in the expansion. \nThe main purpose of this thesis was to implement these algorithms numerically and compare their performance against other existing techniques such as Chebyshev expansions or Legendre expansions. This work will also allow us to investigate whether there exist any advantages associated with choosing different types of basis functions when solving differential equations.",
        "watermark_text": "We consider the question of approximating an unknown function f in L ^ 2 ( 0 , 1 ) by a linear mixture of orthonormal polynomials with regard to some weight distribution w on ( 0 , 1 ) . We see that if we choose the weights so as to minimize the error between the approximation and the true answer then this results to a system of equations which can be answered using spectral algorithms .The resulting algorithm is demonstrated to have optimal convergence rates under certain conditions . In particular it has been determined recently that if the coefficients of the expansion are chosen optimally then the frequency of convergence is O ( N ^ { - 2 } ) , where N describes the number of words using in the expansion .The main aim of this dissertation was to execute these algorithms numerically and compare their performance against other existing techniques such as Chebyshev expansions or Legendre expansions . This research will also enable us to examine whether there exist any advantages associated with choosing particular kinds of basis variables when solving differential equations .",
        "ori-fast-z-score": -1.3054598240132387,
        "water-fast-z-score": 4.153735803678487
    },
    {
        "original_text": "We study the complexity of computing permanent polynomials over graphs with bounded treewidth, focusing on two special cases that are relevant to combinatorial optimization problems: (1) Perfect matchings in bipartite graphs, (2) Matricies whose entries can be expressed as linear combinations of perfect matchings in bipartite subgraphs. We show that both these classes have polynomial-time algorithms for evaluating their respective permanent polynomials when restricted to matrices of bounded treewidth. Our results imply new efficient algorithms for several important combinatorial optimization problems such as maximum weight independent set, minimum vertex cover, and weighted matroid intersection. In addition, we give an algorithm for approximating the permanent of any matrix within a factor of O(n^{1/3}), where n is the number of rows or columns of the input matrix. This improves upon the best known approximation ratio of O(n^{2/3}). Finally, we present some open questions related to our work.",
        "watermark_text": "We research the complexity of computing permanent polynomials over graphs with bounded treewidth , concentrating on two particular instances that are applicable to combinatorial algorithms problems : ( 1 ) Perfect matchings in bipartite graphs , ( 2 ) Matricies whose entries can be described as linear pairs of perfect matchings in bipartite subgraphs . We see that both these classes have polynomial - time algorithms for evaluating their respective permanent polynomials when confined to matrices of bounded treewidth .Our results yield modern effective methods for numerous crucial combinatorial algorithms problems such as maximum weight independent setting , minimum vertex cover , and weighted matroid intersection . In addition , we give an algorithm for approximating the permanent of any matrix within a factor of O ( n ^ { 1 / 3 } ) , where n is the number of columns or rows of the input matrix .This improves upon the best known approximation ratio of O ( n ^ { 2 / 3 } ) . Finally , we present some open questions related to our work .",
        "ori-fast-z-score": -0.11867816581938533,
        "water-fast-z-score": 4.153735803678487
    },
    {
        "original_text": "We study the non-equilibrium evolution of an interacting onedimensional Bose gas initially prepared in a coherent state with finite particle number fluctuations and show that it exhibits universal features, which are independent of microscopic details such as interactions or initial conditions. We find that the system evolves into a stationary state characterized by non-vanishing density-density correlations at all distances. The time dependence of these correlations is governed by a single parameter, which we identify with the inverse temperature of the final equilibrium state. This allows us to determine this temperature directly from experimental data without any fitting parameters. Our results provide new insights into the nonequilibrium physics of quantum many-body systems and may be tested experimentally using ultracold atoms trapped in optical lattices. \nI. INTRODUCTORY REMARK\nThe recent development of techniques for trapping and manipulating cold atomic gases has opened up exciting possibilities for studying strongly correlated quantum matter far from thermal equilibrium  1  . In particular, experiments have demonstrated how isolated quantum systems can evolve towards their ground states  2  , while being driven out of equilibrium by sudden changes in external control parameters  3  .\nIn this work, we consider the case where the system is suddenly quenched across a phase transition  4  . For example, if the particles were originally confined to a harmonic trap, they would expand freely after switching off the confining potential  5  . Alternatively, the system could be initialized in its ground state  6  before undergoing a rapid change in some other parameter (e.g., magnetic field)  7, 8  . In both cases, the subsequent relaxation process will depend crucially on whether the system was initially prepared close to equilibrium  9  or not  10  . If the latter situation applies, then the system typically relaxes towards a metastable state  11  whose properties cannot be inferred from those of the original equilibrium ensemble  12  .",
        "watermark_text": "We explore the non - equilibrium evolution of an interacting onedimensional Bose gas initially produced in a coherent state with discrete particle size fluctuations and find that it displays universal features , which are independent of microscopic information such as interactions or initial conditions . We see that the system evolves into a stationary state characterized by non - vanishing density - density correlations at all distances .The period dependence of these correlations is governed by a single parameter , which we identify with the inverse temperature of the finished equilibrium state . This enables us to predict this heat directly from experimental evidence without any fitting factors .Our results bring fresh insights into the nonequilibrium dynamics of quantum several - bodies systems and may be investigated experimentally utilizing ultracold atoms trapped in optical lattices . I .INTRODUCTORY REMARK The rapid progress of techniques for trapping and manipulating cool nuclear gases has opened up interesting possibilities for studying strongly coupled quantum matter far from temperature equilibrium 1 . In particular , researchers have demonstrated how isolated quantum systems can evolve towards their ground positions 2 , while being driven out of equilibrium by sudden variations in external control factors 3 .In this research , we imagine the case where the system is suddenly quenched across a phase transition 4 . For instance , if the molecules were first confined to a harmonic trap , they may expand freely after switching off the confining potential 5 .Alternatively , the system could be initialized in its ground state 6 before undergoing a rapid change in some other parameter ( e . g . , magnetic field ) 7 , 8 . In both cases , the subsequent relaxed process will depend crucially on whether the system was initially developed close to equilibrium 9 or not 10 .If the latter situation applies , then the system typically relaxes towards a metastable state 11 whose characteristics never be inferred from those of the previous equilibrium ensemble 12 .",
        "ori-fast-z-score": -0.8111071056538127,
        "water-fast-z-score": 6.651078266361265
    },
    {
        "original_text": "The development of large space telescopes requires the use of lightweight materials to reduce launch costs and increase telescope performance in orbit. Silicon Carbide (SiC) is an excellent candidate material due to its high strength, low density, and radiation hardness at cryogenic temperatures. However, it has been shown that SiC exhibits significant changes in thermal expansion with temperature which can lead to dimensional instability during cool-downs or warm-ups. This work presents results on the measurement of the coefficient of thermal expansion (CTE) of SiC-100 over a wide range of temperatures using a novel technique based on laser interferometry. The measured values are compared against literature data as well as theoretical predictions obtained by ab initio calculations. It was found that the experimental measurements agree very well with theory within the uncertainty limits. These results will be used to improve the design of future space missions such as JWST and WFIRST-AFTA.",
        "watermark_text": "The construction of large space telescopes demands the using of lightweight materials to reduce rocket expenses and increase telescope performance in orbit . Silicon Carbide ( SiC ) is an excellent candidate material owing to its high strength , low density , and radiation hardness at cryogenic temperatures .However , it has been shown that SiC exhibits significant variations in heat expansion with temperature which can lead to dimensional instability during cool - downs or warm - ups . This research provides findings on the observation of the coefficient of thermal expansion ( CTE ) of SiC - 100 over a broad variety of conditions utilizing a innovative method based on laser interferometry .The measured measures are compared against literature statistics as well as conceptual predictions acquired by ab initio estimates . It was shown that the empirical observations coincide very best with theoretical within the uncertainty constraints .These data will be used to improve the development of potential space missions such as JWST and WFIRST - AFTA .",
        "ori-fast-z-score": -1.3587324409735149,
        "water-fast-z-score": 5.737948294722722
    },
    {
        "original_text": "We study the controllability properties of quantum subsystems that are described by a master equation with Lindblad form. We show how to construct invariant sets for such systems in terms of their generators. These results allow us to prove that certain classes of open quantum systems cannot be controlled using only unitary operations on the system s Hilbert space. Finally we present an algorithm which allows one to determine whether or not a given set is invariant under the dynamics generated by a particular generator. This work was supported by NSF grant PHY-0456628. Quantum mechanics has been successfully applied to many physical phenomena ranging from atomic physics to condensed matter theory. However, it remains unclear what exactly constitutes a quantum mechanical description of reality. One approach towards answering this question involves studying the behavior of closed quantum systems whose states evolve according to Schrödinger equations. Another approach focuses on describing the evolution of open quantum systems where the state of the system interacts continuously with its environment. The latter class of problems can often be formulated as questions about the controllability of quantum dynamical systems. For example, consider the problem of steering the state of a two-level atom between different energy levels using laser pulses.",
        "watermark_text": "We research the controllability properties of quantum subsystems that are explained by a master equation with Lindblad form . We see how to build invariant pairs for such systems in terms of their generators .These results allow us to prove that particular categories of open quantum systems cannot be governed using only unitary operations on the scheme s Hilbert space . Finally we present an algorithm which allows one to find whether or not a given set is invariant under the dynamics generated by a certain generator .This research was supported by NSF grant PHY - 0456628 . Quantum theory has been successfully application to many natural objects including from atomic physics to condensed matter theory .However , it remains unsure what actually constitutes a quantum mechanical explanation of reality . One approach towards answering this question involves studying the dynamics of closed quantum systems whose states evolve according to Schrödinger equations .Another approach focuses on explaining the evolution of open quantum systems where the state of the state interacts continuously with its surroundings . The latter group of problems can often be understood as challenges about the controllability of quantum dynamical systems .For instance , consider the question of steering the state of a two - level atom between various energy levels use laser pulses .",
        "ori-fast-z-score": 1.1547005383792515,
        "water-fast-z-score": 6.543303050815759
    },
    {
        "original_text": "We present the first dual field theory in emergent spacetime, which is derived from a unifying field theory in higher dimensional spacetime. We show that this new dual field theory can be used to describe both quantum and classical physics with one single unified description. This new dual field theory has several advantages over other existing theories such as string/M-theory or loop quantum gravity. First, it provides an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic scale down to macroscopic scale. Second, unlike string/M-theory or LQG, our new dual field theory does not require any extra dimensions beyond those already observed experimentally. Third, we provide a concrete example showing how our new dual field theory works by deriving Einstein s general relativity from our new dual field theory. Finally, we also derive Maxwell s equations from our new dual field... \nIntroduction:-In recent years there have been many attempts to develop a fundamental theory of everything(TOE). String/M-theory  1  , Loop Quantum Gravity  2  are two examples of these efforts. However, despite their successes they still suffer from some problems. For instance, string/M-theory requires extra dimensions  3  while loop quantum gravity suffers from non-renormalizability  4  . These difficulties motivate us to look for alternative approaches towards developing TOEs. Recently, a novel approach called  emergent spacetime  was proposed  5, 6  . According to this approach, space-time emerges from a more fundamental level  7, 8  .\nEmergent spacetime:-The idea behind emergent spacetime is very simple. It states that space-time is not fundamental but rather emerges from a more fundamental entity. To see why this might happen consider the following argument. Imagine you are sitting on your couch watching TV. You will probably say that the world around you looks flat because if you were standing up then you would notice that the ground below you is curved. Now imagine yourself floating above Earth. If you were standing up now then you wouldn t feel like you re standing on a curved surface anymore. Instead you d feel like you re standing on top of a",
        "watermark_text": "We introduce the first dual field model in emergent spacetime , which is developed from a unifying field model in larger dimensional spacetime . We see that this new dual field model can be used to explain both quantum and classical physics with one single unified description .This new dual field model has numerous benefits over other existing models such as string / M - theory or loop quantum gravitational . First , it gives an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic range down to macroscopic scale .Second , unlike string / M - theory or LQG , our new dual field theory does not require any additional dimensions beyond those already detected experimentally . Third , we provide a clear example showing how our new dual field theory works by deriving Einstein s general relativity from our new dual field theory .Finally , we also generate Maxwell s coefficients from our new dual field . . . Introduction : - In recent history there have been many efforts to develop a basic theory of things ( TOE ) . String / M - theory 1 , Loop Quantum Gravity 2 are two examples of these attempts .However , despite their successes they still suffer from some problems . For instance , string / M - theory requires added dimensions 3 while loop quantum gravitational suffers from non - renormalizability 4 .These difficulties motivate us to search for alternative approaches towards developing TOEs . Recently , a new approach called emergent spacetime was suggested 5 , 6 .According to this methodology , space - time arises from a more fundamental level 7 , 8 . Emergent spacetime : - The idea behind emergent spacetime is very simple .It says that space - time is not essential but rather emerges from a more fundamental entity . To see why this might happen think the following argument .Imagine you are sat on your couch watching TV . You will probably say that the world around you looks flat because if you were standing up then you might see that the earth below you is curved .Now imagine yourself rising above Earth . If you were standing up now then you wouldn t felt like you re standing on a curved surface anymore .Instead you d feel like you re standing on top of a",
        "ori-fast-z-score": 0.3892494720807615,
        "water-fast-z-score": 6.538461538461538
    },
    {
        "original_text": "The authors present an experimental method for determining the probability that two photons simultaneously hit pixels in a detector, as well as its spatial resolution. The method is based on measuring correlations between pairs of photons emitted by a source with known angular distribution. It can be used to characterize any type of photon-counting detector (CCD cameras, photomultipliers etc.) without requiring knowledge about their internal structure or electronics. This information may then be used to improve the performance of imaging systems such as telescopes. The results are presented for a silicon-strip detector. They show good agreement with Monte Carlo simulations. DOI: 10.1088/1742-6596/aa5e20\nSpatial resolution and coincidence resolving time measurement of Si strip detectors using single-photon counting technique \nI. INTRODUCTIO N\nIn many applications it is important to know how accurately one can determine the position where a photon hits a detector. For example this information is needed when designing optical instruments like telescopes  1  . In order to measure the spatial resolution of a detector we need to have some reference point against which we compare our measured data  2  .\nOne way to obtain this reference point is to use a light source emitting photons at a well-defined angle relative to the normal direction  3  , see Fig.  1(a) . If the detector has no intrinsic spatial resolution, all detected photons will come from a small area around the center of the detector surface. By scanning the detector over different angles θ, we can find out what fraction of the total number of counts comes from each part of the detector  4  . We call these fractions the response function R(θ) of the detector  5  . Knowing the shape of the response function allows us to calculate the spatial resolution of the detector  6  . However, if there is more than one pixel per unit solid angle, the situation becomes complicated because now several pixels could detect a given photon  7, 8  . To solve this problem we introduce here a new concept -the joint probability P ij that i-th and j-th pixels detect a photon simultaneously  9  . Using this concept together with the response function we",
        "watermark_text": "The authors present an research technique for determining the probability that two photons simultaneously struck pixels in a detector , as well as its spatial resolution . The method is based on measuring correlations between pairs of photons generated by a source with known angular distribution .It can be used to characterize any type of photon - tracking detector ( CCD cameras , photomultipliers etc . ) without using knowledge about their internal structure or electronics .This knowledge might then be used to upgrade the performance of optical applications such as telescopes . The results are presented for a silicon - strip detector .They show good agreement with Monte Carlo simulations . DOI : 10 . 1088 / 1742 - 6596 / aa5e20 Spatial resolution and coincidence resolving time measurement of Si strip detectors using single - photon counting technique I . INTRODUCTIO N In many applications it is important to consider how accurately one can determine the position where a photon hits a detector .For instance this data is required when designing optical equipment like telescopes 1 . In order to measure the spatial resolution of a detector we require to have some reference location against which we compare our measured data 2 .One method to obtain this reference location is to use a light source emitting photons at a better - defined angle relative to the normal direction 3 , see Fig . 1 ( a ) .If the sensor has no intrinsic temporal resolution , all detected photons will coming from a small area around the center of the sensor surface . By scanning the sensor over different angles θ , we can find out what fraction of the total number of counts coming from each portion of the detector 4 .We call these fractions the response function R ( θ ) of the sensor 5 . Understanding the shape of the response function allows us to estimate the spatial resolution of the sensor 6 .However , if there is more than one pixel per unit solid angle , the situation grows difficult because now multiple pixels might detect a given photon 7 , 8 . To solve this situation we approach here a new notion - the joint probability P ij that i - th and j - th pixels detect a photon simultaneously 9 .Using this concept together with the response function we",
        "ori-fast-z-score": 2.2998495985826177,
        "water-fast-z-score": 8.380035799446205
    },
    {
        "original_text": "We have analyzed the shapes of interstellar extinction curves in the infrared through ultraviolet wavelength range using data for more than 100 sight lines with known distances and reddenings, including those obtained by us at Kitt Peak National Observatory (KPNO) and Cerro Tololo Inter-American Observatory (CTIO). We find that all observed extinction curves can be fitted well by a single power law function A(lambda) = lambda -alpha , where alpha is an index ranging between 1.5 to 2.0. This result suggests that there are no significant differences among various types of interstellar dust grains as far as their optical properties are concerned. In addition, we show that the value of alpha correlates strongly with the total-to-selective extinction ratio Rv . These results suggest that the shape of interstellar extinction curve may provide important information on the physical conditions of interstellar matter along individual sight lines. Keywords: Interstellar extinction; Power-law index; Reddening; Dust grain",
        "watermark_text": "We have analyzed the shapes of interstellar extinction lines in the infrared through ultraviolet frequency range utilizing information for more than 100 sight lines with reported distances and reddenings , notably those acquired by us at Kitt Peak National Observatory ( KPNO ) and Cerro Tololo Inter - American Observatory ( CTIO ) . We see that all observed extinction lines can be fit well by a single power law relation A ( lambda ) = lambda - alpha , where alpha is an index ranging between 1 . 5 to 2 . 0 .This result suggests that there are no major changes among various types of interstellar dust grains as long as their optical properties are concerned . In addition , we find that the value of α correlates heavily with the total - to - selective extinction ratio Rv .These data suggest that the form of interstellar extinction curve might give important information on the physical conditions of interstellar matter along individual sight lines . Keywords : Interstellar extinction ; Power - law index ; Reddening ; Dust grain",
        "ori-fast-z-score": 1.0834726777719228,
        "water-fast-z-score": 5.820855000871991
    },
    {
        "original_text": "The book is intended for graduate students in physics and mathematics, as well as researchers working on the foundations of quantum mechanics.  The first part deals with conservation laws (energy-momentum) and generation of physical fields by sources. In particular, it contains an introduction to gauge invariance and its role in modern physics. The second part presents basic principles of field theory. It includes chapters devoted to Lagrangian formalism, quantization rules, Feynman diagrams, renormalization group methods etc. This textbook covers all topics that are usually included into courses on Quantum Field Theory at universities. The text is written in a clear style without using too many mathematical formulas. All necessary definitions and theorems are presented in detail. A large number of examples illustrate various concepts discussed throughout the book. An extensive set of exercises helps readers to understand main ideas behind each chapter. The solutions to most problems can be found in the end of the book.",
        "watermark_text": "The text is intended for graduate studying in science and mathematics , as well as scientists studying on the foundations of quantum mechanics . The first part deals with conservation laws ( power - momentum ) and generation of physical fields by sources .In particular , it contains an outline to gauge invariance and its role in modern physics . The second part provides fundamental principles of field principle .It includes sections devoted to Lagrangian formalism , quantization laws , Feynman diagrams , renormalization group models etc . This book covers all issues that are typically included into courses on Quantum Field Theory at institutions .The text is authored in a clear manner without using too big mathematical formulas . All necessary statements and theorems are presented in detail .A wide score of instances highlight numerous concepts discussed throughout the book . An elaborate series of tests allows users to comprehend main ideas behind each volume .The answer to most problems can be found in the end of the book .",
        "ori-fast-z-score": -0.4364357804719848,
        "water-fast-z-score": 6.764754597315764
    },
    {
        "original_text": "We present new observations of the central region of the nearby Seyfert galaxy NGC 4258, which show that its nuclear disk is warped by an angle of ~20 degrees with respect to the plane of the host galaxy s stellar bulge (see Figure 1 ). The warp has been detected using near-infrared integral field spectroscopy obtained at Gemini Observatory on Mauna Kea, Hawaii. \n \n We also report the detection of significant rotation about the minor axis of this warped structure, as well as evidence for counter-rotation within the innermost few hundred parsecs of the nucleus. These results are consistent with previous studies based on optical data alone. \n \n In addition, we find that the kinematics of the gas in the outer regions of the nuclear disk can be explained if it orbits around the supermassive black hole located at the center of the galaxy under the influence of both gravitational forces and magnetic fields. This result suggests that the observed warps may have their origin in the magneto-rotational instability (MRI) operating in accretion disks surrounding massive black holes. \n \n Finally, we discuss how these findings could help us understand the physics behind the so-called  Bardeen-Petterson effect : i.e., the alignment between the spin axes of the stars and the angular momentum vector of the accreting material onto the central supermassive black hole.",
        "watermark_text": "We present new images of the central region of the nearby Seyfert galaxy NGC 4258 , which show that its nuclear core is warped by an angle of ~ 20 degrees with regard to the plane of the host universe s stellar bulge ( see Figure 1 ) . The warp has been detected using near - infrared inverse field spectroscopy acquired at Gemini Observatory on Mauna Kea , Hawaii .We additionally report the observation of large rotation about the minor axis of this warped structure , as also as data for counter - movement within the innermost few hundred parsecs of the nucleus . These conclusions are compatible with previous research based on optical data alone .In addition , we find that the kinematics of the gas in the exterior areas of the atomic disk can be understood if it orbits around the supermassive black hole located at the center of the galaxy under the effects of both gravity forces and magnetic fields . This result suggests that the seen warps may have their source in the magneto - rotational instability ( MRI ) working in accretion disks surrounding massive blue holes .Finally , we talk how these results could assist us explain the physics behind the so - called Bardeen - Petterson effect : i . e . , the alignment between the spin axes of the stars and the angular velocity tensor of the accreting matter onto the main supermassive black hole .",
        "ori-fast-z-score": -2.4494897427831783,
        "water-fast-z-score": 4.4907311951024935
    },
    {
        "original_text": "We present new near-infrared (NIR) spectroscopy and photometry for HD 97048, an evolved star with a dusty circumstellar environment that is surrounded by a large debris disk. The NIR spectrum shows strong emission lines in H I Paschen series as well as Brackett γ line at 2.166 µm. We also detect CO bandheads around 2.3 µm which are characteristic features of late-type stars. In addition, we find evidence of water vapor absorption bands near 1.4-1.8 µm indicating the presence of warm water vapor in the inner part of the system. \n \n Using our newly obtained data together with archival optical spectra, we have derived physical parameters such as effective temperature T eff = 8200 K, surface gravity log g = 3.9 dex, luminosity L = 4 × 10^6 Lsun, mass M = 5M⊙, radius R = 6R⊙, and age t = 7×10^7 years. These values indicate that this object belongs to the red giant branch phase on its way towards becoming a white dwarf.",
        "watermark_text": "We present new near - infrared ( NIR ) spectroscopy and photometry for HD 97048 , an evolved star with a dusty circumstellar climate that is surrounded by a large debris ring . The NIR spectrum displays strong absorption patterns in H I Paschen series as well as Brackett γ line at 2 . 166 µm .We additionally observe CO bandheads around 2 . 3 µm which are peculiar characteristics of late - class stars . In addition , we find proof of water vapor absorption groups near 1 . 4 - 1 . 8 µm indicating the presence of warm water vapor in the inner part of the system .Using our newly derived measurements coupled with archival optical spectra , we have derived mechanical parameters such as effective heat T eff = 8200 K , surface gravity log f = 3 . 9 dex , luminosity L = 4 × 10 ^ 6 Lsun , mass M = [UNK] , diameter R = [UNK] , and age t = 7×10 ^ 7 years . These values indicate that this body belongs to the red dwarf branch stage on its route towards becoming a white dwarf .",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 3.4874291623145783
    },
    {
        "original_text": "The standard model is the most successful theory in particle physics, but it fails to explain gravity. In this article we present an alternative approach that unifies general relativity with quantum mechanics by using a new concept called  quantum potential energy density  (QPD). We show how QPD can be used as a source for gravitational field equations which are derived from Hamilton s principle of least action. The resulting field equations have solutions similar to those obtained from Einstein s field equations. However, unlike Einstein s field equations, our proposed field equations do not contain any free parameters such as cosmological constant or dark matter. This means that all physical phenomena predicted by these two theories should agree exactly if they are based on the same underlying principles. Finally, we discuss some possible experimental tests of our proposal. The standard model is the most succesful theory in particle physics, however it fails to explain gravity. \n \n In this article we present another approach that unifies general relavity with quantum mechanics by introducing a new concept called “quantum potental energy density”(QPD). \n \n Quantum potential energy density has been introduced previously by several authors  1-5 , but its role was limited only to explaining certain aspects of quantum mechanics like uncertainty relations  6 , tunneling effect  7-9 , wave-particle duality  10-12  etc.. \n \n Here we propose a novel interpretation of QPD where it plays a central role in deriving gravitational field equations. These field equations are then derived from Hamilton’s principle of least action. \n \n Our results suggest that QPD may play a fundamental role in understanding both gravity and quantum mechanics at their deepest level.",
        "watermark_text": "The classic description is the most popular concept in particle theory , but it fails to explain gravity . In this page we present an additional method that unifies general relativity with classical mechanics by using a new definition called quantum potential energy density ( QPD ) .We see how QPD can be used as a source for gravitational field equations which are derived from Hamilton s principle of least action . The resulting field equations have solutions comparable to those generated from Einstein s field equations .However , unlike Einstein s field equations , our proposed field equations do not include any free parameters such as cosmological factor or black material . This implies that all physical phenomena predicted by these two explanations should agree precisely if they are based on the same underlying principles .Finally , we talk some possible experimental tests of our proposal . The conventional hypothesis is the most succesful model in particle theory , however it fails to explain gravity .In this article we present another methodology that unifies general relavity with quantum mechanics by offering a new notion called “ quantum potental energy density ” ( QPD ) . Quantum potential electricity density has been proposed earlier by various literature 1 - 5 , but its significance was confined only to describing particular aspects of quantum mechanics like uncertainty relations 6 , tunneling effect 7 - 9 , wave - particle duality 10 - 12 etc . .Here we develop a new definition of QPD where it takes a central role in deriving gravitational field equations . These field equations are then constructed from Hamilton ’ s principle of least action .Our results propose that QPD would play a basic part in understanding both gravity and quantum mechanics at their deepest level .",
        "ori-fast-z-score": 2.2132669799727465,
        "water-fast-z-score": 8.842595171198449
    },
    {
        "original_text": "We study the possibility that electroweak symmetry breaking is triggered by strong dynamics at an ultraviolet (UV) fixed point, as suggested by gauge-Higgs unification models with warped extra dimensions. We show how this scenario can be realized within the framework of composite Higgs models based on strongly-coupled gauge theories. In particular we consider two different realizations of such scenarios: one where the Higgs arises as a pseudo-Nambu-Goldstone boson associated to spontaneous breaking of approximate global symmetries; another where it emerges as a bound state of new fermions charged under the Standard Model gauge group. The latter case leads to novel signatures for Higgs production through gluon fusion which are potentially observable at future colliders. Finally, we discuss possible implications of these results for cosmology. Gauge-Higgs unification provides a compelling explanation for why the weak scale is so much smaller than any other mass scale in nature  1  . It also offers a natural solution to the hierarchy problem between the Planck and TeV scales  2  , since quantum corrections to the Higgs potential are cut off at the UV scale  3  .\nIn order to realize this idea in practice, however, several challenges must be overcome  4  : i) the Higgs should arise naturally out of some strongly coupled sector; ii) the Higgs couplings to SM particles should agree with experiment; iii) there should exist a mechanism to generate masses for all SM fields without introducing large hierarchies among them. These issues have been addressed recently using the Randall-Sundrum model  5  , where the Higgs field lives on the IR brane while gravity propagates into the bulk  6  -  8  . This setup allows for a calculable description of the Higgs physics  9  , but introduces additional complications due to the presence of Kaluza-Klein gravitons  10  .",
        "watermark_text": "We research the idea that electroweak symmetry breaking is caused by intense dynamics at an ultraviolet ( UV ) fixed point , as suggested by gauge - Higgs unification theory with warped extra dimensions . We see how this situation can be realized within the framework of composite Higgs theories based on highly - coupled gauge physics .In particular we suppose two different realizations of such scenarios : one where the Higgs arises as a quasi - Nambu - Goldstone boson associated to spontaneous breaking of approximate global symmetries ; another where it appears as a bound state of new fermions charged under the Standard Model gauge group . The latter situation leads to novel signatures for Higgs production through gluon fusion which are possibly observable at current colliders .Finally , we explain possible possibilities of these results for cosmology . Gauge - Higgs unification presents a powerful explanation for why the weak scale is so greatly smaller than any other mass scale in nature 1 .It additionally offers a natural solution to the ranking problem between the Planck and TeV scales 2 , since quantum corrections to the Higgs potential are cut off at the UV scale 3 . In order to realize this idea in practice , however , various challenges must be overcome 4 : i ) the Higgs should occur readily out of some strongly coupled sector ; ii ) the Higgs couplings to SM objects should comply with observation ; iii ) there should exist a process to produce masses for all SM fields without eliminating huge hierarchies among them .These issues have been addressed recently utilizing the Randall - Sundrum model 5 , where the Higgs field lives on the IR brane while gravity propagates into the bulk 6 - 8 . This configuration allows for a calculable description of the Higgs physics 9 , but introduces additional difficulties owing to the presence of Kaluza - Klein gravitons 10 .",
        "ori-fast-z-score": -0.2727272727272727,
        "water-fast-z-score": 6.6996452071463715
    },
    {
        "original_text": "We consider the problem of quantizing an arbitrary vector in a Grassmannian manifold to minimize its distortion under a given rate constraint, which is relevant for multi-input-multi-output (MIMO) communications systems employing feedback. We derive upper bounds on the minimum achievable distortion as well as lower bounds on the corresponding optimal rates by using information-theoretic tools such as entropy power inequalities and data processing inequalities. Our results show that the performance gap between these two bounds increases when the dimension of the underlying Grassmannian manifold grows large. Finally, we provide numerical examples illustrating our theoretical findings. The work presented here was supported by NSF Grant CCF-0635035. Multi-input-multi-output communication systems are widely used in wireless networks due to their high spectral efficiency  1  . In this context, it has been shown recently  2  , that the use of limited-rate feedback can significantly improve system performance at low signal-to-noise ratios (SNRs). However, the amount of available feedback resources may be severely constrained in practice  3  .\nIn order to reduce the required feedback overhead while maintaining good performance, one approach consists of exploiting channel state information (CSI), i.e., knowledge about the current fading coefficients, to perform joint encoding across multiple transmit antennas  4  -  6  . This technique, known as spatial multiplexing or beamforming, requires CSI at both transmitter and receiver sides. Since acquiring perfect CSI at the transmitter side through training-based schemes typically involves significant signaling overhead  7  , practical implementations often resort to quantized versions of the true CSI  8 -  10  . Therefore, there exists a trade-off between the accuracy of the transmitted signals and the amount of feedback needed to convey them  11  .\nThe design of efficient transmission strategies over MIMO channels with limited feedback remains an open research area  12  . A number of recent works have focused on characterizing fundamental limits associated with different aspects of MIMO systems operating under various assumptions regarding the availability of CSI  13  -  16  . For example,  17  considers the case where only statistical information about the channel...",
        "watermark_text": "We consider the question of quantizing an arbitrary vector in a Grassmannian manifold to minimize its distortion under a given rate constraint , which is relevant for multi - input - multi - output ( MIMO ) communications systems employing feedback . We derive upper limits on the minimum achievable distortion as well as lower bounds on the associated optimal prices by using data - theoretic techniques such as entropy energy inequalities and information processing inequalities .Our results show that the performance difference between these two limits increases when the dimension of the embedded Grassmannian manifold rises huge . Finally , we provide numerical examples illustrating our theoretical results .The work presented here was supported by NSF Grant CCF - 0635035 . Multi - input - multi - output communication systems are widely used in wireless networks due to their high spectral efficiency 1 .In this sense , it has been shown recently 2 , that the using of restricted - frequency feedback can significantly boost design efficiency at low sound - to - noise ratios ( SNRs ) . However , the quantity of available feedback opportunities would be severely constrained in practice 3 .In order to reduce the necessary feedback overhead while maintaining good efficiency , one method relies of exploiting channel state information ( CSI ) , i . e . , knowledge about the present fading coefficients , to conduct joint encoding across multiple send antennas 4 - 6 . This method , known as spatial multiplexing or beamforming , requires CSI at both antenna and receiver sides .Since obtaining perfect CSI at the broadcasting side through education - based methods typically requires large signaling overhead 7 , practical implementations usually resort to quantized versions of the true CSI 8 - 10 . Therefore , there exists a trade - off between the accuracy of the transmitted signals and the quantity of feedback needed to transport them 11 .The model of effective transmission strategies over MIMO sources with restricted input remains an open research field 12 . A several of recent works have concentrated on characterizing fundamental limits related with various parts of MIMO systems operating under various assumptions regarding the availability of CSI 13 - 16 .For instance , 17 considers the case where only statistical information about the channel . . .",
        "ori-fast-z-score": 0.8944271909999159,
        "water-fast-z-score": 8.944587733233664
    },
    {
        "original_text": "The observed smallness of the vacuum energy density is one of the most puzzling problems in physics today, and it has been suggested that this problem may be solved by considering quantum gravity effects on the vacuum fluctuations.  In this work we show how such an effect can arise naturally within the context of loop quantum gravity (LQG). We consider a model where the gravitational field is quantized using LQG techniques while matter fields are treated classically. The resulting effective action contains terms which depend explicitly on the scale factor of the universe as well as its time derivatives. These terms lead to corrections to the standard Friedmann equations at high energies. Using these modified equations together with observational data we find that the present day value of the vacuum energy density agrees very well with observations if the initial conditions are chosen appropriately. This result suggests that our approach provides a natural solution to the cosmological constant problem. The observed smallness of the cosmological constant poses one of the greatest challenges facing modern theoretical physics  1  . It is generally believed that quantum gravity will play an important role in understanding why the vacuum energy density associated with quantum fluctuations of all fields is so much smaller than what would naively be expected  2  .\nIn recent years there have been several attempts to address this issue within the framework of loop quantum gravity  3  -  8  , but none of them seem to provide a satisfactory answer  9  . In particular, the results obtained in Refs.  6  -  8  do not agree with each other or with current experimental bounds  10  . Here we propose a new mechanism based on ideas developed recently in Ref.  11  . Our starting point is the observation that the Wheeler-DeWitt equation derived from the canonical formulation of general relativity leads to modifications of the usual Schrödinger equation when applied to states describing macroscopic systems  12  . As shown in Ref.  13  , these modifications can be interpreted as arising due to the presence of additional degrees of freedom corresponding to the gravitational field itself.",
        "watermark_text": "The observed smallness of the vacuum energy density is one of the most puzzling difficulties in science today , and it has been proposed that this question could be answered by investigating quantum gravitational influences on the vacuum fluctuations . In this research we explain how such an influence can arise naturally within the context of loop quantum gravitational ( LQG ) .We consider a description where the gravitational field is quantized utilizing LQG techniques while matter forces are treated classically . The resulting effective action contains terms which depend explicitly on the scale factor of the universe as well as its time functions .These terms lead to corrections to the standard Friedmann equations at high energies . Using these modified equations together with observational data we find that the present day value of the vacuum energy density agrees very best with observations if the first terms are chosen properly .This result suggests that our approach offers a natural solution to the cosmological constant problem . The observed smallness of the cosmological constant presents one of the greatest challenges facing current theoretical physics 1 .It is usually thought that quantum gravitational will take an important role in understanding why the vacuum energy density associated with quantum fluctuations of all fields is so even smaller than what would naively be anticipated 2 . In recent history there have been numerous attempts to tackle this question within the framework of loop quantum gravitational 3 - 8 , but none of them seem to provide a adequate answer 9 .In particular , the results derived in Refs . 6 - 8 do not comply with each other or with current experimental bounds 10 .Here we propose a new method using on ideas developed lately in Ref . 11 .Our starting point is the observation that the Wheeler - DeWitt equation derived from the canonical formulation of general relativity leads to modifications of the usual Schrödinger equation when applied to states describing macroscopic systems 12 . As seen in Ref .13 , these alterations can be interpreted as occurring due to the presence of added degrees of freedom corresponding to the gravitational field itself .",
        "ori-fast-z-score": 1.323448205074589,
        "water-fast-z-score": 8.17423891369599
    },
    {
        "original_text": "The polarimetry of Comet Hale-Bopp was studied by the University of Hawaii 2 m telescope (UH2T) and the 1.5 m telescope at Mt. Wilson Observatory in 1997-1998, using broadband filters centered on 0.55 μm, 0.65 μm, 0.85 μm, and 1.25 μm.  The results show that the polarization degree is generally low for all wavelengths except near perihelion when it increases to about 10%-15% with an angle of ~40°-50° counterclockwise relative to solar north pole. This indicates that the dust particles are aligned perpendicularly to the Sun-comet-observer line. We also find that there exists a wavelength dependence of the polarization degree which decreases as the wavelength becomes longer. These observations suggest that the size distribution of the dust grains has a power law index between -3 and -4. In addition, we found that the polarization degree shows no significant variation during the period of our observation.",
        "watermark_text": "The polarimetry of Comet Hale - Bopp was studied by the University of Hawaii 2 m observatory ( UH2T ) and the 1 . 5 m observatory at Mt . Wilson Observatory in 1997 - 1998 , using broadband filters centered on 0 . 55 μm , 0 . 65 μm , 0 . 85 μm , and 1 . 25 μm .The results show that the polarization degree is typically poor for all wavelengths except near perihelion when it rises to about 10 % - 15 % with an angle of ~ 40° - 50° counterclockwise relative to solar west pole . This implies that the dust particles are aligned perpendicularly to the Sun - comet - observer path .We additionally find that there exists a frequency dependence of the polarization degree which drops as the frequency becomes longer . These measurements suggest that the size distribution of the dust grains has a power law index between - 3 and - 4 .In addition , we concluded that the polarization degree exhibits no considerable variation during the period of our experiment .",
        "ori-fast-z-score": 1.1094003924504583,
        "water-fast-z-score": 5.547001962252292
    },
    {
        "original_text": "We consider the capacity region of a multiple-input-multiple-output (MIMO) fading channel in which each transmitter has perfect knowledge of its own instantaneous channel state information and uses a quantized precoding matrix to maximize mutual information between itself and the receiver. We show that, for any given number of transmit antennas at all transmitters, there exists an optimal number of receive antennas such that the sum-capacity is maximized when all receivers have this same number of antennas. This result holds even if the channels are correlated across time or frequency. The optimal number of receive anten-nas increases as more transmit antennas are used by the transmitters. For example, we find that using four transmit antennas results in the highest sum-rate when three receive antennas are employed per user; however, five receive antennas should be used instead if eight transmit antennas are available.",
        "watermark_text": "We consider the capacity area of a multiple - input - multiple - output ( MIMO ) fading signal in which each antenna has good knowledge of its own instantaneous channel state information and using a quantized precoding vector to maximize mutual information between itself and the receiver . We see that , for any certain number of transmit antennas at all transmitters , there exists an appropriate number of receive antennas such that the sum - capacity is maximized when all transmissions have this same amount of antennas .This result holds even if the transmissions are correlated across time or bandwidth . The appropriate number of receive anten - nas increases as more transmit antennas are using by the transmitters .For instance , we find that using four transmit antennas results in the highest sum - efficiency when three receive antennas are employed per user ; however , five send antennas should be used instead if eight send antennas are available .",
        "ori-fast-z-score": -0.762000762001143,
        "water-fast-z-score": 4.318004318006477
    },
    {
        "original_text": "We present the results of an investigation into the spatial distribution and temporal evolution of magnetic field strength in active region plage using high-resolution spectropolarimetric data obtained with Hinode/SOT-SP. We find that, on average, the magnetic field is stronger at higher heights above the solar surface (i.e., closer to the limb) than it is near disk center. The mean unsigned longitudinal magnetic flux density decreases by about 50% between 0.3′′ and 1′′ above the solar surface. This decrease occurs over a range of heliocentric angles where the photospheric plasma β increases significantly. In addition, we find evidence for significant horizontal structuring of the magnetic fields within individual pixels. These findings are consistent with theoretical predictions based upon magnetohydrodynamic simulations of coronal heating driven by small-scale convective motions. Finally, we show how these observations can be used as input parameters for models of chromospheric heating via Alfvén waves generated by resonant absorption.",
        "watermark_text": "We present the conclusion of an research into the spatial distribution and spatial evolution of magnetic force power in active region plage using high - resolution spectropolarimetric evidence derived with Hinode / SOT - SP . We see that , on average , the magnetic force is greater at higher altitudes above the solar surface ( i . e . , farther to the limb ) than it is near disk area .The mean unsigned lateral magnetic flux concentration drops by about 50 % between 0 . 3 ′ ′ and 1 ′ ′ above the solar surface . This decrease occurs over a range of heliocentric angles where the photospheric plasma β changes significantly .In addition , we find proof for significant horizontal structuring of the magnetic waves within individual pixels . These studies are compatible with theoretical estimates based upon magnetohydrodynamic simulations of coronal heating driven by small - scale convective movements .Finally , we give how these observations can be used as input parameters for models of chromospheric heating via Alfvén currents produced by resonant absorption .",
        "ori-fast-z-score": -0.1111111111111111,
        "water-fast-z-score": 5.444444444444445
    },
    {
        "original_text": "We present photoionization models for the heliosheath, which is the region between the termination shock (TS) at ~100 AU and the solar wind termination shock (SWTS). The SWTS is located beyond 1 AU in the solar system s frame but within 0.3 AU in the rest frame of the Sun. We use these models to constrain the boundary conditions of the heliosphere using interstellar neutral hydrogen data obtained with the Lyman-alpha instrument on board the Solar Wind Anisotropy Probe (SWAP), as well as in situ measurements made near Earth during the Voyager 2 mission. Our results show that the TS distance decreases with increasing solar activity; this effect can be explained by an increase in the density of the solar wind plasma. For low solar activity levels we find that the TS distance agrees very well with previous estimates based on observations of energetic particles.",
        "watermark_text": "We use photoionization estimates for the heliosheath , which is the region between the termination shock ( TS ) at ~ 100 AU and the solar wind termination shock ( SWTS ) . The SWTS is situated beyond 1 AU in the solar system s frame but within 0 . 3 AU in the remainder frame of the Sun .We use these models to constrain the boundary parameters of the heliosphere utilizing interstellar neutral hydrogen evidence derived with the Lyman - alpha instrument on board the Solar Wind Anisotropy Probe ( SWAP ) , as well as in situ measurements made near Earth during the Voyager 2 mission . Our results show that the TS distance reduces with rising sun activity ; this effect can be described by an increase in the density of the solar wind plasma .For low solar activity rates we find that the TS distance agrees very best with previous estimates based on observations of energetic particles .",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 2.994344952558949
    },
    {
        "original_text": "We present an approach to extract the underlying physics from large sets of experimental data by using machine learning techniques and statistical analysis. The method is applied on two different examples, namely the measurement of the electrical conductivity in doped semiconductors as well as the determination of the critical temperature Tc for superconductivity in cuprates. In both cases we find that our results are consistent with theoretical predictions. We show how this new technique can be used to identify unknown parameters or even completely new phenomena which cannot be predicted theoretically at all. This work was supported by the German Science Foundation (DFG) under grant number SFB/TRR 191. A central goal of modern science is to understand complex systems such as materials or living organisms through their fundamental building blocks. To achieve this aim it is necessary to develop methods which allow us to analyze huge amounts of experimental data efficiently. Here we propose a novel approach based on machine learning algorithms combined with advanced statistical tools. Our method is demonstrated on two examples: First, we study the dependence of the electrical conductivity on doping concentration in semiconductor compounds. Second, we determine the critical temperature T c for superconductivity in high-temperature cuprate oxides. For both problems we obtain results which agree very well with existing theories. Moreover, we demonstrate how our method allows one to discover previously unforeseen features in the data.",
        "watermark_text": "We present an way to extract the fundamental theory from huge sets of experimental evidence by using computer learning techniques and statistical analysis . The method is applied on two different examples , notably the determination of the electrical conductivity in doped semiconductors as well as the determination of the significant heat Tc for superconductivity in cuprates .In both cases we find that our findings are compatible with theoretical expectations . We see how this new technique can be used to identify unseen conditions or even completely new events which cannot be described theoretically at all .This project was supported by the German Science Foundation ( DFG ) under grant number SFB / TRR 191 . A central goal of modern science is to explain complex systems such as materials or living organisms through their major building frames .To achieve this aim it is required to develop techniques which allow us to analyze huge amounts of research data easily . Here we undertake a innovative method built on machine computing methods coupled with sophisticated statistical tools .Our method is demonstrated on two examples : First , we study the relationship of the electrical conductivity on doping concentration in semiconductor compounds . Second , we determine the significant heat T c for superconductivity in high - temperature cuprate oxides .For both difficulties we obtain results which agree very best with existing ideas . Moreover , we prove how our technique permits one to identify formerly unforeseen features in the information .",
        "ori-fast-z-score": -0.3682298471593294,
        "water-fast-z-score": 7.98489954161323
    },
    {
        "original_text": "The projectile fragmentation of 86Kr at 64MeV/nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a beam intensity of 1nAe. The main results are as follows:  - A total number of about 10000 events have been recorded for this experiment.  - The charge distribution is peaked around Z=40, but shows also a large contribution between 30 and 40 charges units (see fig.1 ). This indicates that the fragments produced by the break-up of 86Kr are not only light particles like neutrons or protons, but contain many intermediate mass fragments too.   - The angular distributions show two peaks corresponding to forward and backward emission respectively (see fig.2 ).  - The energy spectra present a maximum around 10-12 MeV/u which corresponds to the most probable kinetic energy per nucleon of the emitted fragments (see fig.3 ).\n- The isotopic composition of the fragments is shown on figure 4 . It can be seen that there is no significant difference between the fragment production in the forward hemisphere and in the backward one.",
        "watermark_text": "The projectile fragmentation of 86Kr at 64MeV / nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a laser intensity of 1nAe . The main results are as follows : - A total quantity of about 10000 events have been observed for this study .- The charge distribution is peaked around Z = 40 , but shows also a large contribution between 30 and 40 charges units ( view fig . 1 ) . This implies that the fragments produced by the broken - up of 86Kr are not only light particles like neutrons or protons , but contain many intermediate mass pieces too .- The angular distributions show two peaks related to forward and back emission respectively ( see fig . 2 ) . - The energy spectra produce a maximum around 10 - 12 MeV / u which equals to the most likely kinetic power per nucleon of the emitted objects ( see fig . 3 ) .- The isotopic structure of the fragments is displayed on figure 4 . It can be shown that there is no major variation between the fragment production in the front hemisphere and in the backward one .",
        "ori-fast-z-score": -0.3611575592573076,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "In this work, we propose an energy-efficient cooperative transmission scheme for wireless sensor networks (WSNs). The proposed scheme is based on the combination of collaborative beamforming at the source node with cooperative transmission to multiple relay nodes. In particular, by exploiting channel state information (CSI) feedbacks from all the relays, the source can adjust its transmit power level according to the instantaneous CSI so as to maximize the total network lifetime while satisfying certain quality-of-service requirements. We first derive closed-form expressions for the optimal power allocation between the source and each relay under different system settings. Then, using these results, we formulate the problem of maximizing the WSN s lifetime subject to minimum data rate constraints into a convex optimization framework which can be efficiently solved numerically. Finally, simulation results are presented to verify our theoretical analysis and demonstrate that significant performance gains over conventional schemes can be achieved through the use of the proposed approach.",
        "watermark_text": "In this research , we propose an energy - efficient joint propagation scheme for wireless sensor networks ( WSNs ) . The proposed system is based on the combination of collaborative beamforming at the source node with coordinated transmission to multiple relay nodes .In particular , by exploiting channel state information ( CSI ) feedbacks from all the relays , the source can adjust its broadcast capacity level according to the instantaneous CSI so as to maximize the total channel lifetime while fulfilling various quality - of - service standards . We first derive closed - form expressions for the ideal power distribution between the source and each relay under various system settings .Then , using these results , we formulate the question of maximizing the WSN s life due to minimum data rate constraints into a convex optimization framework which can be easily solution numerically . Finally , simulation data are presented to confirm our theoretical analysis and suggest that significant efficiency increases over traditional schemes can be obtained through the using of the suggested approach .",
        "ori-fast-z-score": -0.4364357804719848,
        "water-fast-z-score": 5.7486571321943885
    },
    {
        "original_text": "We propose to use the concept of Maxwell s demon in order to explain how nanodevices can be used for information processing, storage or transmission. We show that this approach is useful because it allows us to understand why some devices are more efficient than others at performing these tasks. In particular we consider two types of nanodevices which have been proposed recently as candidates for quantum computers - spin chains and arrays of coupled cavities. The first type consists of an array of spins arranged on a line with nearest neighbour interactions between them while the second one has a similar structure but instead of spins it contains atoms trapped inside optical cavities. For both cases we calculate their efficiency using the Landauer principle. Finally we discuss possible experimental implementations of our ideas. Introduction:-The idea of Maxwell s demon was introduced by James Clerk Maxwell (1831-1879)  1  . It describes a hypothetical intelligent being who could control microscopic particles individually so that they would always move into separate containers depending on whether each particle had a higher energy level or lower energy level  2  .\nMaxwell s demon is usually described as a thought experiment whose purpose is to demonstrate that entropy cannot decrease spontaneously  3  , i.e., that heat does not flow spontaneously from hot bodies to cold ones  4  . However, there exists another interpretation of Maxwell s demon according to which he imagined a device capable of sorting individual molecules based on their velocities  5  . This interpretation leads naturally to the question about what sort of physical system might behave like such a device  6  .",
        "watermark_text": "We suggest to use the idea of Maxwell s demon in order to explain how nanodevices can be used for information processing , processing or transmission . We suggest that this methodology is beneficial because it allows us to realize why some machines are more efficient than others at performing these tasks .In particular we investigate two forms of nanodevices which have been proposed lately as candidates for quantum computers - spinning chains and arrays of coupled cavities . The first sort consists of an array of spinning grouped on a line with nearest neighbour interactions between them while the second one has a similar composition but instead of spinning it contains atoms trapped inside optical cavities .For both cases we estimate their productivity using the Landauer law . Finally we talk proposed experimental implementations of our concepts .Introduction : - The idea of Maxwell s demon was introduced by James Clerk Maxwell ( 1831 - 1879 ) 1 . It describes a hypothetical intellectual being who might control microscopic particles individually so that they would everyone travel into independent tanks depending on whether each particle had a higher energy level or lesser energy level 2 .Maxwell s creature is usually characterized as a thought experiment whose purpose is to demonstrate that entropy cannot fall spontaneously 3 , i . e . , that heat does not flow spontaneously from hot bodies to hot ones 4 . However , there exists another explanation of Maxwell s demon according to which he imagined a device capable of sorting individual molecules based on their velocities 5 .This interpretation turns naturally to the question about what sort of natural system might perform like such a device 6 .",
        "ori-fast-z-score": 0.09016696346674323,
        "water-fast-z-score": 6.825001477017446
    }
]