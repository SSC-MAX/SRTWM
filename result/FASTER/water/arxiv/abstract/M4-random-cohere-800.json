[
    {
        "original_text": "The D0 and CDF experiments have searched for single-top production in the t-channel, s-channel, and associated Wt channel using data corresponding to an integrated luminosity of 5.4 fb-1 collected by the Fermilab Tevatron Collider between 1992 and 1996.  The results are presented as 95% confidence level upper limits on the cross sections times branching ratios into leptons (electrons or muons) plus jets.  In addition, we present measurements of the top quark mass made with these events. We find no evidence for new physics beyond standard model expectations. These results supersede those previously reported by both collaborations. \nWe thank our colleagues in the CERN accelerator departments for their vital contributions to this work. This research is supported by the U.S. Department of Energy under contract No. DE-AC02-76SF00515. The D0 experiment has also performed searches for single-top quarks produced via the t-channel, s-channnel, and associated Wt channels using 4.3 fb-1 of data taken during Run II of the Fermilab TeVatron collider  1  .",
        "watermark_text": "The D0 and CDF research have searched for single - top activity in the t - channel , s - channel , and related Wt channel using data related to an integrated luminosity of 5 . 4 fb - 1 collected by the Fermilab Tevatron Collider between 1992 and 1996 . The results are presented as 95 % confidence rate upper limits on the cross sections times branching ratios into leptons ( atoms or muons ) plus jets .In addition , we present measurements of the top quark mass made with these events . We see no evidence for new science beyond standard theory expectations .These conclusions supersede those previously reported by both collaborations . We thank our colleagues in the CERN accelerator departments for their vital contributions to this research .This research is backed by the U . S . Department of Energy under contract No . DE - AC02 - 76SF00515 .The D0 study has additionally performed investigations for single - top quarks produced via the t - channel , s - channnel , and related Wt channels using 4 . 3 fb - 1 of evidence gained during Run II of the Fermilab TeVatron collider 1 .",
        "ori-fast-z-score": -0.36650833306891567,
        "water-fast-z-score": 4.031591663758072
    },
    {
        "original_text": "We study the energy transfer in a network of coupled nonlinear oscillators with time delay, which is motivated by the dynamics of biological systems such as neural networks and genetic regulatory networks. We show that there exists an optimal coupling strength for each individual oscillator to achieve maximum energy transfer efficiency among all other oscillators. The results are obtained through numerical simulations on both small-scale and large-scale networks. In particular, we find that the energy transfer efficiency decreases when the number of nodes increases beyond a certain threshold value. This phenomenon can be explained by the fact that the total amount of available energy per node decreases rapidly due to the increase of the number of nodes. Finally, we discuss possible applications of our findings to real-world problems. Energy transfer plays important roles in many natural phenomena including brain activity  1  , heartbeat  2  , and gene regulation  3  . It has been shown recently that efficient energy transfer may also exist in complex networks  4  -  6  .\nIn this work, we consider a system consisting of N identical nonlinear oscillators connected via delayed couplings (see Fig.   1 ). Each oscillator i = 1; 2; ...; N is described bẏ \nwhere x i 2 R n denotes its state vector, f : R n ! R n describes the local dynamics of each oscillator, c ij > 0 represents the coupling strength between two oscillators i and j, and h(t) is the transmission delay satisfying h max < h(t) < h min ; t 0:",
        "watermark_text": "We research the power transfer in a network of coupled nonlinear oscillators with time delay , which is motivated by the dynamics of biological systems such as neural systems and genome regulatory circuits . We see that there exists an appropriate coupling strength for each individual oscillator to achieve maximum energy transfer efficiency among all other oscillators .The results are derived through computational simulations on both small - scale and large - scale networks . In particular , we find that the power transfer efficiency decreases when the number of nodes increases beyond a certain threshold value .This phenomenon can be described by the fact that the total amount of available energy per node decreases quickly due to the increase of the number of nodes . Finally , we explain possible applied of our findings to real - time situations .Energy transfer plays important roles in multiple natural phenomena including brain activity 1 , heartbeat 2 , and gene control 3 . It has been shown lately that efficient energy flow would also exist in complex networks 4 - 6 .In this study , we study a system consisting of N identical nonlinear oscillators related via delayed couplings ( saw Fig . 1 ) .Each oscillator i = 1 ; 2 ; . . . ; N is described [UNK] where x i 2 R n denotes its state vector , f : R n ! R n describes the local dynamics of each oscillator , c ij > 0 represents the coupling strength between two oscillators i and j , and h ( t ) is the transmission delay satisfying h max < h ( t ) < h min ; t 0 :",
        "ori-fast-z-score": -0.5345224838248488,
        "water-fast-z-score": 4.09800570932384
    },
    {
        "original_text": "We study the electronic properties of armchair-edged carbon nanotubes with magnetic flux piercing them, using density functional theory (DFT). We find that for tubes with diameter larger than 1 nm there is no significant difference between the results obtained by DFT and those predicted by the effective-mass approximation. For smaller diameters we observe deviations which are attributed to the breaking of the valley degeneracy due to the curvature effects. The Aharonov-Bohm-effect manifests itself as an oscillatory behavior of the energy gap when varying the applied magnetic field strength. In addition, we show how this effect can be used to tune the bandgap of these structures. Graphene nanorings have been proposed recently as building blocks for novel nanoelectronic devices such as transistors or spintrons  1-3 . These systems exhibit interesting physical phenomena like the quantum Hall effect  4  , persistent currents  5  , and Klein tunneling  6  . Recently it has also been shown that they may serve as efficient single photon sources  7, 8  .\nIn order to understand their transport characteristics one needs to know the dependence of the energy spectrum on various parameters such as the radius R, the number N of hexagons along the circumference, and the external magnetic field B. This problem was addressed theoretically within different approximations  9-13  but only very few studies were performed based on first-principles calculations  14-16 . Here we present a detailed investigation of the influence of the magnetic field on the electronic structure of armchair-edge carbon nanotubes using density functional theory  17  . Our main focus will be on small-diameter tubes where the curvature leads to important modifications compared to large-diameter tubes  18  .",
        "watermark_text": "We research the electronic properties of armchair - edged carbon nanotubes with magnetic flux piercing them , using density functional theory ( DFT ) . We see that for tubes with diameter greater than 1 mm there is no major improvement between the results derived by DFT and those predicted by the effective - weight method .For smaller diameters we perceive deviations which are owing to the breaking of the valley degeneracy owing to the curvature processes . The Aharonov - Bohm - effect manifests itself as an oscillatory behavior of the power gap when varying the introduced magnetic force power .In addition , we show how this effect can be used to balance the bandgap of these structures . Graphene nanorings have been proposed lately as building blocks for novel nanoelectronic elements such as transistors or spintrons 1 - 3 .These systems exhibit exciting physical phenomena like the quantum Hall phenomenon 4 , persistent currents 5 , and Klein tunneling 6 . Recently it has also been shown that they may serve as efficient single photon sources 7 , 8 .In order to comprehend their transport characteristics one needs to knowledge the dependence of the power spectrum on various variables such as the radius R , the number N of hexagons along the circumference , and the external magnetic force B . This problem was resolved theoretically within various approximations 9 - 13 but only very few experiments were performed based on third - principles measurements 14 - 16 .Here we present a detailed investigation of the impact of the magnetic force on the electronic stability of armchair - side carbon nanotubes using density functional theory 17 . Our main attention will be on small - radius tubes where the curvature contributes to significant modifications contrast to large - radius pipes 18 .",
        "ori-fast-z-score": -1.1818181818181819,
        "water-fast-z-score": 6.636363636363637
    },
    {
        "original_text": "We present the results of an optical spectroscopic survey of radio galaxies in clusters at redshifts z=0.4-0.8, carried out with the William Herschel Telescope (WHT). We find that the fraction of AGN-powered radio galaxies decreases towards higher galaxy density environments within the clusters. This is consistent with previous studies which have found evidence for environmental quenching of star formation activity among massive galaxies. However we also find that there are many examples where powerful radio sources reside in dense regions without any obvious signs of being environmentally suppressed. These objects may be undergoing rapid evolution or they could represent a population of recently accreted field galaxies whose properties are still evolving to resemble those of their local counterparts. The sample consists of 20 radio galaxies selected from the VLA-COSMOS 3 GHz Large Project catalogue (Smolčić et al., 2009) using the following criteria: 1) They lie in one of four X-ray luminous clusters at 0.4 < z < 0.8; 2) Their radio luminosity lies above L(3GHz) = 10 25 W Hz-1; 3) They do not show strong emission lines indicative of ongoing nuclear activity; 4) They were observed during our WHT run on 2010 May 24-25.",
        "watermark_text": "We present the conclusion of an optical spectroscopic study of radio stars in clusters at redshifts z = 0 . 4 - 0 . 8 , conducted out with the William Herschel Telescope ( WHT ) . We see that the fraction of AGN - powered radio stars reduces towards higher galaxy concentration environments within the clusters .This is consistent with previous research which have shown evidence for environmental quenching of galaxy formation activity among huge objects . However we also find that there are many instance where powerful radio sources exist in dense areas without any obvious signs of being environmentally suppressed .These bodies may be experiencing rapid evolution or they may contain a population of newly accreted field galaxies whose characteristics are still changing to reflect those of their nearby rivals . The sample consists of 20 radio objects chose from the VLA - COSMOS 3 GHz Large Project catalogue ( Smolčić et al . , 2009 ) applying the following criteria : 1 ) They sit in one of four X - ray luminous clusters at 0 . 4 < z < 0 . 8 ; 2 ) Their radio luminosity sits above L ( 3GHz ) = 10 25 W Hz - 1 ; 3 ) They do not show weak absorption tracks indicative of ongoing nuclear activity ; 4 ) They were detected during our WHT running on 2010 May 24 - 25 .",
        "ori-fast-z-score": -1.1793237883215741,
        "water-fast-z-score": 6.685631938613182
    },
    {
        "original_text": "We present observations of the Mg II k line asymmetry during flares, which are compared with results obtained by numerical simulations using the RH code (Uitenbroek 2001). The observed profiles show that the blue wing is enhanced relative to the red one at all heights above the limb where we can see the flare emission. This effect is more pronounced for higher altitudes. We find that this behavior cannot be explained solely by Doppler shifts due to bulk plasma motions along the LOS. In addition, our modeling shows that the observed profile shapes cannot be reproduced without including nonthermal electron beams as an additional heating source. \n \n Keywords: Solar flare, chromospheric lines, nonthermal electrons, radiative hydrodynamics model, RH code, Mg II k line, line asymmetry. 1 Introduction \n \n During solar flares, intense energy release leads to rapid changes in physical conditions throughout the atmosphere of the Sun. These include temperature increases up to several million degrees Kelvin, strong magnetic fields, high densities, and large velocities. All these factors affect the shape of spectral lines emitted by different atmospheric layers. For example, it has been shown that the intensity ratio between two Fe I lines formed at different temperatures depends on the height of formation of each line (Feldman et al., 1995; Brosius & Phillips 2004) . Also, the presence of nonthermal electrons causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles (e.g., Canfield et al. (1990) ; Doschek et al. (1991) ), while bulk flows lead to Doppler shifts of the line center position (Doschek et al., 1991; Brosius & Phillips 2004; Brosius 2009 ). Therefore, studying the temporal evolution of the line profiles provides important information about the dynamics of the flaring region. However, interpreting such data requires detailed knowledge of the underlying physics involved in the processes responsible for the observed phenomena. \n \n In particular, the study of the Mg II h&k lines offers unique opportunities to investigate various aspects of solar flares because they form over a wide range",
        "watermark_text": "We present observations of the Mg II k line asymmetry during flares , which are compared with data derived by numerical simulations using the RH code ( Uitenbroek 2001 ) . The observed profiles indicate that the blue wing is enhanced compared to the red one at all heights above the limb where we can see the flare emission .This phenomenon is more pronounced for greater altitudes . We see that this behavior cannot be described solely by Doppler variations owing to bulk plasma dynamics along the LOS .In addition , our modeling demonstrates that the seen profile patterns cannot be altered without using nonthermal electron beams as an additional thermal source . Keywords : Solar flare , chromospheric lines , nonthermal atoms , radiative hydrodynamics theory , RH code , Mg II h line , edge asymmetry .1 Introduction During solar flares , intense heat release leads to rapid alterations in physical conditions throughout the atmosphere of the Sun . These include temperature increases up to several million degrees Kelvin , intense magnetic fields , large densities , and large velocities .All these influences influence the morphology of spectral lines emitted by various atmospheric elements . For instance , it has been shown that the frequency proportion between two Fe I lines formed at different temperatures depends on the height of formation of each line ( Feldman et al . , 1995 ; Brosius & Phillips 2004 ) .Also , the presence of nonthermal atoms causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles ( e . g . , Canfield et al . ( 1990 ) ; Doschek et al .( 1991 ) ) , while bulk flows result to Doppler movements of the line center position ( Doschek et al . , 1991 ; Brosius & Phillips 2004 ; Brosius 2009 ) . Therefore , studying the temporal evolution of the line profiles provides crucial data about the dynamics of the flaring zone .However , interpreting such information requires deep knowledge of the fundamental physics involved in the mechanisms involved for the seen phenomena . In particular , the knowledge of the Mg II h & k lines provides unique possibilities to examine different components of sun flares because they shape over a broad range",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.485281374238571
    },
    {
        "original_text": "The purpose of this study is to examine how an organisation can use Information Technology Infrastructure Library (ITIL) as a process optimisation tool within its service centre environment. The research focuses on the release management process at the IT service centre of Harz University and examines whether it complies with all relevant aspects of the ITIL framework. A case study approach was used to collect data through interviews and document analysis. This article presents the results of the investigation into the current state of the release management process at Harz University s IT service centre. It also provides recommendations for improving the process based on the findings. Keywords: information technology infrastructure library, process optimization, release management process, university, IT service centre, case study method. 1 Introduction Today, universities are increasingly relying on their computer systems to support teaching and research activities. As such, they need reliable services that meet user requirements  1  . However, many universities have experienced problems related to poor quality software releases  2  , which may lead to system failures or even loss of data  3  .\nIn order to avoid these issues, organisations should implement appropriate processes  4  . One widely accepted set of guidelines for managing information technology (IT) services is provided by the Information Technology Infrastructure Library  5  . According to  6  , ITIL has been adopted by more than 80% of Fortune 500 companies worldwide since 2003.",
        "watermark_text": "The purpose of this study is to examine how an institution can using Information Technology Infrastructure Library ( ITIL ) as a process optimisation platform within its service centre environment . The studies centers on the release control system at the IT service centre of Harz University and examines whether it complies with all relevant parts of the ITIL framework .A case study method was used to collect data through interviews and report analysis . This page presents the conclusion of the examination into the present state of the release control system at Harz University s IT network centre .It additionally offers suggestions for improving the process depending on the reports . Keywords : info industry infrastructure library , process optimization , release control system , university , IT service centre , case study method .1 Introduction Today , universities are increasingly relying on their computer machines to support education and scientific activities . As such , they seek reliable services that meet user requirements 1 .However , many universities have experienced difficulties related to bad quality code releases 2 , which sometimes lead to system failures or even loss of documentation 3 . In try to minimize these problems , organisations should implement appropriate processes 4 .One widely accepted set of guidelines for controlling information tech ( IT ) services is provided by the Information Technology Infrastructure Library 5 . According to 6 , ITIL has been used by more than 80 % of Fortune 500 companies globally since 2003 .",
        "ori-fast-z-score": 0.27975144247209416,
        "water-fast-z-score": 8.672294716634918
    },
    {
        "original_text": "We report on the detection by Fermi Large Area Telescope (LAT) of prompt emission in gamma rays with energies above 100 MeV associated with GRB 080916C, one of the brightest bursts ever detected at high energy. The LAT data show that this emission is highly variable and peaks within 1 s after the onset of the burst. We find no evidence for spectral evolution during the first few hundred seconds following the trigger time. A simple power law fit to the LAT spectrum yields an index of -2.2 +/-.1 over the range 100 MeV - 10 GeV. This value is consistent with previous measurements made using Konus-Wind and AGILE satellites but differs significantly from those obtained by other instruments operating below 100 MeV. Our results are inconsistent with models which predict a softening of the photon spectrum as it evolves into the X-ray band. They also rule out scenarios where the high-energy photons originate solely from inverse Compton scattering off relativistic electrons accelerated in internal shocks. \n \n Keywords: Gamma-ray burst",
        "watermark_text": "We report on the discovery by Fermi Large Area Telescope ( LAT ) of prompt emission in gamma waves with energies above 100 MeV related with GRB 080916C , one of the brightest bursts ever observed at high energy . The LAT results show that this emission is strongly varied and spikes within 1 s after the beginning of the explosion .We see no evidence for spectral evolution during the first few hundred moments following the trigger time . A straightforward power law suited to the LAT spectrum gives an index of - 2 . 2 + / - . 1 over the range 100 MeV - 10 GeV .This value is compatible with previous measurements made using Konus - Wind and AGILE spacecraft but varies dramatically from those achieved by other satellites operating below 100 MeV . Our results are inconsistent with models which predict a softening of the photon spectrum as it evolves into the X - ray band .They even figure out situations where the high - energy photons arise solely from inverse Compton absorption off relativistic electrons accelerated in internal shocks . Keywords : Gamma - ray burst",
        "ori-fast-z-score": -0.5933908290969266,
        "water-fast-z-score": 5.815230125149881
    },
    {
        "original_text": "The shell-model calculations are performed for the ground states and low-lying excited states in 16,17O nuclei using the effective interaction derived by Brown et al.  The results show that the calculated excitation energies agree well with experimental data except for some cases where the observed levels have large mixing between different configurations. In addition to the energy level scheme, we also calculate electromagnetic transition probabilities among these states. It is found that our calculation reproduces fairly well the measured B(E2) values but underestimates the B(M1) values significantly. This may be due to the fact that the M1 operator used here does not include the spin-orbit term which plays an important role in this case. Finally, we discuss briefly about the possible existence of new collective excitations in 17O nucleus. PACS: 21.10.Ks, 22.60.-n Shell Model Study of Neutron Rich Oxygen Isotopes",
        "watermark_text": "The shell - model calculations are performed for the ground states and low - lying excited states in 16 , 17O ions using the effective interaction derived by Brown et al . The results show that the derived excitation energies agree well with theoretical data except for some cases where the reported amounts have huge mixing between various configurations .In addition to the power level scheme , we also obtain electromagnetic transition probabilities among these states . It is found that our analysis reproduces reasonably well the measured B ( E2 ) values but underestimates the B ( M1 ) values considerably .This might be due to the fact that the M1 operator used here does not include the spin - orbit term which plays an important role in this instance . Finally , we talk briefly about the possible existence of new collective excitations in 17O nucleus .PACS : 21 . 10 . Ks , 22 . 60 . - n Shell Model Study of Neutron Rich Oxygen Isotopes",
        "ori-fast-z-score": 0.7171371656006361,
        "water-fast-z-score": 5.259005881071332
    },
    {
        "original_text": "We present the theory for two-photon interactions in broadband down-converted light, including entanglement between photons generated by spontaneous parametric down conversion (SPDC). We show that this leads to new effects such as photon bunching at zero time delay and antibunching at nonzero delays. These results are compared against experimental data obtained using SPDC sources based on periodically poled lithium niobate waveguides. The theoretical model is also used to predict the effect of varying pump bandwidths and crystal lengths on the degree of second-order coherence g(2)(0) measured experimentally. This work was supported by EPSRC grant EP/G037656/1. \n \n In recent years there has been growing interest in quantum optics experiments involving broadband down-conversion  1–3 . Such experiments have led to demonstrations of novel phenomena such as single-photon switching  4 , sub-Poissonian statistics  5 , squeezing  6 , and nonclassical correlations  7, 8 . However, many aspects of these experiments remain poorly understood due to difficulties associated with modelling the complicated nonlinear processes involved  9, 10 . Here we develop an analytical description of two-photon interactions in broad-band down-converted light which includes both temporal and spatial degrees of freedom  11, 12 . Our approach allows us to calculate the joint spectral intensity distribution of the down-converted field  13 , which can then be used to determine the probability density function describing the arrival times of pairs of photons produced via spontaneous parametric downconversion  14–18 . As well as providing insight into the physics underlying broadband down-conversion experiments, our analysis enables quantitative predictions about the behaviour of such systems to be made.",
        "watermark_text": "We introduce the principle for two - photon interactions in broadband down - converted radiation , particularly entanglement between photons generated by spontaneous parametric down transformation ( SPDC ) . We suggest that this results to novel influences such as photon bunching at zero time time and antibunching at nonzero delays .These conclusions are compared against empirical data acquired using SPDC sources based on periodically poled lithium niobate waveguides . The conceptual theory is also used to predict the impact of differing flow bandwidths and crystal lengths on the degree of second - order coherence k ( 2 ) ( 0 ) measured experimentally .This project was supported by EPSRC award EP / G037656 / 1 . In recent years there has been growing interest in quantum optics tests featuring wireless down - transfer 1 – 3 .Such experiments have led to experiments of new events such as single - photon mixing 4 , sub - Poissonian statistics 5 , squeezing 6 , and nonclassical correlations 7 , 8 . However , many aspects of these experiments exist poorly studied attributed to difficulties linked with modelling the complicated nonlinear processes involved 9 , 10 .Here we develop an analytical explanation of two - photon interactions in wider - band down - converted radiation which includes both temporal and spatial degrees of liberty 11 , 12 . Our solution enables us to estimate the joint spectral intensity distribution of the down - converted field 13 , which can then be used to estimate the probability density function explaining the departure periods of pairs of photons created via spontaneous parametric downconversion 14 – 18 .As well as providing information into the physics underlying wireless down - transfer experiments , our analysis enables numerical assumptions about the behaviour of such systems to be made .",
        "ori-fast-z-score": -1.0690449676496976,
        "water-fast-z-score": 7.247844507162112
    },
    {
        "original_text": "The dielectric properties, phase transition behavior, and microstructure evolution were investigated for the (0.65 Pb(Ni-1/3Nb-2/3)O_3  -0.35PbTiO3) (PNT) ceramics with different sintering temperatures ranging from 850 to 1100 °C. The PNT samples exhibited high permittivity values up to ~10 4 , low loss tangent below 10 -2 , and large tunability over 30% under an electric field strength of 30 kV/cm at room temperature. With decreasing temperature down to 77 K, the permittivity increased slightly while the loss tangent decreased significantly due to the freezing out of mobile ions. At cryogenic temperatures, two relaxation processes were observed in the frequency range between 1 Hz and 100 kHz. The first process was attributed to the grain boundary effect; it shifted towards higher frequencies as the temperature decreased. The second process was associated with ferroelectric domain wall motion; its relaxation time constant remained almost unchanged when the temperature changed.",
        "watermark_text": "The dielectric characteristics , phase change response , and microstructure formation were researched for the ( 0 . 65 Pb ( Ni - 1 / 3Nb - 2 / 3 ) O _ 3 - 0 . 35PbTiO3 ) ( PNT ) ceramics with various sintering temperatures ranging from 850 to 1100 °C . The PNT specimens exhibited high permittivity values up to ~ 10 4 , low loss tangent below 10 - 2 , and large tunability over 30 % under an electric field intensity of 30 kV / cm at room temperature .With decreasing temperature down to 77 K , the permittivity increased somewhat while the loss tangent decreased significantly related to the freezing out of mobile atoms . At cryogenic temperatures , two relaxation processes were detected in the frequency region between 1 Hz and 100 kHz .The first mechanism was due to the grain boundary phenomenon ; it shifted towards higher frequencies as the temperature reduced . The second process was correlated with ferroelectric domain floor motion ; its relaxation time constant remained nearly intact when the temperature changed .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.335783750799325
    },
    {
        "original_text": "Social networks are ubiquitous in our daily life, and have been studied extensively by researchers across many disciplines. However, the analysis of social network data is often challenging due to its complexity. In this work we propose NodeTrix, an efficient hybrid representation that can be used to analyze large-scale social networks efficiently. We show how NodeTrix can be applied to solve several important problems including community detection, link prediction, node classification, and influence maximization. Our experiments on real-world datasets demonstrate that NodeTrix outperforms state-of-the-art approaches significantly both in terms of efficiency and effectiveness. 1 Introduction Social networks play an increasingly important role in people s lives. They provide us with new ways to communicate with each other, share information, collaborate, or even make friends. As such, they have attracted much attention from researchers across various fields ranging from sociology  1  , psychology  2  , biology  3  , computer science  4  , engineering  5  , etc.. The rapid development of online social media has led to unprecedented growth in the amount of available social network data  6  . For example, Facebook alone now contains more than one billion active users  7  .\nHowever, analyzing large volumes of social network data remains a challenge because it usually involves complex relationships among nodes  8  . To tackle these challenges, recent research efforts focus on developing effective representations for social networks  9  -  11  . These representations aim at capturing different aspects of social networks while being able to scale up well when dealing with massive amounts of data  12  . Among them, matrix factorization techniques  13  -  15  have shown great promise as they allow us to represent social networks using low-rank matrices  16  . Matrix factorization methods decompose a given adjacency matrix into two smaller matrices (i.e., latent factors) which capture structural properties of the original graph  17  .",
        "watermark_text": "Social networks are ubiquitous in our daily living , and have been studied frequently by researchers across many disciplines . However , the examination of social group information is often challenging due to its complexity .In this research we develop NodeTrix , an efficient hybrid representation that can be used to analyze large - scale social systems efficiently . We see how NodeTrix can be applied to solve many important problems namely community detection , link discovery , node classification , and influence maximization .Our experiments on real - global datasets prove that NodeTrix outperforms state - of - the - art methods significantly both in terms of efficiency and effectiveness . 1 Introduction Social networks take an increasingly important role in everyone s lives .They offer us with innovative ways to interact with each other , transfer material , collaborate , or even keep friends . As such , they have garnered many scrutiny from researchers across numerous topics including from geography 1 , psychology 2 , chemistry 3 , computer science 4 , engineering 5 , etc . .The rapid progress of internet social marketing has led to unprecedented growth in the quantity of available social platform data 6 . For instance , Facebook alone now contains more than one billion active people 7 .However , examining high quantities of social group information remains a problem because it often includes difficult connections among nodes 8 . To tackle these problems , recent study efforts focus on developing accurate representations for social organizations 9 - 11 .These representations aim at representing different components of social organizations while being able to level up well when dealing with massive amounts of statistics 12 . Among them , matrix factorization techniques 13 - 15 have shown great hope as they allow us to depict public networks using reduced - class matrices 16 .Matrix factorization techniques decompose a given adjacency vector into two smaller matrices ( i . e . , latent factors ) which capture structural aspects of the original graph 17 .",
        "ori-fast-z-score": 0.15617376188860607,
        "water-fast-z-score": 9.419837224354428
    },
    {
        "original_text": "We have developed an improved photoionization model for the soft X-ray spectrum of the Seyfert 1 galaxy NGC 4151, based on its optical and UV properties as well as previous observations in the X-ray band.  We find that the observed soft X-ray emission is dominated by line emission from highly ionized species such as O viii-xxii, Ne ix-xiii, Mg xii-xv, Si xiv-xxvi, S xix-xxxi, Ar xxviii-xxxviii, Ca xx-xxxiii, Fe xx-xxxvi, Ni xx-xxxvii, and possibly also C v-vi. In addition to these lines we predict significant contributions from continuum emission due to free-free processes (bremsstrahlung) and recombination radiation. Our best-fit parameters are consistent with those found previously using other methods. However, our results suggest that the gas density may be higher than estimated before, while the ionization parameter appears lower.",
        "watermark_text": "We have developed an better photoionization theory for the dark X - ray spectrum of the Seyfert 1 galaxy NGC 4151 , relying on its optical and UV qualities as well as earlier findings in the X - ray band . We see that the reported soft X - ray radiation is dominated by line emission from highly ionized species such as O viii - xxii , Ne ix - xiii , Mg xii - xv , Si xiv - xxvi , S xix - xxxi , Ar xxviii - xxxviii , Ca xx - xxxiii , Fe xx - xxxvi , Ni xx - xxxvii , and maybe also C v - vi .In addition to these lines we estimate significant contributions from continuum emission due to free - free processes ( bremsstrahlung ) and recombination emission . Our best - fitting values are compatible with those identified previously used other methods .However , our findings show that the gas density might be higher than calculated before , while the ionization variable appears smaller .",
        "ori-fast-z-score": -1.6035674514745464,
        "water-fast-z-score": 5.252257314388902
    },
    {
        "original_text": "We report on the observation of ground state magneto optical resonance (GMOR) in cesium vapor confined to a sub-micron thickness layer inside a glass micro-cell. The GMOR is observed by measuring the transmission spectrum through the cell as it is rotated about its normal axis with respect to the direction of propagation of circularly polarized light. We show that this effect can be explained using simple classical electrodynamics and we present experimental results which demonstrate the dependence of the GMOR signal strength on various parameters such as the intensity, frequency detuning and polarization angle of the incident laser beam. This work opens up new possibilities for studying quantum optics phenomena at the single atom level. \n \n In recent years there has been considerable interest in developing techniques for trapping atoms or molecules within microscopic volumes  1  . Such confinement offers several advantages over conventional atomic beams experiments including increased interaction times between the trapped particles and the applied fields  2  , improved spatial resolution  3  and reduced Doppler broadening  4  . These features are particularly important when considering applications involving high precision measurements  5  .\nIn addition to these practical benefits, confining neutral matter to small dimensions also provides opportunities for exploring fundamental physics  6  . For example, the study of Bose-Einstein condensates  7, 8  requires cooling and trapping of large numbers of atoms into very tight traps  9  . Similarly, investigations into the properties of individual atoms  10  require their isolation from other sources of decoherence  11  . Finally, studies of macroscopic quantum effects  12  may benefit from the ability to control the number of particles involved  13  . \n \n Here we describe our efforts towards achieving controlled confinement of neutral matter to extremely small dimensions. Specifically, we have developed a technique for producing a thin film of cesium gas inside a glass micro-cell  14  . By exploiting the strong magnetic dipole moment associated with the cesium ground state  15  , we observe a novel form of magneto-optical resonance  16  known as ground state magneto-optical resonance  17  . Our observations suggest that this phenomenon could provide a useful tool for investigating quantum optics processes occurring at the single atom level  18  .",
        "watermark_text": "We report on the observation of ground state magneto optical resonance ( GMOR ) in cesium vapor confined to a sub - micron thickness sheet inside a glass micro - cell . The GMOR is observed by monitoring the propagation spectrum through the cell as it is rotated about its regular axis with regard to the direction of propagation of circularly polarized light .We see that this effect can be described using simple classical electrodynamics and we present experimental results which demonstrate the dependence of the GMOR wave strength on various variables such as the frequency , frequency detuning and polarization angle of the incident beam beam . This research raises up new possibilities for studying quantum optics dynamics at the single atom level .In recent years there has been substantial interest in improving procedures for trapping atoms or compounds within microscopic volumes 1 . Such confinement gives numerous benefits over traditional molecular beams studies namely increased interaction times between the captured particles and the applied fields 2 , enhanced angular resolution 3 and reduced Doppler broadening 4 .These features are particularly important when assessing uses concerning high precision observations 5 . In addition to these useful benefits , confining neutral matter to small dimensions additionally offers options for studying basic physics 6 .For instance , the investigations of Bose - Einstein condensates 7 , 8 requires freezing and trapping of large numbers of atoms into very strict trapping 9 . Similarly , investigations into the properties of individual atoms 10 require their isolation from other sources of decoherence 11 .Finally , investigations of macroscopic quantum effects 12 may benefit from the ability to affect the quantity of particles concerned 13 . Here we explain our initiatives towards attain controlled confinement of neutral matter to incredibly small sizes .Specifically , we have developed a technique for producing a thin film of cesium gas inside a glass micro - cell 14 . By exploiting the strong magnetic dipole point involved with the cesium ground state 15 , we study a new form of magneto - optical resonance 16 known as ground state magneto - optical resonance 17 .Our observations suggest that this phenomenon might give a helpful resource for investigating quantum optics processes observed at the single atom level 18 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.460169506877884
    },
    {
        "original_text": "We show that the equivalence principle (EP) is violated in quantum gravity if there are dilatons or axions coupled to photons. The violation can be tested by measuring the polarization rotation angle of light passing through gravitational fields. We find that the EP-violating effect is suppressed for macroscopic distances but enhanced for microscopic ones such as those inside atoms. This suggests that the measurement of atomic clocks may provide an opportunity to test the EP at high precision. \n \n In this work we study how the equivalence principle (EP), which states that all local physical laws should take their same form in any freely falling frame, is modified when one considers quantum gravity effects. It has been shown previously that the EP is violated in general relativity with massive gravitons  1  . Here we consider whether it remains valid in theories beyond Einstein s theory where new degrees of freedom exist. Specifically, we focus on two types of models: scalar-tensor theories  2  , including Brans-Dicke theory  3  , and string-theory inspired models  4  .\n \nIn these theories, dilatons and/or axions appear as additional degrees of freedom besides graviton(s). Dilatons couple directly to photons while axions do so indirectly via coupling to photons and gluons  5  . These couplings lead to violations of the EP  6  . For example, in scalar-tensor theories, the photon acquires a mass term proportional to the strength of the gravitational field  7, 8  . As a result, the speed of light depends on its direction relative to the gravitational field  9  . If the gravitational field varies along the path of propagation, then the speed of light also changes accordingly  10  . Since different polarizations travel at slightly different speeds, they acquire different phases during propagation  11  . Therefore, the polarization state of light will rotate after traveling through a gravitational potential gradient  12  .",
        "watermark_text": "We see that the equivalence principle ( EP ) is violated in quantum gravitational if there are dilatons or axions related to photons . The violation can be evaluated by monitoring the polarization rotation angle of light traveling through gravity fields .We see that the EP - violating phenomenon is suppressed for macroscopic distances but improved for microscopic ones such as those inside atoms . This implies that the observation of atomic clocks may provide an ability to test the EP at high precision .In this research we study how the equivalence principle ( EP ) , which says that all local physical rules should take their same shape in any freely falling frame , is modified when one studies quantum gravitational changes . It has been shown previously that the EP is violated in general relativity with massive gravitons 1 .Here we study whether it remains accepted in theories beyond Einstein s theory where new degrees of liberty exist . Specifically , we focus on two forms of models : scalar - vector models 2 , notably Brans - Dicke theory 3 , and string - theory inspired models 4 .In these theories , dilatons and / or axions exist as additional degrees of autonomy besides graviton ( s ) . Dilatons couple directly to photons while axions do so indirectly via coupling to photons and gluons 5 .These couplings contribute to violations of the EP 6 . For instance , in scalar - vector theories , the photon acquires a mass term proportional to the strength of the gravitational field 7 , 8 .As a result , the speed of light changes on its direction relative to the gravitational field 9 . If the gravitational field varies along the path of propagation , then the speed of light additionally changes similarly 10 .Since various polarizations move at slightly different speeds , they acquire various phases during propagation 11 . Therefore , the polarization state of light will rotate after moving through a gravitational potential gradient 12 .",
        "ori-fast-z-score": 0.5222329678670935,
        "water-fast-z-score": 7.950706915615445
    },
    {
        "original_text": "We present the results of our study on gravitational wave (GW) foregrounds for the Laser Interferometer Space Antenna (LISA). We focus on double white dwarfs, which are expected to be one of the most important sources in terms of GW energy density and event rate. In particular we investigate how their properties depend on the initial conditions at formation time as well as on the subsequent evolution driven by nuclear burning and orbital decay due to emission of gravitational waves. The latter is studied with detailed numerical simulations using an updated version of the Eggleton code that includes general relativistic effects. \n \n Our main findings can be summarized as follows: \n \n 1. We find that the number of systems detectable within a given volume depends strongly on the assumed distribution function of binary parameters such as mass ratio q = M2/M1 or total system mass Mtot = M1 + M2. This dependence arises because different distributions lead to very different fractions of binaries with favorable orientations relative to the detector s line-of-sight. If all binaries have random orientation then only about 10% of them will produce signals above the detection threshold. On the other hand if they form preferentially face-on this fraction increases up to 50%. Therefore it seems crucially important to determine the true distribution functions of these quantities observationally before making any predictions regarding the number of detections. \n \n 2. We show that there exists a strong correlation between the masses of the two components of a double white dwarf binary. As a result, the majority of systems detected by LISA will consist of nearly equal-mass objects. However, even though the average value of q is close to unity, there still exist many systems where the secondary component has significantly lower mass than its companion. These systems may provide valuable information about the physics of stellar mergers since they allow us to probe the regime of low-q binaries not accessible through observations of single degenerate stars.",
        "watermark_text": "We present the conclusion of our research on gravity wave ( GW ) foregrounds for the Laser Interferometer Space Antenna ( LISA ) . We focus on double white dwarfs , which are expected to be one of the most important sources in terms of GW energy density and event frequency .In particular we investigate how their characteristics rely on the first parameters at structure point as well as on the subsequent evolution accelerated by nuclear burning and orbital decay owing to emission of gravitational waves . The latter is studied with comprehensive numerical simulations using an updated edition of the Eggleton code that contains general relativistic effects .Our main results can be summarized as follows : 1 . We see that the quantity of systems detectable within a given volume depends strongly on the assumed distribution function of binary parameters such as mass ratio p = M2 / M1 or total system weight Mtot = M1 + M2 .This dependence occurs because different distributions result to very different fractions of binaries with favorable orientations relative to the sensor s line - of - view . If all binaries have random orientation then only about 10 % of them will generate frequencies above the screening threshold .On the other hand if they occur preferentially face - on this amount rises up to 50 % . Therefore it appears crucially vital to estimate the true distribution functions of these quantities observationally before making any observations involving the number of detections .2 . We see that there exists a powerful correlation between the masses of the two parts of a double white dwarf binary .As a result , the majority of components observed by LISA will consist of almost equal - mass particles . However , even though the average value of q is close to unity , there still exist many systems where the secondary component has much lower weight than its companion .These systems may provide valuable info about the physics of stars mergers since they allow us to probe the regime of low - q binaries not accessible through observations of single degenerate stars .",
        "ori-fast-z-score": 0.16116459280507606,
        "water-fast-z-score": 6.93007749061827
    },
    {
        "original_text": "We report on point contact Andreev reflection (PCAR) measurements performed on single crystals of the heavy fermion compound HoNi2B2C, which is an antiferromagnet with T N = 1.5 K that becomes a type-II superconductor below Tc = 0.8 K. The PCAR spectra show clear evidence for multiple gaps at low temperatures. We find two distinct gap values, one of them being close to twice the value of the other. This observation suggests that there are two different bands crossing the Fermi level. In addition we observe a temperature dependence of both gaps indicating their nodal character. Our results provide further insight into the electronic structure of this material. Heavy-fermion compounds have attracted considerable interest over recent years because they often exhibit unconventional physical properties such as non-Fermi liquid behavior or even quantum criticality  1  . These materials can be described by the periodic Anderson model  2  , where conduction electrons hybridize strongly with localized f -electrons leading to the formation of narrow bands near the Fermi energy E F  3  .\nHoNi 2 B 2 C belongs to the family of so-called borocarbides  4  . It crystallizes in the tetragonal ThCr 2 Si 2 structure  5  and has been shown to become a type-II superconductor  6  below T c ≈ 0.8 K  7, 8  . At ambient pressure it orders magnetically around T N = 1.6 K  9  . Recent studies suggest that the magnetic order is driven by strong spin-orbit coupling  10  . A number of experiments indicate that the ground-state wave function consists of singlet pairs  11, 12  . However, the exact nature of the pairing mechanism remains unclear  13  .",
        "watermark_text": "We report on point touch Andreev reflection ( PCAR ) observations performed on single crystals of the heavy fermion compound HoNi2B2C , which is an antiferromagnet with T N = 1 . 5 K that remains a class - II superconductor below Tc = 0 . 8 K . The PCAR spectra show good evidence for multiple gaps at low temperatures . We see two separate gap values , one of them being close to double the value of the other .This measurement indicates that there are two different bands crossing the Fermi level . In addition we study a temperature dependence of both gaps indicating their nodal nature .Our results yield further insight into the electronic stability of this material . Heavy - fermion compounds have garnered considerable interest over recent months because they frequently exhibit unusual physical properties such as non - Fermi solid behavior or even quantum criticality 1 .These compounds can be described by the periodic Anderson model 2 , where conduction electrons hybridize heavily with localized f - ions causing to the formation of narrow bands near the Fermi energy E F 3 . HoNi 2 B 2 C belongs to the class of so - called borocarbides 4 .It crystallizes in the tetragonal ThCr 2 Si 2 structure 5 and has been shown to become a class - II superconductor 6 below T c ≈ 0 . 8 K 7 , 8 . At ambient pressure it orders magnetically around T N = 1 . 6 K 9 .Recent research suggest that the magnetic order is caused by strong spin - orbit interaction 10 . A variety of studies reveal that the ground - state wave function consists of singlet sets 11 , 12 .However , the exact nature of the pairing structure remains disputed 13 .",
        "ori-fast-z-score": 0.5720775535473553,
        "water-fast-z-score": 7.181324987175317
    },
    {
        "original_text": "We study the possibility that there are two different lifetimes for neutral B mesons, one corresponding to the standard model and another to new physics beyond it.  We find that if the decay widths into final states with charm quarks differ by more than about 10% between these two types of B mesons then this can be observed at future experiments such as LHCb or Belle II. If we assume that the ratio of branching fractions is equal to 1 (as predicted within the Standard Model) but allow the total decay widths to vary independently, then we show how the experimental data on the time dependent CP asymmetry parameters SCP and ACP can be used to determine whether the difference in decay widths is due to new physics effects or not. Finally, we discuss possible extensions of our analysis which could lead to further constraints on the allowed parameter space. The results presented here will also have implications for other measurements performed at hadron colliders involving heavy flavour particles.",
        "watermark_text": "We research the prospect that there are two different lifetimes for neutral B mesons , one corresponding to the standard description and another to new science beyond it . We see that if the decay widths into initial states with charm quarks vary by more than about 10 % between these two kind of B mesons then this can be observed at current experiments such as LHCb or Belle II .If we suppose that the proportion of branching fractions is equal to 1 ( as predicted within the Standard Model ) but allow the total degradation widths to vary independently , then we explain how the theoretical data on the period dependent CP asymmetry characteristics SCP and ACP can be used to predict whether the difference in decay widths is due to novel physics effects or not . Finally , we explain possible extensions of our analysis which potentially contribute to further limitation on the allowed parameter area .The results presented here will also have consequences for other tests accomplished at hadron colliders regarding heavy flavour atoms .",
        "ori-fast-z-score": -2.032002032003048,
        "water-fast-z-score": 5.505585837114527
    },
    {
        "original_text": "We study the circular and non-circular motion near the event horizons of rotating black holes by using the Hamilton-Jacobi method, which is an extension of the standard geodesic approach to include higher-order corrections due to gravitational radiation reaction effects. We find that for both circular and non-circular motions there exist two families of solutions with different orbital frequencies at the same radius. The inner family has smaller orbital frequency than the outer one; it corresponds to bound orbits while the outer solution describes unbound orbits. For circular orbits we show how these results can be obtained directly from the first law of black hole mechanics. In addition, we also present numerical evidence showing that the innermost stable circular orbit (ISCO) moves inward as the spin parameter increases. Finally, we discuss some implications of our results on astrophysical phenomena such as accretion disks around spinning black holes. Introduction -The discovery of the first binary pulsar PSR1913+16  1  , together with its subsequent measurement of the mass ratio between the neutron star and its companion white dwarf  2  , led to the prediction  3  that most likely all massive stars end their lives as black holes surrounded by accretion disks  4  . Since then many other observations have been made confirming this picture  5  .\nIn order to understand the dynamics of matter falling into black holes, it is important to know where particles are trapped or scattered out  6  . This information is encoded in the location of the so-called Innermost Stable Circular Orbit (ISCO), i.e., the smallest possible radius r ISCO of a particle s circular orbit  7, 8  . It turns out that the value of r ISCO depends sensitively on the spin angular momentum J = Ma 2 /(2r g ) of the black hole  9  : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO decreases rapidly until finally it reaches the Schwarzschild radius R s ≡ 2GM/c 2  10  . Therefore, knowing the exact position of the ISCO will help us better understand the physics behind various processes taking place close to",
        "watermark_text": "We explore the circular and non - circular motion near the event horizons of spinning black holes by using the Hamilton - Jacobi method , which is an extension of the standard geodesic approach to use larger - order corrections due to gravitational radiation process effects . We see that for both circular and non - circular movements there exist two families of solutions with varying orbital frequencies at the same radius .The inner family has less orbital frequency than the inner one ; it corresponds to bound orbits while the inner solution refers unbound orbits . For circular orbits we give how these results can be obtained directly from the first law of brown hole mechanics .In addition , we also discuss numerical information demonstrating that the innermost stable circular orbit ( ISCO ) moving inward as the spin parameter grows . Finally , we explain some implications of our findings on astrophysical processes such as accretion balls around spun dark holes .Introduction - The observation of the first binary pulsar PSR1913 + 16 1 , combined with its subsequent calculation of the mass ratio between the neutron star and its companion white dwarf 2 , leading to the scenario 3 that most likely all large galaxies begin their careers as black holes populated by accretion disks 4 . Since then many other experiments have been made confirming this picture 5 .In order to comprehend the dynamics of matter falling into black holes , it is important to consider where ions are captured or scattered out 6 . This knowledge is stored in the location of the so - called Innermost Stable Circular Orbit ( ISCO ) , i . e . , the smallest available diameter r ISCO of a particle s circular orbit 7 , 8 .It turns out that the value of r ISCO relies sensitively on the spin angular velocity J = Ma 2 / ( 2r g ) of the dark hole 9 : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO falls slowly until finally it meets the Schwarzschild diameter R s ≡ 2GM / c 2 10 . Therefore , knowing the exact position of the ISCO will assist us better understand the physics behind several mechanisms taking place nearby to",
        "ori-fast-z-score": -1.7905475715715027,
        "water-fast-z-score": 6.6577138248976375
    },
    {
        "original_text": "We present an alternative derivation of Einstein gravity, which does not use the axiom of choice and is based on the concept that topology can be hidden inside general relativity (GR). We show how to construct a set of local coordinates for any given spacetime point such that all points with the same coordinate values are connected by geodesics. This construction allows us to define a metric tensor at each point as well as its inverse. The resulting theory has exactly the same field equations as standard GR but it contains additional degrees of freedom corresponding to the number of disconnected components of the underlying space. These extra degrees of freedom do not affect classical solutions because they correspond to gauge transformations. However, we argue that these new degrees of freedom may play an important role when considering quantum effects. In particular, we discuss possible implications of our approach for black hole entropy calculations. Finally, we comment on some open problems related to this work.",
        "watermark_text": "We introduce an alternative derivation of Einstein relativity , which does not use the axiom of choice and is based on the idea that geometry can be hidden inside general relativity ( GR ) . We see how to build a setting of local coordinates for any certain spacetime point such that all points with the same coordinate parameters are connected by geodesics .This construction gives us to define a metric tensor at each point as well as its inverse . The resulting theory has precisely the same field equations as conventional GR but it contains additional degrees of liberty corresponding to the number of disconnected components of the underlying set .These added degrees of liberty do not alter classical solutions because they relate to gauge processes . However , we feel that these new degrees of liberty might play an important role when assessing quantum effects .In particular , we discuss possible possibilities of our approach for black hole entropy calculations . Finally , we comment on some open problems related to this research .",
        "ori-fast-z-score": -0.3333333333333333,
        "water-fast-z-score": 4.919349550499537
    },
    {
        "original_text": "We study stability properties of the periodic Toda lattice with respect to small  time-periodic perturbations. We show that if the perturbation is sufficiently small, then there exists an exponentially stable solution which can be found by solving a linear algebraic system. The proof relies on the Floquet theory and Lyapunov-Schmidt reduction method. This result generalizes previous results obtained in the case when the unperturbed system has only one equilibrium point or when it possesses two equilibria but they are not connected via heteroclinic orbits. In particular we prove that for any number of equilibria greater than 2 (including infinitely many) there exist arbitrarily large perturbations such that all solutions of perturbed systems converge to infinity as t → ∞. \nIntroduction\n\nThe Toda lattice is a classical example of a completely integrable Hamiltonian system introduced by Toda  Tod  . It describes N particles moving along straight lines with pairwise exponential interaction potential between them. For simplicity let us consider the case N = 1. Then the equation describing this motion takes the form \nwhere x(t), y(t) ∈ R n , A :  0, T   × R n → R n×n is continuous matrix-valued function satisfying some additional conditions specified below. If A ≡ 0, i.e., no external forces act upon the particle, then the corresponding solution is called the free Toda flow. It was shown in  KN  that the free Toda flow is globally asymptotically stable provided that the spectrum of the matrix A does not intersect the imaginary axis. Moreover, the authors proved that the set of initial data leading to bounded trajectories coincides with the set of initial data belonging to the basin of attraction of the zero solution. However, these results do not hold true anymore if the matrix A depends on time.",
        "watermark_text": "We explore equilibrium properties of the periodic Toda lattice with regard to small time - periodic perturbations . We see that if the perturbation is sufficiently small , then there exists an exponentially stable solution which can be found by solving a linear mathematical scheme .The proof uses on the Floquet model and Lyapunov - Schmidt reduction technique . This result generalizes earlier findings obtained in the case when the unperturbed body has only one equilibrium point or when it enjoys two equilibria but they are not linked via heteroclinic orbits .In particular we prove that for any number of equilibria greater than 2 ( including infinitely many ) there exist arbitrarily huge perturbations such that all solutions of perturbed systems converge to infinity as t → ∞ . Introduction The Toda lattice is a traditional instance of a completely integrable Hamiltonian structure developed by Toda Tod .It describes N particles moving along straight lines with pairwise exponential interaction potential between them . For simplicity let us consider the case N = 1 .Then the equation explaining this motion takes the form where x ( t ) , y ( t ) ∈ R n , A : 0 , T × R n → R n×n is continuous matrix - valued function satisfying some additional conditions defined below . If A ≡ 0 , i . e . , no external forces action upon the particle , then the equivalent solution is dubbed the free Toda flow .It was shown in KN that the free Toda flow is internationally asymptotically stable given that the spectrum of the matrix A does not intersect the imaginary axis . Moreover , the papers proved that the set of initial data leading to finite trajectories coincides with the set of initial results belonging to the basin of attraction of the zero solution .However , these results do not stand true anymore if the function A depends on time .",
        "ori-fast-z-score": 0.2705008904002297,
        "water-fast-z-score": 6.2215204792052825
    },
    {
        "original_text": "Globular clusters are dense stellar systems that contain thousands to millions of stars, and may be the oldest gravitationally bound objects known.  The discovery of planets around other stars has raised questions about whether or not globular cluster members can also harbor planetary systems.   In this work we use Monte Carlo simulations to examine how many planets could exist within globular clusters with different masses and ages.  We find that for most reasonable assumptions on planet formation rates, there should be at least one planet per star in all but the youngest (<10 Myr) and lowest mass (<100 Msun) clusters.  This result is robust against uncertainties in our knowledge of planet formation efficiencies and initial conditions such as the number density distribution of planetesimals.  Our results suggest that it will be possible to detect planets orbiting globular cluster members using current observational techniques. Keywords: Planetary systems; Stellar evolution; Star clusters; Formation",
        "watermark_text": "Globular complexes are dense stellar structures that host hundreds to millions of stars , and may be the earliest gravitationally locked objects known . The observation of planets around other stars has raised questions about whether or not globular cluster groups can also harbor planetary structures .In this research we utilize Monte Carlo simulations to examine how many worlds could occur within globular complexes with various masses and periods . We see that for most reasonable assumptions on planet development rates , there should be at least one planet per star in all but the youngest ( < 10 Myr ) and lowest mass ( < 100 Msun ) clusters .This result is robust against uncertainties in our know of planet development efficiencies and first situations such as the number density density of planetesimals . Our results propose that it will be possible to identify planets orbiting globular cluster elements using current observational techniques .Keywords: Planetary systems; Stellar evolution; Star clusters; Formation",
        "ori-fast-z-score": 0.11867816581938533,
        "water-fast-z-score": 6.527299120066193
    },
    {
        "original_text": "We present new observations made with the Cosmosoma experiment, which were designed to search for evidence of an excess in cosmic microwave background (CMB) temperature fluctuations above those predicted by standard cosmological models. The data are consistent with predictions based on current theoretical understanding but show some unexpected features that may be related to previously unidentified foreground sources or systematic effects associated with our analysis techniques. \n \n We have used these results to place limits on possible contributions from primordial gravitational waves and other exotic phenomena such as topological defects. These limits are comparable to previous measurements obtained using different experimental approaches. In addition we report the detection of a significant signal at frequencies below 10GHz, which is not expected within conventional cosmological models. This could represent either a new source of foreground contamination or a novel physical effect. Further investigation will require additional experiments to confirm this result and determine its origin. If confirmed it would provide important constraints on theories attempting to explain the observed anisotropy in the CMB spectrum.",
        "watermark_text": "We present new experiments done with the Cosmosoma study , which were built to search for indication of an amount in cosmic microwave background ( CMB ) temperature fluctuations above those predicted by traditional cosmological predictions . The data are compatible with predictions based on current theoretical knowledge but display some surprising characteristics that might be connected to formerly unidentified foreground sources or systematic effects involved with our analysis methods .We have utilized these results to place limits on potential contributions from primordial magnetic waves and other exotic processes such as topological defects . These restrictions are comparable to previous measurements obtained using separate observation approaches .In addition we report the finding of a substantial frequency at speeds below 10GHz , which is not anticipated within conventional cosmological predictions . This might represent either a new cause of foreground contamination or a novel physical impact .Further investigation will demand additional studies to confirm this result and establish its identity . If confirmed it would offer important restrictions on experiments pursuing to explain the observed anisotropy in the CMB spectrum .",
        "ori-fast-z-score": -1.0540925533894598,
        "water-fast-z-score": 7.233165373381237
    },
    {
        "original_text": "We study the slow wave resonance (SWR) effect for periodically layered media with an arbitrary number N of anisotropic layers, each characterized by its own permittivity tensor and thickness. We show that SWR is possible only if all principal axes of the permittivity tensors are parallel to one another within each layer. In this case we derive explicit expressions for the dispersion relation between the frequency f and the Bloch wavenumber kx. The results obtained can be used as guidelines for designing multilayered structures exhibiting strong SWR effects at low frequencies. \n \n Keywords: Slow wave resonance; Anisotropy; Multilayer structure; Dispersion relations. 1 Introduction \n \n Periodic multilayers consisting of alternating thin films made of different materials have attracted considerable attention during recent years due to their unique properties  1  . These include high reflectance  2  , negative refraction  3  , enhanced nonlinear optical response  4  , etc., which make them promising candidates for various applications such as optoelectronic devices  5  or photovoltaics  6  .\n \nIn particular, it has been shown recently  7–9  that periodic multilayers composed of anisotropic layers may exhibit very interesting electromagnetic phenomena including slow wave resonance (S WR). This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium  10  . It leads to extremely large values of the effective refractive index n eff = c / v ph  11  where c is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode  12  . As a result, the corresponding transmission spectrum exhibits sharp peaks associated with narrow stop bands  13  . Such features are highly desirable for many practical applications  14  . \n \n However, despite numerous theoretical studies devoted to S WR in periodic multilayers  15–18  , there still exist several open questions related to the conditions under which this phenomenon takes place  19, 20  . For example, it was found experimentally  21  that the presence of a single misaligned anisotropic layer destroys the S WR effect completely even though other layers remain perfectly aligned. On the other hand, numerical simulations  22  suggest that",
        "watermark_text": "We explore the slow frequency resonance ( SWR ) effect for regularly layered media with an arbitrary number N of anisotropic layers , each described by its own permittivity matrix and thickness . We see that SWR is possible only if all primary directions of the permittivity tensors are connected to one another within each surface .In this situation we derive explicit expressions for the dispersion constant between the frequency f and the Bloch wavenumber kx . The results derived can be used as guidelines for constructing multilayered buildings presenting strong SWR effects at low frequencies .Keywords : Slow wave vibration ; Anisotropy ; Multilayer structure ; Dispersion relations . 1 Introduction Periodic multilayers consisting of alternating thin sheets formed of different materials have garnered considerable scrutiny during recent seasons due to their distinct characteristics 1 .These include high reflectance 2 , negative refraction 3 , enhanced nonlinear optical reaction 4 , etc . , which make them promising candidates for various uses such as optoelectronic technologies 5 or photovoltaics 6 . In particular , it has been shown ago 7 – 9 that periodic multilayers consisting of anisotropic surfaces may exhibit very interesting electrical processes including slow frequency resonance ( S WR ) .This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium 10 . It results to incredibly large values of the effective refractive index n eff = c / u ph 11 where p is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode 12 .As a result , the associated transmission spectrum exhibits severe spikes identified with narrow stop rings 13 . Such characteristics are extremely practical for numerous practical applications 14 .However , despite several theoretical experiments devoted to S WR in periodic multilayers 15 – 18 , there still appear several open questions related to the conditions under which this phenomenon happens place 19 , 20 . For instance , it was shown experimentally 21 that the presence of a single misaligned anisotropic surface destroys the S WR effect totally even though other layers remain perfectly aligned .On the other hand , numerical simulations 22 suggest that",
        "ori-fast-z-score": -0.15811388300841897,
        "water-fast-z-score": 8.432781346758377
    },
    {
        "original_text": "We present the results of cosmological hydrodynamic simulations that follow the evolution of dark matter haloes within different cosmic environments (clusters, filaments, sheets and voids). We find that:\n(i) The mass accretion histories of clusters are dominated by major mergers with other massive systems at high redshifts z > 1.\n(ii) In contrast to clusters, most of the growth of filamentary structures is driven by smooth gas accretion along their length.  This leads to an extended formation history for these objects which can be traced back to early times z < 5. (iii) Sheet-like structures form through the merger of smaller filaments into larger ones. They grow mainly via smooth gas accretion but also experience minor mergers with small groups or galaxies during their lifetime. (iv) Voids evolve almost exclusively due to smooth gas accretion. Their assembly time-scales are typically longer than those of clusters and filaments because they have less dense surroundings.",
        "watermark_text": "We present the conclusion of cosmological hydrodynamic simulations that take the evolution of dark matter haloes within various cosmic environments ( complexes , filaments , sheets and voids ) . We see that : ( i ) The mass accretion histories of clusters are dominated by major mergers with other giant bodies at high redshifts z > 1 .( ii ) In comparison to groups , most of the development of filamentary structures is caused by smooth gas accretion along their duration . This leads to an extended structure life for these objects which can be traced back to early years z < 5 .( iii ) Sheet - like structures develop through the merger of tiny filaments into larger ones . They develop principally via smooth gas accretion but also experience minor mergers with little groups or galaxies during their lifetime .( iv ) Voids evolve virtually primarily due to soft gas accretion . Their development time - scales are typically longer than those of clusters and filaments because they have less dense surroundings .",
        "ori-fast-z-score": -0.23904572186687872,
        "water-fast-z-score": 4.865804798594798
    },
    {
        "original_text": "We present an extension to the cable model that allows one to account for membrane dynamics in neurons with active conductances over a wide range of time scales and spatial dimensions, including those relevant to subthreshold electrogenesis. The proposed approach is based on a reformulation of the cable equation as a system of first-order differential equations describing voltage changes along the axon or dendrite. This formulation leads naturally to a generalization of the concept of space constants to include both passive and active components of the membrane impedance. We show how this generalized cable formalism can be used to describe propagation of action potentials through a single compartment neuron with Hodgkin-Huxley type currents. Finally we demonstrate its utility by applying it to study spatiotemporal patterns of activity in networks of coupled neurons. Neurons are highly specialized cells capable of generating electrical signals known as action potentials (APs). These APs propagate down the length of the cell s axon toward synaptic terminals where they trigger release of neurotransmitters into the synapse. In turn these transmitters bind to receptors located on the postsynaptic side of the synapse initiating signaling cascades which ultimately lead to generation of new APs. Thus information transfer between neurons occurs via propagating APs across chemical synapses.",
        "watermark_text": "We introduce an addition to the cable theory that enables one to explain for membrane dynamics in cells with active conductances over a broad variety of time scales and spatial dimensions , particularly those applicable to subthreshold electrogenesis . The proposed approach is based on a reformulation of the cable equation as a system of first - order differential coefficients governing voltage changes along the axon or dendrite .This formulation leads naturally to a generalization of the notion of space constants to consider both passive and active components of the membrane impedance . We see how this generalized cable formalism can be used to explain propagation of action potentials through a single chamber neuron with Hodgkin - Huxley type flows .Finally we prove its utility by using it to study spatiotemporal changes of action in networks of coupled neurons . Neurons are extremely specialized molecules capable of transmitting electrical messages termed as action potentials ( APs ) .These APs propagate down the length of the cell s axon toward synaptic terminals where they stimulate release of neurotransmitters into the synapse . In turn these transmitters attach to receptors located on the postsynaptic side of the synapse initiating activation cascades which ultimately cause to development of new APs .Thus information transfer between neurons occurs via propagating APs across molecular synapses .",
        "ori-fast-z-score": -1.6865480854231356,
        "water-fast-z-score": 5.346252667281783
    },
    {
        "original_text": "We consider the possibility that dark matter is made up of bosonic particles, which can condense into a superfluid state at low temperatures. We show how this scenario could explain several puzzling observations in astrophysics and cosmology. In particular we argue that: (i) The observed flat rotation curves of spiral galaxies are explained by the presence of a halo of cold dark matter surrounding each galaxy. (ii) The formation of large-scale structures such as clusters of galaxies proceeds through gravitational collapse of overdensities in the primordial density field seeded by quantum fluctuations during inflation. (iii) Dark energy may arise naturally if the universe contains a large number of weakly interacting massive particles with masses around $10^{22}$ GeV. This article is part of a series on Quantum Matter. For more information see http://arxiv.org/abs/quant-ph/0604070 . \nIntroduction:  Many theories beyond the Standard Model predict new types of elementary particles whose existence has yet to be confirmed experimentally. One particularly interesting class of models involves so-called WIMPZILLAs  1  , i.e., stable relic particles with masses around $10^9$ GeV or higher  2  . These particles would have been produced thermally in the early Universe but their abundance today should still be determined by their annihilation cross section  3  .\nIn this Letter we propose an alternative explanation for the origin of dark matter based on the idea that it consists of self-gravitating bosons  4  . Boson stars  5  are gravitationally bound states of scalar fields  6  predicted by many extensions of the Standard Model  7, 8  . They were first studied in the context of supersymmetric grand unified theories  9  where they play the role of solitonic solutions  10  . More recently, boson stars have also been considered within the framework of string theory  11  . If these objects exist then they will form a population of compact remnants  12  that might constitute all or some fraction of the dark matter  13  .",
        "watermark_text": "We consider the prospect that dark matter is made up of bosonic particles , which can condense into a superfluid state at low temperatures . We see how this situation could explain several puzzling discoveries in astrophysics and cosmology .In particular we claim that : ( i ) The observed flat rotation curves of spiral nuclei are explained by the presence of a halo of cold dark matter surrounding each galaxy . ( ii ) The formation of large - scale structures such as clusters of stars happens through gravity collapse of overdensities in the primordial density field seeded by quantum fluctuations during inflation .( iii ) Dark energy may arise naturally if the universe consists a large number of mildly interacting massive particles with masses around $ 10 ^ { 22 } $ GeV . This page is part of a trilogy on Quantum Matter .For more information see www : / / arxiv . org / abs / quant - ph / 0604070 . Introduction : Many theories beyond the Standard Model predict new types of primary objects whose existence has yet to be verified experimentally .One especially interesting class of models involves so - called WIMPZILLAs 1 , i . e . , stable relic objects with masses around $ 10 ^ 9 $ GeV or greater 2 . These particles might have been created thermally in the early Universe but their density today should still be determined by their annihilation cross section 3 .In this Letter we propose an additional argument for the origin of dark matter based on the idea that it consists of self - gravitating bosons 4 . Boson galaxies 5 are gravitationally bound states of scalar fields 6 expected by many extensions of the Standard Model 7 , 8 .They were first investigated in the context of supersymmetric grand unified fields 9 where they hold the part of solitonic answers 10 . More recently , boson stars have also been discussed within the framework of string theory 11 .If these objects exist then they will form a population of compact remnants 12 that might constitute all or some fraction of the dark matter 13 .",
        "ori-fast-z-score": 1.6783627165933783,
        "water-fast-z-score": 7.495152097492019
    },
    {
        "original_text": "We study the correlations and sum rules in a semi-infinite system with impurities at its surface, which is described by the quantum two-dimensional (2D) one component plasma model. We use the exact diagonalization method to calculate the density-density correlation function and static structure factor as well as their corresponding sum rules. The results show that there are two different regimes depending on whether the temperature T is larger or smaller than the Fermi energy EF . In particular, we find that when T < EF , the behavior of these quantities can be understood within the framework of Landau s Fermi liquid theory. However, if T > EF , our numerical data deviate significantly from this picture. Finally, we also investigate how the presence of impurities affects the above mentioned physical properties. Our findings suggest that the effect of impurities depends strongly on the distance between them. If they are close enough, then the impurity-impurity interaction dominates over other interactions leading to an increase of the effective mass of particles near the surface.",
        "watermark_text": "We consider the correlations and sum rules in a semi - infinite system with impurities at its surface , which is characterized by the quantum two - dimensional ( 2D ) one element plasma model . We use the exact diagonalization technique to estimate the density - density correlation function and static structure parameter as well as their corresponding sum rules .The results show that there are two different regimes depending on whether the temperature T is bigger or smaller than the Fermi energy EF . In particular , we find that when T < EF , the dynamics of these quantities can be understood within the framework of Landau s Fermi liquid physics .However , if T > EF , our numerical statistics deviate substantially from this picture . Finally , we also investigate how the presence of impurities impacts the above mentioned physical properties .Our findings show that the impact of impurities relies highly on the distance between them . If they are close enough , then the impurity - impurity interaction dominates over other molecules giving to an increase of the effective mass of molecules near the surface .",
        "ori-fast-z-score": 2.5927248643506746,
        "water-fast-z-score": 6.4372630957871815
    },
    {
        "original_text": "We present the results of an observation performed by XMM-Newton on the galaxy cluster Abell S0740 (SA57). The data were taken between December 2004 and January 2005 for a total exposure time of about 100 ks, split into two pointings separated by 1 arcmin. We detect more than 50 sources within the field-of-view of our observations. Most of them are associated to galaxies at different redshifts; we also find several active galactic nuclei (AGN) as well as one background quasar. In order to study their properties, we have extracted spectra for all detected sources using circular regions centered on each source position. For most of these objects, we could fit single power-law models or thermal plasma emission models. From this analysis, we derive luminosities ranging from 1042 erg s-1 up to 1044 erg s-1 . Using the observed fluxes and assuming that they follow a standard candle model, we estimate the number density distribution of clusters per unit volume as a function of redshift. This allows us to calculate the expected number of clusters above a given mass limit as a function of redshift and compare it with the predictions obtained from numerical simulations.",
        "watermark_text": "We present the conclusion of an observation performed by XMM - Newton on the galaxy cluster Abell S0740 ( SA57 ) . The data were took between December 2004 and January 2005 for a total sensitivity length of about 100 ks , separated into two pointings separated by 1 arcmin .We detect more than 50 sources within the field - of - view of our observations . Most of them are related to galaxies at different redshifts ; we also find several active galactic nuclei ( AGN ) as well as one background quasar .In order to study their characteristics , we have gathered spectra for all detected sources using circular regions centered on each source place . For most of these objects , we may fit single power - law models or thermal plasma radiation estimates .From this analysis , we derive luminosities ranging from 1042 erg s - 1 up to 1044 erg s - 1 . Using the seen fluxes and assuming that they follow a traditional candle model , we estimate the number density spread of clusters per unit volume as a function of redshift .This enables us to estimate the expected number of clusters above a given mass limit as a function of redshift and compare it with the estimates obtained from numerical simulations .",
        "ori-fast-z-score": 0.6546536707079772,
        "water-fast-z-score": 4.858987147293248
    },
    {
        "original_text": "We study instabilities that develop in the accretion flow onto black holes during gamma-ray bursts (GRBs). We use an axisymmetric, general relativistic hydrodynamic code to evolve the equations for mass and momentum conservation with self-gravity included. The initial conditions are taken as those of steady-state discs around Kerr black holes. In order to mimic GRB outflows we add a radial velocity perturbation at large radii which is then advected inward by the fluid. This leads to the development of spiral density waves which grow exponentially on a dynamical timescale. These waves can be identified with the Rossby wave instability (RWI) predicted analytically by Lovelace et al. (1999) . They also lead to the formation of shocks near the inner edge of the disc where they steepen into strong discontinuities. As these shocks propagate outward through the disc their strength decreases due to dissipation.",
        "watermark_text": "We research instabilities that develop in the accretion flow onto black holes during gamma - ray flare ( GRBs ) . We use an axisymmetric , general relativistic hydrodynamic program to evolve the expressions for charge and momentum conservation with self - gravity included .The initial conditions are took as those of stable - state discs around Kerr black holes . In order to mimic GRB outflows we create a radial speed perturbation at large radii which is then advected inward by the liquid .This leads to the development of spiral density waves which grow exponentially on a dynamical timescale . These waves can be identified with the Rossby wave disturbance ( RWI ) anticipated analytically by Lovelace et al .( 1999 ) . They also lead to the formation of shocks near the inner boundary of the disc where they steepen into deep discontinuities .As these shocks propagate outward through the disc their intensity reduces owing to dissipation .",
        "ori-fast-z-score": 0.13018891098082389,
        "water-fast-z-score": 4.03585624040554
    },
    {
        "original_text": "We present new XMM-Newton observations of the Wolf Rayet binary system WR147, which is one of only two known systems with an O-type companion star and a WN6-7h primary component (the other being WR20a). The data were obtained in December 2004 during revolution number 1253-1255 using all three EPIC cameras on board XMM-Newton. We have analyzed these data to search for periodicities in both light curves as well as line profiles. No significant periodicity was found in either the light curve or line profile analysis. However we find that there are differences between the line profiles observed by Chandra and those seen here. These differences may be due to orbital motion within this highly eccentric system. This work has been supported by NASA grant NAG5-10842. Keywords: Wolf-Rayet stars; binaries; X-rays; XMM-Newton",
        "watermark_text": "We report new XMM - Newton discoveries of the Wolf Rayet binary system WR147 , which is one of only two discovered systems with an O - class companion star and a WN6 - 7h primary component ( the other being WR20a ) . The data were obtained in December 2004 during revolution number 1253 - 1255 utilizing all three EPIC photographers on board XMM - Newton .We have analyzed these information to search for periodicities in both light curves as well as line profiles . No considerable periodicity was found in either the light curve or line profile analysis .However we find that there are variations between the line profiles observed by Chandra and those viewed here . These changes may be due to orbital movement within this strongly eccentric system .This project has been supported by NASA grant NAG5 - 10842 . Keywords : Wolf - Rayet stars ; binaries ; X - radiation ; XMM - Newton",
        "ori-fast-z-score": -0.13736056394868904,
        "water-fast-z-score": 4.354648431614539
    },
    {
        "original_text": "We present the results of an optical survey for high redshift galaxies in the field surrounding the radio galaxy PKS 1138-262 (z = 3.9). We have detected over 100 candidate Lyman-alpha emitting galaxies with redshifts between 2 and 5, including several new spectroscopically confirmed members of this cluster. The spatial distribution of these objects is consistent with that expected if they are located within a single dark matter halo centered on the radio source. This result suggests that clusters may be identified by their diffuse emission as well as individual member galaxies. In addition to confirming the existence of a massive cluster around PKS 1138-262 we find evidence for two other overdensities of Lyman-alpha emitting sources near the line-of-sight to the radio source. These structures could represent additional clusters or proto-clusters which will evolve into richer systems like those found today. Finally, our data suggest that there exists a large population of faint Lyman-alpha emitting objects whose properties are similar to those observed locally but whose number density increases rapidly towards higher redshifts.",
        "watermark_text": "We present the conclusion of an optical survey for high redshift galaxies in the field surrounding the radio star PKS 1138 - 262 ( z = 3 . 9 ) . We have discovered over 100 candidate Lyman - alpha emitting galaxies with redshifts between 2 and 5 , including ten new spectroscopically confirmed members of this cluster .The geographic distribution of these objects is consistent with that expected if they are situated within a single black material halo focused on the radio source . This result suggests that clusters might be identified by their diffuse emission as well as additional member galaxies .In addition to proving the existence of a huge cluster around PKS 1138 - 262 we find proof for two other overdensities of Lyman - alpha emitting sources near the line - of - view to the radio source . These structures could constitute extra clusters or proto - nuclei which will evolve into richer complexes like those observed nowadays .Finally , our statistics indicate that there exists a large colony of distant Lyman - alpha emitting objects whose characteristics are comparable to those observed locally but whose number density increases quickly towards higher redshifts .",
        "ori-fast-z-score": -0.9878783399072131,
        "water-fast-z-score": 5.019011475427825
    },
    {
        "original_text": "We study the phase behavior of a system of N identical hard rods confined to a square box with periodic boundary conditions, using Monte Carlo simulations at constant pressure P . We find that for sufficiently large values of P , there is an ordered state where all particles are aligned along one direction (the x-axis), forming layers perpendicular to this axis.  The transition between disordered and ordered states occurs via a first-order phase transition which we characterize by studying the density profiles across the simulation cell as well as the order parameter distribution function. For small values of P , however, no such ordered state exists. Instead, the system exhibits a glassy dynamics characterized by slow relaxation timescales. Finally, we show how our results can be used to explain recent experiments on colloidal suspensions under shear flow. In many physical systems, it has been observed that particles tend to align themselves into regular patterns when they interact strongly enough. This phenomenon is known as capillarity  1  or self-assembly  2  .\nIn particular, in two dimensions, particles may form stripes  3  -  5  , squares  6  , hexagons  7  , or even more complex structures  8  depending on their shape  9  , size  10  , interactions  11  , and external fields  12  . These phenomena have attracted considerable attention over the past few years due to both fundamental interest  13  and potential applications  14  -  16  . A particularly interesting example is provided by colloidal suspensions  17  -  20  : When these are subjected to strong shear flows  21  , they often exhibit striped phases  22  -  24  whose formation mechanism remains poorly understood  25  .",
        "watermark_text": "We explore the phase response of a system of N identical hard rods confined to a square box with periodic border conditions , using Monte Carlo simulations at steady pressure P . We see that for enough large values of P , there is an ordered state where all atoms are aligned along one orientation ( the x - axis ) , forming sheets parallel to this axis .The shift between disordered and ordered states happens via a first - order phase shift which we characterize by examining the density patterns across the model cell as well as the order parameter distribution relation . For small values of P , however , no such ordered state exists .Instead , the system displays a glassy dynamics defined by small relaxation timescales . Finally , we tell how our findings can be used to explain latest studies on colloidal suspensions under shear flow .In many physical structures , it has been observed that particles tend to align themselves into normal patterns when they interact strongly sufficiently . This phenomenon is known as capillarity 1 or self - assembly 2 .In particular , in two dimensions , particles may form colors 3 - 5 , circles 6 , hexagons 7 , or especially more complex shapes 8 depending on their shape 9 , size 10 , interactions 11 , and external fields 12 . These phenomena have garnered considerable focus over the previous few years owing to both basic attention 13 and possible use 14 - 16 .A notably important example is provided by colloidal suspensions 17 - 20 : When these are subjected to powerful shear flows 21 , they frequently exhibit striped cycles 22 - 24 whose formation system stays little explained 25 .",
        "ori-fast-z-score": -1.863448669773839,
        "water-fast-z-score": 6.894291116568838
    },
    {
        "original_text": "We calculate the two-loop beta function for the coupling constant of the AdS5xS5 superstring theory and show that it is proportional to the one-loop result, which implies that there are no non-trivial fixed points at any finite value of the string coupling constant.  We also find that the dilaton field has an imaginary part when we take into account the higher-order terms beyond the leading order approximation. This indicates that our results may be valid only within some limited region of the parameter space where the imaginary part of the dilaton can be neglected. The present work was motivated by the recent study on the gauge/gravity correspondence between N=4 super Yang-Mills (SYM) theories with 16 supercharges and type IIB strings on AdS5xS5G5 backgrounds  1  . In this context, the existence of nontrivial fixed points would correspond to the conformal invariance of the dual SYM theories  2  , while the imaginary part of the dilatonic scalar fields would indicate the instability of the corresponding solutions  3  .\nIn Ref.  4  , the authors have calculated the one-loop beta functions for both the metric tensor and the dilaton field using the Green-Schwarz formalism  5  . They found that these beta functions do not vanish even if they are evaluated at vanishing values of the string coupling constants. However, their calculations were performed under the assumption that all the fermionic contributions vanish identically  6  . It turns out that such an assumption does not hold true  7, 8  . Therefore, it seems necessary to perform more detailed analysis taking into account the effects due to the fermions as well as those coming from the bosons.",
        "watermark_text": "We calculate the two - loop beta function for the coupling constant of the AdS5xS5 superstring theory and find that it is proportional to the one - loop result , which implies that there are no non - trivial fixed points at any finite value of the string coupling constant . We additionally find that the dilaton field has an imaginary part when we took into consideration the higher - order terms beyond the led order approximation .This implies that our findings may be valid only within some restricted region of the parameter space where the imaginary part of the dilaton can be forgotten . The present work was motivated by the recent study on the gauge / gravity correspondence between N = 4 super Yang - Mills ( SYM ) theories with 16 supercharges and class IIB sequences on AdS5xS5G5 backgrounds 1 .In this situation , the existence of nontrivial fixed points would coincide to the conformal invariance of the dual SYM theories 2 , while the imaginary part of the dilatonic scalar fields might suggest the instability of the equivalent solutions 3 . In Ref .4 , the papers have predicted the one - loop beta functions for both the metric tensor and the dilaton field using the Green - Schwarz formalism 5 . They found that these beta distributions do not vanish even if they are evaluated at vanishing values of the string coupling constants .However , their analyses were performed under the assumption that all the fermionic contributions vanish identically 6 . It turns out that such an assume does not stand true 7 , 8 .Therefore , it appears necessary to conduct more precise analysis taking into consideration the effects due to the fermions as also as those coming from the bosons .",
        "ori-fast-z-score": -0.2847473987257497,
        "water-fast-z-score": 5.362108949786505
    },
    {
        "original_text": "We present the results of our analysis on quiet sun magnetograms obtained by Hinode/SOT/SP and SDO/HMI instruments, which are compared with those simulated using an MHD model. The observed data were processed to remove instrumental effects such as stray light contamination and spatial smearing due to finite pixel size. We found that the simulated magnetograms reproduce well the main features in the observed ones; however there is still room for improvement especially regarding the fine structures seen in the observed magnetograms. \n \n Keywords: Solar activity, Magnetohydrodynamics (MHD), Quiet Sun, Space weathering, Solar atmosphere, Magnetic field strength, Photospheric plasma flows, Solar surface convection, Solar dynamo, Solar irradiance variability, Solar cycle, Solar corona, Solar flares, Solar prominences, Solar winds, Solar energetics, Solar physics, Solar interior, Solar rotation",
        "watermark_text": "We present the conclusion of our analysis on silent solar magnetograms acquired by Hinode / SOT / SP and SDO / HMI instruments , which are compared with those modeled using an MHD model . The observed measurements were processed to remove instrumental impacts such as stray light degradation and spatial smearing due to finite pixel size .We determined that the simulated magnetograms reproduce well the main features in the seen ones ; however there is already room for improvement especially regarding the fine structures visible in the observed magnetograms . Keywords : Solar activity , Magnetohydrodynamics ( MHD ) , Quiet Sun , Space weathering , Solar atmosphere , Magnetic field intensity , Photospheric plasma flows , Solar surface convection , Solar dynamo , Solar irradiance variability , Solar cycle , Solar corona , Solar flares , Solar prominences , Solar winds , Solar energetics , Solar chemistry , Solar interior , Solar rotation",
        "ori-fast-z-score": -0.7878385971583353,
        "water-fast-z-score": 2.888741522913896
    },
    {
        "original_text": "We have studied by means of molecular dynamics simulations how the dynamic behavior of silver atoms deposited on gold (100) is affected when the substrate temperature and the coverage are varied in such a way that the average number of nearest neighbors per atom changes between 1 to 4. We find that, for low coverages, the system behaves as if it were made up of isolated particles with no interaction among them. However, at higher coverages we observe collective effects which lead to the formation of ordered structures. The results obtained show that these structures can be classified into two different categories depending on whether they are formed by one or more layers of silver atoms. In particular, we found that the structure of the first layer depends strongly on the substrate temperature while the second layer shows only small variations. Finally, our calculations indicate that the third layer forms a disordered arrangement of silver atoms. This work was supported by DGESIC under project PB98-0443-C02-01",
        "watermark_text": "We have researched by means of molecular dynamics simulations how the dynamic behavior of silver atoms deposited on gold ( 100 ) is affected when the substrate temperature and the coverage are varied in such a way that the average number of nearest neighbors per atom shifts between 1 to 4 . We see that , for low coverages , the system behaves as if it were made up of isolated molecules with no activity among them .However , at higher coverages we study collective effects which lead to the formation of ordered systems . The results collected show that these structures can be categorized into two different categories depending on whether they are created by one or more bands of silver atoms .In particular , we reported that the composition of the first layer relies highly on the substrate temperature while the second layer exhibits only tiny variations . Finally , our calculations suggest that the third layer makes a disordered arrangement of silver atoms .This project was supported by DGESIC under contract PB98 - 0443 - C02 - 01",
        "ori-fast-z-score": 1.2701705922171767,
        "water-fast-z-score": 6.1942248145051675
    },
    {
        "original_text": "We present the results of our investigation into accretion disk continuum emission in black hole candidates (BHCs). We have developed an analytical model for calculating the spectrum emitted by a thin, optically thick accretion disk around a Schwarzschild black hole and applied it to several BHCs with known mass functions. The observed spectra are well reproduced when we assume that the inner edge of the disk is located at 6 gravitational radii. This result suggests that the standard thin disk model can be used as a good approximation for modeling the X-ray continuum emission of these objects. \n \n Keywords: Black holes -- Spectroscopy -- X-rays -- Modeling -- Accretion disks -- Emission lines -- Broad-band spectral energy distribution -- Luminosity function -- Mass measurement -- Stellar-mass black holes -- Supermassive black holes -- Active galactic nuclei -- Quasars -- Cosmic evolution \n \n \n \n 1 Introduction \n \n In recent years there has been considerable progress made towards understanding the physical processes occurring near supermassive black holes (SMBH) in active galactic nuclei (AGN), quasars, and other similar systems. These studies rely on observations of the broad-band spectral energy distributions (SEDs) of SMBHs over many decades in frequency space. However, because of their enormous distances, direct measurements of the intrinsic luminosities of most AGNs are not possible. Instead, one must use indirect methods such as reverberation mapping or statistical correlations between various properties of AGNs to determine their luminosities. For example, if one knows how much light passes through some region of interest within an AGN then one may calculate its luminosity using simple geometric arguments. Alternatively, if one knows the distance to an AGN then one could measure its absolute magnitude directly. Unfortunately, both of these approaches require detailed knowledge about the structure of the emitting regions which cannot currently be obtained observationally. Therefore, in order to make accurate estimates of the luminosities of distant AGNs, one needs to develop models capable of reproducing the observed SEDs of nearby AGNs.",
        "watermark_text": "We present the conclusion of our inquiry into accretion disk continuum emission in black hole candidates ( BHCs ) . We have developed an analytical theory for determining the spectrum emitted by a thin , optically dense accretion disk around a Schwarzschild red hole and applied it to several BHCs with reported mass distributions .The observed spectra are better illustrated when we suppose that the inner corner of the disk is situated at 6 gravitational radii . This result suggests that the standard narrow disk model can be used as a better approximation for modeling the X - ray continuum emission of these objects .Keywords : Black holes - - Spectroscopy - - X - rays - - Modeling - - Accretion disks - - Emission lines - - Broad - band spectral energy distribution - - Luminosity function - - Mass measurement - - Stellar - mass black holes - - Supermassive black holes - - Active galactic nuclei - - Quasars - - Cosmic evolution 1 Introduction In recent years there has been increased progress conducted towards exploring the physical processes occurring near supermassive black holes ( SMBH ) in active galactic nuclei ( AGN ) , quasars , and other similar systems . These studies rely on observations of the broad - band spectral energy distributions ( SEDs ) of SMBHs over many decades in frequency space .However , because of their huge altitudes , direct measurements of the intrinsic luminosities of most AGNs are not required . Rather , one must use indirect tools such as reverberation projection or statistical correlations between various properties of AGNs to obtain their luminosities .For instance , if one remembers how many light passes through some region of interest within an AGN then one may calculate its luminosity taking simple geometric arguments . Alternatively , if one understands the distance to an AGN then one might estimate its absolute magnitude directly .Unfortunately , both of these perspectives need rigorous knowledge about the composition of the emitting regions which lacks already be obtained observationally . Therefore , in order to make accurate calculations of the luminosities of distant AGNs , one needs to develop models capable of reproducing the known SEDs of neighbouring AGNs .",
        "ori-fast-z-score": -0.9733285267845753,
        "water-fast-z-score": 5.028864055053639
    },
    {
        "original_text": "The present work is an attempt to show that the concept of time can be extended into a higher-dimensional space, and that this extension may have important consequences for our understanding of physical phenomena.  The author considers the possibility that there are five dimensions of space (four ordinary spatial dimensions plus one extra temporal dimension) which could explain some of the observed properties of matter such as entropy production and irreversibility.   In particular he shows how the existence of these additional dimensions would lead to a violation of the principle of entropy increase with time, and suggests that this might provide a possible explanation for the arrow of time. This article is available from: http://arxiv.org/abs/astro-ph/0403070v1. Introduction:  Time has always been considered by physicists as being fundamentally different from other quantities like position or velocity because it cannot be measured directly but only inferred indirectly through its effects on other measurable quantities.  However, recent developments in theoretical physics suggest that we should consider whether the concept of time itself needs to be modified so that it becomes more closely related to other fundamental concepts such as mass, charge and energy.  For example, string theory predicts that all particles are vibrating strings moving along a multidimensional space called  space-time   1  .    Another approach involves considering the possibility that time is not just another quantity but rather part of a larger structure known as spacetime  2  , where the latter consists of both space and time together  3  .  According to this viewpoint, time is no longer regarded as something separate from space; instead they are viewed as two aspects of the same thing  4  .\nIn fact, many modern theories of quantum gravity predict that the universe contains at least three large scale dimensions - namely length, width and height  5  - while also containing a fourth small-scale dimension  6  .",
        "watermark_text": "The present work is an attempt to see that the notion of time can be enlarged into a higher - dimensional space , and that this extension may have important implications for our studying of natural behavior . The author considers the prospect that there are five spheres of space ( four ordinary spatial dimensions plus one extra temporal dimension ) which could explain some of the seen characteristics of matter such as entropy production and irreversibility .In particular he shows how the existence of these additional dimensions would result to a violation of the principle of entropy increase with time , and suggests that this might give a possible reason for the arrow of time . This section is accessible from : www : / / arxiv . org / abs / astro - ph / 0403070v1 .Introduction : Time has always been regarded by physicists as being fundamentally changed from other quantities like position or speed because it rarely be understood directly but only inferred indirectly through its consequences on other measurable quantities . However , recent developments in theoretical physics suggest that we should consider whether the notion of time itself needs to be altered so that it becomes more closely related to other fundamental concepts such as mass , charge and energy .For instance , string theory predicts that all atoms are vibrating chords moving along a multidimensional space termed space - time 1 . Another approach requires studying the idea that time is not just another quantity but rather component of a greater formation referred as spacetime 2 , where the former consists of both space and time together 3 .According to this viewpoint , time is no longer regarded as something separate from space ; simply they are regarded as two parts of the same thing 4 . In reality , many contemporary ideas of quantum gravitational suggest that the universe possesses at least three large scale dimensions - including size , length and size 5 - while also containing a third small - scale dimension 6 .",
        "ori-fast-z-score": -0.7373087284671365,
        "water-fast-z-score": 7.511768544535079
    },
    {
        "original_text": "We present new mid-IR photometry and spectroscopy of the HUDF-JD2 galaxy at redshift 2.081, which is one of the most luminous infrared galaxies known to date. The SED shows that it has an extremely red continuum with strong PAH emission features in its rest frame optical spectrum. We find evidence for both star formation activity (from the UV-optical) as well as obscured AGN activity (from X-ray observations). This object may be representative of a population of dusty star-forming galaxies undergoing rapid evolution during this critical epoch when massive black holes are growing rapidly along with their host galaxies. Keywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies",
        "watermark_text": "We present new mid - IR photometry and spectroscopy of the HUDF - JD2 galaxy at redshift 2 . 081 , which is one of the most luminous infrared galaxies known to date . The SED shows that it has an extremely red continuum with strong PAH emission features in its rest frame optical spectrum .We get data for both star formation activity ( from the UV - optical ) as well as obscured AGN activity ( from X - ray observations ) . This object may be representative of a population of dusty star - creating stars undergoing fast evolution during this critical epoch when massive brown holes are growing faster along with their host galaxies .Keywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies",
        "ori-fast-z-score": 0.2886751345948129,
        "water-fast-z-score": 2.3094010767585034
    },
    {
        "original_text": "In this work, we study the spectral efficiency (SE) performance of spectrum pooling systems in which multiple secondary users share the same licensed band with one primary user. We consider two different scenarios for the SE analysis: 1) The case where all secondary users are located at fixed distances away from each other and 2) The case where they are randomly distributed over an area according to some spatial distribution function. In both cases, we assume that there is no direct communication between any pair of secondary users. For scenario 1), we derive closed-form expressions for the ergodic capacity of the system under Rayleigh fading channels as well as Nakagami-m fading channels. Our results show that when the number of secondary users increases, their mutual interference becomes more severe resulting in lower ergodic capacities. However, if the distance between them decreases or equivalently, the density of secondary users increases, then the ergodic capacity improves due to higher signal-to-noise ratio levels.",
        "watermark_text": "In this research , we study the spectral efficiency ( SE ) performance of bandwidth pooling systems in which several secondary users share the same licensed band with one secondary customer . We consider two different scenarios for the SE assessment : 1 ) The case where all secondary users are situated at fixed distances away from each other and 2 ) The case where they are randomly distributed over an area according to some spatial distribution relation .In both cases , we suppose that there is no continuous communication between any pair of secondary users . For scenario 1 ) , we derive closed - form expressions for the ergodic strength of the device under Rayleigh fading filters as well as Nakagami - m fading transmissions .Our results show that when the quantity of secondary users increases , their mutual interference becomes more serious resulting in reduced ergodic capacities . However , if the distance between them grows or equivalently , the density of secondary users increases , then the ergodic strength improves due to higher sound - to - noise ratio levels .",
        "ori-fast-z-score": 1.118033988749895,
        "water-fast-z-score": 5.813776741499453
    },
    {
        "original_text": "We present an equation of state for atomic systems with large scattering lengths, which is obtained in the framework of the lowest-order constrained variational method (LOCV). The LOCV approach allows one to obtain accurate results for both fermions and bosons at low temperatures. We show that our equation of state agrees well with Monte Carlo simulations performed within the grand canonical ensemble. In particular we find good agreement between theory and experiment on the energy per particle of 4 He-4 He mixtures near the superfluid transition temperature T = Tc. Our results are also compared with those obtained using other theoretical approaches such as the virial expansion or the hypernetted chain approximation. \nI. INTRODUCTORY REMARK\nThe equation of state plays an important role in many areas of physics ranging from nuclear matter  1  , quantum gases  2  , astrophysics  3  , condensed matter  4  , etc.. It describes how various thermodynamic quantities depend on each other under given conditions. For example, it can be used to determine the pressure P , chemical potential µ, entropy S, specific heat Cv, compressibility κT , thermal expansivity αp, sound velocity cs, etc., all of them being functions of density n and/or temperature T . Hereafter we will use the symbol EOS to denote any of these quantities.\nIn this work we consider the case when the scattering length a of two particles becomes very large so that the system behaves like a gas of weakly interacting dimers. This situation occurs e.g. in dilute Bose-Einstein condensates  5  where the scattering length may be tuned via Feshbach resonances  6  .\nII. THEORETICAL APPROACHES\n\nA. Grand Canonical Ensemble\nTo describe the properties of a mixture consisting of Nα atoms of species A and Nβ atoms of species B, we employ the grand-canonical ensemble  7, 8  \nwhere H is the total Hamiltonian of the system, β ≡ 1/kB T denotes inverse temperature, μi is the chemical potential of species i ∈ {A, B}, and Z(Nα,",
        "watermark_text": "We present an equation of state for nuclear systems with large scattering lengths , which is achieved in the framework of the lowest - order constrained variational technique ( LOCV ) . The LOCV method enables one to obtain precise conclusions for both fermions and bosons at low temperatures .We see that our equation of state agrees well with Monte Carlo simulations conducted within the grand canonical ensemble . In particular we find good agreement between theoretical and experiment on the power per particle of 4 He - 4 He mixtures near the superfluid transition volume T = Tc .Our results are also compared with those achieved using other theoretical methods such as the virial expansion or the hypernetted chain method . I .INTRODUCTORY REMARK The equation of state plays an important role in different areas of science diverse from nuclear matter 1 , quantum gases 2 , astrophysics 3 , condensed matter 4 , etc . . It expresses how various thermodynamic quantities rely on each other under given conditions .For instance , it can be used to estimate the pressure P , chemical potential µ , entropy S , basic heat Cv , compressibility κT , thermal expansivity αp , noise speed cs , etc . , all of them being functions of density n and / or temperature T . Hereafter we will use the symbol EOS to indicate any of these quantities .In this research we imagine the case when the scattering height a of two particles gets very huge so that the system behaves like a gas of weakly interacting dimers . This condition occurs e . g .in dilute Bose - Einstein condensates 5 where the scattering duration could be tuned via Feshbach resonances 6 . II .THEORETICAL APPROACHES A . Grand Canonical Ensemble To describe the properties of a mixture consisting of Nα atoms of genus A and Nβ elements of genus B , we utilize the grand - canonical ensemble 7 , 8 where H is the total Hamiltonian of the system , β ≡ 1 / kB T denotes inverse temperature , μi is the chemical potential of species i ∈ { A , B } , and Z ( Nα ,",
        "ori-fast-z-score": -0.17407765595569785,
        "water-fast-z-score": 6.44087327036082
    },
    {
        "original_text": "We present an improved semi-analytical method (SAM) that includes gravitational heating by dark matter halos and gas cooling in galaxy formation, which is essential to reproduce observed properties of galaxies such as luminosity functions at different redshifts.  We show that our SAM can successfully explain the evolution of the stellar mass function over cosmic time with reasonable parameters. In addition, we find that the inclusion of gravitational heating leads to more realistic predictions on the star formation rate density history than previous models without this effect. Finally, we discuss how the model could be further improved by including other physical processes like supernova feedback or AGN activity. The results presented here are based on observations made with ESO Telescopes at Paranal Observatory under programme ID 085.A-0488(A). This work was supported by JSPS KAKENHI Grant Number JP15K05481. Figure 1 . Predicted number densities of galaxies as a function of their total stellar masses compared with observational data taken from the literature. Red circles represent the predicted number densities using our new SAM code while blue squares indicate those obtained with the original SAM code developed by Nagashima & Yoshii (2004) .",
        "watermark_text": "We introduce an excellent semi - modelling techniques ( SAM ) that encompasses gravitational heating by black material halos and gas warming in universe formation , which is crucial to reproduce observed properties of stars such as luminosity functions at different redshifts . We suggest that our SAM can effectively predict the evolution of the stellar mass function over cosmic time with satisfactory parameters .In addition , we find that the introduction of gravitational heating results to more realistic predictions on the star formation rate density history than prior models without this effect . Finally , we explain how the model could be further better by including other physical processes like supernova feedback or AGN activity .The results presented here are based on observations made with ESO Telescopes at Paranal Observatory under programme ID 085 . A - 0488 ( A ) . This project was supported by JSPS KAKENHI Grant Number JP15K05481 .Figure 1 . Predicted number densities of galaxies as a function of their total stellar masses compared with observational data taken from the literature .Red rings represent the expected number densities using our new SAM code while blue squares correspond those acquired with the previous SAM code developed by Nagashima & Yoshii ( 2004 ) .",
        "ori-fast-z-score": -0.21081851067789195,
        "water-fast-z-score": 5.346252667281783
    },
    {
        "original_text": "We present new molecular opacity tables that include all relevant molecules in cool, carbon-rich stellar envelopes and are valid over a wide range of temperatures (T = 1000 - 10000 K), densities (ρ = 10 −10 -10 6 g/cm 3 ) and compositions (C/O=0.5-2). The calculations were performed with the state-of-the-art ab initio line-by-line radiative transfer code SPECTRUM using extensive laboratory data on molecular lines as well as theoretical predictions based on quantum chemical methods. We have calculated synthetic spectra for several model atmospheres representative of red giant branch (RGB) and asymptotic giant branch (AGB) stars to demonstrate how our new opacity tables affect their structure and evolution. Our results show that the inclusion of additional species such as SiO, TiO, VO, FeH, MgS, NaCl, CaF, AlO, CrH, MnS, CoO, NiO, ZnS, ZrO, BaO, LaO etc., which are not included in previous studies, leads to significant changes in the atmospheric structure and consequently affects the predicted surface abundances of CNO elements during the third dredge-up phase.",
        "watermark_text": "We create novel molecular opacity lists that include all relevant molecules in cold , carbon - rich stellar envelopes and are applicable over a broad variety of temperatures ( T = 1000 - 10000 K ) , densities ( ρ = 10 −10 - 10 6 g / cm 3 ) and compositions ( C / O = 0 . 5 - 2 ) . The calculations were performed with the state - of - the - art ab initio line - by - line radiative transfer code SPECTRUM combining extensive research data on chemical lines as well as conceptual predictions based on quantum chemical techniques .We have adjusted synthetic spectra for various model atmospheres representative of red dwarf branch ( RGB ) and asymptotic giant branch ( AGB ) stars to indicate how our new opacity tables affect their structure and evolution . Our results show that the inclusion of added species such as SiO , TiO , VO , FeH , MgS , NaCl , CaF , AlO , CrH , MnS , CoO , NiO , ZnS , ZrO , BaO , LaO etc . , which are not mentioned in earlier analyses , leads to significant improvements in the atmospheric composition and consequently affects the expected exterior abundances of CNO compounds during the third dredge - up process .",
        "ori-fast-z-score": -1.585187847802434,
        "water-fast-z-score": 4.755563543407302
    },
    {
        "original_text": "We present the first version of our new code, WHAM (Weno-Hybrid Arbitrary Mesh), which is based on the recently developed weighted essentially non-oscillatory (WENO) schemes for solving hyperbolic conservation laws in one dimension and multi-dimensions.  The main idea behind this method is to use high-order spatial reconstruction with an adaptive mesh refinement technique to achieve high accuracy at low computational cost. We have implemented several different versions of the WENO algorithm into our code including the fifth-order WENO-Z scheme as well as the third- and fifth-order WENO-JS schemes. In addition we also implement the fourth-order Runge-Kutta time integration scheme along with the Harten-Lax-van Leer contact discontinuity capturing scheme to handle discontinuities arising during hydrodynamic evolution. Our results show that all these algorithms are able to produce accurate solutions when compared against exact or reference solutions.",
        "watermark_text": "We introduce the first generation of our new code , WHAM ( Weno - Hybrid Arbitrary Mesh ) , which is based on the recently advanced weighted essentially non - oscillatory ( WENO ) schemes for solving hyperbolic conservation forces in one dimension and multi - dimensions . The main idea behind this algorithm is to use large - order spatial reconstruction with an adaptive mesh refinement technique to achieve high sensitivity at low numerical cost .We have integrated various different versions of the WENO algorithm into our code including the fifth - order WENO - Z plan as also as the third - and fifth - order WENO - JS schemes . In addition we also execute the third - order Runge - Kutta time integration scheme along with the Harten - Lax - van Leer contact discontinuity capturing scheme to manage discontinuities resulting during hydrodynamic evolution .Our results show that all these algorithms are able to produce accurate answers when compared against exact or reference solutions .",
        "ori-fast-z-score": 2.1652509527331207,
        "water-fast-z-score": 6.039910552360811
    },
    {
        "original_text": "We present evidence that the strong equivalence principle (SEP) holds in general relativity at least up to second post Newtonian order, by showing that the SEP is satisfied if it holds at first PN order.  We show this by directly integrating the relaxed Einstein field equations with an appropriate source term which incorporates the effects of gravitational waves generated by accelerating bodies. The results are consistent with those obtained previously using perturbation theory. This work was supported by NSF grant PHY-0456747. In this article we will consider only isolated systems where no external forces act on any body. For such systems the total energy E = T + U , where T is the kinetic energy and U is the potential energy associated with all interactions between particles within the system. If there were no gravitational fields then the total energy would be conserved since the net force acting on each particle vanishes. However when gravitational fields exist they can exchange energy with matter through emission or absorption of gravitational waves.",
        "watermark_text": "We present evidence that the strong equivalence principle ( SEP ) holds in general relativity at least up to second post Newtonian order , by showing that the SEP is fulfilled if it holds at first PN order . We see this by specifically integrating the relaxation Einstein field equations with an appropriate source term which includes the effects of gravitational waves generated by accelerating objects .The results are compatible with those achieved formerly using perturbation theory . This research was supported by NSF grant PHY - 0456747 .In this discussion we will use only isolated systems where no external forces action on any body . For such systems the total energy E = T + U , where T is the kinetic power and U is the potential energy associated with all interactions between particles within the system .If there were no gravity fields then the total energy must be conserved since the net force acting on each particle vanishes . However when gravity fields arise they can trade power with matter through emission or emission of gravitational waves .",
        "ori-fast-z-score": 0.8944271909999159,
        "water-fast-z-score": 5.661385170722978
    },
    {
        "original_text": "We study the problem of finding an optimal schedule for data transmission over multiple channels with interference constraints, where each channel is assigned to one transmitter-receiver pair and transmissions on different pairs are subject to mutual interference. We consider two models: (i) The first model assumes that all transmitters have fixed power levels. (ii) In the second model we assume that transmitters can adjust their powers dynamically. For both cases, we show how to find an optimal schedule by solving a sequence of linear programs. Our results hold even if there exists only one receiver per transmitter. This work was supported by NSF grant CCF-0430018. 1 Introduction Wireless networks consist of many nodes communicating via radio signals. Each node has limited range and thus cannot communicate directly with every other node. Instead, it communicates indirectly through intermediate nodes called relays or routers. A fundamental question in this context is: How should these relays be placed?",
        "watermark_text": "We explore the question of finding an appropriate schedule for information transmission over multiple channels with interference constraints , where each channel is allotted to one transmitter - receiver set and signals on separate pairs are subject to mutual interference . We consider two models : ( i ) The first theory requires that all transmitters have fixed power rates .( ii ) In the second theory we suppose that transmitters can adjust their powers dynamically . For both cases , we show how to find an appropriate schedule by solving a sequence of linear programs .Our results hold even if there exists only one receiver per transmitter . This work was supported by NSF grant CCF - 0430018 .1 Introduction Wireless networks consist of several nodes communicating via radio signals . Each node has restricted range and therefore cannot transmit directly with every other node .Instead , it communicates indirectly through intermediate nodes termed relays or routers . A basic issue in this situation is : How should these relays be placed ?",
        "ori-fast-z-score": -1.0256451881367414,
        "water-fast-z-score": 3.623286509262706
    },
    {
        "original_text": "We present X-ray luminosity functions (XLFs) for normal galaxies at z=0.5-2, based on deep Chandra observations of the Great Observatories Origins Deep Survey-North field. We use photometric redshifts to select galaxy samples with different stellar masses and star formation rates. The XLFs are derived by fitting the observed number counts using a Schechter function plus an exponential cutoff below Lx=1041 erg s-1. Our results show that the faint-end slope is steeper than -1.0 for all mass bins considered here. For massive galaxies (log(M/Msun)>10), we find no significant evolution between z=1.6 and 0.7. However, there appears to be some evidence for evolution towards lower characteristic luminosities as well as flatter slopes at higher redshift. These results suggest that the most massive galaxies may have evolved into less luminous systems over time.  We also compare our results with previous studies which used shallower data or smaller sample sizes.",
        "watermark_text": "We create X - ray luminosity functions ( XLFs ) for normal galaxies at z = 0 . 5 - 2 , relying on deep Chandra measurements of the Great Observatories Origins Deep Survey - North area . We use photometric redshifts to select galaxy samples with various stellar masses and sun formation rates .The XLFs are derived by fitting the observed number counts using a Schechter function plus an exponential cutoff below Lx = 1041 erg s - 1 . Our results show that the faint - end slope is steeper than - 1 . 0 for all mass bins included here .For huge objects ( log ( M / Msun ) > 10 ) , we find no considerable evolution between z = 1 . 6 and 0 . 7 . However , there seems to be some evidence for expansion towards lesser characteristic luminosities as well as flatter slopes at higher redshift .These conclusions show that the most large galaxies must have transformed into fewer luminous systems over time . We additionally compare our findings with previous research which using shallower evidence or smaller data numbers .",
        "ori-fast-z-score": -1.0681034923744679,
        "water-fast-z-score": 5.656854249492381
    },
    {
        "original_text": "We present an algorithm to construct the reduced basis space in the context of nonlinear problems with multiple solutions, which is based on the concept of quasi-equilibrium grid (QEG). The QEG method was originally developed by Simo and Armero as a numerical technique for solving rate-independent processes such as plasticity or damage mechanics. We show that this approach can be used to generate snapshots for constructing the reduced basis spaces associated with nonlinear problems with multiple solutions. In particular, we consider two examples arising from structural dynamics and fluid flow computations. Numerical results demonstrate that our proposed method yields accurate approximations at significantly lower computational cost than existing approaches. Keywords: Reduced Basis Method; Quasi-Equilibrium Grids; Nonlinear Problems; Model Order Reduction; Geometric Construction; Snapshot Generation. 1 Introduction.\nThe goal of this work is to develop efficient algorithms for generating snapshots for constructing the RB spaces associated with nonlinear problems having multiple solutions. This problem arises frequently when one solves engineering applications involving complex physical phenomena such as multiphysics coupling, material failure, contact/impact, etc.. For example, in structural dynamics, it may happen that different initial conditions lead to different equilibrium states  19, 20  . Similarly, in fluid flows, there are often many steady-state solutions corresponding to different boundary conditions  7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18  .\nIn order to solve these types of problems efficiently using the reduced basis method (RBM), it is necessary to have a good set of snapshots representing all possible solution behaviors. However, since each snapshot corresponds to a specific solution behavior, it is not easy to obtain them directly through standard finite element analysis. Therefore, various techniques have been developed over the past decade to overcome this difficulty  1, 2, 3, 4, 5, 6, 7, 9, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40",
        "watermark_text": "We present an algorithm to build the reduced basis space in the context of nonlinear issues with many solutions , which is based on the idea of quasi - equilibrium grid ( QEG ) . The QEG method was originally developed by Simo and Armero as a numerical technique for solving rate - based processes such as plasticity or damage mechanics .We see that this methodology can be used to create snapshots for constructing the reduced basis sets associated with nonlinear issues with many solutions . In particular , we define two examples arising from functional dynamics and fluid stream computations .Numerical results show that our proposed approach produces accurate approximations at significantly reduced theoretical cost than existing techniques . Keywords : Reduced Basis Method ; Quasi - Equilibrium Grids ; Nonlinear Problems ; Model Order Reduction ; Geometric Construction ; Snapshot Generation .1 Introduction . The goal of this project is to develop fast algorithms for generating snapshots for constructing the RB spaces related with nonlinear issues having many solutions .This problem arises often when one solves engineering applications requiring complex physical phenomena such as multiphysics coupling , structure crash , touch / explosion , etc . . For instance , in structural physics , it could happen that different initial conditions lead to different equilibrium states 19 , 20 . Similarly , in flow flows , there are often many steady - condition solutions corresponding to different boundary rules 7 , 8 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 .In order to solve these kinds of problems easily using the reduced basis method ( RBM ) , it is required to have a good collection of snapshots describing all possible solution behaviors . However , since each snapshot belongs to a certain solve behavior , it is not straightforward to obtain them directly through conventional finite element extraction .Therefore , various methods have been used over the previous decade to overcome this obstacle 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40",
        "ori-fast-z-score": -1.5888598190134724,
        "water-fast-z-score": 8.0
    },
    {
        "original_text": "We present the results of an investigation into the physical nature of polar broad absorption line quasars (BALQSOs). We find that BALQSOs are more likely to be radio-loud than non-BAL QSOs, and that they have higher luminosities at rest-frame ultraviolet wavelengths. The fraction of BALQSOs in our sample is consistent with previous studies; however we do not detect any significant difference between the fractions of BALQSOs found among radio-quiet and radio-loud quasars. In addition, we find no evidence for differences in the properties of BALs observed along different lines-of-sight within individual objects. Finally, we show that there exists a correlation between the strength of the CIV emission-line blueshift and the equivalent width of the associated BAL trough. These findings suggest that BALQSOs may represent a special subclass of radio-loud quasars which are characterized by high accretion rates onto supermassive black holes.",
        "watermark_text": "We present the conclusion of an research into the physical nature of polar wide absorption line quasars ( BALQSOs ) . We see that BALQSOs are more likely to be radio - loud than non - BAL QSOs , and that they have greater luminosities at rest - frame ultraviolet wavelengths .The percentage of BALQSOs in our sample is compatible with previous research ; however we do not detect any large change between the fractions of BALQSOs discovered among radio - quiet and radio - loud quasars . In addition , we find no evidence for variations in the properties of BALs observed along various lines - of - view within particular objects .Finally , we prove that there exists a correlation between the strength of the CIV radiation - line blueshift and the equivalent size of the associated BAL trough . These conclusions propose that BALQSOs might represent a unique subclass of radio - loud quasars which are marked by high accretion speeds onto supermassive black holes .",
        "ori-fast-z-score": 0.5,
        "water-fast-z-score": 6.573840933228048
    },
    {
        "original_text": "We present results from direct cosmological hydrodynamic simulations that follow the formation of supermassive black holes (SMBHs) in galactic nuclei, their subsequent evolution through mergers with other SMBHs, and the associated feedback on galaxy properties. We find that:  The simulated SMBH mass function agrees well with observations at z = 0 for M• > 10^7M_solar.  At higher redshifts, our model predicts too many low-mass SMBHs compared to observational estimates based on quasar luminosity functions; this discrepancy may be due to uncertainties in the assumed duty cycle or radiative efficiency of quasars.  Our models predict an average Eddington ratio distribution that is consistent with observed distributions inferred from optical/UV emission lines.  In addition, we show that the predicted relation between BH mass and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass.",
        "watermark_text": "We present results from direct cosmological hydrodynamic simulations that take the formation of supermassive black holes ( SMBHs ) in galactic nuclei , their ensuing evolution through mergers with other SMBHs , and the associated feedback on star dynamics . We see that : The simulated SMBH weight distribution agrees well with observations at h = 0 for M • > 10 ^ 7M _ solar .At higher redshifts , our model predicts too many lowest - weight SMBHs compared to observational projections based on quasar luminosity functions ; this discrepancy may be due to uncertainties in the expected duty cycle or radiative efficiency of quasars . Our models predict an estimated Eddington density distribution that is compatible with observed distributions inferred from optical / UV absorption lines .In addition , we prove that the expected relation between BH weight and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass .",
        "ori-fast-z-score": -0.508000508000762,
        "water-fast-z-score": 4.318004318006477
    },
    {
        "original_text": "We propose to use hierarchical hidden Markov random fields (HHMRFs) as the underlying model in an unsupervised segmentation algorithm for hyperspectral images. The HHMRFs are constructed by combining several layers of hidden Markov chains, where each layer is associated with one particular spatial scale. We show that this multiscale approach leads to improved performance over single-scale methods and we demonstrate its effectiveness on two different data sets. Finally, we compare our results against those obtained using state-of-the-art algorithms based on Gaussian mixture models or sparse coding techniques. \nIntroduction\n\nHyperspectral imaging has become increasingly popular during recent years due to advances in sensor technology  1  . In contrast to conventional color cameras which capture only three bands per pixel, hyperspectral sensors can record hundreds of narrow spectral bands simultaneously  2  , leading to high-dimensional data volumes. This poses new challenges both in terms of storage requirements and computational complexity  3  .\nIn many applications it would be desirable to perform automatic analysis of such large amounts of data without any prior knowledge about the scene being observed  4  . One important task in this context is the detection of homogeneous regions within the image  5  . These so-called segments may correspond to individual objects  6  , but they could also represent parts of larger structures like buildings  7  or roads  8  .",
        "watermark_text": "We suggest to use hierarchical hidden Markov random fields ( HHMRFs ) as the fundamental design in an unsupervised segmentation algorithm for hyperspectral pictures . The HHMRFs are built by combining several elements of hidden Markov chains , where each layer is associated with one certain spatial scale .We suggest that this multiscale approach leads to improved performance over double - scale techniques and we prove its effectiveness on two different data sets . Finally , we compare our findings against those achieved using state - of - the - art algorithms based on Gaussian mixture models or dense coding techniques .Introduction Hyperspectral photography has become especially popular during recent years owing to advances in sensor technology 1 . In comparison to conventional color cameras which capture only three bands per pixel , hyperspectral cameras can display hundreds of broad wavelength lines simultaneously 2 , leading to large - dimensional data capacities .This poses novel challenges both in terms of storage needs and computational capability 3 . In many applications it would be desirable to conduct automatic analysis of such substantial amounts of evidence without any earlier knowledge about the scene being detected 4 .One important task in this context is the observation of homogeneous parts within the image 5 . These so - called features could belong to individual objects 6 , but they may sometimes reflect parts of bigger structures like houses 7 or roads 8 .",
        "ori-fast-z-score": 0.09245003270420485,
        "water-fast-z-score": 7.613508865259127
    },
    {
        "original_text": "We present new models for non-abelian string networks, which are based on the idea that the network is composed by many entangled strings with different velocities and orientations. We show how to construct such velocity-dependent models in terms of Feynman diagrams. In particular we consider two types of diagrams: (i) ladder-like diagrams corresponding to the exchange of gluons between pairs of strings, (ii) cross-ladder like-diagrams describing interactions among three or more strings. The latter type of diagrams can be interpreted as representing junctions where several strings meet at one point. We discuss some properties of these models and compare them with previous results obtained within the framework of Abelian-Higgs model. Finally, we study numerically the evolution of an initial configuration consisting of a single straight string into a complicated tangle of interacting strings using Monte Carlo simulations. This work was supported by the DFG under contract SFB-TR9  Gravitational Physics ",
        "watermark_text": "We introduce novel theories for non - abelian string systems , which are based on the idea that the network is composed by many entangled strings with various velocities and orientations . We see how to build such velocity - dependent models in terms of Feynman diagrams .In particular we define two forms of diagrams : ( i ) ladder - like diagrams corresponding to the transfer of gluons between pairs of sequences , ( ii ) cross - ladder like - diagrams describing relationships among three or more strings . The last sort of diagrams can be interpreted as representing junctions where many strings join at one point .We discuss some properties of these models and link them with previous findings obtained within the framework of Abelian - Higgs system . Finally , we study numerically the evolution of an initial structure consisting of a single straight string into a complicated tangle of interacting strings using Monte Carlo simulations .This project was supported by the DFG under contract SFB - TR9 Gravitational Physics",
        "ori-fast-z-score": 0.9847319278346618,
        "water-fast-z-score": 5.41602560309064
    },
    {
        "original_text": "We present the results of our analysis of the effects of cosmic rays on galaxy clusters, using cosmological hydrodynamic simulations with and without CRs. We find that the presence of CRs leads to an increase in gas temperature at large radii (r > 0.5Rvir) due to adiabatic compression of the ICM during cluster formation. The effect is more pronounced for higher values of the initial magnetic field strength. In addition we find that there are significant differences between the radial profiles of X-ray surface brightness obtained with and without CRs which can be used as observational signatures of their presence. Finally, we show that the inclusion of CRs has little impact on the global properties such as total mass or luminosity but does affect the distribution of metals within the cluster. This work was supported by NASA grant NAG5-9998. Cosmological hydrodynamical simulations were performed using Enzo developed by the Laboratory for Computational Astrophysics at the University of California, San Diego.",
        "watermark_text": "We present the conclusion of our analysis of the effects of cosmic rays on star clusters , using cosmological hydrodynamic simulations with and without CRs . We see that the presence of CRs causes to an increase in gas temperature at large radii ( r > 0 . 5Rvir ) due to adiabatic compression of the ICM during cluster formed .The phenomenon is more pronounced for greater values of the first magnetic force power . In addition we find that there are significant variations between the transverse characteristics of X - ray exterior illumination obtained with and without CRs which can be used as observational signatures of their presence .Finally , we prove that the integration of CRs has little impact on the global properties such as total mass or luminosity but does affect the distribution of metals within the cluster . This research was supported by NASA grant NAG5 - 9998 .Cosmological hydrodynamical simulations were performed using Enzo developed by the Laboratory for Computational Astrophysics at the University of California, San Diego.",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "We present the demographics and properties of transition objects in SDSS DR7, which are defined as galaxies with both emission lines (ELGs) and absorption features (AGNs). We find that there is an excess number of ELG-AGN pairs at small separations compared to random distributions. The fraction of AGNs among all ELGs increases towards lower luminosities. There appears to be no significant difference between the fractions of AGNs found within different types of ELGs. These results suggest that some ELGs may harbor hidden AGNs. This work was supported by NASA grant NNX10AD65G. We thank the anonymous referee for helpful comments on this manuscript. In recent years, it has been shown that many active galactic nuclei (AGNs), especially those with low luminosity or obscured by dusty torii, have strong emission line components (see e.g., Ho et al. (1997) , Hao et al. (2005) ), making them appear like normal star-forming galaxies when observed through optical spectroscopic surveys such as Sloan Digital Sky Survey (SDSS; York et al. (2000) ) .\nIn order to identify these  transition objects , we use two criteria based on their spectral energy distribution (SED): 1) they must show both emission lines (ELGs; see Section 2.1 below) and absorption features (Section 2.2) simultaneously; and 2) they should not be classified as quasars according to the BPT diagram (Baldwin et al. 1981 , Kewley et al. 2001 . By applying these selection criteria to the entire sample of galaxies in the seventh data release (DR7; Abazajian et al. 2009 ) of the SDSS, we obtain a total of 16,082 transition objects out of a parent sample of 3,962,843 galaxies.",
        "watermark_text": "We present the demographics and features of transfer objects in SDSS DR7 , which are specified as galaxies with both emission lines ( ELGs ) and emission elements ( AGNs ) . We see that there is an excess amount of ELG - AGN pairs at small separations compared to random distributions .The percentage of AGNs among all ELGs increases towards less luminosities . There seems to be no major variation between the fractions of AGNs observed within various types of ELGs .These data suggest that some ELGs might harbor hidden AGNs . This research was supported by NASA grant NNX10AD65G .We thank the anonymous referee for useful comments on this manuscript . In recent years , it has been shown that several active galactic nuclei ( AGNs ) , particularly those with poor luminosity or obscured by dusty torii , have strong emitted path constituents ( saw e . g . , Ho et al .( 1997 ) , Hao et al . ( 2005 ) ) , making them seem like usual star - creating galaxies when observed through optical spectroscopic studies such as Sloan Digital Sky Survey ( SDSS ; York et al .( 2000 ) ) . In order to identify these transition objects , we using two requirements according on their spectral power distribution ( SED ) : 1 ) they must show both emission lines ( ELGs ; seeing Section 2 . 1 below ) and emission elements ( Section 2 . 2 ) simultaneously ; and 2 ) they should not be categorized as quasars according to the BPT chart ( Baldwin et al .1981 , Kewley et al . 2001 .By applying these selection criteria to the entire sample of galaxies in the seventh data release ( DR7 ; Abazajian et al . 2009 ) of the SDSS , we obtain a total of 16 , 082 transition objects out of a parent sample of 3 , 962 , 843 galaxies .",
        "ori-fast-z-score": -3.104378865665871,
        "water-fast-z-score": 4.308294733275792
    },
    {
        "original_text": "We have analyzed the pulse profiles in two energy bands (3-20 keV, 20-100 keV) for 4U0115+63 using data obtained by the Rossi X-ray Timing Explorer (RXTE). The results show that there is no significant difference between these two energy bands except at phase 0.7-0.9 where we see an excess emission above 100 keV. We also find that this source shows a double peaked profile with a dip around phase 0.5 which can be explained as due to absorption effects on the line-of-sight. In addition, we have used data from the International Gamma-Ray Astrophysics Laboratory (INTEGRAL), which has detected cyclotrons lines near 30 keV and 60 keV respectively. Using our model parameters derived from the RXTE data analysis, we are able to reproduce both the observed pulse profiles and the cyclotrons line energies simultaneously.",
        "watermark_text": "We have analyzed the pulse profiles in two energy bands ( 3 - 20 keV , 20 - 100 keV ) for 4U0115 + 63 utilizing information obtained by the Rossi X - ray Timing Explorer ( RXTE ) . The results show that there is no major variation between these two energy bands except at phase 0 . 7 - 0 . 9 where we saw an excess emission above 100 keV .We additionally find that this source shows a double peaked feature with a dip around phase 0 . 5 which can be understood as owing to absorption effects on the line - of - view . In addition , we have utilized information from the International Gamma - Ray Astrophysics Laboratory ( INTEGRAL ) , which has detected cyclotrons lines near 30 keV and 60 keV respectively .Using our model values generated from the RXTE information study , we are able to predict both the seen beam profiles and the cyclotrons line values concurrently .",
        "ori-fast-z-score": 0.13736056394868904,
        "water-fast-z-score": 4.354648431614539
    },
    {
        "original_text": "The measurement of ultra-low potassium contaminations in silicon is important for the development and production of semiconductor devices, especially solar cells. The detection limit of conventional methods such as flame photometry or atomic absorption spectroscopy (AAS) is not sufficient to meet the requirements set by industry standards. In this work we present an alternative method based on accelerator mass spectrometry (AMS). We show that AMS can be used to measure potassium concentrations down to 10(-12) at% K in Si samples. This corresponds to a sensitivity improvement by three orders of magnitude compared to standard techniques like flame photometry. Furthermore, our results demonstrate that AMS has no significant matrix effects when measuring low-potassium doped Si wafers. Finally, we discuss possible applications of AMS beyond its use as a highly sensitive analytical tool. Keywords: Silicon wafer, Accelerator mass spectrometry, Flame photometry",
        "watermark_text": "The measurement of ultra - low potassium contaminations in silicon is important for the development and production of semiconductor devices , particularly solar devices . The measurement limit of typical techniques such as flame photometry or atomic absorption spectroscopy ( AAS ) is not reasonable to meet the requirements set by industry standards .In this research we present an different method using on accelerator mass spectrometry ( AMS ) . We see that AMS can be used to measure potassium levels down to 10 ( - 12 ) at % K in Si samples .This corresponds to a sensitivity difference by three orders of magnitude compared to standard methods like fire photometry . Furthermore , our findings show that AMS has no considerable matrix impacts when examining low - potassium doped Si wafers .Finally , we discuss possible use of AMS beyond its use as a highly sensitive diagnostic tool . Keywords : Silicon wafer , Accelerator mass spectrometry , Flame photometry",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "We present new near-infrared (NIR) and millimeter-wave observations of the starless dense core FeSt 1-457, which is located in the Taurus molecular cloud complex at a distance of 140 pc. The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 May 24-25 UT. We detected two sources within the central 0.5 arcmin region; one source was found to be associated with an infrared dark cloud (IRDC), while another source was not. Both sources are embedded deeply inside the dusty envelope surrounding the dense core. In addition, we observed this object simultaneously with the Nobeyama 45 m radio telescope at 1 mm wavelength during the same night as our NIR observation. No significant emission line features were seen in either spectrum. Using these observational results, we discuss possible scenarios for the formation of stars in such a young dense core.",
        "watermark_text": "We report new near - infrared ( NIR ) and millimeter - wave studies of the starless rich core FeSt 1 - 457 , which is situated in the Taurus molecular mist complex at a distance of 140 pc . The NIR data were obtained with the Subaru observatory using the SofI camera on 2005 May 24 - 25 UT .We observed two sources within the inner 0 . 5 arcmin region ; one source was reported to be involved with an infrared shadow cloud ( IRDC ) , while another source was not . Both sources are lodged deeply inside the dusty envelope surrounding the dense core .In addition , we studied this body simultaneously with the Nobeyama 45 m radio telescope at 1 mm frequency during the same night as our NIR observation . No notable emission line characteristics were witnessed in either spectrum .Using these observational results , we explain possible strategies for the formation of stars in such a young dense core .",
        "ori-fast-z-score": -0.8962581595302719,
        "water-fast-z-score": 4.572004572006858
    },
    {
        "original_text": "The Megapie (Megavoltage Ionization Projection Imaging Experiment) is an experiment designed to study the feasibility and performance of proton radiography for medical applications. The main goal of this project was to develop a compact, high intensity ion source based on laser-plasma interaction in order to produce protons with energies up to several hundred MeV. In addition, it has been shown that such sources can be used as targets for neutron production by spallation reactions induced by energetic ions. This work presents results obtained during experiments performed at GSI Darmstadt using a pulsed deuteron beam accelerated by the SIS-18 synchrotron accelerator. Neutrons produced by the D+D reaction were detected by means of two fission chambers placed around the target chamber. A detailed analysis of these data allowed us to determine the number of neutrons emitted per incident deuteron particle and their energy distribution.",
        "watermark_text": "The Megapie ( Megavoltage Ionization Projection Imaging Experiment ) is an project meant to study the feasibility and performance of proton radiography for medical uses . The main goal of this project was to develop a compact , large intensity particle channel relying on laser - plasma interaction in order to produce protons with intensity up to several hundred MeV .In addition , it has been shown that such sources can be used as targets for neutron production by spallation reactions generated by energetic ions . This research provides findings obtained during experiments conducted at GSI Darmstadt involving a pulsed deuteron light accelerated by the SIS - 18 synchrotron accelerator .Neutrons created by the D + D process were detected by means of two fission chambers put around the target chamber . A precise analysis of these information permitted us to predict the quantity of neutrons emitted per incident deuteron particle and their power distribution .",
        "ori-fast-z-score": 0.762000762001143,
        "water-fast-z-score": 7.112007112010668
    },
    {
        "original_text": "We have studied the thick brane model in which our universe is embedded into an extra dimension and found that it can explain some recent observations such as cosmic microwave background anisotropy, supernovae Ia data and baryon acoustic oscillations without introducing any new physics beyond standard model. \n \n In this model, we assume that there exists a scalar field whose potential has two degenerate minima at different values of the vacuum expectation value (VEV). The VEVs are determined by the parameters of the potential. We find that if the difference between these VEVs is large enough to satisfy the condition for the existence of stable domain walls then the thickness of the wall becomes larger than the Hubble radius today. This means that the domain walls cannot be produced during inflationary epoch. On the other hand, if the difference between these vacua is small compared to the Hubble scale, the domain walls will be created after inflation but they decay before nucleosynthesis era due to their extremely high tension.",
        "watermark_text": "We have researched the deep brane model in which our universe is anchored into an additional dimension and found that it can describe some latest measurements such as cosmic microwave background anisotropy , supernovae Ia data and baryon acoustic oscillations without exploring any new science beyond standard model . In this description , we suppose that there exists a scalar field whose potential has two degenerate minima at different values of the vacuum expectation value ( VEV ) .The VEVs are decided by the variables of the potential . We see that if the difference between these VEVs is huge enough to meet the requirement for the existence of stable domain barriers then the length of the wall grows larger than the Hubble diameter today .This implies that the domain barriers cannot be formed during inflationary epoch . On the other hand , if the difference between these vacua is tiny relative to the Hubble scale , the domain barriers will be formed after inflation but they decay before nucleosynthesis era due to their extremely raised tension .",
        "ori-fast-z-score": -2.629502940535666,
        "water-fast-z-score": 4.063777271736939
    },
    {
        "original_text": "We study the global properties of solar active regions by using high-resolution magnetograms, vector magnetic fields (VMB), and photospheric velocity maps obtained with Hinode/SOT/SP. We find that there is an anti-correlation between the inclination angle of the coronal field lines at the PILs and the amount of newly emerged flux in ARs. The correlation coefficient decreases as we go to higher latitudes. This suggests that the emergence of new flux plays an important role for determining the structure of the coronal field above the PILs. In addition, we found that the distribution of the inclination angles of the coronal field line depends on their distance from the center of the sunspot group. The results suggest that the evolution of the coronal field can be understood if one takes into account both the emergence of new flux and the differential rotation. Keywords: Coronal field, Active region",
        "watermark_text": "We research the global properties of solar active regions by using high - resolution magnetograms , vector magnetic fields ( VMB ) , and photospheric velocity maps obtained with Hinode / SOT / SP . We see that there is an counter - correlation between the inclination angle of the coronal field lines at the PILs and the quantity of newly emerged flux in ARs .The relationship coefficient drops as we move to higher latitudes . This implies that the emergence of new flux serves an important role for determining the composition of the coronal field above the PILs .In addition , we proved that the spread of the inclination angles of the coronal field line depends on their distance from the center of the sunspot group . The results show that the evolution of the coronal field can be understood if one takes into consideration both the emergence of new flux and the differential rotation .Keywords: Coronal field, Active region",
        "ori-fast-z-score": 1.4770978917519928,
        "water-fast-z-score": 5.169842621131974
    },
    {
        "original_text": "We present an efficient data redistribution scheme that allows the parallel execution of computations on dynamically resized computational domains in distributed memory environments. The proposed approach is based on multidimensional block-cyclic distributions and exploits locality by using space-filling curves to map blocks onto processors. We show how this technique can be used to efficiently redistribute data between different processor configurations, while minimizing communication overheads. Our experimental results demonstrate significant performance improvements over existing approaches when executing applications with dynamic load balancing requirements. In particular, we achieve speedups up to 3Â compared to state-of-the-art techniques such as the one presented in  1  . \nIntroduction\n\nParallel computing has become increasingly important due to its ability to solve large problems faster than serial computers  2  , but it also presents new challenges related to the distribution of work among multiple processing units  3  .\nIn order to take advantage of parallelism, many algorithms are designed so that they can run simultaneously on several processors  4  . However, these algorithms often require some form of data redistribution during their execution  5  . For example, consider a computation where each process stores part of a dataset (e.g., matrix)  6  . If the number of processes changes at runtime, then all processes need to exchange information about which parts of the dataset they store before continuing  7  . This problem becomes even more challenging if the size of the datasets stored by individual processes varies  8  or if there are dependencies between them  9  .",
        "watermark_text": "We create an efficient information redistribution system that enables the parallel execution of computations on dynamically resized computational regions in distributed storage systems . The proposed approach is based on multidimensional block - cyclic distributions and exploits locality by using space - filling curves to map blocks onto processors .We suggest how this methodology can be used to easily redistribute information between various computer configurations , while minimizing communication overheads . Our research results show considerable performance improvements over existing techniques when executing systems with dynamic load balancing requirements .In particular , we accomplish speedups up to 3Â relative to state - of - the - art methods such as the one illustrated in 1 . Introduction Parallel logic has become rapidly key thanks to its able to solve huge problems quicker than serial machines 2 , but it also provides new obstacles linked to the distribution of work among multiple processing facilities 3 .In order to take advantage of parallelism , many algorithms are built so that they can run simultaneously on numerous processors 4 . However , these algorithms often demand some kind of file redistribution during their execution 5 .For instance , consider a computation where each process stores portion of a dataset ( e . g . , matrix ) 6 . If the number of processes changes at runtime , then all processes must to exchange knowledge about which portions of the dataset they contain before continuing 7 .This problem arises even more challenging if the length of the datasets collected by individual processes vary 8 or if there are dependencies between them 9 .",
        "ori-fast-z-score": -0.811502671200689,
        "water-fast-z-score": 7.605002667571556
    },
    {
        "original_text": "We study the resonance phenomenon for an open-loop control problem in a nonlinear stochastic model describing interactions between phytoplankton (plants) and zooplankton (animals). The main goal is to find optimal values of parameters characterizing external periodic forcing, which maximize the growth rate of planktons. We show that this optimization problem can be reduced to finding solutions of some algebraic equations. In particular, we prove that there exists only one solution corresponding to maximum value of the objective function. Moreover, it turns out that the obtained results are robust with respect to small perturbations of initial conditions. Finally, numerical simulations illustrate our theoretical findings. \n \n Keywords: Stochastic differential equation, Periodic forcing, Resonance, Optimization problems, Nonlinear dynamics \n \n 1 Introduction \n \n Interactions among different species play important role in many natural ecosystems. For example, phytoplankton (algae or plants), living at the base of food chain, provide energy source for other organisms such as zooplankton (fishes or animals). Therefore, understanding how these two populations interact may help us better understand ecosystem functioning. Recently, several mathematical models have been proposed to describe population dynamics of phytoplankton- zooplankton systems  1–3  . These models include deterministic terms representing intrinsic growth rates of both populations and their interaction effects, as well as random fluctuations due to environmental factors. It has been shown that under certain assumptions on the coefficients of the model, its long-term behavior exhibits chaotic attractor  4  , which makes analysis of the system very difficult. On the other hand, if the effect of random fluctuations is neglected then the resulting deterministic model becomes much easier to analyze  5–7  .\n \nIn  8  , authors studied the following model:\n \n \n \n dX(t) = rX(t)(1 - X(t))dt + fX(t)sin(wt)dW(t),\n dY(t) = rY(t)(1 - Y(t))dt + fy(t)sin(w0t)dW(t).\n \n(",
        "watermark_text": "We research the resonance phenomenon for an open - loop control problem in a nonlinear stochastic model explaining interactions between phytoplankton ( plants ) and zooplankton ( animals ) . The main goal is to find optimal values of values characterizing external periodic forcing , which maximize the development time of planktons .We see that this optimization problem can be reduced to finding solutions of some algebraic equations . In particular , we prove that there exists only one solve corresponding to maximum value of the objective function .Moreover , it turns out that the achieved findings are robust with regard to small perturbations of initial conditions . Finally , numerical simulations highlight our theoretical results .Keywords : Stochastic integral equation , Periodic forcing , Resonance , Optimization problems , Nonlinear dynamics 1 Introduction Interactions among different species play attractive role in different biological environments . For instance , phytoplankton ( algae or plants ) , live at the base of eat chain , provide energy source for other species such as zooplankton ( fishes or organisms ) .Therefore , studying how these two communities interact may assist us better understand ecological functioning . Recently , various computational models have been proposed to explain population behavior of phytoplankton - zooplankton communities 1 – 3 .These models include deterministic terms representing intrinsic development rates of both populations and their interaction influences , as also as random fluctuations owing to environmental factors . It has been shown that under certain assumptions on the coefficients of the model , its long - term behavior presents dynamic attractor 4 , which makes study of the system very difficult .On the other hand , if the impact of random fluctuations is neglected then the resulting deterministic model seems far easy to analyze 5 – 7 . In 8 , authors explored the following model : dX ( t ) = rX ( t ) ( 1 - X ( t ) ) dt + fX ( t ) sin ( wt ) dW ( t ) , dY ( t ) = rY ( t ) ( 1 - Y ( t ) ) dt + fy ( t ) sin ( w0t ) dW ( t ) .(",
        "ori-fast-z-score": 2.482817665807104,
        "water-fast-z-score": 8.877545314489295
    },
    {
        "original_text": "We study the scattering properties of surface plasmons (SPs) by a single subwavelength groove in an optically thick metal film, which is excited by a normally incident plane wave with circular polarization. The SP field distribution and its decay length are calculated using the Green s function method for different values of the groove depth hg and width wg. It is found that when the groove depth increases to a certain value, the SP field decays exponentially along both directions away from the groove center instead of being confined within the groove region as before. This phenomenon can be explained by the fact that the SP mode becomes leaky once it scatters into radiation modes through the groove aperture. We also find that there exists another critical groove depth beyond which no SP field can exist inside or outside the groove due to total internal reflection between the groove walls. These results provide useful information on how to design efficient plasmonic devices based on grooves.",
        "watermark_text": "We determine the scattering properties of surface plasmons ( SPs ) by a single subwavelength groove in an optically dense metal film , which is excited by a normally incident plane wave with circular polarization . The SP field distribution and its decay width are measured using the Green s function method for different values of the groove height hg and width wg .It is found that when the groove height rises to a certain value , the SP field decays exponentially along both directions away from the groove center instead of being confined within the groove region as before . This phenomenon can be described by the fact that the SP mode becomes leaky once it scatters into radiation modes through the groove aperture .We additionally find that there exists another important groove width beyond which no SP field can occur inside or outside the groove due to complete internal reflection between the groove walls . These conclusions provide useful info on how to build efficient plasmonic systems relying on grooves .",
        "ori-fast-z-score": -2.0647416048350555,
        "water-fast-z-score": 2.7529888064467407
    },
    {
        "original_text": "We present new observations of the low surface brightness galaxy PGC 045080, which is known to host an active galactic nucleus (AGN). We use these data to study the properties of this AGN as well as its relationship with the surrounding gas disk.  The AGN has been detected by previous studies at radio wavelengths using Very Large Array (VLA) observations. In our work we have used VLA archival data along with new observations made with the Karl G. Jansky Very Large Array (JVLA), to detect emission lines associated with the AGN. These include H-alpha,  NII  ,  SII  ,  OIII  , and  CII  . Using these line fluxes we calculate the luminosity of the AGN to be 1.1 x 10^41 erg/sec. This value agrees very closely with that found for other similar galaxies. We also find evidence for outflows on both large and small scales around the AGN.",
        "watermark_text": "We report new images of the poor floor velocity galaxy PGC 045080 , which is known to host an active galactic nucleus ( AGN ) . We use these information to study the properties of this AGN as well as its connection with the nearby gas envelope .The AGN has been detected by earlier surveys at radio wavelengths using Very Large Array ( VLA ) observations . In our work we have utilized VLA archival data along with recent observations made with the Karl G . Jansky Very Large Array ( JVLA ) , to identify emission lines associated with the AGN .These include H - alpha , NII , SII , OIII , and CII . Using these line fluxes we determine the luminosity of the AGN to be 1 . 1 x 10 ^ 41 erg / sec .This value agrees very closely with that shown for other similar galaxies . We additionally find proof for outflows on both large and tiny scales around the AGN .",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 5.077963596336064
    },
    {
        "original_text": "We present an overview of the state-of-the-art methods for spectral analysis on spherical data, with emphasis on their applications to problems arising in geophysical sciences (e.g., global seismological tomography) and astrophysics (e.g., cosmic microwave background). We also discuss some recent advances in this area that have been made by our group at Columbia University. The main focus is on the development of new algorithms for computing accurate estimates of the power spectrum of signals defined over the surface of the unit sphere using only partial information about these signals. In particular, we consider two classes of methods: those based on the use of spherical harmonic expansions and those based on wavelet transforms. Finally, we briefly describe several open research questions related to the topic discussed here. Spherical data arise naturally in many areas of science including astronomy, meteorology, oceanography, geodesy, and medicine. For example, astronomers routinely collect large amounts of data describing the positions of celestial objects such as stars or galaxies; similarly, weather forecasters gather measurements of atmospheric pressure, temperature, humidity, wind speed, etc., at various locations around the globe. These types of data are often represented mathematically as functions defined over the surface of a sphere.",
        "watermark_text": "We bring an overview of the state - of - the - art methods for spectral modeling on spherical measurements , with emphasis on their applications to problems arose in geophysical sciences ( e . g . , global seismological tomography ) and astrophysics ( e . g . , planetary microwave background ) . We also discuss some latest advances in this area that have been made by our team at Columbia University .The main interest is on the development of new method for calculation precise estimates of the power spectrum of waves defined over the surface of the unit sphere utilizing only partial knowledge about these signals . In particular , we investigate two groups of methods : those relying on the using of spherical harmonic expansions and those based on wavelet transforms .Finally , we briefly illustrate numerous open scientific questions related to the subject mentioned here . Spherical data arise naturally in multiple fields of science including science , meteorology , oceanography , geodesy , and medicine .For instance , astronomers typically gather huge amounts of statistics explaining the places of astronomical bodies such as planets or galaxies ; likewise , weather forecasters gather measurements of atmospheric pressure , temperature , moisture , breeze pressure , etc . , at numerous locations around the globe . These sorts of statistics are often depicted mathematically as functions defined over the surface of a sphere .",
        "ori-fast-z-score": -2.011435198964418,
        "water-fast-z-score": 6.674238124719146
    },
    {
        "original_text": "We present an algorithm that systematically scans all possible 7-colourings of the grid, and report on its performance in terms of running time and memory consumption. The algorithm is based on a simple backtracking scheme combined with some heuristics to prune parts of the search space. We have implemented this algorithm using Java 1.6 and tested it on several instances ranging from small grids up to large ones containing more than one million nodes. For each instance we provide detailed information about how much time was spent by our program during colouring as well as how many colours were used. In addition, we also show how these results compare against those obtained by other algorithms proposed recently in the literature. \n \n Keywords: Coloring problems, Computational complexity theory, Graphs, Backtrack search, Heuristic methods, Grid graphs, Integer programming, Optimization problems, Search trees, Time-complexity analysis \n \n \n \n INTRODUCTION \n \n A graph G = (V, E) consists of two sets V and E where V denotes the set of vertices or nodes and E denotes the set of edges between pairs of nodes. An edge e=(u,v) connects node u ∈ V to v ∈ V . If there exists no such connection then e is not included in E. A path P is defined as a sequence of distinct nodes v1 , v2 , … , vn such that vi−1vi ∈ E for i = 2 , 3 , … , n . A cycle C is defined as a path whose first and last nodes are identical. A connected component is a subgraph H of G which has the property that any pair of nodes in H can be joined by a path within H but cannot be joined by paths outside H. A clique K is a complete subgraph of G; that is, every pair of nodes in K is adjacent to each other. A k-clique is a clique consisting of exactly k nodes. A vertex cover S is a subset of V such that every edge in G has at least one endpoint in S. A dominating set D is a subset of V",
        "watermark_text": "We create an algorithm that systematically scans all possible 7 - colourings of the grid , and report on its effectiveness in terms of running time and memory usage . The algorithm is based on a simple backtracking scheme coupled with some heuristics to prune parts of the search space .We have applied this algorithm using Java 1 . 6 and demonstrated it on numerous instances ranging from small grids up to large ones featuring more than one million nodes . For each instance we provide comprehensive information about how many time was spent by our software during colouring as also as how many colours were used .In addition , we also demonstrate how these results compare against those achieved by other methods suggested late in the literature . Keywords : Coloring questions , Computational complexity analysis , Graphs , Backtrack search , Heuristic methods , Grid graphs , Integer programming , Optimization problems , Search trees , Time - complexity analysis INTRODUCTION A graph G = ( V , E ) contains of two sets V and E where V denotes the set of vertices or nodes and E denotes the set of vertices between pairs of vertices .An path e = ( v , v ) links node e ∈ V to v ∈ V . If there exists no such connection then e is not added in E . A path P is given as a sequence of distinct nodes v1 , v2 , … , vn such that vi−1vi ∈ E for i = 2 , 3 , … , n .A cycle C is characterized as a path whose first and last nodes are equal . A linked component is a subgraph H of G which has the feature that any pair of vertices in H can be joined by a path within H but cannot be joined by tracks outside H . A clique K is a complete subgraph of G ; that is , every pair of vertices in K is adjoining to each other .A k - clique is a clique consisting of exactly k nodes . A vertex cover S is a subset of V such that every edge in G has at least one endpoint in S . A dominating setting D is a subset of V",
        "ori-fast-z-score": 0.8770580193070293,
        "water-fast-z-score": 7.367287362179046
    },
    {
        "original_text": "We present an experimental study on the effect that different initial states have in a quantum experiment, using quantum process tomography (QPT). We prepare three different initial states and perform QPT to reconstruct their density matrices. The results show how the choice of initial state affects the outcome of the experiment. In particular we find that the fidelity between two initial states is not sufficient to determine whether they will give rise to similar or dissimilar outcomes when measured with respect to some observable. This work was supported by EPSRC grant EP/G061794/1. Introduction:-Quantum mechanics has been successfully applied to many fields such as information processing  1  , metrology  2  and sensing  3  . However, it remains unclear what exactly constitutes a  quantum  experiment  4  .\nIn this Letter we consider one aspect of quantum experiments -the role played by the initial state of the system under investigation. It is well known that the measurement statistics depend upon the initial state  5  but there are few studies which investigate how the choice of initial condition influences the final result  6  . Here we use quantum process tomography  7, 8  to examine the influence of the initial state on the outcome of a quantum experiment. Our aim is to understand better how the initial conditions may be chosen so as to maximise the probability of observing certain phenomena  9  .",
        "watermark_text": "We present an experimental test on the impact that different initial states have in a quantum experiment , using quantum method tomography ( QPT ) . We produce three different initial states and conduct QPT to reconstruct their density matrices .The results show how the chosen of initial state impacts the result of the experiment . In particular we find that the fidelity between two initial states is not sufficient to judge whether they will giving rise to similar or dissimilar effects when measured with regard to some observable .This project was supported by EPSRC award EP / G061794 / 1 . Introduction : - Quantum theory has been successfully application to many fields such as intelligence processing 1 , metrology 2 and perception 3 .However , it remains unsure what actually constitutes a quantum experiment 4 . In this Letter we mention one element of quantum experiments - the part played by the first state of the process under inquiry .It is well established that the observation statistics depend upon the initial state 5 but there are few researchers which probe how the selection of initial condition influences the finished result 6 . Here we using quantum process tomography 7 , 8 to examine the impact of the initial state on the result of a quantum experiment .Our aim is to study easier how the first parameters might be chosen so as to maximise the probability of experiencing certain observations 9 .",
        "ori-fast-z-score": -1.7483145522430754,
        "water-fast-z-score": 6.799001036500849
    },
    {
        "original_text": "We present multimodal nested sampling (MNS), a novel algorithm that is able to efficiently explore the posterior distribution in high-dimensional parameter spaces, such as those encountered when fitting complex models to observational data sets. MNS combines ideas from simulated annealing with importance sampling techniques to find the global maximum likelihood solution within a given tolerance level. We demonstrate how this method can be used on real-world problems by applying it to two different astrophysics applications: modelling the observed fluxes of gamma-ray bursts using a time-dependent model; and determining the parameters of a binary black hole merger event detected by gravitational waves. In both cases we show that our new approach outperforms existing Markov chain Monte Carlo algorithms. The code implementing these examples will be made publicly available at https://github.com/mns-method/mns-method/tree/master/examples. Multimodal nested sampling (M NS) is a novel algorithm that is capable of exploring the posterior distribution in high dimensional parameter spaces, such as are found when fitting complex models to large observational datasets. It combines ideas from simulated annealling with importance sampling techniques to locate the global maximum likelihood solution to any problem within some specified tolerance. This talk describes the basic principles behind M NS and demonstrates its application to two astrophysics problems: modelling the observed light curves of gamma ray bursts; and determining the physical properties of a binary black hole system inferred from gravitational wave observations.",
        "watermark_text": "We create multimodal nested sampling ( MNS ) , a new algorithm that is able to easily examine the posterior distribution in high - dimensional parameter sets , such as those experienced when fitting large models to observational data sets . MNS mixes ideas from simulated annealing with importance sampling methods to find the global maximum likelihood solution within a given tolerance level .We suggest how this algorithm can be used on real - global issues by using it to two different astrophysics applications : modelling the emitted fluxes of gamma - ray clusters using a time - dependent model ; and determining the variables of a binary white hole merger event detected by gravitational waves . In both cases we prove that our new approach outperforms previous Markov chain Monte Carlo algorithms .The software implementing these examples will be made fully available at https : / / github . com / mns - method / mns - method / tree / master / examples . Multimodal nested filtering ( M NS ) is a novel algorithm that is capable of analyzing the posterior distribution in high dimensional parameter sets , such as are found when fitting large models to large observational datasets .It combines insights from simulated annealling with importance sampling methods to locate the global maximum likelihood solution to any question within some specified tolerance . This discussion describes the fundamental principles behind M NS and demonstrates its use to two astrophysics issues : modelling the emitted light curves of gamma radiation bursts ; and determining the physical properties of a binary white hole system inferred from gravitational wave surveys .",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 8.348430768491543
    },
    {
        "original_text": "The WiFeS instrument is an integral field spectrograph for the Australian National University 2.3m telescope at Siding Spring Observatory, Australia.  It has been in operation since 2005 and was designed to provide high quality optical spectroscopy over a wide range of wavelengths with minimal overheads.   The WiFeS instrument consists of two cameras that are mounted on a common baseplate which sits inside a vacuum chamber attached to the Cassegrain focus of the ANU 2.3m telescope.    Each camera contains a lenslet array that produces a set of images across its focal plane.  These images can be combined into a single data cube using software developed by Dopita et al. (2007).    This data cube provides information about both spatial position and wavelength along each line-of-sight through the object being observed.  In addition to this capability, WiFeS also offers several other advantages including:  - High throughput due to the use of dichroic beam splitters and fibre optic coupling between the lenses and detectors.  - Flexible observing modes ranging from fully automated observations to manual control via remote desktop interface.  - Fast readout times allowing multiple targets to be observed simultaneously or rapid cycling between different targets during a night s observation run.  - Low maintenance requirements as it does not require any moving parts within the vacuum enclosure.  - Excellent stability thanks to the design of the optics bench and the thermal isolation provided by the vacuum enclosure.  - Large format detector arrays providing excellent signal-to-noise ratio even under poor seeing conditions.  - Robust mechanical design ensuring long-term reliability...",
        "watermark_text": "The WiFeS instrument is an integral field spectrograph for the Australian National University 2 . 3m telescope at Siding Spring Observatory , Australia . It has been in operation since 2005 and was built to provide high quality optical spectroscopy over a broad variety of wavelengths with minimal overheads .The WiFeS instrument consists of two cameras that are installed on a common baseplate which sits inside a vacuum chamber connected to the Cassegrain scope of the ANU 2 . 3m telescope . Each lens includes a lenslet antenna that generates a pair of pictures across its focal surface .These photographs can be merged into a single data cube using software created by Dopita et al . ( 2007 ) .This data cube provides information about both visual orientation and wavelength along each line - of - view through the element being detected . In addition to this capability , WiFeS also provides various other advantages namely : - High throughput owing to the using of dichroic laser splitters and fibre optic coupling between the lenses and detectors .- Flexible monitoring mechanisms ranging from fully autonomous observations to manual control via remote desktop interface . - Fast readout hours permitting multiple targets to be spotted concurrently or rapid cycling between various destinations during a night s observation run .- Low maintenance requirements as it does not require any shifting components within the vacuum enclosure . - Good integrity thanks to the design of the optics bar and the thermal isolation provided by the vacuum enclosure .- Large format detector arrays offering good signal - to - noise ratio especially under bad seeing conditions . - Robust mechanical architecture ensuring long - term reliability . . .",
        "ori-fast-z-score": -0.6211495565912797,
        "water-fast-z-score": 7.0101164243872995
    },
    {
        "original_text": "The authors have used scanning tunneling microscopy to study the surface structure and electronic properties of single crystals of the high-temperature cuprate superconductor Bi2Sr2CaCu2O8+d (Bi-2212). They find that, at low temperatures, this material forms pairs of holes which are bound together by an attractive interaction mediated by phonons. The binding energy is found to be about 0.5 eV per hole pair. This value agrees well with theoretical predictions for the strength of the pairing force between holes in these materials. \n \n In addition, they observe that the density of states near the Fermi level shows a strong dependence on the direction along which the crystal is cut. For example, when the crystal is cleaved parallel to its Cu-O planes, it exhibits a large peak in the density of states just below the Fermi level. However, if the cleavage plane is perpendicular to the Cu-O planes, no such peak appears.",
        "watermark_text": "The authors have utilized scanning tunneling microscopy to study the surface structure and electronic properties of single crystals of the high - temperature cuprate superconductor Bi2Sr2CaCu2O8 + d ( Bi - 2212 ) . They find that , at low temperatures , this metal creates sets of holes which are bound together by an attractive interaction mediated by phonons .The interaction power is found to be about 0 . 5 eV per hole pair . This value agrees well with theoretical expectations for the strength of the pairing force between holes in these structures .In addition , they demonstrate that the density of states near the Fermi level exhibits a large dependence on the direction along which the crystal is cutting . For instance , when the crystal is cleaved parallel to its Cu - O planes , it displays a large peak in the density of states just below the Fermi level .However , if the cleavage plane is perpendicular to the Cu - O axes , no such peak appears .",
        "ori-fast-z-score": 2.75,
        "water-fast-z-score": 6.4007575309253015
    },
    {
        "original_text": "We present here an overview of our survey, which is aimed at tracing the evolution in the number density and luminosity function (LF) of galaxies as a function of their stellar masses up to z ~ 1.5. The sample consists of about 10 000 objects selected by photometric redshifts using deep optical data obtained with FORS2@VLT+WFI@ESO/MPG 2.2m telescope + Spitzer IRAC 3.6 & 4.5 micron bands. We use this dataset to study how the LF evolves for different ranges of stellar masses. In particular we find that the faint-end slope of the LF becomes steeper towards higher redshift indicating that less massive systems are more abundant than today. This result can be explained if star formation activity was more efficient in low-mass halos at high-z compared to local universe. Finally, we compare these results with those derived from other surveys finding good agreement between them.",
        "watermark_text": "We present here an overview of our survey , which is aiming at studying the evolution in the number density and luminosity function ( LF ) of galaxies as a function of their stellar masses up to z ~ 1 . 5 . The sample consists of about 10 000 items selected by photometric redshifts using deep optical data acquired with FORS2 @ VLT + WFI @ ESO / MPG 2 . 2m telescope + Spitzer IRAC 3 . 6 & 4 . 5 micron bands .We use this dataset to study how the LF evolves for different ranges of stars masses . In particular we find that the faint - end slope of the LF becomes steeper towards higher redshift indicating that less massive components are more rich than presently .This result can be described if star formation activity was more efficient in low - density halos at high - z compared to nearby universe . Finally , we compare these results with those generated from other surveys obtaining strong approval between them .",
        "ori-fast-z-score": 2.4618298195866544,
        "water-fast-z-score": 6.154574548966636
    },
    {
        "original_text": "The self-duality condition on the curvature tensor is an important ingredient in supergravity theories, but it has been difficult to incorporate into superspace formulations because of its non-Lagrangian nature.  In this work we show how to construct Lagrangians for self-dual supergravities by using twistor theory as our guide.   We first review the basic ideas behind twistor theory and then use these results to develop new techniques that allow us to write down manifestly supersymmetric actions for self-dual supergravitational fields with arbitrary gauge groups.  The resulting action can be written either in terms of chiral or twisted-chiral superfields depending upon whether one uses the light-cone or covariant approach respectively.   Finally, we discuss some applications of these results including the construction of N = 1, D = 4 supergravity coupled to Yang-Mills multiplets. This article is available from: http://arxiv.org/abs/hep-th/0405033",
        "watermark_text": "The self - duality condition on the curvature tensor is an important ingredient in supergravity models , but it has been difficult to insert into superspace formulations because of its non - Lagrangian existence . In this research we explain how to build Lagrangians for self - dual supergravities by using twistor theory as our guide .We first review the fundamental ideas behind twistor theory and then use these results to develop new strategies that enable us to write down manifestly supersymmetric movements for self - dual supergravitational fields with arbitrary gauge groups . The resulting action can be written either in terms of chiral or twisted - chiral superfields depending upon whether one uses the light - cone or covariant approach respectively .Finally , we explain some applications of these results namely the creation of N = 1 , D = 4 supergravity combined to Yang - Mills multiplets . This section is accessible from : www : / / arxiv . org / abs / hep - th / 0405033",
        "ori-fast-z-score": 0.13018891098082389,
        "water-fast-z-score": 4.816989706290483
    },
    {
        "original_text": "We propose to use the time evolution of cosmological redshifts in order to probe the nature of dark energy, which is one of the most important problems in modern physics and astronomy. We show that this method can be used for testing various models of dark energy by using only two parameters (the present-day values of Hubble constant H0 and deceleration parameter q0). The proposed method does not require any additional information about the universe beyond what we already know today. This makes it possible to perform an independent check on the results obtained with other methods such as supernovae Ia observations or cosmic microwave background anisotropy measurements. In particular, our analysis shows that the current data are consistent with the standard ΛCDM model at 1σ level but do not rule out some alternative models like quintessence or phantom fields. Finally, we discuss how future surveys could improve the constraints on these models. Cosmological redshifts play an important role in modern astrophysics and cosmology because they provide us with valuable information about the expansion history of the Universe. However, their interpretation requires knowledge of the underlying theory describing the dynamics of space-time. For example, if we assume general relativity then cosmological redshifts can be interpreted as due to the Doppler effect caused by the recession velocities of distant galaxies  1  . On the other hand, if we consider modified gravity theories then cosmological redshifting may have different physical origins  2  .\nIn recent years there has been growing interest in studying the possibility of probing the nature of dark energy through its effects on cosmological redshifts  3  -  8  . Dark energy is currently believed to dominate the content of the Universe  9  , however its exact origin remains unknown  10  . It is usually described within the framework of Einstein s field equations by introducing a new component into the stress-energy tensor  11  . Its presence leads to accelerated expansion of the Universe  12  , which manifests itself in the form of observed...",
        "watermark_text": "We suggest to use the period evolution of cosmological redshifts in order to probe the nature of dark energy , which is one of the most important problems in modern physics and astronomy . We see that this technology can be used for studying several models of bright energy by using only two parameters ( the present - day parameters of Hubble constant H0 and deceleration parameter q0 ) .The proposed approach does not require any additional information about the universe beyond what we already understand today . This lets it convenient to conduct an independent check on the results derived with other methods such as supernovae Ia detection or cosmic microwave background anisotropy observations .In particular , our analysis shows that the present data are compatible with the standard ΛCDM theory at 1σ level but do not leave out some additional models like quintessence or phantom fields . Finally , we explain how potential study could enhance the restrictions on these models .Cosmological redshifts play an important role in modern astrophysics and cosmology because they give us with important information about the expansion history of the Universe . However , their explanation requires knowledge of the fundamental theory explaining the dynamics of space - time .For instance , if we suppose general relativity then cosmological redshifts can be interpreted as owing to the Doppler impact caused by the recession velocities of distant galaxies 1 . On the other hand , if we treat modified gravity theories then cosmological redshifting might have different physical origins 2 .In recent years there has been growing interest in investigating the prospect of probing the nature of dark energy through its consequences on cosmological redshifts 3 - 8 . Dark energy is currently suspected to dominate the content of the Universe 9 , however its exact origin stays unclear 10 .It is usually characterized within the framework of Einstein s field equations by bringing a new constituent into the strain - energy tensor 11 . Its presence contributes to accelerated expansion of the Universe 12 , which manifests itself in the form of observed . . .",
        "ori-fast-z-score": 0.4931969619160719,
        "water-fast-z-score": 8.495296818075921
    },
    {
        "original_text": "We propose to cool fermionic atoms in optical lattices by using the pairing mechanism between two different hyperfine states, which is analogous to Cooper pair formation in superconductors. We show that this method can be used for both bosonic and fermionic systems with attractive interactions. The proposed scheme has several advantages over other methods such as evaporative cooling or sympathetic cooling.  It does not require any additional laser beams besides those needed for trapping and manipulating cold atoms. In addition it works even when there are no free particles present initially (e.g., at zero temperature). Finally we discuss how our proposal could be realized experimentally. Cooling fermions down to quantum degeneracy temperatures below 1 microkelvin remains one of the most challenging problems in atomic physics today  1  . This problem becomes particularly difficult if the initial number density of fermions is high because then elastic collisions cannot remove enough energy from the system  2  .\nIn recent years, however, new experimental techniques have been developed  3, 4  , allowing us to trap and manipulate cold atoms on an unprecedented level  5  . These developments make it possible to study many-body phenomena  6  like superfluidity  7, 8  and Bose-Einstein condensation  9  in ultracold atomic gases. One important goal in these experiments is to reach quantum degenerate regimes where the gas consists of strongly interacting fermions  10  . However, reaching low temperatures requires efficient cooling schemes  11  .\nOne promising approach towards achieving this goal is to use the pairing mechanism  12  . Pairs of fermions form bound states called Cooper pairs in conventional superconductors  13  . Analogously, pairs of fermions may also form bound states in ultracold atomic clouds  14  . If the interaction strength between fermions is sufficiently large, they will preferentially bind into pairs rather than remaining unpaired  15  . Therefore, cooling fermions via pairing should work well even",
        "watermark_text": "We suggest to cool fermionic atoms in laser lattices by using the pairing principle between two different hyperfine states , which is analogous to Cooper couple formation in superconductors . We see that this process can be used for both bosonic and fermionic systems with interesting interactions .The proposed system has numerous benefits over other methods such as evaporative cooling or sympathetic heating . It does not require any additional laser electrons besides those required for trapping and manipulating cool ions .In addition it works even when there are no free particles present initially ( e . g . , at zero temperature ) . Finally we talk how our proposal possible be realized experimentally .Cooling fermions down to quantum degeneracy temperatures below 1 microkelvin remains one of the most challenging difficulties in nuclear science today 1 . This problem remains particularly challenging if the first number density of fermions is high because then elastic collisions cannot eliminate much energy from the system 2 .In recent years , however , new experimental methods have been created 3 , 4 , allowing us to trapping and manipulate cold molecules on an remarkable level 5 . These advances give it able to study many - bodies phenomena 6 like superfluidity 7 , 8 and Bose - Einstein condensation 9 in ultracold atomic atoms .One important aim in these experiments is to reach quantum degenerate regimes where the gas consists of highly interacting fermions 10 . However , finding low temperatures involves optimal cooling schemes 11 .One promising alternative towards reaching this goal is to use the pairing principle 12 . Pairs of fermions form bound states called Cooper pairs in standard superconductors 13 .Analogously , pairs of fermions may sometimes form bound states in ultracold nuclear clouds 14 . If the interaction strength between fermions is sufficiently great , they will preferentially bind into couples rather than keeping unpaired 15 .Therefore , cooling fermions via pairing should work better even",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.723229626397817
    },
    {
        "original_text": "We revisit the foundations of quantum mechanics by introducing an alternative formulation to the standard Feynman path integral approach, which is based on the concept of dynamical phase transition (DPT). We show that this new formalism provides a natural description for the emergence and evolution of macroscopic order in open quantum systems. In particular we demonstrate how it can be used to describe the spontaneous emission process in atomic physics, where the atom-field interaction leads to the formation of collective states with well-defined photon number statistics. The proposed framework also allows us to study the dynamics of many-body interacting systems beyond mean field theory. Finally, we discuss possible applications of our results to condensed matter physics and quantum information science. Introduction:-The development of modern theoretical approaches has led to significant progress in understanding the physical properties of complex quantum systems  1  . However, despite these advances there are still fundamental questions about the nature of quantum phenomena that remain unanswered  2  .\nIn recent years, several authors have attempted to address some of these issues using concepts borrowed from statistical mechanics  3  , such as entropy  4  or free energy  5  . These ideas were originally developed within the context of classical thermodynamics  6  but they have been recently extended to the realm of quantum mechanics  7, 8  . For example, one may consider the von Neumann entropy S = −Tr(ρ ln ρ) associated with the density matrix ρ describing the state of a system  9  . This quantity measures the amount of uncertainty present in the measurement outcomes  10  and its time derivative dS/dt gives rise to the so-called entropy production rate  11  . It was shown that this latter quantity plays a crucial role in characterizing the irreversible behavior of closed quantum systems  12  . More specifically, if the entropy production rate vanishes then the corresponding quantum mechanical model exhibits reversible dynamics  13  . On the other hand, when the entropy production rate becomes positive the system undergoes a non-equilibrium phase transition  14  .",
        "watermark_text": "We revisit the foundations of quantum mechanics by offering an additional formulation to the standard Feynman path integral approach , which is based on the notion of dynamical phase change ( DPT ) . We suggest that this new formalism gives a natural explanation for the emergence and evolution of macroscopic order in open quantum systems .In particular we prove how it can be used to explain the spontaneous emission mechanism in nuclear physics , where the atom - field interaction results to the formation of collective states with good - defined photon number statistics . The proposed framework specifically allows us to study the dynamics of several - bodies interacting systems beyond mean field theory .Finally , we explain possible applied of our findings to condensed matter science and quantum information physics . Introduction : - The advance of modern conceptual approaches has led to significant progress in understanding the physical properties of complex quantum systems 1 .However , despite these developments there are still significant questions about the nature of quantum effects that continue unanswered 2 . In recent months , various published have tried to tackle some of these problems using concepts borrowed from statistical mechanics 3 , such as entropy 4 or free energy 5 .These concepts were formerly advanced within the context of classical thermodynamics 6 but they have been lately extended to the domain of quantum mechanics 7 , 8 . For instance , one may see the von Neumann entropy S = −Tr ( ρ ln ρ ) associated with the density function ρ describing the state of a system 9 .This value measures the extent of uncertainty found in the measurement processes 10 and its time derivative dS / dt gives rise to the so - called entropy production probability 11 . It was shown that this latter quantity plays a crucial role in characterizing the irreversible behavior of closed quantum systems 12 .More specifically , if the entropy production level vanishes then the associated quantum mechanical model shows reversible dynamics 13 . On the other hand , when the entropy production level gets positive the system undergoes a non - equilibrium phase change 14 .",
        "ori-fast-z-score": 1.5523010514126656,
        "water-fast-z-score": 9.615384615384615
    },
    {
        "original_text": "We present an anatomical study on the structure and evolution of malicious singularities in complex networks, which are defined as nodes that have a disproportionately large number of connections to other nodes. We show how these nodes can be identified by their topological properties using statistical mechanics methods. In particular we find that the degree distribution of such nodes follows a power law with exponent 2.5 ± 0.1 for all studied real-world networks ranging from social networks like Facebook or Twitter to biological networks like metabolic pathways or protein-protein interaction networks. This finding is consistent across different network sizes and types. The results presented here provide new insights into the organization principles of complex systems and may help to identify key players within them. Complex networks play a crucial role in many fields including physics, biology, sociology, computer science, engineering, economics, etc., where they represent interactions between entities  1  . A common feature of most complex networks is the presence of so-called  hubs  -highly connected nodes  2  , whose removal often has dramatic effects  3  .\nIn this work we focus on identifying hubs in complex networks based solely on their topological features. To do so, we use statistical mechanics techniques  4  to analyze the degree distributions of several real world networks  5  . Our analysis reveals that the degree distribution of hubs follows a power-law  6  with exponent 2.5±0.1 independently of the size and type of the considered network (see Fig.  1 ). Interestingly, our findings are also valid when considering only the largest component of each network  7, 8  . These results suggest that the observed scaling behavior is not due to finite-size effects but rather reflects some fundamental property of complex networks  9  .",
        "watermark_text": "We present an anatomical research on the composition and evolution of malicious singularities in complex networks , which are specified as nodes that have a disproportionately huge amount of links to other connections . We see how these layers can be identified by their topological features using statistical mechanics principles .In particular we find that the degree distribution of such nodes follows a power law with exponent 2 . 5 ± 0 . 1 for all observed real - time connections including from social organizations like Facebook or Twitter to biological organizations like genetic pathways or protein - gene interaction systems . This found is consistent across different network lengths and types .The results presented here provide fresh insights into the organization characteristics of complex systems and may assist to identify key players within them . Complex networks take a crucial role in many fields including science , biology , sociology , computer science , engineering , economics , etc . , where they represent interactions between entities 1 .A characteristic characteristic of most large systems is the presence of so - called hubs - highly wired nodes 2 , whose disappearance often has dramatic effects 3 . In this research we focus on establishing hubs in complex networks based primarily on their topological features .To do so , we utilize statistical mechanics principles 4 to analyze the degree distributions of several real world networks 5 . Our study reveals that the degree distribution of hubs follows a power - law 6 with exponent 2 . 5±0 . 1 independently of the height and kind of the considered network ( see Fig .1 ) . Interestingly , our findings are also legitimate when examining only the greatest element of each network 7 , 8 .These data suggest that the seen scaling behavior is not due to finite - length effects but rather displays some fundamental property of complex networks 9 .",
        "ori-fast-z-score": -0.1643989873053573,
        "water-fast-z-score": 7.726752403351793
    },
    {
        "original_text": "We study cascades on large blog graphs, where each node is an individual blogger and edges represent links between blogs. We propose a novel cascade model that captures the fact that people are more likely to read posts by their friends than random posts. Our main contributions are: (1) we develop efficient algorithms for computing the cascade size distribution under our model; (2) we show how to use these results to estimate the number of active users at any given time during a cascade; (3) we demonstrate the effectiveness of our approach using data collected from LiveJournal.com. The Web has become one of the most important communication channels today. In particular, social networks such as Facebook or Twitter have attracted millions of users who share information with others through online messages known as tweets or status updates. These messages can be seen by all followers of the user posting them, which may cause further propagation of the message within the network. This phenomenon is called viral marketing  1  , and it has been studied extensively over recent years  2  . However, despite its importance, there still remain many open questions about the dynamics of this process  3  .\nIn this work, we focus on studying cascades on large blogging communities, where each node represents an individual blogger and edges connect pairs of blogs written by the same person  4  . A cascade starts when some blogger writes a post containing a URL pointing to another blog s page. Then, if her readers click on the link, they will visit the other blog and possibly continue reading additional posts. As shown in Figure 1 , the resulting graph contains several connected components representing different topics discussed by the community members.",
        "watermark_text": "We research cascades on huge website graphs , where each node is an individual blogger and edges represent connections between blogs . We suggest a novel cascade model that captures the fact that individuals are more likely to see posts by their colleagues than random posts .Our main contributions are : ( 1 ) we develop fast algorithms for modeling the cascade size distribution under our model ; ( 2 ) we study how to use these results to estimate the total of active participants at any given time during a cascade ; ( 3 ) we prove the ability of our approach using data taken from LiveJournal . com . The Web has become one of the most important communication platforms today .In particular , social sites such as Facebook or Twitter have garnered millions of people who share data with others through online emails known as tweets or status updates . These messages can be saw by all supporters of the user sending them , which would cause further transmission of the message within the channel .This phenomenon is dubbed viral marketing 1 , and it has been studied thoroughly over recent years 2 . However , despite its significance , there still continue several open questions about the dynamics of this process 3 .In this research , we focus on studying cascades on huge blogging environments , where each node symbol an individual blogger and edges connect sets of blogs written by the same people 4 . A cascade starts when some blogger writes a post containing a URL pointing to another blog s page .Then , if her viewers flip on the link , they will access the other blog and maybe continue reading additional posts . As seen in Figure 1 , the resulting graph contains multiple connected elements representing different issues discussed by the community members .",
        "ori-fast-z-score": 0.42717882885838043,
        "water-fast-z-score": 8.799883874482637
    },
    {
        "original_text": "We present the first dual field theory in emergent spacetime, which is derived from a unifying field theory in higher dimensional spacetime. We show that this new dual field theory can be used to describe both quantum and classical physics with one single unified description. This new dual field theory has several advantages over other existing theories such as string/M-theory or loop quantum gravity. First, it provides an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic scale down to macroscopic scale. Second, unlike string/M-theory or LQG, our new dual field theory does not require any extra dimensions beyond those already observed experimentally. Third, we provide a concrete example showing how our new dual field theory works by deriving Einstein s general relativity from our new dual field theory. Finally, we also derive Maxwell s equations from our new dual field... \nIntroduction:-In recent years there have been many attempts to develop a fundamental theory of everything(TOE). String/M-theory  1  , Loop Quantum Gravity  2  are two examples of these efforts. However, despite their successes they still suffer from some problems. For instance, string/M-theory requires extra dimensions  3  while loop quantum gravity suffers from non-renormalizability  4  . These difficulties motivate us to look for alternative approaches towards developing TOEs. Recently, a novel approach called  emergent spacetime  was proposed  5, 6  . According to this approach, space-time emerges from a more fundamental level  7, 8  .\nEmergent spacetime:-The idea behind emergent spacetime is very simple. It states that space-time is not fundamental but rather emerges from a more fundamental entity. To see why this might happen consider the following argument. Imagine you are sitting on your couch watching TV. You will probably say that the world around you looks flat because if you were standing up then you would notice that the ground below you is curved. Now imagine yourself floating above Earth. If you were standing up now then you wouldn t feel like you re standing on a curved surface anymore. Instead you d feel like you re standing on top of a",
        "watermark_text": "We introduce the first dual field model in emergent spacetime , which is developed from a unifying field model in larger dimensional spacetime . We see that this new dual field model can be used to explain both quantum and classical physics with one single unified description .This new dual field model has numerous benefits over other existing models such as string / M - theory or loop quantum gravitational . First , it gives an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic range down to macroscopic scale .Second , unlike string / M - theory or LQG , our new dual field theory does not require any additional dimensions beyond those already detected experimentally . Third , we provide a clear example showing how our new dual field theory works by deriving Einstein s general relativity from our new dual field theory .Finally , we also generate Maxwell s coefficients from our new dual field . . . Introduction : - In recent history there have been many efforts to develop a basic theory of things ( TOE ) . String / M - theory 1 , Loop Quantum Gravity 2 are two examples of these attempts .However , despite their successes they still suffer from some problems . For instance , string / M - theory requires added dimensions 3 while loop quantum gravitational suffers from non - renormalizability 4 .These difficulties motivate us to search for alternative approaches towards developing TOEs . Recently , a new approach called emergent spacetime was suggested 5 , 6 .According to this methodology , space - time arises from a more fundamental level 7 , 8 . Emergent spacetime : - The idea behind emergent spacetime is very simple .It says that space - time is not essential but rather emerges from a more fundamental entity . To see why this might happen think the following argument .Imagine you are sat on your couch watching TV . You will probably say that the world around you looks flat because if you were standing up then you might see that the earth below you is curved .Now imagine yourself rising above Earth . If you were standing up now then you wouldn t felt like you re standing on a curved surface anymore .Instead you d feel like you re standing on top of a",
        "ori-fast-z-score": 0.3892494720807615,
        "water-fast-z-score": 6.538461538461538
    },
    {
        "original_text": "We present results from three-dimensional hydrodynamic simulations of accreting white dwarfs in close binary systems, focusing on the boundary layer between the disk and the star. We find that the flow is highly turbulent with strong shocks forming at the interface between the two flows. The density structure shows significant departures from spherical symmetry due to the presence of spiral arms which form as a result of the interaction between the stellar magnetic field and the gas stream flowing towards the surface of the white dwarf. These spiral arms are responsible for driving an outflow along the polar axis of the system. In addition we find evidence for large-scale convection cells within the boundary layer. Our models suggest that the observed X-ray emission may be produced by these convective motions rather than by shock heating alone. This work was supported by NASA grant NAG5-7262. \n \n Keywords: Hydrodynamics; Shock waves; Convection",
        "watermark_text": "We present results from three - dimensional hydrodynamic simulations of accreting white dwarfs in close binary systems , concentrating on the boundary layer between the disk and the star . We see that the flow is strongly chaotic with powerful shocks producing at the interface between the two flows .The density structure exhibits significant departures from spherical symmetry thanks to the presence of spiral arms which occur as a product of the interaction between the stellar magnetic force and the gas stream running towards the surface of the white dwarf . These spiral arms are responsible for producing an outflow along the polar axis of the system .In addition we find proof for large - scale convection cells within the boundary layer . Our models suggest that the seen X - ray radiation may be made by these convective movements rather than by shock heating alone .This project was supported by NASA gift NAG5 - 7262 . Keywords : Hydrodynamics ; Shock currents ; Convection",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.88240082724041
    },
    {
        "original_text": "In this thesis, we study the problem of physical layer network coding (PLNC) in wireless networks with multiple relays and single-antenna nodes.  We first consider PLNC for two-way relay channels where each node has only one antenna.  In particular, we propose an efficient scheme to perform PLNC at both source nodes simultaneously by using linear codes over finite fields.  Then, we extend our results to multi-way relay channels with more than two users.  Finally, we investigate the performance of PLNC under imperfect channel state information (CSI). The main contributions are summarized as follows:  1. Two-way Relay Channels: We propose a novel approach to perform PLNC at the sources simultaneously based on linear codes over finite fields.   2. Multi-Way Relay Channels: By extending our previous work, we develop a new method to perform PLNC at all source nodes simultaneously.  3. Imperfect Channel State Information: We analyze the impact of imperfect CSI on the performance of PLNC schemes.",
        "watermark_text": "In this dissertation , we study the issue of physical layer network signaling ( PLNC ) in telecommunications networks with many relays and multiple - antenna nodes . We first consider PLNC for two - way relay channels where each node has only one antenna .In particular , we propose an efficient algorithm to conduct PLNC at both source nodes simultaneously by using linear codes over discrete fields . Then , we expanded our findings to multi - way transmission networks with more than two users .Finally , we investigate the performance of PLNC under imperfect channel state information ( CSI ) . The main contributions are presented as follows : 1 .Two - way Relay Channels : We suggest a new approach to conduct PLNC at the sources simultaneously based on linear codes over discrete fields . 2 .Multi - Way Relay Channels : By extending our previous research , we develop a new method to conduct PLNC at all source nodes simultaneously . 3 .Imperfect Channel State Information : We evaluate the impact of imperfect CSI on the performance of PLNC networks .",
        "ori-fast-z-score": 2.1652509527331207,
        "water-fast-z-score": 6.951595164037914
    },
    {
        "original_text": "We present an analytic expression for the thermal Casimir force acting on two parallel plates made out of different materials, one being metallic (silver) while another is dielectric (silicon dioxide). The result obtained agrees with that derived by Lifshitz theory within 1% accuracy in the whole range of separations considered here. We also show how our results can be used to calculate the temperature dependence of the Casimir pressure at fixed separation distance. \n \n In this work we consider the case where one plate consists of silver and other of silicon dioxide. Silver has been chosen because it is widely used as a coating material in microelectromechanical systems (MEMS), whereas SiO2 is often employed as a substrate or insulator layer in MEMS devices. Our results are applicable not only to these specific cases but also to any system consisting of two parallel plates separated by vacuum gap filled with gas medium. This includes such diverse situations like semiconductor heterostructures, quantum dots, nanowires etc., which have attracted considerable attention recently due to their potential applications in nanotechnology. \n \n It should be noted that the problem under consideration was first addressed theoretically more than 50 years ago  1  . However, despite numerous attempts  2  , no exact solution has yet been found. Therefore, most theoretical studies were performed using approximate methods  3  -  6  . These approaches include various modifications of the proximity force approximation  7, 8  , the Derjaguin-Muller-Toporov method  9  , the multiple reflection expansion  10  , the scattering matrix formalism  11  , the Green s function technique  12  , the density functional theory  13  , the mode summation  14  , the fluctuating surface charge model  15  , the effective-medium theory  16  , the generalized plasmon-pole model  17  , the Drude-Lorentz model  18  , the hydrodynamic model  19  , the nonlocal response  20  , the local field correction  21  , the random phase approximation  22  , the Monte Carlo simulation  23  , the finite element method  24  , the numerical integration  25  , the variational principle  26  , the perturbation theory  27  , the renormalization group  28  , the self-consistent screening  29  ,",
        "watermark_text": "We present an analytic definition for the thermal Casimir force acting on two connected sheets formed out of different materials , one being metallic ( silver ) while another is dielectric ( silicon dioxide ) . The result obtained agrees with that derived by Lifshitz principle within 1 % accuracy in the whole range of separations mentioned here .We also demonstrate how our findings can be used to estimate the temperature dependence of the Casimir pressure at fixed separation distance . In this research we study the case where one plate contains of silver and other of silicon dioxide .Silver has been chosen because it is widely useful as a coating layer in microelectromechanical systems ( MEMS ) , whereas SiO2 is often employed as a substrate or insulator layer in MEMS devices . Our results are applicable not only to these individual cases but also to any system consisting of two connected sheets connected by vacuum gap filled with liquid medium .This encompasses such diverse situations like semiconductor heterostructures , quantum dots , nanowires etc . , which have garnered considerable scrutiny lately owing to their potential applications in nanotechnology . It should be mentioned that the issue under consideration was first addressed theoretically more than 50 centuries earlier 1 .However , despite several attempts 2 , no accurate solution has already been finding . Therefore , most theoretical experiments were performed using approximate methods 3 - 6 .These approaches involve various alterations of the proximity stress approximation 7 , 8 , the Derjaguin - Muller - Toporov method 9 , the multiple mirror expansion 10 , the scattering matrix formalism 11 , the Green s function method 12 , the density functional theory 13 , the mode summation 14 , the fluctuating surface charge model 15 , the effective - medium theory 16 , the generalized plasmon - pole hypothesis 17 , the Drude - Lorentz model 18 , the hydrodynamic model 19 , the nonlocal response 20 , the local field correction 21 , the random phase approximation 22 , the Monte Carlo simulation 23 , the finite element method 24 , the numerical integration 25 , the variational theory 26 , the perturbation theory 27 , the renormalization group 28 , the self - consistent screening 29 ,",
        "ori-fast-z-score": 1.5461980716652028,
        "water-fast-z-score": 7.7309903583260144
    },
    {
        "original_text": "We present an improved quantum hard-sphere ground-state equation-of-state (EOS) for the description of dense matter in astrophysics and nuclear physics, which is based on the exact solution to the Schrödinger equation with a repulsive delta-function potential. The EOS has been derived by solving numerically the corresponding integral equations using the method of successive iterations. We have also obtained analytical expressions for the pressure and energy density as functions of the number density at zero temperature. Our results are compared with those calculated previously within various approximations such as the virial expansion up to second order, the Carnahan-Starling approximation, and the Percus-Yevick approximation. It turns out that our new EOS agrees well with these previous calculations over wide ranges of densities and temperatures. In particular, it reproduces very accurately the low-density limit where the ideal gas law holds exactly. \n \n Keywords: Equation of state",
        "watermark_text": "We introduce an efficient quantum hard - sphere ground - state equation - of - state ( EOS ) for the description of dense materials in astrophysics and nuclear science , which is based on the exact solution to the Schrödinger equation with a repulsive delta - function potential . The EOS has been constructed by solving numerically the equivalent integral equations using the method of successive iterations .We have already established analytical expressions for the pressure and energy density as functions of the number density at zero temperature . Our results are compared with those estimated previously within various approximations such as the virial expansion up to second order , the Carnahan - Starling approximation , and the Percus - Yevick approximation .It turns out that our new EOS agrees well with these previous calculations over broad ranges of densities and temperatures . In particular , it reproduces very correctly the small - density maximum where the ideal gas theory holds exactly .Keywords: Equation of state",
        "ori-fast-z-score": 0.8427009716003844,
        "water-fast-z-score": 3.731961445658845
    },
    {
        "original_text": "We present new experimental results on the relaxation dynamics of a liquid film that is pulled off an inclined solid substrate by gravity and capillarity. The experiments are performed in a microgravity environment aboard the International Space Station (ISS). We find that, for sufficiently large pulling speeds, the relaxation process can be described as a succession of three stages. In stage I, the contact angle decreases rapidly to its equilibrium value at which point the contact line stops moving. Stage II starts when the contact line has stopped moving; during this stage, the contact angle remains constant while the height profile of the free surface continues evolving towards its final shape. Finally, in stage III, the contact angle increases again until it reaches its initial value. This behavior is explained using a simple model based on lubrication theory. Our analysis shows that the relaxation time scales with the inverse of the pulling speed. For small pulling speeds, we observe deviations from our theoretical predictions due to inertial effects. \n \n Liquid films play important roles in many natural phenomena such as rain drops falling down a window or water evaporating into air. Dewetting processes occur frequently in nature but also have applications in industrial processes like coating technologies where thin films need to be removed from substrates. Understanding how these systems evolve over time requires knowledge about their relaxation dynamics after they have been perturbed out of equilibrium. Here, we study experimentally the relaxation of a liquid film that was pulled off an inclined solid wall by gravity and capillary forces.",
        "watermark_text": "We report new experimental results on the relaxation behavior of a liquid movie that is drawn off an inclined solid substrate by gravitational and capillarity . The studies are performed in a microgravity atmosphere aboard the International Space Station ( ISS ) .We see that , for enough large pulling speeds , the relaxation process can be described as a sequence of three stages . In stage I , the contact angle decreases quickly to its equilibrium value at which point the contact line stopping moved .Stage II began when the contact line has stopped movement ; during this phase , the contact angle remains regular while the height profile of the free boundary continues changing towards its final form . Finally , in stage III , the contact angle raises again until it hits its initial value .This phenomenon is understood using a simple model based on lubrication theory . Our study shows that the relaxation time varies with the inverse of the pulling velocity .For small pulling velocity , we perceive deviations from our theory assumptions owing to inertial influences . Liquid films play important roles in many natural phenomena such as rainfall drops sliding down a window or water evaporating into air .Dewetting methods happen widely in nature but also have applications in industrial systems like coating technologies where loose films need to be removed from substrates . Understanding how these systems develop over time needs experience about their relaxation behavior after they have been perturbed out of equilibrium .Here , we study experimentally the relaxation of a liquid movie that was yanked off an inclined solid wall by gravitational and capillary forces .",
        "ori-fast-z-score": -0.17277368511627203,
        "water-fast-z-score": 7.717436331412897
    },
    {
        "original_text": "The switching behavior and the photovoltaic properties of two new diarylethene derivative molecular junctions were investigated by using cyclic voltammetry, UV-Vis spectroscopy, and electrochemical impedance spectroscopy (EIS). The results show that both compounds can be switched between their open-ring isomer state and closed-ring isomer state in solution with different colors under visible light irradiation at room temperature. In addition to this reversible color change process, the photocurrent response was also observed for these molecules when they are used as active layers in organic solar cells. This work provides an insight into the relationship between the structure and function of diarylethene-based molecular switches. Switchable materials have attracted great attention because of their potential applications in optoelectronic devices such as optical memory storage systems, smart windows, and organic solar cells. \n \n Diarylethenes belong to one class of switchable materials which undergoes a rapid and complete structural transformation upon exposure to ultraviolet or visible light.  1  These unique features make them promising candidates for use in various fields including chemical sensors  2  , data storage  3  , and organic electronics  4  . However, most reported diarylethene based molecular switches suffer from poor solubility in common solvents  5  , low quantum yield  6  , and slow response time  7  . Therefore, it remains challenging to develop efficient diarylethene molecular switches with improved performance  8  .\n \nIn recent years, many efforts have been made to improve the performances of diarylethenes  9  -  11  . For example, some researchers introduced bulky substituents on the carbon atoms adjacent to the double bond  12  -  14  ; others synthesized diarylethenes containing electron-donating groups  15  -  17  . Although these modifications could enhance the solubility and quantum efficiency of diarylethens, the response times still remain relatively slow  18  . \n \n Herein we report two novel diarylethene dyes 1 and 2 ( Figure  1 ) bearing electron-withdrawing groups. Both compounds exhibit good solubility in common organic solvents and high quantum yields. They can",
        "watermark_text": "The switching activity and the photovoltaic properties of two new diarylethene derivative chemical junctions were researched by using cyclic voltammetry , UV - Vis spectroscopy , and electrochemical impedance spectroscopy ( EIS ) . The results show that both compounds can be switched between their closed - ring isomer state and opened - ring isomer state in solution with various shades under visible color irradiation at room temperature .In addition to this reversible color transformation process , the photocurrent response was also observed for these molecules when they are applied as active layers in organic solar systems . This research provides an insight into the relationship between the composition and activity of diarylethene - based molecular switches .Switchable materials have garnered great popularity because of their potential applications in optoelectronic products such as laser memory memory devices , smart mirrors , and organic solar devices . Diarylethenes represent to one category of switchable materials which undergoes a rapid and complete structural transformation upon exposure to ultraviolet or visible light .1 These unique features make them promising candidates for use in different fields including molecular sensors 2 , computer processing 3 , and organic devices 4 . However , most published diarylethene based molecular switches tend from poor solubility in standard solvents 5 , low quantum strength 6 , and poor response speed 7 .Therefore , it remains challenging to develop fast diarylethene molecular switches with improved performance 8 . In recent years , various efforts have been placed to improve the performances of diarylethenes 9 - 11 .For instance , some researchers incorporated bulky substituents on the carbon atoms adjacent to the double bond 12 - 14 ; others synthesized diarylethenes bearing electron - donating groups 15 - 17 . Although these alterations could enhance the solubility and quantum efficiency of diarylethens , the response periods currently continue relatively slow 18 .Herein we study two novel diarylethene dyes 1 and 2 ( Figure 1 ) containing electron - withdrawing groups . Both compounds exhibit great solubility in standard organic solvents and large quantum yields .They can",
        "ori-fast-z-score": -0.6446583712203042,
        "water-fast-z-score": 7.091242083423347
    },
    {
        "original_text": "We study the zero-lag synchronization between two identical chaotic systems with different time scales by using dynamical relaying method, which is based on introducing an intermediate system to transmit information between them. The stability analysis shows that the proposed scheme can achieve zero-lag synchronization under some conditions. Numerical simulations are performed for Lorenz and Chen systems as examples. It is shown that the proposed scheme has advantages over other existing methods in terms of robustness against parameter mismatch and external disturbances. \nI. INTRODUCTIO N\nSynchronization plays important roles in many fields such as biology  1  , physics  2  , engineering  3  . In recent years, chaos synchronization  4  -  6  has attracted much attention due to its potential applications in secure communication  7  , chemical reactions  8  , biological systems  9  .\nChaos synchronization was first studied by Pecora and Carroll  10  who introduced the concept of master-slave synchronization. Since then, various schemes have been developed  11  -  13  . Among these schemes, adaptive control  14  , active control  15  , backstepping  16  , sliding mode  17  , fuzzy logic  18  , impulsive control  19  , intermittent control  20  , pinning control  21  , etc., were widely used  22  -  24  . However, most of these works focused only on the case where there exists no delay between slave and master systems  25  -  27  . Recently, several studies have investigated the problem of synchronizing chaotic systems with time delays  28  -  30  . For example, Wu et al.  31  presented a new approach to realize lag-synchronized chaos between two chaotic systems with different dimensions through state feedback controllers. Liu et al.  32  designed a novel delayed-feedback controller to synchronize two chaotic systems with unknown parameters. Wang et al.  33  proposed a simple but effective method to synchronize two chaotically oscillating systems with time-varying delays. Although these results provide useful insights into the design of synchronized chaotic systems with time-delays, they cannot be applied directly to solve practical problems because it may take too",
        "watermark_text": "We explore the zero - lag synchronization between two unrelated turbulent systems with varying time ranges by using dynamical relaying model , which is based on introducing an intermediate system to transmit data between them . The stability analysis shows that the suggested system can attain zero - lag synchronization under some conditions .Numerical simulations are performed for Lorenz and Chen networks as instance . It is demonstrated that the suggested system has advantages over other existing techniques in terms of robustness against parameter mismatch and external disturbances .I . INTRODUCTIO N Synchronization plays important roles in different fields such as biology 1 , physics 2 , engineering 3 . In past decades , chaos synchronization 4 - 6 has drew much attention due to its potential applications in safe communication 7 , chemical processes 8 , biological systems 9 .Chaos synchronization was first investigated by Pecora and Carroll 10 who proposed the idea of master - servant synchronization . Since then , various strategies have been created 11 - 13 .Among these schemes , adaptive control 14 , active control 15 , backstepping 16 , sliding mode 17 , fuzzy logic 18 , impulsive control 19 , continuous control 20 , dragging control 21 , etc . , were commonly used 22 - 24 . However , most of these works focused only on the case where there exists no delay between slave and master schemes 25 - 27 .Recently , various studies have explored the issue of synchronizing dynamic systems with time delays 28 - 30 . For instance , Wu et al .31 presented a new approach to realize lag - synchronized chaos between two chaotic structures with varying dimensions through state feedback controllers . Liu et al .32 designed a innovative delayed - feedback controller to synchronize two chaotic structures with unknown parameters . Wang et al .33 introduced a simple but effective model to synchronize two chaotically oscillating systems with time - differing delays . Although these results present valuable insights into the creation of synchronized turbulent systems with time - delays , they cannot be applied directly to solve practical questions because it could took too",
        "ori-fast-z-score": -0.08192319205190406,
        "water-fast-z-score": 8.16496580927726
    },
    {
        "original_text": "The prediction of the next cycle is an important problem in space weather research, which has been studied for more than half century. In this work we use two different methods to predict the strength and duration of the twenty-first solar cycle (SC21). The first method uses artificial neural networks trained on data from previous cycles. We find that our network predicts SC21 with high accuracy. The second method relies on the analysis of sunspot number time series using wavelet transform. This approach allows us to identify periodicities in the signal related to the solar activity. Our results show that both approaches are able to make accurate predictions about the upcoming solar cycle. Solar activity exhibits cyclic behavior over multiple timescales ranging from minutes up to thousands years. Understanding these cycles can help us better understand how the Sun works as well as its influence on Earths climate. \n \n Predicting the strength and duration of forthcoming solar cycles is one of the most challenging problems in space weather research. It was shown by several authors that it is possible to forecast the amplitude of the current cycle based on information available at the beginning of the cycle itself  1  . However, predicting the exact timing of maxima or minima within each cycle remains difficult  2  . \n \n Here we present two independent methods to predict the properties of the twenty-first solar activity cycle (SC21) starting from the end of twentieth cycle (SC20), i.e., from January 2010. Both methods rely only on publicly available data sets obtained from NASA s Space Weather Prediction Center  3  , NOAA  4  , and SIDC  5  .\n \nMethod 1: Artificial Neural Networks \n \n First, we train an artificial neural network  6  on data from past solar cycles. Specifically, we consider the following inputs: 1) monthly mean sunspot numbers; 2) monthly mean 10.7-cm radio flux values; 3) monthly mean F10.7 index; 4) monthly mean Mg II index. These quantities were averaged over the last ten solar cycles prior to SC20. For example, if we want to predict SC21, then we average all four quantities between December 2009 and November 2019. Note that",
        "watermark_text": "The calculation of the new cycle is an important task in space weather study , which has been studied for more than quarter century . In this study we using two different methods to predict the strength and duration of the hundred - first solar cycle ( SC21 ) .The first method uses artificial neural systems trained on evidence from previous periods . We see that our system predicts SC21 with high clarity .The second method relies on the characterization of sunspot number period series employing wavelet transform . This method enables us to identify periodicities in the signal related to the sun activity .Our results show that both approaches are able to make accurate forecast about the ongoing solar cycle . Solar behavior exhibits cyclic behavior over numerous timescales varied from seconds up to thousands decades .Understanding these cycles can help us better understand how the Sun operates as well as its influence on Earths environment . Predicting the strength and duration of forthcoming solar cycles is one of the most challenging difficulties in space weather study .It was shown by various papers that it is easy to forecast the frequency of the present process depending on knowledge accessible at the beginning of the cycle itself 1 . However , predicting the exact timing of maxima or minima within each cycle remains impossible 2 .Here we present two independent methods to predict the properties of the twenty - first solar activity period ( SC21 ) beginning from the end of twentieth cycle ( SC20 ) , i . e . , from January 2010 . Both methods rely only on publicly accessible data sets taken from NASA s Space Weather Prediction Center 3 , NOAA 4 , and SIDC 5 .Method 1 : Artificial Neural Networks First , we develop an synthetic cognitive network 6 on evidence from previous solar cycles . Specifically , we investigate the following output : 1 ) weekly mean sunspot numbers ; 2 ) weekly mean 10 . 7 - cm radio flux values ; 3 ) weekly mean F10 . 7 index ; 4 ) weekly mean Mg II index .These quantities were averaged over the last ten solar cycles prior to SC20 . For instance , if we wish to predict SC21 , then we average all four quantities between December 2009 and November 2019 .Note that",
        "ori-fast-z-score": 1.543033499620919,
        "water-fast-z-score": 9.412504347687607
    },
    {
        "original_text": "We report on infrared spectroscopic observations with the Infrared Spectrograph (IRS) aboard the Spitzer Space Telescope toward the nearby late-type galaxy NGC 3621, which is known to harbor a supermassive black hole at its center. The IRS spectrum shows prominent emission lines such as  Ne II 12.81 and  S III 18.71 µm that are commonly seen in active galactic nuclei (AGNs). We find that these emission lines can be reproduced by photoionization models using AGN-like ionizing radiation fields. From the observed line ratios we estimate the electron density n e = 10 3 cm −3 , temperature T e = 1000 K, and ionization parameter U H = 1 × 10 −2 . These results suggest that the central region of NGC 3621 has properties similar to those found for Seyfert galaxies. This work was supported by NASA through grant number GO-08460.01-A awarded by the Jet Propulsion Laboratory, California Institute of Technology under contract with NASA.",
        "watermark_text": "We report on infrared spectroscopic observations with the Infrared Spectrograph ( IRS ) aboard the Spitzer Space Telescope toward the nearby mid - class galaxy NGC 3621 , which is known to harbor a supermassive black hole at its core . The IRS spectrum displays large emitted lines such as Ne II 12 . 81 and S III 18 . 71 µm that are often observed in active galactic nuclei ( AGNs ) .We see that these radiation patterns can be reproduced by photoionization models using AGN - like ionizing radiation fields . From the known line ratios we estimate the electron concentration h e = 10 3 cm −3 , temperature T e = 1000 K , and ionization variable U H = 1 × 10 −2 .These results show that the central region of NGC 3621 has properties similar to those found for Seyfert galaxies . This work was supported by NASA through grant number GO - 08460 . 01 - A awarded by the Jet Propulsion Laboratory , California Institute of Technology under contract with NASA .",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 3.640679257301507
    },
    {
        "original_text": "We consider the problem of decoding linear block codes over an arbitrary finite field using the min-sum algorithm, which is one of the most popular algorithms in practical applications such as Turbo coding.  We show that under certain conditions on the degree distribution of parity-check nodes, there exists a unique optimal solution to the optimization problem associated with each node update rule at every iteration of the min-sum decoder. This result leads us to propose a new stability condition for the min-sum decoder based on the concept of local convergence. The proposed stability condition can be used to determine whether or not the min-sum decoder converges globally by checking if it locally converges within a small number of iterations. Finally, we present simulation results showing that our proposed stability condition outperforms existing ones when applied to LDPC codes. In this work, we study the problem of decoding linear binary block codes using the min-sum (MS) algorithm  1  , which has been widely adopted in many practical communication systems including Turbo-coding  2  . It was shown in  3  -  5  that MS decoding achieves near maximum-likelihood performance while requiring only low complexity per bit compared to other iterative decoders  6  .\nIn general, the MS algorithm solves the following problem: given a codeword c =  c0 c1 . . . cm−1  ∈ Fm−1 2\n, find the vector x * ∈ F2 n satisfying Hx * = c where H denotes the parity check matrix of size m × n. To solve this problem, the MS algorithm performs message passing between variable nodes and parity-check nodes according to the following rules: 1) At each iteration t, compute the log likelihood ratio (LLR) λt(i), i ∈ {0, . . . , m − 1}, corresponding to ci as: \nwhere N (j) represents the set of neighbors connected to j via edges in H; 2) Update the LLRs of all parity-check nodes:",
        "watermark_text": "We consider the question of decoding linear block sequences over an arbitrary finite field using the min - sum algorithm , which is one of the most popular methods in practical applications such as Turbo coding . We see that under certain conditions on the degree distribution of parity - check vertices , there exists a unique optimal solving to the algorithms issue associated with each node update rule at every iteration of the min - sum decoder .This result leads us to propose a new stability condition for the min - sum decoder relying on the idea of local convergence . The proposed stability condition can be used to determine whether or not the min - sum decoder converges worldwide by testing if it locally converges within a small number of iterations .Finally , we present modeling results confirming that our proposed stability situation outperforms current ones when applied to LDPC coding . In this research , we study the question of decoding linear binary block sequences using the min - sum ( MS ) algorithm 1 , which has been widely adopted in many practical communication schemes notably Turbo - codes 2 .It was shown in 3 - 5 that MS decoding achieves near maximum - likelihood performance while using only low complexity per bit relative to other iterative decoders 6 . In general , the MS algorithm solves the following task : given a codeword c = c0 c1 ...cm−1 ∈ Fm−1 2 , find the vector x * ∈ F2 n satisfying Hx * = c where H represents the parity check matrix of width m × n . To solve this situation , the MS algorithm performs message passing between variable nodes and parity - check nodes according to the following laws : 1 ) At each iteration t , compute the log probability ratio ( LLR ) λt ( i ) , i ∈ { 0 , . .. , m − 1 } , analogous to ci as : where N ( j ) indicates the group of neighbors connected to j via paths in H ; 2 ) Update the LLRs of all parity - check vertices :",
        "ori-fast-z-score": -0.16783627165933782,
        "water-fast-z-score": 5.937318271050344
    },
    {
        "original_text": "We present optical and near-infrared photometry of SN 2006bp, which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett (Puckett et al., 2007) . The supernova is located at an unusually large distance for its host galaxy, with a recession velocity of ~1000 km/sec. \n \n We find that the light curve can be well fit using a model consisting of three components: shock breakout emission, radioactive decay powered luminosity, and dust extinction. Using this model we derive physical parameters such as the progenitor radius, mass loss rate, and explosion energy. Our results are consistent with those found for other type-II SNe but suggest that the progenitor star had a lower initial mass than previously thought. This may indicate that there exists more diversity among progenitors of type-II SNe than has been realized so far. In addition to these findings, our observations provide new insights into the physics of shock breakout and early-time evolution of type-II SNe.",
        "watermark_text": "We present visual and far - infrared photometry of SN 2006bp , which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett ( Puckett et al . , 2007 ) . The supernova is situated at an exceptionally wide distance for its host galaxy , with a collapse speeds of ~ 1000 cm / sec .We see that the light spiral can be well fitting using a description consisting of three components : shock breakout emission , radioactive decay powered luminosity , and dust extinction . Using this description we derive physical factors such as the progenitor diameter , mass loss rate , and explosion power .Our results are compatible with those detected for other class - II SNe but suggest that the progenitor star had a smaller original mass than previously thought . This might suggest that there exists more diversity among progenitors of type - II SNe than has been realized so far .In addition to these results , our observations offer additional perspectives into the physics of wave breakout and first - time evolution of type - II SNe .",
        "ori-fast-z-score": -0.9299811099505543,
        "water-fast-z-score": 5.579886659703326
    },
    {
        "original_text": "The distance geometry problem is the following: given n points in space, find their coordinates such that they are as close to each other as possible while respecting some constraints on distances between pairs of points.  In this work we consider an application of the distance geometry problem to music analysis and propose a novel method for automatic transcription of musical scores into symbolic representations based on the concept of pitch class profiles (PCP). The proposed approach allows us to recover the underlying harmonic structure of polyphonic music by solving a system of quadratic equations with linear equality constraints using convex optimization techniques. We demonstrate our algorithm s performance on several classical piano pieces. 1 Introduction\n\nMusic Analysis\nAutomatic transcription of musical scores has been one of the most challenging problems in computer science over the past decades. It consists of recovering the underlying harmonic structure of a piece of music from its audio signal or MIDI file. This task can be divided into two main subtasks:  detection of note onset times; estimation of pitches at detected notes  locations. Note onset time detection is usually performed by applying various heuristics to the raw audio data  22, 23  . Once the note onset times have been determined, the next step is to estimate the pitches corresponding to these events. There exist many different approaches to solve this problem ranging from simple template matching methods to more sophisticated statistical models  7, 8, 10, 11, 13, 14, 16, 17, 19-21, 24-26  .\nIn this work we focus on the second part of the problem -estimation of pitches-which is known as  pitch estimation  or  pitch tracking . Pitch tracking algorithms try to assign a pitch value to every detected event in order to obtain a sequence of pitch values which correspond to the original score. A common way to represent pitches is through so-called pitch-class profiles (PCPs)  6, 12, 15, 18, 27  , where each entry corresponds to the number of occurrences of a particular pitch within a certain window around the current time instant. For example, Figure 1 shows a typical PCP obtained from a single-note mel",
        "watermark_text": "The distance geometry issue is the following : given n points in space , find their coordinates such that they are as close to each other as possible while respecting some restrictions on distances between pairs of points . In this study we investigate an use of the distance geometry issue to music analysis and suggest a new method for efficient reproduction of visual scores into symbolic representations based on the idea of pitch class profiles ( PCP ) .The proposed approach allows us to regain the fundamental chord form of polyphonic music by modeling a system of quadratic variables with linear equality restrictions utilizing convex optimization tools . We test our algorithm s playing on numerous traditional instrument pieces .1 Introduction Music Analysis Automatic recording of musical scores has been one of the most challenging difficulties in computer science over the previous decades . It consists of finding the fundamental chord form of a work of music from its audio stream or MIDI file .This job can be grouped into two principal subtasks : detection of note onset times ; estimation of pitches at identified notes sites . Note onset time detection is usually performed by using numerous heuristics to the raw audio information 22 , 23 .Once the tone arrival times have been determined , the second step is to estimate the pitches corresponding to these events . There remain many various approaches to solve this question ranging from complicated template matching algorithms to more sophisticated mathematical models 7 , 8 , 10 , 11 , 13 , 14 , 16 , 17 , 19 - 21 , 24 - 26 .In this research we focus on the second part of the question - estimation of pitches - which is known as pitch estimation or pitch tracking . Pitch tracking schemes seek to give a pitch number to every detected occurrence in order to obtain a sequence of pitch values which coincide to the actual performance .A popular way to represent notes is through so - called pitch - class profiles ( PCPs ) 6 , 12 , 15 , 18 , 27 , where each entry relates to the quantity of occurrences of a certain pitch within a certain window around the present time instant . For instance , Figure 1 shows a typical PCP obtained from a single - note mel",
        "ori-fast-z-score": -0.37582301400141443,
        "water-fast-z-score": 9.594005619147026
    },
    {
        "original_text": "We present the results of our analysis on stellar surface structure effects in high precision space-based optical astrometric observations, which are expected to be achieved by future space missions such as Gaia and SIM. We show that these effects can cause systematic errors in the derived parameters for individual stars with precisions better than 1 microarcsecond (mas). The main sources of error include limb darkening effect, gravity brightening effect, and rotational distortion effect. These effects depend strongly on the spectral type of observed stars. For example, we find that the rotationally distorted shape of late-type giant stars may lead to an apparent shift of up to several mas between their positions measured at different epochs. This is comparable or even larger than the accuracy goal set for Gaia mission. Therefore it will be necessary to take into account these effects when analyzing data obtained by future space missions. Keywords: Astrometry, Gravity",
        "watermark_text": "We present the conclusion of our analysis on stellar surface structure effects in high precision space - based optical astrometric observations , which are expected to be completed by future space missions such as Gaia and SIM . We suggest that these influences can cause deliberate errors in the derived parameters for individual stars with precisions higher than 1 microarcsecond ( mas ) .The main sources of error include limb darkening effect , gravity brightening effect , and rotational interference effect . These effects influence heavily on the spectral type of measured stars .For instance , we find that the rotationally altered form of late - class giant stars would result to an apparent shift of up to several mas between their positions measured at different epochs . This is analogous or especially bigger than the accuracy goal set for Gaia expedition .Therefore it will be required to take into consideration these influences when examining data received by future orbital flights . Keywords : Astrometry , Gravity",
        "ori-fast-z-score": 0.45291081365783825,
        "water-fast-z-score": 5.887840577551898
    },
    {
        "original_text": "We present new measurements of line emission for the brightest cluster galaxies (BCGs) in clusters with z < 0.3, using data obtained by the Chandra X-ray Observatory. We find that BCGs  optical luminosities are correlated strongly with their soft-band X-ray luminosities; this correlation is stronger than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity.  The observed relationship can be explained if we assume that most of the X-rays come from inverse Compton scattering off hot electrons associated with the central supermassive black holes. This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs. In addition to the strong correlation between Lopt and LX , we also observe a weak but significant anti-correlation between Lopt and the temperature Tgas of the intracluster medium surrounding each galaxy. These results suggest that the gas density around these galaxies decreases as they evolve into more massive systems.",
        "watermark_text": "We present new studies of line emission for the brightest cluster stars ( BCGs ) in clusters with z < 0 . 3 , using data derived by the Chandra X - ray Observatory . We see that BCGs visual luminosities are correlated heavily with their soft - band X - ray luminosities ; this relationship is strengthened than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity .The observed relationship can be described if we suppose that most of the X - radiation come from inverse Compton absorption off warm particles associated with the main supermassive black holes . This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs .In addition to the strong correlation between Lopt and LX , we also observe a weak but significant anti - correlation between Lopt and the temperature Tgas of the intracluster medium circling each galaxy . These data suggest that the gas density around these objects decreases as they develop into more massive structures .",
        "ori-fast-z-score": 1.5428161556520092,
        "water-fast-z-score": 6.527299120066193
    },
    {
        "original_text": "The Fermi Large Area Telescope (LAT) is the primary instrument on NASA s Fermi satellite, launched in June 2008 to study high-energy gamma rays and cosmic rays. The LAT has been taking data since August 4, 2008, and it continues to operate today. This talk will present highlights of recent results obtained by the LAT collaboration using this unique dataset. These include new measurements of the diffuse extragalactic background light at high energies, constraints on dark matter annihilation models, and studies of blazars as potential sources for ultra-high energy cosmic rays. I will also discuss some of the challenges associated with analyzing such large datasets. Finally, I will briefly describe plans for future observations that could be made with the LAT. Keywords: High-Energy Astrophysics, Dark Matter, Blazar, Ultra-High Energy Cosmic Ray, Diffuse Extragalactic Background Light. Title: Studies of Cosmic Rays With GeV Gamma Rays",
        "watermark_text": "The Fermi Large Area Telescope ( LAT ) is the primary instrument on NASA s Fermi satellite , launched in June 2008 to study high - energy beta particles and cosmic rays . The LAT has been took images since August 4 , 2008 , and it continues to run today .This discussion will present highlights of recent results derived by the LAT collaboration using this innovative dataset . These include new detection of the diffuse extragalactic background light at high energies , constraints on dark matter annihilation predictions , and investigations of blazars as possible sources for ultra - large energy cosmic rays .I will also discuss some of the challenges associated with analyzing such large datasets . Finally , I will briefly outline plans for future data that might be made with the LAT .Keywords : High - Energy Astrophysics , Dark Matter , Blazar , Ultra - High Energy Cosmic Ray , Diffuse Extragalactic Background Light . Title : Studies of Cosmic Rays With GeV Gamma Rays",
        "ori-fast-z-score": 1.5491933384829668,
        "water-fast-z-score": 5.337745350213779
    },
    {
        "original_text": "We present the results of searches for gravitational wave signals from compact binary coalescences (CBCs) using data collected by the third and fourth science runs (S3, S4) of the Laser Interferometer Gravitational-Wave Observatory (LIGO). We use two different search methods to look for CBCs: an unmodeled matched filter method that is sensitive to all possible source orientations; and a modeled template bank method which uses templates based on post-Newtonian expansions of general relativity. The latter method has higher sensitivity but only covers certain regions of parameter space. In this work we report upper limits on the rate density of CBC events as a function of chirp mass and total mass. These are derived under the assumption that the observed event rates follow Poisson statistics with no background noise. For both search methods, our most stringent upper limit is obtained at high masses where the signal-to-noise ratio decreases rapidly due to detector antenna response functions.",
        "watermark_text": "We present the results of investigations for gravitational wave signals from compact binary coalescences ( CBCs ) using data taken by the third and fifth science ran ( S3 , S4 ) of the Laser Interferometer Gravitational - Wave Observatory ( LIGO ) . We use two different search methods to find for CBCs : an unmodeled matched filter method that is sensitive to all possible source orientations ; and a modeled template bank method which uses templates based on post - Newtonian expansions of general relativity .The last approach has larger resolution but only covers certain regions of parameter space . In this research we publish higher restrictions on the frequency density of CBC events as a function of chirp mass and total mass .These are derived under the assumption that the seen event frequencies follow Poisson statistics with no background noise . For both search methods , our most stringent upper maximum is achieved at high masses where the signal - to - noise proportion decreases quickly due to detector antenna reaction functions .",
        "ori-fast-z-score": -0.3333333333333333,
        "water-fast-z-score": 4.777777777777778
    },
    {
        "original_text": "We present an analytical model to study the effect of mass loading feedback on particle concentration and enstrophy in fully developed turbulence. The cascade process is modeled by using a set of coupled ordinary differential equations, which are derived based on dimensional analysis and Kolmogorov s similarity hypothesis. We show that the presence of particles can significantly affect both the energy transfer rate between different scales as well as the dissipation rates at small scales. In particular, we find that the total amount of energy transferred into smaller scales decreases when there exists significant mass loading feedback. This result suggests that the presence of heavy particles may lead to reduced turbulent mixing efficiency. Finally, our results also indicate that the effects of mass loading feedback become more pronounced if the Stokes number increases or the initial volume fraction of particles becomes larger. Our findings provide useful insights into understanding how heavy particles influence the dynamics of fluid flows. C \nAuthor(s): Yi-Chun Chen , Shih-Chieh Hwang , Chia-Hui Wu , Yu-Ting Lin , Ming-Yuan Liu , Chao-Lin Wang , Jie-Sheng Huang , Wen-Ju Tsai , Tzi-Chao Chan , Chin-Fa Lee , Kuo-Yang Chang , Chung-Ming Yeh , Yuan-Kang Chiou , Chien-Nan Chu , Cheng-Wei Hsieh , Chien-Wen Lu , Chien-Chung Wu , Chien-Shu Chen , Chien-Chin Wu , Chien-Chin Yang , Chien-Chin Lai , Chien-Chin Su , Chien-Chin Hung , Chien-Chin Chen , Chien-Ching Wu , Chien-Ching Tai , Chien-Ching Li , Chien-Ching Sun , Chien-Ching Liang , Chien-Ching Chen , Chien-Chong Wu , Chien-Chung Chen , Chien-Chung Lai , Chien-Chung Su , Chien-Chung Hung , Chien-Chung",
        "watermark_text": "We present an analytical theory to study the impact of mass displacement feedback on particle concentration and enstrophy in fully developed turbulence . The cascade process is modeled by using a setting of coupled ordinary differential coefficients , which are derived based on dimensional evaluation and Kolmogorov s similarity hypothesis .We see that the presence of particles can significantly affect both the power transfer frequency between various scales as well as the dissipation levels at small scales . In particular , we find that the total quantity of power sent into smaller scales decreases when there exists significant volume displacement feedback .This result suggests that the presence of hard particles may contribute to reduced fluid mixing efficiency . Finally , our findings also suggest that the effects of mass displacement feedback become more pronounced if the Stokes number increases or the initial volume fraction of molecules changes larger .Our findings provide useful insights into studying how heavy grains alter the dynamics of fluid flows . C Author ( s ) : Yi - Chun Chen , Shih - Chieh Hwang , Chia - Hui Wu , Yu - Ting Lin , Ming - Yuan Liu , Chao - Lin Wang , Jie - Sheng Huang , Wen - Ju Tsai , Tzi - Chao Chan , Chin - Fa Lee , Kuo - Yang Chang , Chung - Ming Yeh , Yuan - Kang Chiou , Chien - Nan Chu , Cheng - Wei Hsieh , Chien - Wen Lu , Chien - Chung Wu , Chien - Shu Chen , Chien - Chin Wu , Chien - Chin Yang , Chien - Chin Lai , Chien - Chin Su , Chien - Chin Hung , Chien - Chin Chen , Chien - Ching Wu , Chien - Ching Tai , Chien - Ching Li , Chien - Ching Sun , Chien - Ching Liang , Chien - Ching Chen , Chien - Chong Wu , Chien - Chung Chen , Chien - Chung Lai , Chien - Chung Su , Chien - Chung Hung , Chien - Chung",
        "ori-fast-z-score": 0.7844645405527362,
        "water-fast-z-score": 7.060180864974626
    },
    {
        "original_text": "We present the results of an analysis of the anisotropy in the distribution of satellite galaxies around isolated field galaxies, using data obtained by the Sloan Digital Sky Survey (SDSS). We find that there is no significant difference between the distributions for satellites with different luminosities or colors and those found around central cluster galaxies. The observed anisotropies are consistent with predictions based on tidal forces acting during galaxy mergers. This suggests that these effects may be responsible for the formation of both clusters and groups of galaxies. \n \n Keywords: Galaxy merger, Group/cluster of galaxies, Tidal stripping, SDSS, Isolated galaxy \n \n \n \n 1 Introduction \n \n Clusters of galaxies contain many thousands of galaxies which reside within a common dark matter halo. These systems form through gravitational collapse driven by the mutual attraction of their constituent galaxies. However, it remains unclear how this process occurs over time-scales ranging from individual galaxy interactions to the assembly of massive clusters containing hundreds of member galaxies. In particular, we do not know whether all galaxies evolve into members of large clusters or if some fraction remain as isolated field galaxies throughout cosmic history. \n \n 2 Previous Work \n \n Several studies have investigated the properties of satellite galaxies surrounding brightest cluster galaxies (BCGs) at low redshifts z < 0.1. For example, Carlberg et al. (1997), Lin & Mohr (2004a), and Hansen et al. (2005) used samples of BCG-satellite pairs selected from optical surveys such as the Palomar Observatory Sky Survey (POSS-II; Reid et al., 1991) and the Sloan Digital Sky Surveys (SDSS; York et al., 2000). They found that the number density profiles of satellite galaxies show strong deviations from spherical symmetry, indicating that they are distributed anisotropically about their host galaxies. Furthermore, they showed that the degree of anisotropy depends strongly on the projected distance from the center of the host galaxy. At small distances, the radial profile shows a steep decline towards the center of the host while the tangential component increases rapidly beyond a characteristic radius R",
        "watermark_text": "We present the conclusion of an assessment of the anisotropy in the distribution of satellite galaxies around dispersed field galaxies , using data derived by the Sloan Digital Sky Survey ( SDSS ) . We see that there is no major variation between the distributions for satellites with various luminosities or colors and those found around central cluster clusters .The observed anisotropies are compatible with predictions based on tidal forces acting during galaxy mergers . This implies that these influences might be responsible for the formation of both clusters and groups of clusters .Keywords : Galaxy consolidation , Group / cluster of galaxies , Tidal stripping , SDSS , Isolated galaxy 1 Introduction Clusters of galaxies contain many thousands of galaxies which reside within a common dark matter halo . These systems create through gravity collapse driven by the mutual proximity of their constituent galaxies .However , it remains unsure how this process occurs over time - scales ranging from individual galaxy encounters to the assembly of vast clusters containing hundreds of member galaxies . In particular , we do not understand whether all galaxies evolve into members of large clusters or if some fraction remain as isolated ring galaxies throughout cosmic history .2 Previous Work Several studies have explored the properties of satellite galaxies surrounding brightest cluster clusters ( BCGs ) at low redshifts z < 0 . 1 . For instance , Carlberg et al .( 1997 ) , Lin & Mohr ( 2004a ) , and Hansen et al . ( 2005 ) used data of BCG - satellite pairs selected from optical surveys such as the Palomar Observatory Sky Survey ( POSS - II ; Reid et al . , 1991 ) and the Sloan Digital Sky Surveys ( SDSS ; York et al . , 2000 ) .They found that the number density patterns of satellite galaxies show strong deviations from spherical symmetry , showing that they are distributed anisotropically about their host galaxies . Furthermore , they demonstrated that the degree of anisotropy depends strongly on the projected distance from the hub of the host galaxy .At small distances , the radial profile displays a sharp decline towards the hub of the host while the tangential component increases quickly beyond a typical radius R",
        "ori-fast-z-score": 0.242535625036333,
        "water-fast-z-score": 5.640760748177662
    },
    {
        "original_text": "The detection and study of cosmic rays is one of the main goals for imaging atmospheric Cherenkov telescopes (IACTs). The background produced by these events can be reduced using different techniques, such as cuts on shower parameters or image cleaning algorithms. In this work we present an alternative method to reduce the background based on machine learning techniques. We use Random Forest classifiers trained with simulated data to identify cosmic-ray images among all recorded IACT images. This approach allows us to obtain results similar to those obtained with other methods but at lower computational cost. Finally, we apply our technique to real data taken with HESS-II telescope during its first year of operation. Our analysis shows that it is possible to improve the quality of reconstructed gamma-ray showers while reducing the number of rejected hadronic showers. \n \n Keywords: Machine Learning; Cosmic Ray Identification; Image Cleaning; Gamma-ray Astrophysics; Hadronic Shower",
        "watermark_text": "The observation and investigation of cosmic rays is one of the main goals for imaging atmospheric Cherenkov telescopes ( IACTs ) . The background formed by these events can be reduced use different methods , such as cuts on shower parameters or image cleaning algorithms .In this project we present an additional method to reduce the background based on machine learning techniques . We use Random Forest classifiers trained with simulated evidence to identify cosmic - ray pictures among all collected IACT images .This method enables us to obtain results comparable to those acquired with other methods but at lower mathematical price . Finally , we apply our technique to real information taken with HESS - II telescope during its initial season of operation .Our study shows that it is possible to upgrade the performance of reconstructed alpha - ray showers while reducing the quantity of rejected hadronic showers . Keywords : Machine Learning ; Cosmic Ray Identification ; Image Cleaning ; Gamma - ray Astrophysics ; Hadronic Shower",
        "ori-fast-z-score": 0.46499055497527714,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "In this work, we consider the problem of scanning data in multi-dimensional space with noisy measurements. We propose an algorithm that sequentially decides which dimension to scan next based on the current measurement vector. The proposed method is shown to be optimal under certain conditions. In addition, it can also handle cases where there are multiple targets present simultaneously. Finally, numerical results show that our approach outperforms existing methods by orders of magnitude. \n \n Keywords: Scanning, sequential decision making, multi-object tracking, information-theoretic analysis \n \n 1 Introduction \n \n In many applications such as radar detection  1  , sonar  2  or computer vision  3  , one needs to detect objects (e.g., aircrafts) in multi-dimensional spaces using limited resources. For example, in air traffic control  4  , radars need to track several aircrafts at once while minimizing false alarms due to clutter noise. This task requires efficient algorithms to decide how to allocate available resources among different dimensions so that the overall performance is optimized. A common strategy used in these problems is to perform scans along each dimension separately until some stopping criterion is met. However, this may lead to suboptimal solutions since the best solution depends not only on the current measurement but also on future measurements. Therefore, it becomes necessary to develop new techniques to solve these problems more efficiently. \n \n In recent years, significant progress has been made towards solving various resource allocation problems related to multi-target tracking  5  . Most of them focus on optimizing the number of sensors  6  , their locations  7, 8  , or the sensor network topology  9  . These works assume that all target states are known exactly before performing any optimization. However, in practice, target state estimates are often uncertain because they are obtained through noisy measurements  10  . As a result, the aforementioned approaches cannot guarantee global optimality when applied directly to practical scenarios  11  . \n \n To address this issue, researchers have developed robust versions of classical resource allocation strategies  12  . They typically use worst-case formulations  13  to ensure that the resulting allocations remain feasible even if the true target states deviate significantly...",
        "watermark_text": "In this research , we investigate the question of scanning data in multi - dimensional space with noisy measurements . We suggest an algorithm that sequentially decides which dimension to scan next depending on the current measurement vector .The proposed approach is demonstrated to be appropriate under certain conditions . In addition , it can also handle cases where there are multiple targets present concurrently .Finally , numerical findings show that our approach outperforms current methods by orders of magnitude . Keywords : Scanning , sequential decision making , multi - object sensing , info - theoretic analysis 1 Introduction In many applications such as radar detection 1 , sonar 2 or computer vision 3 , one needs to identify images ( e . g . , aircrafts ) in multi - dimensional spaces utilizing limited resources .For instance , in airline traffic control 4 , radars need to track numerous aircrafts at once while minimizing false alarms due to clutter sound . This job needs efficient techniques to choose how to allocate available resources among different dimensions so that the overall performance is optimized .A typical strategy used in these problems is to conduct scans along each dimension separately until some stops criterion is reached . However , this might lead to suboptimal solutions since the best solution depends not only on the present observation but also on future measurements .Therefore , it becomes necessary to develop new tactics to solve these problems more efficiently . In recent seasons , substantial advances has been achieved towards solving various resource transfer problems related to multi - target tracking 5 .Most of them rely on optimizing the number of measurements 6 , their destinations 7 , 8 , or the sensor network topology 9 . These works assume that all target states are known exactly before performing any optimization .However , in practice , target state measurements are often uncertain because they are derived through noisy measurements 10 . As a result , the aforementioned approaches lack guarantee global optimality when applied directly to practical situations 11 .To address this question , researchers have developed stable editions of classical asset distribution tactics 12 . They generally using worst - case formulations 13 to ensure that the resulting allocations remain viable even if the true target states deviate substantially . . .",
        "ori-fast-z-score": 1.3127849234810511,
        "water-fast-z-score": 9.286096001408149
    },
    {
        "original_text": "We present new near-infrared (NIR) and millimeter-wave observations toward the starless dense core FeSt 1-457, which is located in the Taurus molecular cloud complex at a distance of 140 pc. The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 December 8-9 under photometric conditions. We detected no point sources down to Ks = 20 mag within an area of 0.5 arcmin2 centered on the peak position of the dust continuum emission observed by SCUBA-2 on JCMT. In addition, we found that there are two peaks in the 1.3 mm continuum map made with MAMBO-II on IRAM 30 m telescope. These results suggest that this object may be a protostellar candidate or a prestellar core surrounded by infalling envelopes. To investigate its dynamical state further, we carried out high-resolution interferometric observations with Nobeyama 45-m radio telescope. Our results show that the central part of the core has a velocity gradient along the east-west direction, suggesting that it is collapsing.",
        "watermark_text": "We report new near - infrared ( NIR ) and millimeter - wave images toward the starless rich core FeSt 1 - 457 , which is situated in the Taurus molecular dust complex at a distance of 140 pc . The NIR data were obtained with the Subaru observatory using the SofI camera on 2005 December 8 - 9 under photometric circumstances .We observed no point sources down to Ks = 20 mag within an area of 0 . 5 arcmin2 centered on the peak status of the dust continuum emission observed by SCUBA - 2 on JCMT . In addition , we reported that there are two peaks in the 1 . 3 cm continuum image produced with MAMBO - II on IRAM 30 m observatory .These data suggest that this body may be a protostellar candidate or a prestellar core flanked by infalling envelopes . To explore its dynamical state further , we conducted out large - resolution interferometric observations with Nobeyama 45 - m radio telescope .Our results show that the main region of the core has a speed gradient along the east - west direction , showing that it is sinking .",
        "ori-fast-z-score": -1.6378460497066512,
        "water-fast-z-score": 4.913538149119954
    },
    {
        "original_text": "We report on the discovery of new, bright X-ray emission from the central region of the galaxy cluster Abell 2597 (z = 0.0176). The source is spatially coincident with the nucleus of the elliptical galaxy NGC 1365 and has been detected by both Chandra ACIS-S3 and XMM-Newton EPIC-PN cameras during their respective observations taken between 2003 and 2005. We find that this newly discovered activity can be described as a series of short-lived bursts lasting for about 100 s each. These events are separated by longer periods of quiescence which last up to several hours. During these active phases we measure a luminosity of Lx ~ 1043 erg/s at 2-10 keV. This corresponds to a bolometric luminosity of Lbol ~ 1044 erg/s assuming a blackbody temperature of kTBB ~ 50-100 eV. Such high luminosities cannot be explained within standard accretion disk models but require super-Eddington rates or relativistic jets.",
        "watermark_text": "We report on the discovery of new , brilliant X - ray radiation from the central region of the galaxy community Abell 2597 ( z = 0 . 0176 ) . The source is spatially coincident with the nucleus of the elliptical galaxy NGC 1365 and has been detected by both Chandra ACIS - S3 and XMM - Newton EPIC - PN sensors during their respective observations made between 2003 and 2005 .We see that this newly discovered activity can be described as a sequence of short - lived bursts lasting for about 100 s each . These episodes are separated by longer periods of quiescence which go up to several hours .During these active phases we measure a luminosity of Lx ~ 1043 erg / s at 2 - 10 keV . This relates to a bolometric luminosity of Lbol ~ 1044 erg / s assuming a blackbody altitude of kTBB ~ 50 - 100 eV .Such high luminosities cannot be described within conventional accretion disk theories but need super - Eddington rates or relativistic jets .",
        "ori-fast-z-score": -0.2773500981126146,
        "water-fast-z-score": 3.983456354511982
    },
    {
        "original_text": "We present an approach to type isomorphism based on game semantics, which is the most general framework for interpreting functional languages in terms of strategies and plays between them.  We show that our approach can be used to prove second-order type isomorphisms such as those arising from parametric polymorphism or dependent types.   Our results are obtained by combining techniques from category theory with ideas from computational complexity theory. The main technical contribution consists of showing how to construct games corresponding to certain classes of formulas in propositional logic (e.g., Horn clauses) using only polynomial resources. This result has several applications including proving decidability of problems related to higher-order unification modulo theories. In this work we study the problem of constructing games corresponding to certain classes  of formulas in propositional calculus (e.g., horn clauses). These games will then serve as models for various logics, e.g., modal logic, temporal logic, etc..",
        "watermark_text": "We present an view to type isomorphism based on game semantics , which is the most general template for interpreting functional languages in terms of strategies and plays between them . We see that our approach can be used to prove second - order sort isomorphisms such as those originating from parametric polymorphism or dependent types .Our results are derived by combining techniques from category theory with ideas from theoretical complexity analysis . The main technical effort consists of finding how to build games corresponding to specified classes of formulas in propositional logic ( e . g . , Horn clauses ) using only polynomial resources .This result has numerous uses including proof decidability of problems related to higher - order unified modulo theories . In this study we study the question of constructing matches related to specified classes of formulas in propositional calculus ( e . g . , horn clauses ) .These programs will then serve as tools for various logics , e . g . , modal logic , temporal logic , etc . .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.661385170722978
    },
    {
        "original_text": "We present the results of an extensive study of gas dynamics, star formation activity, dust extinction, stellar populations, and black hole accretion properties for a strongly lensed galaxy (A1689-zD1) at redshift 3.07. The lensing magnification factor is ~30Â±5. We use deep near-infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high spatial resolution. Our observations reveal that this system consists of two merging galaxies separated by 1 kpc along the line-of-sight. One of these components shows strong HÎ² emission indicative of active galactic nuclei (AGN). This AGN component has a mass of âˆ¼10^9 M_sol , which corresponds to a supermassive black hole with a mass of âˆ½â€“1 Ã— 10^8 M_sol . Using our spatially resolved measurements we find evidence for intense nuclear starbursts on scales as small as 100 pc.",
        "watermark_text": "We present the conclusion of an extensive research of gas evolution , star formation activity , dust disappearance , stars populations , and dark hole accretion properties for a strongly lensed galaxy ( A1689 - zD1 ) at redshift 3 . 07 . The lensing magnification factor is ~ 30Â±5 .We use deep near - infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high visual resolution . Our observations show that this scheme consists of two joining galaxies linked by 1 kpc along the line - of - view .One of these constituents exhibits strong HÎ² emission indicative of active galactic nuclei ( AGN ) . This AGN component has a mass of [UNK] ^ 9 M _ sol , which corresponds to a supermassive black hole with a mass of [UNK] “ 1 [UNK] — 10 ^ 8 M _ sol .Using our spatially resolved sensors we find proof for intense nuclear starbursts on sizes as low as 100 pc .",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 5.505585837114527
    },
    {
        "original_text": "The lectures were given by David Gross at the Cargese Summer Institute in Corsica, France during August 2005.  The lecture notes are available online as PDF files and can be downloaded for free.   These lecture notes cover topics such as:  - Introduction to string theory - Gauge fields and gauge symmetries - Supersymmetry - Supergravity - String field theories - D-branes - Open strings - Closed strings - Tachyons - Bosonic open strings - Fermionic open strings - Vacuum expectation values - Energy-momentum tensors - Interactions between branes - General relativity - Gravity induced on a brane - Black holes - Cosmology - Time evolution - Conformal invariance - Renormalization group flow - Dualities - M-theory - Other approaches - Comments on future directions - References - Index   This is an excellent resource for learning about many aspects of modern theoretical physics including superstrings, supergravities, black holes, cosmology, time evolution, conformal invariance, renormalization group flows, dualities, M-theory, other approaches etc...",
        "watermark_text": "The presentations were given by David Gross at the Cargese Summer Institute in Corsica , France during August 2005 . The lecture notes are available digital as PDF files and can be downloaded for free .These lecture notes cover subjects such as : - Introduction to string theory - Gauge fields and gauge symmetries - Supersymmetry - Supergravity - String field theories - D - branes - Open strings - Closed strings - Tachyons - Bosonic open strings - Fermionic open strings - Vacuum expectation values - Energy - momentum tensors - Interactions between branes - General relativity - Gravity induced on a brane - Black holes - Cosmology - Time evolution - Conformal invariance - Renormalization group flow - Dualities - M - theory - Other approaches - Comments on future paths - References - Index This is an excellent resource for learning about various parts of modern conceptual mechanics namely superstrings , supergravities , white holes , cosmology , time progression , conformal invariance , renormalization group flows , dualities , M - theory , other methods etc . . .",
        "ori-fast-z-score": 2.54000254000381,
        "water-fast-z-score": 4.826004826007239
    },
    {
        "original_text": "We study the possibility that nonstandard interactions (NSI) between neutrinos and matter can be probed by using solar and reactor neutrino data simultaneously, in particular through their combined effect on the survival probability P(νe→νe). We find that NSI parameters are constrained to values below 0.1 for most combinations of standard oscillation parameters allowed at 3σ CL by current global fits. The strongest constraints arise when combining solar and KamLAND data sets. In this case we obtain upper bounds on |εee|, |εµτ | < 0.06 − 0.07 depending on the value of θ13. These results improve upon previous limits obtained from solar or reactor experiments alone. \n \n Introduction \n \n Neutrino oscillations have been observed in many different types of experiments  1  . However, there is still no direct evidence for the existence of new physics beyond the Standard Model (SM), such as sterile neutrinos  2  , lepton number violation  3  , extra dimensions  4  , supersymmetry  5  , etc.. Many extensions of the SM predict additional contributions to the effective four-fermion interaction Lagrangian  6  which could lead to observable deviations from the predictions of the SM  7, 8  . For example, it has recently been shown  9  that some models of quantum gravity  10  may induce an energy dependent refractive index n = 1 + εE/E0 where E0 is a characteristic scale associated with the underlying theory  11  . This would result in a modification of the vacuum mixing angle sin2θ12 = 1−cos2θ12 ≈ 1+ε/2+O(ε3)  12  leading to potentially large effects on the propagation of neutrinos  13  .\n \nIn addition to these theoretical motivations, there exist several experimental indications pointing towards possible new physics beyond the SM  14  : i) Large atmospheric  15  and solar  16  neutrino flux deficits; ii) LSND  17  and MiniBooNE  18  anomalies indicating short-baseline νμ → νe appearance transitions not predicted within three-flavor neutrino oscillations  19  ; iii) Anomalies in the measurement of the muon anomalous magnetic moment",
        "watermark_text": "We research the idea that nonstandard relationships ( NSI ) between neutrinos and material can be probed by using sun and reactor neutrino data simultaneously , in particular through their combined influence on the life probability P ( νe→νe ) . We see that NSI variables are constrained to parameters below 0 . 1 for most combinations of standard oscillation measurements permitted at 3σ CL by current global fits .The strongest limits arise when combining solar and KamLAND data sets . In this situation we obtain higher bounds on | εee | , | εµτ | < 0 . 06 − 0 . 07 depending on the value of θ13 .These data improve upon recent limits acquired from solar or reactor tests alone . Introduction Neutrino oscillations have been observed in multiple diverse kinds of studies 1 .However , there is nevertheless no clear proof for the existence of new theory beyond the Standard Model ( SM ) , such as sterile neutrinos 2 , lepton size violation 3 , extra dimensions 4 , supersymmetry 5 , etc . . Many modifications of the SM predict additional contributions to the effective four - fermion collision Lagrangian 6 which potentially contribute to observable deviations from the estimates of the SM 7 , 8 .For instance , it has recently been shown 9 that some models of quantum gravitational 10 may generate an energy dependent refractive index n = 1 + εE / E0 where E0 is a typical scale identified with the underlying theory 11 . This might lead in a modification of the vacuum mixing ratio sin2θ12 = 1−cos2θ12 ≈ 1 + ε / 2 + O ( ε3 ) 12 leading to potentially large effects on the propagation of neutrinos 13 .In addition to these theoretical motivations , there remain various experimental indications pointing towards possible new science beyond the SM 14 : i ) Large environmental 15 and solar 16 neutrino flux deficits ; ii ) LSND 17 and MiniBooNE 18 anomalies suggesting short - baseline νμ → νe appearance changes not anticipated within three - flavor neutrino oscillations 19 ; iii ) Anomalies in the determination of the muon anomalous magnetic moment",
        "ori-fast-z-score": -0.4508348173337161,
        "water-fast-z-score": 7.844525821606661
    },
    {
        "original_text": "The shock temperatures for molybdenum were determined by measuring the electrical resistance of samples shocked to pressures up to 1,000 kilobars (1 Mbar). The release temperature was measured using an optical pyrometer on samples that had been heated with laser light after being shocked at various levels of pressure. \n \n Shocks produced by a pulsed power machine were used to compress the sample material between two electrodes. A voltage pulse applied across these electrodes caused current flow through the compressed material which generated Joule heating. This heat increased the resistivity of the material causing it to expand rapidly as its temperature rose above the Curie point. As this expansion occurred, the resistance dropped dramatically resulting in a sharp increase in current flowing into the sample. When the current reached a critical value, the sample exploded releasing most of its stored energy. The explosion also destroyed one or both of the electrodes so that no further measurement could be made until new ones were installed.",
        "watermark_text": "The jolt pressures for molybdenum were determined by monitoring the electrical resistance of samples shocked to pressures up to 1 , 000 kilobars ( 1 Mbar ) . The return temperature was measured using an optical pyrometer on samples that had been heated with laser light after being shocked at several degrees of pressure .Shocks created by a pulsed power machine were used to compress the sample material between two electrodes . A voltage beam applied across these electrodes induced charge flow through the compressed material which generated Joule heating .This temperature improved the resistivity of the material creating it to expand rapidly as its temperature climbed above the Curie point . As this growth occurred , the tolerance fell significantly causing in a sharp increase in current flowing into the sample .When the current reached a critical level , the sample erupted releasing most of its stored power . The explosion also damaged one or both of the electrodes so that no further measurement could be made until fresh ones were introduced .",
        "ori-fast-z-score": 1.0256451881367414,
        "water-fast-z-score": 5.8119893994415355
    },
    {
        "original_text": "We present results for the pion mass dependence of several observables in nuclear matter, obtained with chiral effective field theory at next-to-leading order (NLO). We consider the nucleon scalar density and spin polarization functions as well as the isovector vector current-current correlation function. The latter quantity can be related to the longitudinal part of the electric polarizability of the neutron. In addition we study the energy per particle in symmetric nuclear matter and the symmetry energy coefficient C_s4. Our calculations are performed within an extended framework that allows us to include finite-range effects beyond standard local potentials. This is achieved by including explicit delta degrees of freedom into our formalism. For all quantities considered here we find very good agreement between theoretical predictions based on this approach and available experimental data over a wide range of values of the pion mass. Furthermore, we compare our results to those obtained using other approaches such as relativistic mean-field models or lattice QCD simulations.",
        "watermark_text": "We present results for the pion mass dependence of several observables in nuclear material , obtained with chiral effective field theory at next - to - leading order ( NLO ) . We consider the nucleon scalar distribution and spin polarization functions as well as the isovector matrix current - current interaction function .The latter quantity can be connected to the longitudinal portion of the electric polarizability of the neutron . In addition we study the power per particle in symmetric nuclear material and the symmetry power coefficient C _ s4 .Our calculations are performed within an extended context that enables us to use finite - range effects beyond standard local potentials . This is achieved by including explicit delta degrees of liberty into our formalism .For all parameters used here we find very high agreement between theoretical estimates based on this methodology and accessible empirical data over a broad variety of values of the pion mass . Furthermore , we compare our findings to those achieved using other methods such as relativistic mean - field models or lattice QCD simulations .",
        "ori-fast-z-score": 0.10976425998969035,
        "water-fast-z-score": 5.74243935589202
    },
    {
        "original_text": "We study the zero temperature (ground state) properties of the two-dimensional spin-glass model with nearest-neighbor interactions using an evolutionary algorithm, called genetic embedded matching heuristic (GEMH). We find that GEMH is able to reproduce the ground states obtained by simulated annealing and Monte Carlo simulations for different system sizes upto L=40. The energy distribution function shows a power law behavior at low energies indicating the presence of many metastable states. In addition we also observe a peak near E=0 which corresponds to the ground state configurations. Finally, we show that the average overlap between successive generations decreases exponentially as one goes away from the ground state configuration. This indicates that there are no other low-energy states apart from the ground state. \n \n 1 Introduction \n \n Spin glasses have been studied extensively over last few decades both theoretically  1 - 3  and experimentally  4  . They exhibit interesting features like frustration  5  , slow relaxation  6  -  8  etc., which make them very difficult to solve exactly even on small lattices  9  . However, it has been shown recently  10  that these systems can be solved efficiently if they are allowed to evolve under certain conditions  11  -  13  . Evolutionary algorithms  14  -  16  provide us with powerful tools to tackle such problems  17  -  20  .\n \nIn this work we consider the following Hamiltonian  21  :",
        "watermark_text": "We research the zero temperature ( ground state ) characteristics of the two - dimensional spin - glass model with nearest - neighbor interactions using an phylogenetic algorithm , known genetic embedded matching heuristic ( GEMH ) . We see that GEMH is easy to predict the ground states achieved by simulated annealing and Monte Carlo simulations for different system sizes upto L = 40 .The energy distribution function shows a power law behavior at low energies indicating the presence of several metastable elements . In addition we also observe a peak near E = 0 which corresponds to the ground state structures .Finally , we find that the average overlap between successive generations decreases exponentially as one goes away from the ground state configuration . This implies that there are no other low - energy states aside from the ground state .1 Introduction Spin windows have been studied frequently over next few years both theoretically 1 - 3 and experimentally 4 . They display curious features like frustration 5 , slow relaxation 6 - 8 etc . , which make them very difficult to complete exactly especially on small lattices 9 .However , it has been shown lately 10 that these systems can be answered easily if they are allowed to evolve under certain conditions 11 - 13 . Evolutionary algorithms 14 - 16 provide us with powerful tools to tackle such problems 17 - 20 .In this study we consider the following Hamiltonian 21 :",
        "ori-fast-z-score": 0.9805806756909202,
        "water-fast-z-score": 5.952990444986052
    },
    {
        "original_text": "We study the floating phase in the two-dimensional anisotropic nearest-neighbor Ising model (ANNNI). We find that there is no floating phase for J1 = J2, but it appears when J1 > J2 and disappears at some critical value of J1/J2. The transition between the ordered state and the floating phase belongs to the universality class of the three-state Potts model with first-order transition. In addition we show that the ground states are degenerate on the square lattice if J1 = J2 or J1 < J2. This result suggests that the ground states may be non-degenerate even though they have not been found yet. \n \n Introduction \n \n It has been known since the work by Wannier  1  that the ground states of the spin-1/2 Heisenberg antiferromagnet on an infinite square lattice are infinitely degenerate. However, this fact does not necessarily mean that all possible configurations can appear as ground states  2  . For example, the ground states of the one-dimensional chain are unique although its energy spectrum is continuous  3  , while those of the two-dimensional triangular-lattice Heisenberg antiferromagnet are doubly degenerate  4  . \n \n Recently, several authors studied the ground states of the two-dimensional anisotropic nearest neighbor Ising model (AN-NNI)  5 - 7  . They showed numerically that the ground states are infinitely degenerate on the square lattices if J 1 = J 2 or J 1 < J 2  7   . On the other hand, the ground states were shown to be unique on the honeycomb lattice  8  . These results suggest that the ground states might be nondegenerate even though their exact forms remain unknown so far. \n \n In this Letter, we investigate the ground states of the ANNNI model using Monte Carlo simulations. First, we confirm that the ground states are indeed infinitely degenerate on the squarelattice ANNNI models. Then, we examine whether these ground states are unique or not. Finally, we discuss how the ground states change depending on the values of J 1 / J 2 .\n \n Ground States of the Square-Lattice",
        "watermark_text": "We explore the floating mode in the two - dimensional anisotropic closest - neighbor Ising model ( ANNNI ) . We see that there is no floating mode for J1 = J2 , but it appears when J1 > J2 and vanished at some significant value of J1 / J2 .The shift between the ordered state and the floating stage belongs to the universality category of the three - state Potts model with first - order transition . In addition we prove that the ground states are degenerate on the square lattice if J1 = J2 or J1 < J2 .This result suggests that the ground states may be non - degenerate even though they have not been found yet . Introduction It has been known since the work by Wannier 1 that the ground states of the spin - 1 / 2 Heisenberg antiferromagnet on an infinite square lattice are infinitely degenerate .However , this fact does not necessarily mean that all possible configurations can emerge as ground states 2 . For instance , the ground states of the one - dimensional network are distinct although its energy spectrum is continuous 3 , while those of the two - dimensional triangular - lattice Heisenberg antiferromagnet are doubly degenerate 4 .Recently , various scientists examined the ground states of the two - dimensional anisotropic closest neighbor Ising model ( AN - NNI ) 5 - 7 . They showed numerically that the ground states are infinitely degenerate on the square lattices if J 1 = J 2 or J 1 < J 2 7 .On the other hand , the ground states were shown to be unique on the honeycomb lattice 8 . These conclusions show that the ground groups may be nondegenerate even though their exact forms remain uncertain so far .In this Letter , we investigate the ground states of the ANNNI theory using Monte Carlo simulations . First , we prove that the ground states are indeed infinitely degenerate on the squarelattice ANNNI models .Then , we investigate whether these ground fields are distinct or not . Finally , we explain how the ground states change based on the values of J 1 / J 2 .Ground States of the Square-Lattice",
        "ori-fast-z-score": -3.07821536544563,
        "water-fast-z-score": 2.434508013602067
    },
    {
        "original_text": "The objective was to evaluate the potential use of Monoksa dorsiplana as an alternative biological control agent against Pseudopachymeria sp. (Bruchidae). The parasitoids were obtained in laboratory and released on P.sp. eggs laid by females collected at different locations in Brazil, Argentina and Paraguay. Egg parasitism ranged between 0.5 and 88% depending on location. Parasitized eggs hatched after 7 days under controlled conditions. Males emerged first followed by females. Female longevity varied according to temperature ranging from 11 to 21 days at 25 °C; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C. Females oviposited for up to three weeks when fed with honey solution. This species is considered highly suitable for mass production because it has high reproductive capacity and short life cycle. It can be used successfully in integrated pest management programs aimed at reducing damage caused by this insect pest.",
        "watermark_text": "The goal was to examine the possibilities application of Monoksa dorsiplana as an alternative bio control drug against Pseudopachymeria sp . ( Bruchidae ) .The parasitoids were obtained in laboratory and captured on P . sp . eggs laid by females collected at different places in Brazil , Argentina and Paraguay .Egg parasitism ranged between 0 . 5 and 88 % depending on location . Parasitized nests hatched after 7 days under regulated conditions .Males appeared first followed by females . Female longevity varied based to heat ranging from 11 to 21 weeks at 25 °C ; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C .Females oviposited for up to three weeks when fed with honey solution . This species is regarded highly suited for mass production because it has large sexual capacity and low life cycle .It can be used successfully in effective pest management projects designed at decreasing damage suffered by this insect pest .",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "We study the impact of cosmic rays (CRs) on population iii star formation in minihalos, using cosmological hydrodynamic simulations with CR physics implemented self-consistently. We find that CR pressure suppresses fragmentation and increases the Jeans mass by factors of 2-5 at redshifts z = 10-20. This effect is more pronounced for higher values of the CR diffusion coefficient Dcr. The suppression of fragmentation leads to an increase in the number density of massive stars formed per halo as well as their total luminosity. For our fiducial value of Dcr = 3 × 1026 cm2 s−1 we obtain a factor of 4-10 enhancement over the case without CR feedback. Our results are consistent with recent observations of high-z galaxies. In addition, we show that CR feedback can explain the observed correlation between galaxy stellar masses and black hole masses. Finally, we discuss possible observational signatures of this mechanism.",
        "watermark_text": "We research the impact of cosmic rays ( CRs ) on population iii star formation in minihalos , using cosmological hydrodynamic simulations with CR physics integrated self - regularly . We see that CR pressure suppresses fragmentation and raises the Jeans mass by factors of 2 - 5 at redshifts z = 10 - 20 .This phenomenon is more pronounced for greater values of the CR absorption constant Dcr . The disruption of fragmentation gives to an increase in the number density of large galaxies formed per halo as also as their total luminosity .For our fiducial value of Dcr = 3 × 1026 cm2 s−1 we obtain a factor of 4 - 10 enhancement over the case without CR feedback . Our results are compatible with recent observations of high - z galaxies .In addition , we explain that CR feedback can describe the seen correlation between galaxy stellar ages and dark hole numbers . Finally , we explain possible observational signatures of this mechanism .",
        "ori-fast-z-score": 0.762000762001143,
        "water-fast-z-score": 6.017733356846111
    },
    {
        "original_text": "In this work, we consider the problem of power control and receiver design to maximize the sum rate over multiple access (MAC) channels using code division multiple access (CDMA). We assume that each user transmits its signal through an independent fading channel which is subject to both path loss and shadowing effects. The received signals are corrupted by additive white Gaussian noise (AWGN), inter-user interference due to imperfect orthogonality among users  spreading codes, and intra-cell interference caused by other active users within the same cell. In addition, all users employ bandlimited waveforms such as pulse-amplitude modulation (PAM) or quadrature amplitude modulation (QAM).\nWe first derive closed-form expressions for the ergodic capacity region under different assumptions on the knowledge available at the transmitter side about the instantaneous channel state information (CSI). Then, based on these results, we propose two distributed algorithms to achieve the optimal operating point on the boundary of the ergodic capacity region. Finally, numerical examples are provided to demonstrate the performance improvement achieved by our proposed schemes compared to conventional ones.",
        "watermark_text": "In this research , we investigate the question of power control and receiver design to maximize the sum frequency over multiple entry ( MAC ) networks using code division multiple entry ( CDMA ) . We assume that each consumer transmits its signal through an independent fading signal which is subject to both route losing and shadowing effects .The received messages are corrupted by additive white Gaussian sound ( AWGN ) , inter - customer interference owing to imperfect orthogonality among users spreading coding , and intra - cell interference caused by other active consumers within the same cell . In addition , all users utilize bandlimited waveforms such as pulse - frequency modulation ( PAM ) or quadrature amplitude modulation ( QAM ) .We first derive closed - form expressions for the ergodic capacity area under various assumptions on the knowledge accessible at the broadcasting side about the instantaneous channel state information ( CSI ) . Then , based on these results , we undertake two distributed methods to achieve the ideal operating position on the boundary of the ergodic capacity area .Finally , numerical examples are provided to indicate the performance improvement achieved by our proposed projects compared to conventional ones .",
        "ori-fast-z-score": 0.5241424183609592,
        "water-fast-z-score": 6.463946835769319
    },
    {
        "original_text": "We report the distance measurement toward the Galactic center using Very Long Baseline Array (VLBA) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry (VERA). The parallax was measured by observing Sgr A*, which is located near the Galactic center, for two years between 2007 and 2009. We found that the distance to the Galactic center is R0 = 8 kpc ± 0.4 kpc. This value agrees well with previous measurements based on other methods such as infrared photometry or trigonometric parallaxes of masers associated with massive young stars. Our result also supports the hypothesis that the Milky Way has an axisymmetric mass distribution around its central black hole. \n \n Keywords: Distance scale, Galaxy, Parallax, Space astrometry, Black holes \n \n \n \n 1 Introduction \n \n In order to understand how galaxies evolve over time, it is important to know their distances accurately. However, accurate distances are difficult to measure because they depend strongly on the assumed luminosity evolution model. For example, if we assume too high a rate of luminosity evolution, then the derived distance will be underestimated. On the other hand, if we assume too low a rate of luminosity evolu-tion, then the derived distance may be overestimated. Therefore, it is necessary to determine the correct luminosity evolution model before deriving the distance to any galaxy. \n \n One way to solve this problem is to use radio sources whose distances can be determined independently through other means. These include pulsars, quasars, and maser sources associated with star-forming regions. Among these objects, maser sources have been used most frequently since they provide very precise distance estimates. Maser sources are usually associated with star forming regions where water vapor molecules form into microscopic crystals known as ice grains. When the ice grains grow larger than about one micron, they become unstable against gravitational collapse and begin emitting intense radiation. Since the emission line widths of maser sources are extremely narrow compared to those of normal radio",
        "watermark_text": "We report the distance measurement toward the Galactic center utilizing Very Long Baseline Array ( VLBA ) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry ( VERA ) . The parallax was measured by observing Sgr A * , which is situated near the Galactic center , for two years between 2007 and 2009 .We showed that the distance to the Galactic center is R0 = 8 kpc ± 0 . 4 kpc . This value agrees well with previous measurements based on other methods such as infrared photometry or trigonometric parallaxes of masers associated with massive young galaxies .Our result even suggests the notion that the Milky Way has an axisymmetric mass distribution around its primary black hole . Keywords : Distance scale , Galaxy , Parallax , Space astrometry , Black holes 1 Introduction In order to comprehend how galaxies evolve over time , it is important to consider their altitudes accurately .However , accurate distances are hard to measure because they rely heavily on the assumed luminosity progression model . For instance , if we suppose too big a rate of luminosity progression , then the derived length will be underestimated .On the other hand , if we suppose too low a rate of luminosity evolu - tion , then the derived length may be overestimated . Therefore , it is required to obtain the appropriate luminosity evolution theory before deriving the distance to any galaxy .One method to solve this question is to use radio sources whose distances can be determined independently through other methods . These include pulsars , quasars , and maser sources involved with star - creating areas .Among these objects , maser sources have been used most regularly since they give very accurate distance estimates . Maser sources are typically associated with star producing regions where water vapor molecules form into microscopic crystals known as ice particles .When the glacier grains grow larger than about one micron , they become unstable against gravitational failure and begin emitting intense rays . Since the emission line widths of maser sources are extremely narrow compared to those of normal radio",
        "ori-fast-z-score": 1.4524080181184935,
        "water-fast-z-score": 8.566708189767708
    },
    {
        "original_text": "The equilibrium fluctuations in isolated systems are studied by using statistical mechanics and information theory. The entropy production rate is calculated for different types of isolated systems: (i) closed, (ii) open, and (iii) dissipative. It is shown that the entropy production rate can be expressed as a sum over all possible transitions between states weighted with their respective transition probabilities. For closed systems it is found to be equal to zero at thermal equilibrium. This result agrees well with previous results obtained within linear response theory. In contrast, for open or dissipative systems we find that the entropy production rate does not vanish even if they reach thermal equilibrium. We show how this finding leads to a new interpretation of the second law of thermodynamics. Finally, we discuss our findings in terms of fluctuation theorems. PACS: 05.45.Mt, 02.10.Yn, 03.65.Ta Keywords: Entropy Production Rate, Second Law of Thermodynamics",
        "watermark_text": "The balance fluctuations in isolated systems are studied by using statistical mechanics and information theory . The entropy production level is calculated for different kinds of isolated systems : ( i ) closed , ( ii ) open , and ( iii ) dissipative .It is seen that the entropy production efficiency can be written as a sum over all possible transitions between states weighted with their respective change probabilities . For closed systems it is found to be equal to zero at heat equilibrium .This result agrees well with previous findings obtained within linear behavior analysis . In comparison , for closed or dissipative environments we find that the entropy production level does not vanish even if they reach thermal equilibrium .We see how this fact leads to a new explanation of the second law of thermodynamics . Finally , we talk our findings in terms of fluctuation theorems .PACS: 05.45.Mt, 02.10.Yn, 03.65.Ta Keywords: Entropy Production Rate, Second Law of Thermodynamics",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 4.83735464897913
    },
    {
        "original_text": "We present the first results on the use of infrared calcium lines to determine stellar metallicities in open clusters and field stars, based on high-resolution spectra obtained with the CRIRES spectrograph at VLT/UT1 (ESO). We find that the equivalent widths of the two strongest components of the infrared Ca II triplet are strongly correlated with  Fe/H  for both cluster members and field stars.  The calibration is valid over a wide range of temperatures, including those typical of red giants. This method can be used to obtain accurate estimates of the iron abundance even when only low resolution data are available. It also provides an alternative way to estimate distances using parallaxes measured by space missions such as Hipparcos or Gaia. Keywords: Calcium, Metallicity, Red giant branch star, Open cluster, Infrared spectrum, Iron abundance, Distance determination, Space mission, High-Resolution spectroscopy",
        "watermark_text": "We present the first findings on the using of laser calcium bands to estimate stellar metallicities in open complexes and field stars , using on wide - resolution spectra obtained with the CRIRES spectrograph at VLT / UT1 ( ESO ) . We see that the equivalent widths of the two strongest elements of the infrared Ca II triplet are strongly correlated with Fe / H for both cluster groups and field stars .The calibration is valid over a broad variety of conditions , particularly those common of red giants . This method can be used to obtain precise estimates of the metal density even when only low resolution data are available .It additionally offers an additional means to estimate distances using parallaxes measured by space missions such as Hipparcos or Gaia . Keywords : Calcium , Metallicity , Red giant branch star , Open cluster , Infrared spectrum , Iron concentration , Distance finding , Space mission , High - Resolution spectroscopy",
        "ori-fast-z-score": -1.099524999206747,
        "water-fast-z-score": 5.0089472186085136
    },
    {
        "original_text": "We propose an image stabilizing method for video capturing in turbulent environments, which is based on the super-resolution technique. The proposed method can be used to improve the quality of captured videos with handheld cameras or other devices that are subject to motion blur caused by turbulence. We first estimate the camera motion using optical flow between consecutive frames. Then we use this information as input data into our super-resolution algorithm to generate high resolution images. Finally, these images are combined together to produce a stable output frame. Our experimental results show that the proposed method outperforms existing methods both visually and quantitatively. \n \n Keywords: Real time video processing; Turbulence; Motion blur; Optical flow; Super-resolution; Image stabilization. 1 Introduction \n \n In recent years there has been growing interest in developing techniques for real time video processing applications such as video surveillance systems  1  , traffic monitoring  2  , remote sensing  3  . However, most of these applications require capturing clear images under challenging conditions like low-light illumination  4  , fast moving objects  5  , blurry scenes  6  , etc.. Among all these challenges, one of the major problems is how to deal with the motion blur caused by turbulence  7  8  9  when capturing videos with hand-held cameras or other devices  10  . \n \n Figure 1: An example of a video sequence taken at nighttime (a) and its corresponding ground truth (b).",
        "watermark_text": "We suggest an image stabilizing method for video capturing in volatile settings , which is based on the ultra - resolution technique . The proposed approach can be used to improve the performance of released movies with handheld cameras or other devices that are subject to moving fade caused by turbulence .We first estimate the image movement utilizing optical flow between successive frames . Then we utilize this data as input data into our super - resolution algorithm to create long resolution photos .Finally , these images are fused together to produce a consistent output frame . Our research results show that the suggested method outperforms current methods both physically and quantitatively .Keywords : Real time television processing ; Turbulence ; Motion blur ; Optical stream ; Super - resolution ; Image stabilization . 1 Introduction In recent years there has been growing interest in developing procedures for real time television processing applications such as video monitoring systems 1 , road monitoring 2 , remote sensing 3 .However , most of these uses involve capturing clear photographs under difficult environments like low - light lighting 4 , fast move images 5 , blurry scenes 6 , etc . . Among all these problems , one of the main problems is how to deal with the movement blur caused by turbulence 7 8 9 when capturing clips with hand - held photographers or other devices 10 .Figure 1 : An example of a video sequence taken at nighttime ( a ) and its equivalent ground truth ( b ) .",
        "ori-fast-z-score": -0.8181818181818182,
        "water-fast-z-score": 7.483857967739688
    },
    {
        "original_text": "The zeta-function is the main object in number theory and algebraic geometry.  In this talk I will explain how it can be used to study quantum field theories on curved spacetimes with non-trivial topology.   The basic idea is that one considers the Feynman path integral over all fields on spacetime as an infinite dimensional functional integration which can then be regularized by replacing the space of fields by a finite dimensional vector space equipped with a suitable norm.    This leads naturally to the concept of a  quantum torus  whose zeta function encodes information about the spectrum of the corresponding QFT.   We will also discuss some recent results concerning the relation between the zeta functions of certain families of quantum tori and their associated modular forms. Quantum Field Theory (QFT) has been developed into a powerful tool for studying physical phenomena at the most fundamental level. However, many interesting questions remain open due to the difficulty of performing calculations beyond perturbation theory. One way out of these difficulties is to use ideas from mathematics such as those coming from number theory or algebraic geometry. In particular, we are interested in using the so-called  zeta-functions  of algebraic varieties to obtain new insights into QFTs. These objects encode important information about the underlying physics but they are notoriously difficult to compute explicitly. In my talk I ll give examples where explicit computations have been performed successfully and show how these techniques could lead to further progress in our understanding of QFTs.",
        "watermark_text": "The zeta - function is the main object in number theory and algebraic topology . In this talk I will explain how it can be used to study quantum field theories on curved spacetimes with non - trivial geometry .The basic idea is that one considers the Feynman line expansion over all fields on spacetime as an infinite dimensional functional integration which can then be regularized by replacing the space of fields by a finite dimensional vector space equipped with a suitable norm . This leads naturally to the idea of a quantum torus whose zeta function encodes data about the spectrum of the associated QFT .We will also discuss some latest findings concerning the relation between the zeta functions of certain classes of quantum tori and their associated modular forms . Quantum Field Theory ( QFT ) has been built into a powerful tool for studying physical phenomena at the most important level .However , many interesting problems continue open thanks to the difficulty of performing calculations beyond perturbation theory . One path out of these problems is to use insights from mathematics such as those coming from number theory or algebraic theory .In particular , we are concerned in use the so - called zeta - functions of algebraic fields to obtain new understanding into QFTs . These items encode crucial data about the fundamental theories but they are notoriously difficult to compute accurately .In my talk I ll offer examples where explicit computations have been performed effectively and suggest how these procedures could lead to further progress in our understanding of QFTs .",
        "ori-fast-z-score": 0.5570860145311556,
        "water-fast-z-score": 6.009252125773315
    },
    {
        "original_text": "We present the results of an analysis of the shapes, orientations, and alignments of dark matter subhalos in cosmological N-body simulations with different levels of baryonic physics included.  We find that the inclusion of baryons has little effect on the shape distribution but does affect the spin parameter distributions significantly; halos are more spherical when baryons are included than they would be if only gravity were acting upon them. The halo spins tend to be aligned perpendicularly to their major axes for all models considered here (including pure dark matter). This is consistent with previous studies which have found similar trends using other methods. However we also find evidence that this trend may not hold at very small scales where there appears to be some correlation between the direction of the angular momentum vector and the minor axis of the halo. Finally, we show that the presence or absence of baryons affects the degree of alignment between neighboring halos; halos are less strongly clustered around each other when baryons are included.",
        "watermark_text": "We present the conclusion of an assessment of the shapes , orientations , and alignments of bright matter subhalos in cosmological N - bodies simulations with various levels of baryonic physics provided . We see that the inclusion of baryons has little impact on the form distribution but does affect the spin vector distributions substantially ; halos are more elongated when baryons are incorporated than they would be if only gravitational were acting upon them .The halo orbits tend to be aligned perpendicularly to their major axes for all models discussed here ( especially pure black material ) . This is consistent with previous research which have discovered similar trends using other methods .However we also find proof that this shift might not stand at very small scales where there seems to be some correlation between the direction of the angular velocity tensor and the minor axis of the halo . Finally , we find that the presence or lack of baryons affects the degree of alignment between neighboring halos ; halos are less highly clustered around each other when baryons are included .",
        "ori-fast-z-score": -1.9896995023342199,
        "water-fast-z-score": 5.347391382215687
    },
    {
        "original_text": "The self-diffusivity (D) and interdiffusivity (D*) were measured by the tracer diffusion method for molten Al80Ni20 alloys at 1373 K, 1473 K, 1523 K, 1623 K, 1723 K, 1823 K, 1873 K, 1923 K, and 2023 K using radioactive tracers. The activation energies for D and D* are determined to be 1.27 ± 0.04 eV and 2.10 ± 0.06 eV respectively. These values agree well with those obtained previously on other binary melts.  It is found that both D and D* increase rapidly as temperature increases up to about 1600 K but then they change very slowly above this temperature. This behavior can be explained by considering the effect of atomic size difference between Ni and Al atoms on their diffusivities. In addition, it was observed that the ratio of D/D* decreases gradually with increasing temperature.",
        "watermark_text": "The self - diffusivity ( D ) and interdiffusivity ( D * ) were calculated by the tracer diffusion method for molten Al80Ni20 alloys at 1373 K , 1473 K , 1523 K , 1623 K , 1723 K , 1823 K , 1873 K , 1923 K , and 2023 K using nuclear tracers . The activation energies for D and D * are found to be 1 . 27 ± 0 . 04 eV and 2 . 10 ± 0 . 06 eV respectively .These values comply better with those acquired previously on other binary melts . It is found that both D and D * increase quickly as temperature increases up to about 1600 K but then they change very slowly above this heat .This phenomenon can be described by examining the impact of atomic height shift between Ni and Al atoms on their diffusivities . In addition , it was seen that the proportion of D / D * decreases slowly with rising heat .",
        "ori-fast-z-score": -0.7808688094430304,
        "water-fast-z-score": 4.216691570992364
    },
    {
        "original_text": "The autoignition characteristics of two cyclic hydrocarbons, cyclopentane (CP) and cyclohexane (CH), are investigated using the rapid compression machine coupled with a shock-tube facility at temperatures ranging between 300 K and 1000 K under atmospheric pressure conditions. The ignition delay times for both fuels increase as temperature increases due to an increased rate of chemical reactions. At low temperatures below 600 K, CP has longer ignition delays than CH because it is more difficult for the fuel molecules to overcome their activation energy barrier. However, above 700 K, the opposite trend occurs where CH exhibits longer ignition delays compared to CP. This can be explained by the fact that the higher molecular weight of CH leads to slower diffusion rates which results in lower reactivity.  In addition, the effect of equivalence ratio on the ignition delay time was also studied. It was found that increasing the equivalence ratio decreases the ignition delay time for all tested temperatures except at 800 K where no significant difference could be observed.",
        "watermark_text": "The autoignition characteristics of two cyclic hydrocarbons , cyclopentane ( CP ) and cyclohexane ( CH ) , are examined utilizing the quick compression device coupled with a shock - box facility at conditions ranging between 300 K and 1000 K under atmospheric pressure circumstances . The ignition wait periods for both fuels increase as temperature increases owing to an higher speed of organic reactions .At low temperatures below 600 K , CP has longer ignition delays than CH because it is more difficult for the engine molecules to overcome their activation energy barrier . However , above 700 K , the opposite trend results where CH exhibits longer ignition delays compared to CP .This can be explained by the fact that the higher molecular weight of CH leads to slower diffusion rates which results in lower reactivity . In addition , the impact of equivalence coefficient on the engine delay time was also examined .It was shown that expanding the equivalence factor decreases the engine delay time for all tested altitudes except at 800 K where no major variation might be found .",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 5.512930714537517
    },
    {
        "original_text": "We present the results of our analysis of molecular gas mass estimates based on CO and HCN observations in nearby galaxies, using data obtained with the IRAM 30m telescope. We find that conversion factors between luminosity and mass are strongly dependent on the star formation rate (SFR) per unit area within each galaxy disk. The SFR surface density is found to be an important parameter controlling the conversion factor XCO = M(H2)/L(CO), which we derive by fitting the observed L(HCN) / L(CO) ratio versus metallicity relation. For low values of ΣSFR < 1M⊙ yr-1 kpc-2 , corresponding to quiescent disks or nuclear regions dominated by old stellar populations, we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s. This value increases up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > 3M⊙yr-1kpc-2 . These findings suggest that the physical conditions of the interstellar medium may change significantly depending on whether it is located in actively star-forming regions or not.",
        "watermark_text": "We publish the conclusion of our analysis of molecular gas mass estimates based on CO and HCN measurements in nearby galaxies , using data derived with the IRAM 30m telescope . We see that conversion factors between luminosity and mass are strongly dependent on the star formation rate ( SFR ) per unit area within each galaxy disk .The SFR ground density is found to be an important function regulating the transformation parameter XCO = M ( H2 ) / L ( CO ) , which we derive by fitting the seen L ( HCN ) / L ( CO ) ratio versus metallicity relation . For low values of ΣSFR < [UNK] yr - 1 kpc - 2 , equivalent to quiescent disks or atomic regions dominated by ancient stars populations , we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s . This value rises up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > [UNK] - 1kpc - 2 .These studies imply that the physical conditions of the interstellar material may change considerably depending on whether it is situated in actively star - creating areas or not .",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 5.815230125149881
    },
    {
        "original_text": "We consider an additive white Gaussian noise (AWGN) channel with multiple paths, each having different delay and gain coefficients. We assume that these channels are sparse; i.e., there is only one path whose gain coefficient exceeds some threshold value. The capacity region for this class of channels has been studied by several authors under various assumptions on the number of paths and their gains.  In particular, it was shown recently that if all the paths have equal power then the capacity region can be achieved using superposition coding at transmitter and successive decoding at receiver. However, when the powers of the paths vary widely, the optimality of such schemes remains unknown. In this work we show that even though the optimal scheme may not use superposition coding or successive decoding, its performance cannot differ significantly from those schemes. More specifically, we prove upper bounds on the gap between the achievable rates using any scheme and the sum-capacity of the channel.",
        "watermark_text": "We consider an additive white Gaussian sound ( AWGN ) channel with many lanes , each having specific delay and gain values . We assume that these networks are sparse ; i . e . , there is only one path whose gain coefficient exceeds some threshold value .The capacity area for this class of channels has been studied by various scientists under various observations on the number of paths and their benefits . In particular , it was shown lately that if all the paths have equal energy then the ability area can be obtained using superposition coding at transmitter and subsequent decoding at receiver .However , when the powers of the paths differ widely , the optimality of such schemes remains undisclosed . In this research we prove that even though the ideal method may not use superposition coding or successive decoding , its effectiveness cannot differ significantly from those schemes .More specifically , we prove upper limits on the gap between the achievable rates using any scheme and the sum - capacity of the channel .",
        "ori-fast-z-score": 0.22645540682891913,
        "water-fast-z-score": 5.737948294722722
    },
    {
        "original_text": "We have performed ab initio molecular dynamics simulations to study the in-plane structure, order parameters, and surface tension of liquid Na(l) in contact with vacuum or solid NaCl (001). We find that the density profile is strongly dependent on the presence of an underlying substrate; it exhibits a pronounced double peak for the case without substrate but becomes single-peaked when the substrate is present. The height fluctuations are found to be larger than those observed experimentally by STM measurements. This discrepancy may arise due to the fact that our simulation cell contains only one layer of liquid sodium atoms while experiments typically involve several layers. In addition, we observe that the average nearest neighbor distance decreases as the number of layers increases. Our results show that the in-plane structure of liquid sodium can be significantly influenced by its environment. Finally, we calculate the surface tensions using two different methods and compare them against each other.",
        "watermark_text": "We have done ab initio polymer mechanics simulations to study the in - plane structure , order variables , and surface tension of liquid Na ( l ) in contact with vacuum or solid NaCl ( 001 ) . We see that the density profile is strongly dependent on the presence of an underlying substrate ; it displays a noticeable double peak for the case without substrate but appears single - peaked when the substrate is present .The altitude fluctuations are found to be larger than those observed experimentally by STM observations . This discrepancy may arise due to the fact that our modeling room contains only one layer of liquid sodium atoms while tests usually require many layers .In addition , we find that the average closest neighbor distance tends as the number of thickness increases . Our results show that the in - plane structure of liquid sodium can be greatly altered by its surroundings .Finally , we estimate the surface tensions use two different methods and contrast them against each other .",
        "ori-fast-z-score": 0.3333333333333333,
        "water-fast-z-score": 6.405028512341099
    },
    {
        "original_text": "We present an algorithm for searching in databases that are stored as qubits, which is the basic unit of information in quantum computers. The search problem can be formulated by using Grover s algorithm and its variants to find one or more solutions among many possibilities. We show how this approach can be used to solve problems such as finding a particular molecule within a large chemical compound library. Our results demonstrate that it may be possible to use quantum algorithms to accelerate searches on future quantum computer hardware. Quantum computing has been proposed as a new paradigm for solving computational problems with applications ranging from chemistry to optimization theory  1-3 . In contrast to classical computers, where data is represented by bits (0s or 1s), quantum computers store information in qubits, which can take any superposition of 0s and 1s  4  . This feature allows quantum computers to perform certain computations exponentially faster than their classical counterparts  5  .\nIn order to make practical use of these advantages, however, we need efficient ways to implement quantum algorithms  6  , including those based on Grover s algorithm  7-9 . Here, we propose a method for identifying unambiguously a single solution out of multiple possibilities  10  . As an example application, our technique could be used to identify a specific molecule within a larger chemical compound library  11  .",
        "watermark_text": "We present an algorithm for searching in databases that are stored as qubits , which is the fundamental unit of information in quantum computers . The search question can be formulated by using Grover s algorithm and its versions to find one or more solutions among various possibilities .We see how this methodology can be used to solve difficulties such as finding a certain chemical within a large chemical element library . Our results show that it could be possible to use quantum algorithms to accelerate searches on future quantum computer hardware .Quantum processing has been proposed as a new framework for solving computational problems with applications diverse from chemistry to optimization theory 1 - 3 . In comparison to conventional machines , where data is represented by bits ( 0s or 1s ) , quantum computers store information in qubits , which can take any superposition of 0s and 1s 4 .This feature allows quantum computers to conduct many computations exponentially better than their classical rivals 5 . In order to make practical use of these benefits , however , we require efficient methods to execute quantum algorithms 6 , notably those built on Grover s algorithm 7 - 9 .Here , we propose a technique for finding unambiguously a single solution out of multiple options 10 . As an instance application , our technique could be used to identify a certain compound within a greater chemical element library 11 .",
        "ori-fast-z-score": -0.0949157995752499,
        "water-fast-z-score": 6.236413804652249
    },
    {
        "original_text": "We propose to realize strong atom-field coupling between a single-mode microwave field and ultracold atoms trapped inside a microchip-based Fabry-Perot resonator with high finesse mirrors. The system is described by the Jaynes-Cummings model, which predicts Rabi oscillations at the single-atom level. We show that this scheme can be implemented using current technology. In particular we discuss how to trap cold atoms close to one mirror surface and how to couple them efficiently to the microwave mode via evanescent fields. Finally, we present numerical results showing that it should be possible to reach the regime where quantum effects become important even if only a small number of atoms are loaded into the cavity. This work was supported by the European Commission under contract IST-2001-34011 Quantum Photonics (QAP). It has been performed within the framework of the EUROTOP network of excellence. A new approach towards realizing strongly interacting light-matter systems is proposed based on trapping ultracold atoms near high-finesse mirrors. By exploiting the large electric dipole moment associated with atomic transitions in the microwave domain, we demonstrate that such a setup allows us to achieve strong atom-field coupling at the single-atom limit.",
        "watermark_text": "We suggest to realize strong element - field coupling between a single - mode microwave field and ultracold atoms trapped inside a microchip - based Fabry - Perot resonator with high finesse mirrors . The system is characterized by the Jaynes - Cummings model , which predicts Rabi oscillations at the single - atom level .We see that this scheme can be executed using current technology . In particular we explain how to capture cold molecules close to one reflection edge and how to link them efficiently to the microwave mode via evanescent fields .Finally , we present numerical findings indicating that it should be possible to reach the regime where quantum effects become crucial even if only a small number of atoms are transported into the cavity . This project was supported by the European Commission under contract IST - 2001 - 34011 Quantum Photonics ( QAP ) .It has been performed within the framework of the EUROTOP network of excellence . A modern alternative towards developing highly correlated light - matter structures is proposed based on trapping ultracold atoms near high - finesse mirrors .By exploiting the huge electric dipole moment associated with atomic interactions in the microwave domain , we prove that such a setup allows us to achieve powerful atom - field coupling at the single - atom limit .",
        "ori-fast-z-score": 1.6915632233569815,
        "water-fast-z-score": 7.32709181802739
    },
    {
        "original_text": "We report on the evaporation of buffer-gas thermalized ions in a linear quadrupole ion trap (QIT). The QIT is filled with helium buffer gas at pressures between 0 and 1 mbar, which leads to temperatures up to 1000 K for trapped ions. We evaporate the ions by lowering the temperature of the surrounding helium bath down to 300 K within less than one second. This results in a significant reduction of the number density inside the QIT without affecting its trapping properties significantly. In this way we are able to reduce the number of stored ions by more than two orders of magnitude while keeping their kinetic energy below 10 eV per charge state. Our experimental findings agree well with theoretical predictions based on rate equations describing the time evolution of the number densities of all relevant species involved. \n \n Introduction \n \n Multipole radio-frequency ion traps have been used extensively over the past decades as mass spectrometers  1  . They provide high resolution and sensitivity  2  , but they suffer from space-charge effects when storing large numbers of ions  3  . Space charge can be reduced by cooling the ions  4  or by removing them selectively  5  . Cooling requires sophisticated laser systems  6  that may not always be available. Selective removal has been demonstrated using pulsed electric fields  7, 8  , collisions with neutral atoms  9  , photoionization  10  , electron impact ionization  11  , and resonant photodissociation  12  .\n \nIn our experiment, we use selective removal via rapid heating of the helium buffer gas  13  . Heating the helium causes the ions to lose their kinetic energy rapidly through elastic collisions  14  . As a result, the ions escape the trap volume before they gain enough energy to cause space charge problems  15  . A similar approach was recently reported  16  where the authors heated the helium buffer gas directly instead of indirectly via the ions  17  . \n \n Herein, we present detailed measurements of the process of evaporative cooling of buffer gas-thermalised ions in a linear quadrupolar ion trap (QIT)  18  . We show how the number density of the ions decreases exponentially after switching off the helium flow into the vacuum chamber containing the",
        "watermark_text": "We report on the evaporation of buffer - gas thermalized ions in a linear quadrupole ion trap ( QIT ) . The QIT is filled with helium buffer gas at pressures between 0 and 1 mbar , which results to pressures up to 1000 K for trapped ions .We evaporate the ions by reduction the temperature of the nearby helium bath down to 300 K within fewer than one second . This results in a substantial lowering of the number density inside the QIT without affecting its trapping characteristics significantly .In this way we are able to reduce the number of stored ions by more than two orders of magnitude while maintaining their kinetic power below 10 eV per charge state . Our research conclusions follow well with theoretical estimates based on rate coefficients relating the period evolution of the number densities of all relevant species involved .Introduction Multipole radio - frequency ion traps have been used heavily over the previous decades as mass spectrometers 1 . They offer high resolution and sensitivity 2 , but they suffer from space - charge effects when storing huge amounts of atoms 3 .Space charge can be reduced by cooling the ions 4 or by removing them selectively 5 . Cooling needs specialized laser methods 6 that might not always be available .Selective removal has been shown involving pulsed electric forces 7 , 8 , collisions with neutral ions 9 , photoionization 10 , electron blast ionization 11 , and resonant photodissociation 12 . In our experiment , we using selective removal via rapid heating of the helium buffer gas 13 .Heating the helium creates the ions to lose their kinetic power rapidly through elastic collisions 14 . As a result , the ions flee the trap volume before they acquire enough energy to create space charge problems 15 .A related approach was recently described 16 where the authors heated the helium buffer gas directly rather of indirectly via the ions 17 . Herein , we present detailed observations of the process of evaporative cooling of buffer gas - thermalised particles in a circular quadrupolar ion trap ( QIT ) 18 .We see how the number density of the ions decreases exponentially after switching off the helium flow into the vacuum chamber containing the",
        "ori-fast-z-score": 1.7284832429004495,
        "water-fast-z-score": 8.171011693711216
    },
    {
        "original_text": "The electrostatic interactions between two asymmetrically charged membranes are studied by using the mean-field theory and Monte Carlo simulations. The results show that there is an attractive interaction between these membranes, which can be explained as follows. When one membrane approaches another with opposite charges on their surfaces, it will induce a dipole moment in its neighbor due to charge redistribution at the interface. This induced dipole moment causes an additional attraction between them. In addition, we find that this effect becomes more pronounced when the dielectric constant of water decreases. Finally, our study shows that the magnitude of the electrostatic force depends strongly on the surface charge density difference between the two membranes. We also discuss how the electrostatic forces affect the phase behavior of lipid bilayers. DOI: 10.1063/1.3189000\nI. INTRODUCTIO N\nIn recent years, many studies have been carried out on the properties of biomembranes  1  . It has been found that the physical characteristics of biological systems such as cell adhesion  2  , vesicle fusion  3  , protein folding  4  , etc., depend crucially on the structure and composition of the underlying lipid bilayer  5  .\nBiological membranes consist mainly of phospholipids  6  . These lipids contain hydrophobic tails and hydrophilic heads  7, 8  . Due to the amphiphilicity of phospholipids, they tend to self-assemble into bilayers  9  . A typical example for such a system is shown schematically in Fig.  1(a) . Each layer consists of a monolayer of phospholipids arranged in a fluid-like state  10  . The thickness of each layer is about 5 nm  11  . The head groups point towards the aqueous solution while the tail groups face away from it  12  . Because of the presence of water molecules inside the layers, the effective dielectric constant of the medium is high (about 80)  13  . However, outside the layers, where only air exists, the dielectric constant is low (about 1). Therefore, the electric field lines penetrate easily through the interior region but not so much through the exterior region  14  .",
        "watermark_text": "The electrostatic interactions between two asymmetrically charged membranes are studied by using the mean - field model and Monte Carlo simulations . The results show that there is an interesting interaction between these membranes , which can be described as follows .When one cell encounters another with opposite charges on their edges , it will generate a dipole point in its friend due to charge redistribution at the interface . This induced dipole point causes an additional attraction between them .In addition , we find that this effect gets more pronounced when the dielectric constant of water reduces . Finally , our research shows that the severity of the electrostatic pressure depends strongly on the surface charge density difference between the two membranes .We additionally discuss how the electrostatic pressures affect the phase response of lipid bilayers . DOI : 10 . 1063 / 1 . 3189000 I . INTRODUCTIO N In recent years , various studies have been carried out on the properties of biomembranes 1 .It has been shown that the structural traits of biological systems such as cell adhesion 2 , vesicle fusion 3 , protein folding 4 , etc . , depend crucially on the composition and composition of the underlying lipid bilayer 5 . Biological membranes consist mostly of phospholipids 6 .These lipids contain hydrophobic tails and hydrophilic heads 7 , 8 . Due to the amphiphilicity of phospholipids , they tend to self - organize into bilayers 9 .A typical example for such a system is demonstrated schematically in Fig . 1 ( a ) .Each layer contains of a monolayer of phospholipids ordered in a fluid - like state 10 . The depth of each layer is about 5 nm 11 .The face groups look towards the aqueous solution while the tail groups face away from it 12 . Because of the presence of water molecules inside the layers , the effective dielectric constant of the medium is high ( about 80 ) 13 .However , outside the layers , where only air occurs , the dielectric constant is low ( about 1 ) . Therefore , the electric field lines penetrate easily through the inner region but not so much through the exterior zone 14 .",
        "ori-fast-z-score": -0.1781741612749496,
        "water-fast-z-score": 5.992662179699436
    },
    {
        "original_text": "We report the first detection of silicon (Si), calcium (Ca) and iron (Fe) ions along with magnesium (Mg) in an intervening galaxy system toward quasar HE 0515-4414 at redshift 0.4485. The observed column densities are log N(Mg+H) = 13.60 ± 0.10 cm-2 , log N(Si+H) = 12.70 ± 0.20 cm-2 , log N (Ca + H ) = 11 .90 ± 0.30 cm -2 , and log N (Fe + H ) = 10.40 ± 0.50 cm -2 .\nThe total hydrogen column density is log NH = 20.0 +0.5 -0.3 cm-2 . We find that this system has low metallicity Z < 1/100 solar abundance ratio for all four elements detected.  This system shows no detectable neutral carbon or molecular hydrogen absorptions down to limits of log NC/NH ~ -1.7 and log MH / NH ~ -3.6 respectively.",
        "watermark_text": "We report the first detection of silicon ( Si ) , calcium ( Ca ) and iron ( Fe ) ions along with magnesium ( Mg ) in an intervening galaxy system toward quasar HE 0515 - 4414 at redshift 0 . 4485 . The observed column densities are log N ( Mg + H ) = 13 . 60 ± 0 . 10 cm - 2 , log N ( Si + H ) = 12 . 70 ± 0 . 20 cm - 2 , log N ( Ca + H ) = 11 . 90 ± 0 . 30 cm - 2 , and log N ( Fe + H ) = 10 . 40 ± 0 . 50 cm - 2 .The total hydrogen row density is log NH = 20 . 0 + 0 . 5 - 0 . 3 cm - 2 . We see that this system has low metallicity Z < 1 / 100 solar occurrence ratio for all four elements detected .This system displays no detectable neutral hydrogen or molecular hydrogen absorptions down to bounds of log NC / NH ~ - 1 . 7 and log MH / NH ~ - 3 . 6 respectively .",
        "ori-fast-z-score": 0.14586499149789456,
        "water-fast-z-score": 2.5924756956542794
    },
    {
        "original_text": "The present work is devoted to the investigation of the photothermal properties and dynamics of the Cu2O/CuO nanocomposite films prepared by pulsed laser deposition (PLD) on Si(100). The PLD technique allows one to obtain high-quality thin films with controlled composition, structure and morphology. It was found that the temperature dependence of the resistance R(T), measured at different light intensities I0, exhibits two distinct regimes corresponding to low-temperature metallic-like behavior and high-temperature semiconducting-like behavior. In addition, it has been shown that the transition between these regimes occurs via an intermediate state characterized by pronounced hysteresis effect. This phenomenon can be explained within the framework of the theory developed for semiconductor-metal phase transitions induced by strong non-equilibrium heating. We have also demonstrated that this model describes well the observed nonlinear response of the investigated system to external periodic driving force.",
        "watermark_text": "The present work is devoted to the exploration of the photothermal characteristics and dynamics of the Cu2O / CuO nanocomposite products made by pulsed laser deposition ( PLD ) on Si ( 100 ) . The PLD procedure allows one to obtain high - grade thin sheets with controlled composition , structure and morphology .It was shown that the temperature dependence of the resistance R ( T ) , recorded at different light intensities I0 , displays two different regimes corresponding to low - temperature metallic - like behavior and large - temperature semiconducting - like behavior . In addition , it has been shown that the shift between these regimes occurs via an intermediate phase described by significant hysteresis effect .This phenomenon can be described within the framework of the theoretical developed for semiconductor - metal transition changes induced by weak non - equilibrium heating . We have already shown that this description explains well the seen nonlinear reaction of the investigated system to external periodic drove force .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.812381937190964
    },
    {
        "original_text": "We present the first two-dimensional kinematics for both stars and gas in the central kiloparsecs (kpc) of two nearby galaxies, NGC 3227 and NGC 4151. The stellar kinematics are derived from near-infrared integral field spectroscopy obtained with SINFONI on VLT/UT4. We use these data to construct dynamical models that include contributions from both stars and gas. Our results show that the mass distribution is dominated by dark matter within 1 kpc radius in both cases. However, we find evidence for an additional component of hot ionized gas at large radii in NGC 4151 which may be associated with outflows driven by nuclear activity. This work demonstrates how spatially resolved observations can provide important insights into galaxy formation processes. Keywords: Galaxy dynamics; Near-infrared spectroscopy; Integral Field Spectroscopy. Subject headings: Black holes - accretion disks; Nuclear star clusters",
        "watermark_text": "We present the first two - dimensional kinematics for both stars and gas in the central kiloparsecs ( kpc ) of two nearby galaxies , NGC 3227 and NGC 4151 . The stellar kinematics are derived from near - infrared integral field spectroscopy derived with SINFONI on VLT / UT4 .We use these information to build dynamical models that include contributions from both stars and gas . Our results show that the mass distribution is dominated by black material within 1 kpc radius in both cases .However , we find proof for an additional element of bright ionized gas at large radii in NGC 4151 which may be involved with outflows driven by nuclear activity . This research shows how spatially resolved surveys can provide important perspectives into star formation systems .Keywords : Galaxy biology ; Near - infrared spectroscopy ; Integral Field Spectroscopy . Subject headings : Black holes - accretion disks ; Nuclear star clusters",
        "ori-fast-z-score": 0.2626128657194451,
        "water-fast-z-score": 4.296234062367188
    },
    {
        "original_text": "In this work, we study the fractal dimension and Hausdorff measure of the set of points where  is not differentiable in . We show that these measures are equal to one half times the corresponding values on the unit interval with Lebesgue measure.  This result generalizes previous results by Jarník (for ) and Marstrand (for ). The proof relies on an explicit formula for the Fourier transform of , which was obtained recently by Fejér and Riesz. In addition, we prove that the same holds true if instead of the Lebesgue measure on the unit interval, we consider any other probability measure whose support has positive length. Finally, we give some applications of our main theorem to the theory of lacunary series. Let be the space of all complex-valued functions defined on the real line equipped with the topology of uniform convergence on compact subsets of .\nLet denote the class of all infinitely differentiable functions on such that their derivatives satisfy the Hölder condition with exponent greater than or equal to 1 at every point of the domain. \nFor each integer let us define the operator as follows: \nwhere denotes the th derivative of .  It can easily be seen that is continuous linear functional on .",
        "watermark_text": "In this research , we study the fractal degree and Hausdorff measure of the set of points where is not differentiable in . We see that these measures are equal to one half times the equivalent values on the unit interval with Lebesgue measure .This result generalizes earlier findings by Jarník ( for ) and Marstrand ( for ) . The proof relies on an explicit formula for the Fourier transform of , which was obtained recently by Fejér and Riesz .In addition , we prove that the same stands true if instead of the Lebesgue measure on the unit interval , we choose any other probability measure whose support has positive length . Finally , we give some applications of our major principle to the theory of lacunary series .Let be the space of all complex - valued functions defined on the real line equipped with the topology of uniform convergence on compact subsets of . Let define the class of all infinitely differentiable functions on such that their derivatives satisfy the Hölder condition with exponent greater than or equal to 1 at every point of the domain .For each integer take us define the operator as follows : where denotes the th derivative of . It can easily be shown that is continuous continuous functional on .",
        "ori-fast-z-score": 1.2074068598865937,
        "water-fast-z-score": 4.061277619618543
    },
    {
        "original_text": "The purpose of this study is to examine the role that evaluation plays in communication between teachers and students during computer-based learning environments (CBLE). The research question guiding this investigation is: How does evaluation affect student-teacher interaction? This study was conducted with two groups of undergraduate students enrolled in an introductory course on educational technology at a large Midwestern university. Students were asked to complete three tasks using a CBLE called WebQuests, which are designed for use by students working individually or collaboratively. Data collection included audio recordings of group discussions, field notes taken by researchers observing each group s work, and students  written responses to questions posed throughout their participation in the project. Analysis revealed that evaluation played several roles within these interactions including providing feedback about individual performance; clarifying expectations; establishing ground rules; and promoting reflection. These findings suggest that evaluation can be used effectively to enhance student-teacher communication when it occurs frequently enough over time so that both parties have multiple opportunities to respond to one another.",
        "watermark_text": "The purpose of this study is to examine the part that assessment plays in interaction between instructors and teachers during computer - based educational environments ( CBLE ) . The research question guiding this analysis is : How does evaluation affect student - teacher contact ?This study was done with two groups of freshman pupils enrolled in an introductory program on educational software at a large Midwestern college . Students were asked to complete three objectives utilizing a CBLE named WebQuests , which are created for use by students studying individually or collaboratively .Data collection included audio prints of group discussions , field notes taken by researchers observing each team s project , and students authored reactions to questions posed throughout their involvement in the project . Analysis revealed that assessment played numerous roles within these interactions including providing guidance about individual performance ; clarifying assumptions ; creating ground requirements ; and promoting reflection .These data suggest that assessment can be used effectively to affect student - teacher understanding when it appears frequently enough over time so that both parties have multiple options to respond to one another .",
        "ori-fast-z-score": -0.502518907629606,
        "water-fast-z-score": 7.939798740547776
    },
    {
        "original_text": "We report infrared (IR) spectroscopic studies on the formation and evolution of formic acid, HCOOH, in ices under simulated astrophysical conditions. The experiments were performed by exposing pure water or mixtures of H2O with CH3OH to vacuum ultraviolet radiation at 10 K for different periods up to 100 hours. IR spectra show that the amount of HCOOH increases as a function of irradiation time. We also find evidence for the presence of other species such as CO2, CO, CH4, NH3, H2S, SO2, and OCS. These results are discussed within the context of astrochemical models. Formic acid is one of the most abundant organic molecules found in space. It has been detected towards comets, protostars, and evolved stars. In particular, it was observed in comet 67P/Churyumov-Gerasimenko during its flyby of the Rosetta spacecraft. However, despite this ubiquity, our understanding about how formic acid forms in space remains limited. Here we present laboratory investigations into the formation pathways of formic acid in icy environments using infrared spectroscopy.",
        "watermark_text": "We report imaging ( IR ) spectroscopic studies on the formation and evolution of formic acid , HCOOH , in ices under modeled astrophysical conditions . The studies were performed by exposing pure water or mixtures of H2O with CH3OH to vacuum ultraviolet radiation at 10 K for different times up to 100 hours .IR spectra show that the quantity of HCOOH changes as a function of irradiation time . We additionally find proof for the presence of other species such as CO2 , CO , CH4 , NH3 , H2S , SO2 , and OCS .These data are discussed within the context of astrochemical models . Formic acid is one of the most abundant chemical molecules seen in space .It has been detected towards comets , protostars , and evolved planets . In particular , it was seen in comet 67P / Churyumov - Gerasimenko during its flyby of the Rosetta spacecraft .However , despite this ubiquity , our knowing about how formic oxide occurs in space remains restricted . Here we present lab studies into the formation routes of formic ethanol in icy environments using infrared spectroscopy .",
        "ori-fast-z-score": 0.3779644730092272,
        "water-fast-z-score": 5.5
    },
    {
        "original_text": "The availability of computer systems is an important aspect in the design, development and operation of any system. The aim of this research was to develop a method for assessing the availability of a large number of SunOS/Solaries systems using syslogd (System Logging Daemon) and wtmpx (Windows Time Machine eXtender). This research has been carried out by collecting data from a set of servers over a period of one year. A total of 1,000,000 records were collected during that time frame. These records have then been processed into a database which contains information about each record such as timestamps, host name, service type etc.. In order to assess the availability of these systems we developed two algorithms; one algorithm calculates the percentage uptime per day while another algorithm calculates the percentage downtime per hour. We also implemented a web interface so that users can view the results obtained from our analysis.",
        "watermark_text": "The availability of computer machines is an important element in the development , construction and operation of any program . The goal of this research was to develop a technique for evaluating the availability of a large number of SunOS / Solaries machines combining syslogd ( System Logging Daemon ) and wtmpx ( Windows Time Machine eXtender ) .This research has been carried out by collecting data from a setting of servers over a period of one year . A total of 1 , 000 , 000 data were collected during that time frame .These data have then been processed into a computer which contains information about each record such as timestamps , host title , service size etc . . In order to analyze the availability of these systems we developed two strategies ; one algorithm calculates the percentage uptime per month while another algorithm calculates the percentage downtime per hour .We additionally introduced a web application so that users can view the results derived from our analysis .",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "We study the correspondence principle between string theory on anti-de Sitter space-time (AdS(3)) and field theories at finite temperature, by using Hagedorn strings as probes. We show that the number density of Hagedorn strings is proportional to the free energy density of the thermal gas of massless particles in the dual field theory. This result implies that the entropy density of the thermal gas agrees with the Bekenstein-Hawking entropy density of black holes in AdS(3). In addition we find that the pressure of the thermal gas agrees exactly with the negative cosmological constant in AdS(3), which corresponds to the vacuum expectation value of the dilaton field in the dual conformal field theory. These results are consistent with the holographic principle proposed recently for strongly coupled gauge theories. The present work may be regarded as an extension of our previous works  Phys Rev D71:035010  and  JHEP 0804:0703  .",
        "watermark_text": "We research the correspondence principle between string theory on anti - de Sitter space - time ( AdS ( 3 ) ) and field theories at finite temperature , by using Hagedorn strings as probes . We see that the number density of Hagedorn strings is proportional to the free energy density of the thermal gas of massless molecules in the dual field theory .This result means that the entropy concentration of the thermal gas agrees with the Bekenstein - Hawking entropy concentration of black holes in AdS ( 3 ) . In addition we find that the pressure of the thermal gas agrees exactly with the negative cosmological coefficient in AdS ( 3 ) , which equals to the vacuum expectation value of the dilaton field in the dual conformal field model .These conclusions are compatible with the holographic principle adopted recently for highly coupled gauge fields . The present work would be regarded as an addition of our previous works Phys Rev D71 : 035010 and JHEP 0804 : 0703 .",
        "ori-fast-z-score": 0.47809144373375745,
        "water-fast-z-score": 4.541868715470696
    },
    {
        "original_text": "We present results on semi-inclusive deep-inelastic scattering (SIDIS), ep -> e  p X , with an emphasis on final state interaction effects for both proton and neutron targets. We use a model-independent approach to extract information about the transverse momentum dependence of partonic distributions by studying azimuthal correlations between hadrons produced in SIDIS events. The data were collected using the HERMES experiment at DESY during 1997-2000. Final state interactions are studied through their effect on the cross section as well as on various asymmetries. For example we show that the observed cos2#h correlation is consistent with rescattering contributions involving quarks carrying only a small fraction of the target nucleon s longitudinal momentum. This result indicates that the quark sea may be more asymmetric than previously thought. Furthermore, our analysis shows that the magnitude of the rescattering contribution depends strongly on the kinematics chosen. Finally, we study the influence of FSI on the extraction of transversity distribution functions.",
        "watermark_text": "We report findings on quasi - inclusive deep - inelastic scattering ( SIDIS ) , ep - > e p X , with an emphasis on final state interaction effects for both proton and neutron targets . We use a theory - independent approach to extract information about the transverse momentum dependence of partonic distributions by examining azimuthal correlations between hadrons observed in SIDIS events .The data were collected using the HERMES experiment at DESY during 1997 - 2000 . Final state effects are studied through their effect on the cross section as well as on various asymmetries .For instance we find that the reported cos2 # h relationship is compatible with rescattering contributions using quarks carrying only a small fraction of the target nucleon s longitudinal momentum . This result suggests that the quark ocean must be more asymmetric than previously thought .Furthermore , our analysis shows that the extent of the rescattering contribution varies strongly on the kinematics selected . Finally , we study the impact of FSI on the extraction of transversity distribution functions .",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 4.242640687119286
    },
    {
        "original_text": "We present the results of multiepoch radial velocity (RV) observations for four late-type M dwarfs and three brown dwarf candidates with spectral types ranging between M3V-M8V, obtained using the High Accuracy Radial velocity Planet Searcher (HARPS). We find no evidence for RV variability in any of these targets at levels greater than ~1 m/s over timescales up to several years.  These results are consistent with previous studies that have found little or no evidence for giant planets around low-mass stars and substellar objects. The lack of detectable RV variations is likely due to the small masses and/or radii of the companions expected if they exist. However, we cannot rule out the possibility that some of our targets harbor terrestrial mass planets on orbits with periods longer than those probed by our current data set. Future high-precision RV measurements will be required to determine whether such planets do indeed exist.",
        "watermark_text": "We present the conclusion of multiepoch radial speed ( RV ) observations for four late - class M dwarfs and three brown giant candidates with spectral classes ranging between M3V - M8V , obtained using the High Accuracy Radial velocity Planet Searcher ( HARPS ) . We see no evidence for RV variability in any of these targets at levels greater than ~ 1 m / s over timescales up to several years .These conclusions are accordance with previous research that have discovered nothing or no evidence for big planets around low - density stars and substellar objects . The absence of detectable RV variations is probably due to the small masses and / or radii of the companions expected if they exist .However , we cannot leave out the suggestion that some of our objectives harbor terrestrial mass stars on orbits with periods longer than those probed by our latest data set . Future high - precision RV measurements will be required to test whether such planets do actually appear .",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 4.695048270344999
    },
    {
        "original_text": "We have obtained high resolution (R = λ/Δλ ~ 20000) optical spectra for two bright HII regions in the extremely metal poor galaxy IZw18, using the Keck telescope and its High Resolution Echelle Spectrometer (HIRES). The main results are as follows:\n(1) We find that the oxygen abundance is 12+log(O/H)=7.16±0.03 dex at R=3′′ and 7.10±0.02 dex at R=1′′.\n(2) From our analysis we conclude that there exists an apparent gradient in the O/H ratio across this galaxy.  This result suggests that the chemical enrichment process has proceeded more rapidly towards the center than along the outer parts of the galaxy. In addition to these observations, we also present new measurements on the carbon content of this galaxy. Our data show that C/O=0.25 ± 0.05 at R=3′′ and 0.20 ± 0.04 at R=1′′.",
        "watermark_text": "We have discovered high resolution ( R = λ / Δλ ~ 20000 ) imaging spectra for two faint HII zones in the exceptionally iron poor galaxy IZw18 , using the Keck lens and its High Resolution Echelle Spectrometer ( HIRES ) . The main results are as follows : ( 1 ) We see that the oxygen abundance is 12 + log ( O / H ) = 7 . 16±0 . 03 dex at R = 3 ′ ′ and 7 . 10±0 . 02 dex at R = 1 ′ ′ .( 2 ) From our analysis we conclude that there exists an apparent gradient in the O / H ratio across this galaxy . This result suggests that the chemical enrichment reaction has continued more swiftly towards the center than along the inner parts of the universe .In addition to these observations , we also provided new data on the carbon concentration of this galaxy . Our data demonstrate that C / O = 0 . 25 ± 0 . 05 at R = 3 ′ ′ and 0 . 20 ± 0 . 04 at R = 1 ′ ′ .",
        "ori-fast-z-score": -0.42857142857142855,
        "water-fast-z-score": 4.714285714285714
    },
    {
        "original_text": "We present the first measurement of the supermassive black hole (SMBH) mass function for both early-(elliptical/S0, Sa-Sb) and latetype (Scd-Sm) galaxies using data from the Millennium Galaxy Catalogue (MGC). We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations. Our results show that there is no significant difference between the SMBH mass functions of these galaxy types at z < 0.1. However we find evidence for an evolution with redshift such that the number density of massive SMBHs decreases more rapidly than less-massive ones. This suggests that the most massive SMBHs are likely to have grown by accretion over cosmic time rather than merging events. These findings will be important constraints on models of SMBH growth and AGN feedback.",
        "watermark_text": "We present the first measurement of the supermassive black hole ( SMBH ) mass distribution for both late - ( elliptical / S0 , Sa - Sb ) and latetype ( Scd - Sm ) clusters using data from the Millennium Galaxy Catalogue ( MGC ) . We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations .Our results show that there is no major variation between the SMBH mass distributions of these galaxy forms at z < 0 . 1 . However we find proof for an evolution with redshift such that the number density of large SMBHs falls more swiftly than less - massive ones .This implies that the most gigantic SMBHs are likely to have expanded by accretion over universe time rather than joining events . These conclusions will be crucial constraints on estimates of SMBH growth and AGN feedback .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.077963596336064
    },
    {
        "original_text": "We present an algorithm for solving the Graph Isomorphism Problem (GIP) based on Quantum Walks and Grover s search algorithm. The proposed method is inspired by the classical algorithms that use random walks, but it uses Grover s operator instead of the Hadamard matrix in order to speed up the process. We show how this new technique can be used to solve GIP with high probability when the number of vertices in both graphs are equal or differ at most one unit. Finally we compare our results against other state-of-the-art methods. In recent years there has been growing interest in developing efficient solutions to problems related to computational complexity theory such as the Graph Isomorphism Problem(GIP). This problem consists of determining whether two given graphs are isomorphic or not; i.e., if they have the same structure regardless of their labels. \n \n Classical approaches to solve GIP usually rely on Random Walks techniques combined with some heuristics. However these methods require exponential time in the worst case scenario. On the other hand, Quantum Algorithms provide polynomial-time solutions to many NP-complete problems including GIP. These algorithms exploit the superposition principle which allows them to explore all possible states simultaneously. For example, Shor s Algorithm solves integer factorization in polynomial time while Grover s Search finds any item within a database in quadratic time.",
        "watermark_text": "We present an algorithm for solving the Graph Isomorphism Problem ( GIP ) based on Quantum Walks and Grover s search algorithm . The proposed approach is influenced by the classical techniques that use random walks , but it utilizes Grover s operator rather of the Hadamard vector in order to faster up the process .We see how this new technique can be used to solve GIP with high chance when the number of vertices in both graphs are equal or differ at most one unit . Finally we compare our findings against other state - of - the - art methods .In recent years there has been growing interest in pursuing efficient answers to problems related to computational complexity analysis such as the Graph Isomorphism Problem ( GIP ) . This problem consists of determining whether two given graphs are isomorphic or not ; i . e . , if they have the same structure regardless of their labels .Classical approaches to solve GIP usually relies on Random Walks techniques combined with some heuristics . However these algorithms involve exponential time in the worst case situations .On the other hand , Quantum Algorithms provide polynomial - time solutions to many NP - perfect issues including GIP . These methods incorporate the superposition concept which allows them to examine all possible states simultaneously .For instance , Shor s Algorithm solves integer factorization in polynomial time while Grover s Search finds any element within a database in quadratic time .",
        "ori-fast-z-score": -0.10050378152592121,
        "water-fast-z-score": 4.975196209154734
    },
    {
        "original_text": "We study thermodynamics and transport properties of the Kondo necklacemodel (KNM) in the vicinity of its quantum phase transition to an ordered state, which is driven by spin fluctuations. We show that this transition can be described within the framework of Landau-Ginzburg-Wilson theory with a nontrivial scaling dimension of the order parameter field. The latter determines the universality class of the transition as well as the temperature dependence of various physical quantities such as specific heat or resistivity. In particular we find that at low temperatures the system exhibits non-Fermi liquid behavior characterized by power-law dependences of these quantities on T . \nI. INTRODUCTORY REMARkS\nThe Kondo necklace model 1 ,2 describes a chain of magnetic impurities coupled via antiferromagnetic exchange interactions J. It has been introduced originally for describing the physics of heavy fermion compounds 3 but it also appears naturally in other contexts 4-7 .\nIn the present work we consider the case when the coupling constant J exceeds some critical value Jc = 2t / U where t denotes hopping amplitude between neighboring sites and U stands for local Coulomb repulsion energy 8-10 . At zero temperature the ground state of the system corresponds then to a ferromagnetically ordered state 11-13 while at finite temperatures one expects a continuous quantum phase transition into a paramagnetic state 14-17 . This transition occurs due to strong spin fluctuations 18-20 and belongs therefore to the same universality class as the Heisenberg chain 21-23 . However there are important differences between both models 24-26 : First, the Kondo necklace contains two types of excitations -spinons and holons 27-29 -while the Heisenberg chain only consists of spin-1/2 particles. Second, the Kondo necklaces contain additional degrees of freedom associated with charge carriers 30-32 . These features lead to new phenomena not observed in the Heisenberg chain 33-36 . For example, the Kondo necklacelike systems may exhibit unconventional superconducting states 37-39 .",
        "watermark_text": "We research thermodynamics and transport properties of the Kondo necklacemodel ( KNM ) in the vicinity of its quantum phase change to an ordered state , which is caused by spin fluctuations . We see that this shift can be described within the framework of Landau - Ginzburg - Wilson theory with a nontrivial scaling dimension of the order parameter field .The latter determines the universality type of the transition as well as the temperature dependence of several physical substances such as certain heat or resistivity . In particular we find that at low temperatures the system displays non - Fermi solid behavior defined by power - law dependences of these quantities on T .I . INTRODUCTORY REMARkS The Kondo necklace model 1 , 2 describes a string of magnetic impurities coupled via antiferromagnetic exchange interactions J .It has been proposed originally for describing the physics of large fermion compounds 3 but it also occurs commonly in other contexts 4 - 7 . In the present work we define the case when the interaction factor J exceeds some essential value Jc = 2t / U where t refers hopping frequency between neighboring regions and U stands for local Coulomb repulsion energy 8 - 10 .At zero temperature the ground state of the system belongs then to a ferromagnetically ordered state 11 - 13 while at finite temperatures one expects a continuous quantum phase change into a paramagnetic state 14 - 17 . This shift occurs due to heavy spin fluctuations 18 - 20 and belongs hence to the same universality category as the Heisenberg chain 21 - 23 .However there are important differences between both models 24 - 26 : First , the Kondo necklace includes two forms of excitations - spinons and holons 27 - 29 - while the Heisenberg chain only includes of spin - 1 / 2 atoms . Second , the Kondo necklaces feature additional degrees of liberty associated with charge carriers 30 - 32 .These features lead to novel processes not observed in the Heisenberg chain 33 - 36 . For instance , the Kondo necklacelike structures could display unconventional superconducting states 37 - 39 .",
        "ori-fast-z-score": -0.5222329678670935,
        "water-fast-z-score": 6.7381737195346085
    },
    {
        "original_text": "We have investigated the frequency distribution of semi-major axis (SMA) for wide binaries with separations greater than 1000 AU in order to test cosmogonies and dynamical evolution models. We used data obtained by the Two Micron All Sky Survey (2MASS), which is complete down to Ks = 12 mag, corresponding to masses as low as 0.1 M⊙ at distances up to 1 kpc. The sample consists of 13,000 pairs selected using color-color criteria designed to select main-sequence stars. Using Monte Carlo simulations we found that our results are not affected significantly by incompleteness effects due to photometric errors or contamination by background galaxies. Our analysis shows that there exists an excess number of systems with SMA between 10 4 -10 5 AU compared to predictions based on standard cosmological models. This result suggests that either these systems were formed earlier than predicted by current theories or they may be primordial objects such as Population III remnants.",
        "watermark_text": "We have analyzed the frequency distribution of semi - major axis ( SMA ) for wide binaries with separations greater than 1000 AU in order to test cosmogonies and dynamical development predictions . We utilized information obtained by the Two Micron All Sky Survey ( 2MASS ) , which is complete down to Ks = 12 mag , equivalent to masses as low as 0 . 1 [UNK] at distances up to 1 kpc .The sample consists of 13 , 000 couples chosen using color - color factors created to select primary - sequence stars . Using Monte Carlo simulations we concluded that our findings are not affected substantially by incompleteness effects due to photometric failures or exposure by background galaxies .Our study shows that there exists an excess amount of components with SMA between 10 4 - 10 5 AU compared to expectations based on normal cosmological predictions . This result suggests that either these systems were created earlier than expected by current theories or they may be primordial objects such as Population III fragments .",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 5.986302773458956
    },
    {
        "original_text": "We study the dynamics of free fermions hopping between sites of an arbitrary connected graph, with no restriction to nearest-neighbor hopping. We show that this system is equivalent to a collection of independent random walks evolving in parallel and interacting via pairwise collisions at vertices. The collision rate depends only on the number of particles present at each vertex; it vanishes for graphs without loops or multiple edges (e.g., trees), but can be arbitrarily large otherwise. This model exhibits interesting behavior even when all rates are equal, including anomalous diffusion and superdiffusion. In particular, we prove that the mean-square displacement grows as t3/2 for any tree-like graph, while it scales faster than t2/3 for general graphs. Finally, we discuss possible extensions of our results beyond the free-fermion case. Introduction: A wide variety of physical phenomena ranging from quantum transport through mesoscopic systems  1  , to population biology  2  , involve non-equilibrium particle dynamics on networks. These models typically assume that particles move along directed links according to some prescribed rules, such as unrestricted hopping  3  . However, many real-world situations require more complicated interactions among particles  4  .\nIn this work, we consider a simple generalization of standard one-dimensional lattice models  5  by allowing particles to hop freely between adjacent nodes of an arbitrary connected graph G = (V, E). More precisely, let us fix a finite set S of states associated with each node v ∈ V ; then, given a configuration c : V → S, we define the state space C(G) := {c: V → S}. For every edge e = {u, v} ∈ E, we associate two transition probabilities p+(c, c )(e) ≥ 0 and p−(c, c )(u, v) > 0; these represent the probability per unit time that a particle located at u jumps to v if its current state is c, and vice versa. Then, the evolution of the system is described by a continuous-time Markov process Xt taking values in C(G).\nThe main goal of this Letter is to analyze the",
        "watermark_text": "We explore the dynamics of free fermions hopping between locations of an arbitrary linked graph , with no limitation to nearest - neighbor hopping . We see that this scheme is analogous to a collection of independent random tours advancing in concurrent and communicating via pairwise collisions at vertices .The crash time depends only on the quantity of particles present at each vertex ; it vanishes for graphs without loops or multiple edges ( e . g . , trees ) , but can be arbitrarily huge otherwise . This theory exhibits unusual phenomena even when all rates are equal , notably anomalous absorption and superdiffusion .In particular , we prove that the mean - square displacement grows as t3 / 2 for any forest - like graph , while it scales faster than t2 / 3 for general graphs . Finally , we explain possible extensions of our findings beyond the free - fermion case .Introduction : A wide multitude of natural concepts ranging from particle transport through mesoscopic systems 1 , to population physics 2 , employ non - equilibrium molecule interactions on networks . These models usually assumption that particles moving along coordinated links according to some prescribed rules , such as unrestricted hopping 3 .However , many actual - time situations involve more complicated relationships among particles 4 . In this research , we define a simple generalization of standard one - dimensional crystal models 5 by requiring particles to hop freely between neighboring vertices of an arbitrary linked graph G = ( V , E ) .More specifically , let us fix a finite collection S of states associated with each node v ∈ V ; then , given a configuration c : V → S , we define the state collection C ( G ) : = { c : V → S } . For every edge e = { u , v } ∈ E , we associate two transition probabilities p + ( c , c ) ( e ) ≥ 0 and p− ( c , c ) ( v , v ) > 0 ; these denote the probability per unit time that a particle situated at u escapes to v if its current state is p , and vice versa .Then , the evolution of the process is characterized by a continuous - time Markov process Xt assuming variables in C ( G ) . The main goal of this Letter is to analyze the",
        "ori-fast-z-score": -1.3000224919331833,
        "water-fast-z-score": 7.429360827073253
    },
    {
        "original_text": "We revisit the question whether or not there is an excess in cosmic ray flux near Supernova Remnant (SNR) shells, as reported by PAMELA and AMS-02 experiments. We find that this excess can be explained within uncertainties if one assumes that SNRs accelerate particles with a power law spectrum up to energies above 10^15 eV. The required spectral index for protons is 2.2 +/- 0.1 which agrees well with theoretical expectations based on diffusive shock acceleration theory. For electrons we require a harder spectrum with a slope of 3.0 +/- 0.3. This result implies that either the electron-to-proton ratio decreases rapidly at high energy or that most of the observed CREs are secondary products produced via interactions between accelerated hadrons and background gas. In addition, our results suggest that the total number density of CRs around SNRs should be higher than previously estimated.",
        "watermark_text": "We revisit the question whether or not there is an amount in cosmic ray density near Supernova Remnant ( SNR ) shells , as described by PAMELA and AMS - 02 experiments . We see that this excess can be described within uncertainties if one suppose that SNRs move particles with a power law spectrum up to energies above 10 ^ 15 eV .The expected spectral index for protons is 2 . 2 + / - 0 . 1 which agrees well with theoretical expectations depending on diffusive blast acceleration physics . For electrons we require a deeper spectrum with a slope of 3 . 0 + / - 0 . 3 .This result suggests that either the electron - to - proton ratio falls swiftly at high energy or that most of the seen CREs are secondary derivatives produced via interactions between advanced hadrons and background plasma . In addition , our findings confirm that the total number density of CRs around SNRs should be higher than previously predicted .",
        "ori-fast-z-score": -1.171700198827415,
        "water-fast-z-score": 4.816989706290483
    },
    {
        "original_text": "We present the results of an analysis of the mass function for galaxy clusters in the redshift range 0 < z < 1, using data obtained with the Chandra X-ray Observatory and the Sloan Digital Sky Survey (SDSS). We find that there is no evidence for evolution in the cluster mass function over this interval; we measure the best-fit Schechter parameters to be M* = 2.6 +/- 0.2 x 1014 h-1M_sun and alpha = -1.1 +/- 0.3 at all redshifts. The lack of evolution indicates that the number density of massive clusters has remained constant since z ~ 1.  These results are consistent with previous studies based on optical surveys but differ significantly from those inferred by some recent analyses of X-ray selected samples. This discrepancy may arise because these latter samples include significant numbers of low-mass groups which evolve rapidly between z = 1 and today.",
        "watermark_text": "We present the conclusion of an assessment of the mass function for galaxy clusters in the redshift region 0 < z < 1 , using data acquired with the Chandra X - ray Observatory and the Sloan Digital Sky Survey ( SDSS ) . We see that there is no evidence for expansion in the cluster mass distribution over this interval ; we measure the best - fitting Schechter parameters to be M * = 2 . 6 + / - 0 . 2 x 1014 h - 1M _ sun and alpha = - 1 . 1 + / - 0 . 3 at all redshifts .The absence of evolution suggests that the number density of large clusters has remained constant since z ~ 1 . These conclusions are compatible with previous analyses based on optical sampling but change considerably from those inferred by some latest analyses of X - ray selected samples .This discrepancy may arise because these latter samples include significant populations of lowest - mass groups which evolve faster between z = 1 and today .",
        "ori-fast-z-score": -1.61245154965971,
        "water-fast-z-score": 3.5
    },
    {
        "original_text": "We present an analysis of the correlation between radio sources in the southern sky with angular scales greater than 1 degree, and the temperature fluctuations observed by Wilkinson Microwave Anisotropy Probe (WMAP). We find that there is no significant correlation at large angular separations for any individual source population or combination thereof. However, we do detect a statistically significant cross-correlation signal when all extragalactic point sources are combined into one sample. The amplitude of this signal is consistent with theoretical predictions based on the Sunyaev-Zel dovich effect. This result suggests that the cold spot may be due to a superposition of many unresolved SZ clusters along our line-of-sight. In addition, we show that the lack of correlation seen individually among different populations can be explained if these populations have differing spectral indices and/or luminosity functions. Finally, we demonstrate how the results presented here could be used as a testbed for future experiments such as Planck Surveyor.",
        "watermark_text": "We present an assessment of the relationship between radio sources in the southern sky with angular scales greater than 1 degree , and the temperature fluctuations detected by Wilkinson Microwave Anisotropy Probe ( WMAP ) . We see that there is no considerable relationship at large angular separations for any individual source population or combination thereof .However , we do discover a statistically substantial cross - correlation signal when all extragalactic point bodies are united into one sample . The amplitude of this signal is compatible with theoretical estimates based on the Sunyaev - Zel dovich phenomenon .This result suggests that the cool spot may be due to a superposition of several unresolved SZ clusters along our line - of - seeing . In addition , we find that the lack of correlation seen individually among different populations can be described if these populations have differing brightness indices and / or luminosity functions .Finally , we prove how the papers presented here possible be used as a testbed for future research such as Planck Surveyor .",
        "ori-fast-z-score": 1.3242443839434612,
        "water-fast-z-score": 7.002011783343734
    },
    {
        "original_text": "In this article, we study families of holomorphic vector bundles on complex algebraic varieties. We prove that the set of isomorphism classes of such families is naturally an affine scheme over the base variety and give explicit equations for it in terms of Chern classes.  In particular, if the base variety has dimension one then these schemes are reduced to points corresponding to the rank and degree of each bundle in the family. \nWe also show how our results can be used to construct moduli spaces of stable vector bundles with fixed determinant. The main result of this article was announced by J. P. Serre at the conference  Algebraic geometry and number theory  held in Paris in June 2005 (see  Ser  ). Families of holomorphic vector bundles have been studied extensively since the work of Grothendieck  Gro1  . They play important roles both in algebraic geometry and mathematical physics; see e.g.,  Bri1,  Bri2,   Bri3,   ...",
        "watermark_text": "In this page , we study families of holomorphic vector bundles on complex algebraic varieties . We prove that the group of isomorphism classes of such families is naturally an affine scheme over the base variety and take explicit equations for it in terms of Chern classes .In particular , if the base range has size one then these schemes are converted to points corresponding to the rank and degree of each bundle in the class . We also demonstrate how our findings can be used to build moduli spaces of stable vector bundles with constant determinant .The main result of this paper was announced by J . P . Serre at the meeting Algebraic geometry and number theory conducted in Paris in June 2005 ( see Ser ) . Families of holomorphic functional bundles have been studied frequently since the work of Grothendieck Gro1 .They play essential roles both in mathematical mathematics and mathematical science ; seeing e . g . , Bri1 , Bri2 , Bri3 , . . .",
        "ori-fast-z-score": -1.116312611302876,
        "water-fast-z-score": 4.341215710622296
    },
    {
        "original_text": "We present results on the orbital evolution of Jupiter and Saturn in an axisymmetric, viscously evolving protoplanetary disk with embedded planets. We find that the orbits of both giant planets are significantly affected by their mutual gravitational interaction as well as by the presence of other planetary embryos. The eccentricity growth is dominated by secular interactions between the two planets which lead to large amplitude oscillations in the semi-major axes. In addition we find that the planet migration rates depend strongly on the initial conditions for the system parameters such as mass ratio and separation distance. \n \n Keywords: Planet formation - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N-body simulations \n \n \n \n 1 Introduction \n \n Planets form out of dust particles through coagulation processes (Safronov 1969; Wetherill & Stewart 1989) followed by runaway accretion onto these growing objects (Lissauer 1987). This process leads to the formation of planetesimals whose masses range from 10$^{−6}$ M⊕ up to several Earth masses. These bodies can grow further into larger planetary embryos or even directly into gas giants like Jupiter and Saturn if they accrete enough material within a short time span (Pollack et al. 1996) . Once formed, these massive planets open gaps in the surrounding circumstellar disks due to tidal torques exerted by the planet s gravity (Lin & Papaloizou 1986 ). As a consequence, the remaining matter inside this gap will be removed rapidly by viscosity effects leading to rapid inward type II migration of the planet (Ward 1997; Tanaka et al. 2002 ) . \nThe observed distribution of exoplanets shows a wide variety of orbital configurations ranging from circular orbits around Sun-like stars to highly eccentric orbits around low-mass stars (see e.g., Marcy et al. (2005) , Udry & Santos 2007 , Winn et al. (2010 ), Johnson et al. (2011 ) and references therein). However, most of them have been found close to their host star where the detection probability increases dramatically because of the strong stellar",
        "watermark_text": "We report findings on the orbital evolution of Jupiter and Saturn in an axisymmetric , viscously changing protoplanetary disk with attached planets . We see that the orbits of both giant planets are greatly impacted by their mutual gravitational interaction as well as by the presence of other planetary embryos .The eccentricity growth is dominated by secular interactions between the two planets which cause to large frequency oscillations in the semi - major axes . In addition we find that the planet migration rates differ highly on the early conditions for the system parameters such as mass ratio and separation distance .Keywords : Planet structure - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N - bodies simulations 1 Introduction Planets form out of dust particles through coagulation processes ( Safronov 1969 ; Wetherill & Stewart 1989 ) preceded by runaway accretion onto these growing objects ( Lissauer 1987 ) . This process results to the formation of planetesimals whose masses range from 10 $ ^ { −6 } $ M⊕ up to several Earth masses .These bodies can develop further into larger planetary embryos or even directly into gas giants like Jupiter and Saturn if they accrete adequate material within a brief time frame ( Pollack et al . 1996 ) .Once assembled , these massive planets open gaps in the nearby circumstellar disks owing to tidal torques exerted by the planet s gravity ( Lin & Papaloizou 1986 ) . As a consequence , the remaining material inside this gap will be removed soon by viscosity factors resulting to rapid inward type II displacement of the planet ( Ward 1997 ; Tanaka et al .2002 ) . The observed distribution of exoplanets shows a broad variety of orbital arrangements ranging from circular orbits around Sun - like stars to strongly eccentric orbits around low - density stars ( saw e . g . , Marcy et al .( 2005 ) , Udry & Santos 2007 , Winn et al . ( 2010 ) , Johnson et al .( 2011 ) and references therein ) . However , most of them have been observed nearby to their host star where the detection odds grows dramatically because of the strong stellar",
        "ori-fast-z-score": -1.2632278815997784,
        "water-fast-z-score": 4.867251878120797
    },
    {
        "original_text": "We report on an attempt to detect thermal emission from the planet TrES-1 using data obtained with the Spitzer Space Telescope s Infrared Array Camera (IRAC). We find no evidence that this planet is emitting significant amounts of infrared radiation at wavelengths longer than 3 microns, and we place upper limits on its temperature between 1000 K and 1500 K depending upon assumptions about the albedo.  These results are consistent with previous estimates based on optical photometry alone. The lack of detectable infrared flux suggests either that the planet has little or no atmosphere, or else it has a very low surface pressure such as would be expected if the planet were tidally locked into synchronous rotation. This work was supported by NASA under grant NAG5-12942 issued through JPL/Caltech. We thank J. Harrington for providing us with his model predictions prior to publication. We also acknowledge helpful discussions with A. Burrows, D. Charbonneau, M. Marley, R. Seager, S. Sozzetti, T. Swain, C. Traub, B. Zuckerman, and W. Wilson.",
        "watermark_text": "We report on an attempt to identify thermal emitted from the planet TrES - 1 using data acquired with the Spitzer Space Telescope s Infrared Array Camera ( IRAC ) . We see no evidence that this moon is emitting major amounts of infrared rays at wavelengths greater than 3 microns , and we put lower limits on its temperature between 1000 K and 1500 K depending upon predictions about the albedo .These conclusions are compatible with previous estimates based on optical photometry alone . The absence of detectable infrared flux implies either that the planet has little or no environment , or else it has a very low exterior pressure such as would be anticipated if the planet were tidally locked into synchronous rotation .This project was supported by NASA under grant NAG5 - 12942 issued through JPL / Caltech . We praise J . Harrington for providing us with his model models prior to publication .We especially acknowledge helpful talks with A . Burrows , D . Charbonneau , M . Marley , R . Seager , S . Sozzetti , T . Swain , C . Traub , B . Zuckerman , and W . Wilson .",
        "ori-fast-z-score": -1.5491933384829668,
        "water-fast-z-score": 4.905778905196061
    },
    {
        "original_text": "We have studied the pulse-to-pulse intensity variations in two pulsars, PSR B0826-34 and PSR B1133+16, using data obtained with the Parkes radio telescope at 1.4 GHz (92cm) and 2.7GHz(36cm). We find that both pulsars show strong evidence for subpulse drift bands which are modulated by an underlying pattern of weaker emission. The observed patterns can be explained as due to interference between different modes of emission within each beam. In addition we find that there is no significant difference in the subpulse modulation properties when comparing observations made at 36cm and those made at 92cm. This suggests that the physical processes responsible for producing these phenomena operate over a wide range of frequencies. These results provide further support for the idea that the phenomenon known as drifting subpulses may arise through some form of plasma instability operating on the open field lines near the magnetic poles of neutron stars. \n \n Keywords: Pulsar",
        "watermark_text": "We have researched the signal - to - pulse intensity variations in two pulsars , PSR B0826 - 34 and PSR B1133 + 16 , using data acquired with the Parkes radio telescope at 1 . 4 GHz ( 92cm ) and 2 . 7GHz ( 36cm ) . We see that both pulsars give strong evidence for subpulse slip lines which are modulated by an underlying pattern of weaker emission .The observed patterns can be described as owing to interference between various modes of emission within each light . In addition we find that there is no major variation in the subpulse modulation properties when matching observations made at 36cm and those conducted at 92cm .This implies that the physical processes responsible for producing these phenomena run over a broad variety of frequencies . These conclusions provide further evidence for the idea that the process known as drifting subpulses might arise through some kind of plasma instability working on the open field lines near the magnetic poles of neutron galaxies .Keywords: Pulsar",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 6.5484618759809905
    },
    {
        "original_text": "In this thesis, we propose an energy-efficient power control scheme for large code division multiple access (CDMA) systems with variable traffic loads and channel conditions. The proposed approach is based on the concept that all users should be allocated their required data rates at minimum total transmit power consumption while maintaining acceptable quality-of-service (QoS). We first develop a new analytical model which can accurately predict the average received signal-to-interference-plus-noise ratio (SINR) under different system configurations. Based on our analysis results, we then formulate the problem as a convex optimization problem subject to SINR constraints. Finally, by applying Lagrange multiplier method, we obtain closed-form solutions for both uplink and downlink transmissions. Our simulation results show that compared with conventional schemes such as water-filling algorithm, the proposed approach achieves significant performance gains in terms of power efficiency without sacrificing QoS requirements. In addition, it also outperforms other existing approaches in terms of computational complexity. \n \n Keywords: Code Division Multiple Access, Power Control",
        "watermark_text": "In this dissertation , we propose an energy - efficient energy management scheme for large code division multiple entry ( CDMA ) networks with variable traffic loads and channel conditions . The proposed approach is based on the idea that all users should be allocated their required information rates at minimum total broadcast power consumption while maintaining acceptable reliability - of - service ( QoS ) .We first develop a new analytical theory which can accurately forecast the average received signal - to - interference - plus - noise proportion ( SINR ) under various system systems . Based on our analysis results , we then formulate the question as a convex optimization problem subject to SINR restrictions .Finally , by using Lagrange multiplier method , we obtain closed - form methods for both uplink and downlink transmissions . Our modelling findings show that compared with typical strategies such as water - filling algorithm , the suggested approach achieves significant efficiency increases in terms of power performance without sacrificing QoS specifications .In addition , it also outperforms other existing techniques in terms of computational complexity . Keywords : Code Division Multiple Access , Power Control",
        "ori-fast-z-score": 0.9332565252573828,
        "water-fast-z-score": 7.154966693639935
    },
    {
        "original_text": "Gamma-ray bursts (GRBs) are the most energetic explosions in the universe, but their origin is still unknown. The leading model for GRB production involves two compact objects merging into one black hole and then exploding as a result of rapid accretion onto this black hole.  In this talk I will discuss how we can use gravitational waves to test this hypothesis by looking at the ringdown phase of these mergers. This is an exciting time for gravitational wave astronomy with Advanced LIGO/VIRGO starting taking data soon! \nI will also present some recent results on using gravitational waves to study neutron star mergers that may be related to short gamma ray bursts. Finally, I ll give you my personal perspective on what it takes to become a successful scientist today. My research interests include gravitational waves, astrophysics, cosmology, and particle physics. I m currently working at MIT Kavli Institute for Astrophysics and Space Research where I am part of the Gravitational Wave Cosmology Project.",
        "watermark_text": "Gamma - ray clusters ( GRBs ) are the most intense explosions in the universe , but their source is still unclear . The leading theory for GRB development involves two compact entities combining into one dark hole and then exploding as a result of rapid accretion onto this red hole .In this talk I will explain how we can using gravitational waves to test this hypothesis by searching at the ringdown phase of these mergers . This is an exciting day for gravitational wave astronomy with Advanced LIGO / VIRGO starting took data soon !I will also explain some latest findings on uses gravity signals to study neutron galaxy mergers that might be connected to short gamma radiation bursts . Finally , I ll offer you my personal perspective on what it takes to become a successful researcher today .My research interests cover gravitational waves , astrophysics , cosmology , and particle science . I m currently working at MIT Kavli Institute for Astrophysics and Space Research where I am member of the Gravitational Wave Cosmology Project .",
        "ori-fast-z-score": -0.11547005383792514,
        "water-fast-z-score": 6.581793068761733
    },
    {
        "original_text": "We present an analysis of multi-wavelength observations of the pulsar wind nebula (PWN) associated with PSR B1509-58 in the supernova remnant (SNR) G328.4+0. \n2. The radio emission is modeled as synchrotron radiation produced by relativistic electrons accelerated at the termination shock between the pulsar s magnetosphere and the surrounding medium. \n \n We find that the observed properties of this system are consistent with those expected for a young energetic pulsar surrounded by a dense shell of swept-up material. In particular, we show that: \n \n \n \n 1. The total energy contained within the SNR is ~1050 erg, which implies a kinetic energy of ~500 erg for the progenitor star prior to explosion; \n \n 2. The age of the pulsar is estimated to be ~20 kyr based on the spin-down luminosity and characteristic age; \n \n 3. The distance to the source is constrained to be <5 kpc using the dispersion measure and assuming a nominal value for the electron density along the line-of-sight; \n \n 4. The magnetic field strength near the pulsar is inferred to be ~1 mGauss based on modeling of the spectral index distribution across the face of the PWN; \n \n 5. The radius of the PWN is found to be ~0.3 pc, corresponding to a dynamical age of ~30 yrs; \n \n 6. The mass loss rate of the progenitor star was >10-5 Msun/yr during the last few thousand years before core collapse; \n \n 7. The initial mass of the progenitor star was ~25-30 Msuns, implying a red supergiant or blue hypergiant classification; \n \n 8. The ejecta mass of the progenitor star is estimated to be ~7-8 Msuns, indicating that it underwent significant mass loss prior to exploding; \n \n 9. The expansion velocity of the outer edge of the PWN is ~1000 km/sec, comparable to the speed of sound in the shocked gas; \n \n 10. The X-ray",
        "watermark_text": "We present an assessment of multi - wavelength images of the pulsar wind nebula ( PWN ) associated with PSR B1509 - 58 in the supernova remnant ( SNR ) G328 . 4 + 0 . 2 .The radio emission is modeled as synchrotron emission created by relativistic electrons accelerated at the termination shock between the pulsar s magnetosphere and the nearby medium . We see that the seen characteristics of this scheme are compatible with those expected for a young energetic pulsar surrounded by a dense shell of washed - up material .In particular , we find that : 1 . The total energy contained within the SNR is ~ 1050 erg , which implies a kinetic power of ~ 500 erg for the progenitor star previous to explosion ; 2 .The age of the pulsar is predicted to be ~ 20 kyr based on the spin - down luminosity and typical age ; 3 . The distance to the origin is constrained to be < 5 kpc using the dispersion measure and assuming a nominal value for the electron concentration along the line - of - view ; 4 .The magnetic force speed near the pulsar is inferred to be ~ 1 mGauss based on mapping of the spectral index distribution across the face of the PWN ; 5 . The radius of the PWN is found to be ~ 0 . 3 pc , equivalent to a dynamical age of ~ 30 yrs ; 6 .The mass loss rate of the progenitor star was > 10 - 5 Msun / yr during the last few thousand years before core breakup ; 7 . The initial mass of the progenitor star was ~ 25 - 30 Msuns , indicate a blue supergiant or blue hypergiant classification ; 8 .The ejecta mass of the progenitor star is predicted to be ~ 7 - 8 Msuns , showing that it underwent considerable mass loss prior to exploding ; 9 . The expansion velocity of the exterior boundary of the PWN is ~ 1000 kilometers / sec , comparable to the speed of noise in the excited gas ; 10 .The X-ray",
        "ori-fast-z-score": 1.539600717839002,
        "water-fast-z-score": 7.890453678924885
    },
    {
        "original_text": "The missing satellites problem (MSP) is one of the most important problems in space science and technology, with applications ranging from satellite navigation to space debris removal.  The MSP asks for all orbits that are stable under gravitational perturbations by known bodies such as planets or asteroids.   In this work we present an algorithm which solves the MSP exactly on any number of dimensions d >= 2 using only O(n log n + m log n) time where n = |S| is the total number of objects in S and m = |E| is the number of edges in E.   Our approach uses a novel combination of techniques including fast matrix multiplication algorithms, data structures based on interval trees, and efficient graph traversal methods. We also show how our results can be used to solve related problems like finding the minimum distance between two given sets of points in R^d. Finally, we demonstrate the practicality of our method through experiments performed on real-world datasets.",
        "watermark_text": "The missing satellites question ( MSP ) is one of the most important problems in space physics and technology , with applications diverse from satellite communication to space wreckage extraction . The MSP asks for all orbits that are stable under gravity perturbations by known objects such as planets or asteroids .In this project we present an algorithm which solves the MSP exactly on any number of dimensions d > = 2 using only O ( n log n + m log n ) time where n = | S | is the total number of items in S and m = | E | is the number of vertices in E . Our solution uses a innovative combination of techniques including rapid matrix multiplication methods , data models using on interval trees , and elegant graph traversal methods . We additionally prove how our findings can be used to solve related problems like finding the minimum height between two given sets of points in R ^ d .Finally , we prove the practicality of our technique through experiments conducted on real - time datasets .",
        "ori-fast-z-score": -1.709408646894569,
        "water-fast-z-score": 4.529108136578382
    },
    {
        "original_text": "We present new results on the long-term evolution of solar magnetic fields, obtained by applying an advanced data analysis technique to observations made with the Wilcox Solar Observatory (WSO) magnetograph between 1976 and 2009. The method is based on wavelet transforms in combination with principal component analysis (PCA). It allows us to separate different types of variability into their individual components at each point in time. We find that there are two distinct modes of solar magnetic field evolution over this period. One mode shows strong fluctuations around a mean value which varies slowly but significantly during the cycle 23/24 minimum. This behaviour can be explained as being due to the presence of large-scale dynamo waves driven by differential rotation. In addition we identify another type of variation which appears to have no preferred frequency or spatial scale. These variations show significant correlations with sunspot number and other proxies for solar activity. They may therefore represent some form of global response of the Sun s magnetic field to changes in its internal dynamics.",
        "watermark_text": "We report new data on the long - term expansion of solar magnetic waves , obtained by using an sophisticated data analysis technique to observations made with the Wilcox Solar Observatory ( WSO ) magnetograph between 1976 and 2009 . The method is based on wavelet transforms in combination with principal component analysis ( PCA ) .It enables us to separate distinct types of variability into their individual parts at each point in time . We see that there are two different paths of solar magnetic force evolution over this time .One mode displays large fluctuations around a mean value which varies steadily but significantly during the period 23 / 24 minimum . This behaviour can be understood as being owing to the presence of large - scale dynamo waves generated by differential rotation .In addition we identify another type of variation which appears to have no dominant amplitude or geographic range . These changes demonstrate considerable correlations with sunspot number and other proxies for solar activity .They might hence indicate some kind of worldwide response of the Sun s magnetic force to changes in its internal motion .",
        "ori-fast-z-score": 0.43133109281375365,
        "water-fast-z-score": 7.763959670647566
    },
    {
        "original_text": "The information-based asset pricing model is an extension to the traditional CAPM (Capital Assets Pricing Model) that incorporates additional factors into its analysis.  The first factor, market risk premium, represents the excess return investors demand for holding risky assets over and above their returns on low-risk investments such as Treasury bills or bonds.   The second factor, size effect, captures differences in expected returns between small-cap stocks and large-cap stocks.   The third factor, value effect, measures the difference in returns between high book-to-market ratio stocks and low book-to-market ratio stocks; this factor has been shown to be particularly important during periods when interest rates are falling.    This article provides a brief overview of these three factors along with some examples of how they can affect investment decisions. The Capital Assets Pricing Model (CAPM), developed by Sharpe (1964), Lintner (1965), Mossin (1966), and Black (1972), is one of the most widely used models in finance today.  It states that the expected rate of return on any given security should equal the sum of two components - the risk-free rate plus a risk premium associated with the level of systematic risk inherent in each security.  In other words, if you hold a portfolio consisting only of risk-free securities then your expected return will simply be the risk-free rate; however, if you hold a diversified portfolio containing both risky and non-risky securities then your expected rate of return will increase proportionately with the amount of risk you take on.  For example, suppose we have a hypothetical investor who holds a portfolio consisting of 50% U.S. Treasury bills and 50% Standard & Poor’s 500 Index Funds.  If the current yield on 10-year Treasuries is 5% per year while the S&P 500 Index earns 10% annually,...",
        "watermark_text": "The data - based portfolio management model is an addition to the usual CAPM ( Capital Assets Pricing Model ) that incorporates additional factors into its assessment . The first factor , market risk premium , represents the additional return investors need for holding risky funds over and above their returns on small - risk investments such as Treasury bills or bonds .The second factor , size factor , reflects variations in expected returns between small - cap stocks and large - cap stocks . The third factor , value effect , represents the difference in returns between strong book - to - market ratio stocks and low book - to - market ratio stocks ; this factor has been shown to be particularly important during periods when interest rates are falling .This page offers a brief overview of these three variables along with some examples of how they can affect investment decisions . The Capital Assets Pricing Model ( CAPM ) , developed by Sharpe ( 1964 ) , Lintner ( 1965 ) , Mossin ( 1966 ) , and Black ( 1972 ) , is one of the most commonly used theories in finance today .It says that the expected rate of return on any certain security should equivalent the sum of two parts - the danger - free level plus a risk premium associated with the degree of systematic risk inherent in each security . In other words , if you hold a portfolio consisting only of risk - safe securities then your anticipated return will simply be the risk - safe level ; however , if you hold a diversified portfolio encompassing both risky and non - risky securities then your anticipated level of return will expand proportionately with the quantity of risk you took on .For instance , suppose we have a hypothetical buyer who holds a portfolio consisting of 50 % U . S . Treasury money and 50 % Standard & Poor ’ s 500 Index Funds . If the present yield on 10 - month Treasuries is 5 % per month while the S & P 500 Index earns 10 % annually , . . .",
        "ori-fast-z-score": 0.5813183589761798,
        "water-fast-z-score": 7.224956747275377
    },
    {
        "original_text": "We present an analysis of the UKIRT Infrared Deep Sky Survey (UKIDSS) Galactic Cluster Survey data for the open cluster, Pleiades. We use this to derive the number ratio between binaries and single stars in the range 0.1 < M/M⊙ < 1.0 as well as the initial mass function (IMF). The results are compared against previous studies using different techniques. Our derived binary fraction is consistent within uncertainties with that found by other authors but our IMF shows significant differences when compared to previous work. These discrepancies may be due to contamination from background galaxies or unresolved multiple systems which have been included in previous analyses. This study highlights the importance of accurate photometry over large areas combined with high resolution spectroscopy to fully understand the properties of young open clusters such as the Pleiades. Keywords: Open cluster; Binary star systems; Initial Mass Function; Substellar object",
        "watermark_text": "We present an assessment of the UKIRT Infrared Deep Sky Survey ( UKIDSS ) Galactic Cluster Survey data for the open cluster , Pleiades . We use this to derive the number ratio between binaries and single galaxies in the range 0 . 1 < M / [UNK] < 1 . 0 as well as the initial mass function ( IMF ) .The results are compared against prior studies use different methods . Our derived binary fraction is compatible within uncertainties with that detected by other researchers but our IMF displays substantial differences when compared to previous research .These discrepancies may be due to contamination from background galaxies or unresolved multiple systems which have been involved in earlier analyses . This study highlights the importance of accurate photometry over large areas coupled with high resolution spectroscopy to fully realize the properties of young open nuclei such as the Pleiades .Keywords : Open cluster ; Binary galaxy structures ; Initial Mass Function ; Substellar object",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "In this thesis we study the problem of optimizing resource allocation in wireless networks by using non-cooperative game theory. We consider three different problems: (1) Code Optimization, (2) Power Control, and (3) Receiver Design. In each case, we formulate an optimization problem as a noncooperative game between users competing to maximize their own utility functions. Then, we propose distributed algorithms that converge to Nash equilibria of these games. Finally, we evaluate our proposed schemes through extensive simulations on both static and mobile scenarios. \n \n Keywords: Non-Cooperative Game Theory; Wireless Networks; Resource Allocation; Distributed Algorithms; Nash Equilibrium. 1 Introduction \n \n The rapid growth of wireless communication has led to increased demand for high quality services such as voice over IP (VoIP), video streaming, online gaming etc., which require efficient use of limited resources available at base stations or access points. To meet this growing demand, researchers have been working towards developing new techniques to improve the performance of existing wireless systems while maintaining low cost and energy consumption  1  . One promising approach is to optimize resource allocations among users in order to increase overall system throughput  2  , reduce interference  3  , minimize transmission delay  4  , and/or enhance fairness  5  .\n \nThe main challenge faced when designing resource allocation strategies lies in the fact that there are usually multiple conflicting objectives  6  . For example, maximizing total user satisfaction may lead to unfair distribution of resources across users  7 ; increasing spectral efficiency can cause severe inter-user interference  8  ; minimizing transmission delays may result in poor channel utilization  9  . Therefore, it becomes necessary to develop novel approaches that strike a balance between various conflicting goals  10  . \n \n This work was supported in part by NSF under Grants CNS-0721440, CCF-0729260, ECCS-0801571, and CNS-0916275.",
        "watermark_text": "In this dissertation we study the question of optimizing bandwidth allocation in mobile networks by using non - cooperative play logic . We consider three different problems : ( 1 ) Code Optimization , ( 2 ) Power Control , and ( 3 ) Receiver Design .In each situation , we formulate an optimization problem as a noncooperative game between participants competing to maximize their own utility functions . Then , we develop distributed methods that converge to Nash equilibria of these games .Finally , we assess our proposed arrangements through numerous simulations on both static and wireless situations . Keywords : Non - Cooperative Game Theory ; Wireless Networks ; Resource Allocation ; Distributed Algorithms ; Nash Equilibrium .1 Introduction The rapid increase of mobile communication has led to renewed demand for high quality services such as voice over IP ( VoIP ) , television playback , internet gaming etc . , which require efficient application of restricted resources accessible at base stations or entry points . To address this increasing demand , researchers have been pushing towards developing innovative techniques to upgrade the performance of older broadband systems while maintaining low cost and energy consumption 1 .One promising solution is to optimize resource allocations among consumers in order to expand overall network throughput 2 , avoid noise 3 , eliminate communication delay 4 , and / or enhance fairness 5 . The main challenge facing when designing resource allocation strategies rests in the fact that there are typically many conflicting aims 6 .For instance , maximizing gross consumer satisfaction would result to inappropriate distribution of assets across users 7 ; increasing spectral capacity can cause profound cross - customer interference 8 ; minimizing broadcast delays may end in poor channel utilization 9 . Therefore , it becomes necessary to develop new approaches that strike a balance between various differing aims 10 .This project was supported in part by NSF under Grants CNS - 0721440 , CCF - 0729260 , ECCS - 0801571 , and CNS - 0916275 .",
        "ori-fast-z-score": -1.7320508075688774,
        "water-fast-z-score": 8.825211257612851
    },
    {
        "original_text": "We present the results of our Spitzer Space Telescope survey for protostars and young stellar objects (YSOs) in three nearby, intermediate mass star-forming regions: NGC 1333, Serpens South, and Perseus North. We identify over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and/or envelopes. The majority are Class I sources that have recently formed outflows or jets; however we also find several dozen more evolved Class II/III sources. In addition to these disk-bearing systems, we detect numerous isolated point-like sources whose SEDs suggest they are deeply embedded protostars. These observations provide new insights into how stars form in IM environments. Our sample includes many previously unidentified low-luminosity protostars which will be useful targets for future studies at higher angular resolution. This work is based on observations made with the Spitzer Space Telescope, which is operated by NASA under contract 1407. Support for this work was provided by NASA through an award issued by JPL/Caltech. \n \n Keywords: Protostar",
        "watermark_text": "We publish the conclusion of our Spitzer Space Telescope survey for protostars and young stellar bodies ( YSOs ) in three nearby , intermediate mass star - creating areas : NGC 1333 , Serpens South , and Perseus North . We distinguish over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and / or envelopes .The majority are Class I sources that have newly formed outflows or jets ; however we also find several dozen more evolved Class II / III sources . In addition to these disk - bearing components , we locate many isolated point - like sources whose SEDs suggest they are deeply embedded protostars .These measurements give novel knowledge into how stars create in IM environments . Our specimen includes several recently unidentified low - luminosity protostars which will be valuable targets for future research at higher angular resolution .This project is based on observations made with the Spitzer Space Telescope , which is controlled by NASA under contract 1407 . Support for this project was provided by NASA through an grant issued by JPL / Caltech .Keywords: Protostar",
        "ori-fast-z-score": -1.3054598240132387,
        "water-fast-z-score": 5.019960159204453
    },
    {
        "original_text": "We present an algorithm for finding the optimal matching between two sets of clusters, which we call  trueclusters .  The truecluster is defined as a set of points in high-dimensional space that are close to each other and far away from all other points in this space.   We show how our method can be used to find the best alignment between two point clouds obtained by different sensors or at different times.   ... \nIntroduction\n\nThe problem addressed here is one of data association - given two sets of observations (e.g., images), determine what pairs correspond to the same physical object.  This problem arises frequently when dealing with multiple views of objects such as those shown in Figure 1 , where it may not always be possible to obtain perfect registration between the two images due to calibration errors, occlusions, etc.\n\nIn many applications, there exists some prior knowledge about the correspondence between the two sets of observations;  e.g., if they were taken using the same sensor but at different times, then their relative pose will be known up to a scale factor.  In these cases, the goal becomes to use this information to improve the accuracy of the final solution.  \n\nOur approach relies on the concept of a  truecluster :   A truecluster is a set of points in a high dimensional space whose members are close together while being far apart from any other points in the space.  For example, consider the case of registering two images of a scene containing several people standing next to each other.  Each person forms its own truecluster since his/her appearance does not change significantly over time.  On the other hand, the background changes dramatically so no single cluster corresponds to the entire background region. \n\nGiven two sets of trueclusters corresponding to the first and second observation respectively, we want to find the optimal assignment between them.  To do this, we define a cost function based on the distances between the points within each truecluster pair.  Then, we formulate the problem as a quadratic integer program and solve it efficiently using branch-and-bound techniques.  Finally,...",
        "watermark_text": "We present an algorithm for finding the ideal matching between two sequences of clusters , which we call trueclusters . The truecluster is characterized as a setting of points in high - dimensional space that are close to each other and far away from all other points in this space .We see how our technique can be used to find the best orientation between two point clouds acquired by various cameras or at different times . . . . Introduction The question explored here is one of data association - given two sets of measurements ( e . g . , photographs ) , determine what pairs relate to the same physical object .This problem arises often when dealing with many perspectives of items such as those shown in Figure 1 , where it must not always be possible to obtain good registered between the two images resulting to calibration errors , occlusions , etc . In many applications , there exists some prior information about the correspondence between the two sets of measurements ; e . g . , if they were took use the same sensor but at different times , then their relative pose will be described up to a scale factor .In these circumstances , the objective remains to use this data to improve the accuracy of the finished solution . Our solution uses on the idea of a truecluster : A truecluster is a setting of points in a high dimensional space whose members are close together while being far separate from any other points in the space .For instance , consider the case of registering two images of a scene containing several people standing close to each other . Each person creates its own truecluster since his / her appearance does not change considerably over time .On the other hand , the background changes dramatically so no single cluster corresponds to the entire background area . Given two sets of trueclusters corresponding to the first and second observation respectively , we want to find the ideal assignment between them .To do this , we define a price vector depending on the distances between the points within each truecluster pair . Then , we formulate the issue as a quadratic integer program and solve it easily using branch - and - bound techniques .Finally,...",
        "ori-fast-z-score": -0.15713484026367722,
        "water-fast-z-score": 7.542472332656507
    },
    {
        "original_text": "We study the phenomenology of non-zero trilinear soft supersymmetry breaking (SSB) term A 0 in minimal supergravity (mSUGRA). We find that for large values of tan β, there is an upper bound on |A 0 | which can be obtained by requiring correct electroweak symmetry breaking. For small values of tan β, we show that the allowed range of |A 0 | increases with decreasing value of M 1/2 . In both cases, the lower limit on |A 0 | comes from the requirement of not having charge and/or color breaking minima deeper than the electroweak vacuum. The effect of varying |A 0 | on sparticle masses are studied numerically using ISAJET 7.64. It is found that increasing |A 0 | leads to decrease in mass difference between lightest neutralino and lighter charginos as well as increase in mass splitting among squarks and sleptons. This results into enhancement of production cross sections of these particles at hadronic colliders like Tevatron and LHC.",
        "watermark_text": "We explore the phenomenology of non - zero trilinear soft supersymmetry broken ( SSB ) term A 0 in reduced supergravity ( mSUGRA ) . We see that for large values of tan β , there is an upper bound on | A 0 | which can be obtained by requiring proper electroweak symmetry breaking .For small values of tan β , we find that the allowed range of | A 0 | increases with decreasing value of M 1 / 2 . In both cases , the lower limit on | A 0 | stems from the requirement of not having charge and / or color breaking minima deeper than the electroweak cavity .The impact of increasing | A 0 | on sparticle masses are studied numerically utilizing ISAJET 7 . 64 . It is found that varying | A 0 | leads to decrease in mass ratio between lightest neutralino and darker charginos as also as increase in mass separation among squarks and sleptons .This results into enhancement of output cross sections of these particles at hadronic colliders like Tevatron and LHC .",
        "ori-fast-z-score": -0.2581988897471611,
        "water-fast-z-score": 3.8729833462074166
    },
    {
        "original_text": "We present the relativistic second order perturbation theory for fluids in curved space-time with arbitrary number of components. We derive the general expression for the energy-momentum tensor at first order in perturbations as well as its trace-free part which is responsible for gravitational waves generation. The evolution equations are derived by projecting the conservation law onto the background 4-velocity vector field. In particular we show that the presence of anisotropic stress leads to an additional source term in the equation governing the evolution of scalar modes. Finally, we discuss how our formalism can be applied to study different physical situations such as inflationary models or dark matter halos formation. Cosmology has been revolutionized over the past decade thanks to precision measurements of temperature fluctuations in the cosmic microwave background (CMB) radiation  1  . These observations have provided us with detailed information about the early universe and allowed to test fundamental physics on very large scales  2  .\nThe standard model of cosmology assumes that the universe consists of several interacting components including cold dark matter (CDM), baryons, photons, neutrinos etc.. Each component evolves according to some set of hydrodynamical equations describing their dynamics  3  . However, these equations cannot be solved analytically even if one neglects all interactions between particles  4  , so numerical simulations are required  5  . On the other hand, analytical solutions exist only under certain approximations  6  . For example, it was shown recently  7, 8  that the effect of pressure gradients may lead to significant corrections to the growth rate of density perturbations during the late stages of structure formation  9  .",
        "watermark_text": "We introduce the relativistic second order perturbation theory for fluids in curved space - time with arbitrary number of components . We derive the general expression for the power - momentum tensor at first order in perturbations as well as its trace - free portion which is responsible for gravitational waves generation .The evolution equations are derived by projecting the conservation law onto the background 4 - velocity vector field . In particular we find that the presence of anisotropic stress leads to an additional source term in the equation regulating the evolution of scalar modes .Finally , we talk how our formalism can be applied to study various physical conditions such as inflationary theories or black particle halos formation . Cosmology has been revolutionized over the previous decade courtesy to accurate measurements of temperature fluctuations in the cosmic microwave background ( CMB ) radiation 1 .These measurements have provided us with comprehensive information about the early universe and enable to test fundamental theory on very huge scales 2 . The conventional model of cosmology assumes that the universe consists of several interacting components namely cold bright matter ( CDM ) , baryons , photons , neutrinos etc . . Each component evolves due to some setting of hydrodynamical equations explaining their mechanics 3 .However , these equations never be answered analytically even if one neglects all interactions between particles 4 , so numerical simulations are required 5 . On the other hand , analytical solutions arise only under certain approximations 6 .For instance , it was shown ago 7 , 8 that the impact of force gradients might lead to significant corrections to the development time of density perturbations during the late stages of formation formation 9 .",
        "ori-fast-z-score": -2.1213203435596424,
        "water-fast-z-score": 5.1946603473211805
    },
    {
        "original_text": "We present photoionization models for the heliosheath, which is the region between the termination shock (TS) at ~100 AU and the solar wind termination shock (SWTS). The SWTS is located beyond 1 AU in the solar system s frame but within 0.3 AU in the rest frame of the Sun. We use these models to constrain the boundary conditions of the heliosphere using interstellar neutral hydrogen data obtained with the Lyman-alpha instrument on board the Solar Wind Anisotropy Probe (SWAP), as well as in situ measurements made near Earth during the Voyager 2 mission. Our results show that the TS distance decreases with increasing solar activity; this effect can be explained by an increase in the density of the solar wind plasma. For low solar activity levels we find that the TS distance agrees very well with previous estimates based on observations of energetic particles.",
        "watermark_text": "We use photoionization estimates for the heliosheath , which is the region between the termination shock ( TS ) at ~ 100 AU and the solar wind termination shock ( SWTS ) . The SWTS is situated beyond 1 AU in the solar system s frame but within 0 . 3 AU in the remainder frame of the Sun .We use these models to constrain the boundary parameters of the heliosphere utilizing interstellar neutral hydrogen evidence derived with the Lyman - alpha instrument on board the Solar Wind Anisotropy Probe ( SWAP ) , as well as in situ measurements made near Earth during the Voyager 2 mission . Our results show that the TS distance reduces with rising sun activity ; this effect can be described by an increase in the density of the solar wind plasma .For low solar activity rates we find that the TS distance agrees very best with previous estimates based on observations of energetic particles .",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 2.994344952558949
    },
    {
        "original_text": "The Axion Dark Matter Search (ADMX) experiment is designed to search for dark matter in the form of axions, which are hypothetical particles predicted by theories beyond the Standard Model.  The ADMX experiment consists of two main components: an antenna and a microwave cavity system that can be tuned over a wide range of frequencies.   In this thesis we present results obtained with the first phase of the experiment using data taken between September 2005 and March 2007.    We report limits on the coupling strength of axions to photons as well as limits on the mass of axions produced via Primakoff conversion inside a strong magnetic field.  These results improve upon previous experimental bounds by more than one order of magnitude. This work was performed under the auspices of the U.S Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. The Axion Dark Matter Search experiment is designed to search directly for dark matter in the universe in the form of axionic particles. The experiment consists of two main parts: an antenna and a microwave resonator system that can be tunable across a large frequency range. In this dissertation I will discuss our recent results from the first stage of the experiment.",
        "watermark_text": "The Axion Dark Matter Search ( ADMX ) experiment is designed to search for black material in the form of axions , which are hypothetical particles expected by theories beyond the Standard Model . The ADMX experiment consists of two principal portions : an antenna and a microwave cavity network that can be tuned over a broad variety of frequencies .In this dissertation we present results derived with the first phase of the program including data taken between September 2005 and March 2007 . We report limits on the interaction strength of axions to photons as well as limits on the mass of axions produced via Primakoff transformation inside a powerful magnetic force .These data improve upon former empirical bounds by more than one order of magnitude . This research was done under the auspices of the U . S Department of Energy by Lawrence Livermore National Laboratory under Contract DE - AC52 - 07NA27344 .The Axion Dark Matter Search experiment is designed to search specifically for black material in the universe in the form of axionic particles . The project consists of two principal parts : an antenna and a microwave resonator system that can be tunable across a large frequency spectrum .In this dissertation I will explore our latest findings from the first phase of the project .",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 6.413001035278336
    },
    {
        "original_text": "We propose an approach to the problem of predicting football match results based on self-confirming beliefs and their evolution over time. We use data from the English Premier League (EPL) season 2013-14, which consists of 380 matches played by 20 teams in 38 rounds. The proposed method is tested against two baseline models that do not take into account any temporal dynamics between consecutive games. Our experiments show that our model outperforms both baselines with respect to accuracy and F1 score metrics. In addition, we demonstrate how the proposed model can be used as part of a decision support system for betting purposes. Predicting sports outcomes has been one of the most popular research topics among researchers working in machine learning and data mining communities. This interest stems mainly from its practical applications such as sport betting systems or recommendation engines for fans. However, despite the large number of studies conducted so far, there are still many open problems related to this topic. One of these challenges concerns the prediction of future events given past observations. For example, if we want to predict whether team A will win game X vs. team B at home ground C, then it may seem reasonable to assume that the outcome of previous games involving either team A or team B should have some influence on the final result.",
        "watermark_text": "We suggest an approach to the issue of predicting football match results based on self - verified beliefs and their development over time . We use data from the English Premier League ( EPL ) season 2013 - 14 , which consists of 380 games played by 20 teams in 38 rounds .The proposed approach is tested against two baseline theories that do not take into consideration any temporal dynamics between successive games . Our experiments indicate that our model outperforms both baselines with regard to reliability and F1 score metrics .In addition , we prove how the suggested model can be used as part of a decision support system for betting purposes . Predicting games outcomes has been one of the most popular research subjects among researchers practicing in machine computing and information processing communities .This interest arises principally from its practical applications such as sport betting systems or recommendation engines for fans . However , despite the huge amount of studies performed so far , there are still many open problems related to this topic .One of these problems involves the expectation of later developments given past predictions . For instance , if we wish to predict whether squad A will win match X vs . squad B at home ground C , then it must appear probable to assume that the result of previous contests concerning either team A or squad B should have some influence on the last result .",
        "ori-fast-z-score": 0.5669467095138409,
        "water-fast-z-score": 8.199778267512094
    },
    {
        "original_text": "We present new observations with the Hubble Space Telescope (HST) and Chandra X-ray Observatory to study the properties of ionized gas in galaxy clusters at z ~ 0.5-0.8, where most massive clusters are found today.  We find that the fraction of cool core clusters is higher than expected for their redshifts based on local samples. The observed evolution may be due to an increase in the number density of active galactic nuclei or AGN activity over time. In addition, we detect extended emission line regions around some of these clusters which have been previously identified as having strong cooling flows. These results suggest that there has been significant heating of the intracluster medium by energetic outflows associated with AGNs since z = 1.0. This work was supported by NASA grant NAG5-9998. Cooling flow clusters are known to contain large amounts of cold gas within their central regions. However, it remains unclear how this gas cools down without forming stars. Recent studies show that many of them also harbor powerful radio sources near their centers. It is possible that such radio jets heat up the ICM through shocks and/or turbulence generated during the interaction between the jet plasma and the ambient hot gas.",
        "watermark_text": "We present new experiments with the Hubble Space Telescope ( HST ) and Chandra X - ray Observatory to study the properties of ionized gas in galaxy galaxies at z ~ 0 . 5 - 0 . 8 , where most large clusters are found today . We see that the fraction of cold core galaxies is higher than expected for their redshifts based on local samples .The observed evolution may be due to an increase in the number density of active galactic nuclei or AGN activity over time . In addition , we find extended emitted path regions around some of these clusters which have been previously noted as having strong cooling flows .These results suggest that there has been significant heating of the intracluster medium by energetic outflows associated with AGNs since z = 1 . 0 . This work was supported by NASA grant NAG5 - 9998 .Cooling circulation clusters are known to contain significant amounts of cold energy within their central regions . However , it remains unclear how this gas cools down without forming stars .Recent research reveal that several of them additionally harbor potent wireless sources near their regions . It is suggested that such radio jets heat up the ICM through shocks and / or turbulence generated during the interaction between the jet plasma and the ambient warm gas .",
        "ori-fast-z-score": 1.744163198544762,
        "water-fast-z-score": 6.123724356957946
    },
    {
        "original_text": "We present the latest advances in optical frequency combs and their applications to precision metrology, including calibration techniques for high-resolution spectroscopy instruments such as Fourier transform spectrometers (FTS). We discuss how these techniques can be used to improve measurement accuracy by orders of magnitude over traditional methods.  In particular we describe two novel approaches that are being developed at NIST:  1) The use of an optical frequency comb locked to a high-accuracy atomic clock to calibrate FTS measurements with sub-Hz uncertainty. 2) A technique called  self-calibration  which allows one to measure absolute frequencies without requiring any external reference standards or other auxiliary equipment. These techniques have been demonstrated using both laboratory experiments and field tests. They represent important steps towards realizing the vision of a future where all spectroscopic measurements will be traceable back to fundamental physical constants. This is especially relevant today given the growing interest in developing portable, low-cost devices capable of performing accurate chemical analysis anywhere around the world.",
        "watermark_text": "We address the latest advances in imaging bandwidth combs and their applications to precision metrology , notably calibration methods for high - resolution spectroscopy instruments such as Fourier shift spectrometers ( FTS ) . We discuss how these tools can be used to achieve observation reliability by orders of magnitude over traditional techniques .In particular we explain two novel approaches that are being pioneered at NIST : 1 ) The using of an optical frequency comb fixed to a high - speed atomic clock to calibrate FTS calculations with sub - Hz uncertainty . 2 ) A methodology called self - calibration which allows one to measure absolute frequencies without using any external reference standards or other auxiliary machinery .These methods have been shown using both laboratory experiments and field trials . They represent crucial progress towards realizing the vision of a future where all spectroscopic observations will be traceable back to essential scientific constants .This is especially applicable today due the increasing interest in making portable , low - cost devices capable of performing exact chemical analysis anywhere around the world .",
        "ori-fast-z-score": -0.6396021490668313,
        "water-fast-z-score": 5.9696200579570915
    },
    {
        "original_text": "We consider the problem of local purification in quantum networks, where each node is allowed to perform only local operations and communicate classically with its neighbors. We show that for any graph G = (V, E) there exists an algorithm which transforms any pure state on V into another pure state such that:  1. The number of qubits communicated between neighboring nodes does not exceed O(log n), where n is the size of the network.  2. Each node performs at most polylogarithmic many local operations. Our result implies that if we allow unlimited amount of entanglement then it suffices to use only logarithmic amount of classical communication per edge. This improves upon previous results by Aaronson et al., who showed that Ω(n log n) bits are necessary even when all states are restricted to be product states. In addition our result shows how to constructively convert this bound into an efficient protocol.",
        "watermark_text": "We consider the question of local purification in quantum networks , where each node is allowed to conduct only local actions and communicate classically with its relatives . We see that for any graph G = ( V , E ) there exists an algorithm which transforms any pure state on V into another pure state such that : 1 .The amount of qubits transmitted between neighboring nodes does not reach O ( log n ) , where n is the size of the network . 2 .Each node performs at most polylogarithmic many local activities . Our result requires that if we allow unlimited amount of entanglement then it suffices to use only logarithmic amount of classical communication per edge .This improves upon preceding results by Aaronson et al . , who demonstrated that Ω ( h log n ) bits are necessary even when all states are restricted to be product states . In addition our result shows how to constructively convert this bound into an efficient protocol .",
        "ori-fast-z-score": -0.8551861104941365,
        "water-fast-z-score": 2.321219442769799
    },
    {
        "original_text": "We report on neutron scattering experiments performed to study spin fluctuations and magnetic correlations in the metallic phase of quasi-two-dimensional organic superconductor κ-(BEDT-TTF)2Cu N(CN)2 Br (κ-Br). We find that the temperature dependence of the static susceptibility χ0 is well described by the Curie-Weiss law with an antiferromagnetic Weiss constant θ = -26 K, indicating strong antiferromagnetic interactions between spins. The observed broadening of the elastic linewidth Γel at low temperatures indicates short-range spin-spin correlation lengths ξs ~ 5 nm. In addition we observe a large enhancement of the dynamic susceptibility χ′′(Q,ω), which can be attributed to the development of low-energy spin excitations below T* ~ 50 K. These results are consistent with theoretical predictions for two-dimensional systems close to quantum criticality. Our data suggest that the system undergoes a transition into a state where the Fermi surface becomes unstable against formation of electron-hole pairs leading to Cooper pairing. \n \n Introduction \n \n A number of recent studies have shown that many strongly correlated electronic materials exhibit unconventional properties such as high-temperature superconductivity or non-Fermi liquid behavior  1  . One important aspect of these phenomena is the presence of collective charge and/or spin degrees of freedom  2  , whose dynamics often give rise to characteristic features in the excitation spectrum  3  . For example, in cuprate-based high-temperature superconductors  4  , it has been suggested that the pseudogap regime  5  may arise due to competing orders  6  originating from different regions of the Brillouin zone  7, 8  . Similarly, in iron pnictide compounds  9  , the appearance of a spin-density wave order parameter  10  leads to a suppression of the density-of-states near the Fermi level  11  resulting in a partial gap opening  12  . Finally, in heavy fermion metals  13  , the hybridization of localized f-electrons  14  gives rise to a nontrivial momentum structure of the self-energy  15  .\n \nIn this work, we present detailed measurements of the spin fluctuation spectrum in the metallic phase of the quasi",
        "watermark_text": "We report on neutron scattering experiments conducted to study spin fluctuations and magnetic correlations in the metallic phase of quasi - two - dimensional organic superconductor κ - ( BEDT - TTF ) 2Cu N ( CN ) 2 Br ( κ - Br ) . We see that the temperature dependence of the static susceptibility χ0 is well described by the Curie - Weiss law with an antiferromagnetic Weiss constant θ = - 26 K , showing strong antiferromagnetic interactions between spins .The observed broadening of the elastic linewidth Γel at low temperatures indicates short - range spin - spin correlation distances ξs ~ 5 nm . In addition we study a large enhancement of the dynamic susceptibility χ ′ ′ ( Q , ω ) , which can be due to the development of high - energy spinning excitations below T * ~ 50 K . These conclusions are compatible with theoretical estimates for two - dimensional systems close to quantum criticality .Our data suggest that the system undergoes a shift into a state where the Fermi surface gets unstable against development of electron - hole couples leading to Cooper coupling . Introduction A couple of recent studies have shown that several highly correlated optical materials exhibit unusual characteristics such as high - temperature superconductivity or non - Fermi solid behavior 1 .One important feature of these phenomena is the presence of collective charge and / or spin degrees of liberty 2 , whose dynamics often give rise to distinctive features in the excitation spectrum 3 . For instance , in cuprate - based high - temperature superconductors 4 , it has been proposed that the pseudogap regime 5 may arise due to competing orders 6 resulting from different regions of the Brillouin zone 7 , 8 .Similarly , in metal pnictide molecules 9 , the appearance of a spin - density wave order parameter 10 results to a suppression of the density - of - states near the Fermi level 11 producing in a partial gap opening 12 . Finally , in heavy fermion metals 13 , the hybridization of localized f - ions 14 makes rise to a nontrivial momentum arrangement of the self - energy 15 .In this research , we present detailed observations of the spin fluctuation spectrum in the metallic phase of the quasi",
        "ori-fast-z-score": 1.0441851275732486,
        "water-fast-z-score": 7.574735861838574
    },
    {
        "original_text": "We test whether the observed value of lambda is consistent with the prediction that it should be equal to one third of the square root of the number density of galaxies in the universe today, as suggested by Tegmark et al. (2006) . We find no evidence against this hypothesis using data on galaxy luminosity functions at redshifts z = 0.1, 1.0 and 3.5 taken from the Sloan Digital Sky Survey (SDSS). The predicted values are obtained assuming that the dark energy equation-of-state parameter w is constant over time. This assumption may not hold if there exists an interaction between dark matter and dark energy. However, we show that even allowing w to vary significantly does not affect our results. \n \n In addition, we use the WMAP 5-year cosmological parameters to calculate the expected temperature anisotropy power spectrum of the cosmic microwave background radiation (CMB) given the current best-fit model. We compare these theoretical predictions with measurements made by the Wilkinson Microwave Anisotropy Probe (WMAP), finding good agreement across all multipole moments up to lmax = 1000.",
        "watermark_text": "We test whether the known value of lambda is compatible with the observation that it should be equal to one third of the square root of the number density of galaxies in the universe today , as suggested by Tegmark et al . ( 2006 ) .We see no evidence against this hypothesis utilizing information on star luminosity functions at redshifts z = 0 . 1 , 1 . 0 and 3 . 5 taken from the Sloan Digital Sky Survey ( SDSS ) . The predicted readings are derived assuming that the dark energy equation - of - state variable W is constant over time .This assumption must not hold if there exists an interaction between dark matter and dark energy . However , we find that even allowing W to vary significantly does not alter our findings .In addition , we utilize the WMAP 5 - day cosmological values to estimate the expected thermal anisotropy energy spectrum of the cosmic microwave background radiation ( CMB ) given the latest best - fitting model . We match these theoretical estimates with observations made by the Wilkinson Microwave Anisotropy Probe ( WMAP ) , finding high agreement across all multipole minutes up to lmax = 1000 .",
        "ori-fast-z-score": 0.1111111111111111,
        "water-fast-z-score": 6.340751391209736
    },
    {
        "original_text": "We present the first results on differential rotation for an evolved star, based on observations with the Microvariability and Oscillations of STars (MOST) satellite. The target is the F-type main-sequence star kappa 1 Cet (HD 128898), which has been observed in two consecutive runs during 2005-2006. We find that the surface shear rate decreases towards lower latitudes, but increases again at mid-latitudes. This behaviour can be explained if we assume that there are two differentially rotating regions on opposite sides of the equator. In addition to this large-scale pattern, we also detect smaller-scale features such as spots and plages. These structures appear to have lifetimes between one week and several months. Finally, we show how our results compare with theoretical predictions made using stellar evolution models. Keywords: Differential rotation; Stellar activity; Spots; Plages; MOST",
        "watermark_text": "We report the first findings on differential rotation for an evolved star , based on observations with the Microvariability and Oscillations of STars ( MOST ) satellite . The target is the F - class major - sequence star kappa 1 Cet ( HD 128898 ) , which has been observed in two consecutive ran during 2005 - 2006 .We see that the surface shear rate decreases nearer lower latitudes , but grows again at mid - latitudes . This behaviour can be described if we suppose that there are two differentially rotating zones on opposite sides of the equator .In addition to this big - scale signature , we also observe lower - scale characteristics such as spots and plages . These structures appear to have lifetimes between one month and many months .Finally , we tell how our findings compare with theoretical estimates made using stellar evolution models . Keywords : Differential rotation ; Stellar activity ; Spots ; Plages ; MOST",
        "ori-fast-z-score": -0.7745966692414834,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "The relationship between the size of an animal s body (its mass) and that of its brain is known as allometric scaling, but it remains unclear how this relationship arises in evolution.  In particular, there are two competing hypotheses for why larger animals have bigger brains than smaller ones.   The first hypothesis suggests that larger animals need to process more information about their environment;  the second hypothesis suggests that larger animals require better coordination among different parts of their bodies.  Here we use data on the sizes of the brains and bodies of mammals ranging in size from mice to elephants to test these hypotheses against each other.  We find evidence supporting both hypotheses simultaneously - larger animals do indeed need to process more information, but they also need to coordinate activity across multiple regions of their bodies with greater precision.  Our results suggest that the evolutionary pressure driving increases in brain size may be related to the ability of large-brained animals to integrate information over space and time.",
        "watermark_text": "The relationship between the height of an organism s body ( its weight ) and that of its brain is known as allometric scaling , but it remains unclear how this relationship occurs in evolution . In particular , there are two different hypotheses for why greater animals have larger brains than larger ones .The first theory indicates that larger humans need to absorb more information about their environment ; the second hypothesis suggests that larger animals require improved coordination among different components of their bodies . Here we using data on the sizes of the brains and bodies of mammals varied in height from rats to elephants to test these hypotheses against each other .We see evidence proving both hypotheses jointly - larger animals do actually require to absorb more information , but they still must to organize activity across multiple parts of their bodies with higher precision . Our results propose that the evolutionary stress driving variations in brain diameter may be due to the ability of large - brained animals to relate data over space and period .",
        "ori-fast-z-score": -0.21320071635561041,
        "water-fast-z-score": 7.397576490380784
    },
    {
        "original_text": "The cosmic ray origin is still unknown, but it may be related to the supernova explosion.  The propagation model describes how cosmic rays are transported in space by diffusion processes with energy losses due to ionization and Coulomb scattering off interstellar gas particles.   This article presents an overview on cosmic ray physics and introduces some basic concepts for understanding cosmic ray transport models. Cosmic rays have been observed since the 19th century. They consist mainly of protons (about 85%) and helium nuclei (about 14%). Their energies range up to 10^20 eV. However, their sources remain unclear. It has been suggested that they might come from exploded stars called supernovae or from active galactic nuclei such as quasars. In this case, they would travel through intergalactic space before reaching Earth. Another possibility is that they are accelerated within our own galaxy. If so, then they could reach us directly without traveling far away.",
        "watermark_text": "The cosmic ray origin is still unclear , but it could be connected to the supernova explosion . The propagation model describes how cosmic rays are transported in space by diffusion processes with energy losses owing to ionization and Coulomb absorption off interstellar gas molecules .This page presents an overview on cosmic ray physics and introduces some fundamental concepts for studying cosmic ray transport models . Cosmic rays have been observed since the 19th century .They consist mostly of protons ( about 85 % ) and helium nuclei ( about 14 % ) . Their energies range up to 10 ^ 20 eV .However , their sources continue unknown . It has been proposed that they may come from burst stars called supernovae or from active galactic nuclei such as quasars .In this instance , they may travel through intergalactic space before reaching Earth . Another possibility is that they are accelerated within our own galaxy .If so , then they may reach us directly without traveling long away .",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 5.421151989096865
    },
    {
        "original_text": "We present new near-infrared (NIR) polarimetric observations of the Herbig Ae star HD 142527, which reveal that its circumstellar dust is composed of two distinct populations with different grain sizes. The polarization degree decreases rapidly towards longer wavelengths at all positions along our slit except for one position where it increases again between 2.2 and 3.8 microns. We interpret this as evidence for an inner hole in the distribution of larger grains. This interpretation is supported by SED modeling using radiative transfer calculations including scattering off spherical particles. Our results suggest that the outer edge of the gap lies within 0.1 AU of the central star. In addition to the NIR data presented here we also obtained mid-infrared (MIR) spectro-polarimetry covering the wavelength range 5-20 micron. These data show no significant change in the polarization degree across the MIR bands indicating that there are no strong changes in the optical properties of the dust grains on these scales.",
        "watermark_text": "We present new near - infrared ( NIR ) polarimetric studies of the Herbig Ae star HD 142527 , which confirm that its circumstellar dust is composed of two separate populations with varying grain sizes . The polarization degree drops rapidly towards faster wavelengths at all positions along our slit except for one position where it reduces again between 2 . 2 and 3 . 8 microns .We interpret this as proof for an inner cavity in the distribution of bigger grains . This interpretation is backed by SED modeling using radiative transfer calculations including scattering off spherical objects .Our results show that the exterior border of the gap exists within 0 . 1 AU of the main star . In addition to the NIR data provided here we also discovered mid - infrared ( MIR ) spectro - polarimetry representing the frequency range 5 - 20 micron .These data indicate no major shift in the polarization degree across the MIR groups implying that there are no strong changes in the optical properties of the dust grains on these scales .",
        "ori-fast-z-score": 1.4342743312012722,
        "water-fast-z-score": 6.527299120066193
    },
    {
        "original_text": "We present an algorithm for unicast and multicast quality-of-service (QoS) routing in the Internet using soft constraint logic programming (SCLP). The proposed approach is based on the concept that each node maintains its own view about the network topology, which may be different than other nodes  views due to link failures or congestion. We use SCLP as our underlying framework because it can naturally represent such inconsistent information among nodes. In addition, we show how to incorporate bandwidth constraints into the SCLP model by introducing new variables representing available bandwidths between two adjacent links. Finally, we propose several algorithms to solve the problem efficiently. Our experimental results demonstrate that the proposed method outperforms existing approaches significantly under various conditions. Keywords: Quality-of-Service, Constraint Logic Programming, Bandwidth Allocation, Network Optimization, Link Failure, Congestion Control, Internet Service Provider, Unicast",
        "watermark_text": "We present an algorithm for unicast and multicast quality - of - service ( QoS ) routing in the Internet employing soft constraint logic programming ( SCLP ) . The proposed approach is based on the idea that each node maintains its own view about the network topology , which may be changed than other nodes views due to link faults or congestion .We use SCLP as our underlying framework because it can naturally represent such inconsistent information among nodes . In addition , we study how to insert bandwidth constraints into the SCLP model by using new parameters representing available bandwidths between two adjacent links .Finally , we present many algorithms to solve the issue quickly . Our research results show that the suggested method outperforms current approaches substantially under various circumstances .Keywords: Quality-of-Service, Constraint Logic Programming, Bandwidth Allocation, Network Optimization, Link Failure, Congestion Control, Internet Service Provider, Unicast",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "The rapid growth in the use and production of digital media has created an urgent need to develop new models that support long-term access, preservation, and reuse of personal archives.  In this article we present a service model for managing personal archives based on three key concepts:  The archive is viewed as a collection of interrelated objects (e.g., documents, photos); each object is associated with one or more services that provide functionality such as storage, editing, sharing, etc.; and these services are organized into a hierarchy reflecting their relationships.   We describe how our approach can be used by individuals to manage their own personal archives, and also discuss its potential application within organizations where large volumes of data must be managed over extended periods of time. The rapid growth in the use of digital media has led to increased interest in developing systems that allow users to preserve and share their personal information across multiple devices and platforms. However, current approaches have focused primarily on providing solutions for storing and accessing content rather than addressing issues related to preserving it over time. This problem becomes particularly acute when dealing with collections containing thousands of items spanning several years. To address this issue, we propose a service-oriented architecture for organizing and maintaining personal archives.",
        "watermark_text": "The rapid increase in the using and production of digital media has established an urgent need to develop new models that enable large - term access , preservation , and reuse of personal libraries . In this page we present a service model for controlling personal libraries using on three key concepts : The archive is viewed as a collection of interrelated artifacts ( e . g . , files , photos ) ; each object is associated with one or more functions that provide functionality such as processing , editing , sharing , etc .; and these services are coordinated into a structure indicating their connections . We illustrate how our approach can be used by individuals to manage their own individual archives , and also discuss its potential application within organizations where vast volumes of records must be managed over longer periods of time .The rapid increase in the using of digital media has led to greater activity in developing systems that enable users to archive and transfer their personal data across multiple computers and platforms . However , current approaches have concentrated mostly on providing strategies for storing and accessing information rather than solving topics related to preserving it over time .This problem appears particularly intense when dealing with libraries containing many of items spanning numerous years . To address this question , we propose a service - based architecture for storing and keeping personal records .",
        "ori-fast-z-score": 0.7126966450997984,
        "water-fast-z-score": 9.698686309445845
    },
    {
        "original_text": "We propose an encoding scheme for layered associative network (LAN) of spiking neurons, which is based on sparse coding and dense coding. The proposed method can be used to learn the association between input patterns and output patterns by using unsupervised learning algorithms such as Hebbian learning rule or spike-timing-dependent plasticity (STDP). We show that our model has better performance than conventional LANs with respect to both storage capacity and retrieval accuracy. In addition, we demonstrate that our model can perform pattern completion task without any additional training data. \nIndex Terms-Layered associaton network, Sparse coding, Dense coding, Pattern completion, STDP, Unsupervised learning algorithm. 1 Introduction Recently, there have been many studies about artificial neural networks  1  . Among them, layered associative network (L AN )  2  , which consists of multiple layers of neurons connected through synapses, has attracted much attention because it shows high storage capacity and good retrieval accuracy  3  .\nIn L AN s, each neuron receives inputs from all neurons in previous layer via synaptic connections. Then, the activity level of each neuron is determined by its firing rate according to the following equation: \nwhere x i denotes the activity level of ith neuron at time t, w ij represents connection weight from jth neuron in previous layer to ith neuron in current layer, f(·) stands for activation function, and b i indicates bias term  4  . Since the number of possible combinations of activities among neurons increases exponentially when the number of neurons becomes large, storing information in L AN requires huge amount of memory space  5  . To overcome this problem, several approaches have been suggested  6  -  8  . For example, sparseness constraint was introduced into L AN so that only small fraction of neurons are active simultaneously  9  . However, these methods require supervised learning algorithms to train parameters of L AN , which makes their applications limited  10  .",
        "watermark_text": "We suggest an encoding scheme for layered associative network ( LAN ) of spiking neurons , which is based on sparse coding and thin code . The proposed approach can be used to study the relationship between output patterns and input patterns by using unsupervised learning techniques such as Hebbian learning rule or spike - timing - based plasticity ( STDP ) .We suggest that our model has good efficiency than conventional LANs with regard to both storage capacity and retrieval quality . In addition , we prove that our model can conduct pattern completion process without any additional testing information .Index Terms - Layered associaton system , Sparse codes , Dense coding , Pattern completion , STDP , Unsupervised learning scheme . 1 Introduction Recently , there have been many research about artificial neural systems 1 .Among them , layered associative network ( L AN ) 2 , which consists of multiple strands of neurons connected through synapses , has gained great concern because it displays large storage capacity and good retrieval quality 3 . In L AN s , each neuron receives inputs from all neurons in preceding layer via synaptic connections .Then , the activity rate of each neuron is calculated by its fire rate due to the following equation : where h i denotes the activity rate of ith neuron at time t , w ij represents connection weight from jth neuron in earlier layer to ith neuron in current layer , f ( · ) stands for activation function , and g i denotes bias term 4 . Since the number of possible combinations of activities among neurons increases exponentially when the number of neurons becomes large , encoding information in L AN demands huge amount of memory space 5 .To solve this question , various approaches have been proposed 6 - 8 . For instance , sparseness constraint was introduced into L AN so that only tiny fraction of neurons are active simultaneously 9 .However , these algorithms involve supervised learning techniques to train parameters of L AN , which makes their users limited 10 .",
        "ori-fast-z-score": -0.16329931618554522,
        "water-fast-z-score": 8.597735319930415
    },
    {
        "original_text": "The authors report on their experience with immunohistochemistry (IHC) for insulin degrading enzyme (IDE). They found that IDE is expressed by many cell types, including epithelial cells lining ducts or glands, endothelial cells, smooth muscle cells, fibroblasts, adipocytes, neurons, glial cells, astrocytes, oligodendroglia, microglia, Schwann cells, chondrocytes, osteoblasts, myofibroblasts, mesothelial cells, macrophages, lymphocytes, mast cells, neutrophils, eosinophils, basophils, megakaryocytes, erythroid precursors, platelets, monocytes/macrophages, dendritic cells, natural killer cells, B-cells, T-cells, plasma cells, granulocytes, megakaryocytes/platelets, and bone marrow stromal cells. The authors also describe several IHC pitfalls associated with this antigen.",
        "watermark_text": "The authors report on their experience with immunohistochemistry ( IHC ) for insulin degrading enzyme ( IDE ) . They found that IDE is expressed by many cell kinds , notably epithelial cells lining ducts or glands , endothelial cells , soft muscle cells , fibroblasts , adipocytes , cortex , glial cells , astrocytes , oligodendroglia , microglia , Schwann cells , chondrocytes , osteoblasts , myofibroblasts , mesothelial cells , macrophages , lymphocytes , mast cells , neutrophils , eosinophils , basophils , megakaryocytes , erythroid precursors , platelets , monocytes / macrophages , dendritic cells , natural killer cells , B - cells , T - cells , plasma cells , granulocytes , megakaryocytes / platelets , and skin marrow stromal cells .The authors additionally describe several IHC pitfalls associated with this antigen .",
        "ori-fast-z-score": 2.0816659994661326,
        "water-fast-z-score": 3.893314107138301
    },
    {
        "original_text": "We present exact solutions for the electromagnetic field in the presence of spherical particles with arbitrary dielectric functions, including both metals and insulators. We show that these results can be obtained by solving Maxwell s equations using an appropriate Green function approach. The resulting expressions are used to calculate the dispersion relations for surface plasmons (SPs) and surface phonons (SPhPs). In particular we find that SPs exist only when the real part of the dielectric constant is negative while SPhPs exist even if it has positive values. Finally, we compare our results against those obtained within the classical Drude model and discuss their validity limits. Surface plasmons (SPs), which are collective oscillations of conduction electrons at metal-dielectric interfaces, have been extensively studied over many decades  1  . They play important roles in various fields such as optics  2  , electronics  3  , sensing  4  , and catalysis  5  .\nRecently there has also been growing interest in studying surface phonon-polaritons (SPhPs), which are analogous excitations associated with longitudinal acoustic waves  6  . These modes occur not only at surfaces but also inside bulk materials  7, 8  where they may lead to enhanced thermal transport  9  or thermoelectricity  10  . Moreover, SPhPs can couple strongly to light  11  leading to interesting phenomena like superprism  12  and extraordinary transmission  13  effects.",
        "watermark_text": "We present precise solutions for the electromagnetic field in the presence of spherical objects with arbitrary dielectric functions , including both metals and insulators . We see that these results can be obtained by treating Maxwell s equations using an appropriate Green function method .The resulting expressions are using to estimate the dispersion relations for surface plasmons ( SPs ) and surface phonons ( SPhPs ) . In particular we find that SPs occur only when the real part of the dielectric constant is zero while SPhPs exist even if it has negative values .Finally , we compare our findings against those achieved within the classical Drude theory and consider their efficacy limits . Surface plasmons ( SPs ) , which are collective oscillations of conduction electrons at metal - dielectric connections , have been heavily explored over numerous years 1 .They play essential roles in different fields such as optics 2 , electronics 3 , sensing 4 , and catalysis 5 . Recently there has especially been growing interest in investigating surface phonon - polaritons ( SPhPs ) , which are analogous excitations associated with longitudinal acoustic waves 6 .These modes happen not only at surfaces but also inside bulk surfaces 7 , 8 where they may contribute to heightened thermal transport 9 or thermoelectricity 10 . Moreover , SPhPs can close intensely to light 11 contributing to curious phenomena like superprism 12 and exceptional transmission 13 phenomena .",
        "ori-fast-z-score": -0.8164965809277261,
        "water-fast-z-score": 6.25846794771944
    },
    {
        "original_text": "We present new results for the ratio between the core radius rc and the half-light radius r h of open star clusters, based on high-resolution HST imaging data obtained with the Advanced Camera for Surveys (ACS). We find that this ratio is systematically larger than previously reported values by about 0.2 dex. This discrepancy can be explained if we assume that some of these clusters contain an intermediate mass black hole at their center. The presence of such objects would lead to smaller observed values of rc/r h . Our findings are consistent with previous studies which have suggested that many open clusters may harbor IMBHs. In addition, our results provide further evidence against the hypothesis that all open clusters host central massive stars. \n \n Keywords: Open Star Cluster; Core Radius; Half-Mass Radius; Black Hole; Intermediate Mass Black Hole; ACS/HRC FOV; Galaxy",
        "watermark_text": "We publish new data for the proportion between the core radius rc and the half - light diameter r h of open star clusters , using on wide - resolution HST scanning data derived with the Advanced Camera for Surveys ( ACS ) . We see that this ratio is systematically larger than previously reported values by about 0 . 2 dex .This discrepancy can be described if we suppose that some of these clusters hold an intermediate mass black hole at their core . The presence of such objects would result to smaller observed values of rc / r h .Our findings are compatible with previous research which have suggested that several open nuclei may harbor IMBHs . In addition , our findings provide further evidence against the notion that all open complexes host central large objects .Keywords: Open Star Cluster; Core Radius; Half-Mass Radius; Black Hole; Intermediate Mass Black Hole; ACS/HRC FOV; Galaxy",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 5.662208585049306
    },
    {
        "original_text": "The Peierls-Nabarro model is used to study the dislocations dynamics in a crystal lattice, where the energy barrier for glide motion and climb motion are calculated by using the concept of activation volume. The results show that the energy barriers increase with increasing applied stress. It also shows that the energy barrier decreases as temperature increases. Finally it can be concluded that the Peierls-Nabarre model gives good agreement between theory and experimentation. Keywords: Energy Barrier, Dislocation, Glide Motion, Climb Motion, Activation Volume, Peierls-Nabarrou Model. 1 Introduction In this research work we have studied the dislocation dynamics in a crystal lattice which has been done by using the Peierls-Nabbarro model  1  . This model was developed by Peierls  2  , who introduced an elastic strain field into the Frenkel-Kontorova model  3  .\nIn order to calculate the energy barrier for gliding motion and climbing motion, we use the concept of activation volume  4  . We find out how the energy barrier changes when different values of stresses are applied on the system. Also we found out how the energy barrier varies at different temperatures. Finally we compare our theoretical results with experimental data  5  -  8  .",
        "watermark_text": "The Peierls - Nabarro theory is utilized to study the dislocations dynamics in a crystal lattice , where the power barrier for glide movement and ascent movement are measured by using the idea of activation volume . The results show that the electricity obstacles increase with increasing applied strain .It thus suggests that the electricity barrier decreases as temperature increases . Finally it can be realized that the Peierls - Nabarre hypothesis offers excellent agreement between theoretical and experimentation .Keywords : Energy Barrier , Dislocation , Glide Motion , Climb Motion , Activation Volume , Peierls - Nabarrou Model . 1 Introduction In this research effort we have researched the dislocation behavior in a crystal lattice which has been performed by using the Peierls - Nabbarro model 1 .This theory was developed by Peierls 2 , who applied an elastic strain field into the Frenkel - Kontorova model 3 . In order to estimate the power barrier for gliding motion and climbing movement , we utilize the idea of activation volume 4 .We work out how the power barrier changes when varying expressions of stresses are applied on the system . Also we learned out how the power barrier changes at different temperatures .Finally we compare our theory findings with experimental evidence 5 - 8 .",
        "ori-fast-z-score": -0.5241424183609592,
        "water-fast-z-score": 6.81385143869247
    },
    {
        "original_text": "The new reactor is based on the principle that nuclear fusion can be achieved by heating plasma to high temperatures in magnetic fields.  The proposed design uses an array of magnets and electrodes, which are powered by microwave generators, to heat hydrogen gas into plasma at 100 million degrees Celsius (1,000,000 K). This temperature is sufficient to cause nuclear fusion reactions between deuterium nuclei inside the plasma. In this way, energy is released as neutrons and gamma rays. These particles then bombard fuel pellets made up of tritium and lithium-6, causing them to release more energy through further nuclear fusion reactions. The resulting power plant would produce electrical power with no moving parts or radioactive waste products. It could also provide propulsion systems for spacecraft without requiring any chemical fuels. A conceptual drawing of the reactor system is shown below. Nuclear fusion has been studied extensively since its discovery over 50 years ago. However, it remains elusive because the conditions required to achieve fusion are extremely difficult to create experimentally.",
        "watermark_text": "The modern reactor is based on the principle that fusion fusion can be obtained by burning plasma to large conditions in magnetic fields . The proposed design uses an array of magnets and electrodes , which are powered by microwave generators , to heat hydrogen energy into plasma at 100 million degrees Celsius ( 1 , 000 , 000 K ) .This temperature is adequate to create nuclear fusion events between deuterium nuclei inside the plasma . In this way , electricity is released as neutrons and alpha rays .These particles then bombard fuel pellets made up of tritium and lithium - 6 , forcing them to release more electricity through further nuclear fusion compounds . The resulting electricity plant would create electrical power with no moving parts or radioactive waste products .It could also supply propulsion services for spacecraft without using any chemical engines . A conceptual drawing of the reactor system is displayed below .Nuclear fusion has been studied thoroughly since its observation over 50 centuries earlier . However , it remains elusive because the conditions required to achieve fusion are extremely difficult to create experimentally .",
        "ori-fast-z-score": 1.2792042981336627,
        "water-fast-z-score": 6.396021490668312
    },
    {
        "original_text": "We propose that the prompt emission of gamma-ray bursts (GRBs) is due to high-energy protons, muons and electron-positron pairs produced by ultra-relativistic shocks in GRB jets. The observed MeV-GeV spectrum can be explained as synchrotron radiation emitted by these particles accelerated at the shock front. We show that this model naturally explains why the peak energy of the observed spectrum decreases with time during the prompt phase. In addition, we find that our model predicts an anti-correlation between the duration of the prompt phase and the luminosity of the afterglow for short-hard GRBs. This prediction could be tested using future observations made by Fermi/LAT and Swift/BAT. Introduction -Gamma-ray bursts are brief flashes of high energy photons lasting only milliseconds or less  1  . They have been detected out to redshifts z = 8.2  2  , which implies their total energy output may exceed 10^53 erg  3  . Despite decades of research into the origin of GRBs there remains no consensus on how they work  4  .\nThe most popular models involve either black holes or neutron stars collapsing into a black hole  5  . However, it has recently become clear that many GRBs do not fit neatly into one category  6  . For example, some GRBs appear to contain two separate pulses  7, 8  while others exhibit extended periods of activity  9  . Furthermore, some GRBs seem to occur when two galaxies merge  10  . These complexities suggest that more than one mechanism might operate simultaneously  11  .\nIn recent years several authors  12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59   have proposed that GRBs are powered by relativistic jets e",
        "watermark_text": "We suggest that the prompt emission of gamma - ray waves ( GRBs ) is due to large - energy protons , muons and electron - positron couples created by ultra - relativistic shocks in GRB jets . The observed MeV - GeV spectrum can be understood as synchrotron rays generated by these ions advancing at the shock back .We see that this model readily explains why the maximum energy of the seen spectrum drops with time during the prompt phase . In addition , we find that our model predicts an counter - correlation between the duration of the prompt phase and the luminosity of the afterglow for short - hard GRBs .This prediction might be evaluated using later observed made by Fermi / LAT and Swift / BAT . Introduction - Gamma - ray bursts are mild flashes of high energy photons lasting only milliseconds or less 1 .They have been detected out to redshifts z = 8 . 2 2 , which implies their total energy efficiency may exceed 10 ^ 53 erg 3 . Despite decades of research into the origin of GRBs there stands no discussion on how they use 4 .The most popular theories include either black holes or neutron galaxies exploding into a black hole 5 . However , it has recently become clear that several GRBs do not fit nicely into one category 6 .For instance , some GRBs occur to contain two separate pulses 7 , 8 while several display extended phases of activity 9 . Furthermore , some GRBs appears to arise when two galaxies merge 10 .These complexities indicate that more than one process may operate simultaneously 11 . In recent years many writers 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 have proposed that GRBs are powered by relativistic jets e",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.184271554937297
    },
    {
        "original_text": "SDSS J121811+465501 is an extremely faint galaxy discovered in the Sloan Digital Sky Survey (SDSS). It has been classified as a dwarf elliptical galaxy, but its surface brightness profile shows that it is actually a very extended and diffuse object. We have obtained deep optical spectroscopy for this galaxy using the Gemini Multi-Object Spectrograph on Gemini North telescope to study its physical properties. The spectrum reveals strong Balmer absorption lines indicating young stellar populations. Its oxygen abundance is found to be one third solar or lower, which makes SDSS J121811+ 465501 the lowest-metallicity galaxy known at z=0.1. This galaxy may represent a population of galaxies formed early during cosmic time when star formation was more intense than today. Keywords: Dwarf Elliptical Galaxy, Oxygen Abundance, Gemini Observatory, Sloan Digital Sky Survey, Low Surface Brightness",
        "watermark_text": "SDSS J121811 + 465501 is an incredibly faint galaxy discovered in the Sloan Digital Sky Survey ( SDSS ) . It has been classified as a dwarf elliptical galaxy , but its surface brightness profile reveals that it is actually a very extended and diffuse object .We have achieved dark optical spectroscopy for this galaxy using the Gemini Multi - Object Spectrograph on Gemini North telescope to study its physical properties . The spectrum reveals large Balmer spectral lines suggesting young stellar regions .Its oxygen abundance is found to be one third solar or smaller , which makes SDSS J121811 + 465501 the smallest - metallicity galaxy known at z = 0 . 1 . This galaxy might represent a population of galaxies formed early during cosmic time when galaxy formation was more intense than tomorrow .Keywords: Dwarf Elliptical Galaxy, Oxygen Abundance, Gemini Observatory, Sloan Digital Sky Survey, Low Surface Brightness",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 4.810702354423639
    },
    {
        "original_text": "The effect of cooling rate on martensitic transformation temperature (Mf) was investigated for Ni$_{50}$ Mn$_{34}$ In$_{16}$ alloy using differential scanning calorimetry (DSC). The results show that Mf decreases with increasing cooling rates, which is attributed to the increase in nucleation sites at higher cooling rates. A comparison between DSC data obtained under different conditions shows that the presence of stress during cooling has no significant influence on the value of Mf. However, it does affect the microstructure of the material as revealed by transmission electron microscopy (TEM), where the formation of dislocations can be observed when samples are cooled down without applying any external pressure. It also affects the mechanical properties such as yield strength and ultimate tensile strength. \n \n © 2014 Elsevier B.V. \nKeywords: Magnetic shape memory alloys; Cooling rate; Martensitic transformation",
        "watermark_text": "The impact of cooling rate on martensitic transformation temperature ( Mf ) was investigated for Ni $ _ { 50 } $ Mn $ _ { 34 } $ In $ _ { 16 } $ alloy utilizing differential scanning calorimetry ( DSC ) . The results show that Mf falls with higher cooling rates , which is attributed to the improvement in nucleation sites at higher cooling rates .A comparison between DSC data derived under various circumstances reveals that the presence of stress during cooling has no important affect on the value of Mf . However , it does affect the microstructure of the material as revealed by transmission electron microscopy ( TEM ) , where the formation of dislocations can be observed when samples are heated down without applying any external stress .It additionally impacts the structural properties such as yield strength and absolute tensile strength . © 2014 Elsevier B . V . Keywords : Magnetic shape memory alloys ; Cooling rate ; Martensitic transformation",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 3.6765801200722312
    },
    {
        "original_text": "We study the effect of Coulomb gauge fixing on the gluon propagator in Landau gauge, using lattice simulations with two different actions for SU(2) Yang-Mills theory. We find that the inclusion of Gribov copies leads to an increase in the infrared strength of the gluon propagator; this is consistent with earlier results obtained by other groups. \n \n In addition we show how the presence of Gribov copies affects the static quark-antiquark potential at large distances. The latter quantity can be extracted from the correlation function of Polyakov loops which are defined as closed lines winding around the periodic spatial directions of the lattice. This allows us to compare our results directly with those obtained previously within perturbation theory. Our findings suggest that the perturbative approach breaks down when one considers the full non-perturbative effects associated with Gribov copies. Finally, we discuss possible implications of these results for phenomenological studies of QCD.",
        "watermark_text": "We research the impact of Coulomb gauge fixing on the gluon propagator in Landau gauge , using crystal simulations with two different actions for SU ( 2 ) Yang - Mills theory . We see that the introduction of Gribov copies results to an increase in the infrared thickness of the gluon propagator ; this is compatible with previous findings obtained by other groups .In addition we study how the presence of Gribov copies impacts the static quark - antiquark potential at large distances . The latter quantity can be extracted from the relationship function of Polyakov loops which are defined as closed lines wound around the periodic spatial directions of the crystal .This enables us to relate our findings directly with those achieved previously within perturbation theory . Our findings show that the perturbative methodology cracks down when one considers the full non - perturbative properties associated with Gribov copies .Finally , we explain possible possibilities of these results for phenomenological investigations of QCD .",
        "ori-fast-z-score": -1.3438638879193574,
        "water-fast-z-score": 5.0089472186085136
    },
    {
        "original_text": "We present scaling laws that govern the performance and design trade-offs in all-optical soliton pulse compressors based on cascading quadratic nonlinearities, such as self-phase modulation (SPM) followed by cross-phase modulation (XPM). We show how these devices can be designed to operate at high repetition rates with low loss while maintaining their ability to produce compressed pulses. The results are derived analytically using perturbation theory and confirmed numerically through simulations. Our analysis shows that the maximum achievable peak power is limited primarily by SPM-induced spectral broadening; however, this limit may be overcome if XPM is used to compensate for the increased bandwidth associated with higher-order dispersion effects. In addition, we find that the minimum required length scales inversely proportional to the square root of the input pulse energy. Finally, our results indicate that the optimal operating conditions depend strongly on the desired output parameters. \n \n © 2009 Optical Society",
        "watermark_text": "We present scaling principles that govern the performance and engineering trade - offs in all - optical soliton pulse compressors based on cascading quadratic nonlinearities , such as self - phase modulation ( SPM ) preceded by inter - phase modulation ( XPM ) . We see how these machines can be designed to run at high repetition rates with little loss while maintaining their ability to produce compressed signals .The results are derived analytically using perturbation theory and reported numerically through simulations . Our study shows that the maximum achievable peak power is limited primarily by SPM - caused spectral broadening ; however , this limit might be overcome if XPM is utilized to compensate for the increased frequencies associated with higher - order dispersion patterns .In addition , we find that the minimum needed duration scales inversely proportional to the square root of the input pulse power . Finally , our findings show that the ideal operating circumstances rely highly on the desired output parameters .© 2009 Optical Society",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 5.512930714537517
    },
    {
        "original_text": "The magnetic reconnection is one of the most important processes for understanding many phenomena observed in space and laboratory plasmas, such as solar flares, magnetospheric substorms, sawtooth crashes in tokamaks etc.. In this work we present an analytical model which describes the process of magnetic reconnection in collisionless high energy plasma with arbitrary initial conditions. The main idea behind our approach consists in using the concept of generalized force density tensor (GDFT) introduced by MHD theory. We show that GDFT can be used not only to describe the macroscopic dynamics but also microscopic properties of the system like particle distribution functions. Our results are compared with those obtained within other approaches based on kinetic description of particles motion. It turns out that all these models give similar predictions when applied to simple cases where the initial state has no gradients along the direction perpendicular to the background magnetic field. However, if there exist some gradients across the magnetic field lines then different models predict quite different behavior.",
        "watermark_text": "The magnetic reconnection is one of the most important processes for studying many phenomena observed in space and lab plasmas , such as sun flares , magnetospheric substorms , sawtooth crashes in tokamaks etc . . In this research we present an analytical theory which explains the process of magnetic reconnection in collisionless high energy gas with arbitrary initial conditions .The main idea behind our approach consists in utilizing the notion of generalized force density tensor ( GDFT ) developed by MHD physics . We see that GDFT can be used not only to explain the macroscopic behavior but also microscopic characteristics of the process like particle distribution functions .Our results are compared with those achieved within other methods based on kinetic representation of particles movement . It turns out that all these models make comparable predictions when applied to simple instances where the first state has no gradients along the direction perpendicular to the background magnetic force .However , if there exist some gradients across the magnetic force lines then various models predict quite different properties .",
        "ori-fast-z-score": -0.7777777777777778,
        "water-fast-z-score": 5.74243935589202
    },
    {
        "original_text": "We report on kinetic-ion simulations addressing whether ion trapping inflates stimulated Brillouin backscattering (SBS) reflectivities in the presence of an electron beam and plasma waves. We find that, for typical parameters relevant to high-power laser-plasma experiments, SBS is dominated by electrostatic Langmuir wave instabilities rather than ion-acoustic modes. The latter are suppressed due to Landau damping as well as mode conversion into electromagnetic radiation at oblique angles with respect to the direction of propagation. In addition, we show that the effect of ion trapping can be neglected if the density fluctuations associated with the trapped ions are small compared to those caused by the electrons. Finally, we demonstrate that the inclusion of ion trapping does not significantly affect the growth rates or saturation levels of the dominant electrostatic Langmuir waves. This finding suggests that the observed discrepancies between theory predictions and experimental results may originate from other effects such as nonlocality and/or nonlinear coupling among different types of waves.",
        "watermark_text": "We report on kinetic - ion simulations addressing whether electron capture inflates stimulated Brillouin backscattering ( SBS ) reflectivities in the presence of an electron beam and plasma beams . We see that , for typical values appropriate to large - speed laser - plasma experiments , SBS is dominated by electrostatic Langmuir beam instabilities rather than ion - sound modes .The latter are suppressed due to Landau damping as well as mode conversion into electromagnetic radiation at oblique angles with regard to the direction of propagation . In addition , we prove that the impact of ion traps can be forgotten if the density fluctuations associated with the captured atoms are small relative to those generated by the electrons .Finally , we prove that the introduction of ion traps does not dramatically impact the development rates or saturation levels of the dominant electrostatic Langmuir waves . This conclusion suggests that the reported discrepancies between theoretical estimates and theoretical results may originate from other effects such as nonlocality and / or nonlinear coupling among different kinds of waves .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.0201176116964925
    },
    {
        "original_text": "We present an approach for quantifying how much evolutionary history is likely to be lost if we lose particular species, and use this information to prioritize conservation efforts. We show that by considering both taxonomic and phylogenetic diversity simultaneously in conservation planning, it may be possible to conserve more biodiversity than would otherwise be achieved with either measure alone. \n \n The loss of any single species represents not only its own extinction but also the loss of all unique genetic variation within that lineage. This can have important consequences on ecosystem function as well as other aspects of biodiversity such as taxonomy or community composition. However, there are many ways to define what constitutes  biodiversity , each emphasizing different components of biological systems. In order to effectively protect biodiversity, it will therefore be necessary to consider multiple measures together rather than focusing solely on one aspect at a time. \n \n Here we propose a new method for measuring the amount of evolutionary history represented by a set of taxa (e.g., species) based on their relationships inferred using molecular data. Our approach uses the concept of  evolutionary distinctiveness  - which describes the uniqueness of each taxon relative to others in terms of shared evolutionary history - to calculate the expected contribution of individual species to overall phylogenetic diversity. By combining these values into a single index, we obtain a quantitative ranking of species according to their importance for preserving evolutionary history across a given taxonomic group. Using simulated datasets, we demonstrate that our proposed metric performs better than existing methods when used to identify key species for conserving phylogenetic diversity. Finally, we apply our method to assess the vulnerability of amphibian species to climate change impacts.",
        "watermark_text": "We present an perspective for quantifying how many evolutionary history is probably to be lost if we lose particular populations , and use this data to prioritize protection strategies . We suggest that by examining both taxonomic and evolutionary diversity simultaneously in conservation plan , it could be possible to conserve more biodiversity than would normally be achieved with either measure alone .The losing of any single species represents not only its own extinction but also the losing of all unique genetic variation within that lineage . This can have important implications on ecosystem function as well as other parts of ecosystems such as taxonomy or community structure .However , there are many ways to define what creates biodiversity , each emphasizing different components of biological functions . In order to effectively protect biodiversity , it will consequently be required to consider multiple measures together rather than focusing solely on one element at a time .Here we investigate a new method for calculation the extent of evolutionary history displayed by a setting of taxa ( e . g . , species ) based on their connections inferred using molecular data . Our concept employs the notion of evolutionary distinctiveness - which explains the uniqueness of each taxon relative to others in terms of shared evolutionary history - to estimate the expected impact of individual species to overall evolutionary diversity .By combining these values into a single index , we obtain a empirical ranking of taxa according to their importance for preserving phylogenetic evolution across a given taxonomic group . Using simulated datasets , we prove that our proposed measure works better than existing techniques when utilized to identify key taxa for conserving evolutionary evolution .Finally , we apply our technique to analyze the vulnerability of amphibian species to climate impact effects .",
        "ori-fast-z-score": -0.40961596025952024,
        "water-fast-z-score": 8.21926343358871
    },
    {
        "original_text": "We report on the observation of giant magnetoresistance (GMR) effect in Ni80Fe20/Nb/Ni80Fe20 magnetic tunnel junctions with an ultrathin Nb spacer layer, which is as thin as 1 nm and 2 nm respectively. The GMR ratio can reach up to ~80% at room temperature for both samples. We propose that this large GMR effect originates mainly from spin dependent scattering between two adjacent ferromagnetic layers through the stray fields generated by one ferromagnet into another. This work may provide new insights into understanding the physics behind the spin-dependent transport properties in magnetic tunnel junctions. \n \n Magnetic tunnel junction (MTJ), consisting of two ferromagnets separated by a very thin insulating barrier, has been widely studied due to its potential applications in high density nonvolatile memories  1  . In recent years, MTJs have attracted much attention because they are promising candidates for next generation spintronic devices such as read heads  2  , microwave oscillators  3  , logic circuits  4  , etc.. However, there still exist some problems preventing their practical application, e.g., low thermal stability  5  , poor reproducibility  6  , and relatively small magnetoresistive effects  7, 8  .\nRecently, it was found that the interlayer exchange coupling plays an important role in determining the magnetization reversal process  9  . It also affects the spin-dependent transport behavior significantly  10  . Therefore, many efforts have been made to enhance the interlayer exchange coupling strength  11  -  13  . For example, using CoFeB/MgO/CoFeB structure instead of conventional FeCo/AlOx/FeCo structure could greatly increase the interlayer exchange coupling  14  . Moreover, inserting a non-magnetic metal layer like Cu or Ag between two ferromagnetic layers would lead to stronger interlayer exchange coupling  15  . On the other hand, inserting a non-magnetically conducting material like SiO2  16  or Al2O3  17  between two ferromagnetic layers will decrease the interlayer exchange coupling.",
        "watermark_text": "We report on the observation of giant magnetoresistance ( GMR ) effect in Ni80Fe20 / Nb / Ni80Fe20 magnetic tunnel junctions with an ultrathin Nb spacer coating , which is as thin as 1 nm and 2 nm respectively . The GMR ratio can reach up to ~ 80 % at room temperature for both samples .We suggest that this big GMR impact originates mainly from spinning dependent scattering between two adjacent ferromagnetic layers through the stray fields generated by one ferromagnet into another . This research could give novel knowledge into studying the physics behind the spin - dependent transport properties in magnetic tunnel junctions .Magnetic tunnel junction ( MTJ ) , consisting of two ferromagnets connected by a very thin insulating barrier , has been widely explored thanks to its potential applications in high density nonvolatile memories 1 . In recent seasons , MTJs have garnered many scrutiny because they are promising candidates for next generation spintronic systems such as read heads 2 , infrared oscillators 3 , logic devices 4 , etc . .However , there still exist some problems preventing their practical use , e . g . , low heat strength 5 , poor reproducibility 6 , and fairly little magnetoresistive factors 7 , 8 . Recently , it was shown that the interlayer exchange coupling plays an important role in determining the magnetization reversal process 9 .It additionally impacts the spin - based transport behavior dramatically 10 . Therefore , various efforts have been performed to alter the interlayer exchange bonding strength 11 - 13 .For instance , using CoFeB / MgO / CoFeB structure instead of standard FeCo / AlOx / FeCo structure could greatly increase the interlayer exchange bonding 14 . Moreover , inserting a non - magnetic metal layer like Cu or Ag between two ferromagnetic layers would result to heavier interlayer exchange bonding 15 .On the other hand , inserting a non - magnetically conducting substance like SiO2 16 or Al2O3 17 between two ferromagnetic layers will decrease the interlayer exchange bonding .",
        "ori-fast-z-score": 0.0842151921066519,
        "water-fast-z-score": 6.1477090237855885
    },
    {
        "original_text": "We study the nonlinear perturbations of general relativity (GR) and other metric theories of gravity, focusing on their effects on conserved quantities such as energy-momentum tensors. We show that these perturbations can be decomposed into two parts: one is associated with the background geometry while another is related to the perturbation itself. In particular, we find that for any given background solution there exists an infinite number of solutions corresponding to different values of the conserved quantity. This implies that the conservation laws are not preserved under small perturbations. Furthermore, we demonstrate how this effect may lead to violations of the weak equivalence principle. Finally, we discuss possible implications of our results for cosmology and black hole physics. General relativity (GR), which describes gravitational interactions at large scales, has been tested extensively against observations over many decades  1  . However, it remains unclear whether or not GR also holds true at smaller length scales where quantum mechanics becomes important  2  .\nIn order to address this question, several alternative theories have been proposed  3  , including scalar-tensor theories  4  , f(R)-gravity  5  , massive gravity  6  , and so forth  7, 8  . These theories typically involve additional degrees of freedom beyond those present in GR  9  . For example, in scalar-tensor theories, the graviton acquires a mass through its coupling to a scalar field  10  . Similarly, in f(R)-theories  11  , the Einstein-Hilbert action contains higher-order curvature terms  12  . It turns out that both types of theories admit self-accelerating solutions  13  , i.e., de Sitter-like solutions without requiring dark energy  14  .",
        "watermark_text": "We research the nonlinear perturbations of general relativity ( GR ) and other metric explanations of gravitational , concentrating on their impacts on conserved parameters such as energy - momentum tensors . We see that these perturbations can be decomposed into two parts : one is associated with the background geometry while another is related to the perturbation itself .In particular , we find that for any given background solution there exists an endless number of solutions associated to different values of the conserved quantity . This implies that the conservation laws are not preserved under small perturbations .Furthermore , we explain how this effect could lead to infringement of the weak equivalence principle . Finally , we explain possible possibilities of our findings for cosmology and dark hole physics .General relativity ( GR ) , which explains gravitational interactions at large scales , has been tested extensively against measurements over numerous centuries 1 . However , it remains unsure whether or not GR still holds true at greater size scales where quantum mechanics becomes crucial 2 .In order to meet this question , various alternative theories have been proposed 3 , notably scalar - vector models 4 , f ( R ) - gravity 5 , giant gravity 6 , and so forth 7 , 8 . These explanations typically involve additional degrees of autonomy beyond those present in GR 9 .For instance , in scalar - vector theories , the graviton acquires a mass through its interaction to a scalar field 10 . Similarly , in g ( R ) - fields 11 , the Einstein - Hilbert action contains upper - order curvature terms 12 .It turns out that both types of theories admit self - accelerating problems 13 , i . e . , de Sitter - like solutions without using dark energy 14 .",
        "ori-fast-z-score": -1.4485719366802965,
        "water-fast-z-score": 6.454545454545454
    },
    {
        "original_text": "The article presents an analysis of Mykyta s network, which is one of the largest Russian-language social media communities in Ukraine. The author describes how this community was formed; its main characteristics are also analyzed. It has been found that the majority of users who create content on Mykyta belong to the age group 18-24 years old (more than 80%). In addition, it has been established that most members of the community have higher education (over 50%), live in large cities with more than 100 thousand inhabitants (about 70%) and work as specialists or managers (about 60%).\nIt should be noted that the study does not cover all aspects of the functioning of the community under consideration. For example, there were no attempts made to analyze the relationship between the structure of the community and the quality of user-generated content. This issue will require further research. Keywords: Social media, online communication, sociolinguistics",
        "watermark_text": "The essay presents an assessment of Mykyta s network , which is one of the largest Russian - language social media communities in Ukraine . The author explains how this community was formed ; its primary characteristics are also analyzed .It has been shown that the majority of viewers who generate text on Mykyta come to the age band 18 - 24 days old ( more than 80 % ) . In addition , it has been noted that most citizens of the public have higher education ( over 50 % ) , live in large cities with more than 100 thousand inhabitants ( about 70 % ) and work as experts or executives ( about 60 % ) .It should be mentioned that the study does not include all aspects of the functioning of the neighborhood under consideration . For instance , there were no attempts made to analyze the relationship between the composition of the neighborhood and the quality of customer - produced content .This problem will demand further studies . Keywords : Social media , internet communication , sociolinguistics",
        "ori-fast-z-score": -0.7385489458759964,
        "water-fast-z-score": 5.908391567007971
    },
    {
        "original_text": "We present the results of an analysis of magnetic field evolution, temperature variation, and plasma flow velocity observed by Hinode/SOT/SP (Solar Optical Telescope Spectro-Polarimeter) on September 24-25, 2007 during solar minimum period. The active region NOAA 10930 was located at S19E09 when it produced two flares with GOES class M5.7 and M1.0 respectively. We found that there were significant changes in the photospheric magnetic fields before and after these flares. In particular, we detected a new flux emergence event which occurred about one hour prior to the first flare. This newly emerged flux led to the formation of a coronal hole overlying the active region. After the second flare, the polarity inversion line moved toward the center of the active region where the strongest magnetic shear existed. During this time interval, we also found a rapid decrease in the intensity of the Fe xxi emission lines near the footpoints of the loops connecting opposite-polarities. These observations suggest that the energy released by the flares may have caused heating of the loop-top regions as well as evaporation of chromospheric material into the corona along the reconnected loops.",
        "watermark_text": "We present the conclusion of an assessment of magnetic field evolution , temperature variation , and plasma circulation velocity observed by Hinode / SOT / SP ( Solar Optical Telescope Spectro - Polarimeter ) on September 24 - 25 , 2007 during solar low time . The active region NOAA 10930 was positioned at S19E09 when it produced two flares with GOES class M5 . 7 and M1 . 0 respectively .We determined that there were substantial alterations in the photospheric magnetic fields before and after these flares . In particular , we identified a new flux emergence phenomenon which occurred about one hour prior to the first flare .This newly emerged flux led to the formation of a coronal hole overlying the active region . After the second flare , the polarity inversion line moved toward the center of the active region where the greatest magnetic shear existed .During this time interval , we also discovered a rapid decrease in the frequency of the Fe xxi emission lines near the footpoints of the loops connecting opposite - polarities . These measurements suggest that the electricity emitted by the flares might have caused heating of the loop - top regions as also as evaporation of chromospheric matter into the corona along the reconnected loops .",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 4.777777777777778
    },
    {
        "original_text": "We present optical (BVRI), near infrared (JHK) and mid-infrared (IRAC 3.6-8.0 micron; MIPS 24 micron) photometry for the known population of low-mass stars and brown dwarfs in the open star forming region Sigma Orionis. We use these data to derive spectral types and bolometric luminosities for all objects with masses below 0.1 solar masses. The resulting substellar mass function is compared to that derived by previous studies using different techniques. Our results are consistent with those obtained previously but we find evidence for an excess number of very-low mass objects at the faint end of our sample which may be due to unresolved binaries or contamination by background galaxies. This work was supported by NASA grant NAG5-12942. We thank J. Stauffer for providing us with his list of candidate members prior to publication. \n \n Keywords: Open clusters",
        "watermark_text": "We use visual ( BVRI ) , near infrared ( JHK ) and mid - infrared ( IRAC 3 . 6 - 8 . 0 micron ; MIPS 24 micron ) photometry for the known community of lowest - weight stars and dark dwarfs in the open star producing zone Sigma Orionis . We use these information to derive spectral classes and bolometric luminosities for all bodies with masses below 0 . 1 solar masses .The resulting substellar mass distribution is compared to that derived by earlier surveys using different methods . Our results are compatible with those generated previously but we find proof for an excess amount of very - low weight objects at the faint ending of our sample which may be due to unresolved binaries or exposure by background galaxies .This project was supported by NASA loan NAG5 - 12942 . We praise J . Stauffer for providing us with his list of candidate participants previous to publication .Keywords : Open clusters",
        "ori-fast-z-score": -1.75,
        "water-fast-z-score": 4.6615618337804685
    },
    {
        "original_text": "We present deep optical and near-infrared observations of two gamma-ray burst (GRB) host galaxies, which are located behind the Large Magellanic cloud (LMC). The LMC is an ideal laboratory for studying the effects of massive star winds on their surroundings because it contains many young open clusters with ages ranging between 1 Myr to several hundred million years old. We use these data to probe the geometry of the surrounding interstellar medium (ISM), as well as that of the stellar winds produced by the most recent generation of stars within each cluster. In particular we focus our attention on the properties of Wolf Rayet (WR) stars, whose powerful winds can have dramatic effects on their environments over large distances.  By comparing the observed line-of-sight column densities of hydrogen gas towards different clusters at various orientations relative to the plane of the galaxy, we find evidence for significant differences in the structure of the ISM along lines of sight passing through the disk compared to those passing through the halo. This suggests that there may be large-scale variations in the density distribution of the ISM throughout this region of space.",
        "watermark_text": "We present dark optical and near - infrared observations of two gamma - ray burst ( GRB ) host galaxies , which are situated behind the Large Magellanic cluster ( LMC ) . The LMC is an suitable lab for studying the effects of large galaxy winds on their environment because it contains large old closed clusters with ages ranging between 1 Myr to several hundred million days old .We use these information to probe the morphology of the nearby interstellar medium ( ISM ) , as well as that of the stellar winds produced by the most current generation of stars within each cluster . In particular we focus our focus on the properties of Wolf Rayet ( WR ) stars , whose massive winds can have dramatic effects on their habitats over large distances .By comparing the reported line - of - view column densities of hydrogen gas towards different galaxies at several orientations compared to the plane of the galaxy , we find proof for significant variations in the composition of the ISM along tracks of view traveling through the disk compared to those traveling through the halo . This implies that there may be large - scale variations in the density patterns of the ISM throughout this area of space .",
        "ori-fast-z-score": -1.5724272550828775,
        "water-fast-z-score": 5.346252667281783
    },
    {
        "original_text": "We present new near-infrared (NIR) observations of the young stellar cluster IC 1396 N, located in the Orion Nebula Cluster region. The data were obtained with the adaptive optics system NAOS-CONICA on the VLT telescope and cover an area of 0.5 arcmin2 around the central star HD 37022. We detect more than 100 point sources down to Ks = 18 mag within this field-of-view. Using these data we have constructed colour-magnitude diagrams for different areas inside our field-of-view. From these CMDs we find that there are two populations of stars which can be separated by their position in the diagrams: one population is redder and fainter while another has bluer colours and brighter magnitudes. These results suggest that the first group consists mainly of low mass pre-main sequence stars surrounded by circumstellar disks, whereas the second group contains mostly high mass main-sequence stars without any surrounding material.",
        "watermark_text": "We report new near - infrared ( NIR ) observations of the small stellar cluster IC 1396 N , located in the Orion Nebula Cluster region . The data were obtained with the adaptive optics network NAOS - CONICA on the VLT telescope and cover an area of 0 . 5 arcmin2 around the primary star HD 37022 .We detect more than 100 point sources down to Ks = 18 mag within this field - of - view . Using these information we have created colour - magnitude diagrams for different areas inside our field - of - view .From these CMDs we find that there are two communities of stars which can be apart by their placement in the diagrams : one community is redder and fainter while another has bluer colours and darker magnitudes . These data suggest that the first group contains primarily of high mass pre - principal sequence stars surrounded by circumstellar disks , whereas the second set contains primarily low mass primary - sequence stars without any surrounding media .",
        "ori-fast-z-score": 0.12403473458920847,
        "water-fast-z-score": 5.417490779798923
    },
    {
        "original_text": "The nonequilibrium steady states (NESS) of matrix product form are the focus of this work, which is intended to be useful for researchers in computational physics and chemistry who wish to solve problems with such NESSs using numerical methods.  The first part of the article introduces the concept of NESSs as well as some basic properties that they possess. In particular, we show how one can construct an explicit representation of any given NESS by solving a linear system of equations whose coefficient matrices depend on the underlying transition rates between different microstates. We also discuss several important issues related to the construction of these coefficient matrices. The second part of the article presents two examples illustrating our approach. Finally, we provide a detailed discussion about various aspects of the proposed method along with possible extensions. Nonequilibrium steady states (NESs), i.e., time-independent solutions of master equations describing open systems far away from equilibrium, have been studied extensively over the past few decades  1  . They play crucial roles in many areas ranging from statistical mechanics  2  , quantum optics  3  , chemical reaction dynamics  4  , and biophysics  5  .\nIn recent years there has been growing interest in developing efficient algorithms for computing NESs  6  -  8  . This is mainly due to their importance in applications where it may not always be feasible or desirable to obtain exact analytical results  9  -  11  . For example, in molecular dynamics simulations  12  , Monte Carlo sampling techniques  13  , and kinetic Monte Carlo schemes  14  , only approximate values of NESs are available. Moreover, even if the exact solution were known, its direct use would still require significant amount of storage space  15  . Therefore, it becomes necessary to develop fast and accurate numerical methods for calculating NESs  16  -  18  .\nThere exist numerous approaches for numerically approximating NESs  19  -  21  . Among them, the most popular ones include the eigenvector-following algorithm  22  , the power iteration scheme  23  , and the Krylov subspace projection technique  24  . These methods usually involve repeated application of the original master equation until convergence is reached  25  . However, since the number of...",
        "watermark_text": "The nonequilibrium steady states ( NESS ) of matrix product type are the subject of this study , which is intended to be used for researchers in computational physics and chemistry who desire to solve difficulties with such NESSs using numerical methods . The first part of the article describes the idea of NESSs as well as some fundamental properties that they possess .In particular , we explain how one can build an explicit representation of any given NESS by modeling a linear network of equations whose coefficient matrices depend on the underlying transition rates between various microstates . We especially consider many important matters related to the creation of these coefficient matrices .The second part of the article gives two examples illustrating our approach . Finally , we provide a detailed discussion about various parts of the suggested method along with possible extensions .Nonequilibrium steady states ( NESs ) , i . e . , time - based answers of master equations representing open systems close away from equilibrium , have been studied frequently over the previous few years 1 . They play crucial roles in different areas ranging from statistical mechanics 2 , quantum optics 3 , chemical process mechanics 4 , and biophysics 5 .In recent years there has been growing interest in building fast algorithms for processing NESs 6 - 8 . This is mainly owing to their importance in applications where it would not always be impossible or useful to obtain exact analytical results 9 - 11 .For instance , in polymer dynamics simulations 12 , Monte Carlo analysis methods 13 , and dynamic Monte Carlo schemes 14 , only approximate estimates of NESs are available . Moreover , even if the exact solution were known , its immediate application would still demand significant amount of storage space 15 .Therefore , it becomes necessary to develop fast and precise quantitative methods for calculating NESs 16 - 18 . There remain various approaches for numerically approximating NESs 19 - 21 .Among them , the most popular ones include the eigenvector - following procedure 22 , the power iteration scheme 23 , and the Krylov subspace projection procedure 24 . These methods usually include repeated application of the original master equation until convergence is reached 25 .However , since the quantity of . . .",
        "ori-fast-z-score": -0.8315218406202999,
        "water-fast-z-score": 8.390811300804845
    },
    {
        "original_text": "We present an approach to validating the performance of machine-learning algorithms for identifying modules in networks, based on synthetic datasets generated by simulating random walks through known modular structures. We show that this method can be used to identify and rank different types of modules with high accuracy across a range of sizes and densities. The results are robust against noise and missing links. This validation strategy is useful both as a benchmarking tool for comparing competing methods and also as a means of assessing how well existing approaches perform when applied to real-world systems. In recent years there has been growing interest in developing computational tools capable of detecting functional units within complex biological networks such as protein-protein interaction (PPI) or gene regulatory networks  1–3  . These so-called “modules” represent groups of nodes which interact more strongly among themselves than they do with other parts of the system  4  , and may correspond to molecular complexes  5  , signaling pathways  6  , metabolic cycles  7  , or even entire cellular processes  8  .\nThe identification of these modules is important because it provides insight into the organization of the underlying network  9  , and allows us to predict new interactions  10  , detect disease genes  11  , and understand evolutionary relationships  12  . However, despite considerable effort  13–19  , no single algorithm consistently outperforms all others  20  , so researchers have developed a variety of complementary techniques  21–23  .",
        "watermark_text": "We present an way to validating the performance of machine - computing methods for finding modules in networks , using on synthetic datasets generated by simulating random runs through known modular structures . We see that this algorithm can be used to identify and rank different kinds of modules with high sensitivity across a range of sizes and densities .The results are robust against noise and lost connections . This validation methodology is important both as a benchmarking tool for evaluating rival techniques and also as a means of assessing how well existing techniques perform when applied to real - time systems .In past decades there has been growing interest in establishing computational tools capable of detecting functional units within complex biological groups such as protein - gene interaction ( PPI ) or protein regulatory circuits 1 – 3 . These so - called “ modules ” denote groups of nodes which interact more strongly among themselves than they do with other parts of the system 4 , and may correspond to chemical complexes 5 , signaling pathways 6 , metabolic processes 7 , or possibly entire cellular processes 8 .The identity of these modules is important because it gives knowledge into the organization of the underlying network 9 , and allows us to predict new interactions 10 , predict disease genes 11 , and understand evolutionary relationships 12 . However , despite considerable work 13 – 19 , no single method consistently outperforms all others 20 , so researchers have developed a variety of complementary techniques 21 – 23 .",
        "ori-fast-z-score": 0.8908708063747479,
        "water-fast-z-score": 8.139287438099235
    },
    {
        "original_text": "We present new results on the faint-end slope and evolution of the luminosity function (LF) for optically-selected quasars in the redshift range 0.5 < z < 2.2, based on the VIMOS-VLT Deep Survey (VVDS). We use two different methods to estimate the LF parameters at each redshift bin: 1/Vmax method and maximum likelihood fitting technique. Our best-fit values are obtained by combining these two techniques with Monte Carlo simulations. We find that our data is consistent with previous studies within their uncertainties. However we show that there exists an apparent discrepancy between the observed number density of bright quasars and the predictions made using the standard quasar formation model. This may be due to incompleteness effects or biases introduced during the selection process. In addition, we also investigate the dependence of the LF shape on the optical luminosities of quasars.",
        "watermark_text": "We report new data on the faint - end slope and evolution of the luminosity function ( LF ) for optically - selected quasars in the redshift region 0 . 5 < z < 2 . 2 , using on the VIMOS - VLT Deep Survey ( VVDS ) . We use two different methods to estimate the LF variables at each redshift bin : 1 / Vmax method and greatest probability fitting technique .Our best - fitting values are derived by combining these two strategies with Monte Carlo simulations . We see that our information is compatible with previous research within their uncertainties .However we prove that there exists an apparent discrepancy between the expected number density of bright quasars and the assumptions produced using the standard quasar structure model . This might be due to incompleteness effects or biases created during the selection phase .In addition , we also investigate the relationship of the LF formation on the optical luminosities of quasars .",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 6.713171133426189
    },
    {
        "original_text": "We present the results of our analysis of a sample of 25 high-resolution quasar absorption line systems with metallicities ranging between 1/100 and 1/10 solar, selected to have low dust content (i.e., < 0.1 mag extinction at 2200 A). We use these data together with those for another 20 DLAs presented by Pettini et al. (1999) to investigate the chemical enrichment history of DLA galaxies over cosmic time. The main conclusions are as follows: \nThe abundance patterns observed in this sample can be explained if we assume that most of the metals were produced during an early burst of star formation which occurred less than 10 Gyr ago. \n\n\nThis is consistent with previous studies based on smaller samples but it also shows that there may not always be evidence for recent star formation activity even when such activity has been inferred from other indicators. \n\nIn addition, we find no correlation between metallicity and dust content or neutral hydrogen column density.\n\nFinally, we show that the mean value of  Fe/H  measured in DLAs agrees well with the predictions made using simple models of galactic chemical evolution.",
        "watermark_text": "We publish the conclusion of our analysis of a sample of 25 high - resolution quasar absorbed line systems with metallicities ranging between 1 / 100 and 1 / 10 solar , selected to have lowest dust content ( i . e . , < 0 . 1 mag extinction at 2200 A ) . We use these results together with those for another 20 DLAs given by Pettini et al .( 1999 ) to examine the chemical enrichment history of DLA galaxies over cosmic time . The main results are as follows : The concentration trends experienced in this specimen can be described if we suppose that most of the metals were produced during an early burst of galaxy formation which occurred less than 10 Gyr ago .This is consistent with previous analyses based on smaller specimens but it also shows that there may not always be confirmation for recent star formation activity even when such activity has been inferred from other indicators . In addition , we find no correlation between metallicity and dust content or neutral hydrogen column density .Finally , we prove that the mean value of Fe / H measured in DLAs agrees well with the assumptions done using simple theories of galactic material evolution .",
        "ori-fast-z-score": 1.078327732034384,
        "water-fast-z-score": 6.11104144857543
    },
    {
        "original_text": "We present some new results on the monotonicity, stability and construction of central difference schemes for nonlinear systems of hyperbolic conservation laws with nonlocal source terms. We consider two types of source term models: one is the relaxation model in which the source term can be written as an integral over the past history; another is the fractional step method where the source term is treated implicitly by solving a system of ordinary differential equations at each time level. The main idea behind our approach to construct stable numerical methods is based on the concept of entropy conservative fluxes introduced recently by Tadmor et al.. In particular, we show that any scheme constructed using these entropy conservative fluxes will automatically preserve positivity if it satisfies certain conditions. Finally, several examples are presented to illustrate the theoretical results obtained here. Cite this article as: Zhi-Hong Liu, On Monotonicity, Stability, and Construction of Central Schemes for Hyperbolic Conservation Laws With Source Terms, Journal of Computational Physics, Volume 227, Issue 1, 15 January 2008, Pages 1-33",
        "watermark_text": "We see some new results on the monotonicity , stability and formation of central variation schemes for nonlinear systems of hyperbolic conservation laws with nonlocal source terms . We consider two forms of source word models : one is the relaxation model in which the source word can be written as an integral over the present history ; another is the fractional step technique where the source word is treated implicitly by solving a system of simple differential coefficients at each time level .The main idea behind our approach to build stable numerical models is based on the notion of entropy conservative fluxes proposed lately by Tadmor et al . . In particular , we prove that any scheme built using these entropy liberal fluxes will automatically preserve positivity if it satisfies certain conditions .Finally , various instances are presented to illustrate the theoretical results derived here . Cite this page as : Zhi - Hong Liu , On Monotonicity , Stability , and Construction of Central Schemes for Hyperbolic Conservation Laws With Source Terms , Journal of Computational Physics , Volume 227 , Issue 1 , 15 January 2008 , Pages 1 - 33",
        "ori-fast-z-score": -1.6733200530681511,
        "water-fast-z-score": 3.679023140400945
    },
    {
        "original_text": "We present new spectroscopic observations of galaxies at z ~ 1.5-2.0 selected by their UVJ colors and optical morphologies, obtained with VLT/VIMOS on the Very Large Telescope (VLT). We find that these objects are mostly early-type galaxies showing signs of recent star formation activity. The observed properties suggest that they may be progenitors of local massive elliptical galaxies. These results provide further evidence supporting the scenario where most massive galaxies grow through mergers between gas-rich disk systems during the first half of cosmic time. This is an Open Access article distributed under the terms of the Creative Commons Attribution License 2.0, which permits unrestricted use, distribution, and reproduction in any medium provided the original work is properly cited. \n \n Keywords: galaxy evolution; merger remnants; young ellipticals; CDF-S field \n \n Massive galaxies evolve rapidly over cosmic time as a result of merging processes involving smaller companions. In particular, it has been suggested that many of today s brightest cluster galaxies were formed via major mergers of two or more gas-rich disks at redshifts around one to three  1  . However, direct observational evidence for this process remains elusive because of the difficulty in identifying such events at high redshift  2  .\n \nIn order to study the physical mechanisms driving galaxy growth we have carried out deep spectroscopy of galaxies at intermediate redshifts using the VLT-VIMOS spectrograph  3  . Our sample consists of about 100 galaxies selected based on their ultraviolet J (UVJ) color  4  , morphological type  5  , and apparent magnitude  6  . Most of them show strong emission lines characteristic of active star-forming regions  7, 8  . Their stellar masses range from 10^10 M_sol to 10^11 M_sol  9  . \n\n\nThe main goal of our project was to identify possible candidates for progenitor populations of local massive elliptical/S0 galaxies  10  . To do so, we used several selection criteria designed to select galaxies with similar characteristics to those found among nearby massive spheroids  11  : \n\n\n1. Morphological type: all targets must",
        "watermark_text": "We report new spectroscopic observations of clusters at z ~ 1 . 5 - 2 . 0 selected by their UVJ colors and optical morphologies , obtained with VLT / VIMOS on the Very Large Telescope ( VLT ) . We see that these objects are mostly early - class stars displaying signs of recent star formation activity .The observed properties suggest that they may be progenitors of local heavy elliptical galaxies . These data provide further evidence supporting the scenario where most large galaxies grow through mergers between gas - rich disk systems during the first half of cosmic time .This is an Open Access article distributed under the terms of the Creative Commons Attribution License 2 . 0 , which allows unrestricted use , distribution , and reproduction in any medium provided the original book is properly cited . Keywords : galaxy evolution ; collision remnants ; young ellipticals ; CDF - S field Massive stars develop rapidly over cosmic time as a product of combining processes involving smaller companions .In particular , it has been proposed that several of today s brightest cluster objects were created via large mergers of two or more gas - rich disks at redshifts around one to three 1 . However , direct observational evidence for this process remains elusive because of the difficulty in identifying such events at high redshift 2 .In order to study the physical mechanisms governing galaxy formation we have carried out deep spectroscopy of galaxies at intermediate redshifts using the VLT - VIMOS spectrograph 3 . Our specimen consists of about 100 galaxies chose based on their ultraviolet J ( UVJ ) color 4 , morphological class 5 , and apparent magnitude 6 .Most of them show intense emission lines typical of active star - creating areas 7 , 8 . Their stellar masses range from 10 ^ 10 M _ sol to 10 ^ 11 M _ sol 9 .The main goal of our work was to identify possible nominees for progenitor populations of local heavy elliptical / S0 galaxies 10 . To do so , we using numerous selection categories modified to select clusters with similar characteristics to those detected among neighboring massive spheroids 11 : 1 .Morphological type : all targets must",
        "ori-fast-z-score": 0.16116459280507606,
        "water-fast-z-score": 6.98800816145174
    },
    {
        "original_text": "We study the phenomenological consequences of supersymmetric models with gauge-mediated breaking, in which the Standard Model is extended by adding new vector-like matter fields and extra dimensions. We show that these models can be constructed such that they are free of any unnatural fine-tuning problems associated with the Higgs mass or flavor-changing neutral currents. In particular we find that:  1) The lightest scalar superpartner (the  Higgs  boson) has a mass at most around 300 GeV.  2) Flavor changing neutral current effects are suppressed to an acceptable level for generic values of parameters.  3) Gauge coupling unification occurs naturally within experimental uncertainties. 4) There exists a large parameter space where all sparticles have masses above 1 TeV while still satisfying constraints on electroweak symmetry breaking. 5) These models provide a natural explanation for why there may not yet exist evidence for supersymmetry at accelerator experiments.",
        "watermark_text": "We research the phenomenological consequences of supersymmetric theories with gauge - mediated breaking , in which the Standard Model is extended by added new vector - like matter fields and extra dimensions . We see that these models can be built such that they are free of any strange fine - tuned flaws associated with the Higgs mass or flavor - changing neutral currents .In particular we find that : 1 ) The lightest scalar superpartner ( the Higgs boson ) has a mass at most approximately 300 GeV . 2 ) Flavor shifting neutral current effects are suppressed to an acceptable level for generic values of values .3 ) Gauge coupling unification happens easily within experimental uncertainties . 4 ) There exists a large parameter room where all sparticles have masses above 1 TeV while already satisfying constraints on electroweak symmetry breaking .5 ) These models represent a natural explanation for why there may not already exist evidence for supersymmetry at accelerator studies .",
        "ori-fast-z-score": 0.7385489458759964,
        "water-fast-z-score": 5.908391567007971
    },
    {
        "original_text": "We present new results on the incidence and properties of intervening absorbers along the sightline towards GRB 080913, based on high-resolution spectroscopy obtained with X-shooter at VLT-UT2 (ESO program ID 080.A-9007). We detect two strong absorption systems in the spectrum of this burst, one associated with an intervening galaxy at z = 1.5394 ± 0.0002, and another system at z = 2.084 ± 0.001 that is likely due to a damped Lyman alpha absorber. The latter has been previously detected by Fynbo et al. (2009) using low resolution spectra taken with FORS-2/VLT. Our analysis shows that both these systems are rich in metals, including Si II, Mg II, Fe II, Al III, O I, N V, and possibly also C IV. In addition we find evidence for several weaker metal lines which may be associated with either or both of these systems.",
        "watermark_text": "We report new data on the incidence and properties of intervening absorbers along the sightline towards GRB 080913 , using on wide - resolution spectroscopy acquired with X - shooter at VLT - UT2 ( ESO program ID 080 . A - 9007 ) . We detect two strong absorption complexes in the spectrum of this burst , one linked with an intervening galaxy at z = 1 . 5394 ± 0 . 0002 , and another system at z = 2 . 084 ± 0 . 001 that is probably due to a damped Lyman alpha absorber .The latter has been previously observed by Fynbo et al . ( 2009 ) using small resolution spectra made with FORS - 2 / VLT .Our study shows that both these systems are rich in metals , notably Si II , Mg II , Fe II , Al III , O I , N V , and maybe also C IV . In addition we find proof for numerous smaller metal bands which may be identified with either or both of these systems .",
        "ori-fast-z-score": -1.6641005886756874,
        "water-fast-z-score": 3.6055512754639896
    },
    {
        "original_text": "The concept of defects in crystals has been developed by the Russian school since the 1930s. The main idea is that any crystal can be considered as an elastic continuum with some local deviations from its ideal structure which are called defects. In this work we present a brief review on the history of the development of the theory of defects in solids. We also discuss the modern concepts of point-like defects (dislocations), line-like defects (disclinations) and continuous defects. Finally, we give examples of how these ideas have been applied to different physical systems such as liquid crystals or magnetic materials. Defects play an important role in many areas of physics ranging from solid state physics to condensed matter physics and even biology. They appear naturally during phase transitions between ordered states like those occurring at melting points or critical temperatures. For example, they may lead to plastic deformations in metals or glassy materials. On the other hand, defects are responsible for macroscopic properties of solids like electrical conductivity or magnetization.",
        "watermark_text": "The concept of flaws in crystals has been originated by the Russian school since the 1930s . The main idea is that any solid can be regarded as an elastic continuum with some local deviations from its ideal structure which are called flaws .In this research we present a brief review on the history of the development of the principle of flaws in solids . We especially examine the newer concepts of point - like defects ( dislocations ) , edge - like defects ( disclinations ) and continuous defects .Finally , we give evidence of how these ideas have been used to different physical structures such as fluid crystals or magnetic materials . Defects serve an important role in many fields of science ranging from solid state mechanics to condensed matter science and even biology .They arise naturally during phase transitions between ordered states like those occurring at melting points or critical temperatures . For instance , they may contribute to plastic deformations in metals or glassy materials .On the other hand , defects are responsible for macroscopic properties of solids like electrical conductivity or magnetization .",
        "ori-fast-z-score": 0.5555555555555556,
        "water-fast-z-score": 6.184165460191406
    },
    {
        "original_text": "We study the graviton propagator in covariant massive gravity theory with an arbitrary number of gravitons and show that it is given by the sum over all Feynman diagrams which are obtained by attaching one or more gravitons to each vertex of the tree-level graviton propagator. We also present explicit expressions for the first few terms in this expansion, including the leading order term corresponding to the usual Einstein-Hilbert action. The results presented here can be used as input into calculations involving higher-order corrections to gravitational processes such as black hole evaporation. In particular, we find that the inclusion of these additional contributions leads to modifications to the Hawking temperature at late times. \nI. INTRODUCTORY REMARkS\nThe purpose of this work is twofold. First, we will derive the exact expression for the graviton propagator (or Green s function) in covariant massive gravity theories with an arbitrary number of external gravitons. Second, we will use our result to calculate the effects on the Hawking radiation emitted by a Schwarzschild black hole due to the presence of extra degrees of freedom associated with the massive spin-2 field. Our analysis follows closely the approach developed in Ref.  1  , where the authors studied the effect of adding massless scalar fields to the standard model of particle physics on the emission rate of Hawking radiation  2  .",
        "watermark_text": "We explore the graviton propagator in covariant massive gravity physics with an arbitrary number of gravitons and find that it is given by the sum over all Feynman diagrams which are derived by attaching one or more gravitons to each vertex of the tree - level graviton propagator . We additionally offer explicit expressions for the first few terms in this expansion , notably the main order term corresponding to the usual Einstein - Hilbert action .The results presented here can be used as input into measurements involving higher - order corrections to gravitational processes such as black hole evaporation . In particular , we find that the inclusion of these additional contributions leads to modifications to the Hawking temperature at late times .I . INTRODUCTORY REMARkS The purpose of this project is twofold .First , we will extract the exact representation for the graviton propagator ( or Green s function ) in covariant massive gravity theories with an arbitrary number of external gravitons . Second , we will use our result to estimate the effects on the Hawking radiation emitted by a Schwarzschild red hole due to the presence of added degrees of liberty involved with the huge spin - 2 field .Our study continues carefully the approach developed in Ref . 1 , where the authors explored the impact of adding massless scalar fields to the standard theory of particle physics on the emission speed of Hawking radiation 2 .",
        "ori-fast-z-score": 1.2247448713915892,
        "water-fast-z-score": 6.463663618136471
    },
    {
        "original_text": "The reed is the key component in single-reed musical instruments, such as clarinets or saxophones. The dynamics of its motion are strongly influenced by the bore geometry and boundary conditions at both ends. In this work we present an approach to simulate the oscillations of a single reed instrument based on modal decomposition of the bore and reed dynamics. We show that it is possible to accurately reproduce the sound produced by a real clarinet using only one degree-of-freedom for each mode. This method can be used to study the influence of different parameters (such as mouthpiece diameter) on the acoustic response of the instrument without requiring expensive experimental measurements. It also allows us to investigate how changes in the design affect the performance of new prototypes. \n \n Keywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method",
        "watermark_text": "The reed is the key component in single - reed musical instruments , such as clarinets or saxophones . The structures of its motion are strongly dictated by the bore pattern and boundary pressures at both ends .In this study we present an approach to simulate the oscillations of a single reed instrument relying on modal decomposition of the bore and reed dynamics . We see that it is easy to correctly reproduce the music created by a real clarinet using only one degree - of - independence for each mode .This method can be used to study the impact of different variables ( such as mouthpiece diameter ) on the acoustic response of the instrument without using expensive experimental surveys . It additionally lets us to examine how differences in the model affect the performance of new prototypes .Keywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method",
        "ori-fast-z-score": -1.5756771943166705,
        "water-fast-z-score": 4.727031582950012
    },
    {
        "original_text": "We present the results of an extensive spectroscopic survey for active galactic nuclei (AGN) in the southern hemisphere using the Sloan Digital Sky Survey (SDSS). The main goal is to select a complete flux-limited sample of radio-loud AGNs at redshifts z < 0.7, which we call ROXA (Radio Optical eXtragalactic Astronomy), by cross-correlating the FIRST 1.4 GHz radio source catalogue with the SDSS DR3 photometric database. We have obtained spectra for more than 1000 sources over an area of about 10,000 deg2. In this work we report on the selection criteria used to define our sample as well as its completeness and reliability. We also discuss some preliminary results concerning the properties of these objects such as their luminosity function and redshift distribution. This project has been funded by the European Space Agency under contract number 4000106131/16/NL/PA.",
        "watermark_text": "We present the results of an extensive spectroscopic study for active galactic nuclei ( AGN ) in the southern hemisphere using the Sloan Digital Sky Survey ( SDSS ) . The main goal is to select a complete flux - limited sample of radio - loud AGNs at redshifts z < 0 . 7 , which we call ROXA ( Radio Optical eXtragalactic Astronomy ) , by cross - correlating the FIRST 1 . 4 GHz radio source collection with the SDSS DR3 photometric archive .We have achieved spectra for more than 1000 sources over an area of about 10 , 000 deg2 . In this project we publish on the selection standards used to define our sample as well as its completeness and reliability .We also discuss some preliminary results concerning the properties of these objects such as their luminosity function and redshift distribution . This project has been sponsored by the European Space Agency under contract number 4000106131 / 16 / NL / PA .",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 3.5714285714285716
    },
    {
        "original_text": "The Solar Chromosphere is an important component in our understanding of how the Sun works and its influence on Earth, but it has been difficult to study because of its tenuous nature.  ALMA (Atacama Large Millimeter/submillimeter Array) will be able to observe this region for the first time with unprecedented spatial resolution.   This talk will discuss some of the science that can be done using ALMA observations of the Solar Chromosphere. The Solar Chromosphere is one of the most enigmatic regions of the Sun. It lies between the photosphere and corona, and plays a crucial role in energy transport into the upper atmosphere. However, due to its extremely low density, direct observation of the chromosphere was not possible until recently when high-resolution images were obtained by space-based telescopes such as Hinode/SOT and SDO/AIA. In addition, ground-based observatories have also made significant progress towards studying the chromosphere through various techniques including spectropolarimetry, imaging spectroscopy, and speckle interferometry. Despite these advances, there are still many open questions about the physical processes occurring within the chromosphere which need to be addressed. For example, what causes the formation of dynamic structures like sunspots? How do magnetic fields affect plasma dynamics in the chromosphere? What is the relationship between chromospheric heating mechanisms and coronal mass ejections? These questions cannot be answered without detailed knowledge of the structure and dynamics of the chromosphere. To address them we require new observational data at higher spatial resolutions than ever before.",
        "watermark_text": "The Solar Chromosphere is an important element in our understanding of how the Sun operates and its influence on Earth , but it has been difficult to study because of its tenuous nature . ALMA ( Atacama Large Millimeter / submillimeter Array ) will be possible to observe this area for the first time with incredible spatial resolution .This discussion will explore some of the science that can be performed using ALMA observations of the Solar Chromosphere . The Solar Chromosphere is one of the most enigmatic regions of the Sun .It lies between the photosphere and corona , and plays a crucial role in heat transport into the higher atmosphere . However , owing to its incredibly small abundance , direct observation of the chromosphere was not could until recently when high - resolution images were obtained by space - based telescopes such as Hinode / SOT and SDO / AIA .In addition , land - based observatories have already produced important development towards studying the chromosphere through numerous techniques including spectropolarimetry , optical spectroscopy , and speckle interferometry . Despite these developments , there are still many open questions about the physical processes arising within the chromosphere which require to be addressed .For instance , what causes the formation of dynamic systems like sunspots ? How do magnetic waves affect plasma dynamics in the chromosphere ?What is the relationship between chromospheric heating systems and coronal mass ejections ? These questions cannot be answered without precise understanding of the composition and dynamics of the chromosphere .To address them we require novel observational data at higher spatial resolutions than ever before .",
        "ori-fast-z-score": 1.4,
        "water-fast-z-score": 7.53778361444409
    },
    {
        "original_text": "We propose an algorithm to find optimal hierarchical descriptors (OHDs) that can be used as fingerprints in complex networks, such as social and biological systems. The OHDs represent network structures at different levels of granularity by using a tree-like structure with nodes representing subnetworks or clusters. We show how these trees can be constructed efficiently based on modularity maximization algorithms. In addition, we introduce a novel concept called  clustering coefficient  which is useful when constructing OHDs. Finally, we demonstrate our method through several examples including synthetic benchmark data sets and real-world networks. Our results suggest that the proposed approach provides more accurate descriptions than existing methods. This work was supported by JSPS KAKENHI Grant Number JP26287040. Keywords: Hierarchical descriptor, Clustering coefficient, Modularity Maximization Algorithm, Tree Structure, Fingerprint, Network Description",
        "watermark_text": "We suggest an algorithm to find optimal hierarchical descriptors ( OHDs ) that can be used as fingerprints in complex networks , such as social and biological environments . The OHDs represent system structures at different levels of granularity by using a tree - like structure with vertices representing subnetworks or communities .We see how these trees can be built easily using on modularity maximization algorithms . In addition , we provide a new notion called clustering coefficient which is important when constructing OHDs .Finally , we prove our technique through several examples namely natural benchmark data sets and actual - global networks . Our results show that the suggested approach offers more accurate descriptions than existing techniques .This project was supported by JSPS KAKENHI Grant Number JP26287040 . Keywords : Hierarchical descriptor , Clustering coefficient , Modularity Maximization Algorithm , Tree Structure , Fingerprint , Network Description",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.37925663806037
    },
    {
        "original_text": "The physical characteristics, spectral energy distributions (SEDs), and atmospheric properties of late-type dwarfs are reviewed in this chapter.  The SEDs for these objects have been measured by many authors using ground-based telescopes as well as space observatories such as ISO, Spitzer Space Telescope, and AKARI.  These observations show that the infrared flux increases with decreasing effective temperature.  In addition to their red colors, they also exhibit strong water vapor absorption bands at wavelengths longer than 2 microns.   Their near-infrared spectra reveal features due to methane gas which is abundant in their atmospheres.  They also display prominent atomic lines of potassium and sodium in their optical spectra.  Finally, we discuss how the observed photometric data can be used to determine the fundamental parameters of these objects including mass, radius, luminosity, surface gravity, age, metallicity, and distance.   ... This chapter reviews the physical characteristics, spectral energy distribution (SED) measurements, and atmospheric properties of late type dwarfs.",
        "watermark_text": "The physical qualities , spectral power distributions ( SEDs ) , and atmospheric characteristics of late - class dwarfs are reviewed in this page . The SEDs for these objects have been measured by many scientists using ground - based telescopes as well as space observatories such as ISO , Spitzer Space Telescope , and AKARI .These measurements show that the infrared flux changes with decreasing effective heat . In addition to their red colors , they even exhibit strong water vapor absorption groups at wavelengths greater than 2 microns .Their near - infrared spectra demonstrate characteristics owing to methane gas which is abundant in their atmospheres . They even exhibit prominent atomic patterns of potassium and sodium in their infrared spectra .Finally , we explain how the observed photometric data can be used to determine the fundamental variables of these objects including mass , diameter , luminosity , surface gravity , age , metallicity , and distance . . . .This section reviews the physical qualities , spectral power distribution ( SED ) observations , and atmospheric characteristics of late type dwarfs .",
        "ori-fast-z-score": 0.22360679774997896,
        "water-fast-z-score": 6.555555555555555
    },
    {
        "original_text": "We study isospin-breaking effects on the production rate for heavy-light mesons (D, D*) and light-heavy mesons (D0, D0bar). We use an effective field theory approach to calculate these rates at leading order in perturbation theory. The results are compared with experimental data obtained by CLEO-c. \n \n Isospin symmetry plays an important role in hadronic physics. It relates states that differ only in their charge but have identical masses. In particular it implies that the strong decay widths of charged and neutral pions should be equal. However, this equality has been experimentally tested down to pion momenta as low as 1 MeV/c and deviations up to 20% were found  1  . These deviations can be explained within Chiral Perturbation Theory  2  , which predicts corrections proportional to powers of the momentum transfer between initial and final state particles. At higher energies, where the typical momentum transfers become larger than the chiral scale, one expects such corrections to vanish rapidly  3  .\n \nIn contrast, we consider here processes involving two heavy quarks close to threshold. Here, the typical momentum transfers are small enough so that non-perturbative contributions cannot be neglected anymore. As a consequence, even though the mass difference between charm and anti-charm quarks is tiny, there will still be significant differences between the corresponding cross sections  4  . \n \n This effect was first observed more than 20 years ago  5  when studying the production of charmed mesons in electron-positron collisions. Since then many experiments  6  -  8  have measured the ratio of the production rates for different combinations of heavy-meson pairs. While some of them find good agreement with theoretical predictions  9  based on Heavy Quark Effective Theory  10  , others disagree significantly  11  .",
        "watermark_text": "We research isospin - breaking effects on the production frequency for heavy - heavy mesons ( D , D * ) and light - heavy mesons ( D0 , D0bar ) . We use an efficient field model approach to estimate these rates at leading order in perturbation theory .The results are compared with experimental evidence derived by CLEO - c . Isospin symmetry serves an important role in hadronic physics . It relates states that differ only in their charge but have equal masses .In particular it assumes that the strong decay widths of charged and neutral pions should be equal . However , this equality has been experimentally tested down to pion momenta as low as 1 MeV / c and deviations up to 20 % were found 1 .These deviations can be described within Chiral Perturbation Theory 2 , which predicts corrections proportional to powers of the velocity transfer between initial and final state particles . At higher energies , where the typical velocity transfers become bigger than the chiral scale , one expects such corrections to vanish swiftly 3 .In comparison , we treat here reactions involving two heavy quarks close to threshold . Here , the typical velocity transfers are small enough so that non - perturbative contributions never be forgotten anymore .As a consequence , even though the mass gap between charm and pro - charm quarks is tiny , there will still be considerable changes between the associated cross sections 4 . This phenomenon was first observed more than 20 centuries earlier 5 when examining the production of charmed mesons in electron - positron collisions .Since then many tests 6 - 8 have tested the proportion of the production rates for different combinations of heavy - meson pairs . While some of them find good agreement with theoretical estimates 9 based on Heavy Quark Effective Theory 10 , others disagree significantly 11 .",
        "ori-fast-z-score": -0.08873565094161139,
        "water-fast-z-score": 6.529318494299385
    },
    {
        "original_text": "We present the results of observations made by the Multiband Imaging Photometer for Spitzer (MIPS) in 24 and 70 micron bands toward the Lupus molecular clouds. The data were obtained as part of the Spitzer Space Telescope s  Cores to Disks  Legacy program. We have identified more than 1000 infrared point sources associated with these clouds using our source extraction technique. These include protostars, young stellar objects, and background galaxies. In addition we find that there are many extended emission features which may be related to outflows or other phenomena associated with star formation. A comparison between the observed number counts at 24 microns and those predicted based on models of interstellar dust suggests that most of the detected sources are likely to be low mass stars surrounded by disks. This is consistent with previous studies of this region. However, it appears that some fraction of the brightest sources could also be high-mass protostars.",
        "watermark_text": "We present the conclusion of measurements made by the Multiband Imaging Photometer for Spitzer ( MIPS ) in 24 and 70 micron bands toward the Lupus molecular clouds . The data were obtained as part of the Spitzer Space Telescope s Cores to Disks Legacy project .We have discovered more than 1000 infrared spot sources involved with these clouds using our source mining technique . These include protostars , young stellar bodies , and background galaxies .In addition we find that there are many extended emitted features which may be connected to outflows or other processes associated with star formation . A comparison between the seen amount totals at 24 microns and those predicted based on models of interstellar dust suggests that most of the emitted sources are likely to be low weight stars surrounded by disks .This is consistent with previous research of this area . However , it appears that some fraction of the brightest observers might actually be large - mass protostars .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.2532861073211246
    },
    {
        "original_text": "We present new results on the asteroseismic analysis of the primary component in the binary system Alpha Centari, based on data obtained with the HARPS spectrograph at La Silla Observatory (Chile). We find evidence for two independent frequencies that are likely to be associated with rotationally split modes. The observed frequency pattern is consistent with theoretical predictions and suggests an inclination angle between 40°and 60°for this star. \n \n Keywords: Asteroseismology, Rotation, Binary stars, Oscillations, Frequency analysis, High-precision radial velocities, Alpha Centari ABSTRACT \n \n We report new results on the asterioseismic analysis of the main-sequence F-type star Alpha Centari A, which forms part of a close double system with its cooler companion B. Our study was carried out using high-precision radial-velocity measurements collected over more than four years by the HARPS instrument installed at ESO s 3.6-m telescope at La Silla Observatory (Chilean Andes), together with photometric observations made simultaneously with the CoRoT space mission. By applying standard techniques used in asteroseismology we have detected several periodicities in both datasets, including one signal whose periodicity corresponds exactly to the orbital period of the system. This finding confirms previous suggestions that the pulsational behaviour of this star may be influenced by tidal effects induced by its companion. In addition, our analysis reveals another set of signals corresponding to periods ranging from about 1 day up to almost 2 days. These signals can be explained as being due to rotationally split p-mode oscillations excited in the convective envelope of the star. Their presence provides strong support for the hypothesis that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo processes operating within the convection zone.",
        "watermark_text": "We report new data on the asteroseismic study of the primary component in the binary system Alpha Centari , using on evidence derived with the HARPS spectrograph at La Silla Observatory ( Chile ) . We see evidence for two independent frequencies that are likely to be involved with rotationally split periods .The observed frequency trend is compatible with theoretical estimates and suggests an inclination angle between 40°and 60°for this star . Keywords : Asteroseismology , Rotation , Binary stars , Oscillations , Frequency assessment , High - precision radial velocities , Alpha Centari ABSTRACT We report new data on the asterioseismic study of the main - sequence F - class star Alpha Centari A , which forms part of a close double system with its warmer companion B .Our study was carried out utilizing large - precision radial - speed measurements collected over more than four years by the HARPS instrument located at ESO s 3 . 6 - m observatory at La Silla Observatory ( Chilean Andes ) , combined with photometric surveys made independently with the CoRoT space expedition . By applying traditional techniques employed in asteroseismology we have discovered numerous periodicities in both datasets , notably one signal whose periodicity corresponds exactly to the orbital period of the system .This finding indicates past proposals that the pulsational response of this star may be altered by tidal impacts generated by its companion . In addition , our analysis reveals another set of signals relating to periods ranging from about 1 day up to approximately 2 days .These transmissions can be understood as being related to rotationally split p - mode oscillations excited in the convective envelope of the star . Their presence provides strong evidence for the notion that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo mechanisms operating within the convection zone .",
        "ori-fast-z-score": -0.9838699100999074,
        "water-fast-z-score": 6.887089370699352
    },
    {
        "original_text": "The risk assessment algorithms based on recursive neural networks are proposed in this paper, which can be used to assess the risks for different types of financial assets and make decisions accordingly. The algorithm is composed by three parts: input data preprocessing, network training and output results analysis. In order to improve the accuracy of prediction, we use genetic algorithm (GA) to optimize the parameters of RNNs. Finally, an example is given to show how our method works. Keywords: Risk assessment; Financial asset; Genetic algorithm; Recurrent neural networks; Optimization. 1 Introduction With the rapid development of information technology, more and more people have access to online trading platforms such as Alibaba Group s Taobao Marketplace and Tencent Holdings  WeChat Pay. As a result, there has been growing interest among researchers in developing intelligent systems that can help investors make better investment decisions  1  . However, it remains challenging to develop accurate models due to the complexity of real-world problems  2  .\nIn recent years, artificial intelligence techniques have attracted increasing attention because they provide powerful tools for solving complex problems  3  , especially recurrent neural networks (RNN). Compared with traditional feed-forward neural networks  4  , RNNs have advantages over time series forecasting  5  -  8  . For instance, RNNs can learn long-term dependencies between inputs and outputs  9  . Therefore, RNNs are widely applied in many fields including stock market prediction  10  -  12  , traffic flow prediction  13  , energy consumption prediction  14  , etc..",
        "watermark_text": "The danger assessment methods developed on recursive neural systems are proposed in this paper , which can be used to examine the dangers for different kinds of financial investments and making decisions accordingly . The algorithm is composed by three components : input data preprocessing , network testing and input results analysis .In order to improve the accuracy of prediction , we utilize genetic algorithm ( GA ) to optimize the variables of RNNs . Finally , an instance is given to indicate how our technique works .Keywords : Risk evaluation ; Financial investment ; Genetic algorithm ; Recurrent neural connections ; Optimization . 1 Introduction With the fast development of electronic tech , more and more persons have access to online trading systems such as Alibaba Group s Taobao Marketplace and Tencent Holdings WeChat Pay .As a result , there has been growing interest among researchers in building smart systems that can help investors make better investment decisions 1 . However , it remains challenging to develop precise models due to the complexity of real - global difficulties 2 .In recent years , artificial intelligence techniques have garnered additional attention because they enable powerful tools for solving complex problems 3 , particularly recurrent neural systems ( RNN ) . Compared with typical feed - forward neural systems 4 , RNNs have benefits over time group forecasting 5 - 8 .For instance , RNNs can know long - term dependencies between inputs and outputs 9 . Therefore , RNNs are widely applied in multiple fields including stock price forecast 10 - 12 , transport stream forecast 13 , electricity demand prediction 14 , etc . .",
        "ori-fast-z-score": -0.8908708063747479,
        "water-fast-z-score": 7.902633289178096
    },
    {
        "original_text": "We study the dynamics of an interface driven by a periodic external force in one dimension, using molecular dynamics simulations with Lennard-Jones particles at low temperatures (T = 0.1 − 1). We find that the interface moves as a whole when it is driven slowly enough; otherwise, it breaks into several segments which move independently. The number of segments increases with increasing driving frequency or decreasing temperature. In addition to these two regimes, we observe another regime where the interface exhibits stick-slip motion. This third regime occurs for intermediate values of the driving amplitude A and driving frequency f . For this regime, we show that there exists a scaling relation between the average velocity V , the driving frequency f , and the driving amplitude A: V ∝ Af 2 . Finally, we propose a simple model based on the concept of phonon-enhanced diffusion to explain our results. DOI: 10.1103/PhysRevE.77.020101",
        "watermark_text": "We explore the dynamics of an interface pushed by a periodic external force in one dimension , using polymer mechanics simulations with Lennard - Jones grains at low temperatures ( T = 0 . 1 − 1 ) . We see that the interface moves as a whole when it is driven slowly sufficiently ; otherwise , it splits into numerous segments which move independently .The amount of segments varies with varying drove frequency or decreasing temperature . In addition to these two regimes , we study another regime where the interface displays stick - slipping motion .This third regime appears for intermediate values of the driving intensity A and driving frequency f . For this regime , we find that there exists a scaling relation between the average momentum V , the driving frequency f , and the driving intensity A : V [UNK] Af 2 .Finally , we attempt a simple model based on the idea of phonon - augmented diffusion to explain our findings . DOI : 10 . 1103 / PhysRevE . 77 . 020101",
        "ori-fast-z-score": -0.808290376865476,
        "water-fast-z-score": 4.588314677411235
    },
    {
        "original_text": "We present TRUFAS (Transit Recognition Using Fast Approximate Signatures), an efficient and robust transit search pipeline that uses fast approximate signatures to detect periodic signals in time series data. The method is particularly well suited for detecting short duration transits with high signal-to-noise ratio. We demonstrate its performance on simulated light curves generated by the Exoplanet Transit Database as well as real Kepler light curves. Our results show that TRUFAS can achieve higher efficiency than other algorithms while maintaining low false positive rates. \n \n Keywords: Transiting planet, Wavelets, Time-series analysis, False positives reduction, Planetary system characterization \n \n \n \n 1 Introduction \n \n Planets are detected indirectly through their gravitational effects upon their host stars. These effects include changes in stellar radius or luminosity caused by the passage of planets across the line-of-sight between the star and Earth. This phenomenon is known as a transit event. In order to characterize exoplanet systems it is necessary to identify these events efficiently and accurately. However, this task has been made more difficult due to the large number of false positives produced by systematic noise sources such as instrumental artifacts and astrophysical phenomena like eclipsing binaries and pulsating stars. \n \n To date there have been several methods developed specifically for identifying transit-like features within astronomical time series data. Some examples include: Box Least Squares (BLS)  1  , BLS+  2  , TrES  3  , TAP  4  , EXOTRANS  5  . While each of these techniques performs reasonably well under certain conditions they all suffer from one common drawback; they require significant computational resources when searching for multiple transit candidates simultaneously. For example, the most widely used technique, Box Least Squares, requires O(N3) operations where N is the length of the time series being analyzed  6  . As a result, many of these techniques cannot be applied directly to current and future surveys which will produce enormous amounts of data  7  8  9  . \n \n In recent years wavelet transforms have become increasingly popular for analyzing astronomical time series data  10  ",
        "watermark_text": "We introduce TRUFAS ( Transit Recognition Using Fast Approximate Signatures ) , an efficient and strong transit search pipeline that using fast exact signatures to identify continuous patterns in time series information . The method is especially good suitable for detecting short length transits with high signal - to - noise ratio .We showed its effectiveness on simulated light surfaces derived by the Exoplanet Transit Database as also as realistic Kepler light surfaces . Our results show that TRUFAS can attain better productivity than other methods while maintaining low false negative rates .Keywords : Transiting planet , Wavelets , Time - series analysis , False positives reduction , Planetary network characterization 1 Introduction Planets are detected indirectly through their gravitational impacts upon their host stars . These effects include changes in stellar radius or luminosity caused by the travel of stars across the line - of - view between the star and Earth .This phenomenon is known as a transit event . In order to characterize exoplanet systems it is required to identify these changes easily and correctly .However , this job has been turned more challenging due to the huge amount of false positives created by widespread sound sources such as instrumental artifacts and astrophysical processes like eclipsing binaries and pulsating stars . To date there have been numerous algorithms created exclusively for identifying transit - like phenomena within astronomical date sequence data .Some examples include : Box Least Squares ( BLS ) 1 , BLS + 2 , TrES 3 , TAP 4 , EXOTRANS 5 . While each of these procedures works relatively well under certain conditions they all suffer from one common drawback ; they demand significant computational resources when looking for multiple transit alternatives simultaneously .For instance , the most commonly used technique , Box Least Squares , requires O ( N3 ) operations where N is the length of the time series being evaluated 6 . As a result , many of these procedures cannot be applied directly to recent and future surveys which will generate immense sums of data 7 8 9 .In recent years wavelet transforms have developed relatively popular for studying astronomical time cycle information 10",
        "ori-fast-z-score": -2.5298221281347035,
        "water-fast-z-score": 7.171804696775816
    },
    {
        "original_text": "We present the results of an analysis of the supersymmetric standard model with minimal supergravity boundary conditions at the grand unification scale, including all one-loop corrections to gauge and Yukawa couplings as well as two-loop contributions to the running of the soft supersymmetry breaking parameters.  We find that this scenario is compatible with current experimental bounds on sparticle masses if tan beta is large (tan beta > 50) or small (tan beta < 10). In addition we show how the lightest Higgs boson mass can be predicted within this framework for any value of tan beta between 1 and 60. Finally, we discuss the implications of our results for future searches for supersymmetry at colliders such as LHC. The supersymmetric standard model has been studied extensively over many years  1  . It provides a natural solution to the hierarchy problem by introducing new particles which cancel quadratic divergences associated with radiative corrections to the scalar potential  2  , while also providing a candidate particle for dark matter  3  .\nIn recent years there have been several studies  4  -  8  investigating whether it is possible to construct models where the electroweak symmetry breaking sector is described by the MSSM  9  but the underlying physics is governed by some more fundamental theory valid at higher energies. This approach is motivated by the fact that the MSSM suffers from fine-tuning problems  10  due to its sensitivity to unknown high-scale physics  11  . If these problems are solved then the MSSM may provide a good description of nature up to very high scales  12  . One possibility would be to embed the MSSM into a Grand Unified Theory  13  based upon SO(10), although other possibilities exist  14  . Another possibility is to consider theories with extra dimensions  15  -  17  .",
        "watermark_text": "We present the conclusion of an assessment of the supersymmetric standard theory with minimal supergravity boundary constraints at the grand unified scale , comprising all one - loop corrections to gauge and Yukawa couplings as also as two - loop contributions to the running of the hard supersymmetry broken equations . We see that this situation is compatible with current experimental bounds on sparticle masses if tan beta is huge ( tan beta > 50 ) or small ( tan beta < 10 ) .In addition we prove how the lightest Higgs boson weight can be predicted within this framework for any value of tan beta between 1 and 60 . Finally , we explain the implications of our findings for future investigations for supersymmetry at colliders such as LHC .The supersymmetric standard description has been studied frequently over much years 1 . It provides a natural solution to the ranking problem by using new particles which cancel quadratic divergences associated with radiative corrections to the scalar potential 2 , while also offering a candidate particle for black material 3 .In recent years there have been numerous research 4 - 8 investigating whether it is easy to build theories where the electroweak symmetry breaking sector is modeled by the MSSM 9 but the underlying dynamics is governed by some more fundamental theory valid at higher energies . This method is prompted by the fact that the MSSM suffers from fine - tuned difficulty 10 due to its sensitivity to unknown long - scale physics 11 .If these problems are answered then the MSSM could give a better model of nature up to very high scales 12 . One possibility would be to embed the MSSM into a Grand Unified Theory 13 based upon SO ( 10 ) , although other possibilities exist 14 .Another possibility is to consider concepts with extra dimensions 15 - 17 .",
        "ori-fast-z-score": 0.2683281572999747,
        "water-fast-z-score": 7.184212081070997
    },
    {
        "original_text": "The authors present the results of their study on the scattering between two protons and one neutron, which is known as the triton channel in nuclear physics.  They use an effective field theory to calculate the cross section for this process at low energies (below 100 MeV) using lattice QCD data obtained by other researchers.   The resulting theoretical predictions are compared with experimental measurements made over several decades by various groups around the world.    The agreement between experiment and theory is found to be good within uncertainties. This work was supported by the U.S. Department of Energy under Contract No. DE-AC02-05CH11231. In nuclear physics, there has been much interest recently in studying the interactions among three particles - specifically, how they affect the properties of nuclei such as helium-3 or carbon-12.  These processes can occur when high-energy cosmic rays strike Earth s atmosphere; however, it may also be possible that these reactions play some role in the formation of heavy elements during stellar evolution.  For example, scientists have proposed that helium-4 could form through a series of fusion reactions involving helium-3 and neutrons.  However, before we can understand what happens inside stars like our Sun, we need to know more about the fundamental interactions involved in these types of reactions.  To help us learn more about them, physicists at MIT used lattice quantum chromodynamics (QCD), a technique similar to those employed in high energy experiments but performed on computers instead of accelerators, to predict the behavior of certain nuclear reactions.  Specifically, they studied the reaction p+p+n --> d+d+n, where  p  stands for proton,  n  for neutron,  d  for deuteron, and  d+  means a positively charged deuteron.  Their calculations were based on...",
        "watermark_text": "The authors present the conclusion of their experiment on the scattering between two protons and one neutron , which is known as the triton channel in nuclear physics . They use an efficient field model to estimate the cross section for this process at low energies ( below 100 MeV ) using lattice QCD evidence derived by other researchers .The resulting theoretical estimates are compared with observation observations made over numerous generations by various groups around the world . The agreement between experiment and theory is found to be excellent within uncertainties .This project was supported by the U . S . Department of Energy under Contract No . DE - AC02 - 05CH11231 .In nuclear science , there has been much interest notably in investigating the interactions among three particles - particularly , how they impact the properties of nuclei such as helium - 3 or carbon - 12 . These mechanisms can occur when high - energy cosmic rays strike Earth s atmosphere ; however , it could also be possible that these reactions serve some role in the formation of heavy metals during stellar evolution .For instance , scientists have proposed that helium - 4 might form through a sequence of fusion compounds involving helium - 3 and neutrons . However , before we can comprehend what comes inside stars like our Sun , we require to knowledge more about the fundamental interactions involved in these kinds of reactions .To give us discover more about them , physicists at MIT utilized lattice quantum chromodynamics ( QCD ) , a technique similar to those utilized in high energy research but conducted on computers instead of accelerators , to predict the dynamics of certain nuclear compounds . Specifically , they examined the response pp + p + n - - > d + d + n , where p sits for proton , k for neutron , d for deuteron , and d + means a positively charged deuteron .Their calculations were based on...",
        "ori-fast-z-score": 1.044465935734187,
        "water-fast-z-score": 8.649670160944275
    },
    {
        "original_text": "We present new measurements of the helium mass fraction YHe = 0.24 ± 0.01 (statistical) ±0.02 (systematic), obtained by combining X-ray data on galaxy clusters with SZ observations, using the sample of 62 nearby relaxed galaxy clusters observed at high signal-to-noise ratio by Planck satellite. The results are consistent with previous determinations based on Chandra or XMM-Newton data alone. \n \n We also report an improved measurement of the Hubble constant H0 = 67.4±1.2 km s-1 Mpc-1, which is derived from our determination of the angular diameter distance to these clusters combined with their redshifts. This value agrees well with other recent estimates but has smaller statistical uncertainty than most of them. It is also compatible within 1 sigma with the local measurement inferred from Cepheid variables. \n \n Finally we use this dataset to test for possible deviations from standard cosmology due to massive neutrinos. Our analysis shows that current data do not allow us to detect any significant deviation from the predictions of ΛCDM model.",
        "watermark_text": "We report new studies of the helium mass fraction YHe = 0 . 24 ± 0 . 01 ( statistical ) ±0 . 02 ( systematic ) , obtained by combining X - ray data on star clusters with SZ measurements , using the sample of 62 nearby relaxed galaxy galaxies collected at high signal - to - noise proportion by Planck rocket . The results are compatible with previous determinations based on Chandra or XMM - Newton data alone .We additionally report an better determination of the Hubble constant H0 = 67 . 4±1 . 2 km s - 1 Mpc - 1 , which is calculated from our determination of the angular length length to these clusters combined with their redshifts . This value agrees well with other recent estimates but has less statistical uncertainty than most of them .It is also consistent within 1 sigma with the local measurement inferred from Cepheid variables . Finally we utilize this dataset to test for probable deviations from standard cosmology due to massive neutrinos .Our study shows that current data do not enable us to identify any large deviation from the estimates of ΛCDM system .",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 6.50986776965388
    },
    {
        "original_text": "We present an overview of the phase space approach to special relativity, which is based on the concept that all physical quantities are represented by functions defined over a four-dimensional manifold called spacetime. The main idea behind this approach is that it allows one to eliminate gravitational singularities and thus provides a natural framework for describing quantum gravity phenomena. We also discuss some recent results obtained within this formalism. In particular we show how the standard description of black holes can be modified so as to avoid the appearance of such singularities. Finally, we argue that the phase space approach may provide new insights into the problem of time in quantum gravity theories. This article is part of the themed issue  Quantum gravity . Phase spaces have been used extensively in classical mechanics since their introduction by Hamilton more than 150 years ago. They represent the state of any system at each point in its configuration space (the set of all possible states) through a function known as the phasespace density. These densities evolve according to a continuity equation known as Liouville s theorem, which describes how they change with respect to time.",
        "watermark_text": "We present an overview of the phase space approach to special relativity , which is based on the idea that all physical phenomena are represented by functions defined over a four - dimensional manifold called spacetime . The main idea behind this methodology is that it allows one to eliminate gravity singularities and therefore provides a natural framework for describing quantum gravitational processes .We addition explore some latest findings obtained within this formalism . In particular we explain how the standard description of black holes can be altered so as to eliminate the appearance of such singularities .Finally , we argue that the phase space approach may provide fresh insights into the question of time in quantum gravitational dynamics . This page is part of the themed topic Quantum gravity .Phase functions have been used heavily in classical mechanics since their arrival by Hamilton more than 150 years back . They measure the state of any system at each point in its configuration set ( the set of all possible states ) through a function referred as the phasespace density .These densities grow according to a continuity function referred as Liouville s theorem , which explains how they change with regard to time .",
        "ori-fast-z-score": -0.3110855084191276,
        "water-fast-z-score": 6.18852747755276
    },
    {
        "original_text": "We study the implications for cosmology, astrophysics and particle physics of large volume string compactifications with fluxes in type IIA theory. We find that these models can be described by an effective supergravity action which is valid at energies below the Kaluza-Klein scale. The resulting four-dimensional effective potential has several interesting features. In particular it contains terms which are exponentially suppressed compared to those arising in conventional Calabi-Yau compactifications. These new contributions lead to novel effects such as moduli stabilization via non-perturbative corrections or supersymmetry breaking induced by gaugino condensation on D-branes wrapping internal cycles. Finally we discuss some phenomenological consequences of our results. This work was supported in part by NSF grant PHY-0456735. PACS numbers: 11.25.Wx, 04.50.+h, 98.80.Cq",
        "watermark_text": "We research the implications for cosmology , astrophysics and particle science of large depth string compactifications with fluxes in type IIA theory . We see that these models can be described by an efficient supergravity operation which is valid at energies below the Kaluza - Klein scale .The produced four - dimensional effective potential has various attractive features . In particular it contains terms which are exponentially suppressed compared to those arose in standard Calabi - Yau compactifications .These new contributions bring to novel effects such as moduli stabilization via non - perturbative corrections or supersymmetry breaking induced by gaugino condensation on D - branes wrapping internal cycles . Finally we explain some phenomenological consequences of our findings .This project was supported in part by NSF grant PHY - 0456735 . PACS codes : 11 . 25 . Wx , 04 . 50 . + h , 98 . 80 . Cq",
        "ori-fast-z-score": 1.1094003924504583,
        "water-fast-z-score": 5.269651864139677
    },
    {
        "original_text": "The human genome contains thousands of enhancers, which are non-coding DNA sequences that can activate transcription at distant sites. Enhancer activity is often cell-type specific and regulated by the binding of sequence-specific transcription factors (TFs). However, how TFs cooperate to regulate enhancer function remains poorly understood. Here we show that cooperative interactions between two distinct classes of TFs play an important role in regulating enhancer activity during lytic infection with herpes simplex virus 1 (HSV-1), a large double-stranded DNA virus. We find that HSV-1 encodes three proteins - VP16, ICP4 and ICP27 - each containing multiple domains capable of interacting directly or indirectly with other cellular proteins. Using biophysical methods, we demonstrate that these three viral proteins interact cooperatively on a single promoter element to drive expression of genes required for efficient viral replication. Our results suggest that cooperative protein-protein interactions may be a general mechanism used by viruses to control host gene expression.",
        "watermark_text": "The human genome contains dozens of enhancers , which are non - coding DNA sequences that can stimulate transcription at remote sites . Enhancer activity is often cell - class related and controlled by the interaction of sequence - specific transcription elements ( TFs ) .However , how TFs cooperate to affect enhancer function continues poorly explored . Here we find that cooperative relationships between two separate categories of TFs serve an important role in controlling enhancer activity during lytic infection with herpes simplex virus 1 ( HSV - 1 ) , a large double - stranded DNA virus .We see that HSV - 1 encodes three domains - VP16 , ICP4 and ICP27 - each carrying several domains responsible of interacting directly or indirectly with other cellular hormones . Using biophysical methods , we prove that these three viral molecules interact cooperatively on a single promoter structure to drive expression of genes necessary for efficient viral replication .Our results propose that cooperative protein - gene relationships may be a general process used by viruses to affect host gene transcription .",
        "ori-fast-z-score": -1.1793237883215741,
        "water-fast-z-score": 6.539886462510548
    },
    {
        "original_text": "We present new infrared spectra obtained with the Infrared Spectrograph (IRS) on board the Spitzer Space Telescope for four young stars in nearby open clusters. The targets are all classical T Tauri stars surrounded by circumstellar disks that have been previously studied at optical wavelengths using high-resolution spectroscopy to detect forbidden emission lines produced by ionized iron atoms Fe + . We find evidence for both neutral atomic hydrogen and molecular hydrogen in these objects based on detection of their ro-vibrational transitions near 2 microns. \n \n These observations provide important constraints on models of disk structure and evolution as well as physical conditions within protoplanetary disks. They also allow us to study chemical composition of the gaseous component of the disks. Finally, we use our results to estimate mass accretion rates onto central stars. Our main conclusions can be summarized as follows: \n \n 1. We confirm previous reports of strong  Ne II  12.81 micron line emission in three out of four observed sources. This is consistent with predictions made by theoretical models of photoevaporation of protoplanetary disks driven by intense ultraviolet radiation from central stars. \n \n 2. We report detection of several other ionic species including  S III  18.71 micron,  C II  158 micron, and  N II  122 micron. Their presence indicates significant ionization fraction in the innermost regions of the disks where temperatures exceed 1000 K. \n \n 3. We identify numerous ro-vibrational bands of molecular hydrogen in two of the observed systems. Emission features detected between 2.0-2.3 microns correspond to fundamental vibrational band of H2 1-0 S(1). Other prominent H2 lines include those associated with v=1-0 Q-branch of the first overtone transition 2-0 S(1), which appear in the range 2-2.2 microns.",
        "watermark_text": "We present new infrared spectra obtained with the Infrared Spectrograph ( IRS ) on board the Spitzer Space Telescope for four young stars in nearby open complexes . The targets are all ancient T Tauri stars surrounded by circumstellar disks that have been previously examined at optical wavelengths using high - resolution spectroscopy to identify forbidden emission lines released by ionized iron atoms Fe + .We see evidence for both stable atomic hydrogen and molecular hydrogen in these objects based on observations of their ro - vibrational changes near 2 microns . These measurements give important restrictions on predictions of disk shape and evolution as well as physical conditions within protoplanetary disks .They addition allow us to study chemical composition of the gaseous constituent of the disks . Finally , we utilize our findings to estimate mass accretion levels onto primary stars .Our main results can be summarized as follows : 1 . We report previous accounts of strong Ne II 12 . 81 micron line emission in three out of four predicted sources .This is compatible with predictions making by theoretical theories of photoevaporation of protoplanetary disks powered by intense ultraviolet radiation from central stars . 2 .We report discovery of several other ionic species namely S III 18 . 71 micron , C II 158 micron , and N II 122 micron . Their presence indicates considerable ionization fraction in the innermost parts of the disks where heat exceed 1000 K . 3 .We distinguish numerous ro - vibrational lines of molecular hydrogen in two of the studied structures . Emission features detected between 2 . 0 - 2 . 3 microns correspond to basic vibrational band of H2 1 - 0 S ( 1 ) .Other notable H2 lines include those associated with v = 1 - 0 Q - branch of the first overtone transition 2 - 0 S ( 1 ) , which appear in the range 2 - 2 . 2 microns .",
        "ori-fast-z-score": -1.0776318121606494,
        "water-fast-z-score": 6.529318494299385
    },
    {
        "original_text": "The DWEB benchmark is an open-source data warehouse engineering benchmark that can be used to evaluate the performance and scalability of different data warehouse systems, including relational databases (e.g., Oracle), columnar stores (e.g., MonetDB) and NoSQL databases (e.g,. Cassandra). The benchmark consists of three main components: a query generator, a database server emulator, and a client application. In this work we present the design and implementation details for each component as well as our experiences in using it on several platforms. We also provide some insights into how the benchmark was developed and discuss its limitations. Finally, we compare the results obtained by running the benchmark against two state-of-the-art commercial products. This article is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications (DASFAA 2015).\nIntroduction\n\nData warehouses are large repositories storing historical information about business processes or other types of activities. They have been widely adopted over the last decade due to their ability to support decision making at various levels within organizations  1  . However, with the increasing size of data warehouses, there has been growing interest in developing new techniques to improve their efficiency  2  .\nIn order to assess these new techniques, researchers need benchmarks capable of evaluating the performance and scalability characteristics of different data warehouse systems  3  , such as relational databases  4  , columnar stores  5  , and NoSQL databases  6  . Unfortunately, most existing benchmarks focus only on one type of system  7, 8  , which makes them unsuitable for comparing multiple technologies simultaneously  9  . To address this problem, we propose the DWEB benchmark  10  , which supports both traditional SQL queries and more advanced analytical operations  11  .",
        "watermark_text": "The DWEB benchmark is an open - source information warehouse architecture benchmark that can be used to analyze the performance and scalability of different data warehouse applications , notably relational databases ( e . g . , Oracle ) , columnar stores ( e . g . , MonetDB ) and NoSQL databases ( e . g , . Cassandra ) .The benchmark consists of three principal portions : a query generator , a document server emulator , and a client application . In this project we present the development and implementation information for each product as well as our achievements in utilizing it on numerous systems .We additionally offer some details into how the benchmark was developed and consider its limitations . Finally , we compare the results acquired by running the benchmark against two state - of - the - art commercial products .This page is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications ( DASFAA 2015 ) . Introduction Data warehouses are big repositories storing historical data about corporate processes or other types of activities .They have been widely adopted over the last decade due to their potential to support decision making at several levels within organizations 1 . However , with the increasing size of video warehouses , there has been growing interest in implementing new tactics to improve their productivity 2 .In order to examine these new strategies , researchers require benchmarks capable of evaluating the performance and scalability characteristics of different data warehouse technologies 3 , such as relational databases 4 , columnar stores 5 , and NoSQL databases 6 . Unfortunately , most existing benchmarks focus only on one sort of system 7 , 8 , which makes them unsuitable for comparing multiple concepts simultaneously 9 .To address this situation , we propose the DWEB benchmark 10 , which supports both traditional SQL queries and more advanced descriptive techniques 11 .",
        "ori-fast-z-score": 0.1781741612749496,
        "water-fast-z-score": 7.363817383097771
    },
    {
        "original_text": "The concept of dynamical 3-space is introduced in this review article as an alternative to the standard space-time picture of relativistic physics. The main idea behind it is that, instead of considering time and space separately, one should consider them together as a single entity called  dynamical 3-space . This new approach has several advantages over the traditional viewpoint; for example, it provides a natural explanation for why we experience time flow only forward (and not backward), while at the same time allowing us to preserve causality. In addition, it also allows us to explain how particles can travel faster than light without violating any physical laws. Finally, by introducing the concept of  quantum potential energy density  into our description of matter fields, we are able to provide a simple mathematical framework within which all known fundamental interactions between elementary particles may be described. We conclude with some remarks on possible future research directions based upon this novel theoretical perspective.",
        "watermark_text": "The concept of dynamical 3 - space is proposed in this review article as an alternative to the standard space - time view of relativistic physics . The main idea behind it is that , rather of considering time and space simultaneously , one should consider them combined as a common organization called dynamical 3 - space .This new approach has numerous benefits over the usual interpretation ; for example , it gives a natural explanation for why we experience time flow only ahead ( and not backward ) , while at the same time allowing us to restore causality . In addition , it also enables us to explain how atoms can travel quicker than light without violating any physical rules .Finally , by bringing the notion of quantum potential energy density into our description of matter fields , we are able to provide a simple mathematical framework within which all known fundamental interactions between elementary particles may be described . We continue with some remarks on potential future research paths based upon this new theoretical perspective .",
        "ori-fast-z-score": 1.3093073414159544,
        "water-fast-z-score": 5.965587590013045
    },
    {
        "original_text": "We present high spatial and spectral resolution observations of two IM stars, HD 163296 and MWC 480, obtained with the Submillimeter Array at 1.3 mm wavelength. We detect several compact sources in both objects that are associated with dusty disks or envelopes surrounding these young stellar objects. The disk masses derived for these systems range between 0.1 to 0.5 Msun. In addition we find evidence for an extended component in the vicinity of HD 163296 which may be related to its outflow activity. These results demonstrate that even massive protoplanetary disks can form planets like our own solar system. Keywords: Circumstellar matter - Stars: Herbig Ae/Be - Massive star formation - Planet formation - Protostars - Young stellar objects: General - Millimeter waves - Submillimeter waves - Nearby galaxies - Radio astronomy - High energy astrophysics",
        "watermark_text": "We report high spatial and spectral resolution measurements of two IM stars , HD 163296 and MWC 480 , obtained with the Submillimeter Array at 1 . 3 cm wavelength . We detect many compact sources in both objects that are related with dusty belts or envelopes underlying these young stellar bodies .The disk masses derived for these systems range between 0 . 1 to 0 . 5 Msun . In addition we find data for an extended component in the vicinity of HD 163296 which may be connected to its outflow function .These data demonstrate that even gigantic protoplanetary disks can form planets like our own solar body . Keywords : Circumstellar matter - Stars : Herbig Ae / Be - Massive star formation - Planet structure - Protostars - Young stellar bodies : General - Millimeter waves - Submillimeter waves - Nearby galaxies - Radio astronomy - High mass astrophysics",
        "ori-fast-z-score": 0.13018891098082389,
        "water-fast-z-score": 5.163977794943222
    },
    {
        "original_text": "We study non-Abelian hydrodynamic equations for fluids with spin-orbit coupling, which are derived by applying Noether s theorem to an action functional describing the dynamics of such systems. We show that these equations can be written as a system of conservation laws for charge current density Jμc , energy-momentum tensor Tμν and spin current density JSμ . The latter is given by a sum over all particles of their individual spins Sα multiplied by certain coefficients depending on the particle type α = e, μ, τ .\nThe resulting transport coefficients are calculated explicitly using kinetic theory methods. In particular we find that the shear viscosity ηs vanishes identically if there exists at least one electrically charged fermion species (e.g., electrons) or if the fluid contains only neutral bosons like photons. This result holds both for relativistic and nonrelativistic fluids. Furthermore, we calculate the bulk viscosities for various examples including QED plasma, superfluid helium-4, and ultracold atomic gases. Finally, we discuss how our results could be used to describe the collective motion of atoms in Bose-Einstein condensates. \nI. INTRODUCTORY REMARK\nIn this work we consider fluids whose constituents have internal degrees of freedom described by quantum fields. Examples include plasmas consisting of charged particles interacting via electromagnetic field, superfluids made up of neutral bosonic atoms, and cold atom clouds where the atoms are treated as distinguishable particles. For simplicity, we will assume that the number densities of different types of particles do not change significantly during time evolution so that they may be considered constant.",
        "watermark_text": "We research non - Abelian hydrodynamic equations for fluids with spin - orbit coupling , which are derived by using Noether s theorem to an action functional describing the dynamics of such systems . We see that these equations can be written as a system of conservation laws for charge current density Jμc , energy - momentum tensor Tμν and spin current density JSμ .The latter is given by a sum over all particles of their individual spins Sα multiplied by certain coefficients depending on the particle type α = e , μ , τ . The resulting transport values are measured precisely use kinetic theory techniques .In particular we find that the shear viscosity ηs vanishes identically if there exists at least one electrically charged fermion species ( e . g . , electrons ) or if the liquid includes only neutral bosons like photons . This result holds both for relativistic and nonrelativistic fluids .Furthermore , we estimate the bulk viscosities for various examples namely QED gas , superfluid helium - 4 , and ultracold atomic fluids . Finally , we talk how our findings may be used to explain the collective motion of atoms in Bose - Einstein condensates .I . INTRODUCTORY REMARK In this research we study fluids whose members have internal degrees of autonomy explained by quantum fields .Examples example plasmas consisting of charged particles communicating via electromagnetic field , superfluids composed up of neutral bosonic atoms , and cold particle clouds where the atoms are treated as distinguishable molecules . For simplicity , we will assume that the number densities of different kinds of atoms do not change considerably during time progression so that they may be regarded continuous .",
        "ori-fast-z-score": 0.4508348173337161,
        "water-fast-z-score": 6.041186552271796
    },
    {
        "original_text": "We present an algorithm for the calculation of ground-state properties in fermionic systems using auxiliary field quantum Monte Carlo (AFQMC). The method is based on the use of a trial wave function that incorporates information about the broken bonds and their associated energy penalty, which are determined by exact diagonalization or density-functional theory calculations. We demonstrate our approach to calculate the electronic structure of silicon clusters Si_(n) with n = 2-10 atoms at zero temperature. Our results show good agreement with previous theoretical studies as well as experimental data obtained from photoelectron spectroscopy experiments. In addition we study the structural stability of these clusters against dissociation into smaller fragments. Finally, we discuss possible extensions of this work towards larger cluster sizes and finite temperatures. Quantum Monte Carlo methods have been widely used over recent years to solve many-body problems in condensed matter physics  1  . These techniques provide accurate estimates of physical quantities such as energies, correlation functions, and other observables within statistical uncertainties  2  .\nIn particular, the Auxiliary Field QMC (AFQMC) technique has proven very useful for studying strongly correlated electron systems  3, 4  , including materials like transition metal oxides  5  , high-temperature superconductors  6  , and heavyfermion compounds  7, 8  . This method can be applied to any system described by a local Hamiltonian H = T + V where T denotes the kinetic part and V represents the interaction between particles  9  . It relies on the introduction of a trial wave function |ΨT⟩ that approximates the true ground state |Ψ0⟩ of the system under consideration  10  . Then, the expectation value ⟨O⟩ of some observable O can be calculated through the expression",
        "watermark_text": "We present an algorithm for the determination of ground - state properties in fermionic models using auxiliary field quantum Monte Carlo ( AFQMC ) . The method is based on the using of a trial wave function that incorporates information about the broken bonds and their accompanying energy penalty , which are decided by precise diagonalization or density - functional theory analyses .We showed our approach to estimate the electronic stability of silicon groups Si _ ( n ) with n = 2 - 10 atoms at zero temperature . Our results show good agreement with previous conceptual research as well as empirical data received from photoelectron spectroscopy observations .In addition we study the structural integrity of these complexes against dissociation into tiny components . Finally , we investigate possible extensions of this research towards higher cluster sizes and finite temperatures .Quantum Monte Carlo methods have been widely using over recent years to solve many - bodies problems in condensed matter science 1 . These methods provide accurate calculations of physical quantities such as energies , correlation functions , and other observables within statistical uncertainties 2 .In particular , the Auxiliary Field QMC ( AFQMC ) method has proven very useful for studying strongly interacting ion environments 3 , 4 , notably materials like transition glass oxides 5 , low - temperature superconductors 6 , and heavyfermion compounds 7 , 8 . This method can be applied to any system characterized by a local Hamiltonian H = T + V where T denotes the kinetic component and V describes the interaction between particles 9 .It relies on the introduction of a trial wave function | ΨT ⟩ that approximates the true ground state | Ψ0 ⟩ of the system under consideration 10 . Then , the expectation value ⟨ O ⟩ of some observable O can be determined through the expression",
        "ori-fast-z-score": -1.647508942095828,
        "water-fast-z-score": 5.918640302493727
    },
    {
        "original_text": "The article is devoted to the problem of possible existence of dark matter particles in our Galaxy, which are not detected by other methods than their gravitational effects on visible objects (stars). The author considers the possibility that these hypothetical particles can be described as celestial mechanics daemons with certain properties. In particular, it is shown how such daemons could explain some features observed recently for the DAMA experiment at Gran Sasso National Laboratory. It should be noted that this explanation does not contradict any known experimental data. However, there are also serious difficulties associated with the proposed model. These problems will require further study. This work was supported by Russian Science Foundation grant No 14-50-00040. URL: http://arxiv.org/abs/1409.5189 . \nI. INTRODUCTORY REMARK .\nDark Matter (DM) is one of the most important mysteries of modern physics  1  -  4  . Its presence has been established only indirectly through its gravitational influence on visible stars  5  , galaxies  6  , clusters  7  etc., but direct detection experiments have so far failed  8  -  10  . There exist many theoretical models describing DM  11  -  13  ; however, none of them has yet been confirmed experimentally  14  . One of the possibilities is that DM consists of new elementary particles  15  -  17  . If they interact weakly or electromagnetically with ordinary matter then they would escape detection even if they were produced in large quantities  18  . On the other hand, if they interact strongly enough with normal matter, then they may be detectable directly  19  -  21  . A number of experiments searching for DM particles have been carried out  22  -  26  . Recently, the results obtained by the DAMA collaboration  27  attracted considerable attention  28  -  30  . According to these results, the annual modulation effect  31  -  33  caused by the motion of Earth around Sun  34  -  36  leads to an increase in the rate of nuclear recoils registered by detectors during June-October period  37  compared to December-February period. Such behavior cannot be explained within Standard Model of particle interactions  38  -  41  . Several authors suggested different explanations based on",
        "watermark_text": "The essay is devoted to the question of possible existence of dark matter molecules in our Galaxy , which are not observed by other methods than their gravitational impacts on visible objects ( stars ) . The author considers the prospect that these hypothetical particles can be described as celestial mechanics daemons with certain characteristics .In particular , it is demonstrated how such daemons might explain some features detected lately for the DAMA experiment at Gran Sasso National Laboratory . It should be mentioned that this explanation does not contradict any established experimental evidence .However , there are also serious difficulties linked with the suggested model . These difficulties will demand further study .This project was supported by Russian Science Foundation program No 14 - 50 - 00040 . URL : www : / / arxiv . org / abs / 1409 . 5189 .I.INTRODUCTORY REMARK .Dark Matter ( DM ) is one of the most important wonders of modern physics 1 - 4 . Its presence has been known only indirectly through its gravitational impact on visible stars 5 , galaxies 6 , galaxies 7 etc . , but direct detection experiments have so far unsuccessful 8 - 10 .There exist many theoretical theories describing DM 11 - 13 ; however , none of them has already been confirmed experimentally 14 . One of the possibilities is that DM consists of new primary nucleus 15 - 17 .If they interact weakly or electromagnetically with everyday matter then they may survive observation even if they were produced in large quantities 18 . On the other hand , if they interact heavily enough with normal matter , then they may be detectable directly 19 - 21 .A variety of studies looking for DM nuclei have been carried out 22 - 26 . Recently , the results derived by the DAMA collaboration 27 drew substantial scrutiny 28 - 30 .According to these results , the annual modulation effect 31 - 33 induced by the movement of Earth around Sun 34 - 36 results to an increase in the frequency of nuclear recoils registered by detectors during June - October year 37 contrast to December - February time . Such action cannot be described within Standard Model of particle particles 38 - 41 .Several articles suggested different explanations based on",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.780541105074454
    },
    {
        "original_text": "The Large Magellanic Cloud (LMC) is an ideal laboratory for studying Galactic structure, stellar populations, chemical evolution, and cosmology because it has many advantages over other nearby galaxies such as M31 or M33.  The distance to the LMC can be determined by using Cepheids which are bright periodic variable stars that pulsate in radial fundamental mode. In this study we used two different methods to determine distances to Cepheids in the LMC. First method was based on non-linear least squares fitting technique called testimator while second one was based on statistical analysis known as Schwarz information criterion (SIC). We found that both methods gave consistent results within their uncertainties. Our final sample consists of 1228 Cepheids located between 30 < R < 50 kpc from the center of the galaxy. Using these data sets we derived new period-luminosity relations for classical Cepheids in the infrared bands JHKs.",
        "watermark_text": "The Large Magellanic Cloud ( LMC ) is an excellent laboratory for studying Galactic structure , stars populations , chemical evolution , and cosmology because it has numerous benefits over other nearby galaxies such as M31 or M33 . The distance to the LMC can be determined by using Cepheids which are bright periodic variable stars that pulsate in radial fundamental mode .In this study we using two different methods to estimate distances to Cepheids in the LMC . First method was based on non - linear least squares fit technique called testimator while second one was based on statistical analysis called as Schwarz information criterion ( SIC ) .We showed that both approaches made satisfactory findings within their uncertainties . Our last sample consists of 1228 Cepheids situated between 30 < R < 50 kpc from the hub of the galaxy .Using these information sets we derived additional period - luminosity relations for classical Cepheids in the infrared bands JHKs .",
        "ori-fast-z-score": 1.25,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "The influence of the oxygen partial pressure (pO(2)) during deposition on the structure, electrical conductivity and magnetization in cobalt-doped titanium dioxide thin films is investigated by X-ray diffraction (XRD), scanning electron microscopy (SEM) and vibrating sample magnetometry (VSM). The XRD patterns show that all samples are amorphous at room temperature but crystallize into anatase phase after annealing for 1 hour at 500 °C. It was found that pO(2) has an effect on the grain size as well as the lattice parameters of the deposited films. The resistivity decreases with increasing pO(2) while the saturation magnetization increases. These results suggest that the doping level can be controlled by changing the pO(2) value. \n \n Keywords: Cobalt-doped titanium dioxide film; Oxygen partial pressure; Structural property; Electrical conductivity; Magnetization",
        "watermark_text": "The impact of the oxygen partial pressure ( pO ( 2 ) ) during deposition on the composition , electrical conductivity and magnetization in cobalt - doped titanium dioxide narrow bands is investigated by X - ray diffraction ( XRD ) , scanning electron microscopy ( SEM ) and vibrating sample magnetometry ( VSM ) . The XRD patterns indicate that all specimens are amorphous at room temperature but crystallize into anatase phase after annealing for 1 hour at 500 °C .It was shown that pO ( 2 ) has an influence on the grain size as well as the lattice parameters of the deposited films . The resistivity decreases with expanding pO ( 2 ) while the saturation magnetization increases .These data suggest that the doping rate can be governed by varying the pO ( 2 ) value . Keywords : Cobalt - doped titanium oxygen film ; Oxygen partial pressure ; Structural property ; Electrical conductivity ; Magnetization",
        "ori-fast-z-score": -1.4744195615489712,
        "water-fast-z-score": 3.243723035407737
    },
    {
        "original_text": "The polaron problem is one of the most important problems in condensed matter physics, and has been studied extensively for many years.  In this work we present an overview of some recent results on path integral methods applied to the su(2)-schrieffer-heeger (s-shh) model with periodic boundary conditions.   We first review how the s-shh hamiltonian can be written as a sum over spinless fermions using the Jordan-Wigner transformation.  Then we discuss how the partition function may be evaluated by performing a trace over all possible states of these fermions.  Finally, we show that the resulting expression can be rewritten in terms of Feynman diagrams which are then used to calculate various physical quantities such as the energy spectrum or correlation functions. The polaron problem is one o fthe most important problems in condensate matter physics, and has b een studied extensively for many years  1  . It describes a single electron moving through a lattice of atoms interacting via phonons  2  , where the electron-phonon interaction leads to the formation of a bound state known as a polaron  3  .\nIn this work w epresent an overview of some recent resul ts on path integral m ethods applied t o th e su(2)-schr iefer -heeg er (s-shh ) model  4  wit h p eriodic bo undary condit ions  5  .  W e first r evie w ho w th e shh h amiltonia n ca n be wr it ten as a sum ov er sp inl ess fermi ons usin g th e J ordan-Wign er transfor mat ion  6  .  Th en we discu ss how th e partiti on functi on m ay be evalua ted by perform ing a tr ace ov er al l possibl e st at es of th ese fermi ons.  Fina ll y, we sho w tha t th e resul tin g ex pressio n ca n be rewrite n in term s of Feyn man di agrams wh ich ar e th en u",
        "watermark_text": "The polaron problem is one of the most important problems in condensed matter theory , and has been studied thoroughly for hundreds years . In this research we present an overview of some latest findings on path integral methods applied to the su ( 2 ) - schrieffer - heeger ( s - shh ) model with periodic boundary constraints .We first review how the s - shh hamiltonian can be written as a sum over spinless fermions using the Jordan - Wigner transformation . Then we explain how the partition function could be evaluated by performing a trace over all possible states of these fermions .Finally , we prove that the resulting expression can be rewritten in terms of Feynman diagrams which are then used to estimate various physical components such as the power spectrum or correlation functions . The polaron problem is one o fthe most important problems in condensate matter mechanics , and has b een discussed heavily for many years 1 .It describes a single electron moving through a lattice of atoms interacting via phonons 2 , where the electron - phonon interaction results to the formation of a bound state known as a polaron 3 . In this study w epresent an overview of some latest resul ts on path integral m ethods applied t o th e su ( 2 ) - schr iefer - heeg er ( s - shh ) model 4 wit n p eriodic bo undary condit ions 5 .W e first r evie w ho w th e shh n amiltonia n ca n be wr it ten as a sum ov er sp inl ess fermi ons usin g th e J ordan - Wign er transfor mat ion 6 . Th en we discu ss how th e partiti on functi on m ay be evalua ted by perform ing a tr ace ov er al l possibl e st at en of th ese fermi ons .Fina ll y , we sho l tha t th e resul tin g ex pressio n ca n be rewrite n in word s of Feyn man di agrams wh ich ar e th en u",
        "ori-fast-z-score": 1.4419211804559506,
        "water-fast-z-score": 5.448041796855991
    },
    {
        "original_text": "The purpose of this article is to give an overview of the theory of weight structures on triangulated categories developed by A. Bondal and M. Kapranov.  We will explain how it can be applied to construct new cohomology theories for algebraic varieties over finite fields or number fields.   In particular we will discuss the construction of motivic cohomology using weight structures on derived categories of mixed Tate motives.    The main results are due to J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, and others. This article was written as part of the author s Ph.D thesis at Utrecht University under supervision of Prof. Dr. Wim van der Kallen. It has been published online by the author with permission of the supervisor. For more information about the content see the introduction below.",
        "watermark_text": "The purpose of this page is to give an overview of the notion of weight spaces on triangulated categories established by A . Bondal and M . Kapranov . We will explain how it can be applied to build modern cohomology theories for algebraic fields over arbitrary fields or number fields .In particular we will explore the formation of motivic cohomology involving weight forms on derived categories of mixed Tate motives . The main results are due to J . Ayoub , D . Gaitsgory , R . Hain , S . Katzarkov , V . Lafforgue , C . Soulé , B . Stienstra , and others .This page was written as part of the writer s Ph . D degree at Utrecht University under supervision of Prof . Dr . Wim van der Kallen . It has been publication online by the writer with authorization of the supervisor .For more information about the content read the introduction below .",
        "ori-fast-z-score": -0.42008402520840293,
        "water-fast-z-score": 4.900980294098034
    },
    {
        "original_text": "We present the results of our study on binary models for gamma-ray bursts (GRBs) with progenitors in the mass range 8-40 M⊙, which are expected to produce GRB jets that can be observed at cosmological distances. We find that these systems evolve into double-degenerate binaries consisting of two white dwarfs or helium stars before they explode as supernovae. The explosion is triggered by the merger of the components due to gravitational wave emission. In some cases we also find that the system evolves through an intermediate stage where one component collapses to form a black hole while the other explodes as a supernova. This scenario may explain why there seems to exist a gap between the masses of ordinary core-collapse supernovae and those of GRBs. Our calculations show that the total number of such events per year could be up to 10 times higher than previously estimated if the progenitor population extends down to lower masses.",
        "watermark_text": "We present the conclusion of our study on binary models for gamma - ray bursts ( GRBs ) with progenitors in the mass range 8 - 40 [UNK] , which are expected to produce GRB jets that can be observed at cosmological distances . We say that these systems evolve into double - degenerate binaries consisting of two white dwarfs or helium stars before they explode as supernovae .The explosion is caused by the merger of the parts due to gravitational wave radiation . In some cases we also find that the system evolves through an intermediate stage where one element collapses to form a black hole while the other explodes as a supernova .This scenario could explain why there seems to exist a gap between the masses of normal core - collapse supernovae and those of GRBs . Our calculations show that the total number of such events per year could be up to 10 twice higher than previously predicted if the progenitor number extends down to smaller masses .",
        "ori-fast-z-score": -0.12216944435630522,
        "water-fast-z-score": 3.298574997620241
    },
    {
        "original_text": "We present an analysis of the neutral hydrogen (HI) emission observed with the Westerbork Synthesis Radio Telescope and the Effelsberg 100-m telescope to study the dark matter content of our Galaxy. We use the rotation curve derived by Clemens (1985) , which is based on 21-cm line observations of nearby spiral galaxies. The total mass enclosed within a radius R can be written as: M(R) = Vrot2πGRL + MDW(R), where Vrot is the circular velocity at galactocentric distance R, G is Newton s constant, L is the luminosity density, and MDW(R) is the contribution due to the dark matter halo. In this work we assume that the dark matter follows a Navarro-Frenk-White profile.  Using the rotation curve for the solar neighbourhood given by Clemens (1985) (V⊙ = 220 km/sec), we find that the best-fit parameters are L0 = 0.0013 Msun/pc3 and r0 = 1 kpc. This implies that the local surface brightness ΣL = L/L0 = 3.6 × 10^−26 W/m2/Hz/sr. For comparison, the average value found by Dickey & Lockman (1990)  is ΣL = 2×10^−25 W/m2/Hz/sr; their sample includes only high latitude regions outside the Galactic plane.",
        "watermark_text": "We present an analysis of the neutral hydrogen ( HI ) emission observed with the Westerbork Synthesis Radio Telescope and the Effelsberg 100 - m observatory to study the dark matter content of our Galaxy . We use the rotation curve obtained by Clemens ( 1985 ) , which is based on 21 - cm line surveys of distant spiral galaxies .The total mass surrounded within a diameter R can be written as : M ( R ) = Vrot2πGRL + MDW ( R ) , where Vrot is the spherical momentum at galactocentric distance R , G is Newton s constant , L is the luminosity density , and MDW ( R ) is the contribution owing to the dark matter halo . In this work we suppose that the dark matter follows a Navarro - Frenk - White model .Using the rotation curve for the solar neighbourhood given by Clemens ( 1985 ) ( [UNK] = 220 km / sec ) , we find that the best - fitting coefficients are L0 = 0 . 0013 Msun / pc3 and r0 = 1 kpc . This implies that the local surface brightness ΣL = L / L0 = 3 . 6 × 10 ^ −26 W / m2 / Hz / sr .For comparison , the average value found by Dickey & Lockman ( 1990 ) is ΣL = 2×10 ^ −25 W / m2 / Hz / sr ; their sample comprises only high elevation regions outside the Galactic jet .",
        "ori-fast-z-score": 0.7276068751089989,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We present new results on the X-ray spectrum and variability properties of Mrk 509, one of the brightest Seyfert galaxies observed by XMM-Newton. We find that its 0.5-10 keV continuum is well described by an absorbed power law with Γ = 2.1 ± 0.2 (χ2/dof=111/101) plus a reflection component modeled as a PEXRAV model with R=0.7-1.0 and NH=10-23×1022 cm-2. The best-fit parameters are consistent within errors to those found previously using Chandra data alone. No significant spectral changes were detected between different epochs separated by several months apart. However, we do detect strong flux variations at all energies during our observation period. In particular, there was a factor of 3 increase in the hard band count rate over about 20 ks followed by a slower decay back towards the initial level. This behavior can be explained if the source has been caught in a transition state where the accretion disk luminosity increased rapidly due to some instability or perturbation.",
        "watermark_text": "We report new data on the X - ray spectrum and variability properties of Mrk 509 , one of the brightest Seyfert galaxies studied by XMM - Newton . We see that its 0 . 5 - 10 keV continuum is well described by an absorption power law with Γ = 2 . 1 ± 0 . 2 ( χ2 / dof = 111 / 101 ) plus a mirror element modeled as a PEXRAV model with R = 0 . 7 - 1 . 0 and NH = 10 - 23×1022 centimetres - 2 .The best - fitting values are compatible within errors to those identified previously used Chandra data alone . No meaningful spectral changes were detected between various epochs separated by many months separated .However , we do discover powerful flux variations at all energies during our observation term . In particular , there was a factor of 3 shift in the hard band count rate over about 20 ks followed by a slower decay forward towards the first rate .This phenomenon can be understood if the source has been caught in a transfer state where the accretion disk luminosity increased rapidly due to some distortion or perturbation .",
        "ori-fast-z-score": -0.35603449745815596,
        "water-fast-z-score": 6.527299120066193
    },
    {
        "original_text": "We present the results of an analysis aimed at improving the stellar parameters for the host star of planet TrES-2, as well as its planetary system properties. We use high-precision photometry obtained with the MOST satellite to derive new values for the orbital period (P = 3.819 days), transit epoch (T0 = 2454000 MJD) and radius ratio (Rp/Rs = 0.11). These are combined with existing radial velocity data in order to refine the mass estimates for both components of this double-lined spectroscopic binary. Our best-fit model yields masses of 1.06 ± 0.04M⊙ and 0.84 ± 0.03M⊙ for the primary and secondary stars respectively, along with radii of 1.16 ± 0.02R⊙ and 0.91 ± 0.01R⊙ . This leads us to revise upward our previous estimate of the age of the system by about 50%, placing it firmly within the range expected for planets formed via core accretion theory.",
        "watermark_text": "We present the conclusion of an assessment aimed at enhancing the stellar characteristics for the host star of planet TrES - 2 , as well as its planetary system properties . We use large - precision photometry obtained with the MOST satellite to derive new values for the orbital period ( P = 3 . 819 days ) , transit epoch ( T0 = 2454000 MJD ) and radius ratio ( Rp / Rs = 0 . 11 ) .These are coupled with existing radial speed data in order to refine the mass estimates for both components of this double - lined spectroscopic binary . Our best - fitting model gives masses of 1 . 06 ± 0 . [UNK] and 0 . 84 ± 0 . [UNK] for the primary and secondary stars respectively , along with radii of 1 . 16 ± 0 . [UNK] and 0 . 91 ± 0 . [UNK] .This leads us to revise upward our previous estimate of the age of the system by about 50 % , placing it firmly within the range assumed for planets formed via nucleus accretion theory .",
        "ori-fast-z-score": 1.5650160901149996,
        "water-fast-z-score": 4.25
    },
    {
        "original_text": "We study the evolution of complex networks with multiple modules, where each module is an Erdős-Rényi random graph and all nodes are connected to one another within their own module but not across different modules. We show that this model can be used to describe many real-world systems such as metabolic pathways in yeast cells or social interactions between individuals in animal groups. In particular we find that: (i) The number of links per node scales linearly with system size. (ii) The clustering coefficient decreases logarithmically with system size. (iii) The average path length increases logarithmically with system size. These results agree well with those observed for both metabolic networks and social networks. Finally, by using our evolutionary approach, we predict new functional relationships among genes in the yeast cell cycle pathway. Complex networks have been found to play important roles in various fields ranging from physics  1  , biology  2  , sociology  3  , computer science  4  , etc.. Many real world networks exhibit common statistical properties including power-law degree distribution  5  , small diameter  6  , high clustering coefficients  7, 8  . However, it remains unclear how these networks evolve over time  9  .\nIn recent years there has been growing interest in studying the evolution of complex networks  10 -12  . For example, Barabási-Albert proposed a simple growth mechanism which leads to scale-free networks  13  . Dorogovtsev et al studied the evolution of hierarchical networks  14  . Caldarelli et al investigated the evolution of clustered networks  15  . Newman introduced a fitness-based model  16  . This model was further developed into a more realistic version  17  . Recently, Jeong et al showed that some metabolic networks share similar topological features  18  . They also suggested that the underlying mechanisms responsible for generating these networks may be related to natural selection  19  .",
        "watermark_text": "We research the evolution of complex networks with many modules , where each module is an Erdős - Rényi random graph and all nodes are connected to one another within their own module but not across different modules . We see that this model can be used to explain much actual - time systems such as metabolic processes in bacterial cells or cultural relationships between individuals in livestock groups .In particular we find that : ( i ) The amount of links per node scales linearly with system size . ( ii ) The clustering density decreases logarithmically with system height .( iii ) The estimated path length changes logarithmically with system width . These conclusions follow well with those observed for both metabolic networks and social systems .Finally , by using our evolutionary approach , we estimate new functional links among genes in the yeast cell cycle pathway . Complex networks have been shown to hold important roles in different fields ranging from science 1 , chemistry 2 , anthropology 3 , computer science 4 , etc . .Many actual world networks demonstrate familiar mathematical properties including power - law degree function 5 , low diameter 6 , large clustering coefficients 7 , 8 . However , it remains unsure how these networks develop over time 9 .In recent years there has been growing interest in investigating the evolution of complex networks 10 - 12 . For instance , Barabási - Albert proposed a simple growth mechanism which results to scale - free networks 13 .Dorogovtsev et al studied the evolution of hierarchical networks 14 . Caldarelli et al investigated the evolution of clustered systems 15 .Newman added a fitness - based model 16 . This model was further developed into a more realistic version 17 .Recently , Jeong et al showed that some molecular systems carry similar topological features 18 . They even suggested that the underlying mechanisms involved for generating these networks could be connected to natural selection 19 .",
        "ori-fast-z-score": -0.23942606534028665,
        "water-fast-z-score": 7.747580267412529
    },
    {
        "original_text": "We present the results of an automated search for star cluster candidates (SCCs) using deep HST/ACS images covering most of the disk and halo of M33, obtained as part of program GO-10229. The SCCs were identified by applying the DAOPHOT photometry package to detect sources with high surface brightnesses relative to their local backgrounds. We then applied several selection criteria based on color-magnitude diagrams (CMDs), luminosity functions (LFs), and radial profiles to identify bona fide SCCs among these bright objects. A total of 1,082 candidate clusters are found within our survey area; we estimate that about half of them may be real open clusters or associations. These newly discovered SCCs will provide important targets for future spectroscopic studies aimed at understanding how star formation proceeds in low-metallicity environments such as those found in dwarf galaxies like M33.",
        "watermark_text": "We present the results of an automated search for star cluster applicants ( SCCs ) using deep HST / ACS images covering most of the disk and halo of M33 , obtained as part of program GO - 10229 . The SCCs were discovered by using the DAOPHOT photometry program to identify sources with high surface brightnesses compared to their nearby backgrounds .We then utilized numerous selection standards based on color - magnitude diagrams ( CMDs ) , luminosity functions ( LFs ) , and radial profiles to identify bona fide SCCs among these bright objects . A total of 1 , 082 candidate clusters are found within our survey area ; we estimate that about half of them may be genuine open complexes or associations .These newly discovered SCCs will provide important candidates for future spectroscopic studies aimed at studying how star formation operates in low - metallicity habitats such as those observed in dwarf stars like M33 .",
        "ori-fast-z-score": 0.9701425001453319,
        "water-fast-z-score": 5.335783750799325
    },
    {
        "original_text": "We present new constraints on the redshift distribution of sources contributing to the source subtracted near-infrared background (SSNIB). We use deep Spitzer/MIPS 24 micron data in combination with optical and infrared photometry, including GALEX NUV imaging, to select galaxies at z > 1.5 over an area of 0.6 deg2 centered around the Lockman Hole East field. The resulting sample consists of 16,000 objects selected between redshifts 2<z<8. Using this sample we measure the evolution of the luminosity function out to high redshifts by fitting Schechter functions to our observed number counts as a function of flux density binned into bins of width ∆logS = 0.1 dex. Our results are consistent with previous studies that find evidence for strong luminosity evolution up to z ~ 3 followed by little or no evolution beyond this point. \n \n We then fit models to these measurements using Monte Carlo simulations which include contributions from both obscured AGNs and normal star forming galaxies. These fits show that the majority of the SSNIB is produced by faint galaxies at low redshifts (0.3 < z < 1) while bright galaxies dominate at higher redshifts (4 < z < 6). \n \n Finally, we compare our best-fit model predictions to existing observations of the unresolved extragalactic background light (EBL), finding good agreement within uncertainties.",
        "watermark_text": "We introduce novel constraints on the redshift flow of sources leading to the source subtracted near - infrared background ( SSNIB ) . We use deep Spitzer / MIPS 24 micron data in combination with optical and infrared photometry , using GALEX NUV photography , to select clusters at z > 1 . 5 over an area of 0 . 6 deg2 centered around the Lockman Hole East field .The resulting survey consists of 16 , 000 particles choose between redshifts 2 < z < 8 . Using this specimen we measure the evolution of the luminosity function out to large redshifts by fitting Schechter functions to our measured number counts as a function of flux density binned into bins of width [UNK] = 0 . 1 dex .Our results are compatible with previous analyses that provide evidence for strong luminosity progression up to z ~ 3 followed by much or no development beyond this point . We then fitting models to these measurements using Monte Carlo simulations which contain contributions from both distorted AGNs and normal star producing galaxies .These fits indicate that the majority of the SSNIB is produced by weak nuclei at low redshifts ( 0 . 3 < z < 1 ) while bright clusters influence at higher redshifts ( 4 < z < 6 ) . Finally , we compare our better - fitting model observations to existing observations of the unresolved extragalactic background light ( EBL ) , finding high agreement within uncertainties .",
        "ori-fast-z-score": -1.0425720702853738,
        "water-fast-z-score": 5.902918298980975
    },
    {
        "original_text": "We have obtained deep optical spectra for eight QSOs with known redshifts in the range 0.4-0.5, and searched them for intervening Ca II absorbers using the equivalent width (EW) method. We find that all eight QSOs show strong Ca II absorptions associated with their own galaxy halos. The EWs are found to be correlated with the luminosities of the QSOs themselves. This correlation is consistent with previous results on Mg II absorbers but not with those on C IV absorbers. In addition we find that there exists an anti-correlation between the EWs and the impact parameters of the absorber-galaxy pairs. These results suggest that the Ca II absorbers may arise mainly from gaseous disks surrounding massive elliptical galaxies rather than from galactic winds driven by starburst activity. \n \n \n \n Keywords: Absorber-galaxy pairs; Galaxy halo; Quasar; Redshift",
        "watermark_text": "We have recovered deep optical spectra for eight QSOs with reported redshifts in the range 0 . 4 - 0 . 5 , and explored them for intervening Ca II absorbers using the equivalent thickness ( EW ) method . We see that all eight QSOs exhibit strong Ca II absorptions associated with their own galaxy halos .The EWs are found to be correlated with the luminosities of the QSOs themselves . This correlation is compatible with previous findings on Mg II absorbers but not with those on C IV absorbers .In addition we find that there exists an counter - correlation between the EWs and the impact factors of the absorber - star pairs . These conclusions propose that the Ca II absorbers may arise predominantly from gaseous disks surrounding massive elliptical galaxies rather than from galactic winds driven by starburst activity .Keywords : Absorber - star pairs ; Galaxy halo ; Quasar ; Redshift",
        "ori-fast-z-score": -0.14907119849998599,
        "water-fast-z-score": 5.515634344499481
    },
    {
        "original_text": "We propose an alternative switching mechanism for spintronic devices based on domain walls (DWs). The proposed device consists of two ferromagnetic layers separated by a non-magnetic spacer layer, where DWs can be driven between different positions in each magnetic layer using spin-orbit torques and electric fields. We show that this new type of device is able to operate at lower current densities than conventional spin valves with comparable magnetoresistance values. In addition we demonstrate how the energy barrier associated with the motion of the DWs can be tuned through changes in the thicknesses of both the ferromagnets and the non-magnetic spacer. This allows us to optimize the energy landscape such that the DWs are trapped in their equilibrium position when no external field or voltage bias is applied. Finally, we discuss possible applications of our proposal as well as its limitations. Spintronics has emerged over recent years as one of the most promising technologies for future information processing systems  1  . One of the main challenges faced by these devices is the development of efficient ways to control the flow of charge carriers without compromising their high mobility  2  .\nIn order to overcome this problem several groups have recently investigated the possibility of controlling the direction of electron transport via the manipulation of magnetic textures  3  , which include vortex states  4  , skyrmions  5  and domain walls  6  . Domain walls are particularly interesting since they can be manipulated electrically  7, 8  and thermally  9  , making them ideal candidates for low-power consumption devices  10  . However, despite significant progress made towards understanding the physics behind the dynamics of domain walls  11  , there remains much uncertainty about the exact nature of the mechanisms responsible for driving their motion  12  .",
        "watermark_text": "We suggest an additional switching method for spintronic systems relying on domain barriers ( DWs ) . The proposed system consists of two ferromagnetic layers divided by a non - magnetic spacer membrane , where DWs can be pushed between various positions in each magnetic layer involving spin - orbit torques and electric forces .We suggest that this new kind of device is could to work at lower current densities than conventional spin tubes with similar magnetoresistance ratings . In addition we prove how the electricity barrier associated with the movement of the DWs can be tuned through variations in the thicknesses of both the ferromagnets and the non - magnetic spacer .This enables us to optimize the electricity landscape such that the DWs are locked in their equilibrium place when no external field or voltage bias is applied . Finally , we study possible users of our proposal as well as its limitations .Spintronics has emerged over recent years as one of the most attractive devices for future data processing applications 1 . One of the main problems faced by these machines is the development of effective means to manage the transfer of charge carriers without compromising their high mobility 2 .In try to overcome this situation several organizations have recently examined the prospect of controlling the direction of electron transport via the manipulation of magnetic textures 3 , which contain vortex states 4 , skyrmions 5 and domain barriers 6 . Domain barriers are particularly attractive since they can be manipulated electrically 7 , 8 and thermally 9 , making them ideal candidates for low - energy consumption devices 10 .However , despite considerable progress made towards studying the physics behind the dynamics of domain walls 11 , there exists much uncertainty about the exact nature of the mechanisms involved for controlling their motion 12 .",
        "ori-fast-z-score": -0.5980503604017327,
        "water-fast-z-score": 8.629012342939285
    },
    {
        "original_text": "The quantum group of isometries (QGI) was introduced by Connes as the universal object for deformations of classical groups, which are obtained via spectral triples on commutative C*-algebras.  In this talk we will discuss how to define QGI s using noncommutative geometry techniques such as operator algebras and von Neumann algebras.   We will also explain how these objects can be used to study the classification problem of Riemannian manifolds with positive scalar curvature. The Quantum Group of Isometries (QGI), first defined by Alain Connes, plays an important role in both classical and noncommutative geometry. It is the universal object for deforming classical Lie groups into their corresponding quantum groups. This talk will give an introduction to QGI’s and show that they can be studied through operator algebra theory and von Neumann algebras. Finally it will present some results about the classification problem of Riemannain manifolds with positive scalar curvatures.",
        "watermark_text": "The quantum group of isometries ( QGI ) was introduced by Connes as the universal object for deformations of classical groups , which are derived via spectral triples on commutative C * - algebras . In this talk we will explore how to define QGI s using noncommutative geometry tools such as operator algebras and von Neumann algebras .We will also explain how these objects can be used to study the characterization question of Riemannian manifolds with positive scalar curvature . The Quantum Group of Isometries ( QGI ) , initially established by Alain Connes , holds an important role in both classical and noncommutative geometry .It is the fundamental object for deforming classical Lie fields into their resulting quantum groups . This discussion will provide an introduction to QGI ’ s and explain that they can be investigated through operator algebra analysis and von Neumann algebras .Finally it will present some results about the characterization question of Riemannain manifolds with positive scalar curvatures .",
        "ori-fast-z-score": -0.2773500981126146,
        "water-fast-z-score": 4.437601569801833
    },
    {
        "original_text": "We study the gravitational self-force acting on a wave packet in curved spacetime, and show that it causes its distortion.  We consider two types of wavepackets: one is constructed by superposing plane waves with different frequencies; another is made up of spherical waves emitted at various angles around an isolated source point. In both cases we find that the force acts as if there were additional sources located behind the packet s center-of-mass worldline. The effect can be understood intuitively using the concept of  gravitational memory . Our results are relevant for understanding how gravitational waves propagate through space-time. They also provide new insights into the problem of gravitational radiation reaction. Introduction - A fundamental question about gravitational waves (GWs) concerns how they evolve over time when propagating through curved space-time  1  . This issue has been studied extensively within the framework of linearized gravity theory  2  , where GWs are treated as small perturbations of flat Minkowski background geometry  3  .\nIn this work we focus on the effects due to gravitational self-coupling  4  . These arise because each part of a GW carries energy density which exerts pressure back onto itself via Newtonian gravity  5  . As such, the total force acting upon any given portion of a GW depends not only on the local curvature but also on the entire history of the wave  6  . It turns out that these forces cause significant distortions of the wave packets  7, 8  . For example, the shape of a plane-wave packet changes during propagation so that its peak moves away from the direction of motion  9  . Similar behavior was found for spherical wave packets  10  .",
        "watermark_text": "We consider the gravitational self - force acting on a wave packet in curved spacetime , and find that it creates its degradation . We consider two forms of wavepackets : one is built by superposing plane waves with various frequencies ; another is made up of circular signals emitted at several angles around an exposed source point .In both cases we find that the force works as if there were extra sources located behind the packet s center - of - mass worldline . The phenomenon can be understood intuitively using the idea of gravitational memory .Our results are important for studying how gravity signals propagate through space - time . They also bring fresh insights into the question of gravitational waves reaction .Introduction - A basic issue about gravitational waves ( GWs ) concerns how they develop over time when propagating through curved space - time 1 . This problem has been studied thoroughly within the framework of linearized gravity physics 2 , where GWs are treated as low perturbations of flattened Minkowski background geometry 3 .In this research we focus on the effects due to gravitational self - interaction 4 . These occur because each portion of a GW carries energy density which exerts pressure back onto itself via Newtonian gravity 5 .As such , the total stress acted upon any certain parts of a GW relies not only on the local curvature but also on the entire history of the signal 6 . It turns out that these forces cause significant distortions of the signal packets 7 , 8 .For instance , the morphology of a plane - wave packet shifts during propagation so that its peak changes away from the direction of movement 9 . Similar behavior was seen for spherical wave packets 10 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.131727983645296
    },
    {
        "original_text": "We present an ab initio tight-binding model for calculating the optical properties of semiconductor nanocrystals, which is based on the solution of the Bethe-Salpeter equation (BSE) within the framework of density functional theory (DFT). The BSE describes excitonic effects and allows to calculate absorption spectra with high accuracy. We show that our approach reproduces experimental results very well. In particular we find good agreement between calculated and measured absorption cross sections at low energies where quantum confinement dominates over electron-hole exchange interactions. Our method can be applied to any type of semiconductor material including doped systems as well as core-shell structures. Semiconductor nanocrystals are promising candidates for applications such as light-emitting diodes or solar cells due to their unique optoelectronic properties. However, it remains challenging to predict these properties accurately since they depend sensitively on the electronic structure of the system. Here we propose a new theoretical approach to tackle this problem by combining DFT calculations with the Bethe-Salpether equation (BSE), which takes into account excitonic effects beyond mean-field approaches like Kohn-Sham DFT. This enables us to obtain accurate predictions for the optical properties of semiconductor nanostructures.",
        "watermark_text": "We present an ab initio close - binding model for determining the optical properties of semiconductor nanocrystals , which is based on the solve of the Bethe - Salpeter equation ( BSE ) within the framework of density functional theory ( DFT ) . The BSE describes excitonic effects and allows to estimate absorption spectra with high sensitivity .We see that our approach reproduces experimental results very best . In particular we find good agreement between calculated and reported absorption cross sections at low energies where quantum confinement dominates over electron - hole exchange interactions .Our method can be applied to any type of semiconductor material especially doped systems as well as core - shell systems . Semiconductor nanocrystals are promising candidates for applications such as light - emitting diodes or solar cells due to their different optoelectronic properties .However , it remains challenging to predict these characteristics properly since they rely sensitively on the electronic structure of the device . Here we attempt a new theoretical technique to tackle this question by combining DFT calculations with the Bethe - Salpether equation ( BSE ) , which gives into consideration excitonic effects beyond mean - field methods like Kohn - Sham DFT .This enables us to obtain precise predictions for the optical properties of semiconductor nanostructures .",
        "ori-fast-z-score": 1.4596008983995234,
        "water-fast-z-score": 6.463946835769319
    },
    {
        "original_text": "We present the results of our analysis on the polarization power spectrum in Bianchi type I cosmological models, which are anisotropic generalizations of standard FRW cosmologies. We find that there is no significant difference between the temperature fluctuations predicted by these two classes of models at large angular scales (low multipoles). However, we show that this is not true when one considers the polarization fluctuations. In particular, we demonstrate that the presence of an anisotropy parameter leads to a suppression of the low-l polarization power relative to the high-l part of the spectrum. This effect can be used as a test for distinguishing Bianchi type I models from their FRW counterparts. \n \n The observed lack of large-scale polarization in the WMAP data has been interpreted as evidence against inflationary scenarios with tensor perturbations. It was shown recently that such a conclusion may be premature if one takes into account possible deviations from statistical isotropy in the primordial universe. Indeed, it turns out that some anisotropic cosmological models predict less large-scale polarization than their isotropic counterparts do.",
        "watermark_text": "We present the conclusion of our analysis on the polarization power spectrum in Bianchi class I cosmological models , which are anisotropic generalizations of standard FRW cosmologies . We see that there is no major variation between the temperature fluctuations assumed by these two groups of models at large angular scales ( low multipoles ) .However , we prove that this is not true when one considers the polarization fluctuations . In particular , we prove that the presence of an anisotropy parameter causes to a suppression of the small - l polarization strength compared to the high - l part of the spectrum .This phenomenon can be used as a check for differentiate Bianchi class I theories from their FRW predecessors . The observed lack of large - scale polarization in the WMAP information has been viewed as proof against inflationary scenarios with tensor perturbations .It was shown lately that such a conclusion must be premature if one takes into consideration proposed deviations from statistical isotropy in the primordial universe . Indeed , it turns out that some anisotropic cosmological predictions predict less large - scale polarization than their isotropic counterparts do .",
        "ori-fast-z-score": -0.47809144373375745,
        "water-fast-z-score": 5.498051602938211
    },
    {
        "original_text": "We study the effects on electroweak precision observables (EWPO) due to new physics at the TeV scale, which is motivated by recent LHC results and theoretical arguments for naturalness. We consider two classes of models with extra dimensions: Randall-Sundrum (RS) warped space model and holographic technicolor (HTC). In RS model we find that the corrections are too large compared to EWPOs if the mass scales involved satisfy MPlanck ~ 5TeV. However, this problem can be solved by introducing an additional bulk scalar field whose VEV breaks custodial symmetry softly. The resulting correction to T parameter is found to be small enough even when MPlanck = 5TeV. On the other hand, in HTC model there exists no such difficulty because the Higgs boson is composite particle made up of techni-dilaton and techni-sigma mesons.",
        "watermark_text": "We research the effects on electroweak accuracy observables ( EWPO ) related to recent science at the TeV scale , which is prompted by recent LHC results and theoretical evidence for naturalness . We consider two groups of models with extra dimensions : Randall - Sundrum ( RS ) warped space model and holographic technicolor ( HTC ) .In RS model we find that the corrections are too huge compared to EWPOs if the mass scales concerned meet MPlanck ~ 5TeV . However , this situation can be answered by using an additional bulk scalar field whose VEV cuts custodial symmetry quietly .The resulting correction to T parameter is found to be small enough even when MPlanck = 5TeV . On the other hand , in HTC system there exists no such difficulty because the Higgs boson is composite particle making up of techni - dilaton and techni - sigma mesons .",
        "ori-fast-z-score": -1.2602520756252087,
        "water-fast-z-score": 3.959797974644666
    },
    {
        "original_text": "We present new high-resolution, near-infrared (NIR) spectra for the coolest known members of open clusters M67 and NGC 2516 obtained with the Phoenix spectrograph on Gemini South Observatory. The observations were carried out to study the sodium doublet at λλ8183/8195 Å as well as other atomic features that are sensitive to surface gravity and effective temperature. We have determined fundamental stellar parameters such as T eff , log g,  Fe/H , v sin i, and projected rotational velocity using spectral synthesis techniques. Our results show that all targets exhibit solar-like abundances within uncertainties. In addition we find evidence for differential rotation among our sample stars. Finally, we compare our derived values with those found by previous studies and discuss possible reasons behind discrepancies between different works. \n \n Keywords: Near-infrared spectroscopy, Open cluster, Surface gravity, Differential rotation, Fundamental parameters",
        "watermark_text": "We report new high - resolution , near - infrared ( NIR ) spectra for the coolest known members of open complexes M67 and NGC 2516 obtained with the Phoenix spectrograph on Gemini South Observatory . The images were carried out to study the sodium doublet at λλ8183 / 8195 Å as well as other molecular properties that are subject to surface gravity and effective heat .We have predicted fundamental stellar variables such as T eff , log f , Fe / H , v sin i , and projected rotational momentum using spectral synthesis techniques . Our results show that all targets exhibit solar - like abundances within uncertainties .In addition we find data for differential rotation among our sample stars . Finally , we compare our derived values with those detected by earlier surveys and consider alternative causes behind discrepancies between various works .Keywords : Near - infrared spectroscopy , Open cluster , Surface gravity , Differential rotation , Fundamental parameters",
        "ori-fast-z-score": 0.5,
        "water-fast-z-score": 4.5
    },
    {
        "original_text": "We report on the observation and characterization of two-dimensional defect modes in optically-induced photonic crystals (OIPCs). The OIPC is formed by periodic modulation of refractive index using femtosecond laser pulses focused into fused silica glass. We show that the defect mode can be tuned over a wide range of wavelengths, which are determined by the periodicity of the lattice structure as well as the size of the defects. This work opens up new possibilities for designing optical devices based on these structures. \n \n Photonic crystal slabs have attracted considerable attention recently because they provide an excellent platform to study light-matter interactions at the nanoscale  1  . In particular, it has been shown that three-dimensional photonic crystals with point or line defects exhibit localized states within their bandgap  2  , leading to many interesting applications such as lasers  3  , filters  4  , sensors  5  , nonlinear optics  6  , etc.. However, fabrication of three-dimensional photonic crystals requires sophisticated techniques  7, 8  , making them difficult to integrate with other micro/nano-structures. Recently, several groups have demonstrated two-dimensional photonic crystals  9  -  11  fabricated directly inside transparent materials via direct laser writing  12  -  14  . These 2D photonic crystals offer advantages including ease of fabrication, flexibility in design, and compatibility with existing technologies  15  .\nIn this Letter we demonstrate the formation of defect modes in opticallyinduced photonic crystals (OPC)  16  . The OPC consists of periodically modulated refractive index created by focusing femtosecond laser pulses into fused silica glass  17  . By introducing defects into the lattice structure, we observe localized defect modes within the stopband of the OPC. Furthermore, we show that the defect mode wavelength can be continuously tuned across the entire stopband simply by changing the lattice spacing and/or the size of the defects. \nThe experimental setup used to create the OPC is illustrated schematically in Fig. 1(a) . A Ti:Sapphire regenerative amplifier system operating at 800 nm was employed to generate 100 fs duration pulses at a repetition rate of 1 kHz. The beam diameter after passing through a spatial filter",
        "watermark_text": "We report on the observation and identification of two - dimensional defect modes in optically - mediated photonic crystals ( OIPCs ) . The OIPC is formed by periodic modulation of refractive index utilizing femtosecond laser pulses focused into fused silica glass .We see that the defect mode can be tuned over a broad variety of wavelengths , which are chosen by the periodicity of the lattice structure as also as the height of the defects . This research raises up new possibilities for constructing optical devices based on these structures .Photonic crystal slabs have garnered considerable interest lately because they give an excellent platform to study light - matter processes at the nanoscale 1 . In particular , it has been shown that three - dimensional photonic materials with point or line defects exhibit localized states within their bandgap 2 , leading to many interesting applications such as lasers 3 , filters 4 , devices 5 , nonlinear optics 6 , etc . .However , fabrication of three - dimensional photonic particles needs specialized techniques 7 , 8 , making them harder to integrate with other micro / nano - materials . Recently , various groups have demonstrated two - dimensional photonic particles 9 - 11 fabricated fully inside transparent materials via continuous optical writing 12 - 14 .These 2D photonic materials provide advantages including ease of fabrication , simplicity in design , and compatibility with existing devices 15 . In this Letter we prove the formation of defect modes in opticallyinduced photonic materials ( OPC ) 16 .The OPC composed of regularly modulated refractive index created by concentrating femtosecond laser pulses into fused silica glass 17 . By introducing defects into the lattice structure , we perceive localized failure modes within the stopband of the OPC .Furthermore , we find that the failure mode wavelength can be continuously tuned across the entire stopband solely by varying the crystal spacing and / or the size of the defects . The empirical setup used to create the OPC is depicted schematically in Fig .1 ( a ) . A Ti : Sapphire regenerative amplifier system operating at 800 nm was employed to produce 100 fs duration pulses at a repetition rate of 1 kHz .The beam diameter after passing through a spatial filter",
        "ori-fast-z-score": -0.3223291856101521,
        "water-fast-z-score": 7.526023228839096
    },
    {
        "original_text": "We present surface brightness profiles (SBPs) for a sample of globular clusters in the Large Magellanic Cloud (LMC), Small Magellanic Cloud (SMC) and Fornax galaxies obtained with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel (ACS/WFC). The SBPs are derived using archival data taken as part of the ACS Nearby Galaxy Survey Treasury program. We use these new observations to investigate whether there is any difference between the SBPs of globular cluster systems belonging to different host galaxies. In addition we compare our results with those previously published by other authors who have studied similar samples of globular clusters. Our main conclusions are:  1. There appears to be no significant differences between the SBPs of the three different types of globular clusters that were observed.  2. The majority of the globular clusters appear to follow an exponential profile which can be described by: I(r) = Ie exp -(r/rc)  where rc ~ 0.5 pc.",
        "watermark_text": "We create floor brightness characteristics ( SBPs ) for a sample of globular complexes in the Large Magellanic Cloud ( LMC ) , Small Magellanic Cloud ( SMC ) and Fornax clusters obtained with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel ( ACS / WFC ) . The SBPs are derived using archival imagery made as part of the ACS Nearby Galaxy Survey Treasury project .We use these new studies to examine whether there is any difference between the SBPs of globular cluster systems belonging to different host galaxies . In addition we compare our findings with those previously written by other researchers who have researched similar specimens of globular galaxies .Our main results are : 1 . There seems to be no major changes between the SBPs of the three different kinds of globular complexes that were detected .2 . The majority of the globular complexes appear to follow an exponential profile which can be described by : I ( r ) = Ie exp - ( r / rc ) where rc ~ 0 . 5 pc .",
        "ori-fast-z-score": -0.5547001962252291,
        "water-fast-z-score": 6.10170215847752
    },
    {
        "original_text": "We study number density correlation functions (NDCFs) in classical one-component plasma at high temperatures and find that they are not well defined due to infrared divergences, which is related with the fact that NDCF can be expressed as an integral over the whole space. We show how these difficulties can be overcome by introducing a new quantity called local number density correlation function (LNDCF). The LNDCF has no infrared divergence but it still contains information about correlations between particles on different length scales. In particular we calculate LNDCF for two limiting cases - when all particles have equal velocities or when their distribution is Maxwellian. Finally we discuss possible applications of our results. PACS numbers: 52.27.Lw, 52.35.Jm, 52.38.Bx \nI. INTRODUCTORY REMARK\nIn this work we consider classical one component plasma consisting of charged particles interacting via screened Coulomb potential  1  . This system is described by the following Hamiltonian:",
        "watermark_text": "We explore number density correlation functions ( NDCFs ) in classical one - component plasma at high altitudes and find that they are not well characterised due to infrared divergences , which is related with the fact that NDCF can be described as an integral over the whole space . We see how these problems can be overcome by using a new quantity called regional number density correlation function ( LNDCF ) .The LNDCF has no infrared divergence but it still contains information about correlations between particles on various length scales . In particular we estimate LNDCF for two limiting cases - when all particles have equal velocities or when their distribution is Maxwellian .Finally we explain possible applications of our findings . PACS codes : 52 . 27 . Lw , 52 . 35 . Jm , 52 . 38 . Bx I .INTRODUCTORY REMARK In this research we define classical one element plasma consisting of charged particles interacting via screened Coulomb potential 1 . This system is characterized by the following Hamiltonian :",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 4.608176875690327
    },
    {
        "original_text": "We discuss how chiral symmetry is realized in QCD, with particular emphasis on its implications for the spectrum of excited states. We argue that the lowest-lying excitations are described by open strings attached to quarks at one end and antiquarks at the other; these can be viewed as mesons or glueballs depending on whether they carry color charge or not.  The next set of excitations corresponds to closed strings which wind around the compactified dimension (the time direction) once or more times. These correspond to baryon resonances. Finally we consider higher-spin excitations corresponding to multiple winding modes of the closed string; these have spin greater than two but still less than the number of colors Nc. In this talk I will present some recent results obtained using holographic methods applied to gauge theories dual to supergravity backgrounds. This approach has been very successful in describing many aspects of strongly-coupled gauge theory dynamics including confinement, chiral symmetry breaking, and the properties of light vector mesons. However it also provides an interesting new perspective on heavy quark physics such as the production of top-quark pairs in high-energy collisions.",
        "watermark_text": "We discuss how chiral symmetry is realized in QCD , with particular focusing on its consequences for the spectrum of excited states . We argue that the smallest - lying excitations are explained by open strings attached to quarks at one end and antiquarks at the other ; these can be viewed as mesons or glueballs depending on whether they carry color energy or not .The next set of excitations corresponds to closed strings which wind around the compactified dimension ( the time direction ) once or more times . These correspond to baryon resonances .Finally we study greater - spinning excitations corresponding to multiple winding modes of the shut string ; these have spin greater than two but still less than the number of colors Nc . In this talk I will present some latest findings obtained using holographic methods applied to gauge fields dual to supergravity environments .This method has been very effective in understanding several elements of highly - coupled gauge theory physics including confinement , chiral symmetry breaking , and the properties of light vector mesons . However it also provides an interesting recent perspective on heavy quark theory such as the production of top - quark pairs in high - energy collisions .",
        "ori-fast-z-score": 1.8973665961010275,
        "water-fast-z-score": 6.324555320336758
    },
    {
        "original_text": "We measure the baryonic acoustic oscillation (BAO) scale in the distribution of galaxies by cross-correlating the Sloan Digital Sky Survey Data Release 5 with the Two Degree Field Galaxy Redshift Survey Data Release 3, both at z=0.35-0.55. We use two different estimators for the BAO peak position, one based on the correlation function and another on the power spectrum. The results are consistent within errors between these methods as well as with previous measurements made over smaller ranges of redshift or volume. Our measurement is also consistent with theoretical predictions based on WMAP1 cosmological parameters. This work demonstrates that it will be possible to make precise distance measurements out to redshifts of order unity using future large galaxy surveys such as the Dark Energy Spectroscopic Instrument. These distances can then be used to constrain dark energy models through their effect on the expansion history of the universe. \n \n Keywords: Baryons",
        "watermark_text": "We estimate the baryonic sound oscillation ( BAO ) scale in the distribution of galaxies by inter - correlating the Sloan Digital Sky Survey Data Release 5 with the Two Degree Field Galaxy Redshift Survey Data Release 3 , both at z = 0 . 35 - 0 . 55 . We use two different estimators for the BAO peak point , one based on the interaction function and another on the power spectrum .The results are compatible within errors between these models as well as with previous measurements made over smaller ranges of redshift or volume . Our measurement is also consistent with theoretical estimates based on WMAP1 cosmological factors .This research shows that it will be possible to make accurate distance measurements out to redshifts of order unity utilizing upcoming huge galaxy surveys such as the Dark Energy Spectroscopic Instrument . These ranges can then be used to constrain dark energy models through their effect on the evolution period of the universe .Keywords: Baryons",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 5.077963596336064
    },
    {
        "original_text": "We have recently shown that the one-range addition theorems derived in our previous work are valid not only for the Coulomb interaction potential but also its derivatives, such as the nuclear attraction potential or the exchange potential. \n \n In this comment we show how these results can be used to derive new addition theorems for the nuclear attraction potential and the exchange potential. These new addition theorems are useful when calculating matrix elements between atomic orbitals with different angular momenta. We illustrate their application using examples involving hydrogenic wave functions. Finally, we discuss some possible extensions of these results. DOI: 10.1063/1.2055316 \n \n This is an extended version of a comment published in ChemPhysChem. DOI: 10.1002/cphc.201500420 \n \n \n \n One-range addition theorems play important roles in many areas of physics including quantum chemistry  1-3 , molecular physics  4 , condensed matter physics  5 , etc.. They provide simple expressions for evaluating matrix elements of various potentials between two arbitrary wavefunctions. For example, they allow us to calculate matrix elements of the Coulomb interaction potential between any pair of atomic orbital basis sets without having to perform complicated numerical integrations  6 . Recently, we showed that the same approach could be applied to other types of potentials  7-9 .",
        "watermark_text": "We have recently shown that the one - range addition theorems generated in our previous study are applicable not only for the Coulomb interaction potential but also its derivatives , such as the atomic attraction potential or the exchange potential . In this comment we give how these results can be used to derive new addition theorems for the atomic attraction potential and the transfer potential .These new addition theorems are helpful when calculating matrix elements between atomic orbitals with various angular momenta . We illustrate their application using examples involving hydrogenic wave systems .Finally , we explain some possible extensions of these results . DOI : 10 . 1063 / 1 . 2055316 This is an extended version of a note published in ChemPhysChem .DOI : 10 . 1002 / cphc . 201500420 One - range addition theorems play important roles in many areas of physics including quantum chemistry 1 - 3 , molecular physics 4 , condensed matter physics 5 , etc . . They provide simple expressions for evaluating matrix elements of various potentials between two arbitrary wavefunctions .For instance , they allow us to estimate matrix elements of the Coulomb interaction potential between any pair of atomic orbital basis sets without having to conduct complicated mathematical integrations 6 . Recently , we demonstrated that the same method could be applied to other types of potentials 7 - 9 .",
        "ori-fast-z-score": -0.5076730825668095,
        "water-fast-z-score": 3.7567808109943908
    },
    {
        "original_text": "We study the collective modes in two-band superconductors with different gaps and masses, using the random phase approximation (RPA). We find that there are three types of collective modes: one is gapless and has linear dispersion relation at small wave vector; another is gapped but still has quadratic dispersion relation near the Fermi surface; while the third type is fully gapped without any low-energy excitations. The latter two types can be regarded as phonon-like collective modes. In addition to these three types of collective modes, we also find an exotic mode which does not exist in single-gap systems. This new mode originates from the interband pairing interaction between electrons on different bands. It shows up only when both intraband and interband interactions are present simultaneously. Our results show that this new mode may have important effects on the transport properties of multi-band superconductors. \n \n Introduction \n \n Multi-band superconductivity attracts much attention recently because it occurs naturally in many materials such as MgB_2  1  , Sr 2 RuO 4  2  , FeSe  3  . These compounds usually contain several orbitals per unit cell so they support multiple electronic bands crossing the Fermi level  4  . Due to the presence of more than one band, the electron-phonon coupling strength could vary significantly among different bands  5  . Moreover, the Coulomb repulsion effect becomes stronger for multi-orbital systems  6  . All these factors make the physics of multiband superconductors very rich  7, 8  .\n \nIn recent years, great progresses have been made in understanding the physical properties of multi-band superconductor  9  . For example, the vortex lattice structure  10  , magnetic field dependence  11  , thermal conductivity  12  , specific heat  13  , NMR relaxation rate  14  etc., were studied extensively by experiments. On the theoretical side, various methods including mean-field theory  15  , Eliashberg formalism  16  , functional renormalization group  17  , variational Monte Carlo  18  , exact diagonalization  19  , density matrix renormalization group  20  , and quantum Monte Carlo  21  were used to investigate the ground state properties  22  , thermodynamic quantities  23  ,",
        "watermark_text": "We research the collective modes in two - band superconductors with various gaps and masses , using the random phase approximation ( RPA ) . We see that there are three categories of collective modes : one is gapless and has continuous dispersion relation at small wave vector ; another is gapped but still has quadratic dispersion relation near the Fermi surface ; while the third type is fully gapped without any low - energy excitations .The last two forms can be regarded as phonon - like collective modes . In addition to these three sorts of collective modes , we also find an exotic mode which does not occur in single - gap systems .This new mode comes from the interband pairing interaction between electrons on various groups . It gets up only when both intraband and interband interactions are present concurrently .Our results show that this new mode may have important effects on the travel properties of multi - band superconductors . Introduction Multi - band superconductivity attracts great concern lately because it appears naturally in many materials such as MgB _ 2 1 , Sr 2 RuO 4 2 , FeSe 3 .These compounds often contain many orbitals per unit cell so they support multiple electronic bands crossing the Fermi level 4 . Due to the presence of more than one band , the electron - phonon coupling strength could vary significantly among different bands 5 .Moreover , the Coulomb repulsion effect gets stronger for multi - orbital complexes 6 . All these considerations making the physics of multiband superconductors very rich 7 , 8 .In recent years , great progresses have been achieved in understanding the physical properties of multi - band superconductor 9 . For instance , the vortex lattice structure 10 , magnetic field dependence 11 , thermal conductivity 12 , basic heat 13 , NMR relaxation speed 14 etc . , were studied thoroughly by research .On the theoretical front , various methods notably mean - field model 15 , Eliashberg formalism 16 , functional renormalization group 17 , variational Monte Carlo 18 , exact diagonalization 19 , density matrix renormalization group 20 , and quantum Monte Carlo 21 were used to examine the ground state properties 22 , thermodynamic quantities 23 ,",
        "ori-fast-z-score": 0.9607689228305227,
        "water-fast-z-score": 6.943355894868313
    },
    {
        "original_text": "We present here the rigorous mathematical formulation and complete proof of our previous results on the equivalence between Ising spin glasses (ISGs) and Ising models (IMs). We show that, in the thermodynamic limit N → ∞ with fixed ratio J / T , ISG partition functions can be mapped to IM ones by means of a suitable transformation which preserves all relevant physical quantities such as free energy density f = −k B T ln Z/N . The main idea is to introduce a new set of variables {s} ≡ {s1, ..., sN } representing the local magnetizations of each site i ∈ {1, .., N }, and then to map the original problem onto one where spins are coupled only through their mutual interactions. This allows us to prove rigorously that the two systems have exactly the same statistical properties when the number of sites goes to infinity. \nThe manuscript is organized as follows. In Sec. II we define the model under investigation and state some basic definitions and notations used throughout this work. In Sec. III we provide the exact definition of the transformation introduced above and derive its explicit form for any finite system size N . Then, in Sec. IV, we discuss how it can be extended to infinite-size lattices. Finally, in Sec. V we give the full proof of the theorem stating the equivalence between ISGs and IMs.",
        "watermark_text": "We present here the thorough mathematical formulation and complete proving of our previous findings on the equivalence between Ising spin glasses ( ISGs ) and Ising models ( IMs ) . We see that , in the thermodynamic limit N → ∞ with constant ratio J / T , ISG partition functions can be mapped to IM ones by means of a suitable decomposition which preserves all relevant physical components such as free energy density g = −k B T ln Z / N .The main idea is to introduce a new collection of variables { s } ≡ { s1 , . . . , sN } representing the local magnetizations of each site i ∈ { 1 , . . , N } , and then to map the previous problem onto one where spins are coupled only through their mutual interactions . This enables us to prove rigorously that the two systems have exactly the same statistical characteristics when the number of places goes to infinity .The manuscript is organized as follows.In Sec.II we define the model under inquiry and explain some fundamental definitions and notations used throughout this study . In Sec .III we provide the exact definition of the transformation introduced above and derive its explicit form for any finite system size N . Then , in Sec .IV , we explain how it can be generalized to infinite - length lattices . Finally , in Sec .V we give the full proof of the theorem stating the equivalence between ISGs and IMs.",
        "ori-fast-z-score": 1.801996396010812,
        "water-fast-z-score": 5.7564193416014815
    },
    {
        "original_text": "We present an ab initio study on spin relaxation mechanisms in bulk, single- and double-quantum-well (DQW) structures based on zinc-blende semiconductors such as GaAs or InP. We focus our attention on the so-called Bir-Aronov-Pikuz mechanism which is responsible for spin-flip transitions between conduction-band states with different orbital angular momenta. The main results are summarized below.  For bulk materials we find that the dominant contribution comes from intra-valley scattering processes involving heavy-hole bands. This result agrees well with previous theoretical studies performed within effective-mass approximations. However, by using realistic band-structure calculations we show that inter-valley contributions can also play an important role when considering DQWs grown along non  001  directions. Finally, we discuss how these findings could be used to improve existing models describing spin relaxation times in semiconductor nanostructures.",
        "watermark_text": "We present an ab initio investigation on spin relaxation mechanisms in bulk , double - and double - quantum - well ( DQW ) complexes based on aluminium - blende semiconductors such as GaAs or InP . We focus our focus on the so - called Bir - Aronov - Pikuz process which is responsible for spin - flip transitions between conduction - band elements with various orbital angular momenta .The main results are presented below . For bulk materials we find that the dominant contribution comes from intra - valley reflection processes involving heavy - hole lines .This result agrees well with previous conceptual research performed within efficient - mass approximations . However , by using accurate band - structure estimates we find that cross - valley contributions can also play an important role when assessing DQWs grown along non 001 directions .Finally , we explain how these results could be used to improve previous descriptions describing spin relaxation times in semiconductor nanostructures .",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 5.444444444444445
    },
    {
        "original_text": "We present new multi-color photometric data for the globular cluster M75 (NGC6864) obtained with the Hubble Space Telescope Wide Field Camera 3, which allow us to study its horizontal branch stars in unprecedented detail. We find that the color distribution along the HB is bimodal, indicating two distinct populations of hot and cool HB stars. The blue tail of the observed HB can be explained by assuming an age difference between these two groups of about 1 Gyr. Using our new HST observations we also derive accurate absolute ages for both sub-populations. Our results show that the redder population has an age of 12.6 ± 0.2 Gyr while the bluer one is younger at 11.7 ± 0.1 Gyr. This finding supports previous suggestions that the redder part of the HB may have been formed during a second episode of star formation within this system. \n \n Keywords: Globular clusters; Horizontal branches",
        "watermark_text": "We present new multi - color photometric data for the globular cluster M75 ( NGC6864 ) obtained with the Hubble Space Telescope Wide Field Camera 3 , which allow us to study its horizontal branch stars in unprecedented detail . We see that the color variation along the HB is bimodal , showing two different populations of cold and warm HB stars .The blue tail of the observed HB can be described by assuming an age difference between these two groups of about 1 Gyr . Using our new HST observations we also generate reliable absolute ages for both sub - communities .Our results show that the redder population has an age of 12 . 6 ± 0 . 2 Gyr while the bluer one is younger at 11 . 7 ± 0 . 1 Gyr . This conclusion supports earlier suggestions that the redder half of the HB may have been formed during a second episode of star formation within this system .Keywords : Globular regions ; Horizontal branches",
        "ori-fast-z-score": -0.508000508000762,
        "water-fast-z-score": 3.713069518053983
    },
    {
        "original_text": "We present an algorithm to determine directly the surface gravity (log g) and radius ratio (Rp/Rs) of transiting exoplanets using high-precision photometry obtained with space-based observatories such as CoRoT, Kepler or Spitzer. The proposed technique is based on the measurement of the transit duration in different passbands. We show that this new approach allows us to obtain accurate values of log g and Rp/Rs even when only one transit event has been observed. This makes it possible to study the physical properties of small planets which are difficult to characterize by other methods. In addition, we demonstrate how our method can be used to detect false positives among planet candidates detected by the transit method. Finally, we apply our method to two well-studied systems, HD 209458 b and WASP-12 b, and find good agreement between our results and previous determinations. \n \n Keywords: Extrasolar planet - Surface gravity",
        "watermark_text": "We present an algorithm to estimate directly the surface gravity ( log g ) and radius ratio ( Rp / Rs ) of transiting exoplanets using high - precision photometry obtained with space - based observatories such as CoRoT , Kepler or Spitzer . The proposed methodology is based on the determination of the transit duration in different passbands .We see that this new approach allows us to obtain precise measures of log g and Rp / Rs even when only one transit event has been observed . This gives it able to study the physical properties of tiny planets which are hard to characterize by other methods .In addition , we prove how our technique can be used to identify false positives among planet candidates detected by the transit method . Finally , we apply our technique to two good - investigated systems , HD 209458 b and WASP - 12 b , and find good agreement between our findings and previous determinations .Keywords : Extrasolar planet - Surface gravity",
        "ori-fast-z-score": 0.47809144373375745,
        "water-fast-z-score": 4.302822993603817
    },
    {
        "original_text": "The TACTIC (Telescope Array for Cosmic Triggered Events) is an imaging atmospheric Cherenkov telescope located in Namibia at the site of the HESS experiment, and it was designed to detect gamma rays with energies between 100 GeV and 10 TeV. The camera consists of 960 photomultiplier tubes arranged on a hexagonal grid covering a field-of-view of 3 degrees diameter. It has been taking data since March 2009. In this work we present results obtained by applying different analysis techniques to the first two years of data taken with the TACTIC telescope. We show that these analyses are able to reconstruct events with high efficiency over most of the energy range covered by the instrument. Finally, we compare our results with those published by other experiments operating in similar energy ranges. This article is part of the themed issue  The Universe as seen by ground-based gamma-ray telescopes . Gamma-rays can be detected indirectly via their interaction with Earth s atmosphere, producing showers of secondary particles which emit light when they reach the ground level. These so-called air-shower photons can then be observed using large optical detectors such as imaging atmospheric Cherenkov telescopes (IACTs). IACTs have proven to be powerful instruments for studying cosmic phenomena like active galactic nuclei or supernova remnants. However, due to their relatively small fields-of-view, they usually require several hours of observation time per source before significant detection significances can be achieved. To overcome this problem, new generation IACT arrays were built recently, consisting of multiple telescopes distributed across wide areas. One example is the High Energy Stereoscopic System (H.E.S.S.)  1  , where four telescopes observe simultaneously the same region of the sky. Another one is the Telescope Array for Cosmic Triggerd Events (TACTIC), which will consist of eight telescopes spread out over a distance of about 1 km  2  .",
        "watermark_text": "The TACTIC ( Telescope Array for Cosmic Triggered Events ) is an imaging atmospheric Cherenkov telescope located in Namibia at the location of the HESS program , and it was built to identify gamma radiation with energies between 100 GeV and 10 TeV . The camera consists of 960 photomultiplier frames arranged on a hexagonal grid covering a field - of - view of 3 degrees diameter .It has been took results since March 2009 . In this project we present results acquired by using different analysis methods to the first two years of evidence carried with the TACTIC telescope .We see that these calculations are able to reconstruct events with high efficiency over most of the power range covered by the instrument . Finally , we compare our findings with those published by other experiments working in related energy intervals .This page is part of the themed article The Universe as shown by ground - based gamma - ray telescopes . Gamma - radiation can be emitted indirectly via their contact with Earth s atmosphere , creating showers of secondary particles which emit light when they reach the ground level .These so - called air - shower photons can then be viewed using big optical detectors such as imaging atmospheric Cherenkov telescopes ( IACTs ) . IACTs have proven to be powerful devices for studying cosmic phenomena like active galactic nuclei or supernova remnants .However , owing to their extremely tiny areas - of - view , they generally need multiple hours of observation time per source before significant detection significances can be obtained . To solve this situation , new generation IACT arrays were built recently , consisting of multiple telescopes distributed across wide areas .One case is the High Energy Stereoscopic System ( H . E . S . S . ) 1 , where four telescopes observe simultaneously the same region of the heavens .Another one is the Telescope Array for Cosmic Triggerd Events ( TACTIC ) , which will include of eight telescopes distributed out over a distance of about 1 km 2 .",
        "ori-fast-z-score": -0.3508232077228117,
        "water-fast-z-score": 7.60122529295103
    },
    {
        "original_text": "The MCHIT (Monte Carlo Heavy Ion Transport) code is an advanced tool to simulate the transport of ions in matter, including their interactions with target nuclei as well as elastic scattering off atomic electrons. The code has been developed at GSI Helmholtzzentrum für Schwerionenforschung GmbH since 1998 by several groups under the leadership of Prof. Dr. Jens B. Skarsgard. \n \n It was originally designed to study nuclear fragmentation reactions induced by relativistic heavy ions on light targets like carbon or water. In recent years it has also been used successfully to investigate other topics such as: \n \n \n \n • Radiation damage in biological tissues due to ion beam irradiation \n \n • Secondary particle production in hadronic showers \n \n • Energy deposition in materials exposed to high-energy cosmic rays \n \n • Nuclear reaction cross sections for astrophysical applications \n \n • Hadrontherapy treatment planning",
        "watermark_text": "The MCHIT ( Monte Carlo Heavy Ion Transport ) code is an specialized tool to simulate the movement of atoms in material , particularly their interactions with target nuclei as well as elastic scattering off atomic electrons . The code has been created at GSI Helmholtzzentrum für Schwerionenforschung GmbH since 1998 by many groups under the leadership of Prof . Dr . Jens B . Skarsgard .It was originally intended to study nuclear fragmentation reactions generated by relativistic heavy ions on light sites like nitrogen or water . In past decades it has additionally been used successfully to examine other topics such as : • Radiation injury in biological tissues resulting to ion beam irradiation • Secondary particle production in hadronic showers • Energy deposition in structures exposed to large - energy cosmic rays • Nuclear reaction cross sections for astrophysical applications • Hadrontherapy control planning",
        "ori-fast-z-score": 0.254000254000381,
        "water-fast-z-score": 6.096006096009144
    },
    {
        "original_text": "We study the orbital evolution of planets in binaries under the effect of gravitational perturbations due to third bodies, which can lead to large eccentricities and inclinations for both components of the system. We show that this mechanism is able to explain some observed properties of extrasolar systems such as HD 169830 or Kepler-16. In particular we find that it may be responsible for the formation of hot Jupiters through planet-planet scattering processes. The main results are summarized below: \n1) We present an analytical model describing the long-term evolution of the semi-major axes (a), eccentricities (e), and mutual inclination angles (i) of two orbiting objects under the combined effects of general relativity, tides, and secular interactions between all three bodies. \n2) Using our model, we perform numerical integrations of several representative cases showing how the presence of additional perturbative forces can significantly modify the orbital parameters of the innermost body over time-scales ranging from millions up to billions of years. \n\n3) We apply our model to the case of the exoplanetary system around HD 169830 composed of four giant planets on highly inclined orbits. Our calculations suggest that the current architecture of this system could have been produced by successive scatterings among its planets triggered by strong gravitational encounters with other massive bodies located at distances larger than 100 AU. \n \n 4) Finally, we explore the possibility that the recently discovered transiting super-Earths in the Kepler-16 system might also have formed via similar mechanisms.",
        "watermark_text": "We research the orbital evolution of planets in binaries under the impact of gravitational perturbations due to third body , which can lead to large eccentricities and inclinations for both components of the system . We suggest that this mechanism is could to explain some observed properties of extrasolar systems such as HD 169830 or Kepler - 16 .In particular we find that it could be responsible for the formation of bright Jupiters through moon - planet scattering mechanisms . The main results are presented below : 1 ) We present an analytical theory explaining the long - term evolve of the semi - major axes ( a ) , eccentricities ( e ) , and mutual inclination angles ( i ) of two orbiting objects under the combined influences of general relativity , tides , and secular interactions between all three bodies .2 ) Using our model , we perform numerical integrations of several representative cases showing how the presence of added perturbative stresses can significantly change the orbital variables of the innermost bodies over time - scales extending from hundreds up to billions of years . 3 ) We use our model to the case of the exoplanetary structure around HD 169830 composed of four giant planets on highly inclined planets .Our calculations suggest that the present architecture of this scheme may have been created by successive scatterings among its planets triggered by intense gravitational encounters with other large bodies located at distances bigger than 100 AU . 4 ) Finally , we investigate the suggestion that the recently discovered transiting super - Earths in the Kepler - 16 system might also have formed via related pathways .",
        "ori-fast-z-score": 0.5570860145311556,
        "water-fast-z-score": 7.056422850727971
    },
    {
        "original_text": "We present an analysis of the probability that supernovae enrich protoplanetary disks with heavy elements, and discuss its implications for planet formation theory. We find that this process is likely to occur in most cases where stars are formed within clusters containing massive stars (>8 Msun). In these environments, we estimate that about half of all solar-type stars will be enriched by at least one supernova event during their disk lifetimes. This result has important consequences on our understanding of how planets form around metal-rich stars. The discovery of extrasolar giant planets orbiting metal-rich stars suggests that planet formation may be more efficient when the host star s metallicity is high. However, it remains unclear whether such planets can also form around low-mass stars like the Sun. Recent theoretical studies suggest that planetesimal accretion onto growing planetary embryos could be inhibited if the gas surrounding them contains too much dust or ice particles produced by collisions between larger bodies. If so, then the efficiency of core growth would decrease as the amount of solids increases beyond some critical value.",
        "watermark_text": "We present an assessment of the probability that supernovae enrich protoplanetary disks with heavy components , and consider its consequences for planet development hypothesis . We see that this process is probably to arise in most instances where stars are created within clusters housing massive stars ( > 8 Msun ) .In these habitats , we estimate that about half of all solar - class stars will be enriched by at least one supernova event during their disk lifetimes . This result has significant implications on our knowing of how planets form around metal - rich stars .The observation of extrasolar giant planets orbiting metal - rich stars suggests that planet development possibly be more efficient when the host star s metallicity is high . However , it remains unsure whether such planets can also formation around low - density stars like the Sun .Recent conceptual research suggest that planetesimal accretion onto growing planetary embryos might be inhibited if the gas covering them contains too enough snow or ice particles generated by collisions between larger body . If so , then the ability of core growth would decrease as the quantity of solids increases beyond some essential value .",
        "ori-fast-z-score": -1.3779972440082682,
        "water-fast-z-score": 5.405989188032437
    },
    {
        "original_text": "We propose to use thermal noise as the information carrier for totally secure communications, zero power consumption devices, and computing systems. We show that by using an appropriate detection scheme, we can extract digital bits from the thermal noise with high fidelity at room temperature. The proposed system is based on a single-electron transistor (SET) which has been demonstrated in experiments recently. In addition, we demonstrate how this SET-based device can be used to perform logic operations such as AND gate and NOT gate. Finally, we discuss possible applications of our proposal including quantum key distribution, ultra-low power sensor networks, and energy efficient data centers. This work was supported by NSF under Grant No. ECCS-0926491. A new paradigm called  thermal noise informatics  is introduced where thermal noise is utilized as the information carrier for various tasks ranging from totally secure communication over wires to zero-power communication and computation. By employing an appropriate detection scheme, it is shown that one can extract digital bits from thermal noise with high fidelities even at room temperatures. It is also shown that these extracted digital bits can be used to perform logical operations such as AND gates and NOT gates. Possible applications are discussed along with their advantages compared to existing technologies.",
        "watermark_text": "We suggest to use thermal noise as the information carrier for totally secure services , zero power consumption devices , and computing systems . We see that by using an appropriate detection system , we can extract digital bits from the thermal noise with high fidelity at room temperature .The proposed system is based on a single - ion transistor ( SET ) which has been shown in experiments recently . In addition , we prove how this SET - based device can be used to conduct logic events such as AND gate and NOT gate .Finally , we review possible users of our proposal including molecular key transmission , ultra - low power detector networks , and energy effective data systems . This project was supported by NSF under Grant No .ECCS - 0926491 . A different technology called temperature noise informatics is adopted where thermal noise is utilized as the information carrier for various jobs ranging from completely secure transmission over wires to zero - energy transmission and computation .By using an appropriate detection system , it is demonstrated that one can extract digital bits from temperature noise with high fidelities even at room temperatures . It is also shown that these obtained digital frames can be used to conduct logical functions such as AND doors and NOT gates .Possible products are discussed along with their benefits compared to existing technologies .",
        "ori-fast-z-score": 1.3987572123604708,
        "water-fast-z-score": 8.541985556144386
    },
    {
        "original_text": "We report the first experimental observation of environmental dielectric screening (EDS) effects on optical transitions between different electronic states in individual semiconducting single-wall carbon nanotubes (SWCNTs). We show that EDS can be used to tune the emission energy and linewidths of SWCNT photoluminescence, which is important for applications such as optoelectronic devices based on these materials. \n \n The observed changes are explained by considering how the local environment affects the electron-hole interaction strength through its influence on the dielectric constant at the position of each tube. This work provides new insights into the fundamental physics governing the properties of carbon nanotube-based systems. Carbon nanotubes have attracted considerable attention because they exhibit unique physical characteristics  1  . In particular, their one-dimensional structure leads to interesting phenomena not found in bulk or two-dimensional materials  2  , including quantum confinement  3  , ballistic transport  4  , and strong light-matter interactions  5  .\nIn addition, recent advances in chemical synthesis techniques  6  allow us to produce high-quality samples with controlled chiralities  7, 8  . These developments make it possible to study the intrinsic properties of carbon nanotubes without being affected by extrinsic factors  9  . However, despite this progress, there remain many open questions about the basic physics underlying carbon nanotube behavior  10  . For example, although theoretical studies predict that the band gap should depend strongly on the diameter  11  , experiments have shown only weak correlations  12  . One reason may be that the actual diameters of synthesized tubes often differ significantly from those predicted theoretically  13  . Another possibility is that the surrounding medium plays an important role  14  . Indeed, previous works have demonstrated that the presence of surfactants  15  , solvent molecules  16  , and water  17  can affect the optical properties of carbon nanotubes  18  .",
        "watermark_text": "We report the first laboratory measurement of environmental dielectric screening ( EDS ) impacts on electronic transitions between various electronic states in individual semiconducting single - wall carbon nanotubes ( SWCNTs ) . We see that EDS can be used to balance the emission intensity and linewidths of SWCNT photoluminescence , which is important for applications such as optoelectronic devices based on these materials .The observed changes are explained by examining how the local conditions influences the electron - hole collision strength through its influence on the dielectric constant at the position of each tube . This research provides new understanding into the fundamental theory controlling the properties of carbon nanotube - based systems .Carbon nanotubes have garnered considerable scrutiny because they demonstrate unique physical qualities 1 . In particular , their one - dimensional shape contributes to unusual phenomena not found in bulk or two - dimensional materials 2 , notably quantum confinement 3 , ballistic transport 4 , and strong dark - matter interactions 5 .In addition , recent developments in chemical production method 6 allow us to produce high - grade samples with safe chiralities 7 , 8 . These advances give it able to study the intrinsic characteristics of carbon nanotubes without being affected by extrinsic factors 9 .However , despite this progress , there remain many open questions about the fundamental theory surrounding carbon nanotube behavior 10 . For instance , although conceptual research predict that the band gap should depend greatly on the diameter 11 , researchers have shown only weak correlations 12 .One reason could be that the actual diameters of synthesized tubes often differ significantly from those predicted theoretically 13 . Another possibility is that the nearby medium contributes an important role 14 .Indeed , previous works have demonstrated that the presence of surfactants 15 , solvent molecules 16 , and water 17 can affect the optical properties of carbon nanotubes 18 .",
        "ori-fast-z-score": 1.7320508075688774,
        "water-fast-z-score": 8.601935165449925
    },
    {
        "original_text": "We propose that galactic dark matter is an effective four-dimensional manifestation of extra dimensions, and we show how this can be realized in a simple model with one extra dimension compactified on S 1 /Z 2 . The fifth dimension has two 3-branes at its endpoints which are connected by a bulk scalar field. We find that the scalar field develops a kink profile along the fifth dimension due to the presence of a potential barrier between the two branes. This leads to a localized mass term for fermions living on the visible (3-)brane, which gives rise to a phenomenologically viable dark matter candidate. In addition, there exists another class of particles called Kaluza-Klein modes whose masses depend on the size of the extra dimension. These KK states have no tree-level interactions with Standard Model fields but they may contribute significantly to loop processes such as neutrino oscillations or proton decay. Finally, we discuss possible experimental signatures of our scenario.",
        "watermark_text": "We suggest that galactic dark matter is an efficient four - dimensional manifestation of extra dimensions , and we prove how this can be realized in a simple model with one extra dimension compactified on S 1 / Z 2 . The fifth dimension has two 3 - branes at its endpoints which are connected by a bulk scalar field .We see that the scalar field becomes a kink profile along the fifth dimension owing to the presence of a potential barrier between the two branes . This leads to a localized mass term for fermions residing on the visible ( 3 - ) brane , which gives rise to a phenomenologically viable dark matter candidate .In addition , there exists another class of nuclei termed Kaluza - Klein modes whose masses vary on the size of the extra dimension . These KK states have no tree - level interactions with Standard Model fields but they may contribute greatly to loop processes such as neutrino oscillations or proton emission .Finally , we explain possible experimental signatures of our scenario .",
        "ori-fast-z-score": 0.6108472217815261,
        "water-fast-z-score": 3.8805700005813275
    },
    {
        "original_text": "We present Chandra observations of supernova (SN) 2004et, which is one of only two type IIp SNe ever observed in X-rays. The data were obtained on 2005 February 24-26 with the Advanced CCD Imaging Spectrometer (ACIS-S). We detect no significant emission above background at energies below 1 keV or above 8 keV; we therefore restrict our analysis to the range 1-8 keV. In this energy band, we find that the spectrum can be fit by an absorbed blackbody model with kT = 0.7 ± 0.1 keV and N H = 2.5 +1.0 −0.8 × 10 22 cm −2 . These values are consistent with those found for other type IIp SNe. Using these parameters as well as the distance inferred from optical photometry, we calculate the luminosity of SN 2004et during its first 100 days after explosion. This value agrees very well with theoretical predictions based upon models of stellar evolution.",
        "watermark_text": "We report Chandra measurements of supernova ( SN ) 2004et , which is one of only two class IIp SNe actually seen in X - radiation . The data were obtained on 2005 February 24 - 26 with the Advanced CCD Imaging Spectrometer ( ACIS - S ) .We detect no considerable emission above background at energies below 1 keV or above 8 keV ; we thus restrict our analysis to the range 1 - 8 keV . In this power band , we find that the spectrum can be fit by an absorption blackbody simulation with kT = 0 . 7 ± 0 . 1 keV and N H = 2 . 5 + 1 . 0 −0 . 8 × 10 22 mm −2 .These quantities are compatible with those observed for other class IIp SNe . Using these parameters as well as the distance inferred from optical photometry , we estimate the luminosity of SN 2004et during its initial 100 days after explosion .This value agrees very best with theoretical estimates based upon theories of stars evolution .",
        "ori-fast-z-score": -0.42008402520840293,
        "water-fast-z-score": 5.285714285714286
    },
    {
        "original_text": "We report on the growth and characterization of epitaxial La2/3Ca1/3MnO3-δ (LCMO) thin films grown on SrTiO3(001) (STO). The LCMO film thickness was varied between 5 nm to 50 nm, while keeping the substrate temperature fixed at 700 °C during deposition. We find that for thinner films there is an increase in oxygen deficiency as measured by XPS and XAS. This leads to a decrease in Curie temperature TC = 240 K down to 180 K with decreasing film thickness. In addition we observe a reduction in magnetization M0 below 20 nm which can be explained by the presence of a ferromagnetic dead layer near the interface. Using X-ray magnetic circular dichroim (XMCD), we show that this ferromagnetic dead layer has a net moment along the out-of-plane direction but no in-plane component. Finally, using soft x-ray resonant reflectivity measurements we demonstrate that the Mn valence state changes across the interface due to charge transfer into STO.",
        "watermark_text": "We report on the development and description of epitaxial La2 / 3Ca1 / 3MnO3 - δ ( LCMO ) thin sheets grown on SrTiO3 ( 001 ) ( STO ) . The LCMO movie length was changed between 5 nm to 50 nm , while maintaining the substrate temperature fixed at 700 °C during deposition .We see that for thinner films there is an increase in oxygen deficiency as measured by XPS and XAS . This leads to a reduction in Curie temperature TC = 240 K down to 180 K with decreasing film thickness .In addition we study a reduction in magnetization M0 below 20 nm which can be described by the presence of a ferromagnetic dead coating near the interface . Using X - ray magnetic spiral dichroim ( XMCD ) , we find that this ferromagnetic dead surface has a net moment along the out - of - plane path but no in - plane part .Finally , using soft x - ray resonant reflectivity surveys we prove that the Mn valence state changes across the interface due to charge transfer into STO .",
        "ori-fast-z-score": -0.5,
        "water-fast-z-score": 4.341215710622296
    },
    {
        "original_text": "We present the results of our CCD photometric study of 42 open clusters in the southern hemisphere, carried out at the 1-meter telescope of the South African Astronomical Observatory (SAAO). The observations were made with an SBIG STL-1001E camera equipped with a Kodak KAF-0400 chip and Johnson V filter during three observing runs between September 1998 and February 1999. We have used DAOPHOT II to perform aperture photometry on all stars detected within each cluster field-of-view. A total number of about 15000 stars was measured for each cluster. In addition we obtained UBVRI photometry for some of these clusters using the same instrumentation as described above.  From this data set we derived the following parameters: reddening E(B-V), distance modulus DM, age t, metallicity  Fe/H  , mass function slope x, core radius rc, central surface brightness µ0, concentration index c, and integrated absolute magnitude M.",
        "watermark_text": "We present the conclusion of our CCD photometric analysis of 42 open complexes in the southern hemisphere , conducted out at the 1 - meter telescope of the South African Astronomical Observatory ( SAAO ) . The images were made with an SBIG STL - 1001E camera equipped with a Kodak KAF - 0400 card and Johnson V filter during three observing runs between September 1998 and February 1999 .We have utilized DAOPHOT II to conduct aperture photometry on all stars observed within each cluster area - of - view . A total number of about 15000 stars was measured for each cluster .In addition we derived UBVRI photometry for some of these complexes use the same equipment as described above . From this data set we derived the following variables : reddening E ( B - V ) , distance modulus DM , age t , metallicity Fe / H , mass function slope x , core radius rc , central exterior brightness µ0 , concentration index c , and integrated absolute brightness M .",
        "ori-fast-z-score": -0.8962581595302719,
        "water-fast-z-score": 2.9448482384566077
    },
    {
        "original_text": "In this thesis, we study power control problems in cellular mobile radio systems with code division multiple access (CDMA). We consider the uplink scenario where each user transmits to its base station using an orthogonal spreading sequence and all users share the same frequency band. The objective is to minimize the total transmit power subject to individual quality-of-service constraints at each user s receiver. In order to obtain tractable results, we make use of tools from stochastic geometry which allow us to model the locations of both mobiles and interferers as point processes. Our main contributions are summarized below.  First, we derive closed-form expressions for the outage probability when the number of active users grows without bound. These expressions can be used to determine how many users can simultaneously communicate reliably over the network. Second, we propose distributed power control schemes that achieve these limits asymptotically under certain conditions. Third, we develop centralized power control algorithms that guarantee performance close to optimality even if only partial information about the channel gains or interference levels is available. Finally, we present simulation results illustrating our theoretical findings.",
        "watermark_text": "In this dissertation , we study control power problems in cell mobile radio circuits with code division multiple entry ( CDMA ) . We consider the uplink situation where each consumer transmits to its base station use an orthogonal spreading pattern and all users share the same frequency band .The goal is to minimize the total broadcast capacity related to individual quality - of - service restrictions at each consumer s receiver . In order to obtain tractable results , we make using of tools from stochastic geometry which allow us to model the places of both mobiles and interferers as point processes .Our main contributions are presented below . First , we derive closed - form expressions for the outage likelihood when the number of active usage rises without bound .These expressions can be used to predict how many users can independently connect reliably over the network . Second , we develop dispersed power control schemes that attain these limits asymptotically under certain conditions .Third , we develop concentrated control power methods that guarantee efficiency high to optimality even if only partial knowledge about the channel gains or interference concentrations is accessible . Finally , we present modeling results illustrating our theoretical results .",
        "ori-fast-z-score": 0.19802950859533489,
        "water-fast-z-score": 7.4
    },
    {
        "original_text": "We present results on searches for gravitational wave (GW) burst signals using data collected by the Laser Interferometer Gravitational-Wave Observatory during its fourth science run, which took place between September 2005 and January 2007. We use two different search methods to look for GW bursts: one based on matched filtering with template waveforms and another that uses an optimal filterbank method. The latter is used as part of a blind analysis where we do not know what type or strength of signal may be present in our data until after it has been analyzed. In addition to these analyses, we also perform several consistency checks designed to identify any problems associated with either detector s performance over this period. No significant candidates are found in any of these searches. Using simulated signals injected into the data at random times, we estimate upper limits on the rate density of binary black hole mergers detectable within a given range of total mass.",
        "watermark_text": "We report findings on investigations for gravitational wave ( GW ) burst signals using data amassed by the Laser Interferometer Gravitational - Wave Observatory during its fourth science run , which taken place between September 2005 and January 2007 . We use two different search methods to find for GW bursts : one based on paired processing with template waveforms and another that using an efficient filterbank method .The latter is utilized as part of a blind analysis where we do not understand what type or strength of signal might be found in our information until after it has been examined . In addition to these tests , we also perform several reliability measures designed to identify any problems involved with either detector s performance over this time .No meaningful candidates are found in any of these searches . Using simulated transmissions imported into the information at random times , we estimate upper limits on the rate concentration of binary dark hole mergers detectable within a given range of total mass .",
        "ori-fast-z-score": -1.1322770341445956,
        "water-fast-z-score": 4.98201895023622
    },
    {
        "original_text": "We report the discovery and characterization of XO-2b, an extrasolar planet transiting its host star (HD 149026) with a period of 3.2 days. The planet is a hot Jupiter with M = 1.3 MJup and R = 0.9 RJup orbiting at a distance of only 0.04 AU from HD 149026. We find that this system has a common proper motion companion separated by ~1′′.5. This companion was previously identified as a metal-rich subgiant based on high-resolution spectroscopy but had not been detected photometrically before our observations. Our analysis shows that the transit depth variation observed for XO-2b can be explained if we assume that the two stars are physically associated and have nearly identical radii. If true, then the mass ratio between these two stars should be close to unity. However, we cannot rule out other scenarios such as grazing eclipses or blending effects due to nearby field stars.",
        "watermark_text": "We report the discovery and description of XO - 2b , an extrasolar planet transiting its home star ( HD 149026 ) with a period of 3 . 2 days . The planet is a hot Jupiter with M = 1 . 3 MJup and R = 0 . 9 RJup orbiting at a distance of only 0 . 04 AU from HD 149026 .We see that this system has a common proper motion companion divided by ~ 1 ′ ′ . 5 . This companion was formerly identified as a metal - rich subgiant based on high - resolution spectroscopy but had not been detected photometrically before our observations .Our study shows that the transit size variation detected for XO - 2b can be described if we suppose that the two stars are visually associated and have nearly identical radii . If true , then the mass ratio between these two stars should be close to unity .However , we cannot rule out other scenarios such as grazing eclipses or mixing effects due to nearby field stars .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.5151005964822444
    },
    {
        "original_text": "We present an ab initio study of the electronic and magnetic structure of volborthite, CaFe3(PO4)2(OH)3·H2O (CFPOH), which is one of the most important minerals in geological sciences as it forms at low temperatures under hydrothermal conditions. Volborthite has been studied extensively by neutron scattering experiments but its microscopic origin remains controversial. We show that the ground state of CFPOH can be described within density functional theory using the generalized gradient approximation plus Hubbard U method for Fe-3d orbitals. The calculated spin wave spectrum agrees well with experimental data obtained by inelastic neutron scattering measurements. In addition we find that the magnetocrystalline anisotropy energy is dominated by spin-orbit coupling effects. Finally, we discuss how our results are related to previous theoretical studies based on different approximations. V olborthite, CaF e 3 (P O 4 ) 2 (OH) 3 ·H 2 O (C F P OH ), is one of the most impor-tant minerals in geological sciences because it forms at low tem-peratures under hydrothermal conditions  1  . It was first discovered in 1832  2  , however, only recently have detailed structural investigations revealed that this mineral belongs to the family of compounds known as  Kagome  materials  3  .\nVolborthite crystallizes into a layered structure consisting of alternating kagome planes of iron ions and phosphate groups  4  . This arrangement leads to interesting physical phenomena such as geometric frustration  5  or quantum fluctuations  6  . For example, recent neutron scattering experiments suggest that volborthite undergoes a phase transition below T N = 5 K  7, 8  where the spins order ferrimagnetically along the c-axis  9  . However, there exists no consensus about the nature of this ordering  10  : while some authors claim that the system orders collinearly  11, 12  others argue that non-collinearity plays an essential role  13, 14  .",
        "watermark_text": "We present an ab initio investigation of the electronic and magnetic shape of volborthite , CaFe3 ( PO4 ) 2 ( OH ) 3 · H2O ( CFPOH ) , which is one of the most important minerals in geological sciences as it exists at low temperatures under hydrothermal conditions . Volborthite has been studied frequently by neutron scattering experiments but its microscopic source remains disputed .We see that the ground state of CFPOH can be described within density functional theory using the generalized gradient algorithm plus Hubbard U method for Fe - 3d orbitals . The measured spin wave spectrum agrees well with theoretical data derived by inelastic neutron scattering observations .In addition we find that the magnetocrystalline anisotropy energy is dominated by spin - orbit bonding effects . Finally , we explain how our findings are related to previous conceptual research depending on various approximations .V olborthite , CaF e 3 ( P O 4 ) 2 ( OH ) 3 · H 2 O ( C F P OH ) , is one of the most impor - tant salts in geological sciences because it exists at low tem - peratures under hydrothermal conditions 1 . It was first discovered in 1832 2 , however , only lately have sophisticated structural investigations revealed that this mineral belongs to the group of compounds known as Kagome materials 3 .Volborthite crystallizes into a layered structure formed of alternating kagome planes of iron ions and phosphate groups 4 . This configuration leads to curious physical phenomena such as geometric instability 5 or quantum fluctuations 6 .For instance , recent neutron scattering experiments indicate that volborthite undergoes a phase shift below T N = 5 K 7 , 8 where the spins order ferrimagnetically along the c - axis 9 . However , there exists no consensus about the nature of this ordering 10 : while some writers claim that the scheme orders collinearly 11 , 12 others argue that non - collinearity plays an essential part 13 , 14 .",
        "ori-fast-z-score": 1.0606601717798212,
        "water-fast-z-score": 7.187587726270522
    },
    {
        "original_text": "We present the results for squark-antisquark, gluino-gluon and gaugino-gauge boson production at hadron colliders within the framework of non-minimal flavour violating supersymmetric models (NMFV). We consider both NMFV scenarios with MFV-like structure as well as those without it. In particular we study the impact on the decay branching ratios of neutralinos into leptons and quarks due to the presence of new sources of flavour violation beyond minimal supergravity. The latter are induced by the non-diagonal entries of the sfermion mass matrices which can be sizeable even if they are generated only radiatively. Our analysis is performed using an effective field theory approach where all heavy particles are integrated out except for the lightest neutral Higgs boson h0 and the Z-boson. This allows us to derive analytical expressions for the relevant amplitudes and cross sections.",
        "watermark_text": "We present the results for squark - antisquark , gluino - gluon and gaugino - gauge boson development at hadron colliders within the framework of non - reduced flavour violating supersymmetric theories ( NMFV ) . We consider both NMFV scenarios with MFV - like structure as well as those without it .In particular we study the impact on the decay branching ratios of neutralinos into leptons and quarks owing to the presence of new sources of flavour violation beyond minimal supergravity . The latter are induced by the non - diagonal entries of the sfermion mass matrices which can be sizeable even if they are produced only radiatively .Our study is conducted using an efficient field model approach where all heavy ions are integrated out except for the lightest neutral Higgs boson h0 and the Z - boson . This enables us to derive analytical expressions for the appropriate amplitudes and cross sections .",
        "ori-fast-z-score": -0.13736056394868904,
        "water-fast-z-score": 2.8845718429224694
    },
    {
        "original_text": "We consider the problem of scheduling multiple bag-of-work applications on parallel machines with non-cooperative tasks, where each task has its own deadline and budget constraints. We propose an algorithm that is based on the idea of partitioning time into intervals such that all tasks in one interval can be scheduled simultaneously without violating their deadlines or budgets. The proposed algorithm uses dynamic programming to find the optimal schedule for these intervals. Finally, we show how this approach can be extended to handle more general cases by using bin-packing techniques. Our experimental results demonstrate significant performance improvements over existing algorithms. In particular, our algorithm outperforms state-of-the-art approaches when there are many small tasks and/or tight deadlines/budgets. Keywords: Parallel computing, Computational complexity theory, Computational geometry, Data mining, Bioinformatics, High-performance computing, Grid computing, Cloud computing, Big data analysis, Distributed systems",
        "watermark_text": "We consider the question of scheduling multiple bag - of - job applications on parallel machines with non - cooperative tasks , where each work has its own deadline and funding limitations . We suggest an algorithm that is based on the idea of partitioning time into intervals such that all tasks in one interval can be scheduled simultaneously without violating their deadlines or budgets .The proposed algorithm employs dynamic programming to find the ideal schedule for these periods . Finally , we show how this methodology can be improved to treat more general instances by using bin - packing methods .Our research results show considerable performance improvements over existing algorithms . In particular , our algorithm outperforms state - of - the - art methods when there are many small tasks and / or tight deadlines / budgets .Keywords : Parallel computing , Computational complexity analysis , Computational topology , Data mining , Bioinformatics , High - performance computing , Grid computing , Cloud computing , Big data analysis , Distributed systems",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.798687035041354
    },
    {
        "original_text": "We present numerical results for the evolution of two different types of solar coronal mass ejection (CME) in an open magnetic field configuration, which is relevant to space weather applications. The first type of CMEs are driven by photospheric motions that generate Alfvén waves at the base of the corona; these waves propagate upward into the corona where they steepen into shocks. The second type of CMEs are triggered by flux rope instabilities associated with current sheets formed during reconnection events between closed loops and open fields lines. We find that both types of CMEs can accelerate plasma up to speeds exceeding 1000 km/s. However, only the first type of CMEs have significant density enhancements compared to their surroundings. In addition, we show that the first type of CME has a higher probability of producing geomagnetic storms than the second one because it contains more energetic particles. Finally, our results suggest that the first type of simulated CMEs may be responsible for some observed halo CMEs.",
        "watermark_text": "We present numerical findings for the evolution of two different kinds of thermal coronal mass ejection ( CME ) in an open magnetic field configuration , which is relevant to space weather uses . The first kinds of CMEs are driven by photospheric movements that produce Alfvén currents at the base of the corona ; these currents propagate eastward into the corona where they steepen into shocks .The second kind of CMEs are driven by flux rope instabilities associated with current sheets formed during reconnection events between locked loops and open fields lines . We see that both types of CMEs can accelerate plasma up to speeds exceeding 1000 kilometers / s .However , only the first class of CMEs have considerable density enhancements compared to their environment . In addition , we find that the first class of CME has a higher likelihood of creating geomagnetic winds than the second one because it contains more intense ions .Finally , our findings confirm that the first sort of simulated CMEs might be responsible for some observed halo CMEs .",
        "ori-fast-z-score": -0.9299811099505543,
        "water-fast-z-score": 6.1942248145051675
    },
    {
        "original_text": "We present detailed spectral analysis for the type Ib supernova (SN) 1999dn, which was discovered on September 28th in NGC 3184 by Maza et al. (1999) . The photometric evolution is well reproduced with an exponential decay law and we find that the light curve can be explained as being powered by radioactive 56Ni synthesized during explosive nucleosynthesis. We have analyzed optical spectra obtained at various epochs after explosion using non-LTE time-dependent radiative transfer calculations based on our new code STELLA. In this work, we show results for models without hydrogen lines. Our best-fit model has a total ejecta mass of about 18M⊙ , consisting mainly of helium and carbon-oxygen mixture. This result suggests that SN 1999dn may belong to the class of super-luminous SNe Ia. Keywords: Supernovae, Radiation hydrodynamics, Time dependent",
        "watermark_text": "We present detailed spectral study for the class Ib supernova ( SN ) 1999dn , which was discovered on September 28th in NGC 3184 by Maza et al . ( 1999 ) .The photometric evolution is well illustrated with an exponential decay law and we find that the light spiral can be described as being driven by radioactive 56Ni extracted during explosive nucleosynthesis . We have analyzed laser spectra obtained at numerous epochs after explosion employing non - LTE time - dependent radiative transfer calculations based on our new code STELLA .In this work , we show results for models without hydrogen lines . Our best - fit model has a total ejecta mass of about [UNK] , consisting mainly of helium and carbon - oxygen mixture .This result suggests that SN 1999dn may belong to the class of super-luminous SNe Ia.Keywords: Supernovae, Radiation hydrodynamics, Time dependent",
        "ori-fast-z-score": 0.2672612419124244,
        "water-fast-z-score": 3.2071349029490928
    },
    {
        "original_text": "We present an analysis of the stability of planetary systems in which protoplanetary embryos evolve under oligarchy, i.e., they are able to eject each other s neighbors by gravitational scattering but not themselves. We find that this process leads to rapid growth of the largest embryo until it reaches its isolation mass (the minimum mass required for runaway accretion). The system then evolves into either a single planet or two planets with comparable masses depending on how close the initial conditions were to instability. This evolution is very different than what happens when all bodies grow simultaneously; in particular, we show that there can be multiple stable outcomes even if the initial conditions are identical. Our results suggest that the formation of terrestrial planets may have proceeded through several stages including oligarchy before reaching their final state as observed today. In addition, our work provides new insights about the origin of Mercury-like planets. Protoplanetary embryos form in circumstellar disks around young stars and undergo mutual gravitational interactions during their growth phase. These interactions lead to orbital migration and dynamical instabilities such as collisions between neighboring embryos. If these processes occur frequently enough, only one body will survive at the end of the growth stage leaving behind a planetary system consisting of just one planet. However, recent studies indicate that many planetary systems contain more than one planet suggesting that some mechanism must exist to prevent complete destruction of the system. Here we study the possibility that protoplanetary embryos follow a hierarchical evolutionary path where they first grow hierarchically via gravitational scattering followed by runaway accretion once the largest embryo has reached its isolation mass. Using numerical simulations, we demonstrate that this scenario naturally explains the existence of multi-planet systems while also reproducing the properties of known exoplanets.",
        "watermark_text": "We present an assessment of the stability of planetary networks in which protoplanetary embryos grow under oligarchy , i . e . , they are able to eject each other s neighbors by gravitational scattering but not themselves . We see that this process results to rapid growth of the greatest embryo until it hits its isolation volume ( the minimum mass needed for runaway accretion ) .The system then evolves into either a single planet or two planets with similar masses depending on how close the early conditions were to instability . This evolution is very different than what happens when all bodies grow simultaneously ; in particular , we prove that there can be several stable outcomes even if the first conditions are matched .Our results show that the formation of terrestrial worlds may have continued through several stages including oligarchy before reaching their final condition as found today . In addition , our work offer additional information about the origin of Mercury - like planets .Protoplanetary embryos form in circumstellar disks around new stars and undergo mutual gravitational interactions during their development period . These interactions result to orbital movement and dynamical instabilities such as collisions between neighboring embryos .If these mechanisms occur frequently enough , only one body will survive at the end of the development period leaving behind a planetary system consisting of just one planet . However , recent studies demonstrate that several planetary complexes include more than one planet suggesting that some method may arise to resist total destruction of the system .Here we study the prospect that protoplanetary embryos continue a hierarchical evolutionary course where they originally grow hierarchically via gravitational waves followed by runaway accretion once the greatest embryo has reached its isolation volume . Using numerical simulations , we prove that this situation naturally explains the existence of dual - planet systems while actually reproducing the properties of known exoplanets .",
        "ori-fast-z-score": -0.8333333333333334,
        "water-fast-z-score": 7.166666666666667
    },
    {
        "original_text": "We study the magnetization dynamics driven by an alternating spin polarized current (ASPC) flowing through a magnetic tunnel junction with perpendicular anisotropy. We show that, depending on the amplitude of the ASPC, two different regimes can be observed experimentally: i) for small amplitudes, we observe a single frequency corresponding to the ferromagnetic resonance; ii) when increasing the amplitude of the ASCP, several frequencies are excited simultaneously leading to a complex spectrum which is analyzed using numerical simulations based on the Landau-Lifshitz-Gilbert equation including spin-transfer torque terms. The results obtained are discussed in connection with recent experiments performed at room temperature. \n \n PACS: 75.60.Cc, 76.30.+z, 77.20.Hs \n \n Spin transfer torques have been extensively studied both theoretically and experimentally during last years  1-3 . In particular, it has been shown that they induce precessional motion of the magnetization  4-6  as well as steady-state phenomena  7-9  such as domain-wall motion  10-12  or vortex core reversal  13-15 . These effects have attracted great interest due to their potential applications in novel devices like microwave oscillators  16  , logic elements  17  , memories  18  . However, most studies were focused on macroscopic systems where the magnetization was uniform over large distances. Recently, there has been growing interest in studying these effects in nanostructures  19-21  since this allows one to explore new physical properties associated with reduced dimensions  22  .\n \nIn this work, we focus our attention on the magnetization dynamics driven out of equilibrium by an alternating spin polarized Current (ASPC). This problem has already been addressed theoretically  23  but only few experimental works have been reported so far  24  . Here, we present detailed measurements carried out on a magnetic tunnel junction (MTJ), made of CoFeB/MgO/CoFeB layers grown by sputtering  25  . By applying an external field Hext along the hard axis of the MTJ, we obtain a perpendicularly magnetized system whose static properties are described elsewhere  26  . When",
        "watermark_text": "We research the magnetization dynamics generated by an alternating spin polarized current ( ASPC ) flowing through a magnetic tunnel connecting with transverse anisotropy . We see that , depending on the frequency of the ASPC , two different regimes can be experienced experimentally : i ) for large amplitudes , we perceive a single signal relating to the ferromagnetic resonance ; ii ) when reducing the frequency of the ASCP , various frequencies are excited simultaneously led to a complex spectrum which is evaluated using numerical simulations based on the Landau - Lifshitz - Gilbert formula featuring spin - transfer torque terms .The results collected are discussed in connection with recent experiments conducted at room temperature . PACS : 75 . 60 . Cc , 76 . 30 . + z , 77 . 20 . Hs Spin transfer torques have been heavily examined both theoretically and experimentally during last decades 1 - 3 .In particular , it has been shown that they cause precessional behavior of the magnetization 4 - 6 as well as continuous - phase phenomena 7 - 9 such as domain - wall motion 10 - 12 or vortex core reversal 13 - 15 . These effects have garnered great concern thanks to their potential applications in novel systems like microwave oscillators 16 , logic devices 17 , memories 18 .However , most studies were focused on macroscopic environments where the magnetization was uniform over large distances . Recently , there has been growing interest in investigating these phenomena in nanostructures 19 - 21 since this enables one to examine novel physical properties associated with decreased size 22 .In this research , we focus our focus on the magnetization dynamics caused out of equilibrium by an alternating spin polarized Current ( ASPC ) . This problem has already been addressed theoretically 23 but only few experimental works have been reported so recently 24 .Here , we present detailed observations carried out on a magnetic tunnel junction ( MTJ ) , made of CoFeB / MgO / CoFeB layers grown by sputtering 25 . By applying an external field Hext along the hard axis of the MTJ , we obtain a perpendicularly magnetized body whose dynamic characteristics are explained elsewhere 26 .When",
        "ori-fast-z-score": 0.34050261230349943,
        "water-fast-z-score": 8.342314001435737
    },
    {
        "original_text": "We consider the dynamics of stochastic interacting particle systems in which particles evolve according to an overdamped Langevin equation with multiplicative noise and interact via pair potentials that decay exponentially fast at large distances.  We prove that, under suitable conditions on the interaction potential, these models admit unique stationary states whose density profiles are given by solutions of nonlinear integral equations involving fractional powers of the Laplacian operator. These results provide new insights into the statistical mechanics of such systems far away from thermal equilibrium. Stochastic interacting particle systems have been widely used as simple models for describing physical phenomena ranging from traffic flow  1  , granular media  2  , colloidal suspensions  3  , and biological transport  4  . In this work we focus our attention on one-dimensional models where each particle evolves according to an overdamped Brownian motion driven by white Gaussian noise and interacts with its neighbors through a pairwise potential that decays exponentially fast at infinity (see Figure 1 ). The resulting system is described by the following set of Itô SDE s:",
        "watermark_text": "We consider the dynamics of stochastic interacting particle structures in which particles evolve according to an overdamped Langevin equation with multiplicative sound and interact via pair potentials that decay exponentially rapidly at large distances . We prove that , under suitable conditions on the interaction potential , these models admit unique stationary states whose density profiles are given by solutions of nonlinear integral equations involving fractional powers of the Laplacian operator .These data provide novel knowledge into the statistical mechanics of such systems distant distant from temperature equilibrium . Stochastic interacting particle networks have been widely using as simple models for describing physical phenomena ranging from street passage 1 , granular material 2 , colloidal suspensions 3 , and biological transport 4 .In this research we focus our focus on one - dimensional theories where each particle evolves due to an overdamped Brownian movement generated by white Gaussian interference and interacts with its friends through a pairwise potential that decays exponentially rapidly at infinity ( see Figure 1 ) . The resulting system is characterized by the following setting of Itô SDE s :",
        "ori-fast-z-score": -0.44172610429938614,
        "water-fast-z-score": 5.079850199442941
    },
    {
        "original_text": "We study the gravitational field equations for static spherically symmetric configurations on Randall-Sundrum type II brane-worlds with bulk cosmological constant and matter fields localized on the branes. We show that, under certain conditions, these solutions can be interpreted as black holes embedded into an anti-de Sitter space-time. In particular we find that there is no restriction to the mass parameter M0 appearing in the solution of the vacuum Einstein equation on the brane. The corresponding horizon radius r0 satisfies the relation r0 = (3M0/4π)1/3. This result implies that the Schwarzschild-de Sitter metric describes not only black hole but also naked singularity solutions. Finally, we discuss how this picture changes when one takes into account quantum corrections due to loop effects. PACS numbers: 04.20.-q; 11.10.Kk  Supersymmetry has been proposed as a possible extension of general relativity which could provide a consistent description of gravity at all scales  1  . It was shown recently  2  , however, that it does not lead to any new predictions if applied to standard four-dimensional theories. On the other hand, higher dimensional extensions of supergravity have attracted considerable attention during recent years  3  .\nIn this letter we consider five-dimensional supergravities  4  where the extra dimension is compactified on a circle  5  or orbifold  6  . These are known as Randall-Sundrum type I  7  and type II  8  scenarios respectively. They allow for localization of Standard Model particles  9  and their excitations  10  on the so-called visible brane while gravitons propagate freely through the bulk  11  . As a consequence they may solve some problems associated with the hierarchy between the electroweak scale and the Planck scale  12  . Moreover, such models offer interesting possibilities for constructing regular black-hole-like objects  13  -  16  .",
        "watermark_text": "We research the gravitational field equations for static spherically symmetric configurations on Randall - Sundrum type II brane - planets with bulk cosmological constant and material fields confined on the branes . We see that , under certain conditions , these solutions can be interpreted as black holes inserted into an anti - de Sitter space - time .In particular we find that there is no limitation to the mass vector M0 appearing in the solve of the vacuum Einstein integral on the brane . The corresponding horizon radius r0 satisfies the formula r0 = ( 3M0 / 4π ) 1 / 3 .This result suggests that the Schwarzschild - de Sitter metric encompasses not only black hole but also naked singularity solutions . Finally , we explain how this picture changes when one takes into consideration quantum corrections due to loop processes .PACS codes : 04 . 20 . - q ; 11 . 10 . Kk Supersymmetry has been proposed as a possible extension of general relativity which could give a consistent description of gravitational at all scales 1 . It was shown recently 2 , however , that it does not result to any new predictions if applied to standard four - dimensional theories .On the other hand , greater dimensional applications of supergravity have garnered considerable scrutiny during recent years 3 . In this letter we define five - dimensional supergravities 4 where the extra dimension is compactified on a ring 5 or orbifold 6 .These are known as Randall - Sundrum type I 7 and class II 8 scenarios respectively . They allow for localization of Standard Model particles 9 and their excitations 10 on the so - called visible brane while gravitons propagate continuously through the bulk 11 .As a consequence they may solve some problems identified with the ranking between the electroweak scale and the Planck scale 12 . Moreover , such theories offer useful possibilities for constructing ordinary black - hole - like structures 13 - 16 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.465790872963897
    },
    {
        "original_text": "We present the results of our kinematical study of globular clusters in M31, based on high-resolution spectroscopy obtained at the VLT and Keck telescopes. We find that all clusters studied show evidence for rotation around their major axes (with typical velocities of 100-200 km/s), while only two out of eight objects have significant internal velocity dispersions (of about 50-100 km/s). The remaining six clusters are consistent with being completely dispersionless systems. This is surprising given that these clusters contain large numbers of evolved stars belonging to extended horizontal branches. Our analysis shows that this apparent contradiction can be explained by assuming that most of the cluster mass resides outside the observed field-of-view. In addition we find that the majority of the clusters rotate counterclockwise when viewed along their minor axes. These findings suggest that many globular clusters may not be fully relaxed dynamical systems as previously thought. They also provide new insights into the formation history of globular clusters. \n \n Keywords: Kinematics",
        "watermark_text": "We present the conclusion of our kinematical study of globular complexes in M31 , using on wide - resolution spectroscopy acquired at the VLT and Keck telescopes . We see that all galaxies studied show proof for rotation around their major axes ( with typical velocities of 100 - 200 kilometers / s ) , while only two out of eight objects have considerable internal velocity dispersions ( of about 50 - 100 km / s ) .The remaining six complexes are compatible with being totally dispersionless systems . This is surprising given that these complexes include significant amounts of evolved stars belonging to advanced horizontal branches .Our study shows that this possible contradiction can be described by assuming that most of the cluster density resides outside the seen field - of - view . In addition we find that the majority of the clusters tilt counterclockwise when seen along their minor axes .These studies imply that several globular complexes may not be truly relaxed dynamical systems as previously thought . They also bring fresh insights into the formation history of globular complexes .Keywords: Kinematics",
        "ori-fast-z-score": -1.835325870964494,
        "water-fast-z-score": 6.1942248145051675
    },
    {
        "original_text": "The fossil record is replete with examples of periodic extinction events, but it has been unclear whether these are driven by external factors or internal dynamics within ecosystems. Here we show that biodiversity cycles can be generated solely through interactions between species and their environment without any need to invoke additional mechanisms such as mass extinctions. We use an agent-based model to simulate how communities evolve over time under different environmental conditions. Our results suggest that biodiversity cycles may have played an important role in shaping Earth s biosphere throughout its history. The fossil record contains numerous examples of periodic extinction events (1), which have led some researchers to propose that there must exist underlying periodicity in ecosystem processes (2). However, it remains unknown what causes this apparent regularity in the fossil record; one possibility is that periods of high diversity alternate with intervals during which many species go extinct simultaneously (3) (4) . In addition, it is not clear if all observed patterns of biodiversity cycling represent true cyclical behavior or simply reflect stochastic variation around a mean value (5-7).\nHere we present evidence suggesting that biodiversity cycles can arise spontaneously from ecological interactions alone, without requiring any additional mechanism like mass extinctions. To test our hypothesis, we used an agent-based model to explore how communities evolve over time when subjected to varying levels of environmental stress. This approach allowed us to examine how changes in community composition affect population abundances across multiple trophic levels. By simulating thousands of replicate runs using different parameter values, we were able to identify robust statistical signatures associated with biodiversity cycles.",
        "watermark_text": "The fossil history is replete with examples of periodic mortality events , but it has been uncertain whether these are driven by external influences or internal interactions within ecosystems . Here we show that biodiversity cycles can be formed solely through relationships between species and their environment without any necessity to invoke additional mechanisms such as mass extinctions .We use an agent - based model to simulate how communities evolve over time under various climate circumstances . Our results show that ecosystem cycles might have played an important role in shaping Earth s biosphere throughout its past .The fossil history provides various instances of periodic mortality events ( 1 ) , which have led some researchers to propose that there need arise inherent periodicity in ecological processes ( 2 ) . However , it remains obscure what causes this evident regularity in the fossil history ; one suggestion is that intervals of high diversity alternate with periods during which several species go extinct simultaneously ( 3 ) ( 4 ) .In addition , it is not clear if all observed patterns of biodiversity cycling constitute genuine cyclical behavior or simply reflect stochastic differences around a mean value ( 5 - 7 ) . Here we present evidence indicating that conservation cycles can arise spontaneously from ecosystem interactions alone , without using any additional process like mass extinctions .To study our theory , we using an agent - based model to examine how communities evolve over time when exposed to different amounts of environmental stress . This method allowed us to examine how variations in population composition impact population abundances across multiple trophic levels .By simulating thousands of replicate runs employing multiple parameter values , we were could to identify reliable statistical signatures identified with biodiversity cycles .",
        "ori-fast-z-score": 0.4123930494211613,
        "water-fast-z-score": 9.931270663228416
    },
    {
        "original_text": "We study vortex matter in honeycomb (HC) and kagome (KC) pinning arrays by using the time-dependent Ginzburg-Landau equation with periodic boundary conditions, which is solved numerically on square lattices with sizes up to L = 256. We find that HC and KC have different effects on vortex dynamics depending on their density n. For low densities, vortices are pinned at individual defects for both HC and KC; however, they form ordered structures only in HC but not in KC. At high densities, we observe two distinct phases in HC; one is a vortex molecular crystal state where all vortices occupy single sites, while another phase has a vortex plastic crystal structure where some vortices remain unpinned. In contrast, no such ordered states exist in KC even at very large defect densities. Our results suggest that the difference between HC and KC originates from the fact that the former can support more than one vortex per site whereas the latter cannot.",
        "watermark_text": "We explore vortex matter in honeycomb ( HC ) and kagome ( KC ) locking arrays by using the period - based Ginzburg - Landau equation with periodic border conditions , which is solution numerically on square lattices with sizes up to L = 256 . We see that HC and KC have different impacts on vortex dynamics depending on their density n . For low densities , vortices are glued at individual defects for both HC and KC ; however , they create ordered forms only in HC but not in KC .At high densities , we study two separate phases in HC ; one is a vortex molecular crystal state where all vortices occupy separate sites , while another phase has a vortex plastic crystal shape where some vortices remain unpinned . In comparison , no such ordered states arise in KC even at very big defect densities .Our results show that the difference between HC and KC originates from the fact that the former can support more than one vortex per site whereas the former cannot .",
        "ori-fast-z-score": -0.2581988897471611,
        "water-fast-z-score": 5.422176684690384
    },
    {
        "original_text": "We present an efficient algorithm to simulate the dynamics of nonlinear systems with arbitrary initial conditions and parameters using fast recursive filters (FRFs). The FRF is based on a linear combination of basis functions, which are obtained by solving a set of ordinary differential equations that represent the model under consideration. We show how this approach can be used in conjunction with standard numerical integration schemes such as Euler s method or Runge-Kutta methods to efficiently compute trajectories over large time intervals. In particular we demonstrate our approach on two examples, namely the Lorenz attractor and the FitzHugh-Nagumo neuron model. \nI. INTRODUCTIO N\nThe simulation of complex dynamical systems often requires the solution of sets of coupled ordinary differential equations (ODEs)  1  . For example, many models describing physical phenomena involve ODEs  2  , while other applications include chemical reactions  3  , population growth  4  , epidemiology  5  , neuroscience  6  , climate modeling  7  , etc.. However, even if these problems have been studied extensively  8  -  10  , there still exist several challenges associated with their computational treatment  11  .\nIn general, it is not possible to solve analytically the ODE system representing the problem at hand  12  . Therefore, one has to resort to approximate solutions  13  . These approximations may be obtained either numerically  14  or symbolically  15  . Numerical approaches typically rely on discretizing the continuous-time domain into small segments  16  . This leads to a discrete representation of the original system  17  , where each segment corresponds to a single state variable  18  . Symbolic techniques instead use polynomial expansions  19  , rational expressions  20  , or splines  21  to obtain an approximation of the exact solution  22  .",
        "watermark_text": "We create an efficient algorithm to simulate the dynamics of nonlinear systems with specified initial conditions and parameters utilizing fast recursive filters ( FRFs ) . The FRF is based on a linear mixture of basis variables , which are derived by solving a system of ordinary differential equations that represent the model under consideration .We see how this methodology can be used in partnership with typical numerical integration schemes such as Euler s method or Runge - Kutta methods to easily compute trajectories over large time periods . In particular we prove our approach on two examples , notably the Lorenz attractor and the FitzHugh - Nagumo neuron system .I . INTRODUCTIO N The modelling of complex dynamical systems often needs the solve of pairs of coupled ordinary differential equations ( ODEs ) 1 . For instance , many descriptions describing physical phenomena involve ODEs 2 , while other applications include chemical processes 3 , population development 4 , epidemiology 5 , neuroscience 6 , weather simulation 7 , etc . .However , even if these problems have been studied thoroughly 8 - 10 , there still arise many challenges associated with their mathematical treatment 11 . In general , it is not possible to solve analytically the ODE scheme representing the question at hand 12 .Therefore , one has to resort to approximate solutions 13 . These approximations might be obtained either numerically 14 or symbolically 15 .Numerical methods typically rely on discretizing the discrete - time domain into small sectors 16 . This leads to a discrete model of the original system 17 , where each segment corresponds to a single state variable 18 .Symbolic methods instead include polynomial expansions 19 , real equations 20 , or splines 21 to obtain an approximation of the exact solution 22 .",
        "ori-fast-z-score": -0.811502671200689,
        "water-fast-z-score": 6.7082039324993685
    },
    {
        "original_text": "We present an analysis of the observed properties of the rare, hot (T eff > 20 000 K), helium-rich subdwarf B (sdB) and extreme horizontal branch (EHB) stars in globular clusters that are known as red stragglers or blue hook stars.  We show how these objects can be explained by the merger of two helium white dwarfs with total mass exceeding the Chandrasekhar limit.   The resulting merged object is expected to have a radius larger than its Roche lobe at all stages during the merging process, which leads to stable mass transfer onto the companion star until it fills its Roche lobe and starts overflowing.   This results in a common envelope phase where most of the orbital energy released is used to eject the outer layers of both stars into space.   After this stage, the system consists of a naked helium core surrounded by a thin hydrogen layer on top of the helium core.   If the initial masses of the progenitor white dwarf components were close enough together such that their cores merge before they reach the Chandrasekhar mass, then we expect the final product to resemble a normal sdB star; if not, then the final product will be more massive than the Chandrasekhar",
        "watermark_text": "We present an assessment of the known characteristics of the rare , hot ( T eff > 20 000 K ) , helium - rich subdwarf B ( sdB ) and extreme horizontal branch ( EHB ) stars in globular complexes that are known as red stragglers or blue hook galaxies . We see how these objects can be described by the merger of two helium white dwarfs with total mass exceeding the Chandrasekhar limit .The resulting merged object is expected to have a diameter greater than its Roche lobe at all phases during the merging process , which results to continuous weight transfer onto the companion star until it fills its Roche lobe and starts overflowing . This results in a common envelope phase where most of the orbital heat released is utilized to eject the exterior layers of both stars into space .After this phase , the system consists of a naked helium core flanked by a thin hydrogen layer on top of the helium core . If the first masses of the progenitor white dwarf components were close enough together such that their cores merge before they reach the Chandrasekhar mass , then we expect the finished result to resemble a normal sdB star ; if not , then the finished result will be more massive than the Chandrasekhar",
        "ori-fast-z-score": 1.7056057308448833,
        "water-fast-z-score": 5.5432186252458715
    },
    {
        "original_text": "We present the results of an analysis of the clustering properties of luminous red galaxies (LRGs) in the Sloan Digital Sky Survey Data Release 7 (SDSS DR7). We use a sample of 380,000 LRGs selected to have 0.4 < zphot < 1.0 and Mr < --21.5 + 5logh. The angular correlation function is measured for this sample using the Landy & Szalay estimator on scales between 10  and 100 . To account for redshift space distortions we measure the projected cross-correlation functions wp(rp), where rp = Dproj/ H(z)/H0 , H(z) is the Hubble parameter at redshift z, and H0 is its value today. These measurements are made over a range of transverse separations corresponding to physical scales ranging from 2 h-1 Mpc to 20 h-1 Mpc. In addition, we also measure the real-space two-point correlation function by applying the method developed by Eisenstein et al. (2007) . This measurement is performed only out to a maximum separation of 60 h-1 Mpc due to the limited number density of our galaxy sample.",
        "watermark_text": "We publish the conclusion of an assessment of the clustering behavior of luminous red objects ( LRGs ) in the Sloan Digital Sky Survey Data Release 7 ( SDSS DR7 ) . We use a sample of 380 , 000 LRGs chosen to have 0 . 4 < zphot < 1 . 0 and Mr < - - 21 . 5 + 5logh .The angular correlation function is measured for this specimen using the Landy & Szalay estimator on scales between 10 and 100 . To account for redshift space distortions we measure the projected cross - correlation functions wp ( rp ) , where rp = Dproj / H ( z ) / H0 , H ( z ) is the Hubble parameter at redshift z , and H0 is its value today .These measurements are produced over a range of transverse separations corresponding to physical scales ranging from 2 h - 1 Mpc to 20 g - 1 Mpc . In addition , we also measure the real - space two - point coupling function by using the method developed by Eisenstein et al .( 2007 ) . This measurement is conducted only out to a maximum separation of 60 h - 1 Mpc owing to the limited number density of our galaxy sample .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.302003302004953
    },
    {
        "original_text": "We introduce the concept of generalized conditional random fields (GCRFs) and show how they can be used to model arbitrary probability distributions over structured data sets, such as sequences or trees.  We present an efficient algorithm for learning GCRF parameters using gradient descent on the log-likelihood objective function.   Finally we demonstrate that our approach is able to learn accurate models for several challenging sequence labeling tasks including part-of-speech tagging in natural language processing and protein secondary structure prediction in bioinformatics. Conditional Random Fields (CRFs) (Lafferty et al., 2001 ) are undirected graphical models which have been successfully applied to many problems involving sequential data, e.g. (Sha & Pereira, 2003) . In this work, we propose Generalized Conditional Random Fields (GCRFs), a generalization of CRFs which allows us to represent any distribution over structured data sets like sequences or trees. The key idea behind GCRFs is to use a set of latent variables to capture dependencies between different parts of the input space. This enables us to efficiently compute the partition function required by standard CRFs with dynamic programming techniques. Furthermore, it also makes it possible to train GCRFs using gradient-based methods similar to those employed for Maximum Entropy Markov Models (MEMMs). To evaluate the performance of our method, we apply it to two important applications: part-of-speech taggin",
        "watermark_text": "We introduce the idea of generalized conditional random fields ( GCRFs ) and explain how they can be used to model arbitrary likelihood distributions over structured data sets , such as sequences or trees . We introduce an efficient algorithm for learning GCRF variables using gradient descent on the log - likelihood objective function .Finally we prove that our approach is ability to acquire precise models for numerous challenging gene labeling challenges including whole - of - voice tagging in natural language processing and protein secondary structure prediction in bioinformatics . Conditional Random Fields ( CRFs ) ( Lafferty et al . , 2001 ) are undirected numerical models which have been successfully applied to many difficulties involving sequential data , e . g .( Sha & Pereira , 2003 ) . In this research , we propose Generalized Conditional Random Fields ( GCRFs ) , a generalization of CRFs which allows us to model any distribution over structured data sets like sequences or trees .The main idea behind GCRFs is to use a setting of latent variables to capture dependencies between various parts of the input space . This enables us to easily compute the partition function required by traditional CRFs with dynamic programming tools .Furthermore , it also makes it able to train GCRFs using gradient - based methods similar to those utilized for Maximum Entropy Markov Models ( MEMMs ) . To assess the performance of our technique , we apply it to two essential applications : whole - of - voice taggin",
        "ori-fast-z-score": -0.4833682445228318,
        "water-fast-z-score": 6.735753140545634
    },
    {
        "original_text": "We present an analysis of satellite galaxies, fossil groups (FGs), and galaxy clusters in the Millennium Run simulation. We find that FGs are rare objects with only 0.5% of all halos being classified as such at z=0. The number density of FGs is consistent with observations for systems with Mvir>1013M⊙/h. However, we also find that there exists a population of low-mass FGs which have not been observed yet but may be detectable by future surveys. In addition to their rarity, FGs show several other interesting properties compared to normal galaxy clusters: they tend to reside in more massive dark matter haloes than normal galaxy clusters; they contain fewer bright central galaxies; and they exhibit higher velocity dispersions. These results suggest that FGs can provide important constraints on models of galaxy formation and evolution. This work was supported by NASA grant NAG5-10842.",
        "watermark_text": "We present an assessment of satellite galaxies , fossil bands ( FGs ) , and galaxy regions in the Millennium Run simulation . We see that FGs are scarce objects with only 0 . 5 % of all halos being designated as such at z = 0 .The number density of FGs is consistent with observations for systems with Mvir > [UNK] / h . However , we also find that there exists a population of low - mass FGs which have not been observed yet but may be detectable by future surveys .In addition to their rarity , FGs exhibit several other remarkable attributes relative to normal star clusters : they tend to live in more massive bright matter haloes than regular galaxy clusters ; they contain fewer bright central clusters ; and they show superior velocity dispersions . These data suggest that FGs can provide important restrictions on predictions of galaxy formation and evolution .This project was supported by NASA gift NAG5 - 10842 .",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 5.578319375835658
    },
    {
        "original_text": "We present an atlas of the circumnuclear region (CNR) of 75 nearby active galactic nuclei observed by Hubble Space Telescope s Advanced Camera for Surveying program, which is part of the Nearby Galaxies Survey Treasury project. The CNRs are defined as the brightest central 2 kpc diameter circular aperture centered on each galaxy nucleus and were imaged using the F330W filter to select emission lines at wavelengths longer than 3000 Å . We use these data to study the properties of the nuclear starbursts that power the AGNs through their effects on the surrounding interstellar medium. In addition we examine how the physical conditions within the CNRs vary among different types of AGN activity.  We find that the majority of our sample have significant UV excesses over what would be expected based solely on stellar photospheric emission. This excess can be explained either by hot young stars or by dust extinction. For those objects where both optical spectroscopy and infrared imaging exist, we show that the UV excess is due primarily to dust extinction rather than hot young stars.",
        "watermark_text": "We present an atlas of the circumnuclear zone ( CNR ) of 75 nearby active galactic nuclei seen by Hubble Space Telescope s Advanced Camera for Surveying project , which is part of the Nearby Galaxies Survey Treasury project . The CNRs are specified as the brightest central 2 kpc diameter circular aperture located on each galaxy nucleus and were imaged using the F330W filter to select emission lines at wavelengths greater than 3000 Å .We use these information to study the properties of the atomic starbursts that fuel the AGNs through their impacts on the nearby interstellar material . In addition we investigate how the physical conditions within the CNRs vary among different kinds of AGN activity .We see that the majority of our sample have considerable UV excesses over what would be anticipated based primarily on stellar photospheric emission . This excess can be explained either by hot early stars or by dust disappearance .For those objects where both optical spectroscopy and infrared imaging exist , we find that the UV excess is due primarily to dust extinction rather than hot young stars .",
        "ori-fast-z-score": -0.6974858324629157,
        "water-fast-z-score": 4.184914994777494
    },
    {
        "original_text": "We present results on the role played by the rho meson in describing pion electroproduction data obtained with the CLAS detector at Jefferson Lab (JLab). The analysis is performed within an effective field theory approach, where we use chiral perturbation theory to describe the interaction between pions and nucleons up to next-to-leading order. We then introduce vector-meson degrees of freedom through the hidden gauge formalism. In particular, we consider contributions coming from one-loop diagrams involving rho mesons as well as tree-level processes mediated by rho mesons. Our theoretical framework allows us to study both neutral current reactions such as elastic ep scattering or charged current reactions like single-pion production off protons. Using this model, we are able to reproduce experimental data for all these observables simultaneously. Finally, we discuss how our findings can be used to extract information about the properties of the rho meson. This work was supported by the U.S. \n\n\nDepartment of Energy under Contract No. DE-SC0012704.\n\nPACS numbers: 12.38.Mh",
        "watermark_text": "We report findings on the importance played by the rho meson in representing pion electroproduction measurements obtained with the CLAS detector at Jefferson Lab ( JLab ) . The investigation is conducted within an efficient field model approach , where we using chiral perturbation theory to explain the interaction between pions and nucleons up to next - to - leading order .We then introduce vector - meson degrees of liberty through the hidden gauge formalism . In particular , we treat contributions come from one - loop diagrams using rho mesons as well as tree - level processes induced by rho mesons .Our conceptual formulation enables us to study both neutral current reactions such as elastic ep scattering or charged current reactions like single - pion production off protons . Using this model , we are able to publish empirical data for all these observables simultaneously .Finally , we talk how our findings can be used to extract information about the properties of the rho meson . This research was supported by the U . S . Department of Energy under Contract No .DE - SC0012704 . PACS numbers : 12 . 38 . Mh",
        "ori-fast-z-score": -0.9701425001453319,
        "water-fast-z-score": 4.695048270344999
    },
    {
        "original_text": "We report on Suzaku observations for four active galactic nuclei (AGNs) detected by Swift/BAT survey, which are classified as  obscured AGNs  with column density larger than 10 24 cm-2 . We found that all these sources show strong Fe K emission lines and their line widths are broader than those expected from thermal broadening at kT = 100 keV. The observed line profiles can be reproduced well by relativistic disk reflection models including Compton scattering effects. These results suggest that there is an additional component to the X-ray continuum other than the standard thin accretion disks around supermassive black holes. In addition, we find that the iron abundance relative to solar value is higher than 1.5 times in three out of four objects. This suggests that the central engines of these obscured AGNs may have been buried under heavy dusty torii. Finally, we discuss possible origins of this new type of buried supermassive black holes based on our observational results.",
        "watermark_text": "We report on Suzaku measurements for four active galactic nuclei ( AGNs ) detected by Swift / BAT search , which are classified as obscured AGNs with column height larger than 10 24 mm - 2 . We showed that all these sources show light Fe K emission lines and their line widths are larger than those expected from radiation broadening at kT = 100 keV .The observed line profiles can be reproduced well by relativistic disk absorption theories including Compton scattering effects . These data suggest that there is an additional element to the X - ray continuum other than the standard narrow accretion disks around supermassive black holes .In addition , we find that the metal density relative to solar value is higher than 1 . 5 times in three out of four objects . This implies that the main engines of these obscured AGNs might have been trapped under heavy dusty torii .Finally , we explain possible origins of this new kind of hidden supermassive black holes using on our observational results .",
        "ori-fast-z-score": 0.11867816581938533,
        "water-fast-z-score": 6.128258770283413
    },
    {
        "original_text": "We present new results on the distribution of loop widths in active regions observed by TRACE at 171 Å, using data obtained during solar maximum (May-June 2001). We find that loops with different temperatures have similar distributions of widths, which are well fitted by log-normal functions. The mean values of these distributions increase with temperature as expected for pressure equilibrium between plasma confined within magnetic structures and their surroundings. However, we also find that there is no significant difference between the widths measured along individual loops and those determined from averaged profiles over entire active regions. This suggests that the apparent constancy of loop widths may be due to averaging effects rather than being intrinsic properties of coronal structures. In addition, we show that the widths derived from observations made under different viewing angles do not depend significantly on the position angle of the line-of-sight relative to the direction perpendicular to the local magnetic field vector.",
        "watermark_text": "We report new data on the distribution of loop widths in active regions observed by TRACE at 171 Å , using data acquired during thermal maximum ( May - June 2001 ) . We see that loops with varying temperatures have similar distributions of widths , which are better fitted by log - normal functions .The mean estimates of these distributions increase with temperature as anticipated for pressure equilibrium between plasma confined within magnetic structures and their environment . However , we also find that there is no considerable difference between the widths calculated along individual loops and those estimated from averaged profiles over whole active regions .This implies that the apparent constancy of loop widths might be due to averaging influences rather than being intrinsic characteristics of coronal structures . In addition , we prove that the widths generated from measurements made under distinct observation angles do not depend greatly on the orientation angle of the line - of - view relative to the direction perpendicular to the local magnetic force vector .",
        "ori-fast-z-score": -0.4364357804719848,
        "water-fast-z-score": 4.939391699536065
    },
    {
        "original_text": "We have performed in-orbit focal adjustment (IFA) for the infrared camera onboard AKARI satellite using its own data taken in orbit. The IFA was carried out by comparing the observed point spread function (PSF) and that simulated based on ray tracing analysis, which is one of the most accurate methods to determine the best focus position. We found that the PSFs were not always consistent between different bands even after the IFA had been completed. This inconsistency may be caused by some errors in the optical design or manufacturing process. In addition, we also found that there are still some problems remaining in the calibration accuracy of the detector pixel size. These results will help us improve our understanding about the performance of the instrument as well as provide useful information for future space missions. Keywords: Space mission, Focal adjustment, Point spread function, Ray tracing analysis, Infrared astronomy, Infrared camera",
        "watermark_text": "We have done in - orbit lens adjustment ( IFA ) for the infrared camera onboard AKARI vehicle using its own signal taken in orbit . The IFA was carried out by comparing the seen point spread distribution ( PSF ) and that simulated based on ray tracing imaging , which is one of the most accurate ways to identify the best view point .We determined that the PSFs were not always compatible between various frequencies even after the IFA had been completed . This inconsistency may be caused by some failures in the optical design or manufacturing system .In addition , we also discovered that there are still some problems existing in the calibration reliability of the sensor pixel size . These data will assist us improve our knowing about the performance of the instrument as also as give valuable info for future orbital flights .Keywords : Space mission , Focal correction , Point spread value , Ray tracing investigation , Infrared astronomy , Infrared camera",
        "ori-fast-z-score": -0.8307471607356973,
        "water-fast-z-score": 6.052586456788652
    },
    {
        "original_text": "We present the first results on deep infrared (IR) observations with ISOCAM at 12 um, ISO at 15 um, ESO-VLT/VISIR at 11.7 um, and Spitzer/MIPS at 24 um in the Sculptor galaxy cluster field. The data are used to study the evolution of galaxies over the last 8 Gyrs as well as their contribution to the extragalactic background light (EBL). We find that the IR luminosity function evolves strongly between z=0.5-0.8 and today. At high redshifts we detect an excess number density of luminous infrared galaxies (LIRGs), ultraluminous infrared galaxies (ULIRGs), and active galactic nuclei (AGNs) compared to local samples. This is consistent with previous studies based on optical/NIR surveys. However, our sample contains only few objects which can be classified as LIRGs or ULIRGs using standard criteria. Instead, most sources show very large dust extinction values A(V)>10 mag. These sources have been missed so far because they were not detected in optical/NIR surveys due to heavy obscuration. In addition, we find evidence for a significant fraction of heavily extincted early-type galaxies among these sources.",
        "watermark_text": "We publish the first findings on dark infrared ( IR ) observations with ISOCAM at 12 um , ISO at 15 um , ESO - VLT / VISIR at 11 . 7 um , and Spitzer / MIPS at 24 um in the Sculptor galaxy cluster area . The data are using to study the evolution of galaxies over the last 8 Gyrs as also as their contribution to the extragalactic background light ( EBL ) .We see that the IR luminosity function evolves highly between z = 0 . 5 - 0 . 8 and today . At high redshifts we perceive an excess amount density of luminous infrared galaxies ( LIRGs ) , ultraluminous infrared galaxies ( ULIRGs ) , and active galactic nuclei ( AGNs ) compared to nearby samples .This is consistent with previous research based on laser / NIR surveys . However , our sample comprises only few objects which can be categorized as LIRGs or ULIRGs using conventional requirements .Instead , most sources show very huge dust extinction values A ( V ) > 10 mag . These sources have been missed so far because they were not observed in laser / NIR surveys due to heavy obscuration .In addition , we find proof for a substantial proportion of heavily extincted early - class galaxies among these sources .",
        "ori-fast-z-score": 0.22360679774997896,
        "water-fast-z-score": 4.919349550499537
    },
    {
        "original_text": "We present results on flame evolution during type Ia supernova (SN) explosions, based on two-dimensional hydrodynamic simulations with detailed nuclear reaction networks for both deflagrations and detonations. We find that the transition to detonation is triggered by shock-induced turbulent mixing at densities around 10$^{9}$ g/cm$^3$. The resulting detonation wave propagates through the entire white dwarf star within about 1 s after ignition. In this scenario, the observed light curve can be reproduced if we assume an initial central density of 2 x $10^8$ g/cm$^3$ or higher. For lower values of the central density, the explosion fails to produce enough 56Ni to explain observations. This work was supported by NASA grant NNX10AD03G. Keywords: Flame propagation, Hydrodynamics, Nuclear burning, Supernovae, White dwarfs. Subject headings: Nucleosynthesis",
        "watermark_text": "We report findings on flame evolution during type Ia supernova ( SN ) exploded , using on two - dimensional hydrodynamic simulations with comprehensive nuclear response systems for both deflagrations and detonations . We see that the shift to detonation is caused by shock - caused turbulent mixing at densities around 10 $ ^ { 9 } $ h / cm $ ^ 3 $ .The produced detonation radiation propagates through the entire white dwarf star within about 1 s after explosion . In this situation , the observed light curve can be reproduced if we suppose an initial central density of 2 x $ 10 ^ 8 $ h / cm $ ^ 3 $ or greater .For lower values of the central density , the explosion fails to produce enough 56Ni to explain observations . This research was supported by NASA grant NNX10AD03G .Keywords : Flame transmission , Hydrodynamics , Nuclear burning , Supernovae , White dwarfs . Subject headings : Nucleosynthesis",
        "ori-fast-z-score": -0.2672612419124244,
        "water-fast-z-score": 5.258758927213289
    },
    {
        "original_text": "We present an algorithm for generating new solutions to the coupled Einstein-scalar field equations, starting from vacuum solutions and adding scalar fields in such a way that the resulting solution is minimally coupled.  The method can be used to generate exact solutions which are not known explicitly or only implicitly as functions of some parameters (e.g., by solving algebraic equations). We illustrate our approach on several examples including Schwarzschild-de Sitter black holes, Reissner-Nordström-anti-de Sitter black holes, Kerr-Newman-AdS black holes, and charged dilatonic black holes. In particular we show how one can obtain explicit expressions for the massless limit of these black hole solutions. Our results may also have applications beyond gravity theory, e.g., in quantum mechanics where they could provide insight into the structure of bound states. Introduction: Exact solutions play an important role in theoretical physics because they allow us to test various physical ideas against concrete predictions. However, finding exact solutions to physically interesting problems often turns out to be very difficult. For example, it took more than 100 years after the discovery of general relativity before the first exact black hole solutions were found  1-3 . Even today there exist many open questions about black holes  4  . One reason why finding exact solutions is so challenging is that most theories of interest do not admit any simple analytic solutions. Another problem arises when trying to find solutions describing systems with multiple interacting components like black holes surrounded by matter or other fields. Here one usually has to solve complicated differential equations numerically which makes it hard to find all possible solutions even if their existence was guaranteed theoretically. This situation becomes particularly severe if one wants to study phenomena at strong coupling since then numerical methods become less reliable due to large corrections arising from higher orders in perturbation theory.",
        "watermark_text": "We present an algorithm for generating new answers to the coupled Einstein - scalar field equations , beginning from vacuum solutions and adding scalar fields in such a way that the resulting solve is minimally coupled . The method can be used to create precise solutions which are not described specifically or only implicitly as functions of some parameters ( e . g . , by modeling algebraic equations ) .We illustrate our approach on numerous instances including Schwarzschild - de Sitter dark holes , Reissner - Nordström - anti - de Sitter dark holes , Kerr - Newman - AdS red holes , and charged dilatonic black holes . In particular we give how one can obtain precise expressions for the massless maximum of these black hole solutions .Our results may even have applications beyond gravitational theory , e . g . , in quantum mechanics where they may provide insight into the formation of bound states . Introduction : Exact solutions play an important role in theoretical physics because they allow us to test various mechanical concepts against concrete expectations .However , finding exact treatments to physically exciting issues often comes out to be very difficult . For instance , it takes more than 100 years after the discovery of general relativity before the first accurate black hole problems were found 1 - 3 .Even nowadays there remain many open questions about black holes 4 . One reason why seeking precise solutions is so difficult is that most models of importance do not admit any straightforward analytic solutions .Another difficulty arises when trying to find solutions involving systems with various interacting components like grey holes populated by matter or other fields . Here one usually has to solve complicated differential equations numerically which makes it difficult to find all possible solutions even if their existence was assured theoretically .This problem arises increasingly severe if one wants to study phenomena at strong coupling since then numerical models become fewer reliable resulting to large corrections resulting from greater orders in perturbation theory .",
        "ori-fast-z-score": 0.30499714066520933,
        "water-fast-z-score": 8.387421368293257
    },
    {
        "original_text": "We report on new photometric and spectroscopic observations of the recently discovered mid- to late-Be star V2104 Cyg, which show that it is multiperiodic with two periodicities at P = 0. d . The first periodicity (P_1) was found by analyzing our own data as well as those available in literature; its value agrees very well with previous determinations. The second one (P_2), however, has never been detected before. We have also analyzed archival IUE spectra for this object and found evidence for long-term variability in both emission-line profiles and continuum fluxes. Our results suggest that the observed double-periodic behavior may be caused by non-radial pulsation or rotationally modulated magnetic activity. \n \n Keywords: Multiperiodicity, Nonradial pulsation, Rotational modulation, Mid-to-late B-type stars, Photometry, Spectroscopy",
        "watermark_text": "We report on new photometric and spectroscopic observations of the recently discovered late - to late - Be star V2104 Cyg , which show that it is multiperiodic with two periodicities at P = 0 . d . The first periodicity ( P _ 1 ) was known by analyzing our own data as well as those available in literature ; its value agrees very best with previous determinations .The second one ( P _ 2 ) , however , has never been detected before . We have already analyzed archival IUE spectra for this object and found proof for large - term variability in both emission - line profiles and continuum fluxes .Our results show that the seen double - periodic pattern might be caused by non - radial pulsation or rotationally modulated magnetic activity . Keywords : Multiperiodicity , Nonradial pulsation , Rotational modulation , Mid - to - early B - class stars , Photometry , Spectroscopy",
        "ori-fast-z-score": 1.5714285714285714,
        "water-fast-z-score": 5.0
    },
    {
        "original_text": "The authors present an overview of the role that knots play in proteins, with particular emphasis on their function and evolution.  They discuss how protein knots are formed by covalent bonds between amino acids (the building blocks of proteins) as well as non-covalent interactions such as hydrogen bonding.  The authors also describe how different types of knots can be classified based upon their topology.   Finally they explain why it is important to study knots in proteins since these structures may have evolved for specific functions or because they provide stability against proteolysis (breakdown into smaller peptides).    This article was originally published on BioMed Central. It has been re-posted here under Creative Commons License 3.0. Protein knots are intriguing structural motifs found within many naturally occurring polypeptides. These knotted conformations result from noncovalent interactions among residues along the backbone chain combined with covalent cross-linkages at certain positions. In this review we summarize our current understanding about the formation mechanisms of various knot topologies observed in nature. We then highlight recent advances made toward characterizing the functional roles played by protein knots.",
        "watermark_text": "The authors present an overview of the importance that knots play in proteins , with particular focuses on their function and evolution . They explore how protein knots are created by covalent interactions between amino acids ( the built stones of proteins ) as well as non - covalent interactions such as carbon bonding .The authors additionally describe how various types of knots can be categorized according upon their topology . Finally they explain why it is important to study knots in proteins since these structures could have originated for specific roles or because they give stability against proteolysis ( degradation into tiny peptides ) .This section was originally published on BioMed Central . It has been re - posted here under Creative Commons License 3 . 0 .Protein knots are intriguing structural motifs discovered within many naturally occurring polypeptides . These knotted conformations result from noncovalent interactions among proteins along the backbone ring coupled with covalent cross - linkages at different positions .In this review we summarize our latest understanding about the formation patterns of several knot topologies discovered in nature . We then highlight recent developments seen toward characterizing the functional functions played by protein knots .",
        "ori-fast-z-score": 0.6324555320336759,
        "water-fast-z-score": 6.88998622004134
    },
    {
        "original_text": "We study the effects of general relativity on gravitational wave bursts produced by extreme mass ratio inspirals (EMRIs). We show that, for EMRI systems with total masses M = 10^6M_solar and compact object masses m = 1M_neutron star, the orbital period is less than one second at distances greater than 100 AU. This implies that these sources are likely to be detected as continuous waves rather than short-duration bursts. The detection rate of such events depends strongly upon their luminosities; we find that they may occur up to several times per year within our galaxy. These results suggest that EMRIs could provide an important source of information about supermassive black holes. \n \n Keywords: Black hole, Compact binary system, General relativity, Gravitational wave, Inspiralling neutron star, Relativity theory \n \n \n \n INTRODUCTION \n \n In recent years there has been considerable interest in studying the properties of gravitational radiation emitted during the final stages of stellar evolution when a massive star collapses into a black hole or neutron star  1  . Such processes can produce extremely energetic signals which will be detectable out to cosmological distances using future space-based detectors  2  , including LISA  3  . However, it remains unclear how many of these events should actually be observed  4  . \n \n One possible class of objects which might emit strong gravitational waves are known as  extreme-mass-ratio inspirals  (EMRIs)  5  . Here, a small compact object spirals into a much more massive black hole or neutron star over millions of orbits before being destroyed  6  . For example, if a solar mass star were to spiral into a ten million solar mass black hole then its orbit would shrink down to just a few kilometres before merging  7, 8  . If this process occurs close enough to the event horizon then the resulting signal will have very high frequencies  9  . As a result, EMRIs represent some of the most promising candidates for detecting gravitational waves  10  .",
        "watermark_text": "We research the effects of general relativity on gravity wave bursts created by intense mass ratio inspirals ( EMRIs ) . We say that , for EMRI systems with total masses M = 10 ^ 6M _ solar and compact body masses m = 1M _ neutron star , the orbital period is fewer than one second at distances greater than 100 AU .This implies that these objects are likely to be identified as continuous waves rather than longer - duration bursts . The detection rate of such events depends strongly upon their luminosities ; we find that they may happen up to several twice per year within our universe .These data suggest that EMRIs might give an important source of insight about supermassive black holes . Keywords : Black hole , Compact binary system , General relativity , Gravitational wave , Inspiralling neutron star , Relativity concept INTRODUCTION In recent seasons there has been substantial interest in investigating the properties of gravitational rays generated during the last phases of stellar evolution when a huge star collapses into a black hole or neutron star 1 .Such mechanisms can generate incredibly energetic signals which will be detectable out to cosmological distances using upcoming space - based detectors 2 , notably LISA 3 . However , it remains unsure how many of these changes should really be emitted 4 .One potential class of structures which would emit strong gravitational waves are known as extreme - mass - ratio inspirals ( EMRIs ) 5 . Here , a small compact body spirals into a far more massive brown hole or neutron galaxy over thousands of orbits before being destroyed 6 .For instance , if a solar mass star were to spiral into a ten million solar mass black hole then its orbit may weaken down to just a few kilometres before merging 7 , 8 . If this process occurs nearer sufficient to the event horizon then the resulting signal will have very high frequencies 9 .As a result , EMRIs represent some of the most attractive candidates for detecting gravitational waves 10 .",
        "ori-fast-z-score": -1.59111456835146,
        "water-fast-z-score": 6.36445827340584
    },
    {
        "original_text": "We study non-commutative Donaldson–Thomas invariants for Calabi-Yau threefolds in terms of their crepant resolutions, which are called conifolds. We show that these invariants can be computed by counting holomorphic curves on the resolved spaces with suitable boundary conditions. As an application we compute the Donaldson–Thomas invariant of the quintic threefold using its crepant resolution as well as the mirror quintic. The results agree with those obtained previously via other methods. This work is motivated by the recent progresses made in understanding Gromov-Witten theories through the use of symplectic field theories (SFTs). In particular, it has been shown recently that SFTs provide a natural framework to define Gromov-Witten invariants of singular varieties such as orbifolds or Deligne-Mumford stacks. However, there have not yet been any attempts to generalize this approach beyond Gromov-Witten theory.",
        "watermark_text": "We research non - commutative Donaldson – Thomas invariants for Calabi - Yau threefolds in terms of their crepant resolutions , which are called conifolds . We see that these invariants can be computed by counting holomorphic curves on the resolved spaces with suitable boundary constraints .As an implementation we compute the Donaldson – Thomas invariant of the quintic threefold using its crepant resolution as well as the mirror quintic . The results agree with those achieved prior via other methods .This research is prompted by the recent progresses done in understanding Gromov - Witten theories through the using of symplectic field theories ( SFTs ) . In particular , it has been shown lately that SFTs allow a natural framework to define Gromov - Witten invariants of singular varieties such as orbifolds or Deligne - Mumford stacks .However , there have not already been any efforts to generalize this methodology beyond Gromov - Witten theory .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.041451884327381
    },
    {
        "original_text": "The physisorption of nucleobases (adenine, cytosine, guanine and thymine) onto graphene is investigated by density functional theory calculations at the B3LYP/6-31G(d) level in vacuum conditions. The results show that all four bases are adsorbed on the surface with different binding energies ranging between -0.27 eV for adenine to -1.10 eV for cytosine. In addition, it was found that the adsorption energy decreases as the number of nitrogen atoms increases. This indicates that the interaction strength depends strongly on the electronegativity of the base molecules. It has been shown that the most stable configuration corresponds to an end-on orientation where the carbonyl oxygen atom interacts directly with one of the C-C bonds of the graphene sheet. \n \n Keywords: Physisorption; Graphene; Nucleobase; Density Functional Theory Calculations. Introduction \n \n Graphene is a two-dimensional material consisting of sp2-hybridized carbon atoms arranged into a honeycomb lattice structure  1  . Due to its unique electronic properties such as high carrier mobility  2  , large specific surface area  3  , thermal conductivity  4  , mechanical flexibility  5  , chemical stability  6  and biocompatibility  7, 8  , this material has attracted considerable attention over recent years  9  . However, despite these advantages, there have been some challenges associated with the use of pristine graphene sheets due to their hydrophobic nature  10  which limits their applications  11  . Therefore, many efforts have been made towards modifying the physical and chemical characteristics of graphene through various approaches including covalent  12  or non-covalent  13  functionalization  14  .\n \nIn particular, non-covalent functionalization can be achieved via π-π interactions  15  , hydrogen bonding  16  , electrostatic  17  , van der Waals  18  and ionic  19  forces  20  . Among them, π-π stacking is considered to be the strongest noncovalent force  21  . For example, several studies have reported that aromatic compounds  22  , fullerenes  23  , porphyrins  24  , metal complexes  25  and biomolecules  26  could interact with graphene surfaces via π-",
        "watermark_text": "The physisorption of nucleobases ( adenine , cytosine , guanine and thymine ) onto graphene is investigated by density functional theory analyses at the B3LYP / 6 - 31G ( d ) level in vacuum environments . The results show that all four bases are adsorbed on the surface with various binding frequencies ranging between - 0 . 27 eV for adenine to - 1 . 10 eV for cytosine .In addition , it was shown that the adsorption energy decreases as the number of nitrogen atoms increases . This implies that the interaction strength depends strongly on the electronegativity of the base atoms .It has been shown that the most stable configuration relates to an ending - on position where the carbonyl oxygen element interacts closely with one of the C - C bonds of the graphene sheet . Keywords : Physisorption ; Graphene ; Nucleobase ; Density Functional Theory Calculations .Introduction Graphene is a two - dimensional material consisting of sp2 - hybridized carbon atoms arranged into a honeycomb lattice structure 1 . Due to its unique electronic properties such as wide carrier density 2 , large specific surface region 3 , thermal conductivity 4 , electronic flexibility 5 , chemical integrity 6 and biocompatibility 7 , 8 , this metal has garnered considerable focus over recent years 9 .However , despite these benefits , there have been some challenges associated with the using of pristine graphene strips due to their hydrophobic properties 10 which restricted their functionality 11 . Therefore , various efforts have been placed towards modifying the physical and biological qualities of graphene through several methods namely covalent 12 or non - covalent 13 functionalization 14 .In particular , non - covalent functionalization can be obtained via π - π interactions 15 , hydrogen bonding 16 , electrostatic 17 , van der Waals 18 and ionic 19 forces 20 . Among them , π - π stacking is regarded to be the greatest noncovalent force 21 .For instance , various trials have reported that aromatic molecules 22 , fullerenes 23 , porphyrins 24 , metal ions 25 and biomolecules 26 could interact with graphene surfaces via π -",
        "ori-fast-z-score": 0.09325048082403138,
        "water-fast-z-score": 7.366787985098479
    },
    {
        "original_text": "We have analyzed the redshifts of two samples of active galactic nuclei (AGNs) with different luminosities and found evidence for intrinsic redshift components in both cases.  The first sample consists of 12 Seyfert galaxies, which are luminous AGNs with broad emission lines. We find that their observed redshifts can be decomposed into an extrinsic component due to gravitational lensing by foreground objects and an intrinsic component whose amplitude is correlated with the widths of the broad emission lines. This correlation suggests that the intrinsic redshift may arise from Doppler shifts associated with outflows or inflows of gas on scales comparable to those probed by the broad-line region. The second sample contains low-luminosity quasars selected from the Sloan Digital Sky Survey Data Release 4 quasar catalog. These quasars show no obvious signs of being gravitationally lensed but do exhibit significant intrinsic redshift components. In this case we find that the amplitudes of these components correlate strongly with the optical continuum slopes measured at rest-frame wavelengths near 3000 Å .",
        "watermark_text": "We have analyzed the redshifts of two specimens of active galactic nuclei ( AGNs ) with varying luminosities and found proof for intrinsic redshift components in both cases . The first specimen consists of 12 Seyfert galaxies , which are luminous AGNs with broad absorption paths .We see that their observed redshifts can be decomposed into an extrinsic component due to gravitational lensing by foreground objects and an intrinsic component whose intensity is associated with the widths of the broad emission lines . This correlation suggests that the intrinsic redshift may arise from Doppler movements related with outflows or inflows of gas on scales similar to those probed by the broad - line region .The second survey features small - luminosity quasars chosen from the Sloan Digital Sky Survey Data Release 4 quasar catalog . These quasars exhibit no evident indication of being gravitationally lensed but do exhibit substantial intrinsic redshift components .In this situation we find that the amplitudes of these systems correlate strongly with the optical continuum curves observed at rest - mirror wavelengths near 3000 Å .",
        "ori-fast-z-score": 0.4923659639173309,
        "water-fast-z-score": 5.662208585049306
    },
    {
        "original_text": "The book is available at the following URL: http://arxiv.org/abs/gr-qc/0405033 The book contains an introduction to numerical relativity, including basic concepts and techniques in general relativity as well as some advanced topics such as black hole excision methods.  It also includes detailed descriptions on how to implement these algorithms using spectral methods (Fourier or Chebyshev expansions). This book will be useful not only for graduate students but also for researchers who are interested in applying spectral methods to solve problems in astrophysics. Authors:  Yi-Kai Shu, Jian-Xin Liu, Zhi-Hong Zhang, Yu-Ting Wu, Xiao-Liang Zhao, Wen-Jun Ma, Hong-Yuan Chen, Jie-Qiu Shi, Jun-Zhuo Wang, Yong-Sheng Zhou, Ming-Dao Li, Qing-Wei Guo, Xin-Bin Huang",
        "watermark_text": "The volume is accessible at the following URL : www : / / arxiv . org / abs / gr - qc / 0405033 The text includes an introduction to numerical gravity , comprising fundamental concepts and techniques in general relativity as well as some advanced topics such as black hole excision methods . It additionally contains detailed details on how to execute these algorithms utilizing spectral algorithms ( Fourier or Chebyshev expansions ) .This book will be valuable not only for graduate scholars but also for researchers who are concerned in implementing spectral algorithms to solve difficulties in astrophysics . Authors : Yi - Kai Shu , Jian - Xin Liu , Zhi - Hong Zhang , Yu - Ting Wu , Xiao - Liang Zhao , Wen - Jun Ma , Hong - Yuan Chen , Jie - Qiu Shi , Jun - Zhuo Wang , Yong - Sheng Zhou , Ming - Dao Li , Qing - Wei Guo , Xin - Bin Huang",
        "ori-fast-z-score": -1.9379255804998177,
        "water-fast-z-score": 4.323064756499593
    },
    {
        "original_text": "We consider the dynamics of an ensemble of N interacting dyons in Minkowski space-time with one compactified dimension, and show that it is described by a statistical mechanics model which can be solved exactly for any number of particles. The exact solution shows that there are two phases depending on whether or not the temperature T exceeds some critical value Tc. For T>Tc we find that the system undergoes a phase transition to a state where all but one dyon have vanishing electric charge while their magnetic charges remain finite. In this regime the entropy density scales as S∼1/(g4N) at large N, where g denotes the coupling constant of the theory. We also discuss how our results may be generalized to other theories such as QCD. Introduction:-In recent years much attention has been paid to the study of strongly coupled gauge theories using various techniques ranging from lattice simulations  1  , holography  2  -  4  , and effective field theories  5  . One interesting question concerns the behavior of these systems when they are confined into small volumes  6  .\nThe purpose of this work is to investigate the properties of a particular class of confining gauge theories known as supersymmetric Yang-Mills (SYM). These theories are defined in terms of a set of fields transforming under the adjoint representation of SU(N), and possess both bosonic and fermionic degrees of freedom  7  . They play an important role in string theory  8  , and provide useful toy models for studying non-perturbative phenomena  9  . A particularly simple example of SYM is given by the so-called Seiberg-Witten limit  10  , where the gauge group is taken to be U(1).\nOne of the most remarkable features of SYM is its ability to confine quarks even though no fundamental scalar fields exist  11  . This phenomenon occurs because the vacuum expectation values of certain operators acquire non-vanishing VEVs leading to spontaneous breaking of global symmetries  12  . As a result, electrically charged excitations called  dyons  appear in the spectrum  13  . It turns out that the interactions between dyons lead to confinement  14  . Moreover, the",
        "watermark_text": "We consider the dynamics of an ensemble of N interacting dyons in Minkowski space - time with one compactified dimension , and find that it is characterized by a statistical mechanics model which can be answered exactly for any number of particles . The exact solution shows that there are two phases depending on whether or not the temperature T reaches some essential factor Tc .For T > Tc we find that the system undergoes a phase shift to a state where all but one dyon have vanishing electric current while their magnetic charges remain finite . In this regime the entropy concentration scales as [UNK] / ( g4N ) at large N , where g denotes the interaction constant of the physics .We especially consider how our findings may be generalized to other theories such as QCD . Introduction : - In recent history much attention has been paid to the observation of highly coupled gauge fields using numerous tactics ranging from lattice simulations 1 , holography 2 - 4 , and effective field theories 5 .One interesting question concerns the dynamics of these systems when they are enclosed into small volumes 6 . The purpose of this research is to examine the properties of a certain class of confining gauge fields known as supersymmetric Yang - Mills ( SYM ) .These theories are specified in terms of a group of fields transforming under the adjoint representation of SU ( N ) , and possess both bosonic and fermionic degrees of liberty 7 . They play an important role in string theory 8 , and play popular toy models for studying non - perturbative behavior 9 .A notably simple example of SYM is given by the so - called Seiberg - Witten limit 10 , where the gauge group is taken to be U ( 1 ) . One of the most noteworthy features of SYM is its able to confine quarks even though no basic scalar fields lie 11 .This phenomenon occurs because the vacuum expectation values of certain functions acquire non - vanishing VEVs resulting to accidental breaking of global symmetries 12 . As a result , electrically charged excitations called dyons emerge in the spectrum 13 .It turns out that the interactions between dyons contribute to confinement 14 . Moreover , the",
        "ori-fast-z-score": 0.08192319205190406,
        "water-fast-z-score": 6.904757466825006
    },
    {
        "original_text": "We report on the discovery and analysis of XMM-Newton observations of an uncatalogued, extremely faint X-ray source (X-ray luminosity < 1031 erg s-1) in the Galactic plane at l = 28 deg., b = 0.5 deg.. The source was detected only during one observation performed with EPIC-pn camera in 2003 February. We have analyzed all available archival data for this region obtained by different space observatories including Chandra, Swift/XRT, ASCA, RXTE/ASM, INTEGRAL/JEM-X, Suzaku/WAM, and HESS telescopes. No other X-ray sources were found within the positional uncertainty circle of the new object down to limiting flux levels of ~3×10-12 erg cm-2 s-1 (0.2-10 keV). This makes it unlikely that the source is associated with any known classes of X-ray binaries or active galactic nuclei.",
        "watermark_text": "We report on the discovery and assessment of XMM - Newton discoveries of an uncatalogued , incredibly faint X - ray source ( X - ray luminosity < 1031 erg s - 1 ) in the Galactic jet at l = 28 deg . , b = 0 . 5 deg . . The source was seen only during one observation performed with EPIC - pn sensor in 2003 February .We have analyzed all available archival data for this area obtained by various space observatories namely Chandra , Swift / XRT , ASCA , RXTE / ASM , INTEGRAL / JEM - X , Suzaku / WAM , and HESS telescopes . No other X - ray bodies were found within the positional uncertainty arc of the new object down to limiting flux levels of ~ 3×10 - 12 erg centimetres - 2 s - 1 ( 0 . 2 - 10 keV ) .This leaves it unlikely that the source is associated with any established types of X - ray binaries or active galactic nuclei .",
        "ori-fast-z-score": -0.5897678246195885,
        "water-fast-z-score": 4.718142596956708
    },
    {
        "original_text": "The vortex dynamics is studied numerically for fractal cluster structure (FCCS) superconductor by solving time-dependent Ginzburg-Landau equations under an external magnetic field. The FCCS has been proposed as one possible candidate to explain the origin of high-Tc cuprates, and it consists of randomly distributed clusters which are connected each other via Josephson coupling. We find that the resistivity increases rapidly when the applied current exceeds some threshold value Ic(H), where H denotes the strength of the external magnetic field. This behavior can be understood by considering the motion of vortices inside the clusters. In addition, we show that the critical current density Jc decreases gradually with increasing temperature T . Finally, we discuss how these results may be relevant to experiments on high-Tc cuprate superconductors. PACS: 74.20.-q; 74.25.+s; 74.60.Bz; 74.70.-k",
        "watermark_text": "The vortex dynamics is studied numerically for fractal cluster structure ( FCCS ) superconductor by modeling period - dependent Ginzburg - Landau equations under an external magnetic force . The FCCS has been proposed as one possible candidate to explain the origin of high - Tc cuprates , and it consists of randomly distributed clusters which are connected each other via Josephson coupling .We see that the resistivity increases quickly when the introduced current reaches some threshold factor Ic ( H ) , where H represents the strength of the external magnetic force . This phenomenon can be understood by analyzing the movement of vortices inside the clusters .In addition , we show that the critical current density Jc falls gradually with rising heat T . Finally , we talk how these results may be applicable to experiments on high - Tc cuprate superconductors .PACS: 74.20.-q; 74.25.+s; 74.60.Bz; 74.70.-k",
        "ori-fast-z-score": 0.5252257314388902,
        "water-fast-z-score": 5.252257314388902
    },
    {
        "original_text": "We present the results of a numerical study on the relaxation dynamics of an initially straight contact line in a two-dimensional geometry, which is driven by surface tension and viscous dissipation at the moving interface between liquid and gas phases.  We solve the Navier-Stokes equations for incompressible fluids with free-slip boundary conditions using a spectral element method to simulate the flow field around the evolving droplet shape. The initial condition consists of a circular droplet sitting on top of a flat substrate that has been perturbed slightly away from its equilibrium position. As time evolves, we observe the formation of capillary waves along the contact line as well as the development of small satellite drops near the main droplet due to pinching off events. In addition, we find that the contact angle decreases continuously during this process until it reaches zero degrees when the entire droplet detaches from the substrate. Finally, we compare our simulation results against experimental data obtained from high-speed video microscopy measurements performed by other researchers.",
        "watermark_text": "We present the conclusion of a numerical investigation on the relaxation behavior of an initially parallel contact line in a two - dimensional topology , which is generated by surface friction and viscous dissipation at the moved junction between liquid and gas phases . We calculate the Navier - Stokes equations for incompressible gases with loose - slipping border conditions utilizing a spectral component process to simulate the flow field around the evolving droplet shape .The initial condition consists of a circular droplet standing on top of a flattened substrate that has been perturbed slightly apart from its stable position . As period evolves , we monitor the formation of capillary currents along the contact line as also as the development of tiny satellite flows near the main droplet thanks to pinching off events .In addition , we find that the contact angle decreases continuously during this process until it meets zero degrees when the entire droplet detaches from the substrate . Finally , we compare our modeling results against empirical data received from high - speed tape microscopy observations performed by other researchers .",
        "ori-fast-z-score": -0.7592566023652966,
        "water-fast-z-score": 7.267170336924982
    },
    {
        "original_text": "We study the dynamics of an ensemble of interacting vortices in a two-dimensional superfluid helium film, which is driven by a rotating substrate at constant angular velocity . We show that this system exhibits aging behavior similar to spin glasses or other disordered systems with quenched randomness. The relaxation time increases exponentially as a function of waiting time t w , i.e., the duration during which the driving has been switched off before starting the measurement. This increase can be described by a stretched exponential law exp(−(t/τ)β), where τ denotes the characteristic relaxation time and β < 1 describes its distribution width. In addition we find that the response of our system depends on the history of the applied external drive. For example, if one starts with a high rotation frequency f 0 = ω0/2π and then decreases it slowly towards zero (quasi-static protocol), the final state after switching off the drive does not depend on the initial value f0. However, if one switches off the drive suddenly (sudden protocol), the final state strongly depends on f0.",
        "watermark_text": "We explore the dynamics of an ensemble of interacting vortices in a two - dimensional superfluid helium movie , which is driven by a rotating substrate at constant angular velocity . We see that this scheme exhibits aging activity similar to spinning mirrors or other disordered systems with quenched randomness .The relaxation time rises exponentially as a function of waiting period t w , i . e . , the duration during which the driving has been turned off before beginning the measurement . This increase can be described by a stretched exponential law exp ( − ( t / τ ) α ) , where τ represents the characteristic relaxation time and β < 1 refers its distribution length .In addition we find that the response of our system varies on the history of the applied external drive . For instance , if one starts with a high rotation rate w 0 = ω0 / 2π and then decreases it slowly approaching zero ( quasi - static protocol ) , the last position after switching off the drive does not depend on the first value f0 .However , if one switches off the drive abruptly ( sudden protocol ) , the finished state strongly depends on f0 .",
        "ori-fast-z-score": -0.7683498199278324,
        "water-fast-z-score": 5.09786575873842
    },
    {
        "original_text": "We present the results of cosmological simulations that follow the growth of supermassive black holes (SMBHs) by stochastic gas inflow, including radiative feedback effects on their surroundings. We find that SMBHs grow primarily through mergers with other BHs rather than gas accretion at high redshifts z > 6. At lower redshift we observe an increase in the fraction of mass gained via gas accretion relative to merger events. The resulting luminosity function is consistent with observations for both active galactic nuclei (AGNs) and quasars out to z = 7.5. Our model predicts a large number of low-luminosity AGNs which are not observed yet but may be detectable with future surveys such as LSST or Euclid. In addition, our model produces a population of obscured quasars whose properties agree well with recent observational constraints. Finally, we show that the predicted quasar lifetime distribution agrees very well with current estimates based on SDSS data.",
        "watermark_text": "We present the conclusion of cosmological simulations that follow the development of supermassive black holes ( SMBHs ) by stochastic gas inflow , particularly radiative feedback effects on their environment . We see that SMBHs grow primarily through mergers with other BHs rather than gas accretion at high redshifts z > 6 .At lower redshift we study an increase in the fraction of mass gained via gas accretion compared to merger reactions . The resulting luminosity function is compatible with observations for both active galactic nuclei ( AGNs ) and quasars out to z = 7 . 5 .Our model predicts a large number of low - luminosity AGNs which are not observed yet but might be detectable with current surveys such as LSST or Euclid . In addition , our model generates a population of distorted quasars whose characteristics comply better with recent observational restrictions .Finally , we prove that the expected quasar lifetime spread agrees very best with current estimates based on SDSS information .",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.75
    },
    {
        "original_text": "We study quantum spin-1/2 systems with spatially anisotropic exchange interactions on the distorted kagome lattice, which is relevant for volborthite. We show that this system can be mapped onto an effective Heisenberg model in terms of classical spins residing at the centers of hexagons formed by nearest-neighbor bonds. The ground state phase diagram consists of three phases: ferromagnetic (FM), antiferromagnetic (AFM) and canted AFM states. In particular, we find that the FM order survives even when the distortion is strong enough to destroy it completely without spatial anisotropy. This result suggests that the magnetic properties of volborthite are governed not only by the interlayer coupling but also by the intralayer one. Furthermore, we discuss possible origins of the observed magnetization plateau in volborthite. \nI. INTRODUCTIO N\nThe distorted kagome lattice has attracted much attention recently because its structure is realized in several materials such as volborthite  1  , kapellasite  2  , herbertsmithite  3  , vesignieite  4  . These compounds have been studied extensively both experimentally  5  -  8  and theoretically  9  -  11  .\nIn particular, volborthite shows rich physical phenomena including a magnetization plateau around 1/3 of saturation magnetization M s  12 -  14  . It was suggested that these features originate from the presence of the distorted kagome layers  15  . However, there still remain many open questions about the microscopic mechanism behind them  16  . For example, what kind of interaction plays a crucial role? Is the distortion necessary or not?\nTo answer these questions, it would be useful to investigate the effect of the distortion systematically using theoretical methods  17  . Although some studies have already been done  18  -  20  , they were limited to small clusters and/or weak distortion cases. Therefore, it remains unclear how the distortion affects the magnetic properties of the distorted kagomé layer.\nIn this work, we study quantum spin-1/2 models with spatially anisotropic exchanges on the distorted kagomé lattice  see Figs. 1(",
        "watermark_text": "We explore quantum spin - 1 / 2 systems with spatially anisotropic exchange interactions on the altered kagome lattice , which is relevant for volborthite . We see that this scheme can be mapped onto an efficient Heisenberg structure in terms of classical spins residing at the centers of hexagons formed by nearest - neighbor bonds .The ground state phase diagram consists of three stages : ferromagnetic ( FM ) , antiferromagnetic ( AFM ) and canted AFM states . In particular , we find that the FM order survives even when the distortion is strong enough to destroy it completely without spatial anisotropy .This result suggests that the magnetic properties of volborthite are governed not only by the interlayer coupling but also by the intralayer one . Furthermore , we investigate possible origins of the seen magnetization plateau in volborthite .I . INTRODUCTIO N The distorted kagome lattice has drew much attention lately because its formation is realized in multiple structures such as volborthite 1 , kapellasite 2 , herbertsmithite 3 , vesignieite 4 . These compounds have been studied thoroughly both experimentally 5 - 8 and theoretically 9 - 11 .In particular , volborthite shows rich physical phenomena including a magnetization peak around 1 / 3 of saturation magnetization M s 12 - 14 . It was suggested that these characteristics derive from the presence of the altered kagome layers 15 .However , there still continue several open questions about the microscopic process behind them 16 . For instance , what sort of interaction plays a crucial role ?Is the distortion required or not ? To answer these problems , it would be used to examine the impact of the distortion thoroughly using theoretical methods 17 .Although some researchers have already been performed 18 - 20 , they were restricted to small clusters and / or strong distortion cases . Therefore , it remains unsure how the degradation affects the magnetic properties of the altered kagomé coating .In this research , we study quantum spin - 1 / 2 models with spatially anisotropic exchanges on the curved kagomé lattice see Figs . 1 (",
        "ori-fast-z-score": 2.280350850198276,
        "water-fast-z-score": 8.584388698288787
    },
    {
        "original_text": "We prove that for any surface S of general type, the action of its absolute Galois group G(S) on the set of connected components of the modulis space M_g(S) is faithful.  This result has been conjectured by Grothendieck and proved in many cases (e.g., when g = 0 or 1).  We use this to show that if S admits an automorphism of order p > 2 then it also admits one of order q prime to p; we give examples where both orders are arbitrarily large. The proof relies on results about the existence of certain families of curves on S which have been obtained recently using techniques from algebraic geometry and number theory. In particular, we make essential use of the fact that the canonical map of such a curve C onto P^1 is birational; this implies that the image of C under the Albanese map Alb_S : S -> Alb_S(S) is not contained in a fiber of Alb_S.",
        "watermark_text": "We prove that for any manifold S of general kind , the operation of its absolute Galois group G ( S ) on the group of connected parts of the modulis space M _ g ( S ) is faithful . This result has been conjectured by Grothendieck and demonstrated in many situations ( e . g . , when g = 0 or 1 ) .We use this to see that if S gives an automorphism of order q > 2 then it also admits one of order q prime to p ; we give instance where both orders are arbitrarily big . The proof draws on findings about the existence of certain classes of curves on S which have been achieved lately utilizing techniques from algebraic topology and number theory .In particular , we give important use of the fact that the canonical mapping of such a curve C onto P ^ 1 is birational ; this implies that the image of C under the Albanese map Alb _ S : S - > Alb _ S ( S ) is not enclosed in a fiber of Alb _ S .",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 5.08000508000762
    },
    {
        "original_text": "We present new near-infrared polarimetric observations of the equatorial ring surrounding the evolved star HD 163296 (HR 5171 A). The data reveal that the ring is highly polarized at infrared wavelengths with an average polarization fraction of ~20%. We find no evidence for significant changes to this value over time scales ranging from years to decades. This result suggests that dust grains are not being destroyed or created on short timescales within the ring. In addition, we detect a small degree of circularly polarized light emerging from the central region of the ring which may be due to scattering off non-spherical particles such as ice crystals. \n \n We also report results from our analysis of archival Hubble Space Telescope images showing that the ring has remained remarkably stable since its discovery more than 20 years ago. Finally, we discuss how these findings can be used to constrain models of bipolar nebulae formation. Keywords: Polarization; Circumstellar matter",
        "watermark_text": "We report new near - infrared polarimetric studies of the equatorial ring surrounding the evolved star HD 163296 ( HR 5171 A ) . The data reveal that the circle is strongly polarized at infrared wavelengths with an estimated polarization fraction of ~ 20 % .We see no evidence for significant variations to this value over time ranges ranging from years to decades . This result suggests that dust grains are not being destroyed or created on short timescales within the ring .In addition , we perceive a small level of circularly polarized light arriving from the main region of the circle which may be due to scattering off non - cylindrical ions such as ice particles . We additionally report findings from our analysis of archival Hubble Space Telescope images indicating that the circle has remained remarkably steady since its observation more than 20 decades ago .Finally , we explain how these results can be used to constrain models of bipolar nebulae formation . Keywords : Polarization ; Circumstellar matter",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.3804502135457675
    },
    {
        "original_text": "We study the effects of noise on spatially extended systems by using an extension of the concept of nonequilibrium potential (NEP). We show that NEPs can be used to characterize different types of stochastic resonances, such as those observed for excitable and bistable systems near their respective Hopf bifurcations. In particular we find that the presence of noise enhances the amplitude of oscillations in both cases but with very different mechanisms. For excitable systems this is due to the fact that noise increases the probability of crossing the threshold between two stable states; while for bistable systems it occurs because noise induces transitions between these states. Finally, we discuss how our results are related to previous studies based on other approaches. Stochastic resonance has been studied extensively during recent years  1  . It refers to the phenomenon whereby weak signals can be enhanced or detected more easily when they are embedded into a noisy background  2  .\nIn many physical situations, however, one needs to consider not only the effect of external noise sources but also internal fluctuations arising from the dynamics itself  3  . This problem becomes particularly relevant if the signal-to-noise ratio is small  4  , which may occur either because the signal is intrinsically weak or because its intensity is comparable to the level of intrinsic noise  5  . Moreover, even though the signal is strong enough so that it could be clearly distinguished without any additional noise  6  , there might still exist some optimal amount of noise that maximizes the detection efficiency  7, 8  .",
        "watermark_text": "We research the effects of noise on spatially extended systems by using an extension of the idea of nonequilibrium potential ( NEP ) . We see that NEPs can be used to characterize many kinds of stochastic resonances , such as those observed for excitable and bistable systems near their different Hopf bifurcations .In particular we find that the presence of noise enhances the frequency of oscillations in both cases but with very different mechanisms . For excitable systems this is due to the fact that noise changes the probability of reaching the threshold between two stable states ; while for bistable systems it appears because sound induces transitions between these states .Finally , we talk how our findings are related to previous research based on other methods . Stochastic resonance has been studied significantly during recent seasons 1 .It refers to the situation whereby soft signals can be enhanced or detected more easily when they are lodged into a loud background 2 . In many physical conditions , however , one needs to consider not only the impact of external sound sources but also internal fluctuations originating from the dynamics itself 3 .This problem appears particularly relevant if the signal - to - noise proportion is tiny 4 , which may happen either because the signal is intrinsically weak or because its brightness is equal to the level of intrinsic noise 5 . Moreover , even though the signal is strong enough so that it could be obviously differentiated without any additional noise 6 , there might nevertheless exist some optimal level of noise that maximizes the detection efficiency 7 , 8 .",
        "ori-fast-z-score": 0.38138503569823695,
        "water-fast-z-score": 6.928853368993243
    },
    {
        "original_text": "The Large Hadron Collider (LHC) is expected to produce many new particles and discoveries in its Run II program, including possible evidence for physics beyond the Standard Model through rare decays such as b → sγ or t → cZ. The Belle experiment has recently measured these processes with unprecedented precision, providing important constraints on models that predict deviations from Standard Model expectations.  In this talk I will present an overview of recent results from Belle related to searches for new physics in rare decay modes involving charm quarks. These include measurements of:  - Branching fractions for charmless hadronic B meson decays; - CP asymmetries in neutral D mesons produced in B-meson decays; - Branching fraction for B(Bc→J/ψX). \nI will also discuss how these results can be used to constrain extensions of the Standard Model. Finally, I will briefly describe some future plans for Belle experiments.",
        "watermark_text": "The Large Hadron Collider ( LHC ) is expected to produce many new ions and discoveries in its Run II program , particularly likely evidence for physics beyond the Standard Model through rare decays such as b → sγ or t → cZ . The Belle study has recently recorded these reactions with incredible clarity , providing key restrictions on predictions that forecast deviations from Standard Model expectations .In this talk I will present an overview of recent results from Belle linked to searches for recent theory in rare decay modes involving charm quarks . These include estimates of : - Branching fractions for charmless hadronic B meson decays ; - CP asymmetries in neutral D mesons produced in B - meson decays ; - Branching fraction for B ( Bc→J / ψX ) .I will also discuss how these results can be used to constrain extensions of the Standard Model . Finally , I will briefly outline some future proposals for Belle experiments .",
        "ori-fast-z-score": 1.1920791213585393,
        "water-fast-z-score": 5.960395606792697
    },
    {
        "original_text": "We present an analysis of the accuracy with which different approximants to gravitational-wave (GW) signals emitted by coalescing binaries can be recovered using matched filtering techniques, in particular when applied to simulated detector noise. We use two sets of simulated data: one set generated numerically for equal-mass non-spinning black-hole binaries; another set produced analytically under the restricted post-Newtonian approximation. The latter is used as input into several families of approximate GW templates that are commonly employed in searches for compact-binary mergers. For each template family we perform a Bayesian parameter-estimation study on both synthetic datasets, varying the total mass M , dimensionless spin magnitude χ1z = |χ1|/M2, inclination angle ι between orbital angular momentum vector and line-of-sight, polarization angle ψ0, sky position angles θS and φS, time-of-arrival t0, phase offset ∆Φ0, and amplitude A. In addition, we also vary the distance D to the source. Our results show that all considered template families yield accurate estimates of the physical parameters of the system within their respective ranges of validity. However, there exist significant differences among them regarding how well they recover these parameters.",
        "watermark_text": "We present an assessment of the accuracy with which different approximants to gravitational - wave ( GW ) transmissions generated by coalescing binaries can be recovered using matched filtering tactics , in example when applied to modeled detector noise . We use two sets of simulated evidence : one set produced numerically for equivalent - mass non - spinning black - hole binaries ; another set produced analytically under the restricted pre - Newtonian approximation .The latter is utilized as input into numerous families of approximate GW templates that are often employed in searches for compact - binary mergers . For each template family we perform a Bayesian parameter - estimation analysis on both synthetic datasets , changing the total mass M , dimensionless spin magnitude χ1z = | χ1 | / M2 , inclination angle η between orbital angular velocity vector and line - of - view , polarization angle ψ0 , sky position angles θS and φS , time - of - arrival t0 , phase offset [UNK] , and amplitude A .In addition , we also varies the distance D to the origin . Our results show that all considered template groups yield reliable estimates of the physical components of the system within their different ranges of relevance .However , there remain considerable variations among them governing how best they recover these parameters .",
        "ori-fast-z-score": -0.8955334711889903,
        "water-fast-z-score": 5.148767223478707
    },
    {
        "original_text": "The detection of the hypothetical eta-mesic nuclei is one of the most promising ways to find new physics beyond Standard Model (SM). The experimental signature of such an exotic state would be a peak in the invariant mass distribution of the final-state particles produced by its decay, which can be observed as a bump on top of the smooth nuclear structure function background. In this work we present results obtained using Monte Carlo simulations and Geant4-based full simulation of the proposed experiment at JLab 12 GeV upgrade facility. We show that it will allow us to detect eta-mesic nuclei with high efficiency and good resolution over wide range of masses up to A = 100. This will provide unique opportunity to study properties of these exotic systems and test theoretical predictions. \n \n Keywords: eta-mesic nucleus, eta-nucleon interaction, eta production, eta-decay, eta-nuclear form factor, eta-nuclear potential",
        "watermark_text": "The detection of the hypothetical eta - mesic nuclei is one of the most exciting ways to find new physics beyond Standard Model ( SM ) . The empirical signature of such an exotic state would be a peak in the invariant mass distribution of the finished - state particles generated by its decay , which can be viewed as a bump on top of the smooth radioactive structure parameter background .In this project we present results derived using Monte Carlo simulations and Geant4 - based full simulation of the suggested experiment at JLab 12 GeV development facility . We suggest that it will able us to identify eta - mesic nuclei with high efficiency and good sensitivity over broad spectrum of masses up to A = 100 .This will provide unique opportunity to study properties of these exotic systems and question fundamental predictions . Keywords : eta - mesic nucleus , eta - nucleon collision , eta production , eta - emission , eta - atomic shape factor , eta - atomic potential",
        "ori-fast-z-score": -1.1952286093343936,
        "water-fast-z-score": 5.259005881071332
    },
    {
        "original_text": "We present the results of an analysis of data taken by Milagro, which is sensitive to gamma rays with energies between 100 GeV and 10 TeV. We find that there are no significant excesses in the direction of any short duration GRB (T90 < 2 s) detected by BATSE or Swift during their respective lifetime. The upper limits we derive for these bursts range from 1x10^-6 photons/cm^2/s at 100 GeV up to 3x10^-5 photons/cm^2/s at 10 TeV. These constraints rule out models where the emission is dominated by inverse Compton scattering off relativistic electrons accelerated in internal shocks. \n \n Keywords: Gamma-ray bursts, Milagro Observatory, Upper limit, Internal shock model, Inverse Compton Scattering. Subject headings: Astrophysics - Gamma Ray Astronomy - Cosmic Rays - Space Weather - Fermi Bubbles - Blazars",
        "watermark_text": "We present the conclusion of an assessment of evidence performed by Milagro , which is sensitive to gamma radiation with energies between 100 GeV and 10 TeV . We see that there are no major excesses in the direction of any low duration GRB ( T90 < 2 s ) detected by BATSE or Swift during their respective lifetime .The higher limits we derive for these bursts vary from 1x10 ^ - 6 photons / cm ^ 2 / s at 100 GeV up to 3x10 ^ - 5 photons / cm ^ 2 / s at 10 TeV . These limitations make out models where the emission is dominated by linear Compton absorption off relativistic electrons accelerated in internal shocks .Keywords : Gamma - ray flare , Milagro Observatory , Upper limit , Internal shock model , Inverse Compton Scattering . Subject headings : Astrophysics - Gamma Ray Astronomy - Cosmic Rays - Space Weather - Fermi Bubbles - Blazars",
        "ori-fast-z-score": -1.2649110640673518,
        "water-fast-z-score": 2.846049894151541
    },
    {
        "original_text": "We study satellites in simulated galaxies with different masses at z = 0 using high-resolution cosmological hydrodynamic simulations (the Millennium Run). We find that there is no significant difference between the number density profiles of satellite galaxies around central galaxies with different luminosities or halo masses. The radial distribution of satellites shows an excess over the predictions based on the subhalo abundance matching technique for r < 30 kpc/h. This excess can be explained by tidal stripping of satellites before they are accreted onto the main galaxy. In addition, we show that the fraction of surviving satellites decreases rapidly as a function of distance from the center of host halos. Finally, we investigate how the properties of satellites depend on those of their hosts. Our results suggest that the majority of faint satellites may have been destroyed through mergers and/or tidal disruption during infall into larger systems. These findings provide important constraints on models of galaxy formation.",
        "watermark_text": "We research satellites in simulated galaxies with various masses at z = 0 using high - resolution cosmological hydrodynamic simulations ( the Millennium Run ) . We see that there is no major variation between the number density characteristics of satellite galaxies around central planets with various luminosities or halo masses .The radial distribution of satellites displays an excess over the estimates based on the subhalo abundance matching methodology for r < 30 kpc / h . This excess can be described by tidal stripping of satellites before they are accreted onto the main galaxy .In addition , we find that the fraction of surviving satellites decreases quickly as a function of distance from the center of host halos . Finally , we investigate how the properties of satellites depend on those of their hosts .Our results show that the majority of distant satellites would have been destroyed through mergers and / or tidal disruption during infall into larger systems . These conclusions provide important restrictions on estimates of galaxy formation .",
        "ori-fast-z-score": 0.6974858324629157,
        "water-fast-z-score": 5.579886659703326
    },
    {
        "original_text": "We present an exact solution for the scattering problem at normal incidence to a stack of N parallel layers separated by vacuum gaps or by stepwise potentials. The method is based on the transfer matrix approach combined with the Green s function technique. We derive explicit expressions for reflection coefficients as well as for the phase shifts between adjacent layers. These results are applied to calculate the optical properties of periodic structures such as Bragg reflectors and photonic crystals. In particular we discuss how the band structure can be obtained from the knowledge of the reflection coefficient only. Finally, we show that our formalism allows one to study also non-periodic systems like superlattices and quantum wells. \nI. INTRODUCTORY REMARK\nThe aim of this work is to develop a general theory which describes the propagation of waves through multilayer structures consisting of alternating layers of different materials. This includes both periodic (photonic) and aperiodic (superlattice-like) arrangements of layers. Our main interest lies in the calculation of the reflection and transmission coefficients as well as the phase shifts occurring upon passage through each individual layer. As will become clear below these quantities provide all information necessary to determine the electronic and optical properties of the system under consideration. \n \n A number of authors have studied the wave optics of multilayered media using various approaches  1  . Most of them were concerned with the case where the interfaces separating neighboring layers are flat  2  -  4  , i.e., they do not contain any steps in their profiles. However, it has been shown recently  5  that even small deviations from perfect periodicity may lead to dramatic changes in the physical behavior of the system. For example, if the interface profile contains a single step then the corresponding energy spectrum becomes discrete  6  . Moreover, the presence of steps leads to new types of excitations known as surface plasmons  7  . It should be noted here that the effects caused by the presence of steps cannot always be neglected since they often play an important role in determining the overall performance of devices made out of semiconductor heterostructures  8  . \n \n Another interesting feature associated with stepped interfaces is",
        "watermark_text": "We present an precise solving for the scattering question at normal incidence to a stack of N parallel levels divided by vacuum gaps or by stepwise potentials . The method is based on the transfer matrix approach combined with the Green s function method .We derive explicit expressions for reflection values as well as for the phase transitions between neighboring layers . These results are applied to estimate the optical properties of periodic elements such as Bragg reflectors and photonic crystals .In particular we explain how the band structure can be obtained from the knowledge of the reflection coefficient only . Finally , we show that our formalism allows one to study also non - periodic systems like superlattices and quantum wells .I . INTRODUCTORY REMARK The goal of this project is to develop a general theory which explains the propagation of waves through multilayer structures consisting of alternating structures of different materials .This encompasses both periodic ( photonic ) and aperiodic ( superlattice - like ) arrangements of elements . Our main interest lies in the determination of the reflection and transmission coefficients as well as the phase change occurring upon entry through each individual surface .As will become clear below these quantities offer all information required to obtain the optical and optical properties of the device under consideration . A variety of authors have researched the wave optics of multilayered material utilizing diverse methods 1 .Most of them were involved with the case where the connections dividing neighboring layers are straight 2 - 4 , i . e . , they do not include any steps in their profiles . However , it has been shown recently 5 that even little deviations from good periodicity might lead to significant improvements in the physical dynamics of the system .For instance , if the interface profile contains a single stage then the associated energy spectrum becomes discrete 6 . Moreover , the presence of steps contributes to novel forms of excitations known as surface plasmons 7 .It should be mentioned here that the effects caused by the presence of steps cannot often be forgotten since they frequently play an important role in determining the overall performance of structures making out of semiconductor heterostructures 8 . Another curious concept identified with stepped interfaces is",
        "ori-fast-z-score": -0.22677868380553634,
        "water-fast-z-score": 8.239625511601155
    },
    {
        "original_text": "We propose an experiment to entangle two independent photons in the time domain, using only linear optical elements and single-photon detectors.  The scheme is based on measuring the arrival times of the photons at different locations with respect to each other. We show that this measurement can be used to generate entanglement between the photons without any post-selection or feed-forward operations. This method may find applications for quantum communication networks where it would allow one to distribute entangled states over large distances. Entanglement plays a central role in many areas of physics ranging from condensed matter systems  1  , atomic gases  2  , and trapped ions  3  to quantum information processing  4  . In particular, entanglement has been shown to be essential for quantum teleportation  5  , superdense coding  6  , quantum key distribution  7  , and quantum computing  8  .\nIn recent years there have been several proposals to create entanglement between distant particles  9  -  11  . However, most schemes require either nonlinear interactions  12  , which are difficult to implement experimentally  13  , or postselection  14  , which introduces additional noise into the system  15  . Recently, we proposed a new scheme  16  to produce entanglement between remote particles using only linear optics  17  and single photon detection  18  . Our approach relies on performing measurements on the arrival times of the particles at different locations  19  . Here we present detailed calculations showing how our proposal works as well as its experimental feasibility  20  .  Figure 1 shows a schematic diagram of our setup. Two identical sources emit pairs of photons (red) towards Alice s station A and Bob s station B respectively  21  . Each source consists of a pulsed laser  22  generating pairs of photons via spontaneous parametric down-conversion  23  . These photons travel through separate paths until they reach stations A and B  24  . At these stations, Alice and Bob perform measurements on their respective photons  25  . They measure the arrival times tA and tB  26  of...",
        "watermark_text": "We suggest an project to entangle two independent photons in the time realm , using only linear optical elements and single - photon detectors . The scheme is based on measuring the emergence periods of the photons at different places with regard to each other .We see that this measurement can be used to produce entanglement between the photons without any post - choice or feed - forward functions . This method may see useful for quantum communication networks where it would enable one to distribute entangled states over large distances .Entanglement plays a central role in multiple fields of science ranging from condensed matter structures 1 , atomic atoms 2 , and trapped ions 3 to quantum information processing 4 . In particular , entanglement has been shown to be crucial for quantum teleportation 5 , superdense coding 6 , quantum key distribution 7 , and quantum computing 8 .In past decades there have been numerous ideas to create entanglement between distant particles 9 - 11 . However , most schemes need either nonlinear interactions 12 , which are hard to execute experimentally 13 , or postselection 14 , which introduces additional noise into the process 15 .Recently , we presented a new method 16 to produce entanglement between remote particles utilizing only linear optics 17 and single photon detection 18 . Our solution consists on making observations on the entry rates of the molecules at different places 19 .Here we present detailed calculations demonstrating how our proposal works as also as its empirical feasibility 20 . Figure 1 shows a schematic diagram of our setup .Two similar sources emit pairs of photons ( red ) towards Alice s station A and Bob s station B respectively 21 . Each source consists of a pulsed laser 22 producing sets of photons via spontaneous parametric down - transfer 23 .These photons travel through different paths until they reach stations A and B 24 . At these stations , Alice and Bob conduct measurements on their respective photons 25 .They measure the arrival times tA and tB 26 of . . .",
        "ori-fast-z-score": -0.5035088149780135,
        "water-fast-z-score": 6.88128713803285
    },
    {
        "original_text": "We present new HST photometric data on halo stars in the nearby elliptical galaxy NGC 3377, obtained with the Wide Field Planetary Camera 2 (WFPC2). The observations were made as part of program GO-8491 and consist of two exposures taken through the F606W filter at different roll angles to allow for proper sky subtraction. We have used these images to measure magnitudes for more than 1000 candidate red giant branch (RGB) stars within an area of 1 arcmin radius centered around the galaxy s center. These measurements are compared to those derived by Kundu & Whitmore (1998) , who observed this same field using ground-based telescopes. Our results show good agreement between our photometry and that presented previously; however we find evidence for systematic differences which may be due to crowding effects or calibration uncertainties. \n \n Keywords: Red Giant Branch, Galaxy, WFPC2",
        "watermark_text": "We report new HST photometric data on halo stars in the nearby elliptical galaxy NGC 3377 , obtained with the Wide Field Planetary Camera 2 ( WFPC2 ) . The images were made as part of series GO - 8491 and consist of two exposures took through the F606W filter at different roll axes to allow for correct sky subtraction .We have utilized these images to measure magnitudes for more than 1000 candidate red giant line ( RGB ) stars within an area of 1 arcmin radius centered around the universe s center . These measurements are compared to those derived by Kundu & Whitmore ( 1998 ) , who studied this same field using ground - based telescopes .Our results show good agreement between our photometry and that presented previously ; however we find proof for systematic differences which may be due to crowding effects or calibration uncertainties . Keywords : Red Giant Branch , Galaxy , WFPC2",
        "ori-fast-z-score": 1.4832396974191326,
        "water-fast-z-score": 4.449719092257398
    },
    {
        "original_text": "The Hubble Space Telescope has revealed the most detailed view yet of an active galactic nucleus (AGN) in the galaxy NGC6908, located about 300 million light years away.  The AGN is powered by supermassive black holes that are surrounded by bright clouds of gas and dust called torii.   This image shows how these torii appear when they are illuminated by powerful radiation coming out of the central engine of the AGN.   ... Full text here . \n \n Image credits: NASA, ESA, STScI, A. Simionescu et al. (University of Leicester), DSS2, Digitized Sky Survey 2.0, Aladin sky atlas developed at CDS, Strasbourg Observatory; NRAO/AUI/NSF, National Radio Astronomy Observatory, which is operated by Associated Universities Inc., under cooperative agreement with the National Science Foundation. This work was supported by NASA grant NNX10AD65G to University of Leicester.",
        "watermark_text": "The Hubble Space Telescope has confirmed the most detailed view ever of an active galactic nucleus ( AGN ) in the universe NGC6908 , located about 300 million light years distance . The AGN is powered by supermassive black holes that are surrounded by bright clusters of gas and dust called torii .This image shows how these torii appear when they are illuminated by potent radiation coming out of the main motor of the AGN . . . . Full text here .Image credits : NASA , ESA , STScI , A . Simionescu et al . ( University of Leicester ) , DSS2 , Digitized Sky Survey 2 . 0 , Aladin sky atlas created at CDS , Strasbourg Observatory ; NRAO / AUI / NSF , National Radio Astronomy Observatory , which is controlled by Associated Universities Inc . , under partnership agreement with the National Science Foundation .This project was supported by NASA award NNX10AD65G to University of Leicester .",
        "ori-fast-z-score": 0.9486832980505138,
        "water-fast-z-score": 5.153734142324001
    },
    {
        "original_text": "We study the relationship between network structure, dynamics, and function using an example system that is both complex and experimentally accessible -- the brain s neuronal circuitry. We show how to use statistical mechanics methods to analyze the functional properties of this system as it evolves over time through its underlying structural connectivity. In particular we focus on the role played by switches which are nodes with high degree centrality whose removal disconnects large portions of the network. Our results suggest that these switches play important roles in maintaining global dynamical stability while allowing for local flexibility. The manuscript is organized into four sections. Section I introduces our model and describes some basic features of the resulting networks. Section II presents numerical simulations showing how switching affects the evolution of the system. Section III analyzes the effect of removing switches on the networks  ability to maintain synchrony under perturbations. Finally section IV discusses possible extensions of our work. This article has been published in final form at http://arxiv.org/abs/1306.5995",
        "watermark_text": "We research the relationship between network structure , dynamics , and function using an instance structure that is both complex and experimentally visible - - the brain s neuronal circuitry . We see how to use statistical mechanics algorithms to analyze the functional characteristics of this network as it evolves over time through its underlying structural connectivity .In particular we focus on the part played by switches which are networks with high degree centrality whose removal disconnects huge segments of the organization . Our results show that these switches act key roles in maintaining global dynamical stability while providing for central autonomy .The manuscript is organized into four components . Section I outlines our model and explains some fundamental characteristics of the resulting connections .Section II offers numerical simulations demonstrating how switching influence the evolution of the organization . Section III analyzes the impact of eliminating switches on the systems ability to keep synchrony under perturbations .Finally section IV examines possible extensions of our work . This section has been publication in finished form at http : / / arxiv . org / abs / 1306 . 5995",
        "ori-fast-z-score": -0.9761870601839528,
        "water-fast-z-score": 7.637626158259733
    },
    {
        "original_text": "We present new near-infrared (NIR) observations of the Coma cluster using the Infrared Array Camera on board the Spitzer Space Telescope, which allow us to study the dwarf galaxy population in this rich environment for the first time at wavelengths longer than 1 micron. We identify and classify all galaxies detected within an area of 0.5 deg2 centered around the center of the Coma cluster down to a limiting magnitude of Ks = 18 mag. The majority of these sources are faint red galaxies that have been missed by previous optical surveys due to their low surface brightnesses. Using photometric redshift estimates we find that most of them lie between z=0.1 and z=1.0. By comparing our sample to existing spectroscopic data sets we show that our NIR selection is complete up to M* ~ - 17 + 5 log h70. This corresponds roughly to L*(z=0), but it should be noted that there may still exist some fainter dwarfs below our detection limit.",
        "watermark_text": "We present new near - infrared ( NIR ) observations of the Coma cluster using the Infrared Array Camera on board the Spitzer Space Telescope , which allow us to study the dwarf galaxy community in this rich environment for the first time at wavelengths greater than 1 micron . We recognize and classify all galaxies found within an area of 0 . 5 deg2 centered around the center of the Coma cluster down to a limiting magnitude of Ks = 18 mag .The majority of these sources are faint red objects that have been missed by current visual observations due to their low exterior brightnesses . Using photometric redshift estimates we find that most of them reside between z = 0 . 1 and z = 1 . 0 .By matching our sample to existing spectroscopic data sets we indicate that our NIR selection is complete up to M * ~ - 17 + 5 log h70 . This equals roughly to L * ( z = 0 ) , but it should be mentioned that there may still lie some fainter dwarfs below our detection limit .",
        "ori-fast-z-score": 1.5491933384829668,
        "water-fast-z-score": 5.422176684690384
    },
    {
        "original_text": "We present the results of long-term numerical simulations of binary black hole (BBH) evolution, including gravitational radiation reaction and general relativistic effects such as frame dragging and tidal disruption. We focus on binaries with total mass M = 100-1000M⊙ that evolve through collisional nuclear environments at high redshifts z > 10. Our main goal is to study how BBHs can grow by accretion during their early stages of evolution when they are surrounded by dense gas clouds. In particular we investigate whether these systems can reach masses above 1000M⊙ before merging within a Hubble time. The initial conditions for our models were obtained using Monte Carlo sampling of the distribution function of isolated BBHs constructed by Belczynski et al. (2010) . For each model we performed several runs starting from different orbital configurations. All calculations were carried out assuming circular orbits. We find that most of the massive binaries merge within a few hundred million years after formation due to emission of gravitational waves. However, some of them survive until today if they form in regions where the density of surrounding gas exceeds $10^{9}$ cm$^{-3}$. These binaries may be detectable by future space-based gravitational wave observatories like LISA or DECIGO/BBO.",
        "watermark_text": "We present the conclusion of long - term numerical simulations of binary dark hole ( BBH ) development , notably gravitational radiation reaction and general relativistic effects such as frame dragging and tidal disruption . We focus on binaries with total mass M = 100 - [UNK] that develop through collisional nuclear habitats at high redshifts z > 10 .Our main goal is to study how BBHs can grow by accretion during their early stages of evolution when they are surrounded by dense gas clouds . In particular we investigate whether these systems can reach masses above [UNK] before merging within a Hubble time .The initial conditions for our models were obtained using Monte Carlo analysis of the distribution function of isolated BBHs generated by Belczynski et al . ( 2010 ) .For each model we performed numerous runs beginning from varying orbital locations . All calculations were carried out assuming circular orbits .We see that most of the huge binaries dissolve within a few hundred million months after formed due to emission of gravitational waves . However , some of them remain until today if they exist in areas where the density of neighbouring gas approaches $ 10 ^ { 9 } $ cm $ ^ { - 3 } $ .These binaries may be detectable by future space - based gravity wave observatories like LISA or DECIGO / BBO .",
        "ori-fast-z-score": 0.5129891760425771,
        "water-fast-z-score": 5.437685266051317
    },
    {
        "original_text": "We present near-infrared (NIR) imaging and spectroscopy of star formation activity in the Bok globule CB 54, which is located at a distance of about 1 kpc toward the Galactic anti-center direction. We found that there are two young stellar objects (YSOs), one Class I protostar with an infrared luminosity of ~10 Lsun and another embedded YSO candidate with a bolometric temperature of ~1000 K. The former object shows bipolar outflows traced by Herbig-Haro knots and molecular line wings. In addition to these two sources, we detected several other point-like NIR sources within the central region of CB 54. These may be low-mass pre-main-sequence stars or background galaxies. Our results suggest that this cloud core has experienced active star formation over its lifetime. \n \n Keywords: Star formation; Near-infrared spectroscopy; Bipolar outflow; Young stellar object",
        "watermark_text": "We present near - infrared ( NIR ) imaging and spectroscopy of galaxy formation activity in the Bok globule CB 54 , which is situated at a distance of about 1 kpc toward the Galactic anti - center position . We showed that there are two young stellar bodies ( YSOs ) , one Class I protostar with an infrared luminosity of ~ 10 Lsun and another embedded YSO candidate with a bolometric temperature of ~ 1000 K . The former object displays bipolar outflows traced by Herbig - Haro knots and molecular line wings .In addition to these two sources , we spotted various other point - like NIR components within the central region of CB 54 . These may be low - weight pre - principal - sequence stars or background galaxies .Our results show that this cloud core has undergone active star formation over its lifetime . Keywords : Star formation ; Near - infrared spectroscopy ; Bipolar outflow ; Young stars object",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.640679257301507
    },
    {
        "original_text": "We consider the problem of successive refinement coding for layered broadcast systems, where each receiver is interested only in one out of several layers and can decode all other layers as side information at no cost. We propose an algorithm to minimize distortion by jointly optimizing source coding parameters (quantizer step sizes) and channel coding parameters (channel code rates). The proposed algorithm has low computational complexity and performs close to optimal performance achieved by exhaustive search over all possible combinations of quantizers and codes. Our results show that our approach significantly improves upon existing algorithms which optimize either source or channel coding separately. \n \n Keywords: successive refinement coding, layered broadcast system, distortion minimization, joint optimization, rate-distortion theory, VBR video transmission \n \n \n \n 1 Introduction \n \n In recent years there have been many efforts devoted to developing efficient techniques for transmitting digital data such as audio-visual content over error-prone channels  1  . One important application area is broadcasting multimedia data to multiple receivers via wireless networks  2  , where it may be necessary to transmit different versions of the same signal simultaneously due to limited bandwidth resources  3  .\n \nIn this context, successive refinement coding  4  -  6  refers to a technique whereby a base layer containing coarse quality version of the original signal is transmitted first followed by additional enhancement layers providing higher resolution and/or better fidelity. Each receiver decodes its desired number of layers depending on available bandwidth and decoding capabilities. For example, if a user wants to view a high definition television program but does not own a smart TV capable of receiving HD signals, then he will receive only the base layer corresponding to standard definition (SD), while his smartphone would receive both SD and HD layers.",
        "watermark_text": "We consider the issue of successive refinement compression for layered broadcast systems , where each receiver is interested only in one out of several layers and can decode all other layers as side data at no price . We suggest an algorithm to minimize distortion by jointly optimizing source coding variables ( quantizer step lengths ) and channel code variables ( channel code rates ) .The proposed algorithm has low computational complexity and exhibits nearly to optimal performance achieved by exhaustive search over all possible combinations of quantizers and coding . Our results show that our approach dramatically improves upon existing algorithms which optimize either source or channel code separately .Keywords : multiple refinement compression , layered broadcast network , noise minimization , joint optimization , rate - disturbance theory , VBR television broadcasting 1 Introduction In recent years there have been many efforts devoted to developing optimal methods for transmitting digital data such as audio - visual content over mistake - susceptible channels 1 . One important use area is transmitting multimedia data to multiple receivers via wireless networks 2 , where it could be required to transmit different versions of the same signal concurrently due to limited bandwidth supplies 3 .In this sense , successive refinement coding 4 - 6 refers to a technique whereby a base element containing coarse quality version of the original signal is transmitted initially followed by additional enhancement layers supplying faster clarity and / or improved fidelity . Each receiver decodes its specified quantity of layers depending on available frequencies and decoding skills .For instance , if a consumer wants to see a high resolution television show but does not own a smart TV capable of receiving HD transmissions , then he will receive only the base component corresponding to standard definition ( SD ) , while his smartphone would receive both SD and HD layers .",
        "ori-fast-z-score": 0.318222913670292,
        "water-fast-z-score": 7.741442779335935
    },
    {
        "original_text": "We present an exact time-domain analysis for the scattering by cloaks with arbitrary shapes and constitutive parameters, based on the method of moments in conjunction with the generalized sheet transition conditions. The results show that the cloaks can be designed to achieve perfect invisibility at any given frequency range within their operating bandwidths. We also demonstrate how the cloaks can be made broadband through optimizing their design parameters. Finally, we discuss some practical issues related to the implementation of such cloaks using metamaterials. C loak is one of the most fascinating concepts in electromagnetics  1  . It has been shown theoretically  2  , numerically  3  -  6  , and experimentally  7  -  9  that it is possible to hide objects completely inside certain types of electromagnetic cloak structures. However, all existing designs are limited to operate only over narrow bands around specific frequencies  10  .\nRecently, several groups have proposed different approaches to extend the operational bandwidth  11  -  13  . In particular, Li et al.  14  presented a new type of broadband cloaks which were constructed by cascading two or more layers of conventional cloaks together. Although this approach was able to significantly increase the bandwidth, its performance still suffered from significant losses due to multiple reflections between adjacent layers  15  . To overcome these problems, Liu et al.  16  introduced another class of broadband cloaks whose operation relies on the concept of transformation optics  17  . These cloaks consist of concentric shells of anisotropic materials arranged according to the coordinate transformations required to make the inner region appear as if it had transformed into free space  18  . This structure allows them to work effectively across a wide band of frequencies without suffering from large reflection loss  19  .",
        "watermark_text": "We present an precise time - domain evaluation for the scattering by cloaks with arbitrary shapes and constitutive characteristics , using on the method of moments in partnership with the generalized sheet transfer conditions . The results show that the cloaks can be designed to achieve perfect invisibility at any certain frequency spectrum within their operating bandwidths .We additionally explain how the cloaks can be made broadband through optimizing their design characteristics . Finally , we explain some practical concerns concerning to the implementation of such cloaks using metamaterials .C loak is one of the most important concepts in electromagnetics 1 . It has been shown theoretically 2 , numerically 3 - 6 , and experimentally 7 - 9 that it is easy to hide items completely inside particular kinds of electromagnetic shield structures .However , all proposed models are limited to run only over limited bands around specific frequencies 10 . Recently , various groups have proposed different strategies to widen the operational bandwidth 11 - 13 .In particular , Li et al . 14 described a new kind of broadband cloaks which were built by cascading two or more sheets of standard cloaks combined .Although this solution was able to significantly raise the bandwidth , its reliability nevertheless resulted from significant lost resulting to multiple reflections between neighboring layers 15 . To solve these problems , Liu et al .16 introduced another class of broadband cloaks whose action relies on the idea of transformation optics 17 . These cloaks consist of concentric shells of anisotropic materials arranged according to the coordinate transformations required to make the inner region appear as if it had converted into free space 18 .This structure allows them to work effectively across a broad band of bandwidth without experiencing from huge reflection loss 19 .",
        "ori-fast-z-score": -0.26413527189768715,
        "water-fast-z-score": 8.48528137423857
    },
    {
        "original_text": "We study the conformational properties of one- and two-component bottlebrush polymers in good solvent conditions by means of Monte Carlo (MC) simulations, using an off-lattice model with freely jointed chains. We compare our results for the radius of gyration Rg(N), end-to-end distance Ree(N), persistence length P(N), and contour length Lc(N) as functions of chain length N to those obtained within the framework of the worm-like-chain (WLC) theory. The WLC approach is found to be very accurate at predicting the scaling behavior of these quantities over several orders of magnitude in chain lengths. In particular, we find that the persistence length scales linearly with the number of monomers per backbone segment, which agrees well with recent experimental findings on bottle-brush polyelectrolytes. \n \n Keywords: Polymer brushes, Persistence length",
        "watermark_text": "We research the conformational characteristics of one - and two - component bottlebrush polymers in good solvent circumstances by means of Monte Carlo ( MC ) simulations , using an off - lattice model with freely jointed strands . We relate our findings for the radius of gyration Rg ( N ) , end - to - end distance Ree ( N ) , persistence length P ( N ) , and contour distance Lc ( N ) as functions of chain length N to those achieved within the framework of the worm - like - chain ( WLC ) theory .The WLC approach is found to be very accurate at predicting the scaling behavior of these quantities over numerous orders of magnitude in chain lengths . In particular , we find that the persistence length varies linearly with the quantity of monomers per backbone segment , which agrees well with recent experimental discoveries on bottle - brush polyelectrolytes .Keywords: Polymer brushes, Persistence length",
        "ori-fast-z-score": 0.6868028197434451,
        "water-fast-z-score": 4.2581774824093594
    },
    {
        "original_text": "We present an analytical solution for the dependence of soil moisture in a hillslope profile on saturation at its base, which is determined by groundwater table fluctuations and rainfall infiltration into the saturated zone. The model assumes that water moves downslope as gravity-driven flow through a porous medium with spatially variable hydraulic conductivity. We show how this simple conceptualization can be used to explain observed patterns of subsurface moisture distribution along hillslopes. Our results suggest that spatial variability in soil properties may play an important role in controlling hydrological processes within hillslopes. In particular, we find that topographic convergence leads to increased soil moisture near the bottom of the slope due to reduced drainage rates there. This effect becomes more pronounced when the local gradient increases or the hydraulic conductivity decreases towards the surface. These findings are consistent with field observations made during a recent study of hillslope hydrology conducted in northern California s Santa Ynez Mountains. \n \n Keywords: Hillslope hydrology, Groundwater table",
        "watermark_text": "We present an analytical solution for the dependence of soil rainfall in a hillslope profile on saturation at its base , which is governed by groundwater table fluctuations and rainfall infiltration into the saturated zone . The model assumes that water moves downslope as gravity - guided flow through a porous medium with spatially varying mechanical conductivity .We indicate how this straightforward conceptualization can be used to explain observed patterns of subsurface moisture variation along hillslopes . Our results show that geographic variability in soil properties may play an important role in controlling hydrological processes within hillslopes .In particular , we find that topographic convergence leads to greater soil rainfall near the bottom of the elevation owing to lowered irrigation rates there . This phenomenon grows more pronounced when the local gradient changes or the hydraulic conductivity decreases towards the surface .These conclusions are compatible with field observations made during a recent study of hillslope hydrology conducted in northern California s Santa Ynez Mountains . Keywords : Hillslope hydrology , Groundwater table",
        "ori-fast-z-score": 1.8599622199011085,
        "water-fast-z-score": 6.974858324629157
    },
    {
        "original_text": "The present work is devoted to study some properties of curves in P^3 having an exceptional secant plane, i.e., such that there exists a line intersecting them at two points and not passing through any other point on the curve.  We give necessary conditions for a curve to have an exceptional secant plane (Proposition 1). Then we prove that if a curve has an exceptional secant plane then it lies on a quadric surface (Theorem 2).  Finally, using this result, we show how one can construct all possible families of curves with an exceptional secant plane by means of their associated linear systems (Theorems 3-7).\nKey words: Curve, Secant Plane, Quadric Surface. Mathematics Subject Classification (2000): 14C20, 14D10, 32S15. The research leading to these results was supported by the Russian Foundation for Basic Research under grant No. 02-01-00962-a",
        "watermark_text": "The present work is devoted to study some properties of curves in P ^ 3 having an exceptional secant plane , i . e . , such that there exists a line intersecting them at two points and not passing through any other point on the curve . We take necessary conditions for a curve to have an exceptional secant plane ( Proposition 1 ) .Then we prove that if a curve has an exceptional secant plane then it lies on a quadric surface ( Theorem 2 ) . Finally , using this result , we prove how one can build all possible families of curves with an exceptional secant plane by means of their associated continuous systems ( Theorems 3 - 7 ) .Key words: Curve, Secant Plane, Quadric Surface.Mathematics Subject Classification (2000): 14C20, 14D10, 32S15.The studies leading to these results was supported by the Russian Foundation for Basic Research under grant No . 02 - 01 - 00962 - a",
        "ori-fast-z-score": 1.5714285714285714,
        "water-fast-z-score": 2.82842712474619
    },
    {
        "original_text": "We present new high resolution (R = λ/Δλ ~ 20,000) far-ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE), as well as archival Hubble Space Telescope (HST) data for the hot white dwarf central star in the planetary nebula Sh2-216. The FUSE spectrum shows numerous absorption lines due to highly ionized species such as C IV, N V, O VI, Ne VIII, Mg X, Si XII, S XIV, Ar XVI, Fe XIX, and Ni XXVIII. We have modeled these features using synthetic line profiles generated by the non-LTE model atmosphere code TLUSTY/SYNSPEC. Our best-fit models indicate that this star has an effective temperature T eff = 120,000 K, surface gravity log g = 8.0, mass M = 0.6M☉ , radius R = 0.01R☉ , and is surrounded by a shell of material with density n(He II)/n(He I) = 1.5 x 10-3 .",
        "watermark_text": "We use new high resolution ( R = λ / Δλ ~ 20 , 000 ) far - ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer ( FUSE ) , as well as archival Hubble Space Telescope ( HST ) statistics for the cool white dwarf central star in the planetary nebula Sh2 - 216 . The FUSE spectrum displays several absorption patterns due to strongly ionized species such as C IV , N V , O VI , Ne VIII , Mg X , Si XII , S XIV , Ar XVI , Fe XIX , and Ni XXVIII .We have analyzed these characteristics utilizing artificial line profiles generated by the non - LTE model atmosphere code TLUSTY / SYNSPEC . Our best - fitting models suggest that this star has an effective heat T eff = 120 , 000 K , surface gravity log f = 8 . 0 , mass M = 0 . 6M☉ , diameter R = 0 . 01R☉ , and is enclosed by a shell of material with volume n ( He II ) / n ( He I ) = 1 . 5 x 10 - 3 .",
        "ori-fast-z-score": -1.5109662034355793,
        "water-fast-z-score": 3.6055512754639896
    },
    {
        "original_text": "We have studied the spin relaxation and dephasing processes in semiconductor quantum dots (QDs) by solving numerically the full set of equations for electron-electron interactions within the framework of the equation-of-motion method. We found that, at low temperatures, the dominant mechanism responsible for spin relaxation is due to spin-flip scattering with acoustic phonons. The calculated results are compared favorably with available experimental data on QD ensembles. In addition, we show that the inclusion of exchange interaction between electrons leads to an increase in the spin relaxation time as well as to a reduction in its temperature dependence. \n \n Spin dynamics plays an important role in many physical phenomena such as magnetic resonance imaging  1  , magneto-optical effects  2  , and spintronics  3  . Semiconductor quantum dots (QDs), which can be viewed as artificial atoms  4  , provide us with unique opportunities to study spin relaxation and dephazing mechanisms  5  -  8  . Recently, there has been considerable interest in studying these issues both experimentally  9  -  11  and theoretically  12  -  16  .\nIn this work, we investigate spin relaxation and dephazation processes in QDs using the equation-of-motion (EOM) method  17  . This method allows one to take into account all possible contributions to the self-energy arising from different types of electron-electron interactions including direct Coulomb repulsion, exchange-correlation potential, Hartree-Fock corrections, and correlation energy  18  . It should be noted that our calculations were performed without any additional approximations beyond those used in previous studies based on the EOM formalism  19  -  21  . \nThe obtained numerical results demonstrate that, at low temperatures T < 10 K, the main contribution to spin relaxation comes from spin-flip scattering with acoustic-phonon modes  22  . At higher temperatures, however, other mechanisms become more significant leading to faster spin relaxation times. Our theoretical predictions agree reasonably well with existing experimental data on QD ensembles  23  . \n \n Finally, it was shown that the inclusion of exchange interactions between electrons leads to an enhancement of the spin relaxation rate as well as to a decrease in its temperature dependence  24  .",
        "watermark_text": "We have researched the spin relaxation and dephasing mechanisms in semiconductor quantum dots ( QDs ) by solving numerically the full set of equations for electron - ion interactions within the framework of the equation - of - movement technique . We identified that , at low temperatures , the dominant mechanism causing for spinning relaxation is due to spin - flip scattering with sound phonons .The measured outcomes are compared favorably with available experimental evidence on QD configurations . In addition , we find that the introduction of exchange behavior between electrons contributes to an increase in the spin relaxation time as well as to a reduction in its temperature dependence .Spin dynamics plays an important role in different physical phenomena such as magnetic resonance imaging 1 , magneto - optical phenomena 2 , and spintronics 3 . Semiconductor quantum dots ( QDs ) , which can be viewed as synthetic ions 4 , provide us with special opportunities to study spinning vibration and dephazing processes 5 - 8 .Recently , there has been substantial interest in investigating these problems both experimentally 9 - 11 and theoretically 12 - 16 . In this research , we investigate momentum relaxation and dephazation processes in QDs using the equation - of - movement ( EOM ) method 17 .This method enables one to take into consideration all possible contributions to the self - energy originating from multiple types of electron - ion interactions including direct Coulomb repulsion , transfer - correlation potential , Hartree - Fock corrections , and correlation power 18 . It should be mentioned that our calculations were performed without any additional approximations beyond those utilized in earlier studies based on the EOM formalism 19 - 21 .The derived mathematical findings show that , at low temperatures T < 10 K , the main contribution to spinning relaxation comes from spinning - flip scattering with sound - phonon modes 22 . At higher temperatures , however , other mechanisms become more prominent leading to faster momentum relaxation times .Our theoretical estimates agree reasonably well with existing experimental evidence on QD groups 23 . Finally , it was shown that the introduction of exchange interactions between electrons contributes to an enhancement of the spin relaxation frequency as well as to a reduction in its temperature dependence 24 .",
        "ori-fast-z-score": 0.3086066999241838,
        "water-fast-z-score": 8.538461538461538
    },
    {
        "original_text": "The rapidity and transverse momentum (pT) dependences of the electric charge correlation functions are studied for central Au+Au, d+Au and p+p collisions at RHIC and LHC energies using the AMPT model with string melting mechanism. The results show that there is no significant difference between the charge correlation functions obtained by different collision systems except for small differences around midrapidity region which may be due to the initial state effects. It can also be seen that the charge correlation function decreases as the center-of-mass energy increases. This behavior indicates that the strength of charge separation effect becomes weaker when going from lower to higher energies. Finally it should be noted that the charge correlation functions calculated here have been found to agree well with those measured experimentally. PACS numbers: 25.75.-q, 11.15.-x, 12.38.Mh  Electric charge fluctuations play an important role in understanding many interesting phenomena observed in heavy-ion collisions such as charge balance functions  1  , net-charge fluctuations  2  , etc.. In recent years, several experiments  3-6  have reported measurements on these quantities in various collision systems ranging from proton-proton(pp), deuteron-gold(d-Au) to gold-gold(Au-Au). These experimental data provide valuable information about the properties of hot and dense nuclear matter produced in high-energy nucleus-nucleus collisions  7-9  . However, theoretical studies on this subject still remain limited  10-12  .\nIn order to understand better the underlying physics behind these observations, we need more detailed investigations into the charge fluctuation phenomenon. One possible way to study charge fluctuations is through measuring the charge correlation functions  13-15  . Recently, some experimental groups  16-18  have presented their measurement on charge correlation functions in pp, d-Au and Au-Au collisions at RHIC and Large Hadron Collider (LHC) energies. On the other hand, the relativistic quantum molecular dynamics (RQMD)  19  and the parton-hadron-string dynamics (PHSD)  20  models predict that the charge correlation functions decrease rapidly towards zero",
        "watermark_text": "The rapidity and transverse momentum ( pT ) dependences of the electric charge interaction functions are studied for central Au + Au , d + Au and p + p collisions at RHIC and LHC energies using the AMPT theory with string melting system . The results show that there is no considerable difference between the charge correlation functions obtained by various collision systems except for little differences around midrapidity region which may be due to the early state effects .It can also be shown that the charge correlation function decreases as the center - of - mass momentum increases . This phenomenon suggests that the strength of mass separation effect gets smaller when going from lower to higher energies .Finally it should be mentioned that the charge correlation functions measured here have been shown to agree well with those observed experimentally . PACS codes : 25 . 75 . - q , 11 . 15 . - x , 12 . 38 . Mh Electric charge fluctuations play an important role in understanding several interesting phenomena observed in heavy - ion collisions such as charge balance tables 1 , net - charge fluctuations 2 , etc . .In past times , various study 3 - 6 have reported measurements on these quantities in different collision systems ranging from proton - proton ( pp ) , deuteron - platinum ( d - Au ) to platinum - silver ( Au - Au ) . These observation information provide valuable info about the properties of hot and dense nuclear material created in high - energy nucleus - nucleus collisions 7 - 9 .However , theoretical experiments on this question also remain limited 10 - 12 . In order to realize well the fundamental theory behind these observations , we require more precise studies into the charge fluctuation process .One could way to study charge fluctuations is through study the charge relationship values 13 - 15 . Recently , some experimental groups 16 - 18 have published their observation on charge correlation functions in pp , d - Au and Au - Au collisions at RHIC and Large Hadron Collider ( LHC ) frequencies .On the other hand , the relativistic quantum molecular mechanics ( RQMD ) 19 and the parton - hadron - string theory ( PHSD ) 20 models predict that the charge interaction functions decline rapidly towards zero",
        "ori-fast-z-score": -0.3104602102825331,
        "water-fast-z-score": 7.869470848066687
    },
    {
        "original_text": "We present an overview of our efforts to find planets around stars with high proper motions using data obtained by the TrES space telescope, which was launched on December 6, 2005. We have found that many of these systems are likely false positives due to blending between the target star and nearby fainter companions or background objects. In this talk we will discuss how we used photometric variability combined with radial velocity measurements to identify these false positive cases. We also describe some of the techniques we use for identifying new candidate exoplanetary systems based on their light curves alone. Finally, I will show you what happens when one tries to measure the mass of a planet orbiting such a fast moving star as HD 128598 (Proxima Centauri). This is part of my Ph.D thesis work at Harvard University under the supervision of Dr. Paul Butler. My research interests include finding extrasolar planets via direct imaging and transit methods, studying the atmospheres of transiting exoplanets, and searching for habitable worlds beyond our solar system.",
        "watermark_text": "We present an overview of our work to find planets around stars with high proper motions utilizing information obtained by the TrES spacecraft telescope , which was launched on December 6 , 2005 . We have discovered that several of these systems are likely false positives due to mixing between the target star and distant fainter companions or background variables .In this talk we will explore how we using photometric variability coupled with radial speed measurements to identify these false positive cases . We also describe some of the methods we using for finding new likely exoplanetary systems based on their light curves alone .Finally , I will show you what happens when one attempts to measure the mass of a planet orbiting such a rapidly motion star as HD 128598 ( Proxima Centauri ) . This is part of my Ph . D doctoral research at Harvard University under the guidance of Dr . Paul Butler .My research interests cover finding extrasolar stars via direct detection and transit methods , studying the atmospheres of transiting exoplanets , and searching for habitable worlds beyond our solar system .",
        "ori-fast-z-score": -0.45291081365783825,
        "water-fast-z-score": 4.98201895023622
    },
    {
        "original_text": "We present high angular resolution observations (0.1′′) of dust continuum, molecular line emissions, and maser lines toward the prototypical massive star-forming region G29.96-0 . 02 with the Submillimeter Array (SMA). The SMA data reveal that this source is composed of two compact components separated by 0.3 ′′ , which are associated with different physical processes. One component shows strong thermal dust emission peaking at 345 GHz as well as intense methanol masers distributed along an arc-like structure centered on it. This component coincides spatially with a bright infrared source detected by Spitzer Space Telescope. We propose that this component represents a hot core where massive star formation takes place. The other component exhibits weak dust continuum emission but strong SiO(5-4), SO2(34-26), CH3OH(7-6), and CH 3 CN(12-11) lines. These results suggest that this component may be tracing shocked regions driven by outflows or jets from young stellar objects embedded within the hot core.",
        "watermark_text": "We present high angular resolution measurements ( 0 . 1 ′ ′ ) of dust continuum , molecular line emissions , and maser lines toward the prototypical heavy star - creating area G29 . 96 - 0 . 02 with the Submillimeter Array ( SMA ) .The SMA data reveal that this source is composed of two compact components joined by 0 . 3 ′ ′ , which are related with various physical processes . One component displays strong thermal dust radiation stopping at 345 GHz as well as powerful methanol masers distributed along an arc - like structure focused on it .This source coincides spatially with a bright infrared source detected by Spitzer Space Telescope . We suggest that this component indicates a hotter core where enormous star formation took place .The other component displays mild dust continuum emission but bright SiO ( 5 - 4 ) , SO2 ( 34 - 26 ) , CH3OH ( 7 - 6 ) , and CH 3 CN ( 12 - 11 ) lines . These data suggest that this component may be tracing shocked regions driven by outflows or jets from young stellar bodies lodged within the hotter disk .",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 5.20847435706514
    },
    {
        "original_text": "We prove that if an operator is adjointable, then it has dense range in its domain.  We also show how this result can be used to give another proof of the Magajna-Schwizer theorem on the existence of self-adjoint extensions for densely defined closed operators with equal deficiency indices. Let H be a Hilbert space over C. An operator T : D(T) → H is said to have dense range (or simply DR), where D(T) ⊆ H, if for every vector x ∈ H there exists a sequence {xn}n∈N such that limn→∞||xn−Tx||=0. In other words, the image of T contains no proper subspace of H. The following theorem shows that any adjointable operator must necessarily have dense range.   THEOREM 1.1. If T:D(T)⊆H→H is adjointable, then R(T∗)=D(T).",
        "watermark_text": "We showed that if an operator is adjointable , then it has dense range in its domain . We also demonstrate how this fact can be used to give another proved of the Magajna - Schwizer theorem on the existence of self - adjoint extensions for tightly defined closed operators with equal deficiency indices .Let H be a Hilbert space over C . An operator T : D ( T ) → H is said to have dense range ( or simply DR ) , where D ( T ) ⊆ H , if for every matrix x ∈ H there exists a sequence { xn } n∈N such that limn→∞ | | xn−Tx | | = 0 . In other words , the image of T contains no complete subspace of H . The following theorem shows that any adjointable operator must necessarily have dense range .THEOREM 1.1.If T:D(T)⊆H→H is adjointable, then R(T∗)=D(T).",
        "ori-fast-z-score": 0.29488391230979427,
        "water-fast-z-score": 2.06418738616856
    },
    {
        "original_text": "We consider the problem of approximating an unknown function f in L^2(0,1) by a linear combination of orthonormal polynomials with respect to some weight function w on (0,1). We show that if we choose the weights so as to minimize the error between the approximation and the true solution then this leads to a system of equations which can be solved using spectral methods. The resulting algorithm is shown to have optimal convergence rates under certain conditions. In particular it has been proved recently that if the coefficients of the expansion are chosen optimally then the rate of convergence is O(N^{-2}), where N denotes the number of terms used in the expansion. \nThe main purpose of this thesis was to implement these algorithms numerically and compare their performance against other existing techniques such as Chebyshev expansions or Legendre expansions. This work will also allow us to investigate whether there exist any advantages associated with choosing different types of basis functions when solving differential equations.",
        "watermark_text": "We consider the question of approximating an unknown function f in L ^ 2 ( 0 , 1 ) by a linear mixture of orthonormal polynomials with regard to some weight distribution w on ( 0 , 1 ) . We see that if we choose the weights so as to minimize the error between the approximation and the true answer then this results to a system of equations which can be answered using spectral algorithms .The resulting algorithm is demonstrated to have optimal convergence rates under certain conditions . In particular it has been determined recently that if the coefficients of the expansion are chosen optimally then the frequency of convergence is O ( N ^ { - 2 } ) , where N describes the number of words using in the expansion .The main aim of this dissertation was to execute these algorithms numerically and compare their performance against other existing techniques such as Chebyshev expansions or Legendre expansions . This research will also enable us to examine whether there exist any advantages associated with choosing particular kinds of basis variables when solving differential equations .",
        "ori-fast-z-score": -1.3054598240132387,
        "water-fast-z-score": 4.153735803678487
    },
    {
        "original_text": "We report on the detection of an oscillatory pattern with periods between 5 and 20 minutes, which is observed to be associated with sunspots  penumbrae. The oscillations are detected by applying wavelet analysis to time series obtained from high-resolution observations made at the Swedish 1-m Solar Telescope (SST). We find that these oscillations have amplitudes up to 0.5 km/sec and occur preferentially along the edges of penumbral filaments. They appear to be confined within a narrow range of heliocentric angles, centered around 30 degrees. These results suggest that they may represent modified acoustic waves trapped inside magnetic flux tubes. This work was supported by NASA grants NAG5-7067 and NNG04GK85G. Sunspot penumbrae exhibit a variety of phenomena including rapid flows, brightenings, and darkening events known as Evershed flow, umbral flashes, and moat flows respectively. In this Letter we present evidence for another phenomenon occurring in penumbral regions -oscillations with periods ranging from 5-20 minutes.",
        "watermark_text": "We report on the observation of an oscillatory system with periods between 5 and 20 minutes , which is observed to be correlated with sunspots penumbrae . The oscillations are detected by using wavelet study to time sequences obtained from high - resolution measurements made at the Swedish 1 - m Solar Telescope ( SST ) .We see that these oscillations have amplitudes up to 0 . 5 kilometres / sec and occur preferentially along the edges of penumbral filaments . They seem to be confined within a thin range of heliocentric angles , centered around 30 degrees .These data suggest that they may form altered acoustic waves stuck inside magnetic flux tubes . This research was supported by NASA grants NAG5 - 7067 and NNG04GK85G .Sunspot penumbrae exhibit a variety of phenomena including rapid flows , brightenings , and darkening phenomena known as Evershed flow , umbral flashes , and moat waves respectively . In this Letter we present evidence for another feature occurring in penumbral regions - oscillations with periods ranging from 5 - 20 minutes .",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 6.325771464049632
    },
    {
        "original_text": "We present an algorithm for quantum search that is based on the Grover s algorithm and uses only two qubits to represent one item in the database, which can be viewed as a binary number. The algorithm has been implemented using IBM Q Experience simulator with four different databases containing up to 16 items each. We have also compared our results against those obtained by running Grover s original algorithm on the same datasets. Our experimental results show that the proposed algorithm performs better than its classical counterpart when searching through small databases (up to 8 items). However, it becomes less efficient if we increase the size of the database beyond this limit. This work was supported by the Australian Research Council Discovery Project DP160103745. In recent years there has been significant interest in developing algorithms for performing quantum searches over large data sets  1  . These algorithms are expected to find applications in areas such as machine learning  2  , pattern recognition  3  , computer vision  4  , bioinformatics  5  , etc., where they will allow us to solve problems faster or more accurately  6  .\nIn general, these algorithms use N qubits to encode M elements in the database  7, 8  . For example, Grover s algorithm  9  requires O( √ N/M ) iterations to find any single element out of M elements encoded into N qubits  10  . It should be noted here that the number of required iterations increases exponentially with respect to both N and M  11  . Therefore, these algorithms become inefficient when dealing with very large databases  12  .",
        "watermark_text": "We introduce an algorithm for quantum search that is based on the Grover s algorithm and using only two qubits to represent one element in the database , which can be viewed as a binary value . The algorithm has been deployed using IBM Q Experience simulator with four different databases containing up to 16 artifacts each .We have already compared our findings against those achieved by running Grover s original method on the same datasets . Our research results show that the suggested method performs better than its classical rival when looking through tiny data ( up to 8 objects ) .However , it becomes slower efficient if we increase the length of the database beyond this limit . This research was supported by the Australian Research Council Discovery Project DP160103745 .In recent years there has been significant interest in building methods for performing quantum searches over large data sets 1 . These methods are expected to find uses in areas such as machine computing 2 , image learning 3 , computer vision 4 , bioinformatics 5 , etc . , where they will let us to solve issues quicker or more accurately 6 .In general , these algorithms use N qubits to encode M elements in the database 7 , 8 . For instance , Grover s algorithm 9 requires O ( √ N / M ) iterations to find any single element out of M elements stored into N qubits 10 .It should be mentioned here that the number of required iterations increases exponentially with regard to both N and M 11 . Therefore , these algorithms get inefficient when dealing with very huge databases 12 .",
        "ori-fast-z-score": -0.19802950859533489,
        "water-fast-z-score": 7.389969586232199
    },
    {
        "original_text": "The aim of this book is to provide an overview on the state-of-the-art in on-line condition monitoring and fault diagnosis for industrial processes, with special emphasis on computational intelligence techniques such as neural networks (NNs), fuzzy logic systems (FLS) or evolutionary algorithms (EAs). The book covers both theoretical aspects and practical applications of these methods. It also discusses some recent advances in intelligent sensor technologies that are essential for successful implementation of on-line condition monitoring schemes. This book will be useful not only for researchers but also for engineers who want to apply computational intelligence techniques into their own research work. Contents include:  Chapter 1: Introduction to On-line Condition Monitoring.  Chapter 2: Intelligent Sensors for On-line Condition Monitoring.  Chapters 3-7: Neural Networks for Fault Diagnosis.  Chapters 8-10: Fuzzy Logic Systems for Fault Diagnosis.   Chapters 11-13: Evolutionary Algorithms for Fault Diagnosis.   ...",
        "watermark_text": "The goal of this paper is to provide an overview on the state - of - the - art in on - line condition monitoring and failure detection for industrial systems , with special emphasis on computational intelligence techniques such as neural systems ( NNs ) , fuzzy logic systems ( FLS ) or ecological computers ( EAs ) . The text encompasses both theoretical components and useful users of these algorithms .It additionally outlines some latest advances in intelligent detection systems that are essential for successful implementation of on - line condition monitoring schemes . This book will be valuable not only for researchers but also for designers who desire to apply computational intelligence techniques into their own research effort .Contents comprise : Chapter 1 : Introduction to On - line Condition Monitoring . Chapter 2 : Intelligent Sensors for On - line Condition Monitoring .Chapters 3-7: Neural Networks for Fault Diagnosis.Chapters 8-10: Fuzzy Logic Systems for Fault Diagnosis.Chapters 11-13: Evolutionary Algorithms for Fault Diagnosis....",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 5.75
    },
    {
        "original_text": "We present predictions on the formation rates, masses, orbital parameters, and spin periods of triple stars that contain at least one pulsar (PSR). We use Monte Carlo simulations to generate populations of binaries and triples using distributions of initial binary properties derived from observations of open clusters. The population synthesis is performed by combining our new code for simulating the evolution of close binaries containing PSRs with an existing code for simulating the dynamical interactions between multiple stellar systems. Our results show that most observed PSRs are likely to be found as members of hierarchical triples rather than isolated double neutron star systems or wide binaries. In particular, we find that:  - Most PSRs should have companions whose mass lies within 0.1 M⊙ < Mc < 1.0 M⊙; - Most PSRs should reside in orbits with semi-major axes less than 100 AU; - Most PSRs will not evolve into millisecond pulsars before their second supernova explosion; - Most PSRs may experience significant gravitational wave emission during their lifetimes.",
        "watermark_text": "We report estimates on the formation rates , masses , orbital variables , and spin times of triple stars that host at least one pulsar ( PSR ) . We use Monte Carlo simulations to create populations of binaries and triples using distributions of initial binary properties derived from measurements of open nuclei .The population synthesis is conducted by combining our new code for simulating the evolution of close binaries containing PSRs with an previous code for simulating the dynamical interactions between multiple stellar systems . Our results show that most observed PSRs are likely to be found as members of hierarchical triples rather than scattered double neutron star systems or broad binaries .In particular , we find that : - Most PSRs should have companions whose mass falls within 0 . 1 [UNK] < Mc < 1 . 0 [UNK] ; - Most PSRs should exist in planets with semi - major axes less than 100 AU ; - Most PSRs will not evolve into millisecond pulsars before their second supernova explosion ; - Most PSRs might experience considerable gravitational wave radiation during their lifetimes .",
        "ori-fast-z-score": 0.7875615306482168,
        "water-fast-z-score": 4.837877973981903
    },
    {
        "original_text": "We present an analysis of the alignments between galaxy spins and tidal fields in real space, using data from the Two Mass Redshfit Survey (TMRS). We find that galaxies are preferentially aligned perpendicular to their local tidal field on scales larger than 1 Mpc/h. This alignment is stronger for more massive galaxies at higher redshifts. The observed spin-tide correlation can be explained by the effect of gravitational torques exerted by large-scale structures during the formation process of these galaxies. Our results suggest that this mechanism may play an important role in shaping galactic angular momenta. These findings have implications for understanding how dark matter halos acquire their angular momentum as well as for interpreting observations of cosmic shear statistics. Introduction: Galaxies form within overdense regions of the universe where they experience strong gravitational interactions with other objects such as neighboring galaxies or clusters of galaxies. During the formation process, these interactions induce gravitational torques which affect the orientation of the galactic angular momentum vector. In turn, the orientations of galactic angular momenta determine the shapes of galaxies through dynamical friction processes. Therefore, it has been suggested that the shape distribution of galaxies could provide information about the origin of galactic angular momentums (e.g., Catelan & Theuns 1996; Lee et al. 2008) . However, observational studies show conflicting results regarding whether there exists any preferred direction of galaxy spin axes relative to their neighbors  positions (see e.g., Faltenbacher et al. 2002; Bailin et al. 2005; Paz et al. 2008; Codis et al. 2012 , for recent works).\nIn order to understand the physical mechanisms responsible for determining the directions of galactic angular momentas, we need to study the statistical properties of galaxy spin distributions over large volumes of the universe. Recent surveys like Sloan Digital Sky Survey (SDSS) allow us to measure galaxy orientations accurately enough to perform such analyses. For example, Lee et al. (2008) used SDSS DR4 data to investigate the alignments between galaxy spin vectors and their nearest neighbor s position angles. They found no",
        "watermark_text": "We present an assessment of the alignments between galaxy spins and tidal fields in real space , using data from the Two Mass Redshfit Survey ( TMRS ) . We see that galaxies are preferentially aligned perpendicular to their nearby tidal field on scales bigger than 1 Mpc / h .This alignment is strengthened for more massive galaxies at higher redshifts . The observed spinning - tide relationship can be described by the impact of gravitational torques exerted by large - scale structures during the formation period of these objects .Our results propose that this mechanism may play an important role in shaping galactic angular momenta . These studies have consequences for studying how dark matter halos acquire their angular velocity as also as for interpreting observations of universe shear trends .Introduction : Galaxies shape within overdense regions of the universe where they encounter strong gravitational interactions with other structures such as nearby galaxies or rows of clusters . During the formation period , these interactions initiate gravitational torques which affect the orientation of the galactic angular velocity tensor .In turn , the orientations of galactic angular momenta determine the shapes of galaxies through dynamical friction mechanisms . Therefore , it has been proposed that the form distribution of stars could give information about the origin of galactic angular momentums ( e . g . , Catelan & Theuns 1996 ; Lee et al .2008 ) . However , observational analyses suggest conflicting findings regarding whether there exists any preferred direction of galaxy spin axes relative to their neighbors places ( saw e . g . , Faltenbacher et al .2002 ; Bailin et al . 2005 ; Paz et al .2008 ; Codis et al . 2012 , for recent works ) .In order to comprehend the physical mechanisms involved for determining the directions of galactic angular momentas , we require to study the statistical characteristics of galaxy spin distributions over large quantities of the universe . Recent surveys like Sloan Digital Sky Survey ( SDSS ) able us to measure galaxy orientations correctly sufficiently to conduct such analyses .For instance , Lee et al . ( 2008 ) used SDSS DR4 data to examine the alignments between galaxy spin vectors and their closest neighbor s position angles .They found no",
        "ori-fast-z-score": -0.8512055557875505,
        "water-fast-z-score": 7.140584836498262
    },
    {
        "original_text": "We study the SLE (Schramm-Loewner Evolution) process for the scaling limit of interfaces between different phases in the two-dimensional Ising model with nearest-neighbor interactions on an arbitrary planar graph, and its generalization to higher dimensions. We show that the interface is described by a chordal Schramm-Löwner evolution if the underlying lattice has no loops or multiple edges; otherwise it is described by a radial Schramm-Löwner evolutions. The results are obtained using conformal field theory techniques. In particular we use the fact that the partition function of these models can be written as a correlation function of primary fields in some rational conformal field theories. This allows us to obtain explicit formulas for the probability distribution functions of various geometric quantities associated with the interfaces such as their winding numbers around vertices etc.. \nIntroduction\n\nThe Schramm-Loewner Evolutions (SLE)\nprocesses were introduced by Schramm  Sch00  , who showed that they provide a natural description of the scaling limits of interfaces in statistical mechanics systems at criticality. These processes have been studied extensively since then both theoretically and numerically. For example, see  KSS02, SS04a, SS04b, RS05, Sch06, CS07, KS08, KSV09, KM10, MS11, MZ12, BMS13, BS14, LW15, GKS16, GM17, GK18, HJ19, HK20, JPS20  . A comprehensive review of this subject may be found in  Smi01, Sta03, Joh10  .\nIn this work we consider the SLE process for the scaling limit in two dimensions of interfaces separating different phases in the following class of models:  Let G = (V, E) be any finite connected planar graph without loops or multiple edges. Consider the Ising model with nearest neighbor interaction defined on G. That is, let {σv}v∈V denote a collection of random variables taking values +1 and −1, where each σv represents the state of vertex v ∈ V . Then",
        "watermark_text": "We work the SLE ( Schramm - Loewner Evolution ) process for the scaling maximum of interfaces between various phases in the two - dimensional Ising model with nearest - neighbor interactions on an arbitrary planar graph , and its generalization to higher dimensions . We see that the interface is characterized by a chordal Schramm - Löwner evolution if the underlying lattice has no loops or multiple edges ; otherwise it is characterized by a radial Schramm - Löwner evolutions .The results are derived using conformal field model approaches . In particular we utilize the fact that the splitting function of these models can be written as a correlation function of primary fields in some rational conformal field theories .This enables us to obtain precise formulas for the probability distribution functions of several geometric variables identified with the interfaces such as their winding numbers around vertices etc . . Introduction The Schramm - Loewner Evolutions ( SLE ) processes were introduced by Schramm Sch00 , who demonstrated that they give a natural characterization of the scaling limits of interfaces in statistical mechanics systems at criticality . These mechanisms have been studied frequently since then both theoretically and numerically .For instance , see KSS02 , SS04a , SS04b , RS05 , Sch06 , CS07 , KS08 , KSV09 , KM10 , MS11 , MZ12 , BMS13 , BS14 , LW15 , GKS16 , GM17 , GK18 , HJ19 , HK20 , JPS20 . A full study of this subject may be found in Smi01 , Sta03 , Joh10 .In this research we define the SLE method for the scaling limit in two dimensions of interfaces separating different stages in the following category of models : Let G = ( V , E ) be any finite connected planar graph without loops or multiple edges . Consider the Ising model with nearest neighbor behavior defined on G . That is , let { σv } v∈V denote a collection of random vectors take values + 1 and −1 , where each σv represents the state of vertex v ∈ V .Then",
        "ori-fast-z-score": 1.3750477455423171,
        "water-fast-z-score": 6.875238727711585
    },
    {
        "original_text": "We study the dynamics of the kinetic Ising model on square lattices with periodic boundary conditions by Monte Carlo simulations at finite temperatures T . We find that there is no static order parameter to characterize the dynamic phase transition, but we can define an effective conjugate field H conjugate to the magnetization M as follows: \nH = -ln(<M>)/T,\nwhere <M> denotes the average over all spins. The critical temperature Tc is determined by the condition dH/dT =0. In addition, we show that the fluctuation-dissipation theorem holds well near Tc. \nThe results are compared with those obtained by the mean-field approximation. \n\n\nI. INTRODUCTIO N\n\nIn recent years much attention has been paid to nonequilibrium phenomena such as relaxation processes after rapid changes of external parameters  1  , aging  2  , glassy behavior  3  , etc., because they play important roles not only in physics but also in biology  4  .\nAmong these topics, the kinetic Ising model  5  is one of the most popular models used to investigate non-equilibrium properties  6  . It describes the time evolution of spin variables S i (t) (i=1,...,N)\non a regular lattice under the influence of thermal fluctuations. Here t represents the number of Monte Carlo steps per site (MCS/s). At each step, every spin interacts with its nearest neighbors through exchange interactions J ij . Then it flips according to the Metropolis algorithm  7 :  if e -Sij / kBT > random number between 0 and 1 then flip S j else keep S j unchanged where k B is Boltzmann s constant and T is the absolute temperature. This process continues until equilibrium is reached or some other criterion is satisfied  8  .",
        "watermark_text": "We explore the dynamics of the kinetic Ising model on square lattices with periodic border conditions by Monte Carlo simulations at finite temperatures T . We see that there is no static order parameter to characterize the dynamic phase shift , but we can define an efficient conjugate field H conjugate to the magnetization M as follows : H = - ln ( < M > ) / T , where < M > denotes the average over all spins .The critical temperature Tc is chosen by the condition dH / dT = 0 . In addition , we prove that the fluctuation - dissipation conjecture works well near Tc .The results are compared with those achieved by the mean - field approximation . I . INTRODUCTIO N In recent years much attention has been paid to nonequilibrium phenomena such as relax processes after rapid variations of external parameters 1 , aging 2 , glassy behavior 3 , etc . , because they hold important roles not only in science but also in science 4 .Among these topics , the kinetic Ising model 5 is one of the most popular theories used to examine non - equilibrium properties 6 . It studies the period evolution of spin vectors S i ( t ) ( i = 1 , . . . , N ) on a regular structure under the impact of thermal fluctuations .Here t refers the number of Monte Carlo steps per site ( MCS / s ) . At each step , every spin interacts with its closest neighbors through exchange interactions J ij .Then it flips due to the Metropolis algorithm 7 : if e - Sij / kBT > random value between 0 and 1 then flip S j else kept S k unchanged where k B is Boltzmann s constant and T is the absolute temperature . This process goes until equilibrium is reached or some other criterion is fulfilled 8 .",
        "ori-fast-z-score": 0.9622504486493763,
        "water-fast-z-score": 6.928853368993243
    },
    {
        "original_text": "We present new observations of the central region of the nearby Seyfert galaxy NGC 4258, which show that its nuclear disk is warped by an angle of ~20 degrees with respect to the plane of the host galaxy s stellar bulge (see Figure 1 ). The warp has been detected using near-infrared integral field spectroscopy obtained at Gemini Observatory on Mauna Kea, Hawaii. \n \n We also report the detection of significant rotation about the minor axis of this warped structure, as well as evidence for counter-rotation within the innermost few hundred parsecs of the nucleus. These results are consistent with previous studies based on optical data alone. \n \n In addition, we find that the kinematics of the gas in the outer regions of the nuclear disk can be explained if it orbits around the supermassive black hole located at the center of the galaxy under the influence of both gravitational forces and magnetic fields. This result suggests that the observed warps may have their origin in the magneto-rotational instability (MRI) operating in accretion disks surrounding massive black holes. \n \n Finally, we discuss how these findings could help us understand the physics behind the so-called  Bardeen-Petterson effect : i.e., the alignment between the spin axes of the stars and the angular momentum vector of the accreting material onto the central supermassive black hole.",
        "watermark_text": "We present new images of the central region of the nearby Seyfert galaxy NGC 4258 , which show that its nuclear core is warped by an angle of ~ 20 degrees with regard to the plane of the host universe s stellar bulge ( see Figure 1 ) . The warp has been detected using near - infrared inverse field spectroscopy acquired at Gemini Observatory on Mauna Kea , Hawaii .We additionally report the observation of large rotation about the minor axis of this warped structure , as also as data for counter - movement within the innermost few hundred parsecs of the nucleus . These conclusions are compatible with previous research based on optical data alone .In addition , we find that the kinematics of the gas in the exterior areas of the atomic disk can be understood if it orbits around the supermassive black hole located at the center of the galaxy under the effects of both gravity forces and magnetic fields . This result suggests that the seen warps may have their source in the magneto - rotational instability ( MRI ) working in accretion disks surrounding massive blue holes .Finally , we talk how these results could assist us explain the physics behind the so - called Bardeen - Petterson effect : i . e . , the alignment between the spin axes of the stars and the angular velocity tensor of the accreting matter onto the main supermassive black hole .",
        "ori-fast-z-score": -2.4494897427831783,
        "water-fast-z-score": 4.4907311951024935
    },
    {
        "original_text": "We have determined the iron abundance for two bright, blue supergiants (BSGs) in the Galactic globular clusters Omega Cen and M13 using high-resolution spectroscopy obtained with UVES at VLT-UT2 telescope.  The results are compared to those derived by other authors for similar objects in these clusters as well as in other globulars. We find that our values agree very well with previous determinations within their uncertainties. In particular we confirm the low Fe content found for one star in Omega Cen previously reported by Yong et al. (2005) . This is consistent with theoretical predictions which suggest that this cluster should be dominated by first generation stars formed out of material enriched only by massive supernovae. Our analysis also shows that both studied stars belong to the group of so-called  blue stragglers  -objects located above the main sequence turn-off point on the colour-magnitude diagram but still burning helium in their cores.",
        "watermark_text": "We have predicted the metal density for two bright , blue supergiants ( BSGs ) in the Galactic globular galaxies Omega Cen and M13 using high - resolution spectroscopy acquired with UVES at VLT - UT2 telescope . The results are compared to those derived by other researchers for related objects in these complexes as well as in other globulars .We see that our values comply very best with previous determinations within their uncertainties . In particular we verified the poor Fe concentration found for one star in Omega Cen previously reported by Yong et al .( 2005 ) . This is compatible with theoretical estimates which propose that this cluster should be dominated by first generation stars formed out of debris enriched only by massive supernovae .Our study also shows that both examined stars belong to the group of so - called blue stragglers - objects located above the main sequence turn - off position on the colour - magnitude diagram but still consuming helium in their cores .",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "The article presents results of computer simulation of the dynamics of chromatin in vitro, which is based on the model of self-organization of the chain of nucleosome core particles (NCP) with histone H1 molecules attached to them by electrostatic forces. The NCPs are modeled as rigid cylinders with diameter equal to that observed experimentally for isolated NCPs. It was found that the presence of histone H1 leads to an increase in the persistence length of the chain due to formation of loops between neighboring NCPs. In addition, it has been shown that the presence of histones H1 can lead to the appearance of defects in the structure of the chain consisting of several adjacent NCPs connected only through one H1 molecule. These defects have a significant effect on the elasticity characteristics of the chain. \n \n Keywords: Chromatin, Self-assembly, Computer simulation, Elasticity, Defects",
        "watermark_text": "The section offers results of computational simulation of the dynamics of chromatin in vitro , which is based on the model of self - arrangement of the chain of nucleosome backbone particles ( NCP ) with histone H1 molecules attached to them by electrostatic fields . The NCPs are modeled as compact cylinders with diameter equal to that detected experimentally for isolated NCPs .It was shown that the presence of histone H1 leads to an increase in the persistence length of the chain thanks to formation of loops between neighboring NCPs . In addition , it has been shown that the presence of histones H1 can lead to the appearance of errors in the formation of the chain consisting of several neighbouring NCPs linked only through one H1 molecule .These flaws have a substantial impact on the elasticity parameters of the chain . Keywords : Chromatin , Self - assembly , Computer modeling , Elasticity , Defects",
        "ori-fast-z-score": -0.13736056394868904,
        "water-fast-z-score": 5.906504249793628
    },
    {
        "original_text": "We study the evolution of an isotropic, homogeneous cosmological model filled by radiation and a Chaplygyn gas. We find that this system has two attractors corresponding to different values of the Hubble parameter at late times. The first one corresponds to a de Sitter phase where the energy density of the Chaplygin gas dominates over the other components while the second one describes a decelerating universe dominated by dark matter. In both cases we have found that the initial conditions are fixed by the value of the Hubble constant today. Finally, we show how these results can be used as initial conditions for inflationary models. PACS numbers: 98.80.Cq, 04.20.-q, 95.36.+x  Keywords: Cosmology, Inflation, Chaplygin gas, Radiation, Initial Conditions . \nI. INTRODUCTORY REMARK\nIn recent years there has been considerable interest in studying the possibility that our present day universe may contain some exotic form of matter which behaves like a negative pressure fluid (see e.g.,  1  ). This kind of matter could play an important role in explaining several phenomena observed on large scales such as the accelerated expansion of the universe  2  , the flatness problem  3  or even the origin of structure formation  4  .\nOne possible candidate for this type of matter is known as the Chaplygin gas  5  . It was originally introduced as a phenomenological description of the behaviour of superdense stars  6  but it also appears naturally within superstring theories  7, 8  . Recently, it has been shown  9  that the Chaplygin gas provides a good fit to current observational data  10  if its equation of state takes the following form: p = −A/ρ α , where A and α are positive constants. For small values of ρ, i.e., when the universe is dominated by ordinary matter, the above expression reduces to p ≈ 0 so that the Chaplygin",
        "watermark_text": "We explore the evolution of an isotropic , homogeneous cosmological model filled by radiation and a Chaplygyn gas . We see that this scheme has two attractors corresponding to different values of the Hubble parameter at late times .The first one corresponds to a de Sitter phase where the power concentration of the Chaplygin gas dominates over the other components while the second one states a decelerating universe inhabited by black material . In both cases we have discovered that the early conditions are fixed by the value of the Hubble constant today .Finally , we show how these results can be used as early conditions for inflationary theories . PACS codes : 98 . 80 . Cq , 04 . 20 . - q , 95 . 36 . + x Keywords : Cosmology , Inflation , Chaplygin gas , Radiation , Initial Conditions .I . INTRODUCTORY REMARK In recent years there has been substantial interest in examining the prospect that our contemporary day universe might exist some unusual type of matter which behaves like a negative pressure fluid ( see e . g . , 1 ) .This kind of matter could play an important role in understanding several phenomena observed on huge scales such as the advanced expansion of the universe 2 , the flatness problem 3 or even the origin of structure building 4 . One potential candidate for this form of matter is known as the Chaplygin gas 5 .It was originally developed as a phenomenological explanation of the dynamics of superdense stellar 6 but it also occurs commonly within superstring physics 7 , 8 . Recently , it has been shown 9 that the Chaplygin light provides a better suited to recent observational data 10 if its equation of state takes the following form : p = −A / ρ α , where A and ω are positive constants .For small values of ρ , i . e . , when the universe is dominated by normal matter , the above formula yields to p ≈ 0 so that the Chaplygin",
        "ori-fast-z-score": -0.17677669529663687,
        "water-fast-z-score": 6.540737725975564
    },
    {
        "original_text": "We study the distribution of the total area swept out by a one-dimensional Brownian motion between two fixed times. We show that this distribution is given by an explicit formula involving the modified Bessel function I0(x). This result can be used to derive several interesting identities for special functions such as the Riemann zeta-function or the Hurwitz zeta-functions at even arguments. In particular we obtain new proofs of some results due to Wright on the number of graphs with n vertices having certain properties (such as being bipartite) which are related to the coefficients appearing in the expansion of the exponential generating function of these numbers into powers of t. Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials. The main tool will be the Feynman-Kac representation of the solution of the heat equation. Let Wt denote standard Brownian motion starting at 0. For any real number s > 0 let us consider the random variable A(s), defined as the total area swept out during the time interval  0,s  by the process Wt:",
        "watermark_text": "We test the distribution of the total area swept out by a one - dimensional Brownian movement between two fixed times . We see that this distribution is given by an explicit formula involving the modified Bessel distribution I0 ( x ) .This result can be used to derive several interesting identities for special functions such as the Riemann zeta - function or the Hurwitz zeta - functions at even arguments . In particular we obtain new proofs of some results attributed to Wright on the number of graphs with n edges having specific properties ( such as being bipartite ) which are related to the coefficients appearing in the transformation of the exponential producing function of these integers into powers of t . Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials .The main tool will be the Feynman - Kac representation of the solve of the temperature equation . Let Wt denote standard Brownian movement starting at 0 .For any real number s > 0 let us consider the random variable A ( s ) , defined as the total area swept out during the period interval 0 , s by the process Wt :",
        "ori-fast-z-score": 1.5652475842498528,
        "water-fast-z-score": 5.062895554167108
    },
    {
        "original_text": "The low energy effective theories for superstrings are supergravity and supersymmetric gauge theories in four dimensions, which can be obtained by compactifying the extra six spatial dimensions on a Calabi-Yau manifold.  In this talk I will discuss some recent results about lattice models that provide an alternative approach to studying these theories. The basic idea is to use Monte Carlo simulations to study supersymmetric field theories defined on a finite number of points (the sites) of a regular d-dimensional hypercubic lattice with periodic boundary conditions. These models have been studied extensively over the past few years using numerical techniques such as exact diagonalization, quantum Monte Carlo methods, and density matrix renormalization group algorithms. Recently we developed new Monte Carlo simulation techniques based on the worm algorithm that allow us to simulate large systems at very high temperatures where conventional Monte Carlo methods fail because they suffer from critical slowing down. We used our new method to calculate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang-Mills theory and the N = 1 supersymmetric U(1) gauge theory coupled to matter fields in various representations.",
        "watermark_text": "The lowest energy effective models for superstrings are supergravity and supersymmetric gauge fields in four dimensions , which can be obtained by compactifying the extra six spatial dimensions on a Calabi - Yau manifold . In this talk I will explore some latest findings about lattice models that provide an different approach to researching these theories .The basic idea is to use Monte Carlo simulations to study supersymmetric field theories specified on a finite number of points ( the sites ) of a regular d - dimensional hypercubic structure with periodic border conditions . These systems have been studied frequently over the previous few years employing mathematical techniques such as approximate diagonalization , quantum Monte Carlo methods , and density matrix renormalization group algorithms .Recently we developed novel Monte Carlo simulation method based on the worm algorithm that enable us to simulate large systems at very high altitudes where conventional Monte Carlo methods fail because they suffer from critical speed down . We utilized our new method to estimate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang - Mills theory and the N = 1 supersymmetric U ( 1 ) gauge theory connected to matter groups in different representations .",
        "ori-fast-z-score": 0.6255432421712244,
        "water-fast-z-score": 6.118014998909509
    },
    {
        "original_text": "We consider the problem of linear regression with measurement error, where the errors are assumed to be normally distributed and uncorrelated between different measurements but correlated within each measurement set (i.e., for one given star). We derive an expression for the covariance matrix of the estimated parameters which is valid even if the number of data points per measurement set differs significantly among sets. This allows us to study how the accuracy of the results depends on the distribution of the number of observations over all stars. The derived formula can also be used as a tool for optimizing observational strategies by minimizing the uncertainty of the resulting estimates. In particular we show that it may be advantageous to use only a small fraction of available data points when estimating the coefficients of the model function while using most or all data points for determining its first few derivatives. Finally, we apply our method to simulated data obtained from the Hipparcos astrometric satellite mission.",
        "watermark_text": "We consider the question of linear regression with measurement loss , where the errors are expected to be usually spread and uncorrelated between various measurements but correlated within each measurement set ( i . e . , for one given star ) . We derive an expression for the covariance matrix of the expected variables which is valid even if the proportion of data points per observation set differs greatly among setting .This enables us to study how the accuracy of the results varies on the distribution of the proportion of measurements over all stars . The derived formula can also be used as a tool for optimizing observational strategies by minimizing the uncertainty of the resulting estimates .In particular we prove that it could be advantageous to use only a small fraction of available data points when estimating the coefficients of the model function while using most or all information points for determining its initial few derivatives . Finally , we apply our technique to simulated images obtained from the Hipparcos astrometric satellite mission .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.047146145152358
    },
    {
        "original_text": "We report the detection of beryllium (Be) lines in two ultra-low metallicity halo stars, CS 22892-052 and HE 0107-5240.  These are the first detections of Be in metal-poor halo stars with  Fe/H  < -2.5 dex. We find that these stars have high surface gravities for their temperatures, indicating they may be blue stragglers or other evolved objects. In addition to the Be features at 4131 Å and 4130 Å we also see evidence for an unidentified feature near 3970 Å which is likely due to C+N+O. This work was supported by NASA grant NAG5-9998. Keywords: Beryllium; Blue straggler; Metal poor star; Ultracool dwarf. 1. Introduction.\nThe discovery of extremely low-mass stars has opened up new avenues into understanding how planets form around very cool dwarfs. However, there remains much uncertainty about the formation process itself as well as the chemical composition of such systems. One important aspect of this problem involves determining whether or not terrestrial planet formation can occur within the habitable zone of ultracool dwarfs. To address this question it will be necessary to determine if the atmospheres of these stars contain significant amounts of heavy elements like carbon, nitrogen, oxygen, sulfur, sodium, potassium, magnesium, aluminum, silicon, calcium, titanium, iron, nickel, cobalt, copper, zinc, arsenic, selenium, silver, gold, mercury, lead, uranium, thorium, and plutonium. It should be noted that while some of these metals are produced during stellar nucleosynthesis others are synthesized only through cosmic ray spallation reactions occurring outside of stars.",
        "watermark_text": "We report the observation of beryllium ( Be ) tracks in two ultra - low metallicity halo stars , CS 22892 - 052 and HE 0107 - 5240 . These are the first detections of Be in metal - scarce halo stars with Fe / H < - 2 . 5 dex .We see that these stars have high surface gravities for their temperatures , showing they may be blue stragglers or other evolution bodies . In addition to the Be properties at 4131 Å and 4130 Å we also find proof for an unknown spot near 3970 Å which is probably due to C + N + O .This work was supported by NASA grant NAG5 - 9998 . Keywords : Beryllium ; Blue straggler ; Metal poor star ; Ultracool dwarf .1 . Introduction .The observation of incredibly poor - density stars has opened up new avenues into studying how planets organize around very cool dwarfs . However , there exists much uncertainty about the formation transition itself as well as the chemical composition of such systems .One important dimension of this question involves establishing whether or not terrestrial planet development can occur within the habitable zone of ultracool dwarfs . To address this question it will be required to study if the atmospheres of these planets contain significant amounts of heavy components like carbon , nitrogen , oxygen , hydrogen , potassium , potassium , magnesium , iron , silicon , potassium , titanium , iron , nickel , cobalt , copper , zinc , arsenic , selenium , platinum , gold , mercury , lead , uranium , thorium , and plutonium .It should be mentioned that while some of these metals are produced during stellar nucleosynthesis others are synthesized only through cosmic ray spallation reactions occurring outside of stars .",
        "ori-fast-z-score": -0.47891314261057566,
        "water-fast-z-score": 5.510397987560282
    },
    {
        "original_text": "We present an exact expression for the probability distribution function (PDF) of the number of steps taken by a one-dimensional, discrete-time, self-propelled particle that moves in a periodic potential and interacts with itself via elastic collisions.  We show how this PDF can be used to calculate the mean-square displacement as well as other statistical properties of such particles. The results are illustrated using numerical simulations. \nPACS numbers: 05.45.-a; 05.70.Jk; 05.60.Gg \nI. INTRODUCTORY REMARkS\nThe motion of many biological systems is often described as being driven by internal forces or active processes  1  . Examples include bacteria swimming through fluids  2  , cells crawling on surfaces  3  , and molecular motors moving along cytoskeletal filaments  4  .\nIn recent years there has been growing interest in understanding the dynamics of these active particles  5  -  8  . In particular, it was shown that their behavior may differ significantly from that observed in passive Brownian particles  9  -  11  . For example, while the latter exhibit normal diffusion at large timescales  12  , active particles typically display superdiffusive  13  or even ballistic  14  transport depending on the details of their interactions  15  -  17  . This difference arises because active particles have additional degrees of freedom which allow them to explore more efficiently the available space  18  . As a result they tend to move faster than passive particles  19  .\nRecently we introduced a model describing the motion of a single active particle  20  . It consists of a point-like object that performs a biased random walk in a periodic potential  21  . Its position x(t + 1) = x(t) + v t+1 − v t is determined by its velocity v t+1 = f  x(t), v t   where f  ·  denotes some deterministic force acting upon the particle  22  . Here we consider two different types of potentials V (x). First, when V (x) ∝ cos(2πx/L) (L is the periodicity length), the system exhibits a series of metastable states separated by energy barriers  23  . Second",
        "watermark_text": "We present an precise representation for the probability distribution function ( PDF ) of the number of steps took by a one - dimensional , discrete - time , self - propelled object that moves in a periodic potential and interacts with itself via elastic collisions . We see how this PDF can be used to estimate the mean - square displacement as well as other mathematical properties of such particles .The results are shown using numerical simulations . PACS codes : 05 . 45 . - a ; 05 . 70 . Jk ; 05 . 60 . Gg I .INTRODUCTORY REMARkS The movement of several biological systems is often characterized as being driven by inner forces or active pathways 1 . Examples involve bacteria walking through substances 2 , bacteria crawling on surfaces 3 , and molecular motors moving along cytoskeletal filaments 4 .In recent years there has been growing interest in understanding the dynamics of these active grains 5 - 8 . In particular , it was shown that their motion might variation significantly from that detected in passive Brownian grains 9 - 11 .For instance , while the former exhibit normal convection at large timescales 12 , active grains typically demonstrate superdiffusive 13 or even ballistic 14 transport varying on the details of their interactions 15 - 17 . This difference arises because active particles have additional degrees of liberty which allow them to study more efficiently the available space 18 .As a result they tend to move faster than inactive particles 19 . Recently we presented a theory explaining the movement of a single active molecule 20 .It consists of a point - like particle that conducts a biased random walk in a periodic potential 21 . Its position x ( t + 1 ) = x ( t ) + v t + 1 − u t is chosen by its velocity v t + 1 = f x ( t ) , v t where f · denotes some deterministic force acting upon the particle 22 .Here we define two different kinds of potentials V ( x ) . First , when V ( x ) [UNK] cos ( 2πx / L ) ( L is the periodicity long ) , the system displays a sequence of metastable states separated by energy barriers 23 .Second",
        "ori-fast-z-score": -0.8219949365267865,
        "water-fast-z-score": 7.562353416046435
    },
    {
        "original_text": "We present results on variable X-ray emission from the central parsecs (0.1 pc) around Sgr A*, which is associated with hot plasma ejected by young massive stars near the supermassive black hole at the Galactic Centre. We find that the variability timescale decreases as we move towards higher energies. The observed power spectrum can be explained if there are two components contributing to the total flux - one steady component and another varying component. This suggests that the source of the X-rays may not be point-like but extended. Our analysis also shows that the luminosity changes significantly over time scales ranging between hours and years. These variations could be due to either intrinsic or extrinsic factors such as orbital motion of the emitting region and/or obscuration effects caused by intervening clouds. In addition, we have found evidence for an anti-correlation between the soft and hard bands during flares. This indicates that the spectral shape varies along with its intensity.",
        "watermark_text": "We report findings on variable X - ray radiation from the central parsecs ( 0 . 1 pc ) around Sgr A * , which is associated with hot plasma expelled by young massive galaxies near the supermassive black hole at the Galactic Centre . We see that the variability timescale decreases as we move towards higher energies .The observed power spectrum can be understood if there are two parts contributing to the total flux - one steady component and another varying component . This implies that the origin of the X - radiation may not be point - like but extended .Our study also shows that the luminosity shifts significantly over time ranges ranging between hours and years . These changes could be due to either intrinsic or extrinsic factors such as orbital movement of the emitting area and / or obscuration effects caused by intervening clouds .In addition , we have discovered evidence for an counter - correlation between the soft and hard bands during flares . This implies that the absorption form varies along with its brightness .",
        "ori-fast-z-score": -1.0533703247651751,
        "water-fast-z-score": 4.564604740649092
    },
    {
        "original_text": "We present the first X-ray observations of the super soft source (SSS) in the recurrent nova RS Ophiuchi using data obtained by the Chandra and XMM- Newton observatories during their recent outbursts. The SSS was detected at all epochs, but its luminosity varied significantly between them. We find that the temperature of the SSS is consistent with being constant within errors for each observation epoch. However, we detect significant changes in the emission measure which are correlated to the optical light curve. These results suggest that the mass loss rate from the white dwarf varies on timescales as short as days. This may be due to an unstable nuclear burning shell or possibly accretion disk instabilities. In addition, we report the detection of two absorption features near 1 keV in our Chandra spectrum taken on day +6 after outburst maximum. They can be identified with Fe XXV Kα and Fe XXVI Lyα lines produced in the expanding ejecta.",
        "watermark_text": "We present the first X - ray observations of the super soft source ( SSS ) in the recurrent nova RS Ophiuchi using data acquired by the Chandra and XMM - Newton observatories during their recent outbursts . The SSS was seen at all epochs , but its luminosity differed dramatically between them .We see that the temperature of the SSS is compatible with being steady within errors for each observation epoch . However , we find considerable changes in the emission measure which are correlated to the optical light spiral .These data suggest that the mass loss rate from the white dwarf varies on timescales as short as days . This might be due to an weak nuclear burning shell or possibly accretion belt instabilities .In addition , we note the observation of two spectral features near 1 keV in our Chandra spectrum taken on day + 6 after outburst peak . They can be identified with Fe XXV Kα and Fe XXVI Lyα bands created in the evolving ejecta .",
        "ori-fast-z-score": -0.6401843996644799,
        "water-fast-z-score": 5.163977794943222
    },
    {
        "original_text": "We have calculated the ab initio melting curves for Mo and W using the phase-coexistence method with the generalized gradient approximation (GGA) to density functional theory (DFT). The results are compared with those obtained in previous studies, as well as experimental data on the melting points. We find that our GGA calculations give good agreement with experiment at high temperatures but underestimate the melting temperature significantly below 2000 K. This is probably due to anharmonic effects which we do not take into account here. In addition, we show how the electronic structure changes across the melting transition. \n \n Keywords: Molten metal, Phase diagram, Melting point, Ab initio calculation \n \n \n \n 1 Introduction \n \n It has been known since the early days of quantum mechanics that the properties of matter can be described accurately within this framework only if electron-electron interactions are taken into account explicitly  1  . However, it was soon realized that even simple approximations such as Hartree-Fock or DFT yield useful information about many physical phenomena  2  , including solid-state physics  3  .\n \nIn recent years there has been considerable interest in applying first-principles methods to calculate the thermodynamic properties of materials  4  . These include free energies  5  , phonon frequencies  6  , elastic constants  7  , surface tensions  8  , and other quantities  9  . One important application of these techniques is the prediction of the melting behaviour of solids  10  -  12  . For example, the melting temperature T m of metals can be determined directly from the Gibbs energy difference between the liquid and solid phases  13  :",
        "watermark_text": "We have calculated the ab initio melting curves for Mo and W utilizing the phase - coexistence method with the generalized gradient approximation ( GGA ) to density functional theory ( DFT ) . The results are compared with those achieved in earlier studies , as well as empirical data on the melting points .We see that our GGA measurements give good agreement with research at high temperatures but underestimate the melting temperature significantly below 2000 K . This is probably due to anharmonic effects which we do not take into consideration here . In addition , we find how the chemical structure shifts across the melting transition .Keywords : Molten material , Phase diagram , Melting point , Ab initio method 1 Introduction It has been known since the early days of quantum mechanics that the properties of matter can be described properly within this framework only if electron - atom relationships are took into consideration explicitly 1 . However , it was swiftly understood that even basic approximations such as Hartree - Fock or DFT yield useful details about various physical phenomena 2 , notably solid - state mechanics 3 .In recent years there has been substantial interest in implementing first - principles techniques to estimate the thermodynamic properties of substances 4 . These include free temperatures 5 , phonon frequencies 6 , elastic constants 7 , surface tensions 8 , and other quantities 9 .One important use of these method is the determination of the melting behaviour of solids 10 - 12 . For instance , the melting temperature T m of metals can be determined directly from the Gibbs energy relationship between the liquid and solid phases 13 :",
        "ori-fast-z-score": 0.3713906763541037,
        "water-fast-z-score": 7.427813527082075
    },
    {
        "original_text": "We present an analytical model for high-order harmonic generation (HHG) in diatomic molecules, which is based on the concept of molecular orbitals and their associated electronic wavefunctions. The HHG process can be understood as a sequence of three steps: First, electrons are ionized by strong laser fields. Second, they propagate through the continuum until rescattering with parent ions occurs. Third, these returning electrons emit high harmonics when interacting again with the driving field. We show that this picture leads to a simple expression for the emitted harmonic intensity, which depends only on two parameters characterizing the molecule s orbital structure. This result allows us to explain the observed interference patterns between different harmonics in terms of destructive or constructive interferences between contributions from different molecular orbits. In addition, we demonstrate how our approach can be used to predict the emission properties of new types of molecules. High-order harmonic generation (HHG), i.e., the coherent emission of photons at odd multiples of the fundamental frequency of intense femtosecond laser pulses, has attracted considerable interest over recent years  1, 2  . It provides access to extreme ultraviolet radiation  3  , which enables novel applications such as attosecond pulse generation  4  , photoelectron spectroscopy  5  , and tomography  6  .\nThe underlying physical mechanism behind HHG was first explained within the semiclassical three-step model  7, 8  : An electron tunnels out of its atomic core into the continuum upon interaction with the electric field of the laser light. Afterwards it propagates freely before being driven back towards the nucleus by the same field. Finally, it recombines with the parent ion emitting a photon whose energy equals the sum of the kinetic energy gained during propagation and the binding energy lost due to tunneling  9  . Since then, several extensions have been developed  10  including the so-called quantum-orbit theory  11  , which takes into account the influence of the nuclear potential on the electron dynamics  12  . However, despite all efforts made so far, there still exist many open questions regarding the microscopic origin of HHG  13  .",
        "watermark_text": "We present an analytical theory for high - order harmonic production ( HHG ) in diatomic molecules , which is based on the idea of molecular orbitals and their accompanying electronic wavefunctions . The HHG process can be understood as a sequence of three stages : First , electrons are ionized by intense laser fields .Second , they propagate through the continuum until rescattering with mother ions happens . Third , these returning electrons emit large harmonics when interacting again with the driving field .We see that this picture leads to a simple expression for the emitted harmonic intensity , which depends only on two parameters characterizing the molecule s orbital structure . This result allows us to explain the seen interference patterns between various harmonics in terms of destructive or constructive interferences between contributions from different molecular orbits .In addition , we prove how our approach can be used to predict the emission behavior of new types of molecules . High - order harmonic production ( HHG ) , i . e . , the coherent emission of photons at odd multiples of the fundamental frequency of active femtosecond infrared signals , has garnered considerable interest over recent periods 1 , 2 .It provides entry to extreme ultraviolet radiation 3 , which enables novel applications such as attosecond pulse production 4 , photoelectron spectroscopy 5 , and tomography 6 . The fundamental physical process behind HHG was first explained within the semiclassical three - stepping model 7 , 8 : An electron tunnels out of its atomic backbone into the continuum upon interference with the electric field of the laser light .Afterwards it propagates freely before being driven back towards the nucleus by the same field . Finally , it recombines with the parent ion emitting a photon whose power equals the sum of the kinetic power gained during propagation and the binding energy gain due to tunneling 9 .Since then , various extensions have been created 10 including the so - called quantum - orbit concept 11 , which gives into consideration the impact of the atomic potential on the electron mechanics 12 . However , despite all efforts made so far , there still appear many open questions regarding the microscopic ancestry of HHG 13 .",
        "ori-fast-z-score": 0.8111071056538127,
        "water-fast-z-score": 7.786628214276602
    },
    {
        "original_text": "The aim of this study was to investigate the effect of novel antimicrobial cyclic peptides, named microbe-derived cationic ring structures (MCRs), on cell proliferation and apoptosis induction in A549 non-small-cell lung carcinoma cells. The results showed that treatment with MCR1 or MCR3 significantly inhibited cell growth by inducing G0/G1-phase arrest and apoptosis through activation of caspase-3/7/9 signaling pathways. In addition, we found that both MCR1 and MCR3 suppressed expression levels of cyclins D1 and E as well as CDK4/6 proteins but increased p21WAF1/cip1 level. Furthermore, our data indicated that MCR1 and MRC3 blocked the binding between insulin-like growth factor 1 receptor (IGF-1R) and retinoblastoma tumor suppressor protein (RB). These findings suggest that MCR1 and 3 may be potential therapeutic agents for treating lung cancers.",
        "watermark_text": "The goal of this study was to examine the impact of new antimicrobial cyclic peptides , designated microbe - derived cationic ring structures ( MCRs ) , on cell development and apoptosis activation in A549 non - large - cell lung carcinoma cells . The results suggested that treatment with MCR1 or MCR3 significantly inhibited cell development by inducing G0 / G1 - phase arrest and apoptosis through activation of caspase - 3 / 7 / 9 signaling pathways .In addition , we reported that both MCR1 and MCR3 reduced transcription rates of cyclins D1 and E as well as CDK4 / 6 factors but improved p21WAF1 / cip1 level . Furthermore , our information shown that MCR1 and MRC3 blocked the interaction between insulin - like growth factor 1 receptor ( IGF - 1R ) and retinoblastoma tumor suppressor protein ( RB ) .These data suggest that MCR1 and 3 might be possible therapeutic agents for controlling lung cancers .",
        "ori-fast-z-score": -0.674199862463242,
        "water-fast-z-score": 5.715476066494082
    },
    {
        "original_text": "We compare the magnetic flux distribution in coronal holes (CHs) with that in quiet regions using vector magnetograms observed by Hinode/SOT/SP. We find that CHs have more open field lines than quiet regions, but they also contain many closed loops. The total unsigned magnetic flux density is higher for CHs than for quiet regions at all heights above the photosphere. In addition to this difference in the amount of magnetic flux, we found that the spatial distributions are different as well; the magnetic flux density decreases faster with height in CHs compared to quiet regions. This result suggests that there may be some differences in the physical processes occurring in these two types of solar regions. Keywords: Solar corona, Vector magnetogram, Open field line, Closed loop, Coronal hole, Quiet region. 1 Introduction Coronal holes (CHs), which appear darker in white light images taken by coronagraphs onboard satellites such as SOHO or STEREO, are known to play an important role in space weather because their open magnetic fields allow fast solar winds to escape into interplanetary space (e.g., Wang et al. (1998) , Cranmer & van Ballegooijen (2005) ).\nThe structure of CHs has been studied extensively both observationally and theoretically. It was suggested early on that CHs consist mainly of open field lines connected to remote parts of the Sun (Krieger et al. (1971) ), while closed loops were rarely seen inside them (Wiegelmann et al. (2010a) ). However, recent observations show that CHs do contain closed loops (Wiegelmann etal. (2010b) , Parnell et al. (2011 ), DeForest et al. (2013 , Brooks et al. (2014) ). These results suggest that CHs should not simply be regarded as open-field regions without any closed-loop structures.",
        "watermark_text": "We relate the magnetic flux spread in coronal holes ( CHs ) with that in quiet regions using vector magnetograms observed by Hinode / SOT / SP . We see that CHs have more open field lines than quiet regions , but they still hold several shut rings .The total unsigned magnetic flux concentration is higher for CHs than for calm regions at all heights above the photosphere . In addition to this contrast in the quantity of magnetic flux , we reported that the spatial distributions are distinct as well ; the magnetic flux concentration drops quicker with depth in CHs compared to quiet regions .This result suggests that there may be some variations in the physical processes arising in these two kind of sun areas . Keywords : Solar corona , Vector magnetogram , Open field system , Closed loop , Coronal hole , Quiet region .1 Introduction Coronal holes ( CHs ) , which appear darker in white light pictures taken by coronagraphs onboard satellites such as SOHO or STEREO , are known to play an important role in space weather because their open magnetic fields allow strong sun winds to escape into interplanetary space ( e . g . , Wang et al . ( 1998 ) , Cranmer & van Ballegooijen ( 2005 ) ) .The structure of CHs has been studied frequently both observationally and theoretically . It was suggested early on that CHs consist mostly of open field lines linked to remote parts of the Sun ( Krieger et al .( 1971 ) ) , while closed loops were seldom visible inside them ( Wiegelmann et al . ( 2010a ) ) .However , recent observations show that CHs do contain shut loops ( Wiegelmann etal . ( 2010b ) , Parnell et al .( 2011 ) , DeForest et al . ( 2013 , Brooks et al .( 2014 ) ) . These conclusions show that CHs should not simply be regarded as open - field regions without any closed - loop fields .",
        "ori-fast-z-score": -0.44367825470805694,
        "water-fast-z-score": 5.833630944789017
    },
    {
        "original_text": "We present the results of multi-wavelength studies towards southern hot molecular cores (HMCs) using ammonia, water vapour, and continuum data at 1.3 cm and 3 mm wavelengths obtained with the Australia Telescope Compact Array (ATCA). The HMCs are associated with high-mass star formation regions in which massive young stellar objects have been detected through infrared surveys. We find that all our targets show compact emission features on scales of 0.1 pc or less. These sources appear to be dense clumps embedded within larger-scale structures extending up to several parsecs. In addition, we detect extended emission components surrounding these compact clumps. Our analysis shows that the physical conditions derived for the compact clumps are consistent with those expected for hot molecular gas heated by protostellar outflows. On the other hand, the properties of the extended emission suggest that it is likely tracing an envelope around each source.",
        "watermark_text": "We present the conclusion of dual - wavelength experiments towards southern bright molecular cores ( HMCs ) using ammonia , sea vapour , and continuum data at 1 . 3 cm and 3 cm wavelengths collected with the Australia Telescope Compact Array ( ATCA ) . The HMCs are related with high - density star formation regions in which giant older stars objects have been detected through infrared observations .We see that all our targets exhibit small emitted features on scales of 0 . 1 pc or less . These sources appear to be dense clumps scattered within wider - scale structures spanning up to several parsecs .In addition , we find extended emitted elements surrounding these compact clumps . Our study shows that the physical conditions generated for the compact clumps are compatible with those expected for hard molecular vapor heated by protostellar outflows .On the other hand , the properties of the extended emitted suggest that it is probably tracing an envelope around each source .",
        "ori-fast-z-score": -1.9896995023342199,
        "water-fast-z-score": 5.032769329433615
    },
    {
        "original_text": "We present an algorithm for decomposing functions defined over quadratic surfaces in three dimensions, such as the surface of a sphere or ellipsoid, into multipole expansions. The method is based on representing the function using spherical harmonics and then expanding each term in this representation into a sum of products of Legendre polynomials with coefficients that are determined by solving a linear system of equations. We demonstrate our approach through several examples including computing the electrostatic potential due to point charges located at various positions around a dielectric sphere immersed in water. Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space. This work was supported by NSF grant DMS-0852653 (CAREER). Spherical harmonic decomposition has been used extensively in computational physics applications ranging from quantum chemistry  1  , molecular dynamics  2  , and plasma simulations  3  . In these applications, one often needs to represent a given function f(r) defined over some domain Ω in terms of its expansion coefficients C lm :",
        "watermark_text": "We present an algorithm for decomposing functions defined over quadratic spheres in three dimensions , such as the surface of a sphere or ellipsoid , into multipole expansions . The method is based on representing the function using spherical harmonics and then increasing each term in this representation into a sum of products of Legendre polynomials with coefficients that are decided by solving a linear network of equations .We showed our approach through several examples namely calculation the electrostatic potential due to point charges situated at numerous positions around a dielectric sphere immersed in water . Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space .This work was supported by NSF grant DMS - 0852653 ( CAREER ) . Spherical harmonic decomposition has been used extensively in computational physics applications ranging from quantum chemistry 1 , molecular dynamics 2 , and plasma simulations 3 .In these uses , one frequently needs to depict a given function f ( r ) established over some domain Ω in terms of its expansion function C lm :",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 3.2627549126854696
    },
    {
        "original_text": "We present the first detailed analysis of the X-ray spectrum of the Seyfert 1 galaxy NGC 3783 using data obtained by the High Energy Transmission Grating Spectrometer (HETGS) on board the Chandra Observatory. The source was in an active state during our observation, and we find that its emission is dominated by strong absorption lines due to highly ionized species such as O viii-xxii, Ne ix-xiii, Mg xii-xv, Si xiv-xxvi, S xix-xxxi, Ar xxviii-xxxviii, Ca xx-xxxi, Fe xxv-xxvi, and Ni xxviii-xxix. We detect several narrow emission features which are likely associated with resonant scattering of continuum photons off ions located along the line-of-sight towards the central engine. In addition, there appears to be evidence for broad emission components at energies above 10 keV.",
        "watermark_text": "We present the first detailed analysis of the X - ray spectrum of the Seyfert 1 galaxy NGC 3783 using data acquired by the High Energy Transmission Grating Spectrometer ( HETGS ) on board the Chandra Observatory . The source was in an active condition during our observation , and we find that its emission is dominated by weak absorption lines due to strongly ionized species such as O viii - xxii , Ne ix - xiii , Mg xii - xv , Si xiv - xxvi , S xix - xxxi , Ar xxviii - xxxviii , Ca xx - xxxi , Fe xxv - xxvi , and Ni xxviii - xxix .We detect many narrow radiation elements which are likely correlated with resonant scattering of continuum photons off ions located along the line - of - view towards the main engine . In addition , there seems to be confirmation for wide absorption elements at energies above 10 keV .",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 3.4286375654996775
    },
    {
        "original_text": "We present the results of our numerical simulations on the shallow-decay phase of GRB X-ray light curves, which are produced by the interaction between an ultra-relativistic jet and its surrounding medium in the framework of the internal shock model for GRBs. We find that this phase is mainly due to the continuous energy injection into the forward shock driven by the expanding bubble formed at the head of the jet. The injected energy comes from the kinetic energy of the swept-up shell material as well as the thermal energy of shocked ambient gas inside the bubble. Our simulation results show good agreement with observations both qualitatively and quantitatively. \n \n Keywords: Gamma-ray bursts (GRBs), Afterglow emission, Relativistic winds, Shock waves, Bubbles, Internal shocks, Wind-driven shells, Energy injection, Light curve modeling \n \n 1 Introduction \n \n In recent years, great progress has been made in understanding the origin of gamma-ray bursts (GRBs; see Piran 2004 , Zhang 2007a . It was found that most GRBs have their prompt emissions followed by a relatively smooth power-law decline lasting several hundred seconds known as the  afterglow  phase (Costa et al. 1997; van Paradijs et al. 1997) . This phase can be explained by synchrotron radiation from electrons accelerated behind the blast wave generated when the ejecta hits the circumburst medium (Sari et al. 1998 ). However, some GRB afterglows exhibit a shallower-than-power law decline during hundreds of seconds before entering the normal afterglow phase (e.g., Panaitescu & Kumar 2001; Nousek et al. 2006; Liang et al. 2007; Willingale et al. 2007) , which cannot be explained within the standard fireball model. Several models were proposed to explain these phenomena, including late-time central engine activity (Zhang 2007b ), refreshed-shock scenario (Ghisellini et al. 2007 ) and reverse shock emission (Kobayashi 2000; Kobayashi & Sari 2001) . Recently, Fan & Wei (2007) suggested that the shallow-decay phase",
        "watermark_text": "We present the conclusion of our numerical simulations on the shallow - decay phase of GRB X - ray light curves , which are produced by the interaction between an ultra - relativistic jet and its neighbouring medium in the framework of the internal shock model for GRBs . We see that this phase is mainly owing to the discrete energy injection into the front shock driven by the increasing bubble formed at the head of the jet .The injected power derives from the kinetic power of the swept - up shell material as also as the thermal energy of shocked ambient gas inside the bubble . Our model results show good agreement with observations both qualitatively and quantitatively .Keywords : Gamma - ray bursts ( GRBs ) , Afterglow emission , Relativistic winds , Shock waves , Bubbles , Internal shocks , Wind - driven shells , Energy injection , Light curve modeling 1 Introduction In recent years , great work has been achieved in understanding the origin of gamma - ray bursts ( GRBs ; seeing Piran 2004 , Zhang 2007a . It was shown that most GRBs have their prompt emissions followed by a fairly gradual power - law decrease lasting several hundred moments known as the afterglow period ( Costa et al .1997 ; van Paradijs et al . 1997 ) .This phase can be understood by synchrotron emission from electrons accelerated behind the explosion wave produced when the ejecta hits the circumburst medium ( Sari et al . 1998 ) .However , some GRB afterglows exhibit a shallower - than - energy law decrease during hundreds of moments before entering the usual afterglow stage ( e . g . , Panaitescu & Kumar 2001 ; Nousek et al . 2006 ; Liang et al .2007 ; Willingale et al . 2007 ) , which lacks be described within the standard fireball model .Several models were offered to explain these phenomena , notably late - time central fuel activity ( Zhang 2007b ) , refreshed - jolt scenario ( Ghisellini et al . 2007 ) and reverse shock emission ( Kobayashi 2000 ; Kobayashi & Sari 2001 ) .Recently , Fan & Wei ( 2007 ) proposed that the shallow - decay phase",
        "ori-fast-z-score": -0.5895063447465633,
        "water-fast-z-score": 6.271815075053181
    },
    {
        "original_text": "We present new results on photolysis-induced chemistry in the upper atmosphere of Titan, based on observations made by Cassini/VIMS (Visible Infrared Mapping Spectrometer) during its T5 flyby of Titan s northern hemisphere. The VIMS data show that there is an extensive haze layer between about 400 km altitude and 1000 km above the surface. This haze has been previously attributed to photochemical production of aerosol particles through reactions involving methane and ethane. We find evidence for additional sources of aerosol particles at higher altitudes. These include products of dissociation of nitrogen molecules produced by solar UV radiation, as well as carbon dioxide and water vapor released from the lower stratosphere into the mesosphere/thermosphere region. Our analysis suggests that these processes may be responsible for up to 50% of the total mass loading of the haze observed near 600 km altitude. The presence of this additional source of aerosol particles could have important implications for understanding atmospheric circulation patterns in the upper atmosphere of Saturn s moon Enceladus.",
        "watermark_text": "We report new data on photolysis - caused chemistry in the higher atmosphere of Titan , based on observations made by Cassini / VIMS ( Visible Infrared Mapping Spectrometer ) during its T5 flyby of Titan s northern hemisphere . The VIMS data reveal that there is an extensive haze layer between about 400 kilometres altitude and 1000 kilometers above the surface .This haze has been previously attributed to photochemical production of aerosol gases through reactions involving methane and ethane . We see evidence for additional sources of aerosol particles at higher altitudes .These include products of dissociation of nitrogen molecules released by sun UV rays , as also as carbon dioxide and water vapor sent from the lower stratosphere into the mesosphere / thermosphere region . Our study shows that these mechanisms may be responsible for up to 50 % of the total mass loading of the fog seen near 600 kilometers altitude .The presence of this added source of aerosol particles might have important implications for studying air convection conditions in the higher atmosphere of Saturn s moon Enceladus .",
        "ori-fast-z-score": -1.1470786693528088,
        "water-fast-z-score": 5.9648090806346055
    },
    {
        "original_text": "We present high-resolution (R = λ/Δλ ~ 10000) near-infrared and mid-infrared spectroscopic observations for two ULIRGs, Mrk 231 and Arp 220. The data were obtained with the Subaru Telescope using the Cooled Mid-Infrared Camera and Spectrograph (COMICS). We detect several emission lines in both objects including H I Brγ at 2.16 μm, Paα at 1.87 μm,  Fe II  at 1.64 μm, He I at 1.70 μm,  S III  at 0.95 μm, and  C IV  at 0.15 μm. In addition to these lines, we also find that there are many absorption features such as CO bandheads near 4.7 μm and 6.2 μm. These results show that the observed spectra have complex line profiles which can be explained by multiple components along our line-of-sight and/or different physical conditions within each component.",
        "watermark_text": "We present high - resolution ( R = λ / Δλ ~ 10000 ) near - infrared and mid - infrared spectroscopic observations for two ULIRGs , Mrk 231 and Arp 220 . The data were obtained with the Subaru Telescope using the Cooled Mid - Infrared Camera and Spectrograph ( COMICS ) .We detect many emission lines in both objects including H I Brγ at 2 . 16 μm , Paα at 1 . 87 μm , Fe II at 1 . 64 μm , He I at 1 . 70 μm , S III at 0 . 95 μm , and C IV at 0 . 15 μm . In addition to these lines , we also find that there are many absorption properties such as CO bandheads near 4 . 7 μm and 6 . 2 μm .These data reveal that the seen spectra have complex line profiles which can be described by various components along our line - of - view and / or varying material conditions within each portion .",
        "ori-fast-z-score": 1.2977713690461004,
        "water-fast-z-score": 4.8666426339228765
    },
    {
        "original_text": "We report the discovery and analysis of IGR J16194-2810, an unusual X-ray source discovered by INTEGRAL in 2003. The source is located at RA=16h19m41s DEC=-28d08 00  (J2000) with a positional uncertainty of 1 arcmin radius. It was observed for about 100 ksec on 2004 February 24-25 using XMM-Newton EPIC-pn camera operated in timing mode. We find that this source has a periodicity of P=4.6 hr which we interpret as orbital motion of two compact objects orbiting each other. This interpretation is supported by the presence of strong absorption lines in its optical spectrum indicating the existence of a red giant companion star. Using the measured mass function f(M), we estimate the masses of both components to be Mx=2.7-3.1 M⊙ and My=1.2-1.4 M⊙ respectively.",
        "watermark_text": "We report the discovery and investigation of IGR J16194 - 2810 , an unique X - ray source detected by INTEGRAL in 2003 . The source is situated at RA = 16h19m41s DEC = - 28d08 00 ( J2000 ) with a positional uncertainty of 1 arcmin radius .It was seen for about 100 ksec on 2004 February 24 - 25 using XMM - Newton EPIC - pn sensor run in timing mode . We see that this source has a periodicity of P = 4 . 6 hr which we perceive as orbital movement of two compact entities orbiting each other .This interpretation is backed by the presence of bright absorption lines in its optical spectrum suggesting the existence of a red giant sister star . Using the measured mass distribution f ( M ) , we estimate the masses of both components to be Mx = 2 . 7 - 3 . 1 [UNK] and My = 1 . 2 - 1 . 4 [UNK] respectively .",
        "ori-fast-z-score": -0.7142857142857143,
        "water-fast-z-score": 4.041451884327381
    },
    {
        "original_text": "We present an analysis method for characterizing the stability of optical phase in astronomical instruments, based on the measurement and characterization of fringe contrasts obtained with different integration times.  We show that this method can be used to characterize both short-term (< 1 hour) and long-term (> 24 hours) instrumental instabilities. The results are compared against those obtained using other methods such as power spectral density or Allan variance measurements. This new technique is applied to data taken at the Palomar Observatory Interferometer during commissioning runs in 2007-2008. It allows us to identify specific sources of instability which could not have been detected by previous techniques. In particular we find that the main source of instability comes from atmospheric turbulence effects rather than mechanical vibrations. Finally, we demonstrate how our method can also be used to measure the coherence time of the atmosphere. Keywords: Fringe contrast, Optical interferometry, Instrumentation, Atmospheric turbulence",
        "watermark_text": "We present an assessment method for characterizing the stability of optical phase in astronomical instruments , relying on the observation and description of fringe contrasts obtained with various integration times . We see that this method can be used to characterize both long - term ( < 1 hour ) and long - term ( > 24 hours ) instrumental instabilities .The results are compared against those achieved using other methods such as power spectral coefficient or Allan variance measurements . This new technique is applied to data taken at the Palomar Observatory Interferometer during commissioning running in 2007 - 2008 .It enables us to identify specific sources of tension which could not have been detected by earlier techniques . In particular we find that the main origin of tension comes from ambient turbulence influences rather than structural vibrations .Finally , we prove how our technique can also be used to measure the coherence time of the air . Keywords : Fringe comparison , Optical interferometry , Instrumentation , Atmospheric turbulence",
        "ori-fast-z-score": 0.35603449745815596,
        "water-fast-z-score": 5.892556509887896
    },
    {
        "original_text": "We study the effect of random large-scale forcing on three-dimensional rotating stratified flows, using direct numerical simulations (DNS) with periodic boundary conditions. The flow is forced at large scales by adding to the momentum equation an external force that has zero mean but whose Fourier transform contains both positive and negative wavenumbers. We find that this type of forcing excites two distinct types of modes in the system: vortical and wave-like modes. Vortical modes are characterized by strong vertical motions concentrated near the center of the domain; they have low horizontal velocities and their kinetic energy decays rapidly as we move away from the center. On the other hand, wave-like modes are characterized by weak vertical motions distributed over larger regions of space; they have high horizontal velocities and their kinetic energies decay slowly or even increase slightly when moving away from the center. In addition, these waves can be either stationary or propagating horizontally depending on whether the forcing spectrum peaks at small or large horizontal wavenumber respectively.",
        "watermark_text": "We research the impact of random large - scale forcing on three - dimensional spinning stratified flows , using direct numerical simulations ( DNS ) with periodic border conditions . The flow is displaced at large scales by added to the velocity equation an external force that has zero mean but whose Fourier integral contains both negative and negative wavenumbers .We see that this form of forcing excites two different kinds of modes in the system : vortical and wave - like modes . Vortical modes are characterized by intense vertical motions confined near the center of the domain ; they have low vertical velocities and their kinetic power decays slowly as we move back from the center .On the other hand , wave - like modes are characterized by weak vertical motions spread over larger parts of space ; they have high vertical velocities and their kinetic energies decline slowly or even change slightly when moved away from the center . In addition , these currents can be either static or propagating vertically varying on whether the forcing spectrum peaks at small or large horizontal wavenumber respectively .",
        "ori-fast-z-score": -2.4379951240146283,
        "water-fast-z-score": 4.133991732024804
    },
    {
        "original_text": "The self-consistent approach to the description of nuclear matter is reviewed and its application to other systems, such as atomic nuclei or quark-gluon plasma, discussed briefly. The main idea behind this method is that one should not consider only the mean field acting on particles but also take into account fluctuations around it. This leads to an infinite set of coupled equations for all orders of correlation functions which can be solved by truncation at some order. In particular we discuss how the results depend on the choice of the approximation scheme used. We show that the inclusion of higher-order correlations improves agreement with experimental data considerably. Finally, we present our recent results obtained within the framework of the relativistic random phase approximation (RRPA) including up to fourth-order correlations. These calculations are performed using realistic nucleonnucleon interactions derived from chiral effective theory. It turns out that the RRPA results agree well with available experimental information about excited states of medium-heavy nuclei.",
        "watermark_text": "The self - consistent method to the description of nuclear material is reviewed and its use to other systems , such as atomic ions or quark - gluon plasma , discussed momentarily . The main idea behind this process is that one should not take only the mean field acted on electrons but also took into consideration fluctuations around it .This leads to an endless system of coupled equations for all orders of correlation functions which can be answered by truncation at some order . In particular we explain how the results vary on the selection of the approximation scheme used .We see that the inclusion of greater - order correlations improves agreement with observation information significantly . Finally , we present our latest findings obtained within the framework of the relativistic random phase approximation ( RRPA ) covering up to fourth - order correlations .These analyses are performed using accurate nucleonnucleon interactions derived from chiral effective theory . It turns out that the RRPA results agree well with provided experimental evidence about excited states of medium - heavy nuclei .",
        "ori-fast-z-score": -0.10976425998969035,
        "water-fast-z-score": 6.256562819412349
    },
    {
        "original_text": "We present the first mid-infrared phase curve observations for an extrasolar planet, WASP-121b (1SWASP J140747.93-394542.7), using Spitzer/IRAC at 3.6 and 4.5 microns. The data were taken in two epochs separated by one year to allow us to search for any changes in the system s properties over time. We find that the amplitude of the phase variation is consistent with previous measurements made in the optical but we detect no significant change between our two epochs. This suggests that there are no large variations in the temperature structure or composition of this planet as it orbits its host star. Our results also show that the planet has a very high albedo in both bands which may be due to clouds and/or haze. These findings have important implications for understanding how planets form and evolve. \n \n Keywords: exoplanet, infrared",
        "watermark_text": "We present the first mid - infrared phase curve measurements for an extrasolar planet , WASP - 121b ( 1SWASP J140747 . 93 - 394542 . 7 ) , using Spitzer / IRAC at 3 . 6 and 4 . 5 microns . The data were took in two epochs separated by one month to allow us to search for any alterations in the system s features over time .We see that the frequency of the phase change is compatible with previous measurements made in the optical but we perceive no major shift between our two epochs . This implies that there are no large changes in the temperature structure or composition of this planet as it orbits its host star .Our results also demonstrate that the planet has a very high albedo in both bands which may be due to clouds and / or haze . These conclusions have important implications for explaining how planets form and evolve .Keywords: exoplanet, infrared",
        "ori-fast-z-score": 0.5252257314388902,
        "water-fast-z-score": 4.727031582950012
    },
    {
        "original_text": "We consider the non-relativistic limit of an exact solution to the Einstein field equations in vacuum, which is given by the Schwarzschild metric. We show that this metric can be obtained as a special case of the general relativistic Kerr-Schild ansatz for stationary and axisymmetric solutions with spherical symmetry. The corresponding line element reads ds2 = -(1 + 2M/r)dt2 + (1 - 2M/r)(dr2 + r2 dΩ2), where M denotes the mass parameter. In order to obtain the correct Newtonian limit we have to choose the time coordinate such that dt/dτ ~ 1/Mc² holds asymptotically at spatial infinity. This choice leads to the standard form of the Schwarzschild metric in terms of proper time τ. Finally, we discuss some consequences concerning the gravitational redshift and the equivalence principle. The Schwarzschild metric describes the geometry outside a spherically symmetric body in vacuum. It was first derived by Karl Schwarzschild in 1916  1  .",
        "watermark_text": "We consider the non - relativistic limit of an precise answer to the Einstein field equations in vacuum , which is given by the Schwarzschild metric . We see that this metric can be obtained as a special case of the general relativistic Kerr - Schild ansatz for stationary and axisymmetric solutions with spherical symmetry .The equivalent line element reads ds2 = - ( 1 + 2M / r ) dt2 + ( 1 - 2M / r ) ( dr2 + r2 dΩ2 ) , where M describes the mass vector . In order to obtain the appropriate Newtonian limit we have to choose the time coordinate such that dt / dτ ~ 1 / Mc² holds asymptotically at spatial infinity .This choosing results to the standard form of the Schwarzschild metric in terms of proper time τ . Finally , we explain some consequences concerning the gravitational redshift and the equivalence principle .The Schwarzschild metric measures the topology outside a spherically symmetric body in vacuum . It was first developed by Karl Schwarzschild in 1916 1 .",
        "ori-fast-z-score": 2.1766269588592317,
        "water-fast-z-score": 4.993438317382943
    },
    {
        "original_text": "We present an analysis of the evolution of interstellar dust grains, based on their size distribution inferred by infrared observations with ISO (Infrared Space Observatory). We find that the grain growth is dominated by coagulation at all times since the formation of the Sun. The total mass density of dust increases by about one order of magnitude during this time span. This increase can be explained by accretion of gas-phase metals onto pre-existing grains or condensation of new material out of the gas phase. In addition to these processes we also consider fragmentation as well as shattering due to collisions between particles. Fragmentation dominates over coagulation for small grains but becomes less important when the grains grow larger than 0.1 micrometres. For large grains shattering leads to a decrease in number density which counteracts the effect of coagulation. Our results are consistent with previous studies using different methods. \n \n Keywords: Interstellar medium",
        "watermark_text": "We present an assessment of the evolution of interstellar dust grains , using on their height pattern inferred by infrared observations with ISO ( Infrared Space Observatory ) . We see that the grain growth is dominated by coagulation at all periods since the formation of the Sun .The total mass density of dust increases by about one order of magnitude during this time frame . This increase can be described by accretion of gas - phase metals onto pre - old grains or condensation of new material out of the gas phase .In addition to these mechanisms we also consider fragmentation as well as shattering caused to collisions between particles . Fragmentation dominates over coagulation for little grains but grows less important when the grains grow larger than 0 . 1 micrometres .For large grains breaking leads to a reduction in quantity density which counteracts the impact of coagulation . Our results are compatible with previous research utilizing different methods .Keywords: Interstellar medium",
        "ori-fast-z-score": 0.9701425001453319,
        "water-fast-z-score": 6.305926250944657
    },
    {
        "original_text": "The response prediction of structural system subject to earthquake motions is very important for the design and construction of buildings in seismic areas, especially when it comes to high-rise building structures. In this study, an artificial neural network (ANN) model was developed by using data obtained through nonlinear dynamic analysis on reinforced concrete frame structure subjected to earthquake ground motion records. The ANN model consists of three layers; input layer, hidden layer with 10 neurons, output layer with one neuron representing maximum inter-story drift ratio. Input variables used are peak ground acceleration, duration time, number of stories, story height, mass density per unit floor area, damping coefficient, yield strength of steel bar, elastic modulus of steel bar, shear wall stiffness, and moment capacity of beam-column joint. To verify the accuracy of the proposed ANN model, results predicted by the ANN were compared with those calculated by nonlinear dynamic analysis program. It can be concluded that the ANN model has good performance in predicting the maximum inter-story drift ratios under various earthquake ground motions.",
        "watermark_text": "The behavior analysis of structural structure exposed to earthquake motions is very important for the design and build of structures in seismic areas , particularly when it comes to large - rising building structures . In this study , an synthetic neural network ( ANN ) model was developed by using data derived through nonlinear dynamic analysis on concrete cement frame building exposed to earthquake ground motion records .The ANN system contains of three layers ; input layer , hidden surface with 10 neurons , output layer with one neuron representing maximum inter - story drag ratio . Input variables utilized are peak ground acceleration , duration time , number of floors , story height , mass density per unit floor area , damping coefficient , yield strength of steel bar , elastic modulus of steel bar , shear floor stiffness , and moment capacity of beam - column joint .To verify the accuracy of the suggested ANN theory , results predicted by the ANN were compared with those estimated by nonlinear dynamic analysis project . It can be assumed that the ANN theory has good success in predicting the maximum inter - story drag ratios under various earthquake ground motions .",
        "ori-fast-z-score": 1.0536089137432665,
        "water-fast-z-score": 6.800566625070174
    },
    {
        "original_text": "We present multiwavelength observations for a sample of X-ray selected star forming galaxies (SFGs) in the Chandra Deep Field-South (CDF-S). The sample consists of 16 SFGs with spectroscopic redshifts between 1 and 3, which were detected by both the soft-band (0.5-2 keV) and hard-band (2-8 keV) surveys conducted by the Advanced CCD Imaging Spectrometer on board XMM-Newton. We have obtained optical spectroscopy using the Keck telescope to measure their stellar masses and SFRs as well as near-infrared photometry taken with the Infrared Array Camera aboard Spitzer Space Telescope to estimate dust extinction. Our results show that these SFGs are massive systems with M* = 1013 -1014M⊙ at z ~ 2 -3. They also exhibit high specific star-formation rates ranging from 10^(-3) yr-1 to 10^(1) yr-1, indicating intense ongoing star formation activity.",
        "watermark_text": "We present multiwavelength surveys for a sample of X - ray selected star producing galaxies ( SFGs ) in the Chandra Deep Field - South ( CDF - S ) . The sample consists of 16 SFGs with spectroscopic redshifts between 1 and 3 , which were detected by both the hard - band ( 0 . 5 - 2 keV ) and hard - band ( 2 - 8 keV ) observations conducted by the Advanced CCD Imaging Spectrometer on board XMM - Newton .We have achieved visual spectroscopy utilizing the Keck telescope to measure their stellar distances and SFRs as also as near - infrared photometry seen with the Infrared Array Camera aboard Spitzer Space Telescope to estimate dust extinction . Our results show that these SFGs are powerful systems with M * = 1013 - [UNK] at z ~ 2 - 3 .They also display high specific star - formation rates ranging from 10 ^ ( - 3 ) yr - 1 to 10 ^ ( 1 ) yr - 1 , showing intense ongoing star formation activity .",
        "ori-fast-z-score": -0.7001400420140048,
        "water-fast-z-score": 3.780756226875626
    },
    {
        "original_text": "We investigate whether we can detect anisotropy in quasar H II regions during reionization through their small-scale redshifted 21 cm power spectrum (21-cm PS). In our model, quasars are assumed to be located at peaks of dark matter density fluctuations and ionize surrounding gas with an anisotropic Strömgren sphere whose shape is determined by the local tidal field. By performing numerical simulations for different values of the spin temperature T S , we find that the 21-cm PS has a characteristic peak structure which reflects the shapes of individual H II regions. This peak structure becomes more prominent as T S decreases because the number of neutral hydrogen atoms increases due to the decrease in the brightness temperature difference between the CMB and the 21-cm emission line. Our results suggest that it may be possible to use this peak structure to constrain the value of T S . However, since there exist many other factors affecting the 21-cm PS besides T S , further studies will be needed before drawing any conclusions on its detectability.",
        "watermark_text": "We explore whether we can identify anisotropy in quasar H II regions during reionization through their tiny - scale redshifted 21 cm power spectrum ( 21 - cm PS ) . In our model , quasars are expected to be found at peaks of dark matter density fluctuations and ionize neighboring plasma with an anisotropic Strömgren ball whose shape is chosen by the local tidal field .By conducting numerical simulations for different values of the spin temperature T S , we find that the 21 - cm PS has a typical peak structure which reflects the shapes of different H II regions . This peak structure becomes more prominent as T S drops because the proportion of neutral hydrogen atoms increases owing to the decrease in the brightness temperature difference between the CMB and the 21 - cm absorption line .Our results propose that it could be possible to use this peak structure to constrain the value of T S . However , since there remain many other influences involving the 21 - cm PS besides T S , further studies will be needed before drew any findings on its detectability .",
        "ori-fast-z-score": 1.7320508075688772,
        "water-fast-z-score": 6.350852961085883
    },
    {
        "original_text": "We report the first measurement of the cross section for the process ppbar -> Zgamma + X, where X is any number of additional particles produced along with the Zgamma boson.  The data were collected by the D0 experiment during Run II of Fermilab s Tevatron Collider between 2002 and 2007 using an integrated luminosity of 5.4 fb-1 . We measure the cross section to be 0.84 +/- 0.11 (stat.) +/- 0.10 (syst.) pb, which agrees well with next-to-leading-order perturbative QCD predictions. Using this result we set upper limits on possible anomalous trilinear gauge-boson coupling parameters. These results are also used to derive constraints on models that predict new heavy neutral vector bosons decaying into pairs of photons or gluons. In addition, these measurements provide important input for future searches for Higgs bosons decaying into two photons. \nPACS numbers: 11.30.Er, 12.60.Jv",
        "watermark_text": "We report the first measurement of the cross area for the process ppbar - > Zgamma + X , where X is any number of added particles generated along with the Zgamma boson . The data were collected by the D0 study during Run II of Fermilab s Tevatron Collider between 2002 and 2007 utilizing an integrated luminosity of 5 . 4 fb - 1 .We estimate the cross area to be 0 . 84 + / - 0 . 11 ( stat . ) + / - 0 . 10 ( syst . )pb , which agrees well with next - to - leading - order perturbative QCD estimates . Using this consequence we put upper limits on potential anomalous trilinear gauge - boson correlation parameters .These data are also used to derive restrictions on estimates that forecast new heavy neutral vector bosons decaying into sets of photons or gluons . In addition , these measurements give important output for future investigations for Higgs bosons decaying into two photons .PACS codes : 11 . 30 . Er , 12 . 60 . Jv",
        "ori-fast-z-score": -1.0886621079036347,
        "water-fast-z-score": 4.532898610306738
    },
    {
        "original_text": "We study the dynamics of an interacting Bose gas with repulsive contact interactions in one dimension, focusing on its relaxation to equilibrium after being quenched across the superfluid-Mott insulator transition. We show that this system exhibits universal behavior at late times which is characterized by power-law decaying correlations and algebraic growth of entanglement entropy. The exponents are determined analytically using a mapping onto a classical statistical mechanics problem for a driven diffusive system. This work was supported by NSF grant PHY-0960291 (M.S.) and DOE grants DE-FG03-92-ER40701 and DE-SC0012704 (A.K.). \nI. INTRODUCTORY REMARkS\n\nThe recent experimental realization of quantum degenerate gases has opened up new avenues towards understanding strongly correlated many-body systems  1  . In particular, ultracold atomic gases have been used as model systems to explore phenomena such as fermionization  2  , supersolidity  3  , and Mott-insulating states  4  .\nIn this article we consider a particularly interesting class of experiments where the properties of these systems can be probed through their response to sudden changes in parameters  5  . For example, if the strength of inter-particle repulsion or density of particles is suddenly changed then it takes some time before the system reaches thermal equilibrium  6  . During this nonequilibrium evolution, the system may exhibit novel features like dynamical scaling  7, 8  and non-thermal fixed points  9  . These effects are not only important for our fundamental understanding of quantum matter but also provide useful insights into possible routes to realizing novel phases of matter  10  .\nRecently there has been considerable interest in studying the nonequilibrium dynamics of bosonic systems  11  . A particularly well studied case is when the initial state corresponds to a highly excited state above the ground state  12  . It turns out that even though the initial state is far away from equilibrium, the system relaxes to a steady state described by a Gibbs ensemble  13  . However, if the initial state is prepared deep inside the ordered phase, then the system does not",
        "watermark_text": "We explore the dynamics of an interacting Bose gas with repulsive contact interactions in one dimension , concentrating on its relaxation to equilibrium after being quenched across the superfluid - Mott insulator transition . We see that this system displays universal behavior at late times which is characterized by power - law decaying correlations and algebraic growth of entanglement entropy .The exponents are estimated analytically using a mapping onto a traditional statistical mechanics problem for a driven diffusive system . This research was supported by NSF grant PHY - 0960291 ( M . S . )and DOE funds DE - FG03 - 92 - ER40701 and DE - SC0012704 ( A . K . ) . I .INTRODUCTORY REMARkS The recent experimental realization of quantum degenerate gases has opened up new avenues towards studying strongly interacting multiple - bodies systems 1 . In particular , ultracold nuclear gases have been used as model structures to examine processes such as fermionization 2 , supersolidity 3 , and Mott - insulating states 4 .In this article we imagine a particularly exciting group of studies where the properties of these systems can be probed through their response to unexpected changes in parameters 5 . For instance , if the strength of inter - atom repulsion or density of molecules is suddenly changed then it takes some time before the system reaches heat equilibrium 6 .During this nonequilibrium evolution , the system might exhibit new characteristics like dynamical scaling 7 , 8 and non - cooling fixed points 9 . These effects are not only important for our fundamental understanding of quantum matter but also provide useful insights into possible routes to realizing new phases of matter 10 .Recently there has been substantial interest in investigating the nonequilibrium dynamics of bosonic systems 11 . A notably well discussed case is when the first state corresponds to a highly excited state above the ground state 12 .It happens out that even though the first state is far back from equilibrium , the system relaxes to a steady state described by a Gibbs ensemble 13 . However , if the initial system is prepared deep inside the ordered phase , then the system does not",
        "ori-fast-z-score": 0.5773502691896257,
        "water-fast-z-score": 7.175639059928206
    },
    {
        "original_text": "We consider the problem of time evolution for quantum fields on the Milne universe, which is an open FRW cosmology with negative spatial curvature and vanishing cosmological constant. We show that there are no normalizable solutions to the Klein-Gordon equation corresponding to massive particles at early times (t → −∞). This result can be understood as follows. The Milne universe has a singularity at t = 0 where all physical quantities diverge. In particular, the energy density diverges like $1/t^2$ near this point. As a consequence, any particle state localized around $t=0$ will have infinite energy. Therefore it cannot correspond to a physically meaningful solution of the field equations. On the other hand, we find that there exist normalizable states describing massless particles at early times. These states represent gravitons or photons propagating into the past along geodesics towards the big bang singularity.",
        "watermark_text": "We consider the question of time progression for quantum fields on the Milne universe , which is an open FRW cosmology with negative spatial curvature and vanishing cosmological constant . We see that there are no normalizable responses to the Klein - Gordon equation equivalent to massive particles at early years ( t → −∞ ) .This result can be understood as follows . The Milne universe has a singularity at t = 0 where all physical components diverge .In particular , the power concentration diverges like $ 1 / t ^ 2 $ near this point . As a consequence , any particle state concentrated around $ t = 0 $ will have infinite energy .Therefore it lacks correspond to a physically useful solve of the field equations . On the other hand , we find that there exist normalizable states describing massless objects at early years .These states reflect gravitons or photons propagating into the past along geodesics towards the big bang singularity .",
        "ori-fast-z-score": -0.2672612419124244,
        "water-fast-z-score": 3.640679257301507
    },
    {
        "original_text": "The topological classification of clusters is reviewed, with emphasis on the role played by symmetry and topology in determining cluster structures.  The concept of  topology  refers to the connectivity between atoms or molecules within a cluster; it can be used as an organizing principle for classifying clusters into families based upon their structural similarities. This review focuses primarily on metal clusters (i.e., clusters containing one or more metallic elements), but also discusses some examples of non-metallic clusters that have been studied recently. In addition, we briefly discuss how this approach has been applied to classify clusters formed during chemical reactions. Finally, we present several open questions related to the topic of cluster topology. Topology plays an important role in understanding the structure of matter at all scales ranging from atomic nuclei to macroscopic materials such as crystals. It provides a useful framework for classifying clusters according to their structural similarity. Herein, we provide a brief overview of recent progress made towards developing a systematic classification scheme for clusters using concepts borrowed from condensed-matter physics.",
        "watermark_text": "The topological characterization of clusters is reviewed , with emphasis on the importance played by symmetry and topology in distinguishing cluster structures . The concept of topology refers to the connectivity between molecules or compounds within a cluster ; it can be used as an organizing principle for classifying compounds into families according upon their structural links .This study deals mainly on metal clusters ( i . e . , clusters featuring one or more metallic compounds ) , but also explains some examples of non - metallic complexes that have been studied ago . In addition , we occasionally explore how this methodology has been used to classify clusters formed during chemical processes .Finally , we present many open questions related to the subject of cluster topology . Topology plays an important role in understanding the structure of matter at all scales ranging from atomic atoms to macroscopic materials such as crystals .It provides a helpful basis for classifying clusters according to their structural similarity . Herein , we provide a brief overview of recent progress made towards developing a comprehensive classification system for clusters using concepts borrowed from condensed - matter theory .",
        "ori-fast-z-score": 0.10153461651336192,
        "water-fast-z-score": 6.599750073368524
    },
    {
        "original_text": "We study the phase diagram and critical behavior of an anisotropic system consisting of Nx × Ny spins on a square lattice, where each spin is described by the two-dimensional XY model. We find that there are three phases depending on the values of J1 / J2 (J2 > 0); ferromagnetic state for small J1 / J2 , spiral state for intermediate J1 / J2 , and paramagnetic state for large J1 / J2 . The transition between these states belongs to the universality class of the Ising model. In particular we show that the spiral state has a nontrivial structure which can be regarded as a superposition of ferromagnetically ordered domains with different orientations. This result suggests that the spiral state may have some relevance to the physics of high-Tc cuprates. \n \n Introduction \n \n It was shown recently  1  that the ground-state properties of the twodimensional Heisenberg antiferromagnet with nearest-neighbor interactions depend strongly on whether or not the exchange interaction along one direction vanishes identically. For example, if the exchange interaction along the y-direction vanishes completely, then the ground state becomes ferromagnetic even though it consists only of S = 1/2 spins. On the other hand, when the exchange interaction along both directions does not vanish simultaneously, the ground state is always antiferromagnetic  2  .\n \nIn this work, we consider another type of anisotropy in the two-dimensional XY model: namely, we assume that the coupling constant along the x-direction is larger than that along the y-direction. As will become clear later, such an anisotropy plays an important role in determining the nature of the ground state.",
        "watermark_text": "We explore the phase diagram and critical behavior of an anisotropic scheme consisting of Nx × Ny spins on a square lattice , where each spin is characterized by the two - dimensional XY model . We see that there are three stages depending on the values of J1 / J2 ( J2 > 0 ) ; ferromagnetic state for large J1 / J2 , spiral state for advanced J1 / J2 , and paramagnetic state for large J1 / J2 .The shift between these states belongs to the universality category of the Ising model . In particular we find that the spiral state has a nontrivial structure which can be regarded as a superposition of ferromagnetically ordered domains with various orientations .This result suggests that the spiral state may have some relevance to the physics of high - Tc cuprates . Introduction It was shown recently 1 that the ground - state properties of the twodimensional Heisenberg antiferromagnet with nearest - neighbor interactions depend greatly on whether or not the transfer coupling along one orientation vanishes identically .For instance , if the transfer coupling along the y - direction vanishes totally , then the ground state remains ferromagnetic even though it consists only of S = 1 / 2 spins . On the other hand , when the transfer exchange along both directions does not vanish simultaneously , the ground state is always antiferromagnetic 2 .In this research , we define another type of anisotropy in the two - dimensional XY model : specifically , we suppose that the interaction factor along the x - direction is bigger than that along the y - direction . As will become clear earlier , such an anisotropy takes an important role in determining the nature of the ground state .",
        "ori-fast-z-score": 0.7921180343813395,
        "water-fast-z-score": 6.601706163700764
    },
    {
        "original_text": "The Fermi Large Area Telescope (LAT) has revolutionized our understanding of blazar jets by providing unprecedented sensitivity to gamma rays above 100 MeV. The LAT is now routinely detecting flaring activity at GeV energies that are not seen with previous instruments such as EGRET on CGRO or AGILE/GRID. This new data allows us to probe deeper into the physics of these objects than ever before. \n \n In this talk I will discuss how we can use the upcoming generation of space-based observatories - including GLAST and EXIST - to study blazars over an even broader energy range. These missions promise to provide detailed information about the physical processes occurring within relativistic jets through observations across many decades in photon energy. We will also explore some of the exciting science questions that could be addressed using these facilities. Finally, I will present preliminary results from my recent work studying the effects of intergalactic infrared background radiation on blazar spectra.",
        "watermark_text": "The Fermi Large Area Telescope ( LAT ) has revolutionized our knowing of blazar jets by offering extraordinary exposure to gamma radiation above 100 MeV . The LAT is now regularly detecting flaring activity at GeV values that are not seen with previous instruments such as EGRET on CGRO or AGILE / GRID .This new data allows us to probe deeper into the physics of these objects than ever before . In this talk I will explain how we can using the latest generation of space - based observatories - including GLAST and EXIST - to study blazars over an much broader energy range .These expeditions promise to provide comprehensive information about the natural reactions evolving within relativistic jets through observations across many years in photon energy . We will also investigate some of the exciting science problems that might be addressed using these facilities .Finally , I will present preliminary results from my current work studying the effects of intergalactic infrared background radiation on blazar spectra .",
        "ori-fast-z-score": 1.4770978917519928,
        "water-fast-z-score": 6.474980550884177
    },
    {
        "original_text": "We report near-infrared coronagraphic observations of the young binary system UY Aurigae (=V773 Tau) obtained with the Subaru Telescope in December 2005 and January 2006, using the newly installed HiCIAO instrument equipped with an occulting mask. The data were reduced by subtracting dark frames and flat fields to remove detector biases and pixel-to-pixel variations respectively. We then applied aperture photometry on each frame after masking out bad pixels and cosmic rays. Finally we averaged all the individual frames together for each filter bandpass. Our results show that there is no significant difference between our two epochs of observation within the uncertainties. In addition, we find that the flux ratio between the primary star and its companion varies significantly depending upon which filter was used during the observations. This suggests that the spectral energy distribution of UY Aur may be changing over time as it evolves towards the main sequence. \n \n Keywords: Young stars",
        "watermark_text": "We report near - infrared coronagraphic observations of the young binary system UY Aurigae ( = V773 Tau ) obtained with the Subaru Telescope in December 2005 and January 2006 , using the newly installed HiCIAO object fitted with an occulting mask . The data were reduced by subtracting bright frames and flat fields to remove detector biases and pixel - to - pixel differences respectively .We then added aperture photometry on each frame after masking out bad pixels and cosmic rays . Finally we combined all the different images together for each filter bandpass .Our results show that there is no considerable difference between our two epochs of observation within the uncertainties . In addition , we find that the flux ratio between the primary star and its companion vary significantly depending upon which filter was used during the surveys .This implies that the spectral power distribution of UY Aur may be changing over time as it evolves towards the main sequence . Keywords : Young stars",
        "ori-fast-z-score": 1.270001270001905,
        "water-fast-z-score": 4.993438317382943
    },
    {
        "original_text": "We report on an experiment that tests the predictions of quantum mechanics and local hidden variable theories for two entangled photons in a Bell state, using polarization-entanglement swapping to create a loophole-free Bell inequality violation.  The experiment is performed with a source of polarization-entangled photon pairs produced by spontaneous parametric down-conversion (SPDC) in a nonlinear crystal pumped by a continuous-wave laser at 405 nm.   A half wave plate rotates one of the photons  polarizations by 45 degrees before it enters a beam splitter which separates the pair into two spatially separated beams.   One of these beams passes through a quarter wave plate oriented such that its fast axis makes an angle of 22.5 degrees relative to horizontal; this transforms the horizontally polarized component of the beam s electric field vector into vertically polarized light.   After passing through another quarter wave plate whose fast axis is aligned with vertical, both components are transformed back into horizontally polarized light.   This transformation can be represented as follows:  H → V → H = HVH.   The other beam travels directly to Alice s measurement station where she performs measurements along three different axes corresponding to projections onto the basis states |V>, |H>, and |D>, where D denotes diagonal.   Bob measures his photon along four different axes corresponding to projections",
        "watermark_text": "We report on an experiment that tests the assumptions of quantum mechanics and local hidden variable theories for two entangled photons in a Bell state , using polarization - entanglement swapping to create a loophole - free Bell inequality violation . The experiment is conducted with a source of polarization - entangled photon pairs formed by spontaneous parametric down - transfer ( SPDC ) in a nonlinear crystal pumped by a continuous - wave beam at 405 nm .A half wave plate rotates one of the photons polarizations by 45 degrees before it enters a light splitter which separates the pair into two spatially joined beams . One of these beams passes through a quarter wave plate angled such that its fast axis creates an angle of 22 . 5 degrees relative to vertical ; this changes the horizontally polarized component of the laser s electric field vector into horizontal polarized light .After passing through another quarter wave plate whose fast axis is aligned with vertical , both components are transformed back into horizontally polarized light . This transformation can be described as follows : H → V → H = HVH .The other light journeys directly to Alice s monitoring facility where she takes measurements along three different axes corresponding to projections onto the basis states | V > , | H > , and | D > , where D denotes diagonal . Bob measures his photon along four different axes corresponding to projections",
        "ori-fast-z-score": 0.9138115486202573,
        "water-fast-z-score": 4.569057743101286
    },
    {
        "original_text": "We study how classical and quantum uncertainty affect the price dynamics in an incomplete information setting, where agents have access to different sources of information about the underlying state variable. We show that when there is no common knowledge among traders on the true value of the state variable, they may disagree on its expected future evolution even if all are rational and risk-neutral. This disagreement leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based solely on their private signals. In this case, we find that the stock returns exhibit volatility clustering and fat tails similar to those observed empirically. Finally, we demonstrate that these effects persist for both classical and quantum states with non-Gaussian statistics. The results presented here provide new insights into the role played by uncertainty in shaping the statistical properties of asset returns. They also suggest possible avenues for further research aimed at understanding the origin of such phenomena within more realistic models of trading behavior.",
        "watermark_text": "We research how classical and quantum uncertainty influence the price dynamics in an incomplete information context , where agents have access to different sources of information about the underlying state variable . We see that when there is no shared information among traders on the true value of the state variable , they may differ on its expected past development even if all are realistic and chance - neutral .This dispute leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based primarily on their private signals . In this instance , we find that the stock returns display volatility clustering and lean tails identical to those observed empirically .Finally , we prove that these consequences persist for both classical and quantum states with non - Gaussian statistics . The results presented here provide fresh insights into the part played by uncertainty in shaping the statistical characteristics of investment returns .They also suggest possible avenues for further studies aimed at studying the origin of such patterns within more realistic descriptions of market behavior .",
        "ori-fast-z-score": -0.7504787743864564,
        "water-fast-z-score": 5.9696200579570915
    },
    {
        "original_text": "We present the results of our study on bimodality in galaxies and active galactic nuclei (AGN). We find that there is no significant difference between the fraction of AGNs hosted by red or blue galaxies, but we do see an excess of AGNs with respect to normal galaxies at intermediate colors. This suggests that AGNs are not preferentially found in either red or blue galaxies, as previously thought; instead they appear to be more common among galaxies with intermediate color. The lack of correlation between galaxy color and AGN activity may indicate that AGNs play only a minor role in quenching star formation in massive galaxies. Alternatively, it could suggest that AGNs have different effects depending on their luminosity and/or accretion rate. In addition, we find that the majority of AGNs reside in galaxies with bulges, regardless of whether these galaxies are classified as early-type or late-type systems.",
        "watermark_text": "We present the conclusion of our research on bimodality in galaxies and active galactic nuclei ( AGN ) . We see that there is no major variation between the fraction of AGNs hosted by red or blue clusters , but we do saw an surplus of AGNs with regard to normal galaxies at intermediate colors .This implies that AGNs are not preferentially found in either blue or blue stars , as previously thought ; however they appear to be more common among clusters with intermediate color . The absence of correlation between galaxy color and AGN activity may indicate that AGNs serve only a minor importance in quenching star formation in massive galaxies .Alternatively , it could indicate that AGNs have different impacts depending on their luminosity and / or accretion rate . In addition , we find that the majority of AGNs occur in galaxies with bulges , regardless of whether these objects are classified as early - class or late - class systems .",
        "ori-fast-z-score": 0.8551861104941365,
        "water-fast-z-score": 6.305926250944657
    },
    {
        "original_text": "We study the second-order correlation function for an atom interacting with two modes of light, one resonant and another off-resonant to atomic transition frequency. We show that higher order antibunching can be observed when the atom is initially prepared in an excited state or ground state superposition. The effect is more pronounced if the initial state has some population on the excited state. This phenomenon may have applications in quantum information processing. \n \n Introduction:-In recent years there has been considerable interest in studying nonclassical properties of radiation fields generated by atoms  1  . In particular, it was shown that the photon statistics of such systems are governed by the first-order coherence function g (1) (τ)  2  , which describes bunching behavior at short times and anti-bunching at longer times  3  . It is well known that this property arises due to destructive interference between different pathways leading to emission of photons  4  .\nRecently, several authors studied the effects of spontaneous emission on the second-order correlation functions  5  -  8  . They showed that the presence of spontaneous emission leads to sub-Poissonian statistics  6 - 8  . However, these studies were restricted only to the case where the atom interacts with a single mode of field. On the other hand, many experiments involving atoms interacting simultaneously with multiple modes of electromagnetic field have also been performed  9  -  11  . For example, in Ref.  10  , the authors investigated the influence of vacuum fluctuations on the fluorescence spectrum of a three-level system driven by two laser beams. In addition, they found that the intensity noise of the emitted light depends strongly on the relative phase difference between the driving lasers. Motivated by these experimental results we consider here the problem of calculating the second-order correlation function of an atom interacting simultaneously with two modes of light  12  .",
        "watermark_text": "We test the second - order correlation function for an element interacting with two modes of light , one resonant and another off - resonant to atomic transition frequency . We see that higher order antibunching can be experienced when the atom is initially prepared in an excited state or ground state superposition .The phenomenon is more pronounced if the first state has some population on the excited state . This phenomenon might have applications in quantum information processing .Introduction : - In recent years there has been substantial interest in investigating nonclassical characteristics of radiation fields generated by atoms 1 . In particular , it was shown that the photon statistics of such systems are governed by the first - order coherence function h ( 1 ) ( τ ) 2 , which explains bunching behavior at short periods and pro - bunching at shorter times 3 .It is well established that this property originates due to destructive interference between various pathways leading to emission of photons 4 . Recently , various papers studied the effects of induced emission on the second - order correlation functions 5 - 8 .They showed that the presence of spontaneous emission contributes to sub - Poissonian statistics 6 - 8 . However , these experiments were restricted only to the case where the atom interacts with a single mode of field .On the other hand , many tests utilizing atoms interacting simultaneously with various modes of electromagnetic field have already been performed 9 - 11 . For instance , in Ref .10 , the authors explored the impact of vacuum fluctuations on the fluorescence spectrum of a three - level network driven by two laser beams . In addition , they reported that the frequency sound of the emitted light depends strongly on the relative phase change between the driving lasers .Motivated by these observation findings we mention here the question of calculating the second - order correlation function of an element interacting simultaneously with two modes of light 12 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.3484692283495345
    },
    {
        "original_text": "We present an analysis of the final masses of gas giant planets in our Solar System, based on their orbital parameters and compositions inferred by remote sensing observations. We find that Jupiter s mass is consistent with its composition if it formed at 5 AU or less; Saturn s mass can be explained only if it formed beyond 10 AU. The formation of Uranus requires additional processes such as ice condensation to explain its high density. Neptune may have been born more massive than we see today but lost most of its initial mass through photoevaporation driven by intense stellar radiation. Our results suggest that the core accretion model for planet formation cannot fully account for all observed properties of gas giant planets. Keywords: Planet formation, Core accretion theory, Photoevaporation, Mass loss, Stellar radiation, Ice condensation, Orbital evolution, Final mass, Solar system, Remote sensing observation, Compositions, Density",
        "watermark_text": "We present an assessment of the last masses of gas giant planets in our Solar System , relying on their orbital characteristics and compositions inferred by distant sensing measurements . We see that Jupiter s mass is compatible with its composition if it created at 5 AU or smaller ; Saturn s mass can be understood only if it created beyond 10 AU .The formation of Uranus demands extra processes such as ice condensation to explain its high density . Neptune might have been born more massive than we saw nowadays but lost most of its initial mass through photoevaporation driven by intense stellar radiation .Our results show that the core accretion theory for planet development cannot fully account for all observed properties of gas giant worlds . Keywords : Planet structure , Core accretion theory , Photoevaporation , Mass loss , Stellar radiation , Ice condensation , Orbital development , Final mass , Solar system , Remote sensing observation , Compositions , Density",
        "ori-fast-z-score": -0.8551861104941365,
        "water-fast-z-score": 4.764608329895903
    },
    {
        "original_text": "In this work, we study the charged axially symmetric solution and energy in teleparallel theory equivalent to general relativity (GR). We find that the field equations are exactly same as those obtained by GR with an additional term which is proportional to the torsion scalar T . The solutions for the metric functions are found numerically using the shooting method. It turns out that these solutions have no singularities at all. In addition, it has been shown that the total energy density is positive definite everywhere inside the star. Finally, we show that our results agree well with those obtained by GR. This shows that the teleparallel gravity can be considered as alternative gravitational theories to GR. Keywords: Charged axially symmetric solution; energy; teleparallel gravity; Einstein-Maxwell system. 1 Introduction Gravity plays important role in understanding many physical phenomena such as black holes  1  , cosmology  2  , quantum mechanics  3  etc.. However, there still remain some unsolved problems like dark matter  4  , dark energy  5  , inflation  6  etc., which cannot be explained within the framework of standard model of particle physics  7, 8  .\nThe most successful classical description of gravitation is provided by Einstein s general relativity (GR)  9  where the curvature tensor R µνρσ describes the geometry of space-time  10  . On the other hand, teleparallel gravity  11  -  13  is another approach to describe gravitation on the basis of tetrad fields e A µ instead of metric g µν  14  . Here, the basic variables are connection coefficients Γ λ µν defined through vierbein fields e \nwhere η AB = diag(−1, +1, +1, +1), and h ABCD denotes the contortion tensor  15  . The corresponding Lagrangian density reads  16  :",
        "watermark_text": "In this research , we study the charged axially symmetric solution and energy in teleparallel theory equivalent to general relativity ( GR ) . We see that the field equations are exactly same as those given by GR with an additional term which is proportional to the torsion scalar T .The responses for the metric functions are found numerically using the shot technique . It happens out that these solutions have no singularities at all .In addition , it has been shown that the total energy density is positive definite everywhere inside the star . Finally , we find that our findings agree well with those achieved by GR .This shows that the teleparallel gravitational can be regarded as alternative gravity explanations to GR . Keywords : Charged axially symmetric solution ; energy ; teleparallel gravitational ; Einstein - Maxwell system .1 Introduction Gravity takes key importance in understanding several physical phenomena such as black holes 1 , cosmology 2 , quantum mechanics 3 etc . . However , there still continue some unsolved issues like dark matter 4 , darkness energy 5 , inflation 6 etc . , which cannot be described within the framework of standard theory of particle science 7 , 8 .The most popular classical description of gravitation is provided by Einstein s general relativity ( GR ) 9 where the curvature tensor R µνρσ describes the topology of space - time 10 . On the other hand , teleparallel gravitational 11 - 13 is another technique to explain gravitation on the basis of tetrad fields r A µ instead of metric g µν 14 .Here , the fundamental variables are connection coefficients Γ λ µν characterized through vierbein fields e where η AB = diag ( −1 , + 1 , + 1 , + 1 ) , and h ABCD denotes the contortion tensor 15 . The equivalent Lagrangian density reads 16 :",
        "ori-fast-z-score": 0.4583492485141057,
        "water-fast-z-score": 6.141879930089016
    },
    {
        "original_text": "The discovery that the universe is expanding at an accelerating rate has led to intense interest in dark energy as well as new ideas about fundamental physics. This talk will review some recent results on these topics including constraints on models for cosmic acceleration using supernovae data, measurements of the Hubble constant with Type Ia supernovae, and tests of general relativity using gravitational lensing statistics. The talk will also discuss how future surveys such as LSST can be used to further our understanding of dark energy and fundamental physics. I will conclude by discussing my own work on testing gravity theories beyond Einstein s theory using weak lensing observations. Keywords: Cosmology, Dark Energy, General Relativity, Weak Lensing, Supernovae, Gravitational Waves, Cosmic Microwave Background. Speaker: Adam Riess (Princeton University) Date: February 18, 2007 Time: 4:30pm - 5:15pm Location: Room B",
        "watermark_text": "The observation that the universe is evolving at an accelerating rate has led to intense interest in dark energy as well as fresh concepts about basic physics . This discussion will review some latest findings on these topics including constraints on estimates for cosmic acceleration using supernovae information , measurements of the Hubble constant with Type Ia supernovae , and experiments of general relativity employing gravitational lensing statistics .The speech will also discuss how potential experiments such as LSST can be used to further our knowing of deep energy and fundamental theory . I will conclude by reviewing my own research on proving gravity fields beyond Einstein s principle involving weak lensing observations .Keywords : Cosmology , Dark Energy , General Relativity , Weak Lensing , Supernovae , Gravitational Waves , Cosmic Microwave Background . Speaker : Adam Riess ( Princeton University ) Date : February 18 , 2007 Time : 4 : 30pm - 5 : 15pm Location : Room B",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 5.337745350213779
    },
    {
        "original_text": "We study the quantum Hall effect (QHE) and its interplay with magnetism in monolayer graphene by using an effective low-energy model that takes into account both electron-electron interactions and disorder effects. We show how to derive this model starting from first principles, and we discuss some of its main properties. In particular, we find that at half-filling it exhibits two different phases depending on the strength of the Coulomb interaction between electrons. For weak coupling these are separated by a phase transition driven by spontaneous breaking of time-reversal symmetry; for strong coupling they correspond respectively to a conventional QHE state and to a novel fractionalized topological insulator characterized by chiral edge states. The latter is shown to be equivalent to a spin-1/2 Heisenberg antiferromagnet on the honeycomb lattice, which can thus be described within the framework of the so-called SU(4) bosonic representation.",
        "watermark_text": "We research the quantum Hall impact ( QHE ) and its interplay with magnetism in monolayer graphene by using an efficient low - energy theory that takes into consideration both electron - atom relationships and disturbance effects . We see how to derive this description starting from initial principles , and we explain some of its primary characteristics .In particular , we find that at half - filling it displays two different stages depending on the strength of the Coulomb interaction between electrons . For weak bonding these are distinct by a phase shift motivated by premature breaking of time - reversal symmetry ; for strong coupling they relate respectively to a traditional QHE state and to a novel fractionalized topological insulator characterized by chiral edge states .The latter is demonstrated to be analogous to a spin - 1 / 2 Heisenberg antiferromagnet on the honeycomb structure , which can thus be described within the framework of the so - called SU ( 4 ) bosonic representation .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.5
    },
    {
        "original_text": "We report the discovery of an extremely bright and hot (T eff = 300,000 K) blue supergiant in the open cluster NGC 6231 with a mass loss rate of 10^-6 M_sun/yr. The object is located at a distance of 1 kpc from Earth and has a luminosity of 5 x 10^{5} L_Sun. It shows strong emission lines of He II 4686 Å, N III 4641 Å, C IV 5801 Å, O V 7322 Å, and H Balmer series. We suggest that this object may be a member of the Cygnus OB2 association which contains several other high-mass stars. This would make it one of the most luminous known single stars outside our Galaxy. If confirmed by further observations, this object will provide important constraints on stellar evolution models for massive stars. Keywords: Open clusters; Blue supergiants",
        "watermark_text": "We report the discovery of an incredibly bright and hot ( T eff = 300 , 000 K ) blue supergiant in the open cluster NGC 6231 with a mass loss rate of 10 ^ - 6 M _ sun / yr . The object is situated at a distance of 1 kpc from Earth and has a luminosity of 5 x 10 ^ { 5 } L _ Sun .It displays large emission lines of He II 4686 Å , N III 4641 Å , C IV 5801 Å , O V 7322 Å , and H Balmer series . We suggest that this body may be a member of the Cygnus OB2 association which contains multiple other high - weight stars .This might making it one of the most luminous known single lights outside our Galaxy . If confirmed by further observations , this body will provide important restrictions on stellar evolution models for huge stars .Keywords : Open clusters ; Blue supergiants",
        "ori-fast-z-score": 0.14285714285714285,
        "water-fast-z-score": 3.857142857142857
    },
    {
        "original_text": "We consider the problem of finding an approximate solution to a convex optimization problem with a nonconvex objective function and linear constraints, where the feasible region is defined by a set of equality or inequality constraints.  We show that under certain conditions this problem can be solved efficiently using a combination of gradient descent methods for solving the subproblems in each iteration and a line search method based on the Armijo-Goldstein condition.  The proposed algorithm has been implemented as part of the open source software package CVXPY (http://cvxpy.org/).  Numerical experiments are presented which demonstrate the effectiveness of our approach. Keywords: Convex Optimization, Nonconvex Objective Function, Saddle Point Problem, Gradient Descent Method, Line Search Algorithm, Armijo-Goldstain Condition. 1 Introduction In many practical applications it may not always be possible to find an exact solution to a given mathematical model due to computational complexity issues associated with the underlying numerical algorithms used to solve such models.  For example, in some cases it might only be possible to obtain an approximate solution within a specified tolerance level.  This situation arises frequently when dealing with large-scale nonlinear programming problems arising in various fields including engineering design, operations research, economics, etc., see e.g.,  1  ,  4  .",
        "watermark_text": "We consider the question of finding an approximate solve to a convex optimization problem with a nonconvex objective function and linear constraints , where the viable region is given by a setting of equality or inequality constraints . We see that under certain conditions this question can be answered easily using a combination of gradient descent methods for solving the subproblems in each iteration and a line search method using on the Armijo - Goldstein requirement .The proposed algorithm has been deployed as part of the open source software suite CVXPY ( http : / / cvxpy . org / ) . Numerical trials are presented which demonstrate the ability of our approach .Keywords : Convex Optimization , Nonconvex Objective Function , Saddle Point Problem , Gradient Descent Method , Line Search Algorithm , Armijo - Goldstain Condition . 1 Introduction In many practical applications it must not always be possible to find an precise answer to a given numerical model owing to computational difficulty issues associated with the fundamental numerical algorithms used to solve such models .For instance , in some cases it could only be possible to obtain an approximate solve within a specified tolerance range . This problem arises often when dealing with large - scale nonlinear programming difficulties arising in different fields spanning technical design , operations research , economics , etc . , see e . g . , 1 , 4 .",
        "ori-fast-z-score": 0.5883484054145521,
        "water-fast-z-score": 6.995837874966481
    },
    {
        "original_text": "We present VLT/VIMOS integral field spectroscopic observations for three high-z (z ~ 2.5) radio galaxies, which are known to be surrounded by extended Lyman alpha halos. The main goal is to study their kinematics and physical conditions in order to understand how these objects evolve into massive elliptical galaxies at low redshifts. We find that all three sources show complex velocity fields dominated by rotation around an axis perpendicular to the radio jets. In addition we detect several components showing blueshifted velocities up to -500 km/s relative to systemic redshift. These features may represent outflows driven by AGN feedback or galactic winds powered by star formation activity. Finally, we measure the gas density distribution using  OII  emission lines and estimate the mass of ionized hydrogen surrounding each galaxy. Our results suggest that the observed Lyman alpha halos have masses ranging between 10^10 M_sol and 10^11 M_sol .",
        "watermark_text": "We present VLT / VIMOS integral field spectroscopic observations for three high - z ( z ~ 2 . 5 ) radio objects , which are known to be accompanied by extended Lyman alpha halos . The main goal is to study their kinematics and physical conditions in order to explain how these objects evolve into huge elliptical galaxies at low redshifts .We see that all three sources show complex momentum fields dominated by rotation around an axis diagonal to the radio jets . In addition we find various components showing blueshifted velocities up to - 500 cm / s relative to systemic redshift .These features could indicate outflows driven by AGN feedback or galactic winds driven by galaxy formation activity . Finally , we measure the gas density flow use OII emission lines and estimate the mass of ionized gas covering each galaxy .Our results propose that the known Lyman alpha halos have masses ranging between 10 ^ 10 M _ sol and 10 ^ 11 M _ sol .",
        "ori-fast-z-score": 0.6974858324629157,
        "water-fast-z-score": 5.500933918218137
    },
    {
        "original_text": "We report on two new brown dwarf candidates discovered by direct imaging with NACO/VLT at distances of ~100 AU to their host star, which are members of open clusters NGC 2423 (M67) and NGC 4349. The first object is located close to the cluster center and has an estimated mass between 0.03-0.07 M . It was found as part of our survey for low-mass companions to nearby young solar-type stars. We also present follow-up observations of this candidate using adaptive optics techniques that confirm its substellar nature. \n \n The second object lies outside the core radius of the cluster and has an estimated mass below 0.01 M . This companion may be either a planetary or very-low-mass stellar companion depending on whether it formed through gravitational instability or fragmentation during cloud collapse. Both objects have masses well above those predicted by current models of planet formation via disk accretion.",
        "watermark_text": "We report on two new brown dwarf candidates discovered by direct observation with NACO / VLT at distances of ~ 100 AU to their host star , which are members of close complexes NGC 2423 ( M67 ) and NGC 4349 . The first object is situated close to the cluster center and has an estimated mass between 0 . 03 - 0 . 07 M .It was obtained as part of our survey for low - weight companions to nearby young solar - class stars . We additionally post follow - up observations of this candidate using adaptive optics techniques that prove its substellar nature .The second object lies outside the core radius of the cluster and has an estimated mass below 0 . 01 M . This companion might be either a planetary or very - low - weight stellar companion depending on whether it created through gravity instability or fragmentation during cloud collapse .Both bodies have masses well above those predicted by current theories of planet development via disk accretion .",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 4.330522446256832
    },
    {
        "original_text": "We report on an observation made with Suzaku satellite to study X-ray variability of active galactic nucleus (AGN) NGC 3783, which is known as one of brightest Seyfert 1 galaxies at soft X-rays. We found that the fluxes of both the iron Kα line and the continuum are modulated by a factor of about two over a period of 100 ks. The phase lag between these two components was estimated to be ~0.1 s using cross-correlation analysis. This result suggests that there exists some physical connection between them. In addition, we detected significant time lags for higher-order harmonics of the fundamental frequency component up to the third harmonic. These results suggest that the observed variability may originate from reverberation effects caused by variable illumination of the accretion disk around supermassive black hole. Keywords: Reverberation; Time lag; Iron line; AGN",
        "watermark_text": "We report on an observation made with Suzaku spacecraft to study X - ray variability of active galactic nucleus ( AGN ) NGC 3783 , which is known as one of brightest Seyfert 1 clusters at soft X - rays . We determined that the fluxes of both the metal Kα line and the continuum are modulated by a factor of about two over a period of 100 ks .The wave lag between these two parts was calculated to be ~ 0 . 1 s using cross - correlation analysis . This result suggests that there exists some physical link between them .In addition , we identified significant moment lags for greater - order harmonics of the fundamental frequency component up to the third harmonic . These conclusions show that the seen variability may originate from reverberation effects caused by variable illumination of the accretion disk around supermassive black hole .Keywords : Reverberation ; Time lag ; Iron line ; AGN",
        "ori-fast-z-score": 1.6641005886756874,
        "water-fast-z-score": 5.547001962252292
    },
    {
        "original_text": "We present nonsupersymmetric brane configurations in type IIA string theory, which are obtained by wrapping D-branes on supersymmetry-breaking cycles. We also discuss the corresponding configurations in M-theory. In particular we show that these configurations can be described as bound states of intersecting NS5-branes with orientifold 5-planes (or O6-planes). The latter are related to each other via T-duality transformations. Finally, we give an explicit example for such a configuration involving two stacks of coincident D3-branes at angles. This is done using the technique developed recently by Sen. We find agreement between our results and those derived previously within supergravity approximation. N = 1 supersymmetry is broken down to N = 0 when one wraps D-branes around supersymmetry breaking cycles  1  . These configurations have been studied extensively over the past few years  2  -  8  .\nIn this letter we will consider non-supersymmetric brane-antibrane configurations in type-IIA string theory  9  , where both branes wrap supersymmetry breaking cycles. Such configurations were first discussed in  10  . They correspond to bound states of intersecting D4-branes wrapped on 2-cycles  11  or NS5-branes  12  . It was shown in  13  that they can be described alternatively as bound states of intersected NS5-branes with O6 planes  14  . Here we will use the description given in terms of NS5-O6 systems  15  .",
        "watermark_text": "We introduce nonsupersymmetric brane configurations in type IIA string theory , which are derived by wrapping D - branes on supersymmetry - breaking cycles . We also discuss the analogous structures in M - theory .In particular we find that these structures can be described as bound states of intersecting NS5 - branes with orientifold 5 - planes ( or O6 - planes ) . The latter are related to each other via T - duality transformations .Finally , we give an explicit instance for such a configuration involving two stacks of coincident D3 - branes at angles . This is accomplished use the method developed ago by Sen . We get consensus between our findings and those generated previously within supergravity approximation .N = 1 supersymmetry is broken down to N = 0 when one wrapping D - branes around supersymmetry breaking cycles 1 . These arrangements have been studied frequently over the previous few years 2 - 8 .In this letter we will use non - supersymmetric brane - antibrane configurations in type - IIA string theory 9 , where both branes wrap supersymmetry broken cycles . Such configurations were first explored in 10 .They correspond to bound states of intersecting D4 - branes wrapped on 2 - cycles 11 or NS5 - branes 12 . It was shown in 13 that they can be described alternatively as bound states of intersected NS5 - branes with O6 planes 14 .Here we will use the description presented in terms of NS5 - O6 systems 15 .",
        "ori-fast-z-score": 0.6625891564490792,
        "water-fast-z-score": 5.300713251592634
    },
    {
        "original_text": "We study central limit theorems for estimators of parameters in linear regression models where errors are not necessarily normally distributed but have an elliptical distribution, and we allow some explanatory variables to be non-normal. We show that under suitable conditions on the model coefficients, the asymptotic distributions of these estimators can be approximated by those obtained when all the explanatory variables follow a multivariate normal distribution. The results are illustrated through simulation experiments. Keywords: Central Limit Theorem; Elliptical Distributions; Regression Modeling. 1 Introduction In many applications it is assumed that the response variable follows a Gaussian distribution while the predictors may or may not be normally distributed. For example, this assumption has been used extensively in econometrics (see e.g., Greene  2003  ). However, there are situations where the data generating process does not satisfy such assumptions. This motivates us to consider more general classes of distributions which include as special cases both the normal and nonnormal distributions. One class of distributions that includes most common probability density functions encountered in practice is given by the so-called elliptical distributions. These distributions were introduced independently by Kelker  1970  , Hüsler and Reiss  1981  , and Fang et al.  1987  . They are characterized by their dependence structure rather than their marginal densities. A random vector X = (X1, ..., Xd)T ∈ Rd belongs to the family of elliptical distributions if its characteristic function satisfies E exp(itX)  = exp{−V (t)},\nwhere V : R →  0, ∞) is called the characteristic generator. If V ≡ 0 then X is said to belong to the family of spherical distributions. Examples of elliptical distributions include:",
        "watermark_text": "We research central limit theorems for estimators of values in linear regression systems where errors are not necessarily normally distributed but have an elliptical distribution , and we allow some explanatory variables to be non - normal . We see that under suitable conditions on the model coefficients , the asymptotic distributions of these estimators can be approximated by those achieved when all the explanatory variables obey a multivariate normal distribution .The results are shown through simulation studies . Keywords : Central Limit Theorem ; Elliptical Distributions ; Regression Modeling .1 Introduction In many applications it is implied that the response parameter follows a Gaussian distribution while the predictors may or may not be usually spread . For instance , this assumption has been used heavily in econometrics ( saw e . g . , Greene 2003 ) .However , there are circumstances where the information processing process does not satisfy such constraints . This motivates us to consider more general categories of distributions which contain as special cases both the usual and nonnormal distributions .One class of distributions that contains most common probability distribution functions seen in practice is given by the so - called elliptical distributions . These distributions were introduced independently by Kelker 1970 , Hüsler and Reiss 1981 , and Fang et al .1987 . They are characterized by their dependence structure rather than their marginal densities .A random matrix X = ( X1 , . . . , Xd ) T ∈ Rd belongs to the class of elliptical distributions if its characteristic function satisfies E exp ( itX ) = exp { −V ( t ) } , where V : R → 0 , ∞ ) is dubbed the characteristic generator . If V ≡ 0 then X is said to belong to the group of spherical distributions .Examples of elliptical distributions involve :",
        "ori-fast-z-score": -1.165543034828717,
        "water-fast-z-score": 4.930356094132884
    },
    {
        "original_text": "We study the Laplacian spectrum of complex networks, focusing in particular on its relation to the dynamics of random walks on them. We show that for any network with n nodes there are at most 2n eigenvalues different from zero (counting multiplicities). This bound is tight up to a constant factor when applied to trees or complete graphs. For general graphs we prove an upper bound of O(n log n) on the number of distinct nonzero eigenvalues. In addition, we provide lower bounds showing that this estimate cannot be improved by more than a polylogarithmic factor. Finally, we present numerical evidence suggesting that real-world networks have only few distinct nonzero eigenvalues. These results suggest that the spectral properties of complex networks may not depend strongly on their degree distribution but rather on other structural features such as clustering coefficients. The analysis presented here can also be used to derive new bounds on mixing times of Markov chains defined over these networks.",
        "watermark_text": "We research the Laplacian spectrum of complex networks , concentrating in particular on its connection to the dynamics of random runs on them . We see that for any network with n nodes there are at most 2n eigenvalues different from zero ( counting multiplicities ) .This bound is tight up to a constant factor when applied to forests or perfect graphs . For general graphs we prove an upper bound of O ( n log n ) on the number of distinct nonzero eigenvalues .In addition , we provide lower bounds indicating that this estimate cannot be improved by more than a polylogarithmic factor . Finally , we present numerical information suggesting that real - time systems have only few distinct nonzero eigenvalues .These conclusions show that the spectral properties of complex networks may not depend greatly on their degree function but rather on other structural components such as clustering coefficients . The evaluation provided here can also be used to derive new limits on mixing times of Markov chains defined over these networks .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.47213595499958
    },
    {
        "original_text": "We report the observation of dynamic condensation of water vapor on crack tips during slow fracture experiments performed under vacuum conditions (10-6 mbar) and low temperature (77 K). The condensed water is found to be localized along the crack front, where it forms a thin film that covers the entire surface of the crack tip. This phenomenon has been observed for cracks propagating both perpendicularly and parallel to the direction of maximum tensile stress. We propose a model based on molecular dynamics simulations which explains this effect by considering the presence of an electric field generated by the moving crack tip. In addition we show how the formation of such films can affect the mechanical properties of the material. Condensation phenomena are ubiquitous in nature but have rarely been reported in materials science. Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses. These results were obtained using a combination of optical microscopy techniques with environmental scanning electron microscopy (ESEM), Raman spectroscopy and infrared reflection absorption spectroscopy (IRAS).",
        "watermark_text": "We report the observation of dynamic condensation of liquid vapor on break tips during slow fracture studies performed under vacuum environments ( 10 - 6 mbar ) and low heat ( 77 K ) . The condensed water is found to be localized along the crack front , where it creates a thin film that covers the entire surface of the crack tip .This phenomenon has been observed for faults propagating both perpendicularly and parallel to the direction of maximum tensile tension . We suggest a theory based on protein mechanics simulations which explains this effect by assuming the presence of an electric field produced by the moved crack edge .In addition we study how the formation of such films can affect the structural properties of the material . Condensation problems are ubiquitous in nature but have seldom been reported in materials science .Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses . These conclusions were obtained using a combination of optical microscopy methods with environmental scan electron microscopy ( ESEM ) , Raman spectroscopy and infrared reflection detection spectroscopy ( IRAS ) .",
        "ori-fast-z-score": -0.32539568672798425,
        "water-fast-z-score": 5.1759731137650435
    },
    {
        "original_text": "We present the results of an analysis of rise times for a sample of type Ia supernovae (SNeIa) with well-measured light curves and redshifts in order to determine whether there is one mode of SNeIa rise time, as suggested by Phillips et al. (1999), or two modes, as suggested by Riess et al. (1999). We find that our data are consistent with either model at the 2-sigma level; however, we cannot rule out the possibility of only one mode being present. The best-fit values for the parameters describing each distribution differ significantly between these models. If future observations confirm this result, it will have important implications on cosmological studies using SNeIa as distance indicators. In particular, if there really are two populations of SNeIa, then the use of a single value for the stretch parameter may lead to systematic errors in determining distances. \n \n Keywords: Supernova, Light curve",
        "watermark_text": "We present the conclusion of an assessment of rise periods for a sample of type Ia supernovae ( SNeIa ) with good - measured light curves and redshifts in order to find whether there is one mode of SNeIa rise history , as suggested by Phillips et al . ( 1999 ) , or two modes , as suggested by Riess et al .( 1999 ) . We see that our statistics are compatible with either model at the 2 - sigma level ; however , we cannot leave out the suggestion of only one mode being present .The best - fitting values for the variables describing each distribution depend greatly between these models . If future discoveries confirm this result , it will have important implications on cosmological experiments using SNeIa as distance indicators .In particular , if there really are two groups of SNeIa , then the using of a single value for the stretch variable might lead to systematic errors in calculating distances . Keywords : Supernova , Light curve",
        "ori-fast-z-score": -1.116312611302876,
        "water-fast-z-score": 4.83735464897913
    },
    {
        "original_text": "We consider the problem of optimal investment in a financial market when there is no upper bound on the investor s wealth, but his/her utility function exhibits decreasing absolute risk aversion (DARA). We show that under DARA preferences, the value function for this problem can be characterized as the unique solution to a nonlinear partial differential equation (PDE) which we call the Hamilton-Jacobi-Bellman-Isaacs PDE. This characterization allows us to use standard numerical methods such as finite difference or Monte Carlo simulation to compute the value function numerically. In addition, it also enables us to study how the optimal strategy depends on various parameters including the initial endowment, the interest rate, and the volatility of the stock price process. Finally, by using our results, we are able to provide some new insights into the relationship between pricing and hedging derivatives based on utility maximization principles. The main contributions of this work include:",
        "watermark_text": "We consider the question of optimal investment in a financial market when there is no upper bound on the investor s assets , but his / her utility function exhibits decreasing absolute price aversion ( DARA ) . We see that under DARA preferences , the value function for this question can be described as the unique solve to a nonlinear partial differential equation ( PDE ) which we call the Hamilton - Jacobi - Bellman - Isaacs PDE .This definition permits us to use conventional numerical technique such as finite difference or Monte Carlo simulation to compute the value function numerically . In addition , it also enables us to study how the ideal scenario depends on various variables including the early endowment , the interest rate , and the volatility of the stock price cycle .Finally , by using our findings , we are able to provide some fresh insights into the relationship between pricing and hedging derivatives using on utility maximization theories . The main contributions of this research include :",
        "ori-fast-z-score": 1.4142135623730951,
        "water-fast-z-score": 5.969098507002659
    },
    {
        "original_text": "We present deep optical photometry in B, V , R c I c bands for the dwarf irregular galaxy IC 1613 obtained with the Wide Field Imager (WFI) at the MPG/ESO 2.2 m telescope on La Silla Observatory. The data were reduced using standard IRAF routines. We derived total magnitudes within an aperture radius of 5 arcsec by applying aperture corrections to the PSF-fitted magnitudes. Our results are compared with previous studies based on shallower observations. In addition we derive new estimates for the distance modulus DM = 27.9 ± 0.1 mag and foreground extinction A V = 0.10 ± 0.02 mag towards this galaxy. Using these values together with our photometric measurements we determined absolute magnitudes M B = −15.6 ± 0.3 mag, M V = −14.7 ± 0.4 mag, M Rc = −12.8 ± 0.5 mag, M Ic = −11.0 ± 0.6 mag and colour indices U−B = 1.45±0.25 mag, B−V =0.70±0.06 mag, V −Rc=0.55±0.05 mag, V −Ic=1.00±0.07 mag. These parameters allow us to estimate the mean metallicity Z = 0.008 ± 0.001 dex and age t = 3 Gyrs for the stellar population of IC 1613.",
        "watermark_text": "We use deep optical photometry in B , V , R c I c groups for the dwarf irregular galaxy IC 1613 obtained with the Wide Field Imager ( WFI ) at the MPG / ESO 2 . 2 m observatory on La Silla Observatory . The data were reduced use standard IRAF procedures .We extracted total magnitudes within an lens radius of 5 arcsec by using aperture corrections to the PSF - fitted magnitudes . Our results are compared with previous research based on shallower observations .In addition we derive new models for the distance modulus DM = 27 . 9 ± 0 . 1 mag and foreground extinction A V = 0 . 10 ± 0 . 02 mag towards this galaxy . Using these estimates together with our photometric calculations we calculated absolute magnitudes M B = −15 . 6 ± 0 . 3 mag , M V = −14 . 7 ± 0 . 4 mag , M Rc = −12 . 8 ± 0 . 5 mag , M Ic = −11 . 0 ± 0 . 6 mag and colour indices U−B = 1 . 45±0 . 25 mag , B−V = 0 . 70±0 . 06 mag , V −Rc = 0 . 55±0 . 05 mag , V −Ic = 1 . 00±0 . 07 mag .These parameters allow us to estimate the mean metallicity Z = 0 . 008 ± 0 . 001 dex and age t = 3 Gyrs for the stellar population of IC 1613 .",
        "ori-fast-z-score": -0.2626128657194451,
        "water-fast-z-score": 3.5762373640756184
    },
    {
        "original_text": "We propose that the most energetic cosmic rays are accelerated in supernova remnants by relativistic jets powered by hypernova explosions, which may be associated with gamma-ray bursts (GRBs). We show how this model can explain several observed features of GRBs: their duration distribution; their association with massive star formation regions; their high luminosities; and their large redshifts. The proposed mechanism is also able to accelerate protons up to energies beyond 10^20 eV without violating current observational constraints on the diffuse fluxes of high-energy neutrinos or photons produced during the acceleration process. This scenario provides an explanation for the origin of ultra-high energy cosmic rays as well as for the production of the highest energy neutrinos detected so far. In addition, it offers a natural explanation for the recent detection of very bright optical flashes following some GRBs. \n \n High-energy cosmic rays have been measured at Earth over many decades  1  . Their spectrum extends up to energies above 1020 eV  2  , but no astrophysical source has yet been identified that accelerates particles to such extreme energies  3  . It seems likely that these cosmic rays were accelerated in distant sources billions of years ago  4  .\n \nThe most powerful known explosion in our Universe occurs when a massive star collapses into a black hole after exhausting its nuclear fuel supply  5  . Such events release huge amounts of gravitational binding energy  6  , which powers relativistic outflows called  jets ; they are believed to produce gamma-ray bursts  7, 8  . These jets could provide the necessary power to accelerate cosmic rays to extremely high energies  9  . \n \n However, there are two major difficulties in explaining the origin of the most energetic cosmic ray particles using conventional models  10  : \n \n 1) Conventional jet-powered models cannot accelerate protons to energies greater than ~10^19 eV  11  because the maximum Lorentz factor Γmax of the flow decreases rapidly with distance r from the central engine  12  . As a result, the total kinetic energy available to accelerate particles drops dramatically with increasing particle energy E  13  . For example, if we assume that the bulk Lorentz factor of the",
        "watermark_text": "We suggest that the most intense cosmic rays are accelerated in supernova remnants by relativistic jets driven by hypernova bursts , which may be involved with gamma - ray clusters ( GRBs ) . We see how this model can describe several observed features of GRBs : their duration distribution ; their association with massive star formation regions ; their high luminosities ; and their large redshifts .The proposed process is also could to accelerate protons up to energies beyond 10 ^ 20 eV without violating present observational restrictions on the diffuse fluxes of high - energy neutrinos or photons generated during the acceleration cycle . This scenario offers an reason for the origin of ultra - large energy cosmic rays as well as for the production of the highest power neutrinos detected so far .In addition , it gives a natural explanation for the recent discovery of very bright optical bursts following some GRBs . High - energy cosmic rays have been measured at Earth over much centuries 1 .Their range extends up to frequencies above 1020 eV 2 , but no astrophysical source has already been determined that accelerates particles to such extreme energies 3 . It seems likely that these cosmic rays were accelerated in nearby sources billions of years early 4 .The most intense reported blast in our Universe comes when a huge star collapses into a black hole after exhausting its radioactive fuel supply 5 . Such episodes release massive amounts of gravitational binding energy 6 , which powers relativistic outflows called rockets ; they are said to produce gamma - ray waves 7 , 8 .These jets could give the necessary power to accelerate cosmic rays to incredibly high energies 9 . However , there are two major obstacles in understanding the origin of the most intense cosmic ray ions using conventional versions 10 : 1 ) Conventional jet - powered designs cannot accelerate protons to energies higher than ~ 10 ^ 19 eV 11 because the maximum Lorentz factor Γmax of the flow varies dramatically with distance r from the main engine 12 .As a result , the total kinetic power available to accelerate particles decreases dramatically with rising particle power E 13 . For instance , if we suppose that the bulk Lorentz factor of the",
        "ori-fast-z-score": -0.22677868380553634,
        "water-fast-z-score": 8.187458870652156
    },
    {
        "original_text": "We have performed molecular dynamics simulations to investigate the dynamic crack propagation in an icosahedral AlPdMn quasicrystal and its periodic approximant, i-AlCuFe. The results show that both materials exhibit similar features for the crack growth process at low temperatures (T = 300 K). However, there are significant differences between them when T is increased up to 600 K. In particular, we find that the quasicrystal shows a higher resistance against crack propagation than the approximant under tensile loading conditions. This behavior can be explained by considering the different atomic structures of these two systems. \n \n We also studied how the temperature affects the mechanical properties of the quasicrystal. Our results indicate that increasing the temperature leads to a decrease in the elastic constants C11 and C44 as well as in the bulk modulus B. Moreover, our calculations reveal that the Young s moduli E decreases with increasing temperature.",
        "watermark_text": "We have done chemical dynamics simulations to examine the dynamic crack propagation in an icosahedral AlPdMn quasicrystal and its periodic approximant , i - AlCuFe . The results show that both materials exhibit similar features for the crack growth process at low temperatures ( T = 300 K ) .However , there are significant variations between them when T is expanded up to 600 K . In particular , we find that the quasicrystal demonstrates a higher resistance against fracture propagation than the approximant under tensile loading circumstances . This phenomenon can be described by analyzing the different atomic relationships of these two systems .We additionally investigated how the temperature changes the mechanical behavior of the quasicrystal . Our results show that raising the temperature leads to a reduction in the elastic constants C11 and C44 as well as in the bulk modulus B .Moreover , our calculations reveal that the Young s moduli E decreases with expanding temperature .",
        "ori-fast-z-score": 0.5252257314388902,
        "water-fast-z-score": 5.938574464184706
    },
    {
        "original_text": "We present an efficient numerical scheme to detect the existence of periodic orbits in chaotically behaving dynamical systems, such as chaotic maps or chaotic flows. The proposed algorithm is based on the concept of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor. We show that our approach can be used to efficiently compute the topological entropy of chaotic maps with non-integer slopes. Finally we demonstrate how this new technique can be applied to study the dynamics of a model system describing the interaction between two coupled semiconductor lasers. Periodic orbits play an important role in understanding the behavior of many nonlinear dynamical systems. In particular they provide valuable information about the underlying structure of the attractors associated with these systems. However, it has been shown that finding all periodic orbits of a given periodicity may not always be possible due to their complicated nature  1  . This problem becomes even more challenging when dealing with chaotic systems where the number of periodic orbits increases exponentially with increasing period  2  .\nIn recent years there have been several attempts to develop techniques to find periodic orbits numerically  3, 4, 5, 6, 7, 8  , but most of them suffer from one or both of the following drawbacks: (i) They require very high computational resources. (ii) They do not guarantee convergence towards the desired orbit. Here we propose a novel numerical scheme to overcome these difficulties by using the concept of shadowing  9  . Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor. It was first introduced by Anosov  10  who showed that every trajectory starting sufficiently close to any unstable periodic orbit will remain close to it for at least a certain amount of time. Since then various authors  11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44",
        "watermark_text": "We present an efficient numerical system to identify the existence of periodic orbits in chaotically behaving dynamical systems , such as chaotic maps or turbulent flows . The proposed algorithm is based on the idea of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor .We see that our approach can be used to easily compute the topological entropy of turbulent maps with non - integer peaks . Finally we prove how this new technique can be applied to study the dynamics of a prototype system describing the interaction between two coupled semiconductor lasers .Periodic orbits take an important role in understanding the dynamics of several nonlinear dynamical systems . In particular they give valuable info about the fundamental structure of the attractors associated with these systems .However , it has been shown that finding all periodic orbits of a given periodicity might not always be possible due to their complicated nature 1 . This problem arises even more challenging when dealing with turbulent systems where the number of periodic orbits changes exponentially with expanding period 2 .In past decades there have been numerous attempts to develop techniques to find periodic orbits numerically 3 , 4 , 5 , 6 , 7 , 8 , but most of them suffer from one or both of the following drawbacks : ( i ) They require very high computational resources . ( ii ) They do not guarantee convergence towards the desired orbit .Here we develop a new numerical system to overcome these problems by using the idea of shadowing 9 . Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor .It was first developed by Anosov 10 who demonstrated that every orbital beginning sufficiently next to any weak periodic orbit will remain close to it for at least a certain quantity of time . Since then various authors 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44",
        "ori-fast-z-score": -0.43033148291193524,
        "water-fast-z-score": 6.688444820557844
    },
    {
        "original_text": "We report on the fabrication and characterization of electro-optically tunable microresonator devices based on proton exchange (PE) grown lithium niobate-on-insulator substrates. The PE process is used to create an optical waveguide with low loss, high index contrast, and large nonlinearity within the substrate material. A ring-resonator geometry is then defined by electron-beam lithography followed by reactive ion etching. Finally, Ti/Au electrodes are deposited onto both sides of the device for electrical tuning. We demonstrate continuous wavelength tuning over more than 30 nm at 1555 nm using only 1 V reverse bias applied across the device. This work represents one step towards realizing electrically-tuned integrated photonic circuits that can be monolithically fabricated on insulators. Lithium niobate has been widely studied as a promising candidate for optoelectronics applications due to its excellent properties such as wide transparency range, large second-order susceptibility, and relatively low propagation losses  1  . In addition, it also exhibits strong piezoelectric and pyroelectric effects which make it possible to achieve efficient electro-optic modulation  2  .\nIn this letter we present our recent results on the development of electro-optically tuned microring resonators made out of lithium niobate. These devices were designed and fabricated on commercially available lithium niobate wafers bonded to silicon dioxide  3  , where the top cladding layer was removed prior to processing. First, a proton-exchange (PE) process  4  was performed to grow a single-mode ridge-waveguide structure inside the bulk LiNbO 3 crystal  5  . Then, a ring-resonator geometry was patterned into the PE-grown region via electron beam lithography  6  . Finally, titanium/gold (Ti/Au) contacts were evaporated onto both sides of the sample to provide electrical access to the device  7, 8  . Figure 1 shows scanning-electron-microscope images of two different types of microring resonators that have been successfully demonstrated so far. Both devices consist of",
        "watermark_text": "We report on the fabrication and identification of electro - optically tunable microresonator devices using on proton exchange ( PE ) grown lithium niobate - on - insulator substrates . The PE method is utilized to create an optical waveguide with little loss , low index contrast , and large nonlinearity within the substrate material .A ring - resonator configuration is then established by electron - laser lithography preceded by reactive ion etching . Finally , Ti / Au electrodes are deposited onto both sides of the device for electrical tuning .We demonstrate constant wavelength tuning over more than 30 nm at 1555 nm using only 1 V reverse bias applied across the device . This research provides one step towards developing electrically - tuned integrated photonic devices that can be monolithically manufactured on insulators .Lithium niobate has been widely explored as a desirable candidate for optoelectronics applications due to its exceptional properties such as wide clarity range , large second - order susceptibility , and fairly little propagation losses 1 . In addition , it also exhibits strong piezoelectric and pyroelectric influences which make it able to achieve effective electro - optic modulation 2 .In this letter we present our latest findings on the development of electro - optically modified microring resonators made out of lithium niobate . These systems were built and manufactured on commercially used lithium niobate wafers bonded to silicon dioxide 3 , where the bottom cladding surface was eliminated prior to processing .First , a proton - transfer ( PE ) process 4 was done to expand a single - mode ridge - waveguide structure inside the bulk LiNbO 3 crystal 5 . Then , a ring - resonator configuration was patterned into the PE - grown region via electron beam lithography 6 .Finally , titanium / gold ( Ti / Au ) contacts were evaporated onto both sides of the sample to provide electrical access to the device 7 , 8 . Figure 1 shows scan - electron - microscope photographs of two different kinds of microring resonators that have been successfully shown so far .Both devices consist of",
        "ori-fast-z-score": 1.0215078369104984,
        "water-fast-z-score": 8.172062695283987
    },
    {
        "original_text": "We present an approach to calculate the effective material properties of thin layered structures, which are composed by two or more different materials with periodic microstructure. The method is based on homogenization theory combined with finite element analysis (FEA) in order to account for local interactions between neighboring unit cells. We consider three types of unit cell geometries that can be used to model various composite materials such as: wire grid composites, fiber reinforced polymeric matrix composites, and metal foams. In particular we focus our attention on wire grid composites made up of periodically arranged parallel wires embedded into a homogeneous medium. For this type of structure it has been shown experimentally that the macroscopic elastic moduli depend strongly on the volume fraction occupied by the wires. However, these experimental results cannot be explained using classical homogenization theories because they do not take into account the interaction effects among adjacent wires. Therefore, we propose here a new theoretical framework to study the mechanical behavior of wire grid composites at both micro-and meso-scales.",
        "watermark_text": "We present an methods to estimate the effective material properties of thin layered systems , which are composed by two or more separate materials with periodic microstructure . The method is based on homogenization theory combined with finite element assessment ( FEA ) in order to account for local interactions between neighboring unit cells .We consider three categories of unit cell geometries that can be used to model numerous composite materials such as : wire grid composites , fiber strengthened polymeric matrix composites , and steel foams . In particular we focus our focus on wire grid composites made up of regularly arranged connected links embedded into a homogeneous medium .For this form of geometry it has been shown experimentally that the macroscopic elastic moduli rely highly on the density amount filled by the wires . However , these theoretical results cannot be described using traditional homogenization techniques because they do not take into consideration the interaction effects among adjoining strands .Therefore , we propose here a new theoretical framework to study the structural response of wire network composites at both micro - and meso - scales .",
        "ori-fast-z-score": -0.42640143271122083,
        "water-fast-z-score": 5.617988764033708
    },
    {
        "original_text": "We study the controllability properties of quantum subsystems that are described by a master equation with Lindblad form. We show how to construct invariant sets for such systems in terms of their generators. These results allow us to prove that certain classes of open quantum systems cannot be controlled using only unitary operations on the system s Hilbert space. Finally we present an algorithm which allows one to determine whether or not a given set is invariant under the dynamics generated by a particular generator. This work was supported by NSF grant PHY-0456628. Quantum mechanics has been successfully applied to many physical phenomena ranging from atomic physics to condensed matter theory. However, it remains unclear what exactly constitutes a quantum mechanical description of reality. One approach towards answering this question involves studying the behavior of closed quantum systems whose states evolve according to Schrödinger equations. Another approach focuses on describing the evolution of open quantum systems where the state of the system interacts continuously with its environment. The latter class of problems can often be formulated as questions about the controllability of quantum dynamical systems. For example, consider the problem of steering the state of a two-level atom between different energy levels using laser pulses.",
        "watermark_text": "We research the controllability properties of quantum subsystems that are explained by a master equation with Lindblad form . We see how to build invariant pairs for such systems in terms of their generators .These results allow us to prove that particular categories of open quantum systems cannot be governed using only unitary operations on the scheme s Hilbert space . Finally we present an algorithm which allows one to find whether or not a given set is invariant under the dynamics generated by a certain generator .This research was supported by NSF grant PHY - 0456628 . Quantum theory has been successfully application to many natural objects including from atomic physics to condensed matter theory .However , it remains unsure what actually constitutes a quantum mechanical explanation of reality . One approach towards answering this question involves studying the dynamics of closed quantum systems whose states evolve according to Schrödinger equations .Another approach focuses on explaining the evolution of open quantum systems where the state of the state interacts continuously with its surroundings . The latter group of problems can often be understood as challenges about the controllability of quantum dynamical systems .For instance , consider the question of steering the state of a two - level atom between various energy levels use laser pulses .",
        "ori-fast-z-score": 1.1547005383792515,
        "water-fast-z-score": 6.543303050815759
    },
    {
        "original_text": "We present the first panoramic view of the distribution of galaxies around two massive clusters at redshifts z = 0.4-0.6, using deep near-infrared imaging with WFC3 on HST. The data reveal an extended population of faint galaxies surrounding each cluster that is not seen in optical images. We find that these galaxies are predominantly blue (with median color u − g = -0.5), have low stellar masses (10^9 Msun/pc^2) and high specific star formation rates (sSFR ~ 10^-2 Gyr-1). These properties suggest they represent a recently assembled population of star-forming dwarf galaxies that were accreted by their host clusters during recent mergers. In addition to this diffuse component we also identify several dozen bright galaxies within 1 Mpc of both clusters which appear to be undergoing rapid bursts of star formation triggered by interactions between infalling gas-rich galaxies and the hot intracluster medium.",
        "watermark_text": "We present the first panoramic study of the distribution of clusters around two huge clusters at redshifts z = 0 . 4 - 0 . 6 , using deep near - infrared imaging with WFC3 on HST . The data reveal an extended population of faint clusters surrounding each cluster that is not seen in infrared images .We see that these objects are exclusively blue ( with median color u − g = - 0 . 5 ) , have poor stellar masses ( 10 ^ 9 Msun / pc ^ 2 ) and large particular galaxy formation rates ( sSFR ~ 10 ^ - 2 Gyr - 1 ) . These properties suggest they represent a recently assembled colony of star - creating dwarf stars that were accreted by their host clusters during earlier mergers .In addition to this diffuse component we also identify several several bright stars within 1 Mpc of both clusters which appear to be experiencing rapid bursts of galaxy formation followed by interactions between infalling gas - rich galaxies and the hotter intracluster medium .",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 5.032769329433615
    },
    {
        "original_text": "We present new photometric and spectroscopic observations of the classical nova EX Hya made in October 2005, when it was still bright (V = 8 mag). The light curve shows that EX Hya is an intermediate polar with a period of P orb = 0.084 d. We find evidence for two accretion regions on the white dwarf surface which are responsible for the double-peaked emission lines observed during outburst. In addition to these features we also detect narrow absorption components at velocities up to -1500 km s-1 . These absorptions may be caused by material ejected during previous eruptions. Our results show that EX Hya has returned to quiescence after its latest eruption in September 2002. Classical novae have been known since antiquity but their underlying physics remains poorly understood. They are believed to result from thermonuclear runaways triggered by unstable nuclear burning on the surfaces of white dwarfs (WD) in close binary systems. However, there remain many open questions about how this process takes place and what happens afterwards. One such question concerns the nature of the WD magnetic field. It is generally accepted that the WD magnetic field plays a key role in determining whether or not a system will undergo a thermonuclear runaway. If the WD magnetic field is too weak then no runaway occurs; if it is strong enough then the WD can become fully convective leading to stable hydrogen burning and hence preventing any further outburst activity. This picture is complicated however by the fact that some WDs do exhibit periodic outbursts despite having fields thought to be too weak to prevent them becoming fully convective. Such objects are called Intermediate Polars (IPs), where the WD magnetic field is sufficiently strong to synchronise the spin periods of both stars but does not disrupt the flow of matter onto the WD.",
        "watermark_text": "We present new photometric and spectroscopic observations of the classical nova EX Hya made in October 2005 , when it was still bright ( V = 8 mag ) . The light curve shows that EX Hya is an intermediate polar with a period of P orb = 0 . 084 d . We see evidence for two accretion zones on the white dwarf surface which are responsible for the double - peaked emission lines observed during outburst .In addition to these characteristics we also observe narrow absorbed components at velocities up to - 1500 km s - 1 . These absorptions might be caused by material expelled during earlier eruptions .Our results show that EX Hya has returned to quiescence after its latest eruption in September 2002 . Classical novae have been known since ancient but their underlying dynamics appears poorly explored .They are said to arise from thermonuclear runaways caused by volatile nuclear burning on the surfaces of white dwarfs ( WD ) in close binary systems . However , there remain many open questions about how this process comes place and what comes afterwards .One such issue concerns the nature of the WD magnetic force . It is usually agreed that the WD magnetic force plays a key importance in determining whether or not a system will undergo a thermonuclear runaway .If the WD magnetic force is too weak then no runaway occurs ; if it is strong enough then the WD can turn fully convective causing to good hydrogen burning and hence stopping any further outburst activity . This picture is complicated however by the fact that some WDs do exhibit periodic outbursts despite having fields thought to be too weak to prohibit them becoming fully convective .Such elements are called Intermediate Polars ( IPs ) , where the WD magnetic force is sufficiently strong to synchronise the spin times of both stars but does not disrupt the transfer of matter onto the WD .",
        "ori-fast-z-score": -1.247219128924647,
        "water-fast-z-score": 6.057921483348286
    },
    {
        "original_text": "We present 8.4 GHz Very Long Baseline Interferometry (VLBI) images and light curves for the supernova remnant (SNR) associated with the Type IIb supernova SN2004et, which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1. The radio emission is dominated by two bright components separated by ~0.5 arcsec at all epochs observed between 2005 January and 2007 December. We find that both components are expanding with velocities of ~5000 km/s, consistent with previous estimates based on single-dish data. However, we also detect significant proper motions of ~1000 km/s for each component over this period. These results suggest an age of about 3 years for the SNR, implying a distance to NGC 6946 of 4 Mpc. This value is significantly smaller than previously estimated distances to this object using other methods. Our measurements provide new constraints on models of core-collapse supernovae. \n \n Keywords: Supernova remnants",
        "watermark_text": "We create 8 . 4 GHz Very Long Baseline Interferometry ( VLBI ) images and light angles for the supernova remnant ( SNR ) associated with the Type IIb supernova SN2004et , which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1 . The radio emission is dominated by two bright components differentiated by ~ 0 . 5 arcsec at all epochs observed between 2005 January and 2007 December .We see that both components are growing with velocities of ~ 5000 kilometres / s , consistent with previous estimates based on single - dish data . However , we also observe significant normal motions of ~ 1000 kilometers / s for each component over this time .These data suggest an age of about 3 years for the SNR , suggests a proximity to NGC 6946 of 4 Mpc . This value is significantly less than previously estimated distances to this body using other methods .Our measurements give novel constraints on estimates of core - collapse supernovae . Keywords : Supernova remnants",
        "ori-fast-z-score": -0.6509445549041194,
        "water-fast-z-score": 4.727031582950012
    },
    {
        "original_text": "We study the generalized Dicke model with an arbitrary number N of two-level atoms interacting with one-mode radiation field, and show that it can be mapped to a spin-1/2 system by using the Holstein-Primakoff transformation. We then use the exact diagonalization method to calculate its ground state energy spectrum for different values of the coupling constant g and the number N . The results are compared with those obtained by other methods such as perturbation theory and numerical integration. It is found that our results agree well with previous ones when the coupling strength is small but deviate significantly from them if the coupling becomes strong. Finally we discuss some possible applications of this work. PACS: 03.65.Ud, 05.45.Mt, 11.10.Gh, 12.20.Dc, 13.25.Gv \nI. INTRODUCTIO N\nThe Dicke model  1  describes how many identical two-level atoms interact collectively with a single mode of electromagnetic field. In recent years there has been renewed interest in studying this model because of its potential application in quantum information processing  2  , quantum optics  3  , condensed matter physics  4  , etc.. For example, the collective spontaneous emission rate of the atomic ensemble depends on the total angular momentum J = N /2 (N being the number of atoms)  5  .\nIn fact, the Dicke model was originally proposed more than half century ago  6  . Since then various theoretical approaches have been developed to solve it  7 -10  . Among these approaches, the most successful one is probably the so-called HolsteinPrimakoff transformation  11  which maps the original problem into a spin-1/2 system  12  . This approach works very well at weak-coupling regime where the interaction between atom-field is relatively small. However, it fails completely at large-coupling limit since the mapping procedure breaks down due to the appearance of unphysical states  13  . Recently, several authors  14 -19  have tried to overcome this difficulty by introducing new transformations or approximations. Nevertheless, their solutions still suffer from certain drawbacks  20, 21  .",
        "watermark_text": "We explore the generalized Dicke model with an arbitrary number N of two - level atoms interacting with one - mode radiation field , and find that it can be mapped to a spin - 1 / 2 system by using the Holstein - Primakoff transformation . We then use the exact diagonalization technique to estimate its ground state energy spectrum for different values of the interaction factor g and the number N .The results are compared with those achieved by other methods such as perturbation theory and numerical integration . It is found that our findings agree well with previous ones when the interaction strength is tiny but deviate drastically from them if the interaction becomes strong .Finally we explain some possible use of this study . PACS : 03 . 65 . Ud , 05 . 45 . Mt , 11 . 10 . Gh , 12 . 20 . Dc , 13 . 25 . Gv I . INTRODUCTIO N The Dicke model 1 explains how many identical two - level atoms behave collectively with a single mode of electromagnetic field .In recent years there has been continued interest in investigating this model because of its potential application in quantum information processing 2 , quantum optics 3 , condensed matter science 4 , etc . . For instance , the collective spontaneous emission speed of the atomic ensemble depends on the total angular velocity J = N / 2 ( N being the number of atoms ) 5 . In reality , the Dicke concept was originally proposed more than quarter century ago 6 .Since then various theoretical methods have been constructed to solve it 7 - 10 . Among these method , the most popular one is probably the so - called HolsteinPrimakoff transformation 11 which maps the original problem into a spin - 1 / 2 system 12 .This method works very best at weak - interaction regime where the interaction between electron - field is fairly little . However , it fails totally at large - interaction range since the mapping method splits down due to the appearance of unphysical states 13 .Recently , various literature 14 - 19 have tried to overcome this challenge by using new transformations or approximations . Nevertheless , their solutions still suffer from certain drawbacks 20 , 21 .",
        "ori-fast-z-score": -0.16222142113076254,
        "water-fast-z-score": 6.8132996874920275
    },
    {
        "original_text": "We present an overview of our recent work on Bayesian methods for reconstructing the large scale structures in the universe using galaxy redshift surveys. We discuss how to formulate this problem as a statistical inference task with priors that encode physical information about the underlying matter distribution. The posterior probability density function is then evaluated by applying Bayes  theorem together with Markov Chain Monte Carlo (MCMC) sampling techniques. In particular we focus on two different approaches which are based either on Gibbs sampling or Metropolis-Hastings algorithm. Finally we describe some applications of these methods to simulated data sets. This research was supported by NSF grant AST-0707763. Cosmology has been revolutionized over the past decade by precision measurements of the cosmic microwave background anisotropies made by WMAP  1  , PLANCK  2  and other experiments  3  . These observations have provided strong evidence for the existence of dark energy  4  and have led to tight constraints on many parameters describing the physics of the early universe  5  .\nHowever, despite their successes there remain several open questions regarding fundamental aspects of the standard model of cosmology  6  . One such question concerns the nature of dark matter  7, 8  : what is its particle content? What is its mass? How does it interact with ordinary matter?\nAnswering these questions requires detailed knowledge of the spatial distribution of dark matter throughout space and time  9  . Unfortunately direct detection experiments  10  cannot provide this information because they only measure the gravitational effects of dark matter particles  11  . Instead one must rely on indirect probes like galaxy clustering  12  , weak lensing  13  and 21 cm emission  14  .",
        "watermark_text": "We present an overview of our latest work on Bayesian methods for reconstructing the huge scale structures in the universe using galaxy redshift surveys . We discuss how to formulate this question as a statistical inference job with priors that encode physical information about the underlying matter distribution .The posterior likelihood density function is then evaluated by using Bayes relation together with Markov Chain Monte Carlo ( MCMC ) filtering approaches . In particular we focus on two different methods which are based either on Gibbs filtering or Metropolis - Hastings algorithm .Finally we explain some applications of these systems to modeled information sets . This research was supported by NSF grant AST - 0707763 .Cosmology has been revolutionized over the previous decade by precision observations of the cosmic microwave background anisotropies made by WMAP 1 , PLANCK 2 and other experiments 3 . These measurements have provided strong evidence for the existence of deep energy 4 and have led to strict constraints on numerous variables describing the physics of the early world 5 .However , despite their successes there remain many open questions regarding essential aspects of the standard theory of cosmology 6 . One such problem concerns the nature of deep material 7 , 8 : what is its particle content ?What is its weight ? How does it behave with normal matter ?Answering these problems demands clear information of the spatial distribution of dark matter throughout space and time 9 . Unfortunately direct detection experiments 10 cannot offer this data because they only measure the gravitational impacts of dark matter grains 11 .Instead one must rely on indirect probes like galaxy clustering 12 , soft lensing 13 and 21 cm emission 14 .",
        "ori-fast-z-score": 0.9838699100999074,
        "water-fast-z-score": 8.131727983645296
    },
    {
        "original_text": "We present new observations and analysis of the neutral hydrogen (HI) disks surrounding isolated galaxies, using data obtained with the Very Large Array (VLA). We have observed 12 nearby galaxies at 21 cm wavelength to determine their total HI mass and distribution within the optical disk. The sample includes both late-type spirals and dwarf irregulars. Our results show that all but one galaxy has an extended HI halo beyond its optical radius; this is true even for the most gas-rich systems such as NGC 4254 and NGC 5253. In addition, we find evidence for significant amounts of atomic gas outside our detection limits which may be associated with tidal features or other interactions between these galaxies and neighboring companions. These findings are consistent with previous studies showing that many isolated spiral galaxies contain large quantities of cold interstellar medium distributed over several kiloparsecs. \n \n Keywords: Atomic Hydrogen, Galaxy Evolution, Spiral Structure",
        "watermark_text": "We report new studies and investigation of the neutral hydrogen ( HI ) disks comprising isolated stars , using data acquired with the Very Large Array ( VLA ) . We have noted 12 nearby galaxies at 21 cm wavelength to obtain their total HI mass and distribution within the optical disk .The sample comprises both late - class spirals and dwarf irregulars . Our results show that all but one star has an extended HI halo beyond its optical diameter ; this is true even for the most gas - rich complexes such as NGC 4254 and NGC 5253 .In addition , we find proof for significant amounts of atomic liquid outside our detection limits which may be correlated with tidal features or other relationships between these objects and surrounding companions . These conclusions are compatible with previous research indicating that several isolated spiral clusters hold significant amounts of cold interstellar medium spread over several kiloparsecs .Keywords: Atomic Hydrogen, Galaxy Evolution, Spiral Structure",
        "ori-fast-z-score": -0.5852057359806528,
        "water-fast-z-score": 5.969098507002659
    },
    {
        "original_text": "We present photometry for stars in an intermediate-age open cluster, BS90 (Sharpless 1959), located at the center of the star-forming region NGC346 in the Small Magellan Cloud (SMC). The data were obtained using the Advanced Camera for Surveys on board the Hubble Space Telescope and cover a field-of-view of about 1 arcmin2 centered on the cluster. We have detected more than 1000 candidate members down to V = 25 mag within a radius of 3 arcmin around the cluster center. Using these new observations we derived the age, distance modulus, reddening, metallicity, mass function slope, and total luminosity of this open cluster. Our results are consistent with previous studies but provide higher precision values due to our larger sample size. \n \n Keywords: Open clusters; SMC; HST/ACS; photometry; star formation history; intermediate-age",
        "watermark_text": "We present photometry for stars in an intermediate - age open cluster , BS90 ( Sharpless 1959 ) , located at the center of the star - making area NGC346 in the Small Magellan Cloud ( SMC ) . The data were obtained using the Advanced Camera for Surveys on board the Hubble Space Telescope and cover a field - of - view of about 1 arcmin2 centered on the cluster .We have discovered more than 1000 candidate members down to V = 25 mag within a diameter of 3 arcmin around the cluster center . Using these new images we derived the age , distance modulus , reddening , metallicity , mass function slope , and overall luminosity of this open cluster .Our results are compatible with previous findings but give larger precision values due to our larger specimen size . Keywords : Open clusters ; SMC ; HST / ACS ; photometry ; star formation history ; intermediate - age",
        "ori-fast-z-score": -0.13483997249264842,
        "water-fast-z-score": 2.449489742783178
    },
    {
        "original_text": "We present the results of our analysis on the supersymmetric parameter space, taking into account all available experimental data including those from LHC experiments as well as electroweak precision observables (EWPO). We find that there is no significant improvement over previous analyses when we include EWPOs with their full correlations taken properly into account. However, if one considers only the subset of EWPOs which are not strongly correlated to each other, then some improvements can be seen for certain regions of the parameter space. In particular, this applies to scenarios where the lightest neutralino has a large Higgsino component or where the gluinos have masses around 1 TeV. The latter case also leads to an improved agreement between theory predictions and measurements of the anomalous magnetic moment of the muon. Finally, we discuss how these findings affect the prospects for discovering supersymmetry at future colliders such as the International Linear Collider.",
        "watermark_text": "We report the results of our analysis on the supersymmetric parameter room , using into consideration all available observation information including those from LHC experiments as well as electroweak accuracy observables ( EWPO ) . We see that there is no considerable progress over past analyses when we incorporate EWPOs with their full correlations took correctly into consideration .However , if one looks only the subset of EWPOs which are not closely correlated to each other , then some improvements can be shown for particular regions of the parameter space . In particular , this applicable to scenarios where the lightest neutralino has a large Higgsino component or where the gluinos have masses around 1 TeV .The last example also leads to an better agreement between theoretical estimates and measurements of the anomalous magnetic motion of the muon . Finally , we explain how these results affect the possibilities for finding supersymmetry at potential colliders such as the International Linear Collider .",
        "ori-fast-z-score": -3.6765801200722312,
        "water-fast-z-score": 5.077367528252131
    },
    {
        "original_text": "El año que cambió la historia del Universo (2005) es un documental sobre el descubrimiento por parte de Albert Einstein, en 1915, de las ecuaciones básicas de su teoría general relativista y los acontecimientos que tuvieron lugar durante ese mismo año. El film se centra especialmente en dos hechos extraordinarios ocurridos en 1905: la publicación de cinco artículos científicos revolucionarios escritos por Einstein entre marzo y diciembre; y el nacimiento de su hija mayor, Margot, en mayo. La película está narrada por el actor británico David Threlfall e incluye entrevistas con expertos mundiales como Sean Carroll o Brian Cox. ... ​ \n\n\nLa teoría general de la relatividad fue publicada por primera vez en 1915 pero sus fundamentos fueron establecidos ya en 1905 cuando Einstein publicó una serie de trabajos revolucionarios que cambiaron nuestra comprensión del Universo. Este documental cuenta cómo ocurrió todo eso centrándose en dos hechos extraordinarios sucedidos aquel año: la publicación de cinco trabajos científicos revolucionarios escritos por él entre marzo y diciembre; así como el nacimiento de su hija Margot en mayo.",
        "watermark_text": "El año que cambió la historia del Universo ( 2005 ) es un documental sobre al descubrimiento por parte de Albert Einstein , en 1915 , de las ecuaciones básicas de su teoría general relativista y los acontecimientos para tuvieron lugar durante ese mismo año . El movie se centra especialmente en dos hechos extraordinarios ocurridos en 1905 : la publicación de cinco artículos científicos revolucionarios escritos por Einstein entre marzo y diciembre ; y el nacimiento de su hija mayor , Margot , es mayo .La película está narrada por el acting británico David Threlfall e incluye entrevistas en expertos mundiales como Sean Carroll o Brian Cox . . . . La teoría general de la relatividad fue publicada por primera vez en 1915 pero sus fundamentos fueron establecidos yo en 1905 cuando Einstein publicó una serie de trabajos revolucionarios que cambiaron nuestra comprensión del Universo .Este documental cuenta cómo ocurrió todo eso centrándose en dos hechos extraordinarios sucedidos aquel año : la publicación de cinco trabajos científicos revolucionarios escritos por él entre marzo y diciembre ; así como el nacimiento de su hija Margot en mayo .",
        "ori-fast-z-score": 0.3922322702763681,
        "water-fast-z-score": 3.1378581622109447
    },
    {
        "original_text": "We report on Swift observations of the fifth outburst of an unusual transient, which we call IGR J112155952 (IGR 11215). The source was discovered by INTEGRAL in 2003 and has been observed to undergo regular outbursts every ~150 days since then. We find that this is also true for its most recent outburst; it reached peak luminosity Lx = 1.1 x 1036 erg s-1 at T0 = MJD 54656.6 ± 0.2 (2010 September 16) with a duration of about 20 days. During each outburst, the spectrum softens as the flux decreases. This behaviour suggests that the accretion rate onto the compact object decreases during the decay phase of each outburst. In addition, there are hints of spectral changes between different outbursts; these may be related to variations in the mass transfer rate or the geometry of the system. \n \n Keywords: Supernova remnant",
        "watermark_text": "We report on Swift discoveries of the fifth outburst of an strange transient , which we call IGR J112155952 ( IGR 11215 ) . The source was established by INTEGRAL in 2003 and has been observed to undergo normal outbursts every ~ 150 days since then .We see that this is also true for its most subsequent outburst ; it achieved peak luminosity Lx = 1 . 1 x 1036 erg s - 1 at T0 = MJD 54656 . 6 ± 0 . 2 ( 2010 September 16 ) with a duration of about 20 days . During each outburst , the spectrum softens as the flux drops .This behaviour suggests that the accretion rate onto the compact body drops during the decay phase of each outburst . In addition , there are hints of absorption changes between various outbursts ; these may be connected to variations in the mass transfer frequency or the topology of the system .Keywords: Supernova remnant",
        "ori-fast-z-score": 0.4472135954999579,
        "water-fast-z-score": 4.621207153499565
    },
    {
        "original_text": "We have studied in detail how to correct for various observational effects on the determination of the white dwarf luminosity function (WDLF). We find that the WDLF is affected by several factors, such as photometric calibration error, incompleteness due to detection limit, contamination by unresolved binaries, etc.. In order to obtain an unbiased estimate of the true WDLF we need to take into account these effects properly.  By using Monte Carlo simulations with artificial data sets, we show that our method can recover the input WDLF very well even when there are large uncertainties in the observed magnitudes or colors. Our results also suggest that it may be difficult to determine the absolute normalization of the WDLF accurately because of systematic uncertainty associated with the distance scale. Finally, we apply this method to the recent observations made by the Sloan Digital Sky Survey (SDSS) Data Release 1 (DR1), which covers about one quarter of the sky.",
        "watermark_text": "We have researched in detail how to correct for various observational consequences on the determination of the white dwarf luminosity function ( WDLF ) . We see that the WDLF is affected by many processes , such as photometric calibration error , incompleteness attributed to observation limit , contamination by unresolved binaries , etc . .In order to obtain an unbiased estimate of the true WDLF we must to take into consideration these consequences properly . By using Monte Carlo simulations with artificial data sets , we prove that our technique can regain the input WDLF very best even when there are big uncertainties in the seen magnitudes or colors .Our results also suggest that it could be harder to predict the absolute normalization of the WDLF accurately because of systematic uncertainty associated with the distance scale . Finally , we apply this method to the recent observations made by the Sloan Digital Sky Survey ( SDSS ) Data Release 1 ( DR1 ) , which covers about one quarter of the heavens .",
        "ori-fast-z-score": 1.016001016001524,
        "water-fast-z-score": 6.273807116711903
    },
    {
        "original_text": "We propose an erasure distribution for low-density parity-check (LDPC) codes that has closed-form threshold expression and is optimal in the sense that it minimizes the gap between its threshold value and Shannon limit on the binary symmetric channel (BSC). The proposed distribution can be viewed as a generalization of the optimized irregular repeat accumulate (IRA) code ensemble, which was recently introduced by Tanner et al.. We show that our new distribution achieves better performance than IRA over BSCs with small crossover probabilities. Finally, we present simulation results to demonstrate the effectiveness of the proposed distribution under practical conditions. Index Terms-Low density parity check (LDPC), Binary Symmetric Channel (BSC), Optimized Irregular Repeat Accumulate Code Ensemble (OIRA), Gap-to-Shannon Limit (GTSL)\nI. INTRODUCTIO N Low-Density Parity Check (LDPC) codes are linear block codes defined by sparse parity-check matrices  1  . They have been shown to perform close to capacity when decoded using iterative message-passing algorithms such as belief propagation  2  , and they are widely used in many applications including digital communications  3  -  5  .\nThe design of good LDPC ensembles remains one of the most important problems in coding theory  6  . In particular, there exists a large body of research devoted to finding distributions that minimize the gap between their threshold values and Shannon limits  7  -  11  . However, these works mainly focus on regular or quasi-cyclic LDPC codes  12  , while irregular LDPC codes are more commonly used due to their flexibility  13  . Recently, Tanner et al.  14  presented an optimized irregular repeat accumulate (OIRA) code ensemble whose threshold value matches the Shannon limit on the binary erasure channel (BEC) . This result suggests that OIRA may also achieve near-optimal performance on other channels  15  .",
        "watermark_text": "We suggest an erasure distribution for low - density parity - check ( LDPC ) codes that has closed - form threshold expression and is ideal in the sense that it minimizes the gap between its threshold value and Shannon limit on the binary symmetric channel ( BSC ) . The proposed distribution can be viewed as a generalization of the optimized irregular repeat accumulate ( IRA ) code ensemble , which was recently presented by Tanner et al . . We suggest that our new distribution achieves higher success than IRA over BSCs with little crossover probabilities .Finally , we present modeling results to test the ability of the suggested distribution under effective conditions . Index Terms - Low density parity check ( LDPC ) , Binary Symmetric Channel ( BSC ) , Optimized Irregular Repeat Accumulate Code Ensemble ( OIRA ) , Gap - to - Shannon Limit ( GTSL ) I . INTRODUCTIO N Low - Density Parity Check ( LDPC ) codes are linear block sequences specified by dense parity - check matrices 1 .They have been shown to work close to capacity when decoded using iterative message - passing techniques such as faith propagation 2 , and they are widely useful in different applications notably digital communications 3 - 5 . The design of excellent LDPC ensembles holds one of the most important problems in coding theory 6 .In particular , there exists a large body of research devoted to finding distributions that minimize the gap between their threshold coefficients and Shannon limits 7 - 11 . However , these works mainly emphasis on regular or pseudo - cyclic LDPC rules 12 , while irregular LDPC coding are more frequently used owing to their flexibility 13 .Recently , Tanner et al . 14 published an optimized irregular repeat accumulate ( OIRA ) code ensemble whose limit function matches the Shannon limit on the binary erasure channel ( BEC ) .This result suggests that OIRA may even attain near - optimal performance on other channels 15 .",
        "ori-fast-z-score": 0.08873565094161139,
        "water-fast-z-score": 6.427291616177054
    },
    {
        "original_text": "We present an analysis of Lyman alpha emitters (LAEs) selected by narrowband imaging with Subaru/Suprime-Cam and spectroscopic follow-up observations using VLT/VIMOS at z ~ 3.1, which is one of the most active epochs for galaxy formation. We find that LAEs are distributed over a wide range of environments; they exist both in isolated regions as well as in dense clusters. The clustering properties of LAEs depend on their luminosities. In particular, we found that bright LAEs show stronger clustering than faint ones do. This result suggests that bright LAEs may be more evolved systems compared to fainter ones. Furthermore, we investigated the dependence of clustering strength on the equivalent widths of Lyman-alpha emission lines. Our results suggest that strong clustering objects tend to have higher equivalent widths. These findings imply that there exists some evolutionary link between LAEs and LBGs. \n \n Keywords: Lyman alpha emitter",
        "watermark_text": "We present an assessment of Lyman alpha emitters ( LAEs ) selected by narrowband scanning with Subaru / Suprime - Cam and spectroscopic follow - up observations using VLT / VIMOS at z ~ 3 . 1 , which is one of the most stable epochs for galaxy formation . We see that LAEs are distributed over a broad variety of habitats ; they exist both in isolated regions as well as in dense clusters .The clustering qualities of LAEs depend on their luminosities . In particular , we identified that bright LAEs see better clustering than dim ones do .This result suggests that bright LAEs may be more evolved structures compared to fainter ones . Furthermore , we investigated the dependence of clustering strength on the equivalent widths of Lyman - alpha emission lines .Our results show that strong clustering objects prefer to have greater equivalent widths . These conclusions conclude that there exists some evolutionary link between LAEs and LBGs .Keywords: Lyman alpha emitter",
        "ori-fast-z-score": 0.5163977794943222,
        "water-fast-z-score": 4.816989706290483
    },
    {
        "original_text": "We present an explicit expression for the irreducible form of the metric variation of the action term in sixth order gravity, which is valid to all orders in perturbation theory. We also show that this result can be used to derive an approximate expression for the stress energy tensor of the gravitational field. The results are applied to study the evolution of cosmological perturbations during inflation driven by a scalar field with non-canonical kinetic term. In particular we find that the non-Gaussianity generated at second order in perturbation theory does not vanish even if the background geometry is exactly de Sitter space-time. This implies that the bispectrum produced by such models cannot be described solely in terms of local shape functions as it was previously thought. \nI. INTRODUCTORY REMARK\nIn recent years there has been renewed interest on higher derivative theories of gravity motivated mainly by their possible role in quantum gravity phenomenology (see e.g. ), but also because they provide interesting alternatives to standard General Relativity (GR) in the context of modified gravity scenarios . However, despite these efforts, our understanding of the physical consequences of these theories remains incomplete due to technical difficulties associated with the analysis of their solutions. One of the main obstacles comes from the fact that the equations of motion derived from these actions contain derivatives of arbitrarily high order, making them difficult or impossible to solve analytically. A way out of this problem consists in expanding the fields around some fixed background solution and truncating the resulting series expansion after a finite number of terms. Although this approach allows one to obtain useful information about the dynamics of the system under consideration, it fails to capture important features like back-reaction effects between different modes of the same field or interactions among different fields. For example, in the case of inflationary cosmologies based on higher derivative gravity, the truncated perturbative expansions do not reproduce correctly the observed level of primordial non-Gaussianities .\nA more systematic method to deal with these problems involves the use of covariant techniques developed originally within the framework of GR. These methods allow us to express the equations of motion in a manifestly gauge",
        "watermark_text": "We present an explicit expression for the irreducible form of the metric variation of the activity term in sixth order gravity , which is valid to all orders in perturbation theory . We additionally prove that this consequence can be used to derive an approximate representation for the strain energy tensor of the gravitational field .The results are applied to study the evolution of cosmological perturbations during inflation driven by a scalar field with non - canonical kinetic term . In particular we find that the non - Gaussianity generated at second order in perturbation theory does not vanish even if the background geometry is precisely de Sitter space - time .This implies that the bispectrum produced by such theories cannot be described solely in terms of local form variables as it was formerly thought . I .INTRODUCTORY REMARK In recent years there has been continued interest on higher derivative theories of gravitational motivated mainly by their possible role in quantum gravitational phenomenology ( saw e . g . ) , but also because they give exciting alternatives to standard General Relativity ( GR ) in the context of modified gravity scenarios .However , despite these attempts , our grasp of the physical effects of these theories appears incomplete due to technical problems related with the processing of their solutions . One of the main problems comes from the fact that the equations of movement obtained from these actions involve derivatives of arbitrarily high order , making them harder or impossible to solve analytically .A way out of this question involves in expanding the fields around some fixed background solution and truncating the resulting series expansion after a finite number of terms . Although this methodology allows one to obtain usable information about the dynamics of the process under consideration , it fails to capture important features like back - reaction effects between various modes of the same field or relationships among different fields .For instance , in the case of inflationary cosmologies based on higher derivative gravity , the truncated perturbative expansions do not reproduce correctly the seen level of primordial non - Gaussianities . A more thorough method to deal with these problems involves the using of covariant techniques established originally within the framework of GR .These methods provide us to express the equations of movement in a manifestly gauge",
        "ori-fast-z-score": 0.5261522196019802,
        "water-fast-z-score": 7.29096647162744
    },
    {
        "original_text": "We present the results of simultaneous X-ray (Chandra) and radio (RXTE )observations of the Broad Line Radio Galaxy, 3C382 . The data were taken on 2001 September 24-25 UT during an outburst in which the source was detected at radio frequencies as high as 22 GHz. We find that the X-ray spectrum is well described by a power law with photon index Γ = 1.7 ± 0.1 modified by photoelectric absorption consistent with N_H = 2 x 1022 cm-2. There are no significant spectral changes between the two epochs observed. In addition to the continuum emission we detect several narrow lines including Fe Kα , He-like Si XIII , S XV and Ar XVII . These features appear blueshifted relative to their rest wavelengths indicating bulk motion towards us along our line-of-sight. Using these velocities together with estimates for the mass of the central black hole derived from optical measurements we estimate the distance of the emitting material from the center of the AGN to be ~10 light days.",
        "watermark_text": "We present the conclusion of simultaneous X - ray ( Chandra ) and radio ( RXTE ) observations of the Broad Line Radio Galaxy , 3C382 . The data were took on 2001 September 24 - 25 UT during an outburst in which the source was seen at radio altitudes as long as 22 GHz .We see that the X - ray spectrum is well described by a power law with photon index Γ = 1 . 7 ± 0 . 1 augmented by photoelectric diffusion compatible with N _ H = 2 x 1022 centimetres - 2 . There are no notable spectral changes between the two epochs observed .In addition to the continuum emission we perceive several small lines including Fe Kα , He - like Si XIII , S XV and Ar XVII . These features appear blueshifted relative to their rest wavelengths suggesting bulk movement towards us along our line - of - view .Using these velocities together with projections for the mass of the central black hole derived from optical calculations we estimate the distance of the emitting substance from the center of the AGN to be ~ 10 light days .",
        "ori-fast-z-score": -0.8819171036881969,
        "water-fast-z-score": 4.0
    },
    {
        "original_text": "We study the possibility that gravitational waves can be detected by measuring their effect on gyroscopes in space, as proposed for the GP-B experiment. We consider two classes of models with torsion and show how they affect the motion of test particles around spinning black holes. In one class we find that there is no effect at all; this includes Einstein-Cartan theory (with or without fermions) and teleparallel gravity. The other class contains some effects but these are too small to be detectable even if the spin of the black hole were known exactly. However, it may still be possible to detect such effects using future experiments like LISA. Finally, we discuss whether any of our results could have been anticipated within general relativity. This work was supported by NSF grant PHY-0456747. Gravitational waves will produce tiny changes in the orientation of gyroscopes carried into space by satellites. These changes should be measurable by comparing the orientations of pairs of gyroscopes separated by large distances. Such an experiment has recently begun taking data  1  . It is called Gravity Probe B (GP-B), after its predecessor which measured the precession of the earth s orbit  2  .\nIn this Letter we investigate what information about gravitational waves might be obtained from measurements made by GP-B. Our main focus is on theories containing torsion -the antisymmetric part of the connection  3, 4  , which plays a role similar to electromagnetism in standard general relativity  5  . Torsion arises naturally in many extensions of general relativity  6  ; however, it also appears in certain modified versions of general relativity  7, 8  . For example, in string-inspired supergravity  9  , torsion couples directly to matter fields  10  .",
        "watermark_text": "We explore the idea that gravity signals can be identified by monitoring their effect on gyroscopes in space , as suggested for the GP - B experiment . We consider two groups of models with torsion and know how they impact the movement of research particles around spun dark holes .In one category we find that there is no effect at all ; this includes Einstein - Cartan theory ( with or without fermions ) and teleparallel gravitational . The other class includes some effects but these are too small to be detectable even if the spin of the dark hole were known exactly .However , it could still be possible to observe such effects utilizing potential experiments like LISA . Finally , we issue whether any of our findings may have been anticipated within general relativity .This project was supported by NSF grant PHY - 0456747 . Gravitational waves will generate tiny changes in the orientation of gyroscopes transported into space by satellites .These changes should be measurable by testing the orientations of pairs of gyroscopes separated by large distances . Such an observation has recently begun took results 1 .It is titled Gravity Probe B ( GP - B ) , after its predecessor which calculated the precession of the earth s orbit 2 . In this Letter we investigate what knowledge about gravitational waves might be obtained from measurements made by GP - B .Our main interest is on fields containing torsion - the antisymmetric part of the relationship 3 , 4 , which plays a role similar to electromagnetism in standard special relativity 5 . Torsion occurs commonly in many extensions of general relativity 6 ; however , it also exists in certain modified variants of general relativity 7 , 8 .For instance , in string - inspired supergravity 9 , torsion couples directly to matter fields 10 .",
        "ori-fast-z-score": 0.5432144762551112,
        "water-fast-z-score": 8.746195456274092
    },
    {
        "original_text": "We present an efficient computational method to compute the elastic properties, vibrational frequencies and normal modes of proteins using finite element analysis (FEA). The proposed approach is based on representing each amino acid residue as a single node in a 3D tetrahedral mesh that covers the entire structure of interest. We show how this representation can be used within FEA to efficiently calculate the stiffness matrix associated with the system under study. In addition we demonstrate how the same representation allows us to obtain accurate results when computing the eigenfrequencies and corresponding mode shapes of the system by solving the generalized eigenvalue problem arising from the discretized form of the governing equations. Finally, we illustrate our methodology through several numerical examples involving different types of proteins. Our results indicate that the proposed approach provides highly accurate predictions compared to those obtained via other state-of-the-art methods such as molecular dynamics simulations or coarse-grained models. This work was supported by NSERC Discovery Grants RGPIN-2014-04567 and RGPIN-2016-05189 .",
        "watermark_text": "We introduce an efficient numerical technique to compute the elastic properties , vibrational speeds and normal mechanisms of proteins using finite element assessment ( FEA ) . The proposed approach is based on representing each amino residue compound as a single node in a 3D tetrahedral mesh that covers the entire structure of interest .We see how this representation can be used within FEA to easily calculate the stiffness matrix associated with the system under research . In addition we prove how the same representation enables us to obtain precise conclusions when computing the eigenfrequencies and corresponding mode shapes of the system by handling the generalized eigenvalue problem emerging from the discretized form of the governing equations .Finally , we explain our technique through several mathematical examples involving varying kinds of proteins . Our results show that the suggested approach offers highly precise predictions compared to those achieved via other state - of - the - art methods such as protein behavior simulations or fine - grained estimates .This project was supported by NSERC Discovery Grants RGPIN - 2014 - 04567 and RGPIN - 2016 - 05189 .",
        "ori-fast-z-score": -1.091089451179962,
        "water-fast-z-score": 5.965587590013045
    },
    {
        "original_text": "The book Nurturing Breakthroughs by James Watson and Peter Winkler is about how to create breakthroughs in science, technology, engineering or mathematics (STEM). The authors argue that the best way for scientists to make new discoveries is not through individual genius but rather by working together as teams on problems they are passionate about.  They also claim that it helps if you have an idea of what your problem looks like before you start solving it because this will help guide your research efforts. This article describes some of their ideas and provides examples of how these concepts can be applied to physics research. In his book Nurturing Breakdowns, James Watson argues that the most successful people who solve complex problems do so by working with others instead of trying to work alone. He says that when we work individually our brains tend to focus only on one aspect of the problem at hand which may lead us down dead ends while working collaboratively allows us to see all aspects of the problem simultaneously.",
        "watermark_text": "The book Nurturing Breakthroughs by James Watson and Peter Winkler is about how to create breakthroughs in science , technology , engineering or math ( STEM ) . The authors argue that the best method for researchers to make fresh findings is not through individual genius but rather by acting together as teams on problems they are loving about .They also claim that it assists if you have an idea of what your problem looks like before you start investigating it because this will assist guide your study efforts . This page describes some of their ideas and provides examples of how these concepts can be applied to physics studies .In his book Nurturing Breakdowns , James Watson says that the most talented people who solution complex challenges do so by working with others rather of trying to work alone . He said that when we study collectively our mind tend to reflect only on one element of the issue at hand which would guide us down dead ends while working collaboratively allows us to see all aspects of the issue simultaneously .",
        "ori-fast-z-score": -0.5773502691896257,
        "water-fast-z-score": 5.888972745734182
    },
    {
        "original_text": "We study the semiclassical dynamics of electrons in magnetic fields, which are described by the Dirac equation with spin-orbit coupling and Zeeman splitting. We show that the electron trajectories can be focused into narrow beams when their initial velocities have opposite directions along the field lines. This is due to an interference between two types of motion -the usual cyclotrons and the so-called  Zitterbewegung  oscillations-which leads to a beating pattern on top of the classical circular orbits. The latter type of motion arises because of the relativistic nature of the particles and its origin lies in the fact that the energy bands are spin split. Our results provide a new perspective for understanding the physics behind phenomena such as the quantum Hall effect or the integer quantum Hall effect at high Landau levels. \nI. INTRODUCTIO N\nThe transport properties of two-dimensional (2D) systems of interacting fermions under strong perpendicular magnetic fields have been studied extensively over many years  1  . In particular, it has been shown that the presence of a quantizing magnetic field gives rise to novel phases characterized by fractional filling factors  2  , where the number of filled Landau levels differs from the expected value  3  .\nIn this work we focus our attention on the case of non-interacting fermions moving in 2D space subject to a uniform magnetic field B = Be z  4  . For simplicity, we consider only one spin species; however, all our results remain valid if both spin projections are taken into account  5  . In addition, we assume that the Fermi level lies within the conduction band  6  . Under these conditions, the low-energy excitations around the Fermi surface are well-described by the massless Dirac Hamiltonian  7, 8  \nwhere v F denotes the Fermi velocity, σ i=x,y,z denote Pauli matrices acting on the spinor wave function Ψ(r), p x = −i∂/∂x and p y = −i∂/(−i∂y). Hereafter, we seth = 1 and e = 1. It should be noted that Eq. (1) \nII. ELECT",
        "watermark_text": "We research the semiclassical dynamics of electrons in magnetic fields , which are explained by the Dirac formula with spin - orbit coupling and Zeeman splitting . We see that the electron trajectories can be focused into narrow beams when their initial velocities have different directions along the field lines .This is due to an interference between two forms of movement - the usual cyclotrons and the so - called Zitterbewegung oscillations - which results to a beating sequence on top of the classical circular orbits . The latter type of movement occurs because of the relativistic behavior of the atoms and its origin lies in the fact that the power groups are momentum separated .Our results bring a new insight for studying the physics behind processes such as the quantum Hall impact or the integer quantum Hall impact at high Landau concentrations . I . INTRODUCTIO N The transport properties of two - dimensional ( 2D ) complexes of interacting fermions under strong diagonal magnetic waves have been studied thoroughly over numerous years 1 .In particular , it has been shown that the presence of a quantizing magnetic force gives rise to novel phases characterized by fractional filling variables 2 , where the proportion of filled Landau concentrations differs from the expected value 3 . In this research we focus our focus on the case of non - interacting fermions moving in 2D space subject to a uniform magnetic force B = Be z 4 .For simplicity , we treat only one spin species ; however , all our findings remain correct if both spinning projections are took into consideration 5 . In addition , we suppose that the Fermi level sits within the conduction band 6 .Under these conditions , the small - energy excitations around the Fermi surface are better - described by the massless Dirac Hamiltonian 7 , 8 where v F denotes the Fermi velocity , σ i = x , y , z define Pauli matrices acting on the spinor wave function Ψ ( r ) , r x = −i∂ / ∂x and p y = −i∂ / ( −i∂y ) . Hereafter , we seth = 1 and e = 1 .It should be mentioned that Eq . ( 1 ) II .ELECT",
        "ori-fast-z-score": -1.007017629956027,
        "water-fast-z-score": 7.216959681351526
    },
    {
        "original_text": "We consider the Standard Model (SM) in 5 dimensions, where one extra dimension is compactified to an orbifold S 1 /Z 2 . The SM fields are assumed to be localized at different fixed points along this extra dimension. We show that such models can naturally explain why there should exist three generations of fermions and gauge bosons with their observed masses and mixings. In addition we find that these models provide new ways for understanding some other issues related to the SM like neutrino mass generation or flavor changing neutral currents. Finally we discuss how our results could be tested experimentally. Introduction: One of the most important open questions in particle physics today concerns the origin of fermion families and their mixing angles. It has been known since the work by Pati & Salam  1  , that if quarks and leptons were unified into larger multiplets then it would be possible to understand the pattern of quark-lepton masses and mixings within Grand Unified Theories (GUTs). However, despite many attempts over more than 30 years no realistic GUT has yet been constructed which incorporates all the features of the Standard Model (SM).\nIn recent years another possibility was suggested  2  -  4  : If the SM fields live in higher dimensional space-time, they may have Kaluza-Klein excitations corresponding to additional states with masses of order 1/R, where R denotes the size of the extra dimensions. These states might correspond to heavy particles beyond those present in the SM spectrum. This idea leads to interesting phenomenological consequences  5  .\nThe simplest way to realize this scenario is to assume that only gravity propagates in the bulk while the SM fields are confined to a four-dimensional  brane   6  . Such theories lead to corrections to the Newtonian potential between two test masses m 1 and m 2 separated by distance r given by: \nwhere M P l = 1/ √ 8πG N ≈ 10 19 GeV is the reduced Planck scale and n i counts the number of extra spatial dimensions accessible to field i. For distances smaller than about 0.1 mm deviations from the inverse square law predicted by general relativity will become",
        "watermark_text": "We consider the Standard Model ( SM ) in 5 dimensions , where one extra dimension is compactified to an orbifold S 1 / Z 2 . The SM fields are expected to be localized at different fixed points along this extra dimension .We see that such theories can naturally explain why there should exist three generations of fermions and gauge bosons with their observed masses and mixings . In addition we find that these models bring fresh ways for explaining some other issues related to the SM like neutrino mass development or color shifting neutral currents .Finally we talk how our findings may be evaluated experimentally . Introduction : One of the most important open questions in particle science today issues the origin of fermion families and their mixing angles .It has been known since the paper by Pati & Salam 1 , that if quarks and leptons were organized into larger multiplets then it would be possible to comprehend the trend of quark - lepton masses and mixings within Grand Unified Theories ( GUTs ) . However , despite many efforts over more than 30 centuries no realistic GUT has already been constructed which includes all the details of the Standard Model ( SM ) .In recent work another possibility was suggested 2 - 4 : If the SM fields reside in larger dimensional space - time , they may have Kaluza - Klein excitations corresponding to extra states with masses of order 1 / R , where R denotes the height of the extra dimensions . These states could belong to heavy ions beyond those present in the SM spectrum .This idea results to useful phenomenological consequences 5 . The shortest way to realize this situation is to assume that only gravitational propagates in the bulk while the SM fields are localized to a four - dimensional brane 6 .Such theories lead to corrections to the Newtonian potential between two test masses m 1 and m 2 separated by distance r given by : where M P l = 1 / √ 8πG N ≈ 10 19 GeV is the reduced Planck scale and n i counts the quantity of added spatial dimensions accessible to field i . For distances smaller than about 0 . 1 mm deviations from the inverse square law predicted by particular relativity will become",
        "ori-fast-z-score": 2.685380346549405,
        "water-fast-z-score": 9.115037909077289
    },
    {
        "original_text": "We present the results of our investigation on semiclassical scalar propagator in curved space-time, which is based on the WKB approximation to the wave function. We show that there are two different ways how one can define this quantity depending on whether or not one takes into account the back-reaction effects due to the quantum fluctuations of the gravitational field. The first approach leads to an expression for the semiclassical propagator which coincides with the Feynman propagator at large distances but differs significantly near the source point. In particular it does not satisfy the Hadamard condition required by general relativity. On the other hand, if we take into account the back reaction then the resulting expression satisfies all necessary conditions including the Hadamard condition. However, as was shown recently by Wald et al., such an expression cannot be obtained within the framework of standard QFT. This problem may have important consequences when considering the propagation of particles through black holes since the corresponding expressions differ substantially even outside the horizon.",
        "watermark_text": "We present the conclusion of our analysis on semiclassical scalar propagator in curved space - time , which is based on the WKB approximation to the wave function . We see that there are two different ways how one can define this quantity based on whether or not one takes into consideration the back - reaction effects due to the quantum fluctuations of the gravitational field .The first method results to an definition for the semiclassical propagator which coincides with the Feynman propagator at large distances but varies dramatically near the origin point . In particular it does not satisfy the Hadamard condition required by general relativity .On the other hand , if we took into consideration the back response then the resulting expression satisfies all necessary circumstances including the Hadamard condition . However , as was shown lately by Wald et al . , such an form cannot be obtained within the framework of standard QFT .This problem could have important implications when examining the propagation of particles through black holes since the equivalent definitions differ substantially even outside the horizon .",
        "ori-fast-z-score": 0.5698028822981898,
        "water-fast-z-score": 5.128225940683707
    },
    {
        "original_text": "We present Hubble Space Telescope (HST) and Spitzer Space Telescope observations of the edge-on circumstellar disk surrounding 2MASS J04414489+2512172, a young brown dwarf with spectral type M8 located in Upper Scorpius at a distance of 145 pc. The HST data reveal that this object is surrounded by a bright ring-like structure extending to ~0.5′′ (~120 AU). We find evidence for two spiral arms emerging from the inner part of the ring toward its center. These features are also seen in near-infrared images obtained with the adaptive optics system NACO on VLT/UT4. In addition, we detect several knots along these spirals which may be caused by dust clumps or planetesimals embedded within them. Our results suggest that the observed structures could have been formed through gravitational instability triggered by rapid inward migration of solids due to gas drag forces.",
        "watermark_text": "We present Hubble Space Telescope ( HST ) and Spitzer Space Telescope observations of the edge - on circumstellar disk surrounding 2MASS J04414489 + 2512172 , a young brown giant with spectral category M8 situated in Upper Scorpius at a distance of 145 pc . The HST results show that this body is surrounded by a bright ring - like structure extending to ~ 0 . 5 ′ ′ ( ~ 120 AU ) .We get information for two spiral bodies emerging from the inner part of the circle toward its core . These features are also shown in near - infrared images obtained with the adaptive optics scheme NACO on VLT / UT4 .In addition , we find various threads along these spirals which may be caused by dust clumps or planetesimals contained within them . Our results propose that the known structures could have been formed through gravity instability caused by rapid inward movement of solids due to gas drag forces .",
        "ori-fast-z-score": 0.629940788348712,
        "water-fast-z-score": 5.921443410477893
    },
    {
        "original_text": "We present an analysis of the temperature dependence of thermally stimulated luminescent (TSL) glow curves in terms of the nonstationary electron-phonon relaxation theory, which does not assume that the system is close to equilibrium at any time during its evolution.  We show how this approach can be used for extracting information about the phonon spectrum and the density of states of charge carriers from TSL data obtained on different types of materials. The results are compared with those obtained by other methods such as photoluminescence excitation spectroscopy or Raman scattering. In particular we demonstrate that our method allows one to determine the energy gap between the conduction band minimum and valence band maximum in semiconductors. This work was supported by Russian Science Foundation grant No. 14-50-00040. DOI: 10.1063/1.4935190 \nI. INTRODUCTORY REMARK\nThe study of luminescence phenomena has been attracting considerable attention over many years because it provides valuable information about electronic structure and optical properties of solids  1  . Thermal stimulation luminescence (TSL), also known as optically stimulated luminescence (OSL), is particularly useful since it enables us to probe the distribution function of electrons excited into the conduction band  2  .\nIn recent decades there have been numerous attempts to develop theoretical models describing various aspects of luminescence processes  3  , including thermal stimulation luminescence  4  -  8  . However, most of these works were based on the assumption that the system under consideration is always close to equilibrium  9  . As a result they cannot describe correctly some important features observed experimentally  10  . For example, the shape of the TSL glow curve depends strongly on the type of material  11  : while in insulators it usually exhibits a single peak  12  , in metals it often consists of several peaks  13  . Moreover, even within the same class of materials, e.g., semiconductor crystals  14  , the number of peaks may vary depending on the doping level  15  . These observations cannot be explained using existing theories  16  .",
        "watermark_text": "We present an assessment of the temperature dependence of thermally stimulated luminescent ( TSL ) glow curves in terms of the nonstationary electron - phonon relaxation hypothesis , which does not assume that the system is close to equilibrium at any time during its evolve . We see how this methodology can be used for extracting information about the phonon spectrum and the density of states of charge carriers from TSL information obtained on various types of substances .The results are compared with those achieved by other methods such as photoluminescence excitation spectroscopy or Raman absorption . In particular we prove that our technique permits one to estimate the electricity gap between the conduction band minimum and valence band maximum in semiconductors .This project was supported by Russian Science Foundation gift No . 14 - 50 - 00040 .DOI : 10 . 1063 / 1 . 4935190 I . INTRODUCTORY REMARK The investigation of luminescence effects has been drawing tremendous attention over numerous years because it gives valuable info about electronic properties and electronic properties of solids 1 .Thermal stimulation luminescence ( TSL ) , sometimes called as optically stimulated luminescence ( OSL ) , is especially useful since it allows us to probe the distribution behavior of electrons excited into the conduction band 2 . In recent generations there have been numerous attempts to develop conceptual models explaining various parts of luminescence events 3 , notably heat stimulation luminescence 4 - 8 .However , most of these works were based on the assumption that the process under consideration is usually nearly to equilibrium 9 . As a result they cannot describe correctly some important features discovered experimentally 10 .For instance , the form of the TSL flicker curve varies strongly on the kind of material 11 : while in insulators it generally exhibits a single peak 12 , in metals it often consists of several peaks 13 . Moreover , even within the same category of substances , e . g . , semiconductor crystals 14 , the number of peaks may differ depending on the doping level 15 .These measurements cannot be understood using existing models 16 .",
        "ori-fast-z-score": -2.3664319132398464,
        "water-fast-z-score": 7.437357441610946
    },
    {
        "original_text": "We present near-infrared (NIR) spectroscopy of the black hole X-ray binary system A0620-00 obtained with the Subaru Telescope and Gemini Observatory in 2001-2002. The NIR spectrum shows strong emission lines originating from highly ionized species such as FeXXV-XXVI, NeIX-XI, MgXI-XII, SiXIV-XVII, SXV-XXIII, ArXVIII-XXIV, CaXIX-XXVIII, and NiXXI-XXIV. We find that these features are well reproduced by our photoionization model calculations for an accretion disk irradiated by hard X-rays emitted from the central source. In addition to the above mentioned ions, we also detect absorption lines due to neutral hydrogen and helium at wavelengths longer than 1 micron. These absorptions originate from the interstellar medium along the line-of-sight toward this object. \n \n Keywords: Near-infrared spectroscopy",
        "watermark_text": "We use near - infrared ( NIR ) spectroscopy of the dark hole X - ray binary system A0620 - 00 collected with the Subaru Telescope and Gemini Observatory in 2001 - 2002 . The NIR spectrum displays strong absorption lines coming from highly ionized compounds such as FeXXV - XXVI , NeIX - XI , MgXI - XII , SiXIV - XVII , SXV - XXIII , ArXVIII - XXIV , CaXIX - XXVIII , and NiXXI - XXIV .We see that these characteristics are better illustrated by our photoionization theory analyses for an accretion disk irradiated by hard X - radiation emitted from the main source . In addition to the above mentioned ions , we also observe absorption paths due to neutral hydrogen and helium at wavelengths greater than 1 micron .These absorptions originate from the interstellar medium along the line - of - view toward this body . Keywords : Near - infrared spectroscopy",
        "ori-fast-z-score": -1.8962448894726294,
        "water-fast-z-score": 4.521814736434731
    },
    {
        "original_text": "We study the effects on the entropy and Hawking temperature of extremal black holes due to higher derivative terms in the action, namely those coming from supersymmetric (SUSY) or quadratic curvature invariants such as the Gauss-Bonnet term. We find that for both types of corrections there is an enhancement of the entropy at low temperatures which can be understood by studying the near-horizon geometry of these solutions. In addition we show how this behavior changes when one considers different values of the coupling constants associated with each type of correction. Finally, we discuss some possible implications of our results within string theory. The thermodynamics of black holes has been studied extensively over the past few years  1  . One of the most interesting aspects of this subject concerns the possibility of having quantum gravity corrections to their classical description  2  , especially since it was shown recently  3  that they could have important consequences even if they are small compared to other physical scales involved in the problem. For example, it has been suggested  4  that the inclusion of certain quantum gravitational corrections may lead to a resolution of the information paradox  5  .\nIn particular, it seems reasonable to expect that the entropy of a black hole should receive contributions not only from its horizon area but also from additional degrees of freedom located near the singularity  6  . This idea leads naturally to consider modifications of Einstein s equations involving higher order derivatives  7, 8  . However, although many authors have considered various forms of higher-order corrections  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59  , very little attention has been paid so far  60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,",
        "watermark_text": "We explore the effects on the entropy and Hawking temperature of extremal black holes due to higher derivative terms in the operation , particularly those coming from supersymmetric ( SUSY ) or quadratic curvature invariants such as the Gauss - Bonnet term . We see that for both types of corrections there is an enhancement of the entropy at low temperatures which can be understood by examining the near - horizon shape of these solutions .In addition we explain how this behavior changes when one considers distinct expressions of the interaction constants associated with each type of correction . Finally , we explain some possible implications of our findings within string theory .The thermodynamics of grey holes has been studied thoroughly over the previous few years 1 . One of the most exciting aspects of this subject concerns the prospect of having quantum gravitational corrections to their classical description 2 , particularly since it was shown recently 3 that they may have important implications even if they are small relative to other physical scales implicated in the issue .For instance , it has been proposed 4 that the introduction of certain quantum gravitational corrections might lead to a resolution of the information paradox 5 . In particular , it appears justified to predict that the entropy of a black hole should receive benefits not only from its horizon area but also from additional degrees of freedom placed near the singularity 6 .This idea results naturally to consider modifications of Einstein s coefficients involving higher order derivatives 7 , 8 . However , although many writers have thought numerous types of greater - order corrections 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , very less attention has been paid so far 60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 ,",
        "ori-fast-z-score": 0.18569533817705186,
        "water-fast-z-score": 7.926290870042667
    },
    {
        "original_text": "We consider a model for an enzymatic reaction network with multiple futile cycles, where each enzyme is assumed to be present at constant concentration and all reactions are reversible. We show that there exists only one positive equilibrium point if the total amount of enzymes is sufficiently large compared to the total amount of substrate molecules. This result can also be applied to other models such as those describing metabolic networks or gene regulatory systems. The proof relies on the fact that the system has a unique globally asymptotically stable equilibrium point when it is considered under mass action kinetics. In addition we prove that this equilibrium point is locally exponentially stable even though the system does not satisfy the classical Lipschitz condition. Finally, numerical simulations illustrate our results. Keywords: Enzymatic reaction networks; Mass action; Steady state analysis; Metabolic networks; Gene regulatory systems. 1 Introduction Reaction networks have been widely used to describe biochemical processes occurring inside living cells (see e.g.,  1  ,  4  ). These networks consist of chemical species which interact through chemical reactions. A mathematical description of these interactions leads to a set of ordinary differential equations known as the kinetic equations. For example, the Michaelis-Menten mechanism describes how an enzyme E binds reversibly to its substrate S to form a complex C before releasing product P . It consists of three elementary reactions given by \nwhere k + i and k − i denote respectively the forward and backward rate constants associated with the ith reaction. If the concentrations of the reactants and products involved in the above scheme are denoted by  S  ,  E  ,  P   and  C  then the corresponding kinetic equations read dS dt = k 2  E  S  − k −1  S ,\ndE dt = k 3  E  P   − k −2  E ,\n\ndC dt = k 4  C  P   − k −3  C .\n\nThe parameters k i represent the rates of the different reactions. Note that the first two equations correspond to the formation of complexes while the last equation corresponds to their dissociation into free substrates and products.",
        "watermark_text": "We consider a theory for an enzymatic process network with many futile periods , where each enzyme is expected to be found at fixed concentration and all processes are reversible . We see that there exists only one favorable equilibrium point if the total quantity of proteins is sufficiently huge compared to the total quantity of substrate molecules .This result can also be applied to other models such as those describing metabolic networks or gene regulatory processes . The proof based on the fact that the process has a unique globally asymptotically stable equilibrium point when it is regarded under mass activity kinetics .In addition we prove that this equilibrium point is locally exponentially steady even though the model does not satisfy the standard Lipschitz requirement . Finally , numerical simulations exhibit our findings .Keywords : Enzymatic process networks ; Mass response ; Steady state analysis ; Metabolic systems ; Gene regulatory structures . 1 Introduction Reaction networks have been widely using to define biochemical reactions appearing inside live cells ( see e . g . , 1 , 4 ) .These systems consist of chemical species which interact through chemical processes . A mathematical description of these interactions leads to a setting of simple differential equations known as the kinetic equations .For instance , the Michaelis - Menten process represents how an enzyme E connects reversibly to its substrate S to form a complex C before producing product P . It consists of three elementary reactions given by where k + i and k − i describe respectively the forward and back rate constants associated with the ith reaction .If the levels of the reactants and products participating in the above scheme are denoted by S , E , P and C then the associated kinetic equations read dS dt = k 2 E S − k −1 S , dE dt = k 3 E P − k −2 E , dC dt = k 4 C P − k −3 C . The parameters k i describe the rates of the different processes .Note that the first two expressions correspond to the formation of complexes while the last equation relates to their dissociation into free substrates and products .",
        "ori-fast-z-score": -1.697749375254331,
        "water-fast-z-score": 7.469939758793239
    },
    {
        "original_text": "We present high-resolution optical spectroscopy for three open clusters: NGC 2516 (age = 1 Gyr), Hyades (600 Myr) and M67 (3 Gyr). We use these data to measure the abundance ratios of C/Fe, N/Fe, O/Fe, Mg/Fe, Si/Fe, S/Fe, Ca/Fe, Ti/Fe, Cr/Fe, Mn/Ca, Ni/Co, Y/Ba, Zr/Hf, Sr/Y, Ba/Sr, La/Lu, Ce/Pb, Eu/Gd, Yb/Tm, Lu/Hf, W/Mn, Th/U, and U/Th. These measurements are used as input into galactic chemical evolution models that trace the time-evolution of the abundances of all elements heavier than helium produced by nuclear fusion reactions within massive stars. The results show that the observed trends can be explained if we assume that the initial mass function is bimodal with peaks at 8-10 solar masses and 2-3 solar masses.",
        "watermark_text": "We create fast - resolution optical spectroscopy for three open complexes : NGC 2516 ( age = 1 Gyr ) , Hyades ( 600 Myr ) and M67 ( 3 Gyr ) . We use these information to measure the abundance proportions of C / Fe , N / Fe , O / Fe , Mg / Fe , Si / Fe , S / Fe , Ca / Fe , Ti / Fe , Cr / Fe , Mn / Ca , Ni / Co , Y / Ba , Zr / Hf , Sr / Y , Ba / Sr , La / Lu , Ce / Pb , Eu / Gd , Yb / Tm , Lu / Hf , W / Mn , Th / U , and U / Th .These measurements are using as input into galactic chemical evolution models that trace the period - evolve of the abundances of all components heavier than helium produced by nuclear fusion events within large galaxies . The results show that the observed trends can be described if we suppose that the early mass function is bimodal with peaks at 8 - 10 solar masses and 2 - 3 solar masses .",
        "ori-fast-z-score": -1.0674899923282326,
        "water-fast-z-score": 3.2024699769846983
    },
    {
        "original_text": "We report on scanning tunneling microscopy and spectroscopy (STM/S) studies of the electronic structure of individual Si donors in silicon dioxide grown by chemical vapor deposition at low temperatures.  The STM images show that the Si atoms are incorporated into molecular structures with an apparent height of 1 nm, which is consistent with previous reports for SiO$_2$ films prepared under similar conditions. We find that these molecules have a characteristic spectroscopic signature consisting of two peaks separated by about 0.5 eV in dI/dV spectra recorded over them. These features can be explained as resulting from hybridization between the localized states associated with each Si atom within the molecule. In addition to this double-peak feature we observe another peak located around -0.3 V bias voltage, whose origin remains unclear. Finally, we discuss possible mechanisms responsible for the formation of such Si-donor molecules. Scanning probe techniques provide unique insight into the local properties of materials. Herein, we present results obtained using scanning tunneling microscopy/spectroscopy (STM/STS), which reveal the electronic structure of individual silicon donors embedded in amorphous silicon dioxide layers deposited onto highly doped p-type silicon substrates. Our experiments were performed in ultrahigh vacuum chambers equipped with standard facilities for sample preparation and characterization.",
        "watermark_text": "We report on laser tunneling microscopy and spectroscopy ( STM / S ) experiments of the electronic structure of individual Si donors in silicon dioxide grown by molecular vapor precipitation at low temperatures . The STM pictures show that the Si atoms are incorporated into molecular forms with an apparent size of 1 mm , which is consistent with previous findings for SiO $ _ 2 $ films prepared under similar situations .We see that these complexes have a peculiar spectroscopic pattern formed of two peaks distinct by about 0 . 5 eV in dI / dV spectra recorded over them . These features can be understood as occurring from hybridization between the localized states associated with each Si atom within the molecule .In addition to this double - peak structure we study another peak located around - 0 . 3 V bias frequency , whose identity remains disputed . Finally , we investigate possible processes responsible for the formation of such Si - donor molecules .Scanning probe methods provide unique insight into the local characteristics of structures . Herein , we present results acquired using scan tunneling microscopy / spectroscopy ( STM / STS ) , which expose the electronic properties of individual silicon donors embedded in amorphous silicon dioxide sheets injected onto deeply doped n - class silicon substrates .Our experiments were performed in ultrahigh pressure chambers equipped with typical laboratories for sample preparation and determination .",
        "ori-fast-z-score": -1.165543034828717,
        "water-fast-z-score": 7.57602972638666
    },
    {
        "original_text": "We report on helioseismic observations made by GOLF and MDI instruments aboard SOHO spacecraft during the largest recorded solar flare in recent years, which occurred on 2005 Jan. 15 (Solar Flare Event #11). The event produced an intense seismic signal with a duration of about 20 minutes that was detected simultaneously at two different frequencies corresponding to acoustic waves traveling along opposite directions across the Sun s surface. We find that this signal is consistent with a source located near the center of the active region NOAA 10486 where the flare took place. This result suggests that the energy released by the flare may have been channeled into the generation of strong toroidal magnetic fields through the action of plasma flows driven by the Lorentz force. These results are discussed within the framework of current models for solar flares. \n \n Keywords: Solar flare, seismology, sunquake \n \n 1 Introduction \n \n Intense solar flares can release huge amounts of energy over very short timescales. It has recently become possible to study these events using space-based observatories such as the Solar and Heliospheric Observatory (SOHO)  1  . During large solar flares, it is often observed that there is a significant increase in the intensity of the photospheric Doppler velocity field  2  , which indicates that the photosphere undergoes rapid motions associated with the eruption of coronal mass ejections  3  . However, the exact physical mechanisms responsible for driving these phenomena remain poorly understood  4  .\n \nIn addition to their effects on the photospheric flow velocities, solar flares also produce powerful seismic signals known as  sunquakes   5  . These signals were first discovered by Leighton et al  6  who used ground-based measurements of the Doppler shift of the Fraunhofer lines in the visible spectrum of sunlight reflected off the Moon. Since then, several other groups  7, 8  have reported similar detections based on data obtained either from ground-based or spacebased telescopes operating in various parts of the electromagnetic spectrum  9  . More recently, Kosovichev",
        "watermark_text": "We report on helioseismic measurements made by GOLF and MDI instruments aboard SOHO satellites during the greatest documented solar flare in recent years , which occurred on 2005 Jan . 15 ( Solar Flare Event # 11 ) . The event produced an strong seismic response with a duration of about 20 minutes that was detected simultaneously at two different frequencies corresponding to acoustic waves coming along opposite directions across the Sun s surface .We see that this signal is compatible with a source located near the center of the active region NOAA 10486 where the flare took place . This result suggests that the electricity created by the flare might have been channeled into the generation of large toroidal magnetic fields through the activity of plasma flows driven by the Lorentz force .These conclusions are discussed within the framework of recent estimates for solar flares . Keywords : Solar flare , seismology , sunquake 1 Introduction Intense sun flares can release massive amounts of electricity over very brief timescales .It has recently become able to study these incidents use space - based observatories such as the Solar and Heliospheric Observatory ( SOHO ) 1 . During large solar flares , it is often observed that there is a substantial rise in the strength of the photospheric Doppler velocity field 2 , which implies that the photosphere undergoes fast motions resulting with the eruption of coronal mass ejections 3 .However , the exact physical mechanisms involved for controlling these phenomena remain weakly understood 4 . In addition to their impacts on the photospheric flow velocities , sun flares additionally produce violent seismic signals dubbed as sunquakes 5 .These transmissions were first discovered by Leighton et al 6 who used ground - based measurements of the Doppler shift of the Fraunhofer lines in the visible spectrum of sunlight reflected off the Moon . Since then , various other bands 7 , 8 have reported similar detections based on evidence derived either from land - based or spacebased telescopes located in different regions of the electromagnetic spectrum 9 .More recently, Kosovichev",
        "ori-fast-z-score": 0.6713450866373513,
        "water-fast-z-score": 8.166666666666666
    },
    {
        "original_text": "The aim of this thesis is to provide an overview on the state-of-the-art Hartree-Fock Self-Consistent-Field (SCF) methods for solving quantum chemical problems, with special emphasis on their numerical aspects.  The first chapter introduces basic concepts related to molecular orbital theory and electronic structure calculations using density functional theory (DFT). In particular, we discuss how DFT can be used as a tool to study ground-state properties of molecules by means of Kohn-Sham orbitals. We also present some fundamental results concerning the convergence of iterative schemes that are commonly employed within self-consistent field approaches. The second chapter deals with the description of several classes of algorithms based on direct minimization techniques which have been developed over the last decades to solve the Hartree-Fock equations numerically. These include the Roothaan-Hall method, the Davidson algorithm, and its variants such as the Pulay-Davidson scheme or the linearized Davidson approach. Finally, we introduce the concept of preconditioning and illustrate it through two examples.",
        "watermark_text": "The goal of this dissertation is to provide an overview on the state - of - the - art Hartree - Fock Self - Consistent - Field ( SCF ) techniques for solving quantum chemical problems , with special emphasis on their numerical parts . The first section introduces basic concepts related to molecular orbital theory and electronic stability analysis utilizing density functional theory ( DFT ) .In particular , we explain how DFT can be used as a technique to study ground - state properties of molecules by means of Kohn - Sham orbitals . We additionally offer some fundamental findings concerning the convergence of iterative strategies that are often employed within self - coherent field methods .The second chapter deals with the description of several classes of algorithms based on direct minimization techniques which have been built over the last decades to solve the Hartree - Fock equations numerically . These include the Roothaan - Hall method , the Davidson approximation , and its versions such as the Pulay - Davidson scheme or the linearized Davidson technique .Finally , we present the notion of preconditioning and explain it through two examples .",
        "ori-fast-z-score": 0.6793662204867574,
        "water-fast-z-score": 6.863036195648746
    },
    {
        "original_text": "We present an analysis of the transition between first stars and second stars, which are formed by gravitational collapse of primordial gas clouds with masses ranging from 10^4 M_sol to 10^6 M_sol.  We show that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium (IGM). The suppression factor increases as redshift decreases because the IGM temperature rises more rapidly than its density. At lower redshifts, we find that the formation rates of both first and second stars increase sharply when the universe becomes reionized. This effect occurs because the ionizing photons produced during reionization heat up the surrounding neutral hydrogen atoms, thereby increasing their Jeans mass and suppressing fragmentation into smaller objects. Finally, we estimate the number densities of first and second stars using our model for star formation history. Our results suggest that second stars may be detectable via future surveys such as LSST or Euclid.",
        "watermark_text": "We present an assessment of the shift between first stars and second stars , which are created by gravitational decay of primordial liquid clouds with masses vary from 10 ^ 4 M _ sol to 10 ^ 6 M _ sol . We see that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium ( IGM ) .The suppression ratio increases as redshift decreases because the IGM temperature rises more swiftly than its density . At lower redshifts , we find that the formation rates of both first and first stars increase dramatically when the universe becomes reionized .This phenomenon occurs because the ionizing photons created during reionization heat up the nearby neutral hydrogen atoms , thereby expanding their Jeans mass and suppressing fragmentation into bigger objects . Finally , we estimate the number densities of early and first stars using our model for star formation history .Our results propose that second stars would be detectable via upcoming polls such as LSST or Euclid .",
        "ori-fast-z-score": 0.11704114719613057,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "We present the results for neutrino mixing angles, CP violating phases and mass squared differences obtained by using the Fritzsch ansatz to generate the charged fermion masses within an extended supersymmetric grand unified theory based on SO(10). We find that this model can accommodate all experimental data with only one free parameter which is related to the ratio between the two vacuum expectation values of the Higgs fields responsible for breaking down the Pati-Salam gauge symmetry into the Standard Model gauge group. The CKM matrix elements are predicted as well as the Majorana phase associated with leptonic CP violation. In addition we show how the tri-bimaximal pattern observed experimentally in the lepton sector emerges naturally when the quark-lepton unification hypothesis is imposed at high energies. Finally we discuss briefly some phenomenological consequences of our scenario such as neutrinoless double beta decay and proton decay. PACS numbers: 11.30.Pb, 12.60.Cn",
        "watermark_text": "We present the results for neutrino mixing angles , CP violating stages and mass squared variations obtained by using the Fritzsch ansatz to produce the charged fermion masses within an extended supersymmetric grand unified theory based on SO ( 10 ) . We see that this description can handle all theoretical data with only one free parameter which is related to the proportion between the two vacuum expectation values of the Higgs fields responsible for breaking down the Pati - Salam gauge symmetry into the Standard Model gauge group .The CKM matrix elements are expected as well as the Majorana process associated with leptonic CP violation . In addition we show how the tri - bimaximal pattern found experimentally in the lepton region arises readily when the quark - lepton unification theory is imposed at high energies .Finally we talk briefly some phenomenological consequences of our scenario such as neutrinoless double alpha emission and proton decay . PACS scores : 11 . 30 . Pb , 12 . 60 . Cn",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 4.431293675255978
    },
    {
        "original_text": "We present an algorithm for solving the following problem: given a function f on  0,1  and a positive integer n find a piecewise polynomial spline s with knots at 0 = t0 < t1 < ... < tn = 1 such that s(ti) = fi (i=0,...,n), where fi is some approximation of f in ti-1/2 , ti+1/2 . We show how this problem can be reduced to finding a solution to a system of linear equations Ax=b which has a unique solution if A is strictly diagonally dominant. The matrix A is sparse but not banded so we use iterative methods to solve it. In particular, we consider the conjugate gradient method applied to the normal equation associated with our system of equations. We prove convergence of this method under certain conditions. Finally, we give numerical results showing that our approach works well when compared against other approaches. This work was supported by NSF grant DMS-0504520.",
        "watermark_text": "We present an algorithm for solving the following task : given a function w on 0 , 1 and a positive integer n get a piecewise polynomial spline s with knots at 0 = t0 < t1 < . . . < tn = 1 such that s ( ti ) = fi ( i = 0 , . . . , n ) , where fi is some approximation of f in ti - 1 / 2 , ti + 1 / 2 . We see how this question can be reduced to finding a solution to a system of linear equations Ax = b which has a unique solve if A is strictly diagonally dominant .The matrix A is sparse but not banded so we utilize iterative techniques to solve it . In particular , we consider the conjugate gradient technique applied to the normal equation involved with our system of equations .We prove convergence of this method under certain conditions . Finally , we give quantitative results confirming that our approach works well when compared against other methods .This project was supported by NSF grant DMS - 0504520 .",
        "ori-fast-z-score": 0.12403473458920847,
        "water-fast-z-score": 3.8450767722654624
    },
    {
        "original_text": "We present the results of an analysis of absorption line strength maps for 24 early-type spiral galaxies observed with the SAURON integral field spectrograph at the William Herschel Telescope, which are used to derive their stellar populations and chemical abundances. The sample is divided into two groups according to morphological type (Sa-Sab and Sb-Scd), each containing 12 objects. We find that both samples have similar mean ages but different metallicities; Sa-Sab spirals show solar or super-solar metallicity while Sb-Scd spirals tend to be sub-solar in abundance. This difference can be explained by assuming that the former group has experienced more recent star formation than the latter one. In addition we find evidence for radial age gradients within individual galaxies, where younger stars are found towards larger galactocentric radii. Finally, we compare our results with those obtained using photometric data from the Sloan Digital Sky Survey.",
        "watermark_text": "We present the conclusion of an assessment of absorption edge strength projections for 24 early - class spiral clusters seen with the SAURON integral field spectrograph at the William Herschel Telescope , which are using to derive their stellar populations and chemical abundances . The sample is separated into two groups based to morphological class ( Sa - Sab and Sb - Scd ) , each including 12 objects .We see that both samples have equal mean ages but different metallicities ; Sa - Sab spirals exhibit solar or ultra - solar metallicity while Sb - Scd spirals prefer to be sub - solar in abundance . This difference can be described by assuming that the former group has undergone more recent star formation than the former one .In addition we find proof for radial aging gradients within individual stars , where smaller stars are found towards higher galactocentric radii . Finally , we compare our findings with those acquired using photometric data from the Sloan Digital Sky Survey .",
        "ori-fast-z-score": -1.9402850002906638,
        "water-fast-z-score": 5.578319375835658
    },
    {
        "original_text": "We have carried out an extensive spectroscopic survey for high redshift (z > 2) galaxies using the VLT/VIMOS instrument on the ESO Very Large Telescope, targeting sources selected by their strong rest-frame UV emission lines and photometric redshifts. We present here our results obtained with this sample at wavelengths ranging from radio to X-ray. The main goal is to investigate how star formation proceeds in these distant objects through detailed studies of their physical properties such as stellar masses, ages, metallicities or dust content. In particular we focus on two samples of Lyman-alpha emitting galaxies which are known to be very young systems undergoing intense bursts of star formation. Our analysis shows that they exhibit large amounts of cold gas but also significant quantities of dust. This suggests that the bulk of the observed infrared luminosity may not come directly from newly formed stars but rather from reprocessed light emitted by hot dust heated by older populations and/or AGN activity.",
        "watermark_text": "We have carried out an extensive spectroscopic study for high redshift ( z > 2 ) galaxies using the VLT / VIMOS instrument on the ESO Very Large Telescope , targeting sources chosen by their weak rest - frame UV absorption lines and photometric redshifts . We present here our findings obtained with this specimen at wavelengths ranging from radio to X - ray .The main goal is to examine how star formation occurs in these distant objects through detailed analyses of their physical properties such as stellar masses , ages , metallicities or dust content . In particular we focus on two specimens of Lyman - alpha emitting galaxies which are known to be very young structures experiencing aggressive bursts of galaxy formation .Our study shows that they show large quantities of cold gas but also major amounts of dust . This implies that the majority of the seen infrared luminosity might not come directly from newly established stars but rather from reprocessed light emitted by hot dust cooled by existing populations and / or AGN activity .",
        "ori-fast-z-score": 0.10976425998969035,
        "water-fast-z-score": 5.8175057794535885
    },
    {
        "original_text": "We consider a spherically symmetric solution to Einstein s equations in five dimensions with an extra dimension compactified on S 1 /Z 2 . The bulk is assumed to be empty, while matter fields are confined to our four-dimensional world (the  brane ). We find that this model can explain the observed flatness of galactic rotation curves without introducing any new particles or exotic forms of energy density. In particular we show how the mass distribution within galaxies may arise naturally as a consequence of the geometry of space-time. This work was supported by NSF grant PHY-0456728. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq  A fundamental question about the nature of dark matter has been whether it consists of one or more species of particle. If so, what are their masses? What interactions do they have with ordinary matter? How much dark matter does each galaxy contain? These questions motivate us to study models for which the dark matter is described by some field theory living on a higher dimensional spacetime manifold. \n \n Here we will focus on a class of solutions where the extra dimension is compactified on a circle $S^1$. Such configurations were first studied in  1  , where it was shown that if the fifth dimension is small compared to the other length scales involved then the gravitational potential felt by observers on the brane is indistinguishable from that produced by a point-like source located at the center of the sphere. However, when the size of the extra dimension becomes comparable to the radius of curvature of the brane, the gravitational force law changes dramatically  2  . \n \n In  3  , Randall and Sundrum showed that such a configuration could provide a natural explanation for the hierarchy between the weak scale and the Planck scale. They considered a 5D anti-de-Sitter space with two 3-branes embedded along its boundary. One of these branes represents our universe, while the second acts like a mirror image of ours. Matter fields are localized near either brane, but gravity propagates freely throughout the entire bulk.",
        "watermark_text": "We consider a spherically invariant solution to Einstein s equations in five dimensions with an additional dimension compactified on S 1 / Z 2 . The bulk is expected to be empty , while matter fields are localized to our four - dimensional world ( the brane ) .We see that this description can describe the seen flatness of galactic rotation curves without introducing any new ions or exotic kinds of power concentration . In particular we explain how the mass distribution within stars would occur readily as a outcome of the topology of space - time .This project was supported by NSF grant PHY - 0456728 . PACS scores : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq A profound question about the nature of dark matter has been whether it consists of one or more species of particle .If so , what are their masses ? What encounters do they have with normal matter ?How much dark matter does each galaxy consist ? These questions motivate us to study models for which the dark matter is depicted by some field model living on a higher dimensional spacetime manifold .Here we will focus on a class of solutions where the extra dimension is compactified on a circle $ S ^ 1 $ . Such configurations were first explored in 1 , where it was shown that if the fifth dimension is tiny relative to the other length scales included then the gravitational potential felt by observers on the brane is indistinguishable from that created by a point - like source located at the center of the circle .However , when the height of the extra dimension becomes akin to the radius of curvature of the brane , the gravitational pressure law changes dramatically 2 . In 3 , Randall and Sundrum suggested that such a configuration could give a natural explanation for the hierarchy between the strong scale and the Planck scale .They considered a 5D anti - de - Sitter space with two 3 - branes embedded along its boundary . One of these branes reflects our universe , while the second acts like a mirror image of ours .Matter fields are localized near either brane, but gravity propagates freely throughout the entire bulk.",
        "ori-fast-z-score": 1.8593393604027364,
        "water-fast-z-score": 8.056141039648216
    },
    {
        "original_text": "We present an algorithm to compute symbolic models that are approximately bisimilar with respect to the original continuous-time systems, which can be used as abstractions in model checking and controller synthesis problems. The proposed method is based on computing approximate solutions to Hamilton-Jacobi equations using numerical methods such as finite difference or spectral collocation techniques. We show how this approach can be applied to several classes of nonlinear control systems including switched affine systems, piecewise affine systems, and hybrid automata. Finally we illustrate our results by applying them to two examples. Keywords: Approximate bisimulation, Symbolic Model Checking, Nonlinear Control Systems, Finite Difference Method, Spectral Collocation Technique. 1 Introduction In recent years there has been growing interest in developing efficient algorithms for analyzing complex dynamical systems arising in many applications ranging from biology  19, 20  , chemistry  21  , physics  22  , engineering  23  , etc.. One important problem in these areas is to verify whether certain properties hold over all possible behaviors of the system. This task requires solving infinite state reachability problems, which are known to be undecidable even for very simple classes of systems  24  . Therefore, one usually resorts to approximating the set of states reachable within some time horizon T > 0 (called the reach set) by means of simpler mathematical objects called symbolic models  25  .\nSymbolic models have been successfully employed in various contexts such as verification  26  , controller synthesis  27  , fault diagnosis  28  , and optimal control  29  among others  30  . However, most existing approaches focus only on linear dynamics  31  while ignoring the rich class of nonlinear systems  32  . Although it may seem at first glance that dealing with nonlinearities would require more computational effort than their linear counterparts, they actually pose additional challenges due to the fact that the solution space becomes much larger  33  . For example, consider the following nonlinear systeṁ x(t) = f (x(t), u(t)) y(t) = g(x(t)), where t ∈  0, ∞). If the initial condition x0 belongs to R n then the reach set",
        "watermark_text": "We present an algorithm to compute symbolic models that are approximately bisimilar with regard to the actual continuous - time systems , which can be used as abstractions in model checking and controller synthesis problems . The proposed approach is based on solving approximate solutions to Hamilton - Jacobi equations using numerical technique such as finite difference or spectral collocation algorithms .We see how this methodology can be applied to several classes of nonlinear control networks including switched affine systems , piecewise affine systems , and hybrid automata . Finally we explain our findings by application them to two examples .Keywords : Approximate bisimulation , Symbolic Model Checking , Nonlinear Control Systems , Finite Difference Method , Spectral Collocation Technique . 1 Introduction In recent seasons there has been growing interest in building fast algorithms for studying complex dynamical systems emerging in multiple applications ranging from biology 19 , 20 , chemistry 21 , mathematics 22 , engineering 23 , etc . . One important difficulty in these fields is to confirm whether particular features hold over all possible behaviors of the process .This job needs solving infinite system reachability questions , which are known to be undecidable even for very simple groups of models 24 . Therefore , one usually resorts to approximating the set of states reachable within some time horizon T > 0 ( named the reach setting ) by means of simpler mathematical devices named symbolic models 25 .Symbolic models have been successfully utilized in different settings such as verification 26 , controller synthesis 27 , failure detection 28 , and optimal control 29 among others 30 . However , most existing techniques concentrate only on linear mechanics 31 while ignoring the vast class of nonlinear processes 32 .Although it may look at first glance that dealing with nonlinearities might require more mathematical effort than their linear cousins , they actually pose additional challenges due to the fact that the solve space becomes much larger 33 . For instance , consider the following nonlinear [UNK] x ( t ) = w ( x ( t ) , u ( t ) ) y ( t ) = g ( x ( t ) ) , where t ∈ 0 , ∞ ) .If the first condition x0 lies to R n then the reach set",
        "ori-fast-z-score": -0.31426968052735443,
        "water-fast-z-score": 7.905694150420948
    },
    {
        "original_text": "The stability, equilibrium states and the dynamic behavior of solar coronal loops are investigated by applying thermodynamic irreversible energy principles to an idealized model loop system with constant cross section. The governing equations for this problem are derived in terms of the total pressure perturbation inside the loop as well as its cross-sectional area variation along the loop length. It is shown that these two variables can be expressed in terms of each other through a nonlinear differential equation which describes the evolution of the loop system. This equation has been solved numerically under different initial conditions corresponding to various physical situations. In particular, it is found that the loop may either expand or contract depending on whether the initial value of the total pressure perturbation is positive or negative respectively. Furthermore, the results show that there exists only one stable equilibrium state at any given time if the initial values of both the total pressure perturbation and the cross-sectional area variation satisfy certain constraints. Finally, the temporal evolution of the loop system is studied when the initial condition corresponds to a static equilibrium solution.",
        "watermark_text": "The stability , equilibrium states and the dynamic behavior of sun coronal loops are examined by using thermodynamic irreversible energy techniques to an idealized model loop system with constant cross section . The controlling equations for this problem are derived in terms of the total pressure perturbation inside the loop as also as its cross - sectional area change along the loop length .It is demonstrated that these two variables can be described in terms of each other through a nonlinear differential equation which explains the evolution of the loop system . This equation has been solved numerically under various initial conditions corresponding to several physical contexts .In particular , it is found that the loop could either increase or contract depending on whether the initial value of the total pressure perturbation is positive or negative respectively . Furthermore , the results show that there exists only one stable equilibrium state at any certain time if the early values of both the total stress perturbation and the inter - sectional region variation satisfy certain constraints .Finally , the temporal evolution of the loop system is studied when the first situation corresponds to a static equilibrium solution .",
        "ori-fast-z-score": -0.5129891760425771,
        "water-fast-z-score": 4.694855340334425
    },
    {
        "original_text": "We present an explanation for the excess in gamma-ray emission observed by the Energetic Gamma Ray Experiment Telescope (EGRET) at energies above 10 GeV, which is known as the  GeV anomaly . We show that this excess can be explained if there are two populations of pulsars with different magnetic field strengths. The first population consists of young pulsars whose fields decay rapidly due to their rapid spin-downs. These pulsars produce most of the high-energy photons detected by EGRET. The second population consists of older pulsars whose fields have decayed more slowly because they rotate slower than younger pulsars on average. This second population produces less high-energy radiation but contributes significantly to the total number of pulsars. Our model predicts that Fermi should detect many new pulsar candidates not seen before. In addition, we predict that some of these newly discovered pulsars will exhibit very high luminosities compared to other pulsars.",
        "watermark_text": "We present an excuse for the surplus in gamma - ray radiation observed by the Energetic Gamma Ray Experiment Telescope ( EGRET ) at energies above 10 GeV , which is known as the GeV anomaly . We see that this excess can be described if there are two communities of pulsars with varying magnetic force abilities .The first population contains of young pulsars whose fields collapse rapidly due to their quick spinning - downs . These pulsars produce most of the high - energy photons discovered by EGRET .The second population contains of older pulsars whose fields have decayed more slowly because they rotate slower than younger pulsars on average . This second population generates less large - energy rays but amounts strongly to the total number of pulsars .Our model predicts that Fermi should detect many new pulsar prospects not seen before . In addition , we expect that some of these newly discovered pulsars will exhibit very high luminosities relative to other pulsars .",
        "ori-fast-z-score": 0.3721042037676254,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "We study how the evolution of the Carter constant depends on the spin and mass ratio in binary systems with spinning black holes, using numerical relativity simulations. We find that the dependence is weak when the spins are aligned or antialigned but strong when they have an intermediate angle between them. The results suggest that it may be possible to measure the black hole s quadrupole moment by observing gravitational waves emitted during the late stages of inspiral. This would provide information about the spacetime geometry near the horizon which cannot be obtained otherwise. \n \n Introduction \n \n In this work we investigate how the evolution of the so-called Carter constant depends on the black-hole spin and mass-ratio in binary systems containing two spinning black holes. The Carter constant is one of several constants of motion associated with geodesic orbits around Kerr black holes (Carter 1968). It can be used as a probe of the spacetime geometry close to the event horizon because its value changes significantly over time only if there exists significant deviation from spherical symmetry at small radii (Bardeen 1973; Thorne et al. 1986 ). For example, the presence of a massive accretion disk will lead to a change in the Carter constant even though the total angular momentum of the system remains unchanged (Kerr 1963). \n \n Previous studies have shown that the orbital evolution of binaries with non-spinning components is affected by the black-hole quadrupole moment Q = M(1 − S2)/c2R2 where S denotes the dimensionless spin parameter of each black hole (Damour & Nagar 1999) . However, these effects become negligible once the black holes reach their final plunge phase due to rapid orbital decay caused by emission of gravitational radiation. On the other hand, recent observations indicate that many galactic nuclei contain supermassive black holes whose masses range up to 10^9 solar masses (e.g., Gebhardt et al. (2000)). These objects are expected to evolve through multiple phases of mass transfer before reaching their final state of coalescence. During such evolutionary processes, the black holes could acquire large amounts of angular momentum via tidal interactions and/or",
        "watermark_text": "We research how the evolution of the Carter constant depends on the spin and mass ratio in binary systems with twisting black holes , using numerical relativity simulations . We see that the dependence is weak when the spins are aligned or antialigned but weak when they have an intermediate inclination between them .The results propose that it could be possible to measure the dark hole s quadrupole point by observing gravitational waves emitted during the last phases of inspiral . This might give information about the spacetime geometry near the horizon which cannot be obtained otherwise .Introduction In this study we investigate how the evolution of the so - called Carter constant depends on the dark - hole spin and mass - ratio in binary systems surrounding two spin black holes . The Carter constant is one of several constants of movement associated with geodesic orbits around Kerr white holes ( Carter 1968 ) .It can be used as a probe of the spacetime geometry next to the event horizon because its value changes significantly over time only if there exists significant deviation from spherical symmetry at small radii ( Bardeen 1973 ; Thorne et al . 1986 ) .For instance , the presence of a huge accretion wheel will result to a change in the Carter constant even though the total angular velocity of the system stays unchanged ( Kerr 1963 ) . Earlier investigations have shown that the orbital evolution of binaries with non - spinning components is affected by the dark - hole quadrupole moment Q = M ( 1 − S2 ) / c2R2 where S indicates the dimensionless spin variable of each dark hole ( Damour & Nagar 1999 ) .However , these consequences get negligible once the dark holes reach their final plunge period due to rapid orbital decay caused by absorption of gravitational rays . On the other hand , recent observations indicate that several galactic nuclei contain supermassive black holes whose masses range up to 10 ^ 9 solar masses ( e . g . , Gebhardt et al .( 2000 ) ) . These bodies are expected to evolve through several stages of mass transfer before reaching their final position of coalescence .During such evolutionary processes , the dark holes could acquire large quantities of angular velocity via tidal interactions and / or",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 7.976435884012652
    },
    {
        "original_text": "We study nonequilibrium spin dependent transport properties of normal-metal-superconductor (NS) and ferromagnet-superconductor (FS) hybrid systems by using the quasiclassical theory for diffusive conductors with spin-orbit scattering. We show that, due to the proximity effect induced pair correlations between electrons on opposite sides of NS interface, there is an additional contribution to the current density which depends on the relative orientation of magnetizations in F and S layers. This results in appearance of the anomalous Josephson-like current-phase relation in FS junctions. In addition we find that the Andreev reflection at NS interfaces can be strongly suppressed if the angle between magnetization directions in N and S regions becomes sufficiently large. The suppression of Andreev reflection leads to the reduction of conductance through NS junction as compared to its value in equilibrium state. \n \n Finally, we discuss possible experimental realizations of our predictions.",
        "watermark_text": "We research nonequilibrium spin dependent transport properties of normal - copper - superconductor ( NS ) and ferromagnet - superconductor ( FS ) hybrid systems by using the quasiclassical principle for diffusive conductors with spin - orbit scattering . We see that , owing to the proximity effect induced pair correlations between electrons on opposite ends of NS interface , there is an additional contribution to the current density which depends on the relative position of magnetizations in F and S layers .This results in appearance of the anomalous Josephson - like current - phase connection in FS junctions . In addition we find that the Andreev reflection at NS interfaces can be highly suppressed if the angle between magnetization directions in N and S areas becomes enough large .The disruption of Andreev reflection results to the reduction of conductance through NS intersection as compared to its value in equilibrium state . Finally , we explain possible experimental realizations of our predictions .",
        "ori-fast-z-score": 1.3858697343671664,
        "water-fast-z-score": 5.417490779798923
    },
    {
        "original_text": "We study the advantages and disadvantages of composite Higgs models in four dimensions (4D) versus five dimensions (5D). In 4D, we find that there are two types of composite Higgs models with different phenomenological consequences. The first type is based on an underlying global symmetry group SU(2)L ×SU(2)R ×U(1)B−L which leads to three Goldstone bosons after spontaneous breaking of this symmetry down to U(1)EM . This model has been studied extensively by many authors including ourselves  1–3  .\nThe second type is based on an extended gauge symmetry group SU(3)C ×SU(2)L ×U(1)Y ×Z′ where Z′ is a new abelian gauge factor associated with extra spatial dimension  4–6  . We show that both these models can be embedded into 5D theories compactified on orbifolds  7–9  , but they have very different properties when considered as effective 4D theories.",
        "watermark_text": "We research the advantages and disadvantages of composite Higgs systems in four dimensions ( 4D ) vs five dimensions ( 5D ) . In 4D , we find that there are two forms of composite Higgs theories with varying phenomenological consequences .The first class is based on an underlying global symmetry class SU ( 2 ) L ×SU ( 2 ) R ×U ( 1 ) B−L which results to three Goldstone bosons after spontaneous breaking of this symmetry down to U ( 1 ) EM . This theory has been studied frequently by many writers including ourselves 1 – 3 .The second kind is based on an extended gauge symmetry class SU ( 3 ) C ×SU ( 2 ) L ×U ( 1 ) Y ×Z ′ where Z ′ is a new abelian gauge parameter identified with extra spatial dimension 4 – 6 . We see that both these models can be embedded into 5D theories compactified on orbifolds 7 – 9 , but they have very different properties when considered as efficient 4D theories .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.543441112511214
    },
    {
        "original_text": "The cosmological constant is one of the most important parameters in modern physics, and its value has been determined by observations to be extremely small but nonzero.  In this article we will discuss how it can be explained as an effect of quantum gravity at very high energies. We will also show that if the universe underwent inflationary expansion after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation (CMBR). Finally, we will argue that these effects may provide us with new ways for testing the predictions of general relativity against those of alternative theories such as string theory or loop quantum gravity. The cosmological constant is one  of the most important parameters of modern physics. Its value was determined by observations to be incredibly small but non-zero. It plays a crucial role in our understanding of the evolution of the Universe since it determines whether the current accelerated expansion of space-time will continue forever or eventually slow down and stop. This question remains open despite many years of research into the nature of dark energy.",
        "watermark_text": "The cosmological coefficient is one of the most important components in modern physics , and its value has been determined by observations to be extremely tiny but nonzero . In this page we will explore how it can be described as an influence of quantum gravitational at very high energies .We will also demonstrate that if the universe underwent inflationary inflation after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation ( CMBR ) . Finally , we will argue that these consequences may provide us with novel ways for testing the assumptions of general relativity against those of alternative theories such as string theory or loop quantum gravitational .The cosmological coefficient is one of the most important characteristics of modern physics . Its value was calculated by observations to be incredibly small but un - zero .It holds a crucial role in our understanding of the evolution of the Universe since it determines whether the present rapid expansion of space - time will continue forever or eventually halt down and stop . This question stays open despite many years of research into the nature of dark energy .",
        "ori-fast-z-score": 1.8225913092242512,
        "water-fast-z-score": 6.038635299392551
    },
    {
        "original_text": "We present new optical photometry for the open cluster NGC 6791, obtained with the Wide Field Camera 3 (WFC3) aboard HST as part of program GO-12775 (PI: A. Dotter). The data cover an area of 0.5 deg2 around the cluster center at high spatial resolution (0.1 arcsec/pixel), allowing us to study individual stars down to V = 20 mag. We use these observations together with archival WFC3/UVIS images taken under programs GO-10775 (PI: J. Kalirai) and GO-11775 (PI: S. Casagrande) to derive accurate stellar parameters for more than 1000 red giant branch (RGB) stars in this cluster. Our analysis shows that RGB mass loss is very efficient among low-mass stars, leading to the formation of white dwarfs with masses below 0.45 M . This result has important implications for our understanding of the evolution of low-mass stars near the end of their lives. \n \n Keywords: Open clusters",
        "watermark_text": "We present new optical photometry for the open cluster NGC 6791 , obtained with the Wide Field Camera 3 ( WFC3 ) aboard HST as part of series GO - 12775 ( PI : A . Dotter ) . The data cover an area of 0 . 5 deg2 around the cluster center at high spatial resolution ( 0 . 1 arcsec / pixel ) , allowing us to study individual stars down to V = 20 mag .We use these observations together with archival WFC3 / UVIS images took under programs GO - 10775 ( PI : J . Kalirai ) and GO - 11775 ( PI : S . Casagrande ) to derive exact stellar characteristics for more than 1000 red dwarf branch ( RGB ) stars in this cluster . Our study shows that RGB mass loss is very efficient among low - density stars , leading to the formation of white dwarfs with masses below 0 . 45 M .This result has significant implications for our understanding of the evolution of lowest - weight objects near the end of their careers . Keywords : Open clusters",
        "ori-fast-z-score": 1.8382900600361156,
        "water-fast-z-score": 4.727031582950012
    },
    {
        "original_text": "We present results on the gravitational wave emission during the final stages of black hole binary coalescence, when the holes are surrounded by an accretion disk and their orbital evolution is driven by radiation reaction. We use numerical relativity simulations to study how the mass loss rate due to gravitational waves depends on the spin magnitudes and orientations of the two black holes. Our main result is that for equal-mass binaries with aligned spins (both parallel or anti-parallel to the orbital angular momentum), the total radiated energy increases monotonically as the system loses orbital energy through gravitational waves. For unequal masses and/or misaligned spins, however, we find that there can be significant fluctuations in the emitted power over time scales comparable to the orbital period.  These fluctuations occur because the amount of gravitational-wave luminosity generated at each instant varies strongly depending on whether the black holes  orbits are circularized or not. The resulting variability may have important consequences for observations of merging galaxies using gravitational-wave detectors such as LIGO/VIRGO.",
        "watermark_text": "We see results on the gravitational wave radiation during the last phases of grey hole binary coalescence , when the holes are surrounded by an accretion disk and their orbital evolution is caused by radiation process . We use numerical relativity simulations to study how the mass loss rate due to gravitational waves depends on the spin magnitudes and orientations of the two white holes .Our main consequence is that for equal - mass binaries with aligned spins ( both parallel or anti - parallel to the orbital angular velocity ) , the total radiated energy rises monotonically as the system loses orbital energy through gravity signals . For unequal masses and / or misaligned spins , however , we find that there can be considerable fluctuations in the emitted energy over time ranges comparable to the orbital period .These fluctuations happen because the proportion of gravitational - wave luminosity generated at each instant varies strongly depending on whether the dark holes orbits are circularized or not . The produced variability may have important implications for observations of merging galaxies using gravitational - wave detectors such as LIGO / VIRGO .",
        "ori-fast-z-score": 1.0660035817780522,
        "water-fast-z-score": 5.7564193416014815
    },
    {
        "original_text": "In this talk, we will discuss the relationship between loop spaces and Langlands parameters in terms of their connections to representation theory.  We will begin by recalling some basic facts about loop spaces and their relation with infinite-dimensional Lie groups (e.g., loop groups).  Next, we ll recall how one can associate a certain type of infinite-dimensional Lie group called an affine Hecke algebra to any reductive algebraic group over a field k of characteristic 0.   Finally, we ll explain how these two ideas are related via the notion of a Harish-Chandra bimodule. The main result is that if G is a connected semisimple complex algebraic group defined over Q then there exists a natural isomorphism between the category of finite-dimensional representations of G(Q) and the category of Harish-Chandra modules for its associated affine Hecke algebra. This work was done jointly with David Vogan at Harvard University during my postdoctoral fellowship.",
        "watermark_text": "In this talk , we will explore the relationship between loop spaces and Langlands parameters in terms of their connections to representation theory . We will start by examining some fundamental details about loop spaces and their connection with infinite - dimensional Lie fields ( e . g . , loop spaces ) .Next , we ll remember how one can associate a certain type of infinite - dimensional Lie category called an affine Hecke algebra to any reductive algebraic ring over a field k of characteristic 0 . Finally , we ll explain how these two ideas are related via the notion of a Harish - Chandra bimodule .The main consequence is that if G is a connected semisimple complex algebraic ring defined over Q then there exists a natural isomorphism between the category of finite - dimensional representations of G ( Q ) and the category of Harish - Chandra modules for its associated affine Hecke algebra . This research was done jointly with David Vogan at Harvard University during my postdoctoral fellowship .",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 4.913538149119954
    },
    {
        "original_text": "The National Science Foundation (NSF) has recently formed an  Exoplanet Task Force  with the goal of identifying key science goals for future space missions in exoplanet research, including radio astrometry.  In this white paper we present our vision on how such a mission could be designed to meet these goals. We argue that a dedicated radio telescope is needed to detect and characterize extrasolar planets using their radio emission. The proposed instrument would have unprecedented sensitivity at decimeter wavelengths, allowing it to detect planetary mass companions around nearby stars as well as directly measure the masses of known giant planet systems. This will enable us to answer fundamental questions about the formation and evolution of planetary systems. Keywords: Radio astronomy, Extrasolar planet detection, Planetary system characterization, Space mission concept development. 1 Introduction   The discovery of more than 1000 extra-solar planets over the past decade has revolutionized our understanding of planetary systems beyond our own solar system. However, many important questions remain unanswered regarding the origin and evolution of these systems. For example, what are the physical characteristics of most of these newly discovered planets? How do they form? What happens when two or more planets interact gravitationally? Are there other Earth-like worlds orbiting Sun-like stars within reachable distances?  Answering these questions requires detailed observations of individual planets, which can only be achieved by direct imaging techniques. Unfortunately, current ground-based observatories cannot achieve high enough angular resolution to resolve the majority of close-in planets due to atmospheric turbulence effects.   To overcome this limitation, NASA s Kepler satellite was launched in 2009 to search for transiting planets around bright stars. Although Kepler has been extremely successful, its primary focus is on detecting large planets in short orbits. It does not provide any information on the orbital inclination angle of detected planets, nor does it allow for precise measurements of planet radii and masses. Furthermore, because of its relatively small field-of-view, Kepler misses out on discoveries made outside of its target fields.",
        "watermark_text": "The National Science Foundation ( NSF ) has recently established an Exoplanet Task Force with the objective of identifying key research goals for future orbital flights in exoplanet research , notably broadcast astrometry . In this white paper we present our vision on how such a spacecraft could be designed to meet these objectives .We argue that a dedicated radio telescope is required to identify and characterize extrasolar planets using their radio emission . The proposed instrument would have enormous sensitivity at decimeter wavelengths , allowing it to identify planetary mass companions around nearby planets as well as closely determine the masses of known giant planet systems .This will provide us to answer basic concerns about the formation and evolution of planetary networks . Keywords : Radio astronomy , Extrasolar moon discovery , Planetary network detection , Space mission design development .1 Introduction The observation of more than 1000 extra - solar planets over the previous decade has revolutionized our understanding of planetary structures beyond our own solar system . However , many important questions remain unanswered concerning the origin and evolution of these systems .For instance , what are the natural characteristics of most of these newly discovered planets ? How do they create ?What happens when two or more planets interact gravitationally ? Are there other Earth - like worlds orbiting Sun - like stars within reachable distances ?Answering these problems demands full observations of multiple worlds , which can only be obtained by direct observation techniques . Unfortunately , current ground - based observatories cannot achieve high enough angular resolution to identify the majority of close - in planets owing to air turbulence influences .To solve this limitation , NASA s Kepler satellite was launched in 2009 to search for transiting planets around bright stars . Although Kepler has been extremely successful , its primary emphasis is on detecting large planets in small orbits .It does not offer any info on the orbital inclination ratio of detected planets , nor does it enable for precise observations of planet radii and masses . Furthermore , because of its relatively small field - of - view , Kepler misses out on discoveries made outside of its target areas .",
        "ori-fast-z-score": 0.38691161626706844,
        "water-fast-z-score": 8.329938702528295
    },
    {
        "original_text": "We present the results of an extensive search for new globular cluster candidates (GPCs) in the outer halo of M31, based on deep HST/ACS images covering about one quarter of its virial radius. We find that the number density profile of GPCs is well described by a power law with index -1.5 ± 0.1 out to at least 100 kpc. The total number of GPCs within this region amounts to N = 1253±60, which corresponds to a specific frequency S=N/M*=(3.2±0.4)×10−3. This value agrees very well with previous estimates obtained using ground-based data. In addition we identify two previously unknown distant clusters located at projected distances of more than 300 kpc from the center of M31. These objects are among the most luminous known GCs outside our Galaxy. Their integrated magnitudes are mF814W≈−10 mag and their half-light radii range between r h ≈6 pc and r h ≈20 pc.",
        "watermark_text": "We present the conclusion of an extensive search for new globular cluster candidates ( GPCs ) in the exterior halo of M31 , using on dark HST / ACS images covering about one quarter of its virial diameter . We see that the number density profile of GPCs is well described by a power law with index - 1 . 5 ± 0 . 1 out to at least 100 kpc .The total number of GPCs within this area amounts to N = 1253±60 , which corresponds to a certain frequency S = N / M * = ( 3 . 2±0 . 4 ) ×10−3 . This value agrees very best with previous calculated obtained using ground - based data .In addition we identify two formerly unidentified distant clusters situated at projected distances of more than 300 kpc from the center of M31 . These bodies are among the most luminous known GCs outside our Galaxy .Their integrated magnitudes are mF814W≈−10 mag and their half - light radii vary between p h ≈6 pc and p h ≈20 pc .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.810003810005715
    },
    {
        "original_text": "We present new spectroscopic observations for more than 1000 Galactic OB supergiants, obtained with FLAMES/GIRAFFE at the Very Large Telescope (VLT). The sample includes all known O-type dwarfs and giants as well as B-type supergiants brighter than about Mbol = -4 mag within 25 pc distance to Earth. We derive atmospheric parameters T eff , log g, microturbulence velocity vmic, and chemical composition including nitrogen abundance  N/Fe  . For comparison we also analyse a large number of Galactic red supergiants observed by GOSSS project using similar methods. Our results show that there is no significant difference between the mean values of these quantities derived for both samples. However, our analysis reveals systematic differences between different studies based on smaller samples published so far. In particular, we find that the majority of previous investigations overestimated the temperatures of hotter objects due to neglecting non-LTE effects or underestimating gravities because they did not take into account stellar winds.",
        "watermark_text": "We present new spectroscopic observations for more than 1000 Galactic OB supergiants , obtained with FLAMES / GIRAFFE at the Very Large Telescope ( VLT ) . The sample comprises all known O - class dwarfs and giants as well as B - class supergiants hotter than about Mbol = - 4 mag within 25 pc proximity to Earth .We derive air parameters T eff , log g , microturbulence velocity vmic , and biological composition including nitrogen density N / Fe . For comparison we also analyse a large number of Galactic red supergiants detected by GOSSS program use similar methods .Our results show that there is no considerable difference between the mean readings of these quantities generated for both samples . However , our analysis reveals systematic differences between various surveys relying on smaller specimens publications so far .In particular , we find that the majority of previous investigations overestimated the temperatures of hotter objects due to neglecting non - LTE effects or underestimating gravities because they did not take into account galaxy winds .",
        "ori-fast-z-score": 1.9123657749350298,
        "water-fast-z-score": 6.215188768538847
    },
    {
        "original_text": "We study the phase diagram and electronic structure of bilayer ruthenate Sr3Ru2O7 using density functional theory (DFT) calculations, which show that this material is close to an insulator-metal transition driven by charge transfer between layers. We find that the Fermi surface topology changes dramatically across the metal-insulator boundary, with the appearance of new hole pockets at the Brillouin zone center. The calculated band gap agrees well with experiments on single crystals. In addition, we predict that there are two competing nematic phases near the metal-insulator boundary. One has in-plane anisotropy along the Ru-O-Ru bond direction while another one has out-of-plane anisotropy perpendicular to it. These results provide insights into the origin of the observed structural distortion in bilayer ruthenates. Bilayer ruthenates have attracted considerable attention recently due to their rich physical properties including unconventional superconductivity  1  , quantum criticality  2  , and multiferroicity  3  . Among these materials, Sr3Ru2O7 shows particularly interesting behavior because its ground state can be tuned continuously from metallic to insulating states through chemical doping or applying pressure  4  .\nIn recent years, several experimental studies have been performed to investigate the nature of the metal-insulator transition (MIT). For example, angle resolved photoemission spectroscopy measurements  5  found that the Fermi surface topology changed significantly when crossing the MIT line. X-ray scattering  6  showed that the crystal symmetry was lowered from tetragonal to orthorhombic below TMI = 160 K. Neutron scattering  7  revealed that the lattice parameters were different for the ab plane and c axis below TMIT ~ 150 K. However, despite extensive investigations, the microscopic mechanism behind the MIT remains unclear  8  .",
        "watermark_text": "We research the phase diagram and electronic structure of bilayer ruthenate Sr3Ru2O7 using density functional theory ( DFT ) observations , which show that this metal is close to an insulator - iron transition accelerated by charge transfer between layers . We see that the Fermi boundary topology changes dramatically across the metal - insulator boundary , with the emergence of new hole pockets at the Brillouin zone center .The measured band gap agrees well with experiments on single crystals . In addition , we estimate that there are two rival nematic phases near the metal - insulator boundary .One has in - plane anisotropy along the Ru - O - Ru bond direction while another one has out - of - plane anisotropy diagonal to it . These conclusions provide insights into the origin of the reported structural degradation in bilayer ruthenates .Bilayer ruthenates have garnered considerable scrutiny lately owing to their valuable physical properties including unconventional superconductivity 1 , quantum criticality 2 , and multiferroicity 3 . Among these structures , Sr3Ru2O7 shows particularly exciting behavior because its ground state can be tuned continuously from metallic to insulating states through chemical doping or applying tension 4 .In recent years , various experimental studies have been performed to examine the nature of the metal - insulator transition ( MIT ) . For instance , angle resolution photoemission spectroscopy measurements 5 found that the Fermi surface topology changed significantly when crossing the MIT line .X - ray scattering 6 revealed that the crystal symmetry was changed from tetragonal to orthorhombic below TMI = 160 K . Neutron propagation 7 revealed that the crystal conditions were different for the ab plane and c axis below TMIT ~ 150 K . However , despite extensive investigations , the microscopic process behind the MIT remains unsure 8 .",
        "ori-fast-z-score": 0.9838699100999074,
        "water-fast-z-score": 7.244860247099318
    },
    {
        "original_text": "The second law of thermodynamics is one of the most important laws in physics, which states that entropy always increases with time for closed systems. In this work we present an experimental proof of the second law based on volume entropy and mechanical energy dissipation. We show how to measure volume entropy by using two different methods (one direct method and another indirect method) and then compare these results with theoretical predictions. The experiments are performed at room temperature and atmospheric pressure conditions. Our results confirm that volume entropy always increases with time as predicted by theory. This result also confirms that our measurement system works properly. Finally, we discuss some possible applications of our approach. The second law of thermodynamics has been studied extensively over many years  1  . It states that entropy always increases when matter undergoes irreversible processes  2  , such as heat transfer or chemical reactions  3  .\nIn recent decades there have been several attempts to prove experimentally the validity of the second law  4  -  8  . However, none of them were able to provide a complete proof because they did not take into account all relevant physical quantities involved  9  . For example, it was shown theoretically  10  that volume entropy should be included in order to obtain a complete description of the process under study  11  . Therefore, in this work we propose a new experiment aimed at proving the second law of thermodynamics by measuring volume entropy directly  12  .",
        "watermark_text": "The second rule of thermodynamics is one of the most important rules in science , which says that entropy often increases with time for closed systems . In this study we present an experimental confirmation of the second law based on volume entropy and mechanical energy dissipation .We see how to measure volume entropy by using two different methods ( one direct technique and another indirect method ) and then match these results with theoretical estimates . The studies are performed at room temperature and atmospheric pressure environments .Our results verify that mass entropy often increases with time as predicted by theoretical . This result also proves that our measurement network works well .Finally , we explain some possible applied of our approach . The second law of thermodynamics has been studied frequently over numerous years 1 .It says that entropy often increases when matter undergoes irreversible processes 2 , such as heat transfer or molecular compounds 3 . In recent millennium there have been numerous attempts to prove experimentally the legitimacy of the second law 4 - 8 .However , none of them were could to provide a complete confirmation because they did not take into consideration all relevant physical substances involved 9 . For instance , it was shown theoretically 10 that volume entropy should be included in order to obtain a complete model of the process under experiment 11 .Therefore , in this study we undertake a new study aiming at discovering the second law of thermodynamics by observing volume entropy directly 12 .",
        "ori-fast-z-score": -1.4855627054164149,
        "water-fast-z-score": 7.24191812652287
    },
    {
        "original_text": "We present near-infrared (NIR) spectroscopy and photometry for the young open cluster IRAS 18511+0146; we find that it is likely to be an intermediate mass star forming region, with a total luminosity of ~10^6 L_Sun . We identify two distinct populations in this cluster; one population has spectral types ranging between F0-F5V, while another population shows signs of emission lines indicative of accretion disks around pre-main sequence stars. The latter group appears to have ages less than 10 Myr based on their H-R diagram positions. This suggests that these are very young objects which may still be embedded within their natal molecular cloud. Using N-body simulations, we show that such clusters can evolve into open clusters like those observed today if they survive disruption by tidal forces during their formation process. In addition, we also estimate the age spread among members of our sample using the equivalent widths of Pa-alpha line profiles as well as the strength of the Brackett gamma line.",
        "watermark_text": "We present near - infrared ( NIR ) spectroscopy and photometry for the early open object IRAS 18511 + 0146 ; we find that it is probably to be an intermediate mass star producing zone , with a total luminosity of ~ 10 ^ 6 L _ Sun . We distinguish two different populations in this cluster ; one population has spectral classes ranging between F0 - F5V , while another population shows signs of emission lines indicative of accretion disks around post - principal sequence stars .The latter group appears to have ages less than 10 Myr based on their H - R diagram positions . This implies that these are very young objects which perhaps still be embedded within their natal molecular cloud .Using N - bodies simulations , we find that such clusters can evolve into open complexes like those observed nowadays if they survive disruption by waves forces during their formed phase . In addition , we also predict the age distribution among members of our sample using the equivalent widths of Pa - alpha line profiles as well as the strength of the Brackett alpha line .",
        "ori-fast-z-score": -0.6793662204867574,
        "water-fast-z-score": 4.387842813611494
    },
    {
        "original_text": "We present new infrared (IR) photometry for the galaxy cluster MS1054-03 at z = 0.83, obtained with ISOCAM on board ISO. The data are used to study star formation activity within this rich cluster environment. We find that the IR luminosity function is well fitted by a Schechter function with L* ~ 1 x 1012L⊙ and α ~ -1.7 over the range 8-1000 µm. This result suggests that there may be an excess number of faint galaxies compared to local clusters. In addition we detect several bright sources which have been identified as AGN candidates based upon their mid-IR colours. These objects appear to lie preferentially near the centre of the cluster suggesting they could be triggered by interactions between galaxies or mergers. Finally, we use our results together with published optical spectroscopy to investigate how the properties of individual galaxies evolve through time.",
        "watermark_text": "We report new infrared ( IR ) photometry for the galaxy region MS1054 - 03 at z = 0 . 83 , obtained with ISOCAM on board ISO . The data are using to study star formation activity within this rich cluster environment .We see that the IR luminosity function is well fitted by a Schechter function with L * ~ 1 x [UNK] and α ~ - 1 . 7 over the range 8 - 1000 µm . This result suggests that there may be an surplus amount of faint objects compared to nearby clusters .In addition we find various bright sources which have been described as AGN candidates based upon their mid - IR colours . These items seem to lay preferentially near the centre of the cluster suggesting they may be triggered by interactions between objects or mergers .Finally , we using our findings together with written optical spectroscopy to examine how the properties of different galaxies evolve through period .",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "The fine structure of solar prominences is studied by using the data obtained with the Swedish 1-meter Solar Telescope (SST). The observations are made in Hα and Ca II 8542 Å lines, which show that the fine structures have different shapes depending on their locations relative to the magnetic field. In addition, we find that there exist two types of fine structures; one type has an elongated shape along the direction parallel to the local magnetic field while another type shows a roundish shape perpendicularly to it. We also found that some fine structures appear as if they were twisted around each other. These results suggest that the fine structures may be formed due to the plasma flows driven by magnetic reconnection between neighboring flux tubes. Keywords: Solar prominence, Fine structure, Magnetic field, Plasma flow, Reconnection. 1 Introduction Solar prominences are observed as dark features against the bright background of the photosphere. They are thought to consist mainly of cool dense plasma suspended above the solar surface by magnetic fields (Kippenhahn & Schlüter 1957) . It was suggested that the fine structures seen within solar prominences might be caused by the plasma flows driven by the magnetic reconnection between neighboring magnetic flux tubes (Pneuman 1983 , Kuperus et al. 1981 . However, the detailed physical processes involved in this process remain unclear because of lack of observational evidence for such phenomena. Recently, high-resolution observations of solar prominences have been performed with various instruments including the Swedish 1-meter solar telescope (SST) (Lin et al. 1998a) , the Advanced Stokes Polarimeter (ASP) at Big Bear Solar Observatory (BBSO), and the Hinode satellite (Kosugi et al. 2007 ). Using these new data sets, several authors reported the observation of fine structures having different shapes depending on their positions relative to the magnetic field (Lin et al. 1998b , Lin 2004 , Berger et al. 2008 .\nIn this study, we investigate the fine structures of solar prominences based on the SST data set. Our aim is to",
        "watermark_text": "The fine structure of sun prominences is studied by using the information obtained with the Swedish 1 - meter Solar Telescope ( SST ) . The surveys are making in Hα and Ca II 8542 Å lines , which show that the fine structures have different shapes depending on their regions relative to the magnetic force .In addition , we find that there exist two forms of fine structures ; one sort has an elongated form along the direction parallel to the local magnetic force while another type gives a roundish shape perpendicularly to it . We additionally found that some fine structures appear as if they were twisted around each other .These data suggest that the fine structures could be formed owing to the plasma flows driven by magnetic reconnection between neighboring flux tubes . Keywords : Solar prominence , Fine structure , Magnetic field , Plasma movement , Reconnection .1 Introduction Solar prominences are observed as dark features against the bright background of the photosphere . They are said to consist mostly of cold dense liquid suspended above the solar surface by magnetic waves ( Kippenhahn & Schlüter 1957 ) .It was suggested that the fine structures visible within solar prominences might be caused by the plasma flows driven by the magnetic reconnection between neighboring magnetic flux tubes ( Pneuman 1983 , Kuperus et al . 1981 .However , the detailed physical processes responsible in this process remain uncertain because of lack of observational evidence for such events . Recently , large - resolution measurements of sun prominences have been performed with various instruments including the Swedish 1 - meter solar observatory ( SST ) ( Lin et al .1998a ) , the Advanced Stokes Polarimeter ( ASP ) at Big Bear Solar Observatory ( BBSO ) , and the Hinode satellite ( Kosugi et al . 2007 ) .Using these new data sets , various scientists reported the observation of fine structures having different shapes depending on their orientation relative to the magnetic force ( Lin et al . 1998b , Lin 2004 , Berger et al .2008 . In this study , we investigate the fine structures of solar prominences based on the SST results setting .Our aim is to",
        "ori-fast-z-score": 1.5360589585634423,
        "water-fast-z-score": 7.897065047448726
    },
    {
        "original_text": "We present an analytic model for the evolution of the 21 cm brightness temperature fluctuations during cosmic reionization, based on correlated random walks (CRWs). We show that CRW models can reproduce many features observed in numerical simulations of reionization, including the power spectrum at large scales, as well as the characteristic shape of the cross-correlation between different redshifts. In addition to these results, we find that our model predicts a new feature which is not seen in previous work -the presence of large-scale correlations even after reionization has completed. This effect may be detectable with future radio telescopes such as SKA. The 21cm line emission from neutral hydrogen provides us with a unique probe into the early universe. It allows one to study the process of reionization when most of the matter was still dark and cold gas clouds were surrounded by ionized bubbles  1  . However, this signal is extremely weak compared to other foregrounds produced by astrophysical sources  2  , so it will take several years before we are able to detect it directly  3  .\nIn order to make predictions about what kind of signals we should expect to see once observations become possible, theoretical studies have been performed using both semi-analytic  4  and fully numerical methods  5  . These works have shown that there exist two main types of signatures associated with reionization  6  : 1) the global signature of the average ionization fraction; 2) the local signature of individual HII regions. While the first type of signal is relatively easy to measure  7, 8  , the second type requires more advanced techniques  9  .",
        "watermark_text": "We present an analytic model for the evolution of the 21 cm brightness temperature fluctuations during cosmic reionization , using on correlated random tours ( CRWs ) . We suggest that CRW models can generate several characteristics witnessed in mathematical simulations of reionization , notably the power spectrum at large scales , as well as the typical shape of the cross - correlation between various redshifts .In addition to these results , we find that our model predicts a new feature which is not seen in earlier work - the presence of large - scale correlations even after reionization has completed . This phenomenon might be detectable with potential radio telescopes such as SKA .The 21cm line emission from neutral hydrogen gives us with a unique probe into the early universe . It enables one to study the process of reionization when most of the matter was still dark and cold gas clouds were covered by ionized bubbles 1 .However , this signal is incredibly faint compared to other foregrounds caused by astrophysical sources 2 , so it will take many years before we are able to locate it directly 3 . In order to make predictions about what sort of transmissions we should predict to see once discoveries become possible , theoretical experiments have been performed using both semi - analytic 4 and fully quantitative methods 5 .These works have shown that there exist two principal kinds of signatures identified with reionization 6 : 1 ) the global signature of the average ionization fraction ; 2 ) the local signature of individual HII domains . While the first sort of signal is fairly easy to measure 7 , 8 , the second kind needs more advanced techniques 9 .",
        "ori-fast-z-score": -0.4508348173337161,
        "water-fast-z-score": 6.286185570937122
    },
    {
        "original_text": "The theta + (θ+) effect has been observed by many authors, but it was never explained satisfactorily.  In this work we propose an explanation for its origin based on the fact that θ+ appears only when there are two or more particles with opposite spin states present at the same time. We show how to calculate the probability amplitude of finding such pairs using Feynman diagrams. The results obtained agree well with those reported experimentally. This article is available from: http://arxiv.org/abs/1401.5189. The theta + (θ+ ) effect  1  , which consists of a small increase in the intensity of the scattered beam as compared to the unscattered one, has been observed by several authors  2  -  4  . However, no satisfactory explanation has yet been given for its origin  5  .\nIn this work we propose an interpretation for the appearance of θ+ based on the fact that it occurs only if there are simultaneously two or more particles with different spins  6  . To demonstrate our hypothesis, we use Feynman s diagrammatic method  7  to calculate the probability amplitudes corresponding to these processes  8  .",
        "watermark_text": "The theta + ( θ + ) effect has been observed by many writers , but it was never described satisfactorily . In this study we propose an reason for its origin relying on the fact that θ + occurs only when there are two or more electrons with opposite spin states present at the same time .We see how to estimate the probability amplitude of finding such pairs using Feynman diagrams . The results collected accord well with those published experimentally .This section is accessible from : www : / / arxiv . org / abs / 1401 . 5189 . The theta + ( θ + ) effect 1 , which consists of a small increase in the frequency of the scattered beam as compared to the unscattered one , has been observed by many writers 2 - 4 .However , no satisfactory alternative has yet been given for its identity 5 . In this study we propose an interpretation for the appearance of θ + based on the fact that it exists only if there are simultaneously two or more particles with different spinning 6 .To show our theory , we utilize Feynman s diagrammatic method 7 to estimate the probability amplitudes corresponding to these processes 8 .",
        "ori-fast-z-score": -0.7171371656006361,
        "water-fast-z-score": 5.5778737935111105
    },
    {
        "original_text": "We present an algorithm for clustering graphs based on their patterns, which are represented as lattices. The proposed method is applied to analyze the similarity between chemical compounds and protein structures. We show that our approach can be used to identify similar substructures within large databases efficiently. In addition, we demonstrate how it can be utilized to detect structural changes caused by mutations or modifications. Our experiments reveal that the presented technique outperforms state-of-the-art methods significantly both in terms of accuracy and efficiency. Clustering algorithms have been widely studied in many fields such as data mining  1  , bioinformatics  2  , computer vision  3  , etc., due to its importance in discovering hidden information  4  . However, most existing approaches focus only on finding clusters without considering any additional information about them  5  .\nIn this work, we propose a novel graph clustering algorithm called CLUSTERING WITH LATTERS (CLL)  6  , which takes advantage of lattice representation  7, 8  to capture the pattern of each cluster. As shown in Figure 1 , CLL first transforms all input graphs into their corresponding lattices using a set of predefined rules  9  . Then, it performs hierarchical agglomerative clustering  10  over these lattices to find groups of similar graphs. Finally, it assigns each group to one cluster according to the majority vote among all members belonging to the same group  11  .",
        "watermark_text": "We present an algorithm for clustering graphs based on their patterns , which are represented as lattices . The proposed approach is applied to analyze the similarity between chemical molecules and protein compounds .We suggest that our approach can be used to identify similar substructures within large databases accurately . In addition , we prove how it can be employed to identify structural modifications affected by genes or modifications .Our experiments indicate that the offered technique outperforms state - of - the - art methods significantly both in terms of precision and efficiency . Clustering methods have been widely explored in multiple fields such as data extraction 1 , bioinformatics 2 , computer vision 3 , etc . , owing to its significance in discovering secret information 4 .However , most existing techniques concentrate only on discovering clusters without examining any additional information about them 5 . In this research , we propose a new graph clustering procedure entitled CLUSTERING WITH LATTERS ( CLL ) 6 , which uses advantage of lattice representation 7 , 8 to capture the rhythm of each cluster .As seen in Figure 1 , CLL initially transforms all input graphs into their appropriate lattices using a setting of predefined rules 9 . Then , it performs hierarchical agglomerative clustering 10 over these lattices to find groups of related graphs .Finally , it gives each group to one grouping due to the majority vote among all members belonging to the same group 11 .",
        "ori-fast-z-score": -0.9901475429766744,
        "water-fast-z-score": 6.798772019333623
    },
    {
        "original_text": "The GRI (Gamma Ray Imager) is an astrophysics space observatory proposed by the French Space Agency CNES and NASA to study gamma-ray bursts, active galactic nuclei and other phenomena in high-energy astronomy.  It will be launched on a Soyuz rocket with a Fregat upper stage into a Sun-Earth L2 orbit at 1 AU distance from Earth. Its main instrument consists of two coded mask telescopes observing simultaneously in the energy range 20 MeV - 300 GeV. Each telescope has a large field-of-view of 2 steradians and a spatial resolution better than 0.1 degrees. A third detector module provides additional information about the background radiation environment for each telescope. This article describes the design concept of this innovative instrument. Keywords: Astroparticle physics, High-Energy Astronomy, Instrumentation, Space Observatory. Introduction:  The GRI (Gamma Ray...  more ",
        "watermark_text": "The GRI ( Gamma Ray Imager ) is an astrophysics space observatory proposed by the French Space Agency CNES and NASA to study alpha - ray clusters , active galactic nuclei and other processes in high - energy astronomy . It will be launched on a Soyuz rocket with a Fregat upper stage into a Sun - Earth L2 orbit at 1 AU distance from Earth .Its main object consists of two coded mask telescopes observing simultaneously in the power range 20 MeV - 300 GeV . Each observatory has a large field - of - view of 2 steradians and a spatial resolution best than 0 . 1 degrees .A third detector module presents additional information about the background radiation conditions for each telescope . This page describes the design concept of this innovative instrument .Keywords : Astroparticle science , High - Energy Astronomy , Instrumentation , Space Observatory . Introduction : The GRI ( Gamma Ray . . . more",
        "ori-fast-z-score": 1.3363062095621219,
        "water-fast-z-score": 4.008918628686366
    },
    {
        "original_text": "We present an analysis of the connection between different galaxy types using data from the Sloan Digital Sky Survey (SDSS). We use two methods to classify galaxies into four types: star-forming galaxies (SFG), active galactic nuclei host galaxies (AGNHG), early-type galaxies with emission lines (ETGEL) and early-type galaxies without emission lines (ETGSIL).\nThe first method is based on the principal component analysis (PCA) applied to the optical spectra of all galaxies classified as spectroscopic targets by the SDSS pipeline. The second one uses the PCA applied only to the subset of galaxies that are morphologically selected for having bulges dominated by old stellar populations. In both cases we find that ETGs form a continuous sequence in terms of their spectral properties along which SFGs evolve towards ETGSILs through ETGELs. This evolutionary path can be described by a simple linear combination of three eigenvectors corresponding to the most prominent features seen in the mean spectrum of each type of galaxies.",
        "watermark_text": "We present an assessment of the link between various galaxy kinds use data from the Sloan Digital Sky Survey ( SDSS ) . We use two means to classify objects into four types : star - creating galaxies ( SFG ) , active galactic nuclei guest galaxies ( AGNHG ) , early - class galaxies with emitted lines ( ETGEL ) and early - class galaxies without absorption lines ( ETGSIL ) .The first method is based on the main component analysis ( PCA ) applied to the optical spectra of all galaxies designated as spectroscopic targets by the SDSS pipeline . The second one uses the PCA applicable only to the subset of stars that are morphologically selected for having bulges dominated by ancient stars populations .In both cases we find that ETGs form a continuous progression in terms of their spectral properties along which SFGs grow towards ETGSILs through ETGELs . This evolutionary progression can be described by a simple linear mixture of three eigenvectors corresponding to the most notable features found in the mean spectrum of each type of galaxies .",
        "ori-fast-z-score": -0.808290376865476,
        "water-fast-z-score": 4.73427220735493
    },
    {
        "original_text": "We present Spitzer Space Telescope observations at 24, 70, and 160 microns for 12 members of the nearby (140 pc) Taurus star-forming region with ages between 1 Myr to 10 Myr. We find that all sources show excess emission above photospheric levels indicative of circumstellar material surrounding each star. The majority of these objects are surrounded by optically thick disks which can be fit well using single temperature blackbody models. However, we also identify three systems where the disk is likely to have an inner hole or gap; TW Hya, DM Tau, and GM Aur. In addition, we detect two transitional disks around V4046 Sgr and Sz 91. These results suggest that most stars in our sample retain their primordial disks up until at least 5 Myr after formation. Finally, we use mid-infrared spectroscopy obtained with the IRS instrument onboard Spitzer to study the composition of the dust grains in the disks.",
        "watermark_text": "We present Spitzer Space Telescope observations at 24 , 70 , and 160 microns for 12 members of the nearby ( 140 pc ) Taurus star - creating area with periods between 1 Myr to 10 Myr . We see that all sources show extra emitted above photospheric concentrations indicative of circumstellar material surrounding each star .The majority of these objects are surrounded by optically dense disks which can be fit well using single temperature blackbody studies . However , we also identify three components where the disk is expected to have an inner cavity or gap ; TW Hya , DM Tau , and GM Aur .In addition , we find two transitional disks around V4046 Sgr and Sz 91 . These data suggest that most stars in our sample maintain their primordial disks up until at least 5 Myr after formed .Finally , we utilize mid - infrared spectroscopy acquired with the IRS instrument onboard Spitzer to study the composition of the dust grains in the disks .",
        "ori-fast-z-score": 0.39056673294247163,
        "water-fast-z-score": 5.077367528252131
    },
    {
        "original_text": "We study the decoherence of macroscopic quantum superposition states in open systems, and show that it is possible to prepare such states with high fidelity using current experimental techniques.  We consider two different types of macroscopic superposition: coherent spin states (CSS) and Schrödinger cat states (SCS). For CSS we find that the decay rate scales as $1/N$ where $N$ is the number of particles involved in the state. This scaling law can be understood by considering the effect of spontaneous emission on each particle separately. In contrast for SCS the decay rate scales as $1/sqrt(N)$ which cannot be explained by treating individual particles independently. Instead we argue that this behavior arises due to collective effects between all particles in the system. Finally, we discuss how these results could be tested experimentally. Decoherence of macroscopic superposition states has been studied extensively over recent years  1–3  . It was shown theoretically  4  , and confirmed experimentally  5, 6  , that macroscopic superposition states are extremely fragile against environmental noise  7, 8  . The main reason behind their fragility lies in the fact that they involve many particles, so even small interactions with an environment lead to rapid loss of coherence  9  .\nIn this work we focus on studying the decoherence process of macroscopic superposition in open systems. Specifically, we consider two different types of superposition: coherent spin states  10  and Schrödinger cat-states  11  . Coherent spin states have already been prepared experimentally  12  while Schrödinger cat states remain elusive  13  . However, there exist proposals for preparing them  14–18  , and recently some progress towards realizing them has been made  19, 20  .  Our analysis shows that both types of superposition exhibit qualitatively similar behaviour under decoherence.",
        "watermark_text": "We explore the decoherence of macroscopic quantum superposition states in open systems , and suggest that it is easy to analyze such states with high fidelity using current experimental methods . We consider two different kinds of macroscopic superposition : coherent spinning states ( CSS ) and Schrödinger cat states ( SCS ) .For CSS we find that the decay rate scales as $ 1 / N $ where $ N $ is the quantity of particles affected in the state . This scaling law can be understood by using the effect of spontaneous emission on each particle separately .In comparison for SCS the decay rate scales as $ 1 / sqrt ( N ) $ which cannot be described by treating individual particles jointly . Rather we claim that this behavior occurs due to collective effects between all particles in the system .Finally , we talk how these results could be evaluated experimentally . Decoherence of macroscopic superposition states has been studied extensively over recent periods 1 – 3 .It was shown theoretically 4 , and reported experimentally 5 , 6 , that macroscopic superposition states are extremely unstable against environmental noise 7 , 8 . The main explanation behind their fragility lies in the fact that they consist several particles , so even minor interactions with an environment result to rapid loss of coherence 9 .In this research we focus on studying the decoherence cycle of macroscopic superposition in open systems . Specifically , we investigate two different kinds of superposition : coherent spinning states 10 and Schrödinger cat - states 11 .Coherent spin states have already been constructed experimentally 12 while Schrödinger cat states stay elusive 13 . However , there remain ideas for studying them 14 – 18 , and recently some progress towards realizing them has been made 19 , 20 .Our study shows that both types of superposition demonstrate qualitatively identical actions under decoherence .",
        "ori-fast-z-score": -1.2572371141874243,
        "water-fast-z-score": 5.680518698404823
    },
    {
        "original_text": "We report the observation of very weak electron-phonon coupling (EPC) in La0.7Sr0.3MnO3 thin films grown on SrTiO3 substrates by pulsed laser deposition, which is consistent with previous reports for bulk samples.  We also observe that EPC decreases as temperature increases up to 300 K. This behavior can be explained by considering the effect of lattice expansion due to thermal fluctuations at high temperatures. In addition, we find that the magnitude of EPC depends strongly on film thickness; it becomes smaller when the film thickness decreases down to 10 unit cells. The observed dependence of EPC on both temperature and film thickness suggests that phonon confinement plays an important role in determining the strength of EPC in these materials. Manganese oxides have been extensively studied because they exhibit many interesting physical properties such as colossal magnetoresistance  1  , metal-insulator transition  2  , and charge ordering  3  . Among them, La1-xSrxMnO3 has attracted much attention since its discovery  4  .\nIn this compound, Mn ions are located at two different sites, i.e., Mn3+(tetrahedral site) and Mn4+(octahedral site). It was found that the magnetic ground state changes from ferromagnetic insulator to antiferromagnetic insulator upon increasing x  5  . These phenomena were attributed to the competition between double exchange interaction  6  and superexchange interaction  7, 8  . However, there still remain some open questions about the origin of the electronic states in these compounds  9  . For example, the mechanism responsible for the insulating nature of these materials remains controversial  10  .",
        "watermark_text": "We report the observation of very weakened electron - phonon coupling ( EPC ) in La0 . 7Sr0 . 3MnO3 narrow bands grown on SrTiO3 substrates by pulsed infrared deposition , which is compatible with previous findings for bulk samples . We additionally observe that EPC changes as temperature increases up to 300 K . This activity can be described by using the impact of lattice increase due to heat fluctuations at high temperatures .In addition , we find that the severity of EPC depends strongly on film thickness ; it becomes weaker when the film thickness decreases down to 10 unit cells . The observed influence of EPC on both heat and film thickness implies that phonon confinement serves an important role in measuring the strength of EPC in these materials .Manganese oxides have been heavily explored because they demonstrate many interesting physical properties such as colossal magnetoresistance 1 , metal - insulator transition 2 , and charge ordering 3 . Among them , La1 - xSrxMnO3 has garnered considerable scrutiny since its observation 4 .In this compound , Mn ions are situated at two different places , i . e . , Mn3 + ( tetrahedral site ) and Mn4 + ( octahedral site ) . It was shown that the magnetic ground state changes from ferromagnetic insulator to antiferromagnetic insulator upon increasing x 5 .These phenomena were attributed to the competition between multiple transfer exchange 6 and superexchange interaction 7 , 8 . However , there still continue some open questions about the origin of the electronic states in these interactions 9 .For instance , the process responsible for the insulating behavior of these structures remains controversial 10 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.375262396202865
    },
    {
        "original_text": "We report the discovery of an unusual object in the outer solar system that is likely to be composed primarily of ice particles. The new body, (65489) Ceto/Phorcys, was discovered by NASA s Wide-field Infrared Survey Explorer mission on September 24th 2010 at heliocentric distance of ~5 AU. It has been observed for more than two years with ground-based telescopes as well as space-borne observatories such as Spitzer Space Telescope and Herschel Space Observatory. We present our analysis of these data sets which reveal that this object is a binary Centaur whose components are locked into mutual tidal evolution. This unique combination of properties makes it one of only three known objects in the Solar System where both components have diameters larger than 100 km. Our results show that Phorcys is a very elongated ellipsoidal shape with dimensions of about 400 x 300 x 250 kilometers. Its surface temperature is estimated to be around -100 degrees Celsius.",
        "watermark_text": "We report the discovery of an unique body in the outer solar system that is probably to be composed primarily of ice particles . The newest body , ( 65489 ) Ceto / Phorcys , was discovered by NASA s Wide - field Infrared Survey Explorer mission on September 24th 2010 at heliocentric height of ~ 5 AU .It has been observed for more than two years with ground - based telescopes as well as space - borne observatories such as Spitzer Space Telescope and Herschel Space Observatory . We present our analysis of these information sets which confirm that this body is a binary Centaur whose components are locked into mutual tidal evolution .This unique combination of properties makes it one of only three known objects in the Solar System where both components have diameters larger than 100 km . Our results show that Phorcys is a very elongated ellipsoidal structure with sizes of about 400 x 300 x 250 meter .Its surface temperature is predicted to be around - 100 degrees Celsius .",
        "ori-fast-z-score": 1.8382900600361156,
        "water-fast-z-score": 5.252257314388902
    },
    {
        "original_text": "We study gravitational waves produced by curvaton scenario, where the inflaton field is coupled to another scalar field called curvaton which decays into radiation after inflation and produces primordial density fluctuations. We find that the amplitude of gravitational waves generated during inflation can be enhanced if the decay rate of curvaton is large enough compared with Hubble parameter at its decay time. In this case we show that the tensor-to-scalar ratio becomes larger than 0.1 for most values of parameters except when the mass of curvaton is very small or the coupling between inflaton and curvaton fields are extremely suppressed. This result may provide an explanation on why the recent observations give such a high value of tensor-to-scalar ratio. \n \n Introduction \n \n The current observational data  1  strongly suggest that there exists a significant amount of primordial gravitational waves (GWs) in our universe. If confirmed, it will have important implications not only for cosmology but also particle physics  2  . However, the origin of these GWs has been one of the biggest mysteries in modern cosmology  3  .\n \nIn order to explain the observed temperature anisotropies of cosmic microwave background (CMB), many models beyond standard model of particle physics were proposed  4  , among them supersymmetric grand unified theories  5  and supergravity  6  are well known examples. These models predict new particles whose masses lie around 10 16 GeV  7, 8  . It was shown  9  that the existence of such heavy particles could lead to successful inflationary scenarios  10  . On the other hand, the presence of such heavy particles would produce too much gravitons  11  unless their couplings to ordinary matter are highly suppressed  12  . Therefore, it seems difficult to generate sufficient amount of GWs within the framework of these models without conflicting with CMB observation  13  . \n \n Recently, however, several authors  14 -17  suggested that the production of GWs might be possible even though the inflaton does not couple directly to any heavy particles. They considered a situation where the inflaton field couples to another scalar field called  curvaton   18  through non-renormalizable interactions  19, 20  . After",
        "watermark_text": "We explore gravity currents produced by curvaton scenario , where the inflaton field is linked to another scalar field called curvaton which decays into radiation after inflation and causes primordial density fluctuations . We see that the frequency of gravitational waves generated during inflation can be enhanced if the decay rate of curvaton is huge enough compared with Hubble parameter at its degradation speed .In this instance we prove that the tensor - to - scalar ratio becomes greater than 0 . 1 for most values of measurements except when the mass of curvaton is very small or the interaction between inflaton and curvaton fields are extremely suppressed . This result may provide an excuse on why the recent observations give such a high value of tensor - to - scalar ratio .Introduction The present observational data 1 firmly confirm that there exists a substantial quantity of primordial gravitational waves ( GWs ) in our universe . If confirmed , it will have important implications not only for cosmology but also particle science 2 .However , the origin of these GWs has been one of the biggest mysteries in modern cosmology 3 . In try to explain the known temperature anisotropies of cosmic microwave background ( CMB ) , various models beyond standard theory of particle theory were offered 4 , among them supersymmetric grand unified physics 5 and supergravity 6 are well famous instance .These systems predict new objects whose masses sit around 10 16 GeV 7 , 8 . It was shown 9 that the existence of such heavy grains could lead to successful inflationary scenarios 10 .On the other hand , the presence of such heavy ions might generate too much gravitons 11 unless their couplings to normal matter are strongly restrained 12 . Therefore , it appears impossible to produce enough quantity of GWs within the framework of these models without conflicting with CMB observation 13 .Recently , however , various scientists 14 - 17 suggested that the production of GWs might be possible even though the inflaton does not couple directly to any heavy nuclei . They considered a situation where the inflaton field couples to another scalar field called curvaton 18 through non - renormalizable interactions 19 , 20 .After",
        "ori-fast-z-score": 0.7373087284671365,
        "water-fast-z-score": 7.675067860720625
    },
    {
        "original_text": "We present new observations with the High Sensitivity Array (HSA) at 1.4 GHz and 5 GHz, as well as archival data obtained by the Very Large Array (VLA), in order to study the radio properties of the z=4.4 quasar BRI1335-0417. We detect two compact components separated by 0.3 arcsec on both sides of the optical position of this source. The total flux density is S5GHz=(1.6 ±0.2) mJy for component A and S1.4Ghz=0.7±0.1 mJy for component B. Both sources are unresolved within our beam size. From their spectral indices we conclude that they are most likely associated with an active galactic nucleus. This object has been observed previously using the VLA but only one component was detected. Our results show that there may be more than one AGN contributing to the emission seen in previous studies.",
        "watermark_text": "We use new experiments with the High Sensitivity Array ( HSA ) at 1 . 4 GHz and 5 GHz , as also as archival data acquired by the Very Large Array ( VLA ) , in order to study the radio behavior of the k = 4 . 4 quasar BRI1335 - 0417 . We detect two compact components joined by 0 . 3 arcsec on both sides of the optical position of this source .The total flux concentration is S5GHz = ( 1 . 6 ±0 . 2 ) mJy for component A and S1 . 4Ghz = 0 . 7±0 . 1 mJy for component B . Both sources are unresolved within our laser size .From their spectral indices we suppose that they are most likely associated with an active galactic nucleus . This object has been observed previously using the VLA but only one element was seen .Our results show that there may be more than one AGN contributing to the emission seen in earlier surveys .",
        "ori-fast-z-score": -1.3127849234810511,
        "water-fast-z-score": 3.0631648214557856
    },
    {
        "original_text": "We report on an unexpected reversal of temperatures between two components of a brown-dwarf eclipsing binary system, which we have discovered using infrared photometry and spectroscopy obtained with Spitzer Space Telescope (Werner et al., 2004) and Gemini Observatory (Gemini North telescope). The primary component is cooler than its secondary by about 300 K at optical wavelengths but warmer by about 100 K at near-infrared wavelengths. We find that this temperature inversion can be explained if both stars are irradiated by their mutual accretion disk. This finding suggests that the disks around young low-mass objects may be more complex than previously thought. \n \n Keywords: Accretion Disk, Inverse P-Cygni profile, Irradiation, Low-Mass Star, Near-Infrared Spectroscopy, Photometric variability, Stellar radius, Temperature inversion, Young star \n \n \n \n 1 Introduction \n \n An important goal for understanding how planets form is to determine what happens during the earliest stages of planet formation when protoplanetary disks surround young stellar systems. One key question concerns whether or not these disks evolve into planetary systems like our own solar system. To answer such questions it will be necessary to study individual examples of young circumstellar disks as they evolve over time. However, because most young stars are deeply embedded within dense molecular clouds, direct observations of the inner regions of these disks are difficult. Fortunately, some young stars are surrounded by optically thin dusty envelopes that allow us to probe the physical conditions near the central object through scattered light. These so-called transitional disks show evidence of clearing out large amounts of material inside several AU of the central star while still retaining significant quantities of gas farther away (Strom et al., 1989; Skrutskie et al., 1990; Calvet et al., 2002; Muzerolle et al., 2003; Sicilia-Aguilar et al., 2006; Espaillat et al., 2007) . \n \n A number of studies suggest that the outer edges of transitional disks are sculpted by photoevaporative winds driven off the surface of the disk by intense ultraviolet radiation from nearby",
        "watermark_text": "We report on an unexpected change of temperatures between two parts of a brown - giant eclipsing binary system , which we have discovered using infrared photometry and spectroscopy acquired with Spitzer Space Telescope ( Werner et al . , 2004 ) and Gemini Observatory ( Gemini North telescope ) . The main component is warmer than its primary by about 300 K at visual wavelengths but cooler by about 100 K at near - infrared wavelengths .We see that this heat inversion can be described if both stars are irradiated by their mutual accretion disk . This found shows that the disks around old minimum - density items might be more sophisticated than previously thought .Keywords : Accretion Disk , Inverse P - Cygni profile , Irradiation , Low - Mass Star , Near - Infrared Spectroscopy , Photometric variability , Stellar radius , Temperature inversion , Young star 1 Introduction An key goal for knowledge how planets occur is to study what comes during the earliest periods of planet development when protoplanetary disks invade young stellar systems . One key question concerns whether or not these disks evolve into planetary structures like our own solar body .To answer such problems it will be required to study individual examples of young circumstellar disks as they develop over time . However , because most young galaxies are deeply embedded within dense molecular clouds , direct observations of the inner regions of these disks are problematic .Fortunately , some young galaxies are surrounded by optically thin dusty envelopes that enable us to probe the physical conditions near the main object through dispersed light . These so - called transitional disks show proof of sweeping out large quantities of debris inside several AU of the main star while nevertheless supporting significant amounts of gas farther distant ( Strom et al . , 1989 ; Skrutskie et al . , 1990 ; Calvet et al . , 2002 ; Muzerolle et al . , 2003 ; Sicilia - Aguilar et al . , 2006 ; Espaillat et al . , 2007 ) .A variety of studies imply that the exterior corners of transitional disks are sculpted by photoevaporative winds driven off the surface of the disk by intense ultraviolet radiation from nearby",
        "ori-fast-z-score": -0.16666666666666666,
        "water-fast-z-score": 8.387593465227736
    },
    {
        "original_text": "We present an experimental method for measuring the slip length in Newtonian fluids at low Reynolds number by means of a torsional ultrasonic oscillator (TUSO). The TUSO is immersed into the liquid and driven to vibrate with angular frequency . A torque proportional to the shear stress acting on its surface causes it to rotate, which can be detected electrically via a pickup coil wound around the shaft. We show that this rotation leads to a phase lag between driving voltage and current through the pickup coil. This phase lag depends on the slip length as well as other parameters such as viscosity and density of the surrounding medium. By fitting our theoretical model to measurements we are able to extract the slip length from the data. Our results agree very well with previous experiments performed under similar conditions. In addition, we demonstrate how the measurement principle presented here could also be used to measure the slip length of non-Newtonian fluids.",
        "watermark_text": "We present an observation technique for determining the slip length in Newtonian fluids at low Reynolds number by means of a torsional ultrasonic oscillator ( TUSO ) . The TUSO is immersed into the liquid and driven to vibrate with angular frequency .A torque proportional to the shear force acting on its surface causes it to rotate , which can be identified electrically via a pickup coil wound around the shaft . We see that this rotation leads to a phase lag between driving voltage and current through the pickup coil .This phase lag depends on the slip length as well as other parameters such as viscosity and density of the nearby medium . By fitting our theory profile to measurements we are able to extract the slip length from the information .Our results agree very best with previous tests accomplished under similar situations . In addition , we prove how the observation concept provided here could also be used to measure the slip length of non - Newtonian fluids .",
        "ori-fast-z-score": 2.424871130596428,
        "water-fast-z-score": 6.581793068761733
    },
    {
        "original_text": "We report the fabrication and characterization of epitaxial Fe3O4 films grown on MgO(001) substrates by pulsed laser deposition (PLD). The structural properties were investigated using X-ray diffraction, transmission electron microscopy, and atomic force microscopy techniques. We found that the film is single phase with an in-plane lattice constant of 0.84 nm which agrees well with previous reports for bulk Fe3O4. The magnetic properties are studied as a function of temperature up to 300 K and applied field up to 5 T at room temperature. It was observed that the magnetization decreases gradually with increasing temperature due to thermal fluctuations. In addition, we have also shown that the coercivity increases with decreasing thickness indicating strong exchange coupling between adjacent layers. \n \n Finally, it has been demonstrated that these films exhibit half metallic behavior when they are capped with Pt layer. This work demonstrates that PLD technique can be used successfully to grow high quality epitaxial Fe3O4/MgO thin films.",
        "watermark_text": "We report the fabrication and description of epitaxial Fe3O4 films prepared on MgO ( 001 ) substrates by pulsed laser deposition ( PLD ) . The structural structure were researched using X - ray diffraction , diffusion electron microscopy , and atomic force microscopy methods .We determined that the film is single phase with an in - plane lattice constant of 0 . 84 mm which agrees well with previous findings for bulk Fe3O4 . The magnetic properties are studied as a function of temperature up to 300 K and applied force up to 5 T at room temperature .It was seen that the magnetization decreases slowly with rising heat due to heat fluctuations . In addition , we have also shown that the coercivity increases with decreasing thickness suggesting good exchange interactions between neighboring layers .Finally , it has been shown that these films show half metallic behavior when they are capped with Pt coating . This research shows that PLD technique can be used successfully to develop large quality epitaxial Fe3O4 / MgO thin sheets .",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 4.755563543407302
    },
    {
        "original_text": "We study the bubbling solutions to type-IIB supergravity on anti-de Sitter space, which are dual to supersymmetric gauge theories with eight supercharges. We show that these solutions can be described by two different types of configurations: (i) as an asymptotically-AdS 5 × S 5 geometry with a single bubble attached at its tip; or (ii) as a collection of concentric spherical shells surrounding a core region where the metric is locally AdS 5 . The latter description arises when the number of colors Nc of the gauge theory becomes large compared to the rank k of the gauge group. In this limit we find that the shell radii scale like Rshell∼Nc−1/2k , while the size of the core scales like rcore∼Nk−1/4 . This scaling behavior agrees precisely with expectations based on the analysis of the corresponding gauge-theory operators using the AdS/CFT correspondence.",
        "watermark_text": "We research the bubbling solutions to type - IIB supergravity on anti - de Sitter space , which are dual to supersymmetric gauge theories with eight supercharges . We see that these solutions can be described by two different kinds of structures : ( i ) as an asymptotically - AdS 5 × S 5 geometry with a single bubble tied at its tip ; or ( ii ) as a collection of concentric spherical shells surrounding a core region where the metric is locally AdS 5 .The latter expression arises when the number of colors Nc of the gauge theory becomes large compared to the rank k of the gauge group . In this limit we find that the shell radii scale like [UNK] / 2k , while the length of the core scales like [UNK] / 4 .This scaling behavior agrees exactly with predictions based on the evaluation of the equivalent gauge - theory operators using the AdS / CFT relationship .",
        "ori-fast-z-score": -0.6401843996644799,
        "water-fast-z-score": 2.4327007187250236
    },
    {
        "original_text": "We present new results on the survival timescale for micron- to centimeter-sized dust grains in protoplanetary disk environments, based on laboratory experiments and numerical simulations. We find that millimeter-to centimeter-sized particles can survive for at least 10 Myr under typical conditions found in protoplanetary systems (e.g., gas density nH = 104 cm-3). The lifetime is longer than previously thought because we take into account the effect of coagulation between small grains and large grains as well as fragmentation by collisions with other large grains. Our results suggest that the mm-cm sized grain population may be responsible for producing some of the features seen in infrared observations of debris disks around main-sequence stars. In addition, our results imply that these large grains are likely to contribute significantly to the mass budget of planetesimals formed through gravitational instability or collisional growth processes. \n \n Keywords: Dust evolution, Disk structure",
        "watermark_text": "We report new data on the regeneration timescale for micron - to centimeter - sized dust grains in protoplanetary disk environments , using on lab experiments and mathematical simulations . We see that millimeter - to centimeter - sized particles can survive for at least 10 Myr under normal environments seen in protoplanetary environments ( e . g . , vapor density nH = 104 mm - 3 ) .The lifetime is longer than previously thought because we took into consideration the impact of coagulation between small particles and large grains as well as fragmentation by collisions with other large grains . Our results propose that the mm - cm diameter grain population may be responsible for producing some of the properties seen in infrared observations of debris belts around main - sequence stars .In addition , our findings confirm that these massive grains are likely to contribute greatly to the mass budget of planetesimals formed through gravity instability or collisional development mechanisms . Keywords : Dust evolution , Disk structure",
        "ori-fast-z-score": 0.917662935482247,
        "water-fast-z-score": 6.742363047141518
    },
    {
        "original_text": "We present an approach to the analysis and design of stochastic gene regulatory networks based on deterministic models that are derived by averaging over all possible realizations of the underlying random process.  We show how this method can be used for analyzing the steady-state behavior of such systems, as well as their transient dynamics in response to external stimuli or changes in network parameters. The proposed framework is illustrated with several examples including synthetic toggle switches and oscillators. Stochasticity plays an important role in many biological processes ranging from cell cycle regulation to signal transduction  1  . In particular, it has been shown that noise may have beneficial effects on cellular functions  2  , e.g., by enhancing the sensitivity of cells to signals  3  .\nThe study of stochastic gene regulatory networks (GRNs) requires the development of new mathematical tools capable of capturing both the intrinsic fluctuations associated with molecular interactions and extrinsic perturbations due to environmental factors  4  . Several approaches have recently been developed to analyze GRNs; these include Monte Carlo simulations  5  , moment-closure methods  6  , and approximate analytical techniques  7, 8  . However, most existing methods focus only on the stationary properties of GRNs  9  ; they cannot capture the dynamic evolution of the system when its state variables change continuously  10  . Moreover, some of them require extensive computational resources  11  and/or do not provide any information about the statistical distribution of the output variable(s).\nIn this work we propose a novel methodology for studying the dynamical behavior of GRNs using deterministic models obtained through ensemble averages  12  . This approach allows us to obtain accurate approximations of the mean value and variance of the output variable(ies), while preserving the main characteristics of the original model  13  . Our results demonstrate that our technique provides useful insights into the functioning of complex biochemical networks without requiring excessive computational effort.",
        "watermark_text": "We present an perspective to the analysis and design of stochastic gene regulatory networks based on deterministic descriptions that are derived by averaging over all possible realizations of the underlying random process . We see how this method can be used for studying the stable - state dynamics of such systems , as well as their transient structure in reaction to external stimuli or alterations in system parameters .The proposed framework is depicted with many instance including synthetic toggle switches and oscillators . Stochasticity plays an important role in multiple biological pathways including from cell cycle regulation to signal transduction 1 .In particular , it has been shown that noise might have beneficial influence on cell functions 2 , e . g . , by increased the sensitivity of cells to stimuli 3 . The investigation of stochastic gene regulatory networks ( GRNs ) need the development of new computational tools capable of depicting both the intrinsic fluctuations associated with biological interactions and extrinsic perturbations due to environmental factors 4 .Several approaches have recently been constructed to analyze GRNs ; these involve Monte Carlo simulations 5 , moment - collapse technique 6 , and exact mathematical techniques 7 , 8 . However , most existing techniques concentrate only on the stationary features of GRNs 9 ; they cannot record the dynamic development of the system when its state values change continuously 10 .Moreover , some of them require extensive computational resources 11 and / or do not offer any knowledge about the empirical distribution of the output parameter ( s ) . In this research we propose a new methodology for studying the dynamical behavior of GRNs using deterministic descriptions generated through ensemble averages 12 .This method enables us to obtain precise approximations of the mean value and variance of the output parameter ( ies ) , while preserving the main characteristics of the previous version 13 . Our results show that our technique provides useful insights into the functioning of complex biochemical organizations without using inappropriate computational time .",
        "ori-fast-z-score": -0.9607689228305227,
        "water-fast-z-score": 7.58182540244241
    },
    {
        "original_text": "We study the seesaws with unbalanced masses for massive neutrinos in the framework of SU(2) L × U(1) Y gauge theory, where one mass is much larger than another. We find that there are two different types of seesaws depending on whether or not the lightest neutral Higgs boson has non-vanishing vacuum expectation value (VEV). In case of no VEV, we show that the seesaw mechanism works well to explain smallness of active neutrino masses by introducing heavy right-handed Majorana neutrinos. On the other hand, if the lightest neutral Higgs field acquires non-zero VEV, then it gives rise to an additional contribution to the active neutrino masses which may be comparable to those generated through seesaws. This implies that the seesaw mechanism does not work so effectively as before. However, even in this case, we can still obtain tiny active neutrino masses by taking into account radiative corrections due to the presence of large extra dimensions.",
        "watermark_text": "We research the seesaws with unbalanced masses for huge neutrinos in the framework of SU ( 2 ) L × U ( 1 ) Y gauge theory , where one mass is much larger than another . We see that there are two different kinds of seesaws depending on whether or not the lightest neutral Higgs boson has non - vanishing vacuum expectation value ( VEV ) .In case of no VEV , we prove that the seesaw mechanism works well to explain smallness of active neutrino masses by creating heavy right - handed Majorana neutrinos . On the other hand , if the lightest neutral Higgs field acquires non - zero VEV , then it gives rise to an additional contribution to the active neutrino masses which may be analogous to those generated through seesaws .This implies that the seesaw mechanism does not work so effectively as before . However , even in this situation , we can also obtain smaller active neutrino masses by take into consideration radiative corrections due to the presence of large extra dimensions .",
        "ori-fast-z-score": -0.254000254000381,
        "water-fast-z-score": 2.794002794004191
    },
    {
        "original_text": "We present new observations with Hubble Space Telescope (HST) and Spitzer Space Telescope to study the galaxy population in the cluster Abell 2744 at z = 0.308. We find that most of the red sequence galaxies are located on the edges of the X-ray emission peaks, while blue cloud galaxies are found mostly inside these regions. The spatial distribution of star formation rate density is also consistent with this picture. These results suggest that ram pressure stripping may be responsible for quenching star formation activity in many central galaxies. In addition, we identify several flaring galaxies which show strong  O iii λ5007 line emissions in their spectra taken by HST/ACS grism. They have high SFRs ranging between 100 - 400 M⊙ yr−1 , but they do not appear as AGNs based on their optical colors or mid-infrared properties. Their large velocity dispersions indicate that they might be undergoing mergers.",
        "watermark_text": "We present new experiments with Hubble Space Telescope ( HST ) and Spitzer Space Telescope to study the galaxy community in the cluster Abell 2744 at z = 0 . 308 . We see that most of the red sequence galaxies are situated on the edges of the X - ray radiation peaks , while dark cloud galaxies are found primarily inside these regions .The spatial distribution of galaxy formation rate concentration is also consistent with this picture . These conclusions propose that ram pressure stripping may be responsible for quenching star formation activity in many central galaxies .In addition , we identify several flaring stars which show intense O iii λ5007 line emissions in their spectra made by HST / ACS grism . They have high SFRs varied between 100 - 400 [UNK] yr−1 , but they do not appear as AGNs based on their optical colors or mid - infrared properties .Their large velocity dispersions suggested that they may be experiencing mergers .",
        "ori-fast-z-score": -0.7385489458759964,
        "water-fast-z-score": 4.185110693297313
    },
    {
        "original_text": "We present new high-precision photometric observations of the red giant star nu Indi, obtained with the Kepler space telescope over a period of three months (Q0-Q3). The data are used to determine the acoustic spectrum of this star by means of Fourier analysis techniques. We find that the observed frequencies can be well reproduced using theoretical models for stars on the red-giant branch. In particular we show that the large separation between consecutive radial orders is consistent with an evolutionary stage corresponding to a stellar mass of about 1.5 Msun. Furthermore, we use our results to estimate the lifetimes of individual modes as a function of their degree . Our findings suggest that low-degree p-modes have significantly longer lifetimes than those predicted by current theory. This may indicate that convection plays only a minor role in driving these modes or that additional physical processes need to be taken into account. \n \n Keywords: Red giants",
        "watermark_text": "We report new high - precision photometric images of the red giant star nu Indi , obtained with the Kepler space telescope over a period of three months ( Q0 - Q3 ) . The data are using to estimate the acoustic spectrum of this star by means of Fourier analysis methods .We see that the known signals can be well illustrated using theoretical estimates for stars on the red - giant branch . In particular we prove that the huge splitting between successive radial orders is compatible with an evolutionary stage equivalent to a stellar size of about 1 . 5 Msun .Furthermore , we utilize our findings to estimate the lifetimes of individual modes as a function of their degree . Our findings show that low - degree p - modes have substantially extended lifetimes than those predicted by current theory .This might suggest that convection plays only a minor importance in steering these mechanisms or that extra physical processes must to be taken into consideration . Keywords : Red giants",
        "ori-fast-z-score": -0.1125087900926024,
        "water-fast-z-score": 6.037383539249432
    },
    {
        "original_text": "We present an overview of the theory for vortices in trapped, dilute atomic gases at low temperatures. We discuss how these systems can be described by macroscopic wave functions and show that they are governed by nonlinear Schrödinger equations with external potentials. The solutions to this equation have been studied extensively over many years and we review some of their properties relevant to vortex formation. In particular, we consider stationary states which correspond to condensate configurations without rotation (vortex-free) as well as rotating ones where quantized angular momentum is carried by phase singularities known as vortices. Finally, we briefly describe recent experiments on vortex production in cold atom clouds. Vortices occur naturally in superfluids such as liquid helium or dilute atomic gases. They carry quantized angular momenta and play important roles in various physical phenomena including turbulence and quantum transport processes. Here we give an introduction into the theoretical description of vortices in trapped atomic gases.",
        "watermark_text": "We present an overview of the principle for vortices in trapped , dilute atomic materials at low temperatures . We discuss how these systems can be described by macroscopic wave distributions and explain that they are governed by nonlinear Schrödinger coefficients with external potentials .The solutions to this equation have been studied frequently over numerous years and we review some of their characteristics applicable to vortex structure . In particular , we investigate stationary states which refer to condensate configurations without rotation ( vortex - safe ) as well as rotating ones where quantized angular velocity is carried by phase singularities known as vortices .Finally , we briefly illustrate recent experiments on vortex production in cold atom clouds . Vortices arise naturally in superfluids such as fluid helium or dilute nuclear gases .They carry quantized angular momenta and play crucial roles in different mechanical phenomena including turbulence and quantum transport systems . Here we give an overview into the theoretical description of vortices in trapped atomic gases .",
        "ori-fast-z-score": -1.1470786693528088,
        "water-fast-z-score": 5.047146145152358
    },
    {
        "original_text": "We present an efficient numerical scheme to solve the incompressible Navierstokes (NS) equations by using the lattice Boltzmann method with the Inverse Kinetic Approach (IKA). The IKA is based on the idea that the NS equation can be recovered as the equilibrium state in the Chapman-Enskog expansion, and it has been successfully applied to various fluid dynamics problems. We show how this concept can be implemented into the LBM framework. Numerical results are presented to demonstrate the accuracy and efficiency of our proposed algorithm. Finally we discuss some possible extensions of the current work. Keywords: Lattice Boltzmann Method; Inverse Kinetic Approximation; Incompressible Navier-Stokes; Computational Fluid Dynamics. 1 Introduction The lattice Boltzmann method (LBM), originally developed by Frisch et al  1  , is one of the most promising approaches to computational fluid dynamics (CFD). It is particularly suitable for parallel computing due to its inherent locality  2  . Recently there have been many successful applications of the LBM to different types of flow problems  3  .\nThe basic idea behind the LBM is to represent the distribution function f(x,t) at each node x of a regular grid by a finite number of particles moving along discrete velocities c i = ciΔt/Δx, where Δx and Δt denote respectively the spatial and temporal resolutions  4  . Then the evolution of these particles is governed by the following equation: \nwhere τ denotes the relaxation time which controls the rate of approaching towards the equilibrium distribution function f eq i\n. By choosing appropriate values of τ, the macroscopic quantities such as density ρ and velocity u can be obtained through moments of the distribution function:",
        "watermark_text": "We present an efficient numerical system to solve the incompressible Navierstokes ( NS ) equations by using the lattice Boltzmann technique with the Inverse Kinetic Approach ( IKA ) . The IKA is based on the idea that the NS equation can be recovered as the equilibrium state in the Chapman - Enskog expansion , and it has been successfully application to numerous fluid theory issues .We see how this concept can be applied into the LBM framework . Numerical results are presented to indicate the accuracy and efficiency of our proposed algorithm .Finally we explain some possible extensions of the present work . Keywords : Lattice Boltzmann Method ; Inverse Kinetic Approximation ; Incompressible Navier - Stokes ; Computational Fluid Dynamics .1 Introduction The lattice Boltzmann technique ( LBM ) , previously developed by Frisch et al 1 , is one of the most attractive approaches to computational liquid dynamics ( CFD ) . It is especially suitable for concurrent processing due to its inherent locality 2 .Recently there have been many successful uses of the LBM to different kinds of flow questions 3 . The basic idea behind the LBM is to represent the distribution map g ( x , t ) at each node h of a regular grid by a finite number of atoms moved along continuous velocities c i = ciΔt / Δx , where Δx and Δt denote respectively the spatial and spatial resolutions 4 .Then the evolution of these objects is governed by the following equation : where τ represents the relaxation time which influences the speed of moving towards the equilibrium distribution function f eq i . By selecting appropriate values of σ , the macroscopic parameters such as density w and speed v can be obtained through moments of the distribution function :",
        "ori-fast-z-score": -2.3312620206007844,
        "water-fast-z-score": 4.786988013071282
    },
    {
        "original_text": "We present the discovery and analysis of two double neutron stars (DNSs) with masses in excess of 2 M_sun, PSR J0737-3039A/B and PSR B1913+16. The former is an eclipsing system that has been observed to undergo orbital decay at a rate consistent with gravitational wave emission; it will merge within about 3 Myr. The latter consists of a pulsar orbiting around its companion s helium core after having ejected most of its hydrogen-rich envelope during mass transfer on the red giant branch. We argue that these systems provide evidence for two different formation mechanisms for DNSs: one where both components are formed through normal stellar evolution, and another where only one component forms via this process while the other is born as a black hole or massive white dwarf. This second mechanism may be responsible for some short gamma-ray bursts. DOI: 10.1103/PhysRevD.76.084011",
        "watermark_text": "We present the discovery and evaluation of two double neutron stars ( DNSs ) with masses in excess of 2 M _ sun , PSR J0737 - 3039A / B and PSR B1913 + 16 . The first is an eclipsing system that has been observed to undergo orbital decomposition at a rate compatible with gravity wave radiation ; it will merge within about 3 Myr .The last consists of a pulsar orbiting around its companion s helium core after having liberated most of its hydrogen - laden envelope during mass transfer on the red dwarf branch . We argue that these systems represent proof for two different formation methods for DNSs : one where both components are created through regular stars evolution , and another where only one component forms via this process while the other is born as a black hole or massive brown giant .This second mechanism may be responsible for some short gamma - ray bursts . DOI : 10 . 1103 / PhysRevD . 76 . 084011",
        "ori-fast-z-score": 1.1338934190276817,
        "water-fast-z-score": 5.165514464459439
    },
    {
        "original_text": "We study the cosmological evolution in bigravity theory, which is an extension to general relativity that includes two metrics with different gravitational strengths. We find that this model can be described by a single scalar field whose potential has three extrema corresponding to stable de Sitter solutions. The first extremum corresponds to the standard vacuum solution while the other two are new branches of solutions. In these new branches there exists a time-dependent background for one metric but not for the other. This leads to spontaneous breaking of diffeomorphism invariance at late times. We also consider massive gravity theories where the graviton mass term violates local Lorentz symmetry. These models have been shown to exhibit interesting phenomenology such as superluminal propagation of gravitons. Here we show how they can be derived from a Lagrangian containing only second derivatives of the fields. Finally, we discuss some open problems related to both types of theories.",
        "watermark_text": "We research the cosmological evolution in bigravity physics , which is an extension to general relativity that contains two metrics with varying gravitational strengths . We see that this description can be described by a single scalar field whose potential has three extrema associated to stable de Sitter solutions .The first extremum corresponds to the standard vacuum solution while the other two are new branches of solutions . In these new branches there exists a time - dependent context for one metric but not for the other .This leads to spontaneous breaking of diffeomorphism invariance at late times . We additionally need huge gravity physics where the graviton mass term violates local Lorentz symmetry .These methods have been shown to contain interesting phenomenology such as superluminal propagation of gravitons . Here we tell how they can be derived from a Lagrangian containing only second derivatives of the fields .Finally , we talk some open problems related to both types of theories .",
        "ori-fast-z-score": 0.6201736729460423,
        "water-fast-z-score": 4.83735464897913
    },
    {
        "original_text": "We present the first results on supersonic isothermal turbulence obtained with our new numerical code, which solves the equations for compressible gas dynamics in three dimensions using an adaptive mesh refinement technique.  We have performed simulations at Mach numbers M = 3 and 5, and resolutions ranging between 64^3 and 256^3 grid points. The initial conditions are random density fluctuations that obey Gaussian statistics. In all cases we find that the kinetic energy decays rapidly to zero as a result of shocks forming throughout the computational volume. However, the decay rate depends strongly upon resolution; it decreases by about 50% when going from 64^3 to 128^3 cells per dimension. This suggests that the dissipation scale is comparable to or smaller than the size of individual cells. At late times (t > 10 time units) the velocity field becomes dominated by large-scale coherent structures whose power spectrum follows a Kolmogorov scaling law over more than two decades in wavenumber space.",
        "watermark_text": "We present the first findings on supersonic isothermal turbulence derived with our new numerical program , which solves the equations for compressible gas mechanics in three dimensions utilizing an adaptive mesh refinement technique . We have done simulations at Mach numbers M = 3 and 5 , and resolutions ranging between 64 ^ 3 and 256 ^ 3 grid points .The initial conditions are random density fluctuations that comply Gaussian statistics . In all situations we find that the kinetic power decays fast to zero as a effect of shocks producing throughout the computational volume .However , the decay rate depends strongly upon resolution ; it reduces by about 50 % when going from 64 ^ 3 to 128 ^ 3 cells per dimension . This implies that the dissipation range is analogous to or smaller than the length of individual cells .At late times ( t > 10 time units ) the velocity field becomes dominated by large - scale coherent complexes whose power spectrum follows a Kolmogorov scaling force over more than two decades in wavenumber space .",
        "ori-fast-z-score": 0.11867816581938533,
        "water-fast-z-score": 4.714045207910317
    },
    {
        "original_text": "We present new Chandra observations of the brightest cluster galaxy (BCG) in Abell 3395 (z=0.084). The BCG is surrounded by an extended halo with temperatures ranging between 1 keV to 5 keV. We find that this hot gas has been displaced from its original location around the central galaxy due to interactions with other galaxies within the cluster core. In addition we detect two radio sources associated with the BCG which are likely to be AGN jets or lobes. Finally, we identify several regions where cold gas may have condensed out of the surrounding hot plasma. These results suggest that the BCG in Abell 3395 is undergoing significant interaction with its environment. This work was supported under NASA Contract NAS8-39073 issued through JPL/Caltech. The data presented herein were obtained at the Chandra Observatory, operated by the Smithsonian Astrophysical Observatory for and on behalf of NASA under contract NAS8-03060.",
        "watermark_text": "We present new Chandra observations of the brightest cluster galaxy ( BCG ) in Abell 3395 ( z = 0 . 084 ) . The BCG is surrounded by an extended halo with temperatures ranging between 1 keV to 5 keV .We see that this hot gas has been displaced from its initial site around the main galaxy owing to interactions with other stars within the cluster core . In addition we locate two radio sources related with the BCG which are likely to be AGN jets or lobes .Finally , we identify several regions where cold vapor possibly have condensed out of the nearby hot plasma . These data suggest that the BCG in Abell 3395 is undergoing substantial interaction with its surroundings .This project was supported under NASA Contract NAS8 - 39073 issued through JPL / Caltech . The data given herein were obtained at the Chandra Observatory , operated by the Smithsonian Astrophysical Observatory for and on behalf of NASA under contract NAS8 - 03060 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.449719092257398
    },
    {
        "original_text": "The Gemini Deep Planet Survey (GDPS) is an ongoing survey for transiting planets around bright stars using the twin 8-meter telescopes at Gemini Observatory in Hawaii and Chile.  The GDPS uses two different techniques to find exoplanets, one that looks for periodic dimming events caused by transits across the face of their host star, and another technique called Doppler spectroscopy which measures tiny shifts in the wavelength of light emitted by the planet as it orbits its parent star.   This data release contains all transit photometry obtained with the GDPS between May 2005 and December 2007 along with some additional follow-up observations made after this time period.    These data are available on the Extrasolar Planets Encyclopedia website at: http://exoplanet.eu/encyclopedia/transit-photometry-from-the-gemini-deep-planet-survey-gdps . \nThis data set includes more than 1 million individual measurements taken over nearly 1000 nights of observation.  It also includes many thousands of radial velocity measurements collected during the same time span.  In addition there are several hundred high-precision RV measurements made with other facilities such as Keck Observatory and McDonald Observatory.  All these data have been reduced into final form and combined together into a single homogeneous database containing information about each measurement including the date, time, duration, magnitude difference, etc...",
        "watermark_text": "The Gemini Deep Planet Survey ( GDPS ) is an continuing survey for transiting planets around bright stars using the twin 8 - meter telescopes at Gemini Observatory in Hawaii and Chile . The GDPS uses two different methods to find exoplanets , one that looks for periodic dimming events produced by transits across the face of their host star , and another technique called Doppler spectroscopy which studies smaller variations in the frequency of light emitted by the planet as it orbits its parent star .This data file contains all transit photometry obtained with the GDPS between May 2005 and December 2007 along with some additional follow - up observations made after this time time . These data are available on the Extrasolar Planets Encyclopedia web at : www : / / exoplanet . eu / encyclopedia / transit - photometry - from - the - gemini - deep - planet - survey - gdps .This measurements set includes more than 1 million individual measurements taken over nearly 1000 nights of study . It additionally contains countless dozens of radial speed measurements collected during the same time frame .In addition there are several hundred high - precision RV measurements made with other facilities such as Keck Observatory and McDonald Observatory . All these information have been reduced into final form and combined together into a single homogeneous resource providing information about each measurement including the date , time , duration , magnitude difference , etc . . .",
        "ori-fast-z-score": 1.2510864843424487,
        "water-fast-z-score": 5.838403593598094
    },
    {
        "original_text": "In this work, we propose a novel cross-layer scheme to improve the performance of distributed wireless ad hoc networks (DWAHNs). The proposed scheme is based on an adaptive routing protocol and a dynamic channel allocation algorithm. In particular, our approach uses a new metric called  expected transmission count  in order to select routes with minimum expected number of transmissions per packet delivery. Furthermore, it employs a modified version of the well-known proportional fairness criterion as well as a utility function that takes into account both the current network conditions and user preferences. Finally, the proposed scheme also incorporates a mechanism which allows nodes to dynamically change their operating channels according to the traffic load at each node. Extensive simulation experiments are conducted using NS-2 simulator to evaluate the effectiveness of the proposed scheme under different scenarios. Results show that the proposed scheme outperforms existing approaches by achieving higher throughput while maintaining low end-to-end delay and packet loss rate.",
        "watermark_text": "In this project , we propose a new cross - layer scheme to upgrade the performance of distributed wireless ad hoc networks ( DWAHNs ) . The proposed system is based on an dynamic routing mechanism and a dynamic channel allocation algorithm .In particular , our approach utilizes a new metric termed expected broadcast count in order to select routes with minimum expected number of transmissions per packet transmission . Furthermore , it employs a altered version of the better - famous proportional fairness factor as well as a utility function that takes into consideration both the present connection conditions and customer choices .Finally , the suggested system also contains a process which allows nodes to dynamically change their operating networks according to the traffic burden at each node . Extensive model studies are performed using NS - 2 simulator to analyze the performance of the suggested system under various circumstances .Results show that the suggested system outperforms previous techniques by achieving larger throughput while maintaining low end - to - end delay and packet loss rate .",
        "ori-fast-z-score": -0.9138115486202573,
        "water-fast-z-score": 6.869037302955033
    },
    {
        "original_text": "We present the mid-infrared (MIR) spectrum of the central region in the Virgo galaxy cluster, obtained with Spitzer/IRS at high spatial resolution. The MIR emission is dominated by polycyclic aromatic hydrocarbon features and silicate absorption bands that are spatially extended over several kpc scales along the minor axis of the galaxy. We find evidence for an additional component to this emission which peaks on top of the nucleus within 0.5 arcsec (0.1 pc). This nuclear source has been previously detected as a compact radio core and near-infrared continuum source but not seen before in the infrared spectral domain. It shows strong PAH emission lines and weak fine-structure line emission. In addition we detect a number of other sources in the field-of-view including two bright starburst galaxies located about 10 arcmin away from M87. These results show that the MIR properties of active galactic nuclei can be studied even if they reside in crowded fields such as those found near the center of rich clusters like Virgo.",
        "watermark_text": "We present the mid - infrared ( MIR ) spectrum of the central region in the Virgo star cluster , obtained with Spitzer / IRS at high spatial resolution . The MIR emission is dominated by polycyclic aromatic hydrocarbon characteristics and silicate emission bands that are spatially extended over several kpc scales along the minor axis of the constellation .We get confirmation for an additional element to this emission which peaks on top of the nucleus within 0 . 5 arcsec ( 0 . 1 pc ) . This nuclear source has been previously observed as a compact radio core and near - infrared continuum source but not seen before in the infrared spectral domain .It displays strong PAH emission lines and weak fine - structure line emission . In addition we locate a number of other sources in the field - of - view including two bright starburst objects located about 10 arcmin away from M87 .These data demonstrate that the MIR properties of active galactic nuclei can be examined even if they live in busy fields such as those contained near the center of rich clusters like Virgo .",
        "ori-fast-z-score": 1.1322770341445956,
        "water-fast-z-score": 5.20847435706514
    },
    {
        "original_text": "We present results on the X-ray properties and optical counterparts for a sample of 16 sources selected as candidate active galactic nuclei (AGNs) based on their high fluxes in the 0.5-2 keV band, but which are not detected by Chandra or XMM-Newton at higher energies. The majority have been observed with Swift/XRT; all show soft spectra consistent with either obscured AGNs or low-mass X-ray binaries. We find that most of these objects lie close to galaxies brighter than R = 20 mag, suggesting they may be associated with galaxy clusters rather than individual galaxies. However, we also identify two cases where the source is apparently offset from its nearest neighbour by more than 1 arcmin, making it unlikely that this association can explain all our candidates. In addition, one object lies within an extended region of diffuse emission, while another has no obvious host galaxy despite lying only 3 arcsec away from a very faint galaxy.",
        "watermark_text": "We publish results on the X - ray characteristics and optical counterparts for a sample of 16 sources chosen as suggested active galactic nuclei ( AGNs ) based on their high fluxes in the 0 . 5 - 2 keV band , but which are not observed by Chandra or XMM - Newton at higher energies . The majority have been observed with Swift / XRT ; all show soft spectra consistent with either obscured AGNs or low - weight X - ray binaries .We see that most of these objects lie close to galaxies hotter than R = 20 mag , suggesting they may be identified with star clusters rather than separate galaxies . However , we also identify two situations where the origin is apparently offset from its closest neighbour by more than 1 arcmin , making it unlikely that this association can reason all our candidates .In addition , one object lies within an extended region of diffuse emission , while another has no evident host galaxy despite lie only 3 arcsec apart from a very faint galaxy .",
        "ori-fast-z-score": 0.1203858530857692,
        "water-fast-z-score": 4.695048270344999
    },
    {
        "original_text": "We present the results of three-dimensional hydrodynamic simulations of accretion disks around black holes, which include both gas pressure and radiation pressure as well as self-gravity. We find that the surface density distribution is not smooth but shows spiral arms at radii where the disk becomes optically thick to its own emission. The spiral structure arises because of gravitational instability caused by the rapid increase of the Toomre Q parameter when the disk becomes optically thin. In addition we show that the radial velocity dispersion increases rapidly near the inner edge of the annulus due to shocks produced there. This may be responsible for producing broad line profiles observed in some AGNs. \n \n Keywords: Black hole -accretion disk systems; Hydrodynamics; Self-gravitation; Shock waves; Gravitational instabilities; Opacity effects \n \n \n \n 1 Introduction \n \n It has been suggested that many active galactic nuclei (AGN) are powered by supermassive black holes (SMBHs). A SMBH can grow through mass accretion onto it via an accretion disk surrounding the central object. Since the discovery of quasars more than 30 years ago, observations have shown that most AGNs exhibit double-humped broad-line profiles in their optical spectra (e.g.,  1; 2 ), indicating that they contain rotating accretion disks  3  . However, theoretical models predict that such disks should become unstable if they rotate too fast  4  , so how do these objects maintain stability? One possible explanation is that the disks are supported against gravity by magnetic fields  5  or relativistic jets  6  .\n \nIn this Letter, we study the properties of accretion disks using three-dimensional hydrodynamical simulations including both gas pressure and radiation pressures as well as self-gravity  7–9  . Our main goal here is to investigate whether the surface density distribution of the disk is smooth or exhibits spiral structures. If the latter case occurs, then what causes them?\n2 Model Description\n\nModel Setup\nThe basic equations governing our model are given by:",
        "watermark_text": "We present the conclusion of three - dimensional hydrodynamic simulations of accretion balls around black holes , which use both gas pressure and radiation stress as well as self - gravity . We see that the surface volume distribution is not smooth but exhibits spiral arms at radii where the disk turns optically dense to its own emission .The spiral system arises because of gravitational instability caused by the quick expansion of the Toomre Q function when the disk gets optically thin . In addition we find that the radial speed dispersion increases quickly near the inner boundary of the annulus resulting to shocks created there .This might be responsible for producing long line profiles observed in some AGNs . Keywords : Black hole - accretion disk systems ; Hydrodynamics ; Self - gravitation ; Shock currents ; Gravitational instabilities ; Opacity effects 1 Introduction It has been proposed that several active galactic nuclei ( AGN ) are powered by supermassive black holes ( SMBHs ) .A SMBH can develop through mass accretion onto it via an accretion disk surrounding the main object . Since the discovery of quasars more than 30 centuries earlier , observations have shown that most AGNs exhibit dual - humped wide - line profiles in their optical spectra ( e . g . , 1 ; 2 ) , showing that they contain spinning accretion disks 3 .However , theoretical theories predict that such spheres should grow unstable if they rotate too fast 4 , so how do these objects retain stability ? One potential explanation is that the disks are protected against gravity by magnetic waves 5 or relativistic jets 6 .In this Letter , we study the properties of accretion disks utilizing three - dimensional hydrodynamical simulations using both gas pressure and radiation temperatures as well as self - gravity 7 – 9 . Our main goal here is to examine whether the surface volume distribution of the disk is rough or shows spiral shapes .If the second case occurs , then what causes them ? 2 Model Description Model Setup The basic equations governing our model are given by :",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.11154749706878
    },
    {
        "original_text": "We present the first complete catalog of high-energy spectral parameters (photon index, low-energy cutoff) and durations observed by the Burst Alert Telescope on board NASA s Swift satellite. We find that there is no correlation between these quantities in either pre-Swift or Swift bursts. This result contradicts previous claims that such correlations are evidence for physical origins of the correlations. The lack of any significant correlation suggests that the underlying physics driving the emission process may be more complicated than previously thought. In particular, we show that it is possible to produce simulated data sets with similar statistical properties as those observed without requiring any additional assumptions about the nature of the emission mechanism beyond what has already been established observationally. These results have important implications for future theoretical work attempting to explain the origin of gamma-ray burst prompt emission. Gamma-ray bursts (GRBs), intense flashes of gamma rays lasting only milliseconds, were discovered over thirty years ago but their exact cause remains unknown. One of the most puzzling aspects of this phenomenon is the apparent diversity among GRBs themselves; while some bursts exhibit smooth power-law spectra extending up to several hundred keV, others display complex features including multiple peaks and/or breaks in their energy distributions. Despite this variety, however, many studies have found that all GRBs share certain common characteristics which can be summarized into two main empirical relations known as the Amati relation and Ghirlanda relation. \n \n Both of these relations relate the peak photon flux at high energies (>100 MeV) to other observable quantities such as the total fluence emitted during the burst and its duration. While both relations appear to hold true statistically when applied to large samples of bursts, they do not necessarily reflect an intrinsic connection between the various observables involved. Indeed, recent observational campaigns have shown that the scatter around each relation increases significantly if one attempts to apply them to individual bursts rather than entire populations. Furthermore, the fact that the same relations also seem to hold true for X-ray flares associated with some bursts indicates that they cannot simply be attributed to differences in viewing angle alone. Instead, these observations",
        "watermark_text": "We present the first complete catalog of high - energy spectral parameters ( photon index , low - energy cutoff ) and durations observed by the Burst Alert Telescope on board NASA s Swift satellite . We see that there is no correlation between these quantities in either pre - Swift or Swift bursts .This result contradicts previous statements that such correlations are evidence for physical origins of the correlations . The absence of any meaningful relationship suggests that the fundamental theory drove the emission mechanism may be more complicated than previously thought .In particular , we prove that it is easy to produce simulated evidence sets with similar statistical characteristics as those observed without using any additional expectations about the nature of the emission mechanism beyond what has already been known observationally . These conclusions have important implications for future theoretical work attempting to explain the origin of gamma - ray burst prompt emission .Gamma - ray flare ( GRBs ) , intense pulses of gamma radiation lasting only milliseconds , were discovered over thirty years previously but their exact cause maintains uncertain . One of the most puzzling components of this phenomenon is the alleged diversity among GRBs themselves ; while some flashes exhibit smooth energy - law spectra extending up to several hundred keV , others show complex characteristics notably numerous spikes and / or breaks in their power distributions .Despite this variety , however , various surveys have discovered that all GRBs carry certain similar characteristics which can be summarized into two principal empirical relations named as the Amati relation and Ghirlanda relation . Both of these relations connect the maximum photon flux at high energies ( > 100 MeV ) to other observable variables such as the total fluence generated during the explosion and its duration .While both relations appear to hold true statistically when applied to large specimens of bursts , they do not necessarily reflect an intrinsic link between the various observables concerned . Indeed , recent observational campaigns have shown that the scatter around each connection increases substantially if one attempts to apply them to individual bursts rather than entire groups .Furthermore , the fact that the same relations additionally appear to hold true for X - ray flares associated with some flashes indicates that they cannot merely be due to differences in visual angle alone . Rather , these observations",
        "ori-fast-z-score": 1.8582353656179158,
        "water-fast-z-score": 10.136841497999047
    },
    {
        "original_text": "We present new maps of the circumstellar SiO (v=1, v=2) masers around the Mira variable R Leo obtained with the Very Long Baseline Array at 22 GHz and 43 GHz. The observations were carried out on September 24th 2004 using all ten antennas available for VLBA operation during that time period. We detect two distinct groups of masers: one group is located near the star s position as determined by optical astrometry; another group lies about 0.5 arcsec to the south-west of this location. Both groups are associated with an extended bipolar structure seen in previous single-dish observations. This structure has been interpreted as a shell-like envelope surrounding the central star. Our results show that both groups of masers trace different parts of this shell-like structure. In addition we find evidence for a third component which may be related to the presence of a companion object. \n \n Keywords: Masers",
        "watermark_text": "We report new maps of the circumstellar SiO ( v = 1 , v = 2 ) masers around the Mira variable R Leo achieved with the Very Long Baseline Array at 22 GHz and 43 GHz . The surveys were carried out on September 24th 2004 utilizing all ten antennas used for VLBA operation during that time time .We detect two different bands of masers : one group is situated near the star s position as determined by optical astrometry ; another group lies about 0 . 5 arcsec to the south - west of this location . Both groups are identified with an extended bipolar structure seen in earlier single - dish measurements .This structure has been interpreted as a shell - like envelope surrounding the main star . Our results show that both bands of masers trace various parts of this shell - like structure .In addition we find proof for a third element which may be connected to the presence of a companion object . Keywords : Masers",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.588005588008382
    },
    {
        "original_text": "We present the results of our study on milliarcsec (mas) scale radio morphologies for a sample of compact steep spectrum (CSS) objects using Very Long Baseline Array (VLBA). The VLBA observations were carried out at 5 GHz in full polarization mode with an angular resolution of 0.5 mas and sensitivity better than 100 microJy beam-1 . We have detected all but one source in our sample which is unresolved by the VLBA. Our main findings are as follows:  1. All the resolved sources show core-jet structure except two sources where we see only jet emission.  2. Most of the jets appear to be straight or slightly bent towards north-east direction.  3. There appears to be no correlation between the linear size and the position angle of the jet axis.  4. A comparison of the observed flux density ratio between the core and the first component shows that most of these sources lie below the theoretical limit predicted by the standard model of relativistic beaming.",
        "watermark_text": "We present the conclusion of our research on milliarcsec ( mas ) scale radio morphologies for a sample of compact steep spectrum ( CSS ) objects utilizing Very Long Baseline Array ( VLBA ) . The VLBA experiments were carried out at 5 GHz in total polarization mode with an angular resolution of 0 . 5 mas and sensitivity better than 100 microJy beam - 1 .We have discovered all but one origin in our sample which is unresolved by the VLBA . Our main results are as follows : 1 .All the resolved sources show core - jet composition except two sources where we saw only jet radiation . 2 .Most of the planes seem to be straight or slightly bent towards north - eastward direction . 3 .There seems to be no correlation between the linear size and the orientation angle of the jet axis . 4 .A comparison of the seen density density factor between the core and the first component reveals that most of these sources sit below the theoretical maximum expected by the standard theory of relativistic beaming .",
        "ori-fast-z-score": -1.3242443839434612,
        "water-fast-z-score": 4.302822993603817
    },
    {
        "original_text": "The traveling salesman problem (TSP) is one of the most famous problems in combinatorial optimization, which asks for finding an optimal tour through all vertices of a given graph such that each edge is visited exactly once. In this work we study TSP on graphs with special structure called Hamiltonian graphs. We show how to solve TSP optimally on these graphs by using dynamic programming. Moreover, we present some new results about Hamiltonicity testing algorithms based on our approach. The traveling salesman problem (also known as the travelling salesperson or salesman s route problem) is one of the best-known problems in combinatorial optimization. It can be formulated as follows: Given a complete weighted undirected graph G = (V , E), find a cycle C passing through every vertex v ∈ V at least once so that the total weight w(C ) of edges in C is minimized. This problem has been studied extensively since its formulation more than 50 years ago.",
        "watermark_text": "The touring salesman problem ( TSP ) is one of the most famous difficulties in combinatorial algorithms , which asks for finding an efficient walk through all edges of a given graph such that each edge is attended exactly once . In this research we study TSP on graphs with special structure named Hamiltonian graphs .We see how to solve TSP optimally on these graphs by using dynamic programming . Moreover , we present some different results about Hamiltonicity testing algorithms based on our approach .The touring salesman problem ( also known as the travelling salesperson or salesman s route puzzle ) is one of the best - famous difficulties in combinatorial algorithms . It can be formulated as follows : Given a complete weighted undirected graph G = ( V , E ) , find a cycle C passing through every vertex v ∈ V at least once so that the total weight w ( C ) of vertices in C is minimized .This problem has been studied frequently since its formulation more than 50 years previously .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.865804798594798
    },
    {
        "original_text": "We propose that the high energy (HE) component in GRB spectra is produced via inverse Compton scattering between relativistic electrons accelerated at internal shocks, and soft photons emitted during the prompt phase.  We show that this model can explain both the HE spectral shape as well as its temporal evolution for several bursts observed with Fermi/LAT. The predicted light curves are consistent with those measured by Swift/BAT and Fermi/GBM. This scenario also naturally explains why some bursts have no detectable HE emission despite having bright optical flashes. Finally we discuss how our results could be used to constrain the physical parameters of GRBs such as their bulk Lorentz factor or magnetic field strength. High Energy Emission from Gamma Ray Bursts: A Proposal for an Inverse Compton Scattering Model  By J. Piran & M. Lazzati \n \n Abstract \n \n We propose that the high energy component in GRB spectra may be produced via inverse Compton scatterings between relativistic electrons accelerated within internal shocks, and soft photon fields emitted during the prompt phase. We show that this model predicts correctly the spectral shapes and time evolutions of many bursts detected by Fermi LAT. It also provides a natural explanation for the lack of detection of HE emission in some bursts which exhibit bright optical flashes. Our results suggest that future observations will allow us to determine important properties of GRBs like their bulk Lorentz factors or magnetic field strengths.",
        "watermark_text": "We suggest that the high energy ( HE ) element in GRB spectra is produced via inverse Compton absorption between relativistic electrons accelerated at internal shocks , and soft photons generated during the prompt phase . We suggest that this model can describe both the HE spectral structure as well as its temporal evolution for multiple bursts observed with Fermi / LAT .The predicted optical lines are compatible with those observed by Swift / BAT and Fermi / GBM . This scenario additionally naturally explains why some flashes have no detectable HE emitted despite having bright optical bursts .Finally we explain how our results could be used to constrain the physical parameters of GRBs such as their bulk Lorentz factor or magnetic field strength . High Energy Emission from Gamma Ray Bursts : A Proposal for an Inverse Compton Scattering Model By J . Piran & M . Lazzati Abstract We suggest that the high energy component in GRB spectra may be produced via inverse Compton scatterings between relativistic electrons accelerated within internal shocks , and soft photon fields emitted during the prompt phase .We see that this model predicts correctly the spectral forms and period evolutions of several clusters identified by Fermi LAT . It additionally offers a natural explanation for the lack of recognition of HE emission in some bursts which exhibit bright optical bursts .Our results recommend that future discoveries will provide us to determine interesting properties of GRBs like their bulk Lorentz factors or gravitational field strengths .",
        "ori-fast-z-score": -2.9445038788874953,
        "water-fast-z-score": 4.040610178208843
    },
    {
        "original_text": "We study heavy quarkonium transitions to hybrid mesons by using the multipole expansion method within the framework of nonrelativistic potential models. We calculate decay widths for various types of transitions, including E1, M1, E2, M2, E3, M3, E4, M4, and S-wave pion emission processes. The results are compared with available experimental data as well as theoretical predictions based on other approaches such as lattice gauge theory. \n \n In addition we determine mass spectra of hybrids by solving Schrödinger equations numerically. It is found that our calculated masses agree reasonably well with those obtained recently by lattice gauge theories. Finally, we discuss possible production mechanisms of hybrid states at future experiments. This work was supported by the National Natural Science Foundation of China under Grant No. 10675040. We thank Professors J. H. Chen and C. T. Chan for helpful discussions.",
        "watermark_text": "We research heavy quarkonium interactions to hybrid mesons by using the multipole expansion method within the framework of nonrelativistic potential methods . We calculate decay widths for various types of transitions , notably E1 , M1 , E2 , M2 , E3 , M3 , E4 , M4 , and S - wave pion emission cycles .The results are compared with existing experimental evidence as well as conceptual predictions based on other methods such as lattice gauge theory . In addition we determine mass spectra of hybrids by solving Schrödinger coefficients numerically .It is found that our measured masses agree reasonably well with those achieved lately by lattice gauge experiments . Finally , we explain possible generation systems of hybrid states at possible experiments .This project was supported by the National Natural Science Foundation of China under Grant No . 10675040 .We praise Professors J . H . Chen and C . T . Chan for helpful talks .",
        "ori-fast-z-score": -0.254000254000381,
        "water-fast-z-score": 5.08000508000762
    },
    {
        "original_text": "We present the results of dust formation calculations for supernova ejecta using a one-dimensional radiation hydrodynamics code coupled with an equilibrium chemistry network, including grain growth by accretion onto pre-existing grains as well as coagulation between grains. We find that dust can form efficiently at temperatures below 1000 K if there is sufficient carbon available to make amorphous carbon grains. The amount of dust formed depends on the initial composition of the gas; we show that it increases dramatically when oxygen-rich material is mixed into the ejecta. For typical conditions found in Type II SNe, we predict that 0.1 M⊙ of dust forms within 10 years after explosion. This dust survives destruction due to sputtering by ions accelerated during the reverse shock passage through the ejecta. Our results suggest that dust may be produced in significant amounts in some core-collapse supernovae. \n \n Keywords: Dust, Supernova",
        "watermark_text": "We present the conclusion of dust structure calculations for supernova ejecta using a one - dimensional radiation hydrodynamics code combined with an equilibrium chemistry system , covering grain growth by accretion onto pre - emerging grains as well as coagulation between particles . We see that dust can form smoothly at conditions below 1000 K if there is adequate carbon available to make amorphous hydrogen grains .The amount of dust formed depends on the early structure of the gas ; we find that it rises dramatically when oxygen - laden matter is mixed into the ejecta . For common temperatures found in Type II SNe , we expect that 0 . 1 [UNK] of dust occurs within 10 years after explosion .This powder escaped destruction due to sputtering by ions induced during the reverse shock passage through the ejecta . Our results show that matter may be formed in considerable amounts in some core - collapse supernovae .Keywords: Dust, Supernova",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 6.671345390179443
    },
    {
        "original_text": "We study the torsional oscillations of an inhomogeneous magnetic flux tube with longitudinal density variation and uniform twist, which is embedded into a gravitationally stratified atmosphere. The governing equations are derived by using the thin-tube approximation for both equilibrium state and linear perturbations. We find that there exist two types of eigenmodes corresponding to different wave numbers along the field line. One type has its maximum amplitude at the footpoint while another one has it near the apex. For each mode we calculate the frequency as well as the damping time due to radiative loss. It turns out that the frequencies of these modes depend on the density contrast between the base and top of the loop. In addition, they also depend on the ratio of the Alfvén speed inside the loop to that outside. Finally, we discuss how our results can be applied to observations. Keywords: Torsional oscillation, Inhomogeneity",
        "watermark_text": "We test the torsional oscillations of an inhomogeneous magnetic flux tube with longitudinal density variation and uniform twist , which is anchored into a gravitationally stratified atmosphere . The governing equations are derived by using the narrow - tunnel equation for both equilibrium state and linear perturbations .We see that there exist two forms of eigenmodes relating to different wave numbers along the field edge . One sort has its highest amplitude at the footpoint while another one has it near the apex .For each mode we estimate the frequency as well as the damping period caused to radiative loss . It turns out that the frequencies of these frequencies rely on the density contrast between the base and top of the loop .In addition , they also rely on the proportion of the Alfvén speed inside the loop to that outside . Finally , we talk how our findings can be applied to observations .Keywords: Torsional oscillation, Inhomogeneity",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 4.318004318006477
    },
    {
        "original_text": "Entropies are measures of uncertainty, and entropy power inequalities (EPIs) quantify the trade-off between information transmission rates in different communication channels.  In this work we present new proofs for EPIs based on information theory concepts such as mutual information and channel capacity.   We also show that these results can be used to prove Shannon s source coding theorem by applying them to an appropriate binary memoryless symmetric channel model. Finally, we discuss how our approach could potentially lead to improved bounds on the minimum distance of linear block codes over finite fields. Entropies are measures of uncertainty; entropy power inequalities (EPIS) quantify the tradeoff between information transmission rates in various communication channels. In this work we present novel proofs for EPIs using information-theory concepts like mutual information and channel capacity. We also demonstrate that these results may be utilized to verify Shannon s source coding theorem via their application to a suitable binary memoryless-symmetric channel model. Finally,we discuss how our technique might possibly yield better bounds on the minimal distance of linear block codes across finite fields.",
        "watermark_text": "Entropies are measures of uncertainty , and entropy energy inequalities ( EPIs ) quantify the trade - off between information transmission rates in different communication channels . In this research we present new proofs for EPIs based on communication theory ideas such as mutual information and channel capacity .We additionally prove that these results can be used to prove Shannon s source coding theorem by application them to an appropriate binary memoryless symmetric channel structure . Finally , we talk how our approach could potentially lead to greater bounds on the minimum length of linear block sequences over discrete fields .Entropies are measures of uncertainty ; entropy energy inequalities ( EPIS ) quantify the tradeoff between information transmission rates in different communication streams . In this research we present new proofs for EPIs using info - theory ideas like mutual information and channel capacity .We additionally prove that these results may be employed to confirm Shannon s source coding theorem via their application to a suitable binary memoryless - symmetric channel structure . Finally , we explain how our technique may possibly deliver improved bounds on the reduced distance of linear block sequences across bounded fields .",
        "ori-fast-z-score": 0.8,
        "water-fast-z-score": 7.0710678118654755
    },
    {
        "original_text": "We report on our analysis of the Suzaku observation of the z = 1.55 quasar, RBS 315 (RA=00h45m53.6s; DEC=-36d19 59.6 ). The source is detected with an average 2-10 keV flux of 4 x 10^-13 erg cm-2 s-1 corresponding to a luminosity of 3 x 10^44 erg s-1 at this redshift. We find that the spectrum can be well fitted by a power law model modified by Galactic absorption plus reflection component using pexrav model in XSPEC. This gives photon index Γ=1.9 +0.2 -0.1 , reflection fraction f=0.7 +1.0 -1.3 . The observed 0.5-7 keV band luminosity is found to be 5x10^43 erg/sec which corresponds to Eddington ratio L/L edd =0.01-0.03 assuming black hole mass M BH ~10 9 M sun .",
        "watermark_text": "We report on our analysis of the Suzaku observation of the z = 1 . 55 quasar , RBS 315 ( RA = 00h45m53 . 6s ; DEC = - 36d19 59 . 6 ) . The source is detected with an estimated 2 - 10 keV flux of 4 x 10 ^ - 13 erg centimetres - 2 s - 1 resulting to a luminosity of 3 x 10 ^ 44 erg s - 1 at this redshift .We see that the spectrum can be well fitted by a power law theory derived by Galactic absorption plus reflection factor used pexrav system in XSPEC . This gives photon index Γ = 1 . 9 + 0 . 2 - 0 . 1 , absorption proportion f = 0 . 7 + 1 . 0 - 1 . 3 .The observed 0 . 5 - 7 keV band luminosity is found to be 5x10 ^ 43 erg / sec which equals to Eddington ratio L / L edd = 0 . 01 - 0 . 03 assuming black hole weight M BH ~ 10 9 M sun .",
        "ori-fast-z-score": -0.31622776601683794,
        "water-fast-z-score": 2.846049894151541
    },
    {
        "original_text": "We report on XMM-Newton and Chandra X-ray Observatory (CXO) observations of the recently discovered high-energy gamma-ray source, TeV J2032+4131. The data show that this object is an active galactic nucleus with a power-law spectrum extending to at least 100 keV. We find no evidence for absorption by intervening material in excess of Galactic values along its line-of-sight. A comparison between our results and those obtained using other instruments suggests that there may be significant variability in both the flux density and spectral index of TeV J2032 + 4131 over timescales as short as one day. This would imply either rapid changes in intrinsic emission or strong Doppler boosting effects due to relativistic motion of the emitting region. \n \n Keywords: Active galactic nuclei, Gamma rays, Variability, X-rays, High energy astrophysics \n \n 1. Introduction \n \n In recent years, several new classes of high energy sources have been identified through their detection at very-high energies (E > 10 GeV). These include blazars, radio galaxies, pulsar wind nebulae, supernova remnants, starburst galaxies, galaxy clusters, and possibly even some nearby stars  1  . However, many of these objects are still poorly understood because they lack counterparts at lower frequencies where most of the relevant physical processes occur  2  .\n \nIn particular, it has proven difficult to identify the origin of the highest energy photons detected so far  3  , which can reach energies up to 1020 eV  4  . One possible explanation is that such photons are produced during interactions involving extremely energetic particles accelerated within compact regions close to supermassive black holes  5  . Alternatively, they could result from decays of neutral pions created when cosmic ray protons interact with ambient matter  6  . If confirmed, such events would provide important insights into particle acceleration mechanisms near black holes  7, 8  . \n \n Recently, the HESS collaboration reported the discovery of a bright point-like gammaray source located at RA = 20 h 32 m 41 s ± 5′′ and Dec = +39°30′00",
        "watermark_text": "We report on XMM - Newton and Chandra X - ray Observatory ( CXO ) observations of the recently discovered high - energy gamma - ray source , TeV J2032 + 4131 . The data demonstrate that this body is an active galactic nucleus with a power - law spectrum stretching to at least 100 keV .We see no evidence for absorption by intervening material in excess of Galactic values along its line - of - seeing . A comparison between our findings and those achieved using other instruments suggests that there may be considerable variability in both the flux concentration and spectral index of TeV J2032 + 4131 over timescales as short as one day .This might imply either rapid variations in intrinsic emission or strong Doppler boosting effects due to relativistic movement of the emitting area . Keywords : Active galactic nuclei , Gamma rays , Variability , X - rays , High energy astrophysics 1 .Introduction In recent years , various additional types of high energy sources have been described through their observation at very - large energies ( E > 10 GeV ) . These include blazars , television clusters , pulsar wind nebulae , supernova remnants , starburst clusters , galaxy clusters , and maybe even some nearby galaxies 1 .However , many of these objects are still ill explained because they lack counterparts at lower frequencies where most of the appropriate physical processes involve 2 . In particular , it has proven unable to identify the origin of the highest power photons discovered so far 3 , which can reach energies up to 1020 eV 4 .One potential explanation is that such photons are produced during interactions involving extremely excited particles driven within compact regions close to supermassive black holes 5 . Alternatively , they may come from decays of neutral pions created when cosmic ray protons interact with ambient material 6 .If confirmed , such events might give important knowledge into particle acceleration mechanisms near black holes 7 , 8 . Recently , the HESS collaboration reported the discovery of a bright point - like gammaray object found at RA = 20 h 32 m 41 s ± 5 ′ ′ and Dec = + 39°30 ′ 00",
        "ori-fast-z-score": 0.5696519211398116,
        "water-fast-z-score": 7.62440679314584
    },
    {
        "original_text": "We present new astrometric measurements for the candidate exoplanet companion to HD 33636, obtained with the Fine Guidance Sensor (FGS) on board the Hubble Space Telescope (HST). These data are combined with previously published radial velocities in order to determine the mass of this object. We find that it is most likely an M dwarf star with a mass between 0.3 and 1.0 times that of Jupiter s mass. The orbital parameters derived here agree well with those determined by previous authors using different techniques. This system may be similar to our own solar system at early stages of formation when planets were still forming around young stars. Keywords: Extrasolar planet -Astrometry -Radial velocity -HST -Mass determination -HD 33636 . \nIntroduction\n\nThe detection of extrasolar giant planets has been one of the major accomplishments of modern astronomy over the past decade. However, only about 10% of all known planetary systems contain such massive objects. Most of these have been discovered through high-precision Doppler spectroscopy or direct imaging methods. In contrast, very few low-mass companions have been found so far because they produce smaller reflex motions and/or lower luminosity than their more massive counterparts. As a result, there exists a large gap in the distribution of masses among known extra-solar planets ranging from several Earth masses down to Neptune-like masses. It is therefore important to search for low-mass companions as well since they can provide valuable information regarding the formation process of planetary systems. \n \n One possible way to detect low-mass companions is to use high-angular resolution observations made with space-based telescopes like HST. Such observations allow us to measure the position angle of the host star relative to its nearby neighbors. If we assume that the observed motion is due solely to gravitational interaction with another body then we can derive the projected separation and position angle of the companion. By combining these results with accurate radial-velocity measurements taken simultaneously, we can obtain the full three-dimensional orbit of the companion which allows us to calculate its mass.",
        "watermark_text": "We present new astrometric measurements for the candidate exoplanet companion to HD 33636 , obtained with the Fine Guidance Sensor ( FGS ) on board the Hubble Space Telescope ( HST ) . These data are coupled with previously reported radial velocities in order to predict the mass of this body .We see that it is most likely an M dwarf star with a mass between 0 . 3 and 1 . 0 times that of Jupiter s mass . The orbital characteristics obtained here agree well with those determined by earlier authors using similar method .This system might be analogous to our own solar body at early stages of formation when stars were still forming around developing planets . Keywords : Extrasolar planet - Astrometry - Radial velocity - HST - Mass determination - HD 33636 .Introduction The observation of extrasolar giant planets has been one of the main accomplishments of modern astronomy over the previous decade . However , only about 10 % of all known planetary complexes house such powerful entities .Most of these have been detected through high - speed Doppler spectroscopy or direct scanning techniques . In comparison , very few low - mass companions have been detected so far because they produce shorter reflex motions and / or smaller luminosity than their more massive counterparts .As a result , there exists a large gap in the distribution of masses among known extra - solar planets ranging from several Earth masses down to Neptune - like masses . It is consequently essential to search for low - density companions as well since they can provide valuable info regarding the formation transition of planetary structures .One potential way to identify low - weight companions is to use large - angular resolution measurements made with space - based telescopes like HST . Such observations allow us to measure the position angle of the recipient star compared to its local rivals .If we assume that the seen moving is due exclusively to gravitational interaction with another bodies then we can derive the projected separation and position angle of the companion . By combining these results with correct radial - speed measurements taken concurrently , we can obtain the full three - dimensional orbit of the companion which allows us to estimate its weight .",
        "ori-fast-z-score": -0.38461538461538464,
        "water-fast-z-score": 8.076923076923077
    },
    {
        "original_text": "We report the detection of absorption by silicates with an optical depth of 0.1 at 9.7 microns toward the quasar HE 0515-4414 (z = 0.52) using data obtained with ISO-SWS and LWS on board ISO. The silicate feature is detected only when we use the full resolution spectrum, which shows that it has been smoothed out due to blending with other features in lower-resolution spectra. We find no evidence for dust emission associated with this absorber. This result suggests that the absorbing material consists mainly of cold gas rather than warm dust. If so, then the mass of cool gas required to produce such strong absorption lines would be much larger than expected based on current models of galaxy formation. In addition, if the observed absorption arises solely from cold gas, then the implied covering factor of the absorber must be very large compared to what is seen in local galaxies.",
        "watermark_text": "We report the observation of absorption by silicates with an optical height of 0 . 1 at 9 . 7 microns toward the quasar HE 0515 - 4414 ( z = 0 . 52 ) using data acquired with ISO - SWS and LWS on board ISO . The silicate characteristic is detected only when we using the full resolution spectrum , which demonstrates that it has been softened out due to mixing with other properties in smaller - resolution spectra .We see no evidence for powder emission associated with this absorber . This result suggests that the absorbing material contains primarily of cold gas instead than cool dust .If so , then the mass of cold gas needed to produce such strong absorption patterns must be much larger than expected based on current theories of galaxy formation . In addition , if the seen emission arises solely from cool gas , then the implied covering element of the absorber would be very huge compared to what is seen in local stars .",
        "ori-fast-z-score": -0.7071067811865476,
        "water-fast-z-score": 6.3639610306789285
    },
    {
        "original_text": "We report on the fabrication and characterization of charge qubits based on self-assembled InAs quantum dots (QDs) embedded in GaAs/AlGaAs heterostructures. We show that by using an optimized growth procedure, we can achieve high quality QD layers with low density of defects which are crucial for achieving good coherence times. The samples were grown by molecular beam epitaxy at 600 °C under As-rich conditions to minimize the formation of threading dislocations. A single layer of self-assembled InAs/GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm thick Al0.3Ga0.7As barrier layer. Finally, a 20 nm thick GaAs capping layer was deposited. The sample structure is shown schematically in Figure 1 . The photoluminescence spectrum shows emission peaks centered around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states associated with charged excitons.",
        "watermark_text": "We report on the fabrication and description of charge qubits based on self - assembled InAs quantum dots ( QDs ) integrated in GaAs / AlGaAs heterostructures . We suggest that by using an optimized growth technique , we can attain high quality QD layers with minimal concentration of flaws which are important for achieving better coherence times .The samples were cultivated by molecular wave epitaxy at 600 °C under As - rich conditions to minimize the formation of threading dislocations . A single mesh of self - assembled InAs / GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm wide Al0 . 3Ga0 . 7As barrier layer .Finally , a 20 nm deep GaAs capping layer was extracted . The sample structure is displayed schematically in Figure 1 .The photoluminescence spectrum displays emission levels focused around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states correlated with charged excitons .",
        "ori-fast-z-score": -0.24253562503633297,
        "water-fast-z-score": 4.213504858001922
    },
    {
        "original_text": "We present an analysis of the most luminous quasars in the Sloan Digital Sky Survey; these are among the brightest known objects at any wavelength, and have been studied extensively over many years. We use Chandra observations to study their X-ray properties as well as those of lower-luminosity quasars with similar redshifts (z ~ 2). The results show that there is no significant difference between the two samples; both exhibit very hard spectra and high luminosities. This suggests that the physical processes responsible for producing X-rays do not depend strongly on quasar luminosity or redshift. In addition, we find evidence that the X-ray emission may be associated with outflows driven by winds originating near the central black hole. These findings provide new insights into how supermassive black holes grow during the early stages of galaxy formation. \n \n Keywords: quasars, X-ray emission, wind-driven outflow",
        "watermark_text": "We present an assessment of the most luminous quasars in the Sloan Digital Sky Survey ; these are among the brightest known objects at any wavelength , and have been studied frequently over numerous years . We use Chandra measurements to study their X - ray characteristics as well as those of lower - luminosity quasars with similar redshifts ( z ~ 2 ) .The results show that there is no major variation between the two specimens ; both exhibit very hard spectra and large luminosities . This implies that the physical processes responsible for producing X - radiation do not depend greatly on quasar luminosity or redshift .In addition , we find proof that the X - ray radiation may be involved with outflows driven by winds occurring near the main white hole . These studies provide fresh insights into how supermassive black holes expand during the early stages of galaxy formation .Keywords : quasars , X - ray radiation , wind - powered outflow",
        "ori-fast-z-score": 0.508000508000762,
        "water-fast-z-score": 6.350006350009525
    },
    {
        "original_text": "We report on diffuse X-ray emission in the Carina Nebula observed by Suzaku. The spectrum is well reproduced by thermal plasma models at kT = 0.7-1 keV and nH = (0.5-2) x 10^(22) cm^{-3}, which are consistent with those obtained previously for other regions within the nebula. We find that the total luminosity of this component amounts to Lx ~ 1.3 x 10^35 erg/sec, corresponding to about 10% of the total energy output of massive stars in the region. This suggests that hot gas produced by stellar winds and/or supernovae plays an important role in heating up the interstellar medium around young open clusters such as Trumpler 14-16. \n \n \n \n Keywords: Diffuse X-rays, Hot plasma, Open cluster, Supernova remnant, Stellar wind, Carina Nebula",
        "watermark_text": "We report on diffuse X - ray radiation in the Carina Nebula observed by Suzaku . The spectrum is well illustrated by thermal plasma estimates at kT = 0 . 7 - 1 keV and nH = ( 0 . 5 - 2 ) x 10 ^ ( 22 ) cm ^ { - 3 } , which are compatible with those observed previously for other regions within the nebula .We see that the total luminosity of this constituent amounts to Lx ~ 1 . 3 x 10 ^ 35 erg / sec , equivalent to about 10 % of the total energy produced of large galaxies in the region . This implies that hard gas created by stellar winds and / or supernovae plays an important role in heating up the interstellar medium around young open complexes such as Trumpler 14 - 16 .Keywords : Diffuse X - radiation , Hot plasma , Open core , Supernova remnant , Stellar wind , Carina Nebula",
        "ori-fast-z-score": -1.3127849234810511,
        "water-fast-z-score": 3.646624787447364
    },
    {
        "original_text": "We present the first results for atmospheric dynamics in short period extra-solar gas giant planets (EGPs) using 3D general circulation models with radiative transfer and realistic opacities. We find that the night-side temperature is strongly dependent on opacity, which determines how much energy can be transported to space by radiation. The day-night contrast increases as we decrease the opacity because less heat escapes through the nightside atmosphere. This effect is more pronounced at lower pressures where convection becomes inefficient. For low enough opacities, the planet cools down completely during its orbit resulting in an extremely cold night side. Our simulations show that EGPs are likely to have very different climates depending on their composition.  Keywords: General Circulation Modeling, Extrasolar Planetary Systems, Radiation Transfer, Climate, Atmosphere, Energy Transport, Convection, Cooling Rates, Day-Night Contrast",
        "watermark_text": "We present the first findings for atmospheric mechanics in small history additional - solar gas giant galaxies ( EGPs ) using 3D general circulation estimates with radiative transfer and realistic opacities . We see that the night - side temperature is strongly dependent on opacity , which determines how many heat can be transported to space by radiation .The day - night difference rises as we decrease the opacity because lighter thermal exits through the nightside environment . This phenomenon is more pronounced at lower pressures where circulation becomes inefficient .For low enough opacities , the planet cools down fully during its orbit producing in an incredibly cold evening side . Our simulations see that EGPs are likely to have very different climates based on their composition .Keywords: General Circulation Modeling, Extrasolar Planetary Systems, Radiation Transfer, Climate, Atmosphere, Energy Transport, Convection, Cooling Rates, Day-Night Contrast",
        "ori-fast-z-score": -0.2581988897471611,
        "water-fast-z-score": 4.905778905196061
    },
    {
        "original_text": "We present an approach to the description of macroscopic configurations in terms of quantum states, which is based on the concept of entanglement entropy and its generalization for mixed states. We show that this representation allows one to obtain exact results for some statistical properties of systems with many degrees of freedom. In particular, we consider the problem of calculating the partition function of classical spin models at high temperatures. The proposed method can be used as a basis for constructing approximate algorithms for solving problems related to the calculation of thermodynamic characteristics of complex systems. Introduction.\nThe main goal of statistical mechanics is to describe the behavior of macroscopic objects (for example, gases) by using microscopic information about their constituents (atoms). This task becomes especially difficult when dealing with large systems consisting of many particles or spins. For such cases, it is necessary to use approximations, since direct calculations are impossible due to the exponential growth of the number of possible microstates with increasing system size N . One of these approaches is the so-called mean-field approximation  1  , according to which each particle interacts only with all other particles simultaneously; i.e., the interaction between different pairs of particles is neglected. However, even within this simplified model, the calculation of the partition function Z = Tr exp(−βH) (1) remains extremely complicated  2  .\nIn recent years, there has been growing interest in developing new methods for describing macroscopic configurations in terms similar to those used in quantum physics  3  -  8  . These studies were inspired by the fact that both classical and quantum descriptions have certain common features  9  : they are formulated in terms of wave functions ψ(x), where x denotes either positions of particles or spins, respectively. Moreover, the evolution of these wave functions obeys the same Schrödinger equation ih∂ t |ψ(t) = H|ψ(t) , where H is the corresponding Hamiltonian operator. It should also be noted that the density matrix ρ = |ψ(t) ψ(t)| plays the role of a probability distribution in both theories  10  .",
        "watermark_text": "We present an view to the description of macroscopic configurations in terms of quantum states , which is based on the notion of entanglement entropy and its generalization for mixed states . We see that this representation enables one to obtain exact findings for some statistical characteristics of structures with many degrees of liberty .In particular , we investigate the question of calculating the splitting function of classical spin configurations at high heat . The proposed method can be used as a framework for constructing numerical algorithms for solving cases linked to the determination of thermodynamic qualities of complex systems .Introduction . The main goal of statistical mechanics is to explain the dynamics of macroscopic objects ( for example , atoms ) by using microscopic information about their components ( atoms ) .This job becomes especially difficult when dealing with large systems composed of several particles or spins . For such cases , it is important to use approximations , since direct calculations are unable due to the exponential growth of the number of possible microstates with increasing system width N .One of these method is the so - called mean - field approximation 1 , according to which each particle interacts only with all other particles concurrently ; i . e . , the interaction between multiple sets of particles is neglected . However , even within this simplified model , the determination of the partition function Z = Tr exp ( −βH ) ( 1 ) stays extremely difficult 2 .In recent years , there has been growing interest in advanced new concepts for describing macroscopic configurations in terms comparable to those utilized in quantum science 3 - 8 . These studies were inspired by the fact that both classical and quantum descriptions have many common features 9 : they are formulated in terms of wave vectors ψ ( z ) , where h indicates either positions of atoms or spins , respectively .Moreover , the evolution of these wave functions obeys the same Schrödinger equation ih∂ t | ψ ( t ) = H | ψ ( t ) , where H is the analogous Hamiltonian operator . It should additionally be mentioned that the density function ρ = | ψ ( t ) ψ ( t ) | serves the importance of a probability distribution in both models 10 .",
        "ori-fast-z-score": 0.23643312187173018,
        "water-fast-z-score": 8.799551054765924
    },
    {
        "original_text": "We have performed simulations of nova explosions using the hydrodynamic code VH-1, which includes nuclear burning and convection. We find that changes to reaction rates can significantly affect the results of these calculations. In particular, we show how different choices for the 12C(p,γ)13N rate lead to differences in the predicted light curve shapes.  The inclusion of this reaction is important because it affects the amount of 13N produced during the explosion. This isotope decays by electron capture into 14O, which then undergoes β+ decay back down to 14N. If there are too many electrons present at late times (due to an overabundance of 13N), they will be captured onto protons instead of being emitted as positrons; thus, less energy will be released than if no such process were occurring. Our results suggest that the current uncertainty in the 12C(p , γ )13N rate may cause errors in the predicted luminosity of up to 50%.",
        "watermark_text": "We have done simulations of nova explosions using the hydrodynamic code VH - 1 , which includes nuclear combustion and convection . We see that changes to reaction rates can significantly affect the results of these calculations .In particular , we study how various options for the 12C ( p , γ ) 13N rate lead to differences in the expected light curve sizes . The inclusion of this response is important because it affects the quantity of 13N produced during the explosion .This isotope decays by electron capture into 14O , which then undergoes β + decay back down to 14N . If there are too several electrons present at late times ( owing to an overabundance of 13N ) , they will be captured onto protons rather of being emitted as positrons ; thus , fewer electricity will be emitted than if no such mechanism were happening .Our results propose that the present uncertainty in the 12C ( p , γ ) 13N rate may create errors in the expected luminosity of up to 50 % .",
        "ori-fast-z-score": -0.5,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "We present an analytical theory for describing capillary forces between two spherical particles in contact with each other and immersed into a liquid, which is valid even when the separation distance between them becomes comparable to their size. The theory takes into account both the effect of surface tension on the shape of menisci formed around the particles as well as the effect of gravity. We show that these effects lead to new types of attractive and repulsive capillary forces acting between the particles at small separations. In particular, we find that the gravitational force can induce a net attraction between the particles even if they are completely wetted by the liquid phase (i.e., have no dry patches). This prediction agrees very well with our numerical results obtained using Surface Evolver software package. Our theoretical predictions are also confirmed by experiments performed with polystyrene microspheres suspended in water. Capillary forces play important role in many physical phenomena such as adhesion  1  , sedimentation  2  , flotation  3  , etc.. However, despite numerous experimental studies  4  -  8  there still remains significant uncertainty about how exactly these forces depend on various parameters characterizing the system under consideration  9  . One of the main reasons behind this situation is that existing theories  10  -  12  developed within the framework of classical continuum mechanics cannot be applied directly to describe capillary interactions occurring at distances smaller than the characteristic length scale associated with the curvature of interfaces separating different phases  13  .\nIn order to overcome this difficulty one usually resorts to some approximate approaches based either on the concept of effective Hamaker constants  14  or on the so-called  superposition approximation   15  . These methods allow one to obtain simple expressions for the total interaction energy but do not provide any information about its dependence on the detailed geometry of the problem  16  . Moreover, it has been shown recently  17  that the latter approach fails...",
        "watermark_text": "We present an analytical theory for describing capillary forces between two spherical objects in contact with each other and immersed into a liquid , which is valid even when the separation distance between them becomes comparable to their size . The theory took into consideration both the impact of surface friction on the form of menisci constructed around the molecules as well as the impact of gravitational .We see that these influences result to novel sorts of attractive and repulsive capillary forces working between the particles at small separations . In particular , we find that the gravitational field can induce a net attraction between the molecules even if they are completely wetted by the liquid phase ( i . e . , have no dry patches ) .This prediction agrees very best with our numerical findings obtained using Surface Evolver tool package . Our conceptual predictions are also verified by research performed with polystyrene microspheres hanging in water .Capillary forces play vital role in many mechanical phenomena such as adhesion 1 , sedimentation 2 , flotation 3 , etc . . However , despite several experimental studies 4 - 8 there still remains significant doubt about how exactly these forces depend on various variables characterizing the process under consideration 9 .One of the main motives behind this situation is that original theories 10 - 12 developed within the framework of classical continuum mechanics cannot be applied directly to explain capillary behavior happening at distances smaller than the typical length range identified with the curvature of interfaces separating different stages 13 . In try to overcome this obstacle one usually resorts to some approximate approaches depending either on the idea of effective Hamaker constants 14 or on the so - called superposition approximation 15 .These methods provide one to obtain simple definitions for the total interaction power but do not offer any knowledge about its dependence on the detailed geometry of the question 16 . Moreover , it has been shown recently 17 that the latter technique fails . . .",
        "ori-fast-z-score": -0.16329931618554522,
        "water-fast-z-score": 8.765781549553733
    },
    {
        "original_text": "We present an experimental investigation into complementarity between position and momentum measurements on single photons using a modified version of the original Einstein-Bohr photon box experiment.  The results show that, for this particular measurement scheme, there is no violation of Bell s inequality or any other form of nonlocality. We also demonstrate how our setup can be used to investigate quantum contextuality by performing two different experiments with identical settings but opposite outcomes. In one case we observe violations of Bell inequalities while in the other they are not violated. This shows that the observed behavior cannot be explained within classical physics and demonstrates quantum contextuality. Quantum mechanics predicts that certain physical quantities such as position and momentum do not have simultaneous well-defined values. Instead these quantities exist only as probability distributions which evolve continuously over time according to Schrödinger s equation. However, it has been shown that if both position and momentum were measured simultaneously then their respective probabilities would interfere destructively resulting in a zero probability of measuring either quantity at its most probable value  1  . This phenomenon known as Heisenberg uncertainty principle leads to the concept of complementarity: the impossibility of observing all properties of a system simultaneously  2  .\nIn 1964 John Bell showed that local hidden variable theories could not explain some predictions made by quantum mechanics  3  , leading to the formulation of Bell s theorem  4  . Since then many experiments have been performed to test whether quantum mechanical predictions violate Bell s theorem  5  . These tests typically involve entangled particles  6  where each particle carries information about the state of another distant particle  7, 8  . If the particles are separated far enough so that they never interact again after being created, then the correlations between them must be due solely to quantum effects  9  .",
        "watermark_text": "We present an experimental inquiry into complementarity between position and momentum estimates on single photons using a altered version of the original Einstein - Bohr photon box observation . The results show that , for this special measurement scheme , there is no violation of Bell s inequality or any other form of nonlocality .We additionally prove how our setup can be used to examine quantum contextuality by performing two different trials with identical settings but different outcomes . In one instance we exhibit abuses of Bell inequalities while in the other they are not upheld .This shows that the seen behavior cannot be described within classical physics and demonstrates quantum contextuality . Quantum theory predicts that particular physical components such as position and momentum do not have simultaneous well - defined parameters .Instead these quantities occur only as probability distributions which evolution continuously over time according to Schrödinger s equation . However , it has been shown that if both position and momentum were calculated separately then their different probabilities would interfere destructively resulting in a zero probability of assessing either quantity at its most likely value 1 .This phenomenon known as Heisenberg uncertainty theory gives to the notion of complementarity : the impossibility of experiencing all characteristics of a system simultaneously 2 . In 1964 John Bell demonstrated that nearby secret variable theories cannot not understand some observations made by quantum mechanics 3 , leading to the realization of Bell s theorem 4 .Since then many tests have been performed to test whether quantum mechanical predictions violate Bell s theorem 5 . These studies typically involve entangled particles 6 where each particle contains information about the state of another distant particle 7 , 8 .If the molecules are apart farther enough so that they cannot interact again after being created , then the correlations between them need be due exclusively to quantum effects 9 .",
        "ori-fast-z-score": -0.17149858514250882,
        "water-fast-z-score": 8.231932086840423
    },
    {
        "original_text": "We present an analytical model for calculating the aperture efficiency of a reflector antenna with circularly polarized feeds, based on ray tracing through the feed-horn optics and physical optics (PO) at the aperture plane. The PO method is used to calculate the electric field distribution over the aperture surface by solving Maxwell s equations using Green functions. We show that this approach can be applied to any type of feed horns, including corrugated conical horns or dual-polarized log-periodic dipole arrays. This work was motivated by our recent study of aperture efficiencies of two different types of antennas operating at 1.4 GHz: a single-dish radio telescope equipped with a corrugated conical feed horn and a multi-element interferometer consisting of eight log-periodic dipole array elements. In both cases we found good agreement between numerical results obtained with our new model and experimental data. \n \n Keywords: Antenna design",
        "watermark_text": "We present an analytical model for determining the lens energy of a reflector antenna with circularly polarized feeds , using on ray tracing through the feed - horn optics and physical optics ( PO ) at the aperture plane . The PO technique is utilized to estimate the electric field flow over the lens surface by solving Maxwell s equations using Green functions .We see that this methodology can be applied to any type of feed horns , particularly corrugated conical horns or multiple - polarized log - periodic dipole arrays . This research was sparked by our latest research of aperture efficiencies of two different kinds of antennas active at 1 . 4 GHz : a single - dish radio telescope fitted with a corrugated conical feed trumpet and a multi - component interferometer composed of eight log - periodic dipole array modules .In both cases we concluded excellent agreement between mathematical findings obtained with our new model and experimental evidence . Keywords : Antenna design",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 4.714045207910317
    },
    {
        "original_text": "We present the light-cone distribution amplitudes (DAs) for axial vector mesons in terms of their helicity components, which are determined by solving the Bethe-Salpeter equation with an instantaneous interaction kernel and applying the method developed recently to calculate DAs.  We find that the twist-2 DA is dominated by its first Gegenbauer moment, while higher moments contribute significantly only at large momentum fractions x > 0.7. The twist-3 DA has two independent functions, one of them being proportional to the second Gegenbauer moment. Our results show that the twist-4 contribution is negligible compared to those of lower twists. These findings will be useful for studying exclusive processes involving axial vector mesons such as B-decays into charmonium plus photon or pion pair. \nI. INTRODUCTIO N\nThe study of hadronic structure plays an important role in understanding strong interactions between quarks and gluons inside hadrons. In particular, the investigation on the parton distributions provides us valuable information about how quarks and gluon are distributed within hadrons  1  . Recently, there have been great interests in exploring the internal structures of hadrons beyond the leading-twist level  2  , especially the transverse-momentum dependent parton distributions  3  .\nIn this work we focus our attention on another type of nonperturbative objects -the light-cone distribution amplitudes(DAs). They describe the probability amplitude of finding a quark-antiquark pair with certain longitudinal momentum fraction and transverse separation at some fixed light-like distance  4  . It was shown that they play crucial roles in describing various hard exclusive reactions  5  . For example, the decay constants fBπ and fBs can be expressed in terms of the lowest-order DAs  6  ; the form factors of semileptonic decays B→πlν l and B→Klν l depend on both the lowest-and next-to-lowest order DAs  7, 8  . Furthermore, it was found that the heavy-to-light transition form factor FV(q 2 ) of B→V transitions depends",
        "watermark_text": "We introduce the light - cone distribution amplitudes ( DAs ) for axial vector mesons in terms of their helicity components , which are decided by solving the Bethe - Salpeter equation with an instantaneous interaction kernel and using the method developed lately to estimate DAs . We see that the twist - 2 DA is dominated by its initial Gegenbauer moment , while greater moments contribute considerably only at large velocity fractions x > 0 . 7 .The twist - 3 DA has two independent functions , one of them being equal to the second Gegenbauer moment . Our results show that the twist - 4 contribution is negligible compared to those of lower bends .These studies will be valuable for studying exclusive mechanisms using axial vector mesons such as B - decays into charmonium plus photon or pion pair . I . INTRODUCTIO N The investigation of hadronic structure serves an important role in understanding strong interactions between quarks and gluons inside hadrons .In particular , the investigation on the parton distributions offers us valuable info about how quarks and gluon are distributed within hadrons 1 . Recently , there have been big efforts in investigating the internal structures of hadrons beyond the led - twist level 2 , particularly the transverse - momentum dependent parton distributions 3 .In this research we focus our focus on another type of nonperturbative objects - the light - cone distribution amplitudes ( DAs ) . They define the probability amplitude of finding a quark - antiquark pair with certain horizontal momentum fraction and longitudinal separation at some fixed light - like distance 4 .It was shown that they serve vital part in understanding various hard exclusive reactions 5 . For instance , the decay constants fBπ and fBs can be stated in terms of the lowest - order DAs 6 ; the form factors of semileptonic decays B→πlν l and B→Klν l depend on both the highest - and last - to - lowest order DAs 7 , 8 .Furthermore , it was shown that the heavy - to - light shift form parameter FV ( q 2 ) of B→V transitions depends",
        "ori-fast-z-score": 1.044465935734187,
        "water-fast-z-score": 8.181649829917799
    },
    {
        "original_text": "We present an algorithm for computing two-person zero-sum games with imperfect information, which is based on solving linear programs (LPs) and mixed integer programming problems (MIPs). The proposed approach can be applied to any game that has been formulated as a Mixed Integer Linear Program (MILP), including many real-world applications such as energy markets or traffic control systems. We show how our method outperforms state-of-the-art algorithms in terms of computational efficiency by applying it to several test cases. In addition, we provide insights into the structure of the problem instances solved by our algorithm. Finally, we discuss possible extensions of this work. Games are mathematical models used to describe situations where multiple decision makers interact strategically. A key concept in game theory is equilibrium, i.e., a set of strategies that no player wants to deviate from if all other players stick to their strategy. One important class of equilibria are so-called Nash equilibria, which have received considerable attention over the past decades due to their wide applicability across various fields ranging from economics to computer science. However, finding Nash equilibria is known to be computationally hard even for simple classes of games.",
        "watermark_text": "We present an algorithm for modeling two - person zero - sum games with imperfect data , which is based on solving linear programs ( LPs ) and combined integer programming questions ( MIPs ) . The proposed approach can be applied to any game that has been formulated as a Mixed Integer Linear Program ( MILP ) , including much actual - global applications such as energy markets or highway control networks .We see how our technique outperforms state - of - the - art algorithms in terms of computational efficiency by application it to several test situations . In addition , we provide insights into the composition of the question objects solved by our algorithm .Finally , we explain possible extensions of this research . Games are mathematical models used to define situations where multiple thinking makers interact strategically .A central concept in play theory is equilibrium , i . e . , a setting of plans that no player wants to deviate from if all other players stick to their strategy . One important group of equilibria are so - called Nash equilibria , which have received considerable scrutiny over the previous decades owing to their wide applicability across numerous topics including from economics to computer science .However , finding Nash equilibria is known to be computationally hard even for simple groups of games .",
        "ori-fast-z-score": 0.6965260331469925,
        "water-fast-z-score": 6.931032800836721
    },
    {
        "original_text": "We study the vacant set of random interlacements in Rd, d>1, which is defined as the complement of the union of all open paths starting at 0 up to time 1. We prove that it has Hausdorff dimension equal to d-1 almost surely by showing that its upper Minkowski dimension equals this value with probability one. This result extends previous results on the vacant set of simple random walk obtained by Lawler, Schramm and Werner (Annals of Probability 24(3), 1997) and Benjamini, Kalai and Schramm (Journal of Functional Analysis 157(1), 2000). The proof relies heavily on recent developments concerning the geometry of Brownian motion and the theory of stable processes. In particular we use an estimate for the Green function of the killed Brownian motion due to Bass and Burdzy (Annales de l Institut Henri Poincare 22(2), 1999).\nThe main motivation behind our work comes from percolation theory where the vacant set of random walks plays a crucial role. Indeed, we show how our techniques can be used to obtain new information about the critical behavior of bond-percolation models on Zd.",
        "watermark_text": "We test the empty set of random interlacements in Rd , d > 1 , which is defined as the complement of the union of all open routes starting at 0 up to time 1 . We establish that it has Hausdorff size equal to d - 1 fairly surely by showing that its outer Minkowski dimension equals this value with probability one .This result continues preceding results on the empty set of simple random walk obtained by Lawler , Schramm and Werner ( Annals of Probability 24 ( 3 ) , 1997 ) and Benjamini , Kalai and Schramm ( Journal of Functional Analysis 157 ( 1 ) , 2000 ) . The proof draws highly on current developments concerning the topology of Brownian movement and the notion of stable processes .In particular we using an estimate for the Green function of the dead Brownian moving thanks to Bass and Burdzy ( Annales de l Institut Henri Poincare 22 ( 2 ) , 1999 ) . The main motivation behind our work comes from percolation theory where the empty set of random walks holds a crucial role .Indeed , we prove how our approaches can be used to obtain new information about the important dynamics of bond - percolation models on Zd .",
        "ori-fast-z-score": -1.2874526191574363,
        "water-fast-z-score": 4.88240082724041
    },
    {
        "original_text": "We present the design and performance of an extremely low-noise, high-accuracy cryogenic mechanical oscillator based on a suspended silicon nitride membrane with integrated Josephson junctions. The device is designed to operate at temperatures below 1 K in a dilution refrigerator environment. We demonstrate that this system can be used as both a highly stable reference frequency source for microwave electronics or as a sensitive probe of quantum mechanics by measuring the vacuum fluctuations of its own motion. \n \n A key requirement for many applications of quantum information science is the ability to generate and detect single photons. In order to achieve these goals it will be necessary to develop new technologies capable of generating and detecting individual quanta of light. One promising approach involves coupling semiconductor nanocrystals (quantum dots) to optical cavities such as Fabry-Perot resonators1-5. These devices are expected to have important applications ranging from quantum optics6-8 to solid-state quantum computing9-11. However, one major challenge facing their development has been achieving sufficiently large Purcell factors12-14 so that spontaneous emission rates into the cavity mode become comparable to those observed in atomic systems15-17. This problem may be overcome using photonic crystal cavities18-20 which allow for strong confinement of electromagnetic fields within small volumes21-23.",
        "watermark_text": "We present the specification and performance of an incredibly small - noise , large - accuracy cryogenic mechanical oscillator based on a suspended silicon nitride cell with integrated Josephson junctions . The system is designed to work at pressures below 1 K in a dilution fridge climate .We showed that this device can be used as both a highly stable reference wavelength source for microwave electronics or as a sensitive probe of quantum mechanics by monitoring the vacuum fluctuations of its own movement . A crucial requirement for many applications of quantum information physics is the ability to create and locate single photons .In order to achieve these objectives it will be required to develop new inventions responsible of collecting and detecting individual quanta of light . One promising solution involves coupling semiconductor nanocrystals ( quantum dots ) to laser cavities such as Fabry - Perot resonators1 - 5 .These systems are expected to have important use ranging from molecular optics6 - 8 to soft - state quantum computing9 - 11 . However , one major challenge facing their development has been achieving sufficiently huge Purcell factors12 - 14 so that spontaneous emission rates into the cavity mode become similar to those observed in nuclear systems15 - 17 .This problem could be overcome using photonic crystal cavities18 - 20 which allow for strong confinement of electromagnetic forces within tiny volumes21 - 23 .",
        "ori-fast-z-score": 0.8867963503478639,
        "water-fast-z-score": 7.921180343813395
    },
    {
        "original_text": "We present the results of our numerical simulations of magnetized, rotating white dwarf stars that undergo accretion-induced collapse (AIC). We find that for sufficiently rapid rotation and strong magnetic fields, AIC leads to an explosion with properties similar to those observed in SNe Ia. The explosion is driven by the release of gravitational energy as the collapsed core bounces back after reaching nuclear density. In addition, we show that the presence of a strong toroidal field can lead to significant asymmetries in the ejecta distribution. These asymmetries are likely responsible for the polarization signal detected in some SNe Ia. \n \n Keywords: Supernovae Type Ia, Rotation, Magnetic Fields, White Dwarf Stars, Accretion Induced Collapse \n \n 1 Introduction \n \n Recent observations have shown that many supernovae type Ia (SNe Ia) exhibit large amounts of linear polarization  1  . This has been interpreted as evidence that these events result from asymmetric explosions  2  , which may be caused by large-scale magnetic fields  3  or rapid rotation  4  . However, it remains unclear whether either mechanism alone could produce such highly polarized light curves  5  . \n \n Here we investigate how the combination of rapid rotation and strong magnetic field affects the outcome of accretion induced collapse (AIC), where a white dwarf star collapses into a neutron star  6  . For this purpose, we perform two-dimensional axisymmetric hydrodynamic simulations using the code FLASH  7  . Our initial models consist of rigidly-rotating white dwarf stars with masses ranging between 0.6-1.2 Msun  8  . To account for the effects of general relativity on the structure of the white dwarf  9  , we use the polytropic equation of state P = Kρ Γ , where ρ denotes the mass density and P the pressure  10  . \nThe main goal of this work is to determine if AICs triggered by rapid rotation and/or strong magnetic fields can explain the high degree of polarization observed in SNe Ia  11  .",
        "watermark_text": "We present the conclusion of our numerical simulations of magnetized , moving white dwarf stars that suffer accretion - caused collapse ( AIC ) . We see that for enough fast rotation and strong magnetic fields , AIC leads to an explosion with properties similar to those observed in SNe Ia .The explosion is powered by the release of gravitational energy as the collapsed center bounces backward after reaching nuclear density . In addition , we find that the presence of a powerful toroidal field can lead to significant asymmetries in the ejecta distribution .These asymmetries are likely responsible for the polarization signal found in some SNe Ia . Keywords : Supernovae Type Ia , Rotation , Magnetic Fields , White Dwarf Stars , Accretion Induced Collapse 1 Introduction Recent measurements have shown that several supernovae class Ia ( SNe Ia ) exhibit substantial concentrations of linear polarization 1 .This has been viewed as proof that these phenomena come from asymmetric explosions 2 , which may be caused by large - scale magnetic waves 3 or rapid rotation 4 . However , it remains unsure whether either mechanism alone could generate such heavily polarized light curves 5 .Here we investigate how the combination of rapid rotation and strong magnetic force determines the result of accretion induced collapse ( AIC ) , where a white dwarf star collapses into a neutron galaxy 6 . For this use , we perform two - dimensional axisymmetric hydrodynamic simulations using the code FLASH 7 .Our preliminary estimates consist of rigidly - spinning white dwarf stars with masses ranging between 0 . 6 - 1 . 2 Msun 8 . To account for the effects of general relativity on the composition of the white dwarf 9 , we utilize the polytropic equation of state P = Kρ Γ , where ρ indicates the mass density and P the pressure 10 .The main goal of this research is to find if AICs triggered by rapid rotation and / or strong magnetic waves can describe the high degree of polarization observed in SNe Ia 11 .",
        "ori-fast-z-score": 1.1188618555710317,
        "water-fast-z-score": 7.487767802667673
    },
    {
        "original_text": "We present results on dust formation in primordial supernova remnants (SNRs) using three-dimensional hydrodynamic simulations with detailed chemical networks for gas-phase species, grains, and molecules. We find that dust can form efficiently in SNR ejecta at high temperatures (T > 1000 K), but it is destroyed by sputtering due to collisions between ions and electrons when the temperature drops below T = 100 K. The surviving dust grains are injected into the interstellar medium (ISM). Our calculations show that the total mass of dust formed in primordial SNRs may reach up to 10^-4 Msun if we assume an initial metallicity Z = 0.1Zsun. This value agrees well with observations of nearby young SNRs. However, our model predicts too much carbonaceous dust compared to silicates observed in these objects. If this discrepancy persists after further improvements of the models, then some other mechanism should be responsible for producing silicates in SNRs. \n \n Keywords: dust, supernova remnant",
        "watermark_text": "We report findings on dust development in primordial supernova remnants ( SNRs ) using three - dimensional hydrodynamic simulations with complete biological networks for gas - phase species , grains , and molecules . We see that matter can form efficiently in SNR ejecta at high temperatures ( T > 1000 K ) , but it is destroyed by sputtering due to collisions between electrons and electrons when the temperature falls below T = 100 K . The remaining powder grains are pumped into the interstellar medium ( ISM ) .Our calculations show that the total mass of dust formed in primordial SNRs might reach up to 10 ^ - 4 Msun if we suppose an initial metallicity Z = 0 . 1Zsun . This value agrees well with observations of distant new SNRs .However , our model predicts too much carbonaceous powder compared to silicates observed in these objects . If this discrepancy persists after further changes of the models , then some other mechanism should be responsible for producing silicates in SNRs .Keywords : dust , supernova remnant",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 4.737364557517151
    },
    {
        "original_text": "We report the discovery of three planets orbiting an intermediate-mass subgiant star, HD 168625 (M = 1.5 Msun), using high-precision radial velocity measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile. The planet masses are 0.7 MJup , 2.1 MJup , and 3.2 MJup . We find that all three planets have orbital periods shorter than 100 days; two of them are close to their host stars (P orb < 10 d). All three planets are located within the habitable zone around their host star. This is one of only four systems known so far where more than one planet has been found inside this region.  These results demonstrate that it should be possible to detect terrestrial planets in the habitable zones of evolved stars by means of Doppler spectroscopy. Keywords: exoplanet, planetary system",
        "watermark_text": "We report the discovery of three planets orbiting an intermediate - weight subgiant star , HD 168625 ( M = 1 . 5 Msun ) , using high - precision radial speed measurements obtained with the HARPS spectrograph at La Silla Observatory in Chile . The planet masses are 0 . 7 MJup , 2 . 1 MJup , and 3 . 2 MJup .We see that all three worlds have orbital periods shorter than 100 hours ; two of them are close to their host stars ( P orb < 10 d ) . All three planets are situated within the habitable zone around their host star .This is one of only four systems available so far where more than one planet has been seen inside this area . These data demonstrate that it should be possible to identify terrestrial worlds in the habitable zones of evolved planets by means of Doppler spectroscopy .Keywords: exoplanet, planetary system",
        "ori-fast-z-score": -0.29488391230979427,
        "water-fast-z-score": 3.5386069477175313
    },
    {
        "original_text": "We study the dynamics of string cosmologies with nontrivial dilaton potentials, focusing on their chaotic behavior. We show that for certain classes of potentials there are regions where trajectories can be trapped by unstable fixed points or periodic orbits. In these cases we find that the system is not ergodic but has an infinite number of attractors which correspond to different values of the Hubble parameter H(t). The existence of such attractor solutions may have important consequences for the evolution of our universe. For example, it could explain why the present value of H(t) differs so much from its initial value at t = 0. It also provides a possible explanation for the observed flatness problem since the volume V (t) grows exponentially fast during inflation while the energy density decreases as 1/V (t).\nThe results presented here were obtained using numerical methods based on the fourth-order Runge-Kutta algorithm combined with Newton s method for finding roots.",
        "watermark_text": "We research the dynamics of string cosmologies with nontrivial dilaton potentials , concentrating on their chaotic dynamics . We see that for particular categories of potentials there are areas where trajectories can be trapped by unstable fixed points or periodic orbits .In these circumstances we find that the system is not ergodic but has an endless number of attractors which belong to different values of the Hubble parameter H ( t ) . The existence of such attractor solutions may have important implications for the evolution of our universe .For instance , it could explain why the present value of H ( t ) changes so greatly from its initial value at t = 0 . It additionally offers a possible reason for the seen flatness problem since the volume V ( t ) rises exponentially rapidly during inflation while the electricity capacity reduces as 1 / V ( t ) .The results presented here were obtained using numerical technique based on the fourth - order Runge - Kutta algorithm coupled with Newton s method for finding roots .",
        "ori-fast-z-score": -0.48507125007266594,
        "water-fast-z-score": 4.85071250072666
    },
    {
        "original_text": "The BFKL equation is an effective theory for describing high-energy scattering processes at small Bjorken-x, where x denotes the fraction of longitudinal momentum carried by one of the colliding hadrons or nuclei. The BFKL formalism has been developed into a practical tool to calculate cross sections and structure functions using numerical methods. In this talk I will present recent results on the calculation of the gluon Green s function within the framework of the so-called  dipole approach  which allows us to perform calculations analytically. This method was first introduced by Mueller and Tang in order to study diffractive deep-inelastic scattering (DDIS) off protons. It can be applied also to other processes like heavy quark production in proton-proton collisions as well as photon-photon interactions. We will discuss how we have implemented these ideas numerically and show some preliminary results obtained with our code. Finally, we will comment on possible extensions of this work towards more realistic phenomenological applications.",
        "watermark_text": "The BFKL equation is an efficient model for describing long - energy scattering phenomena at small Bjorken - x , where x denotes the fraction of longitudinal momentum carried by one of the colliding hadrons or nuclei . The BFKL formalism has been built into a practical tool to estimate cross sections and structure functions using numerical models .In this talk I will present recent results on the determination of the gluon Green s function within the framework of the so - called dipole approach which allows us to conduct measurements analytically . This method was first developed by Mueller and Tang in order to study diffractive deep - inelastic reflection ( DDIS ) off protons .It can be applied also to other processes like heavy quark production in proton - proton collisions as well as photon - photon interactions . We will explore how we have formulated these ideas numerically and get some preliminary outcomes received with our code .Finally , we will mention on potential extensions of this research towards more realistic phenomenological applications .",
        "ori-fast-z-score": 0.601929265428846,
        "water-fast-z-score": 5.259005881071332
    },
    {
        "original_text": "The Standard Model (SM) is an extremely successful theory, but it leaves many questions unanswered about physics at very high energies. In particular, there are no known fundamental principles that can explain why the SM has three generations of quarks and leptons with such different masses or how gravity fits into this picture. Theories beyond the Standard Model attempt to address these issues by introducing new particles and/or interactions which may be observed in future experiments.  Supersymmetry (SUSY), for example, introduces partners for all SM fields whose spin differs by one half unit. These partner states have identical gauge quantum numbers as their SM counterparts, so they could mix with them if SUSY were broken at low energy scales. This mixing would lead to deviations from SM predictions for observables like cross sections and decay rates. Many extensions of the Standard Model also predict new phenomena associated with extra dimensions of space-time. For instance, theories based on string/M-theory often contain additional spatial dimensions compactified down to tiny sizes. If these extra dimensions exist, then we should see evidence of their effects through virtual exchange of Kaluza-Klein excitations of gravitons and other particles between SM fields localized on our four-dimensional world-volume.",
        "watermark_text": "The Standard Model ( SM ) is an incredibly successful theory , but it leaves many issues unanswered about physics at very high energies . In particular , there are no available fundamental principles that can describe why the SM has three generations of quarks and leptons with such distinct masses or how gravity fits into this picture .Theories beyond the Standard Model attempt to alleviate these problems by introducing additional particles and / or relationships which would be found in future research . Supersymmetry ( SUSY ) , for example , creates partners for all SM fields whose spin varies by one half unit .These partner states have equal gauge quantum values as their SM counterparts , so they may blend with them if SUSY were breaking at low power scales . This blending would result to deviations from SM predictions for observables like cross sections and decay rates .Many modifications of the Standard Model also predict new concepts associated with extra dimensions of space - time . For instance , theories based on string / M - theory often contain extra spatial dimensions compactified down to small sizes .If these extra dimensions exist , then we should see evidence of their influence through virtual exchange of Kaluza - Klein excitations of gravitons and other particles between SM fields confined on our four - dimensional world - volume .",
        "ori-fast-z-score": 1.2247448713915892,
        "water-fast-z-score": 7.005888539421972
    },
    {
        "original_text": "The Large Hadron Collider (LHC) is expected to produce new particles that could be dark matter candidates, such as supersymmetric partners of quarks or leptons.  In this talk I will discuss how these signatures can be searched for using data collected by the ATLAS experiment during Run 1 of the LHC. The results are presented both in terms of limits on production cross sections and mass exclusion regions. Finally, prospects for future searches with Run 2 data are discussed. This work was performed within the framework of the PhD thesis of M.A.M., supervised by A.S.. \nIntroduction\n\nDark Matter Candidates\n\nSupersymmetry\n\nATLAS Experiment\n\nRun 1 Results\n\nProspects for Run 2 Searches\n\nConclusions & Outlook \n\nReferences \n\n\nAcknowledgements\n\n\n\n\n\n- - - - - - - -- - - - - - --- - - - - - ---- - - - - - ----- - - - - - ------ - - - - - -------- - - - - - ---------- - - - - - ------------------ - - - - - -------------- - - - - - ----------------------------------- - - - - - ----------------------------------------------------- - - - - - ------------------------------------------------------------------------------------ - - - - -",
        "watermark_text": "The Large Hadron Collider ( LHC ) is expected to produce new objects that might be dark matter candidates , such as supersymmetric partners of quarks or leptons . In this talk I will explore how these signatures can be searched for utilizing information collected by the ATLAS experiment during Run 1 of the LHC .The results are presented both in terms of limits on production cross sections and mass isolation regions . Finally , prospects for future investigations with Run 2 data are discussed .This project was done within the framework of the PhD thesis of M . A . M . , overseen by A . S . . Introduction Dark Matter Candidates Supersymmetry ATLAS Experiment Run 1 Results Prospects for Run 2 Searches Conclusions & Outlook References Acknowledgements - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -",
        "ori-fast-z-score": 1.2977713690461004,
        "water-fast-z-score": 4.767570631855362
    },
    {
        "original_text": "We present new near-infrared observations of the edge-on spiral galaxy NGC 891, obtained with VLT/VISIR and Gemini/NIRI at wavelengths between 8 and 13 microns (rest-frame). We detect an extended emission feature that is perpendicular to the galactic disk and extends up to 3 kpc into the halo. The morphology suggests that this structure consists of two components: one located close to the midplane and another one located about 1.5 kpc higher than it. This second component has a temperature of T = 120 K ± 20 K and shows no evidence for significant extinction by dust grains along its line-of-sight. Its luminosity corresponds to a star formation rate of 0.1 M⊙ yr−1. These results are consistent with previous studies suggesting that there exists a population of young stars outside the main body of galaxies. They also provide further support for models where supernovae explosions trigger large-scale outflows of gas and dust which can be responsible for the enrichment of intergalactic space.",
        "watermark_text": "We report new near - infrared observations of the edge - on spiral galaxy NGC 891 , obtained with VLT / VISIR and Gemini / NIRI at wavelengths between 8 and 13 microns ( rest - frame ) . We detect an extended emitted characteristic that is parallel to the galactic disk and extends up to 3 kpc into the halo .The morphology suggests that this formation consists of two parts : one located close to the midplane and another one located about 1 . 5 kpc higher than it . This second component has a temperature of T = 120 K ± 20 K and shows no evidence for significant extinction by dust grains along its line - of - view .Its luminosity corresponds to a star development rate of 0 . 1 [UNK] yr−1 . These conclusions are compatible with previous studies suggesting that there exists a population of young stars outside the main body of galaxies .They also provide further evidence for models where supernovae explosions induce huge - scale outflows of gas and dust which can be responsible for the enrichment of intergalactic space .",
        "ori-fast-z-score": 1.7232808737106582,
        "water-fast-z-score": 4.431293675255978
    },
    {
        "original_text": "In this paper, we present an explicit formula for the maximum allowable delay in a linear time-invariant system with multiple delays by using the concept of passivity index. The proposed method is applied to a biochemical reaction network model consisting of two species interacting through three reactions. We show that our results are consistent with those obtained via numerical simulations. Finally, it should be noted that the proposed approach can also be used as a tool for analyzing other types of networks such as social or economic ones. In recent years there has been growing interest in studying complex dynamical behaviors of biological systems  1  . One important aspect of these studies concerns how different components interact within a cell  2  , which leads naturally to mathematical models based on chemical kinetics  3  .\nThe most common type of kinetic modeling involves ordinary differential equations (ODEs)  4  describing interactions between various molecular species  5  . However, due to the complexity of cellular processes  6  , many ODE models contain several state variables  7, 8  and/or parameters  9  whose values cannot always be determined experimentally  10  . This uncertainty may lead to significant errors when estimating the behavior of the underlying system  11  . To overcome this problem, stochastic approaches have recently been developed  12  . Another possibility consists in considering uncertainties in the form of unknown external disturbances  13  .",
        "watermark_text": "In this paper , we present an explicit formula for the maximum allowable delay in a linear delay - invariant system with many delays by using the notion of passivity index . The proposed approach is applied to a biochemical reaction systems system consisting of two organisms evolving through three compounds .We see that our findings are compatible with those achieved via numerical simulations . Finally , it should be mentioned that the suggested approach can also be used as a way for evaluating other types of networks such as social or economic ones .In recent years there has been growing interest in investigating complex dynamical interactions of biological complexes 1 . One important aspect of these research concerns how various components connect within a cell 2 , which results naturally to numerical models relying on chemical kinetics 3 .The most common type of kinetic modeling involves ordinary differential equations ( ODEs ) 4 describing relationships between various molecular compounds 5 . However , owing to the complexity of cellular processes 6 , many ODE descriptions contain many state components 7 , 8 and / or parameters 9 whose values never always be determined experimentally 10 .This instability may contribute to significant errors when estimating the dynamics of the underlying model 11 . To solve this question , stochastic methods have newly been used 12 .Another possibility consists in considering uncertainties in the form of uncertain external disturbances 13 .",
        "ori-fast-z-score": -0.936585811581694,
        "water-fast-z-score": 7.181324987175317
    },
    {
        "original_text": "The rapid development in the field of intelligent transportation systems (ITS) has led to an increasing demand on wireless communications, which is expected to be fulfilled by using Code Division Multiple Access (CDMA). In this paper we present a novel CDMA-based ITS system that can provide high data rate and low latency services with improved security features compared to existing technologies such as Global Positioning Systems (GPS), Wireless Local Area Networks (WLANs), Bluetooth or ZigBee. The proposed system consists of three main components; namely, roadside units (RSUs), mobile vehicles equipped with on-board units (OBUs) and central servers located at traffic control centers (TCCs).\nWe first introduce the basic concepts behind the proposed system followed by describing its key characteristics. Then, we discuss some important issues related to the design of the proposed system including channel modeling, resource allocation algorithms, power consumption analysis and performance evaluation. Finally, simulation results are presented to demonstrate the effectiveness of our proposed system.",
        "watermark_text": "The rapid progress in the field of intelligent transportation devices ( ITS ) has led to an increasing demand on wireless communications , which is expected to be satisfied by using Code Division Multiple Access ( CDMA ) . In this paper we present a new CDMA - based ITS technology that can provide high data rate and low latency services with improved security features relative to existing technologies such as Global Positioning Systems ( GPS ) , Wireless Local Area Networks ( WLANs ) , Bluetooth or ZigBee .The proposed system contains of three principal portions ; namely , roadside centers ( RSUs ) , wireless trucks equipped with on - board units ( OBUs ) and central computers located at road control centers ( TCCs ) . We first introduce the fundamental concepts behind the suggested system followed by describing its essential aspects .Then , we explain some important problems related to the development of the suggested system namely channel modeling , resource sharing algorithms , power consumption evaluation and performance audit . Finally , simulation data are presented to indicate the performance of our proposed system .",
        "ori-fast-z-score": 1.8439088914585775,
        "water-fast-z-score": 7.3326285778338125
    },
    {
        "original_text": "We present new observations and analysis of two nearby supernova remnants, G292.0+1.8 (Cas A) and Kes 79. We find that both remnants show significant asymmetry between their northern and southern halves; however, we argue that this is not due to an asymmetric explosion but rather to differences in the ambient medium into which each half was expanding at the time of its formation.  In Cas A, we observe a large difference in the density structure along the line-of-sight towards the north and south sides of the remnant. The northern side shows evidence for a dense shell-like feature while the southern side appears more uniform with no clear indication of such a shell. This suggests that the progenitor star exploded through a denser region on the northern side than it did on the southern side.   For Kes 79, our X-ray data reveal a bright compact source located near the center of the remnant s southern half. We suggest that this object may be associated with the central engine of the supernova event or possibly even the neutron star itself.",
        "watermark_text": "We present new studies and investigation of two nearby supernova remnants , G292 . 0 + 1 . 8 ( Cas A ) and Kes 79 . We see that both remnants show considerable asymmetry between their western and southern parts ; however , we claim that this is not due to an asymmetric explosion but rather to differences in the atmospheric medium into which each quarter was expanding at the period of its formation .In Cas A , we perceive a large change in the density structure along the line - of - view towards the north and south halves of the remnant . The northern part displays evidence for a dense shell - like feature while the southern side appears more uniform with no clear indication of such a shell .This implies that the progenitor star burst through a denser region on the northern half than it did on the southern side . For Kes 79 , our X - ray data reveal a bright compact source located near the center of the remnant s southern quarter .We suggest that this body may be involved with the main motor of the supernova explosion or possibly also the neutron star itself .",
        "ori-fast-z-score": 0.4472135954999579,
        "water-fast-z-score": 6.484597134749389
    },
    {
        "original_text": "The projectile fragmentation of 86Kr at 64MeV/nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a beam intensity of 1nAe. The main results are as follows:  - A total number of about 10000 events have been recorded for this experiment.  - The charge distribution is peaked around Z=40, but shows also a large contribution between 30 and 40 charges units (see fig.1 ). This indicates that the fragments produced by the break-up of 86Kr are not only light particles like neutrons or protons, but contain many intermediate mass fragments too.   - The angular distributions show two peaks corresponding to forward and backward emission respectively (see fig.2 ).  - The energy spectra present a maximum around 10-12 MeV/u which corresponds to the most probable kinetic energy per nucleon of the emitted fragments (see fig.3 ).\n- The isotopic composition of the fragments is shown on figure 4 . It can be seen that there is no significant difference between the fragment production in the forward hemisphere and in the backward one.",
        "watermark_text": "The projectile fragmentation of 86Kr at 64MeV / nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a laser intensity of 1nAe . The main results are as follows : - A total quantity of about 10000 events have been observed for this study .- The charge distribution is peaked around Z = 40 , but shows also a large contribution between 30 and 40 charges units ( view fig . 1 ) . This implies that the fragments produced by the broken - up of 86Kr are not only light particles like neutrons or protons , but contain many intermediate mass pieces too .- The angular distributions show two peaks related to forward and back emission respectively ( see fig . 2 ) . - The energy spectra produce a maximum around 10 - 12 MeV / u which equals to the most likely kinetic power per nucleon of the emitted objects ( see fig . 3 ) .- The isotopic structure of the fragments is displayed on figure 4 . It can be shown that there is no major variation between the fragment production in the front hemisphere and in the backward one .",
        "ori-fast-z-score": -0.3611575592573076,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We present new constructions for locally decodable codes (LDCs) based on nice subsets of finite fields, prime factors of Mersenne numbers, and the Chinese remainder theorem. Our first construction is an explicit family of LDCs with optimal query complexity that are derived from nice subsets of finite fields. We then show how to use these results in conjunction with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the number of primes used in their construction. Finally we give a lower bound on the length of any LDC over a binary alphabet which uses only one-sided queries. The proofs of our main theorems appear at the end of this extended abstract. \nIntroduction\n\nLocally decodable codes (abbreviated as LCDs)\nare error correcting codes where each codeword has associated with it some decoding algorithm that allows efficient recovery of individual bits or symbols when queried about them. In particular, if the codeword is corrupted by up to t errors, then there exists a deterministic polynomial time algorithm that recovers the original uncorrupted word using O(t) queries per symbol. This property makes such codes useful in applications like data storage systems, peer-to-peer networks, and streaming media distribution services. \n \n A large body of work has been devoted towards understanding the trade-off between the rate of the code, its distance, and the query complexity of the decoder. For example, Guruswami et al. (2005), Chan et al. (2006) , and Kopparty & Saraf (2007)  studied the problem of constructing codes with low query complexity while maintaining high rates and distances. Recently, several works have focused on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain amount of corruption. These include the recent breakthrough result of Dvir et al. (2010a) (which improved upon the previous best-known upper bound due to Sudan et al., 2005 ) and the subsequent improvements made by Dvir et al. (2011 ), Feldman et al. (2012 , and Kopparty et al. (2013) . \n \n Another important",
        "watermark_text": "We introduce novel constructions for locally decodable codes ( LDCs ) based on pleasant subsets of finite fields , prime elements of Mersenne numbers , and the Chinese remainder theorem . Our first build is an explicit class of LDCs with optimal query complexity that are derived from good subsets of finite fields .We then show how to use these results in partnership with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the number of primes used in their design . Finally we give a smaller bound on the length of any LDC over a binary alphabet which uses only one - sided queries .The proofs of our major theorems emerge at the end of this enlarged abstract . Introduction Locally decodable codes ( denoted as LCDs ) are mistake correcting codes where each codeword has associated with it some decoding algorithm that enables efficient returning of individual characters or characters when queried about them .In particular , if the codeword is corrupted by up to t errors , then there exists a deterministic polynomial period algorithm that recovers the actual uncorrupted phrase using O ( t ) queries per symbol . This property gives such codes helpful in applications like data storage systems , peer - to - peer systems , and streaming media distribution services .A vast body of research has been focused towards studying the trade - off between the frequency of the code , its location , and the query complexity of the decoder . For instance , Guruswami et al .( 2005 ) , Chan et al . ( 2006 ) , and Kopparty & Saraf ( 2007 ) studied the question of constructing coding with little query complexity while maintaining high frequencies and distances .Recently , various efforts have concentrated on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain quantity of corruption . These include the recent breakthrough result of Dvir et al .( 2010a ) ( which updated upon the previous good - used upper bound due to Sudan et al . , 2005 ) and the subsequent improvements done by Dvir et al . ( 2011 ) , Feldman et al .( 2012 , and Kopparty et al . ( 2013 ) .Another important",
        "ori-fast-z-score": -0.40689422938557973,
        "water-fast-z-score": 7.021870595978444
    },
    {
        "original_text": "We present new results on the evolution and properties of galactic holes, based on an analysis of deep optical images obtained with the Hubble Space Telescope (HST). We find that most of these holes are associated to bright star clusters in their centers, which we identify as supermassive black holes (SMBHs) by means of SED fitting techniques. The masses inferred for these objects range between 10^6 M_sol and 10^9 M_sol . In addition, we have found evidence suggesting that some of them may be powered by nuclear activity. Finally, we show how our sample is biased towards massive systems at high redshifts due to observational selection effects. Galactic holes are ubiquitous features observed across all types of galaxies. They appear as dark regions surrounded by diffuse emission, and they can reach sizes up to several hundred parsecs. Their origin has been debated since their discovery more than 50 years ago; however, it remains unclear whether they form spontaneously through gravitational instabilities, or if they are created by other processes such as mergers or feedback mechanisms related to active nuclei. Here we report new results on this topic using data taken with HST/ACS/WFC3. Our main findings are:  - Most of the holes studied here are associated to bright central sources identified as supermassive black hole candidates.  - Some of the holes seem to be powered by nuclear activity.  - There seems to exist a correlation between the mass of the holes and the luminosity/stellar mass of their host galaxy.  - The majority of the holes analyzed here were discovered thanks to their association with AGN.",
        "watermark_text": "We report new data on the evolution and features of galactic holes , using on an assessment of deep optical images obtained with the Hubble Space Telescope ( HST ) . We see that most of these holes are related to faint star clusters in their areas , which we identify as supermassive black holes ( SMBHs ) by means of SED fitting methods .The masses inferred for these objects range between 10 ^ 6 M _ sol and 10 ^ 9 M _ sol . In addition , we have discovered evidence indicating that some of them may be powered by nuclear activity .Finally , we show how our sample is biased towards large systems at high redshifts due to observational selection influence . Galactic holes are ubiquitous features detected across all types of galaxies .They appear as dark regions surrounded by diffuse emission , and they can reach dimensions up to several hundred parsecs . Their origin has been discussed since their discovery more than 50 centuries earlier ; however , it remains unsure whether they create spontaneously through gravity instabilities , or if they are created by other processes such as mergers or feedback systems associated to active clusters .Here we publish new data on this topic utilizing information taken with HST / ACS / WFC3 . Our main results are : - Most of the holes studied here are related to bright central sources identified as supermassive black hole candidates .- Some of the holes appear to be powered by nuclear activity . - There seems to exist a correlation between the mass of the holes and the luminosity / stellar size of their target galaxy .- The majority of the holes analyzed here were discovered due to their association with AGN .",
        "ori-fast-z-score": 0.09325048082403138,
        "water-fast-z-score": 6.748852387406954
    },
    {
        "original_text": "We present an explicit calculation of the non-perturbative renormalisation constant for the chromomagnetic operator in heavy quark effective theory (HQET). We use this to calculate the leading order contribution to the mass difference between the ground state vector mesons containing a b-quark, i.e., $B^*$- $B$ mixing. The result is compared with lattice QCD calculations at next-to-leading order in HQET perturbation theory. Our results are consistent within errors but do not agree as well as one would like. This may be due to missing higher-order corrections or systematic uncertainties inherent in both approaches. \n \n Introduction \n \n In recent years there has been considerable interest in studying hadronic systems containing a single heavy quark using the framework provided by heavy quark effective theory (HQT)  1  . One important application of HQT is to study the properties of heavy-light mesons such as the bottomonium system  2  , which can then be used to test our understanding of nonrelativistic quantum mechanics  3  .\n \nIn particular, it is interesting to consider how the masses of these states depend on their spin. For example, the lowest lying bb states have spin-parity J P = 0+ and 1− respectively  4  . These two states mix under the weak interaction through the emission and absorption of virtual gluons  5  . At tree level we find that the lightest physical eigenstate is given by:",
        "watermark_text": "We present an explicit determination of the non - perturbative renormalisation constant for the chromomagnetic operator in heavy quark effective theory ( HQET ) . We use this to estimate the leading order contribution to the mass ratio between the ground state velocity mesons containing a b - quark , i . e . , $ B ^ * $ - $ B $ mixing .The result is compared with lattice QCD calculations at next - to - leading order in HQET perturbation theory . Our results are compatible within errors but do not comply as well as one would like .This might be due to missing higher - order corrections or systematic uncertainties involved in both approaches . Introduction In recent years there has been substantial interest in investigating hadronic networks featuring a single heavy quark using the framework given by large quark effective theory ( HQT ) 1 .One important use of HQT is to study the properties of heavy - light mesons such as the bottomonium system 2 , which can then be used to test our grasp of nonrelativistic quantum mechanics 3 . In particular , it is curious to consider how the masses of these states change on their spin .For instance , the lowest lying bb states have spin - parity J P = 0 + and 1− respectively 4 . These two states mix under the weak interaction through the emission and emission of virtual gluons 5 .At tree level we find that the lightest physical eigenstate is given by :",
        "ori-fast-z-score": 0.10050378152592121,
        "water-fast-z-score": 4.242640687119285
    },
    {
        "original_text": "The Dalitz plot distribution for the decay D+ ->K-pi+pi+ is measured using data collected by the FOCUS experiment at Fermilab, corresponding to an integrated luminosity of 1 fb-1 . The measurement uses a sample of about 2 million events with one charged track and two neutral clusters reconstructed in the central drift chamber (CDC) and electromagnetic calorimeter (EMC). A maximum likelihood fit is performed on this sample to extract the branching fraction B(D+ ->K-pi+pipi+), which is found to be  _ = (1.55 +/- 0.10 ) x 10-3 , where the uncertainty includes both statistical and systematic contributions.  This result agrees well with previous measurements but has improved precision due to the larger number of signal events used here compared to earlier results. It also improves upon the most recent theoretical prediction based on lattice QCD calculations. The ratio Rc/D between the Cabibbo-suppressed and Cabibbo-favored decays into three pions is determined as Rc/D=(0.84+0.11-0.12)x10-2.",
        "watermark_text": "The Dalitz plot distribution for the decay D + - > K - pi + pi + is measured using data taken by the FOCUS experiment at Fermilab , corresponding to an integrated luminosity of 1 fb - 1 . The measurement involves a sample of about 2 million episodes with one charged track and two neutral nuclei reconstructed in the main drift chamber ( CDC ) and electromagnetic calorimeter ( EMC ) .A maximum likelihood fit is conducted on this data to extract the branching fraction B ( D + - > K - pi + pipi + ) , which is found to be _ = ( 1 . 55 + / - 0 . 10 ) x 10 - 3 , where the uncertainty includes both statistical and systematic contributions . This result agrees well with previous measurements but has improved precision thanks to the bigger quantity of signal events employed here compared to earlier findings .It additionally improves upon the most current theoretical estimate based on lattice QCD calculations . The ratio Rc / D between the Cabibbo - subdued and Cabibbo - preferred decays into three pions is calculated as Rc / D = ( 0 . 84 + 0 . 11 - 0 . 12 ) x10 - 2 .",
        "ori-fast-z-score": 0.3721042037676254,
        "water-fast-z-score": 4.83735464897913
    },
    {
        "original_text": "We present the first detection and characterization of infrared extinction law (IRAL) toward an extremely dark cloud core, L183. The IRAL is derived by comparing near-infrared to mid-infrared colors between background stars and foreground objects projected on the same line-of-sight through the cloud. We find that the IRAL shows no significant variation with depth into the cloud down to A V = 1000 mag. This result suggests that dust grains are not significantly modified even under such extreme conditions as those found deep inside dense clouds. Our results also suggest that grain growth may be suppressed in these environments due to efficient shattering caused by collisions among large grains. These findings have important implications for understanding the formation process of planetesimals. \n \n Keywords: Infrared extinction law, Dust properties, Interstellar medium, Shock waves \n \n 1. Introduction \n \n It has been suggested that interstellar dust grains grow up to millimeter sizes or larger within dense molecular clouds because they can survive against destructive collisions with other particles (e.g., coagulation theory; Ossenkopf & Henning 1994). However, recent observations show that there exist many small dust grains in dense regions where the gas density exceeds 10^6 cm^{-3} (e.g., Stepnik et al. 2003; Pagani et al. 2003), which contradicts this scenario. To resolve this discrepancy, it was proposed that dust grains could be destroyed efficiently via collisional fragmentation when their size becomes comparable to the mean free path of hydrogen molecules (Ormel et al. 2007). \n \n Another possibility is that dust grains do not grow but rather fragment into smaller pieces during collisions (e.g., Blum & Wurm 2008). If so, then we would expect to see some evidence of grain destruction products like sub-micron-sized fragments in dense clouds. Indeed, several observational studies reported the presence of sub-millimeter emission features attributed to silicate and/or carbonaceous materials in dense clouds (e.g., Jones et al. 1993; Chiar et al. 1998; Kessler",
        "watermark_text": "We present the first recognition and description of infrared extinction law ( IRAL ) toward an incredibly dark cloud core , L183 . The IRAL is calculated by using near - infrared to mid - infrared colors between background stars and foreground objects projected on the same line - of - view through the cloud .We see that the IRAL displays no considerable variation with depth into the cloud down to A V = 1000 mag . This result suggests that dust grains are not dramatically distorted even under such extreme circumstances as those observed deep inside dense clouds .Our results also suggest that grain growth could be ceased in these habitats due to efficient crushing caused by collisions among huge grains . These conclusions have important implications for studying the formation system of planetesimals .Keywords : Infrared extinction law , Dust properties , Interstellar medium , Shock effects 1 . Introduction It has been proposed that interstellar dust grains grow up to millimeter sizes or larger within dense molecular clouds because they can endure against damaging collisions with other particles ( e . g . , coagulation hypothesis ; Ossenkopf & Henning 1994 ) .However , recent observations show that there remain many small dust grains in dense areas where the gas density reaches 10 ^ 6 cm ^ { - 3 } ( e . g . , Stepnik et al . 2003 ; Pagani et al .2003 ) , which contradicts this situation . To settle this discrepancy , it was suggested that dust grains could be devastated easily via collisional fragmentation when their size grows equivalent to the mean free path of hydrogen compounds ( Ormel et al .2007 ) . Another possibility is that dust grains do not grow but rather cluster into tiny pieces during collisions ( e . g . , Blum & Wurm 2008 ) .If so , then we may expect to see some evidence of grain loss substances like sub - micron - sized fragments in dense clouds . Indeed , various observational surveys reported the formation of sub - millimeter emission elements owing to silicate and / or carbonaceous materials in dense clouds ( e . g . , Jones et al .1993 ; Chiar et al . 1998 ; Kessler",
        "ori-fast-z-score": 0.3965257928590721,
        "water-fast-z-score": 8.379912286910033
    },
    {
        "original_text": "We present an analysis of helioseismic data for the angular velocity profile of the Sun, which is based on the assumption that the total angular momentum of the Sun is conserved during its evolution. We find that this hypothesis leads to a good agreement between theoretical predictions and observations at all latitudes except near the poles where we observe significant deviations. The discrepancies are explained by taking into account the effects of torsional oscillations in the convective envelope of the Sun. Our results show that these oscillations can be excited by internal magnetic fields generated by differential rotation in the radiative interior of the Sun. This mechanism may also operate in other solar-type stars with strong surface magnetic activity. In our study we use high-precision measurements of the frequency splitting of acoustic modes obtained using space-based instruments (GOLF and MDI) aboard the Solar and Heliospheric Observatory satellite. \n \n Keywords: Angular momentum, Torsional oscillations",
        "watermark_text": "We present an assessment of helioseismic data for the angular velocity profile of the Sun , which is based on the assumption that the total angular velocity of the Sun is conserved during its evolution . We see that this hypothesis leads to a better agreement between theoretical estimates and observations at all latitudes except near the poles where we perceive considerable deviations .The discrepancies are explained by take into consideration the effects of torsional oscillations in the convective envelope of the Sun . Our results show that these oscillations can be excited by inner magnetic waves generated by differential rotation in the radiative interior of the Sun .This mechanism may even exist in other solar - class stars with powerful surface magnetic activity . In our research we utilize wide - precision observations of the frequency separation of acoustic modes obtained using space - based instruments ( GOLF and MDI ) aboard the Solar and Heliospheric Observatory telescope .Keywords: Angular momentum, Torsional oscillations",
        "ori-fast-z-score": -0.24618298195866545,
        "water-fast-z-score": 4.431293675255978
    },
    {
        "original_text": "We present the network topology and trading volume for the first experimental futures exchange, which was launched in September 2009 as part of the University of Chicago s Financial Markets Lab (FML). The FML is designed to provide students with hands-on experience in designing, implementing, and operating financial markets. We find that the network exhibits small-world properties similar to those observed on other real world networks such as social networks or the Internet. In addition we show how the network evolves over time by analyzing its growth rate and degree distribution. Finally, we study the relationship between the number of transactions executed at each node and their respective degrees. Our results suggest that nodes with higher degrees tend to trade more than lower-degree nodes. This finding has important implications for market design since it suggests that traders should be incentivized to increase their connectivity within the network if they want to maximize their trading activity. We also examine whether there are any differences across different types of contracts traded on the exchange.",
        "watermark_text": "We present the group geometry and trading volume for the first prototype futures trader , which was launched in September 2009 as part of the University of Chicago s Financial Markets Lab ( FML ) . The FML is designed to provide scholars with hands - on experience in planning , implementing , and operating financial exchanges .We see that the organization displays low - world properties similar to those observed on other actual world networks such as social systems or the Internet . In addition we study how the organization evolves over time by analyzing its expansion frequency and degree distribution .Finally , we study the relationship between the quantity of transactions executed at each node and their individual degrees . Our results show that nodes with higher degrees prefer to trade more than less - degree servers .This study has crucial consequences for trade design since it demonstrates that consumers should be incentivized to expand their connectivity within the network if they wish to maximize their trading activity . We additionally assess whether there are any similarities across different kinds of contracts traded on the market .",
        "ori-fast-z-score": -0.7777777777777778,
        "water-fast-z-score": 6.846754616640485
    },
    {
        "original_text": "We propose a new inflationary model, which is based on the idea that there are two scalar fields in nature and they interact with each other through their potentials. We call this model  smooth hybrid inflation  (SHI). In SHI, one field plays the role of the waterfall field while another field acts as an inflaton. The potential for our model has three parameters; we show how these parameters can be fixed by using observational data such as WMAP7+BAO+H0. Our results indicate that the tensor-to-scalar ratio r=0.0055+0.0005-0.0004 at 95% CL. This value is consistent with recent observations. Moreover, we find that the spectral index ns=1.0145+0.0025-0.0024 at 68% CL. Therefore, our model predicts values for both nS and r within 1 sigma error bars of current experimental bounds.",
        "watermark_text": "We suggest a new inflationary model , which is based on the idea that there are two scalar fields in nature and they interact with each other through their potentials . We call this model smooth hybrid inflation ( SHI ) .In SHI , one field plays the importance of the waterfall field while another field works as an inflaton . The potential for our model has three variables ; we tell how these parameters can be fixed by using observational data such as WMAP7 + BAO + H0 .Our results show that the tensor - to - scalar ratio r = 0 . 0055 + 0 . 0005 - 0 . 0004 at 95 % CL . This value is compatible with recent observations .Moreover , we find that the spectral index ns = 1 . 0145 + 0 . 0025 - 0 . 0024 at 68 % CL . Therefore , our model predicts values for both nS and r within 1 sigma error bars of recent experimental bounds .",
        "ori-fast-z-score": -0.42857142857142855,
        "water-fast-z-score": 1.8571428571428572
    },
    {
        "original_text": "We present the results of our study on super star clusters (SSCs) in which we have found that SSCs can be divided into two categories, namely, those having a single mode and those having a double-mode solution for their density profiles. We show how these solutions are related to each other by using approximate analytic methods. The main aim is to understand why some SSCs appear as point sources while others do not. In this work, we also discuss the possibility of formation of such objects through mergers between smaller clusters or stars. Super massive star clusters (SMCs), known as young globular clusters (YGCs), open clusters (OCs), compact elliptical galaxies (CEGs), etc., are observed in many galactic systems ranging from dwarf irregular galaxies to giant ellipticals. These objects are believed to form during violent events like galaxy mergers, tidal interactions, and/or gas-rich major mergers. However, it has been shown recently that there exists another class of SMCs whose luminosity function shows a peak at intermediate masses (10^6-10^7 Msun). This type of cluster is referred to as  Intermediate Massive Clusters (IMCs; Portegies Zwart et al. (2010)). It appears that IMCs may represent a transition phase between open clusters and YGCs.",
        "watermark_text": "We present the conclusion of our research on super star clusters ( SSCs ) in which we have discovered that SSCs can be grouped into two genres , namely , those having a single mode and those having a twin - mode solution for their density characteristics . We see how these solutions are related to each other by using numerical analytic techniques .The main aim is to explain why some SSCs appear as point sources while many do not . In this research , we also discuss the prospect of formation of such objects through mergers between smaller clusters or stars .Super massive star clusters ( SMCs ) , known as early globular complexes ( YGCs ) , close complexes ( OCs ) , compact elliptical galaxies ( CEGs ) , etc . , are observed in many galactic structures ranging from giant irregular clusters to massive ellipticals . These structures are said to form during violent reactions like galaxy mergers , tidal interactions , and / or gas - rich major mergers .However , it has been shown lately that there exists another class of SMCs whose luminosity function shows a peak at intermediate masses ( 10 ^ 6 - 10 ^ 7 Msun ) . This kind of cluster is referred to as Intermediate Massive Clusters ( IMCs ; Portegies Zwart et al .( 2010 ) ) . It suggested that IMCs might represent a transfer stage between open complexes and YGCs .",
        "ori-fast-z-score": -1.58999682000954,
        "water-fast-z-score": 5.270462766947299
    },
    {
        "original_text": "We have studied the rheology of isotropic networks formed by crosslinking actin filaments with two different concentrations of biotin-avidin linkers, using microrheology experiments on single filament dynamics in combination with macrorheology measurements performed at low frequencies (0.01-10 Hz). We find that both microand macro-rheology are consistent with an elastic network model for which we can extract values for the number density of links between filaments as well as their stiffness. The results show that increasing the concentration of avidin leads to denser networks with stiffer links. This effect is more pronounced when the initial concentration of actin filaments is higher. Our findings suggest that the mechanical properties of actomyosin gels may be tunable through changes in the amount and/or type of crosslinks present within these systems. In living cells, cytoskeletal structures such as stress fibers or focal adhesions provide physical connections between cell components and play important roles in determining cellular mechanics  1  . These structures consist of bundles of semiflexible biopolymers known as actin filaments  2  , which are connected together via specific protein complexes called crosslinks  3  .\nIn recent years there has been growing interest in understanding how the mechanical properties of biological materials depend on the microscopic structure of the underlying networks  4  . For example, it was shown recently that the viscoelasticity of reconstituted actomyosin gels depends strongly on the presence of myosins  5  . However, despite this progress our knowledge about the relationship between the macroscopic behavior of complex fluids and the microstructure of the constituent building blocks remains limited  6  .",
        "watermark_text": "We have researched the rheology of isotropic bands formed by crosslinking actin filaments with two different amounts of biotin - avidin linkers , using microrheology experiments on double filament dynamics in combination with macrorheology measurements completed at low frequencies ( 0 . 01 - 10 Hz ) . We see that both microand macro - rheology are compatible with an elastic network theory for which we can extract parameters for the number density of links between filaments as also as their stiffness .The results show that raising the density of avidin leads to denser networks with stiffer links . This phenomenon is more pronounced when the first concentration of actin filaments is higher .Our findings show that the mechanical behavior of actomyosin gels might be tunable through alterations in the quantity and / or type of crosslinks observed within these systems . In living cells , cytoskeletal structures such as stress fibers or focal adhesions contribute physical bridges between tissue systems and play essential roles in establishing cellular dynamics 1 .These structures composed of bundles of semiflexible biopolymers known as actin filaments 2 , which are connected together via particular protein complexes called crosslinks 3 . In recent years there has been growing interest in understanding how the mechanical behavior of biological materials depend on the microscopic shape of the underlying systems 4 .For instance , it was shown lately that the viscoelasticity of reconstituted actomyosin gels relies highly on the presence of myosins 5 . However , despite this progress our information about the relationship between the macroscopic behavior of complex fluids and the microstructure of the constituent building components remains restricted 6 .",
        "ori-fast-z-score": -0.19611613513818404,
        "water-fast-z-score": 7.19290373059934
    },
    {
        "original_text": "We present new optical and ultraviolet (UV) spectra for the intrinsically X-ray weak quasar PHL 1811, obtained with the Keck Observatory s HIRES spectrograph in 1998-99. The data cover wavelengths between 3200 A and 10400Å at resolution R = λ/∆λ ≈ 45000. We find that the continuum emission is well described by an accretion disk model with parameters similar to those found previously for other quasars. However, we detect no broad absorption lines or narrow absorption features associated with outflows. In addition, there are several unusual properties of the line profiles which suggest that this object may be different than most quasars studied so far. \n \n Keywords: Quasars; Broad Absorption Lines; Accretion Disk Modeling. 1 Introduction \n \n PHL 1811 was discovered as part of the Palomar-Green survey (Schmidt & Green 1983 ) and has been observed extensively since then. It is one of only two known examples of an X-ray weak quasar (Wilkes et al. 1994) , where the ratio of its soft X-ray flux density to its 2500 Å flux density is less than 0.1. Wilkes et al. (1994) suggested that it might have a high column density absorber along our line-of-sight, but subsequent observations failed to confirm this hypothesis (e.g., Mathur et al. 1995) . Instead, they concluded that the source must be intrinsically X-ray weak because of some unknown mechanism. Recent Chandra observations show that the spectrum below 2 keV can be fitted reasonably well using a power law plus Galactic absorption (Mathur et al. 2002 ) . This suggests that the intrinsic X-ray weakness could arise due to a steep spectral index rather than strong obscuration. Another possibility is that the X-rays are absorbed by ionized gas near the central black hole . \n \n PHL 1811 also shows interesting variability on time scales ranging from hours to years. For example, Wilkes et al. (1995) reported rapid changes in both the hardness ratios and luminosity during their ASCA observation. They interpreted these variations as being caused by partial",
        "watermark_text": "We report new optical and ultraviolet ( UV ) spectra for the intrinsically X - ray weak quasar PHL 1811 , obtained with the Keck Observatory s HIRES spectrograph in 1998 - 99 . The data cover wavelengths between 3200 A and 10400Å at resolution R = λ / [UNK] ≈ 45000 .We see that the continuum emission is well described by an accretion disk model with characteristics similar to those noted formerly for other quasars . However , we find no broad absorption patterns or broad absorption properties associated with outflows .In addition , there are several strange properties of the line profiles which show that this body may be unique than most quasars explored so far . Keywords : Quasars ; Broad Absorption Lines ; Accretion Disk Modeling .1 Introduction PHL 1811 was studied as part of the Palomar - Green survey ( Schmidt & Green 1983 ) and has been observed often since then . It is one of only two recorded examples of an X - ray weak quasar ( Wilkes et al .1994 ) , where the proportion of its soft X - ray flux concentration to its 2500 Å flux concentration is less than 0 . 1 . Wilkes et al .( 1994 ) proposed that it could have a high column velocity absorber along our line - of - seeing , but subsequent observations failed to confirm this claim ( e . g . , Mathur et al . 1995 ) .Instead , they concluded that the origin could be intrinsically X - ray weak because of some unidentified mechanism . Recent Chandra measurements show that the spectrum below 2 keV can be fit reasonably well using a power law plus Galactic absorption ( Mathur et al .2002 ) . This shows that the intrinsic X - ray weak could occur due to a sharp spectral index instead than strong obscuration .Another possibility is that the X - radiation are absorption by ionized gas near the main dark hole . PHL 1811 also shows interesting variability on time ranges varied from hours to decades .For instance , Wilkes et al . ( 1995 ) reported quick changes in both the hardness levels and luminosity during their ASCA measurement .They interpreted these changes as being affected by partial",
        "ori-fast-z-score": -1.3821894809301762,
        "water-fast-z-score": 7.890700722669491
    },
    {
        "original_text": "The electronic structure and transport properties of intrinsic ripples on single-layered graphene are investigated by using the tight-binding model with first-principles hopping parameters, which is based on density-functional theory (DFT). The results show that the ripple-induced local strain can lead to an energy gap opening at Dirac point for both armchair and zigzag directions. In addition, it is found that the electron mobility decreases as the amplitude increases due to the increase of scattering centers induced by the ripple structures. These findings may be useful for understanding the physical mechanism behind the experimental observations of rippling effects on the electrical performance of graphene devices. Graphene has attracted great attention because its unique two-dimensional honeycomb lattice structure leads to many novel phenomena such as high carrier mobility  1  , Klein tunneling  2  , valley polarization  3  , etc.. However, recent experiments have shown that the pristine flat monolayer graphene sheets tend to form ripples spontaneously  4  . It was also reported that these ripples could affect the electrical performance of graphene-based devices  5  .\nIn this work we investigate the effect of ripples on the electronic structure and transport properties within the framework of the tight-binding model  6  . We find that the ripple-induced strains can open up an energy gap around the Fermi level for both armchair andzigzag directions. Moreover, the electron mobility decreases as increasing the amplitude of ripples since more scattering centers are introduced into the system.",
        "watermark_text": "The mechanical composition and transport properties of intrinsic ripples on single - layered graphene are examined by using the fast - binding model with first - principles hopping characteristics , which is based on density - functional theory ( DFT ) . The results show that the ripple - caused local tension can lead to an energy gap opening at Dirac position for both armchair and zigzag directions .In addition , it is found that the electron mobility decreases as the frequency rises due to the increase of absorption centers caused by the ripple structures . These conclusions could be valuable for studying the physical mechanism behind the empirical observations of rippling influence on the electrical performance of graphene devices .Graphene has garnered great popularity because its unique two - dimensional honeycomb structure form gives to many novel processes such as long carrier density 1 , Klein tunneling 2 , valley polarization 3 , etc . . However , recent experiments have shown that the pristine rolled monolayer graphene strands tend to form ripples spontaneously 4 .It was also reported that these ripples could affect the electrical performance of graphene - based products 5 . In this research we investigate the impact of ripples on the electronic structure and transport properties within the framework of the tight - binding model 6 .We see that the ripple - mediated strains can offer up an energy gap around the Fermi level for both armchair andzigzag directions . Moreover , the electron mobility decreases as increasing the frequency of ripples since more scattering centers are introduced into the system .",
        "ori-fast-z-score": 0.3746343246326776,
        "water-fast-z-score": 6.80336051416609
    },
    {
        "original_text": "The Sloan Digital Sky Survey (SDSS) is an ongoing project to map the distribution and motion of galaxies, quasars, stars, and other celestial objects in space. The fourth data release was made public on September 30th 2003. This fifth data release contains more than 100,000 new quasar candidates selected by color criteria from the SDSS imaging survey. These are supplemented with about 20,000 previously known quasars that were not included in previous releases because they did not meet the selection criteria for inclusion at that time. \n \n In addition to these newly discovered quasars, this catalog also includes all quasars found during the first four years of the survey as well as those found since then but which have yet to be released publicly. A total of over 250,000 quasars are now available through this catalog. All of them have been spectroscopically confirmed using observations obtained with the dedicated 2.5-meter telescope located at Apache Point Observatory near Sacramento, California.",
        "watermark_text": "The Sloan Digital Sky Survey ( SDSS ) is an continuing work to map the distribution and motion of galaxies , quasars , stars , and other celestial entities in space . The fourth information publication was making public on September 30th 2003 .This fifth information update contains more than 100 , 000 new quasar finalists chosen by color categories from the SDSS imaging survey . These are supplemented with about 20 , 000 former recognized quasars that were not included in earlier versions because they did not meet the selection standards for inclusion at that point .In addition to these newly discovered quasars , this list also contains all quasars discovered during the first four seasons of the census as well as those identified since then but which have never to be available openly . A total of over 250 , 000 quasars are now released through this catalog .All of them have been spectroscopically confirmed using observations collected with the reserved 2 . 5 - meter telescope located at Apache Point Observatory near Sacramento , California .",
        "ori-fast-z-score": -1.5,
        "water-fast-z-score": 5.25
    },
    {
        "original_text": "We show that the non-Gaussian distributions observed in financial returns are due to microscopic interactions between traders and their environment, which lead to non-trivial correlations among different time scales. We present an analytical model for these correlations based on random matrix theory (RMT), which is able to reproduce all statistical properties of real market data with high accuracy. \n \n The distribution of stock prices has been studied extensively over many decades  1  . It was found that this distribution can be well approximated by a Gaussian function  2  , but deviations have also been reported  3  . In particular, it has been shown recently  4  that the tails of the return distribution follow a power law decay P(r) ~ r−α with α = 3 ± 0.1. This finding contradicts the predictions of standard models such as Black-Scholes  5  or Heston  6  , where the tail exponent should be equal to 2  7, 8  .\n \nIn order to explain the origin of these deviations we propose here a new approach based on Random Matrix Theory  9  . RMT describes the statistics of complex systems whose dynamics depend on a large number N of degrees of freedom  10  . For example, RMT has successfully been applied to describe the fluctuations of energy levels  11  , wave functions  12  , spin states  13  , quantum transport  14  , and chaotic scattering  15  . Recently, RMT has also been used to study the statistical properties of stock markets  16  -  22  . Here we will focus on the so-called Dyson Brownian motion  23  , which describes the evolution of a system under the influence of white noise.",
        "watermark_text": "We see that the non - Gaussian distributions found in financial returns are owing to microscopic interactions between traders and their environment , which lead to non - simple correlations among different time ranges . We present an analytical theory for these correlations based on random matrix theory ( RMT ) , which is easy to capture all statistical characteristics of real trading information with high clarity .The function of stock rates has been studied thoroughly over much generations 1 . It was shown that this distribution can be well approximated by a Gaussian distribution 2 , but deviations have also been reported 3 .In particular , it has been shown recently 4 that the tails of the return distribution observe a power law decay P ( r ) ~ r−α with α = 3 ± 0 . 1 . This fact contradicts the estimates of standard models such as Black - Scholes 5 or Heston 6 , where the tail exponent should be equal to 2 7 , 8 .In order to explain the origin of these deviations we undertake here a new approach based on Random Matrix Theory 9 . RMT describes the statistics of complex systems whose dynamics depend on a large number N of degrees of freedom 10 .For instance , RMT has successfully been used to explain the fluctuations of power states 11 , wave systems 12 , spin states 13 , quantum transport 14 , and chaotic scattering 15 . Recently , RMT has additionally been used to study the statistical characteristics of financial traders 16 - 22 .Here we will focus on the so - called Dyson Brownian moving 23 , which explains the evolution of a system under the effects of white sound .",
        "ori-fast-z-score": -1.044073795327749,
        "water-fast-z-score": 5.789863774090244
    },
    {
        "original_text": "We present new calculations for massive star evolution, nucleosynthesis, and yields using updated nuclear reaction rates and solar abundances. We find that our results are sensitive to uncertainties in the helium burning rate at high temperatures (T > 2 x 10^9 K). The sensitivity is particularly strong when we use the most recent recommended value for the 12C(alpha, gamma)16O cross section. This result has important implications for studies of chemical enrichment by supernovae Ia progenitors. \n \n Keywords: Nuclear reactions; Supernovae; Stellar evolution; Yields \n \n 1 Introduction \n \n In this work we study how uncertainties in nuclear physics affect predictions about stellar evolution and nucleosynthesis. Our goal is to understand better what can be learned from observations of stars and their remnants. For example, it is well known that there exist large discrepancies between observed elemental abundance ratios in metal-poor halo stars and those predicted by standard models of galactic chemical evolution  1  . These differences may arise because some key nuclear processes have been poorly understood or not included in current evolutionary codes  2  , but they could also reflect systematic errors in observational data  3  .\n \nIn order to address these issues, we perform detailed numerical simulations of massive star evolution with different sets of input parameters. Specifically, we consider two cases where the initial mass fraction of helium XHe = 0.25 and 0.30 respectively  4  . We evolve each model until its core collapses into a neutron star. During the collapse phase, we follow the hydrodynamics of the explosion as described in  5  . Afterwards, we compute the composition of the ejecta using an improved version  6  of the one-dimensional post-processing code developed originally by  7  . \n \n 2 Input Physics and Numerical Methods",
        "watermark_text": "We report new models for huge galaxy evolution , nucleosynthesis , and yields using updated atomic reaction rates and solar abundances . We see that our findings are susceptible to uncertainties in the helium burning rate at high temperatures ( T > 2 x 10 ^ 9 K ) .The sensitivity is especially powerful when we using the most current recommended estimate for the 12C ( beta , alpha ) 16O cross area . This result has significant implications for research of chemical enrichment by supernovae Ia progenitors .Keywords : Nuclear effects ; Supernovae ; Stellar evolution ; Yields 1 Introduction In this research we study how uncertainties in nuclear science affect assumptions about stellar evolution and nucleosynthesis . Our goal is to study improve what can be learned from measurements of stars and their remnants .For instance , it is well established that there exist large discrepancies between measured elemental availability proportions in metal - scarce halo stars and those predicted by traditional models of galactic chemical evolution 1 . These similarities may arise because some important radioactive processes have been poorly described or not incorporated in current evolutionary codes 2 , but they may also reflect widespread errors in observational data 3 .In order to overcome these problems , we perform comprehensive numerical simulations of large star evolution with various sets of input parameters . Specifically , we solve two situations where the initial mass fraction of helium XHe = 0 . 25 and 0 . 30 respectively 4 .We evolve each model until its core collapses into a neutron star . During the collapse phase , we follow the hydrodynamics of the explosion as described in 5 .Afterwards , we compute the composition of the ejecta using an modified edition 6 of the one - dimensional post - processing code developed originally by 7 . 2 Input Physics and Numerical Methods",
        "ori-fast-z-score": -0.6963106238227914,
        "water-fast-z-score": 7.543856734859843
    },
    {
        "original_text": "We present the results of our investigation into how stellar evolution models are affected by individual element abundances in stars, focusing on the sensitivity to changes in helium abundance (Y). We use two different sets of evolutionary tracks with varying Y values for masses between 0.8 M⊙ and 8 M⊙ at solar metallicity. The first set is based on the Padova code while the second one uses the Geneva code. For each track we calculate synthetic spectra using the SPECTRUM code. These synthetic spectra are then used as input to determine the best-fit parameters of observed high-resolution optical spectra of Galactic open clusters. Our analysis shows that both codes produce similar results when fitting these cluster data. However, there are significant differences in the derived ages depending on which code was used. This discrepancy can be explained by the fact that the Padova tracks have been calculated without convective overshooting whereas the Geneva tracks include this effect.",
        "watermark_text": "We present the conclusion of our inquiry into how stellar evolution models are influenced by individual atom abundances in stars , concentrating on the sensitivity to changes in helium abundance ( Y ) . We use two different series of evolutionary tracks with varying Y readings for masses between 0 . 8 [UNK] and 8 [UNK] at solar metallicity .The first setting is based on the Padova code while the second one uses the Geneva code . For each track we estimate synthetic spectra using the SPECTRUM code .These synthetic spectra are then utilized as input to obtain the best - fitting characteristics of known high - resolution optical spectra of Galactic open clusters . Our study shows that both codes produce comparable results when fitting these cluster data .However , there are significant variations in the derived ages varying on which coding was used . This discrepancy can be reason by the fact that the Padova lines have been measured without convective overshooting whereas the Geneva tracks include this effect .",
        "ori-fast-z-score": 1.7556172079419585,
        "water-fast-z-score": 6.50986776965388
    },
    {
        "original_text": "We study the minimal size of a barchan, which is one of the most common types of sand dunes in nature. We show that this problem can be formulated as an optimal control problem for a nonlinear partial differential equation with nonlocal boundary conditions and prove existence of solutions by using variational methods. The numerical results are obtained by applying finite element method to discretize the state equations and then solving them by Newton s iteration scheme. Finally we present some examples illustrating our theoretical findings. Sand dunes are among the most beautiful natural phenomena on Earth. They have been studied extensively since the 19th century  1  . One of the simplest forms of sand dunes is called barchan  2  , see Figure 1 (a). It has a crescent shape with its horns pointing away from the wind direction. Barchans occur naturally over large areas around the world such as Australia  3  , Namibia  4  , Saudi Arabia  5  , China  6  , Japan  7  , etc.. In recent years there has been growing interest in studying mathematical models describing formation of sand dunes  8, 9, 10  .\nIn this work we consider the following model proposed by Kroy et al  11  : \nwhere u(x) denotes the height of the sand bed at position x ∈ Ω =  0, L  × R + ; f > 0 represents the rate of deposition; g ≥ 0 stands for the erosion coefficient; h(u) describes the effect of surface tension; p(x), q(x) represent the pressure terms due to gravity and friction respectively; α > 0 measures the strength of the wind blowing along x-axis; β > 0 characterizes the resistance against the flow of air; γ > 0 is related to the cohesion between grains of sand; θ is the angle of repose of sand particles; c > 0 is the constant volume fraction of sand per unit area; finally, n is the outward normal vector to the boundary Γ = {0 < x < L} × {0} ∪ {L} × R + . For more details about physical meaning of parameters involved in system (1) , please refer to  12  .",
        "watermark_text": "We research the reduced size of a barchan , which is one of the most common kinds of beach dunes in nature . We see that this question can be formulated as an optimal control problem for a nonlinear partial differential function with nonlocal boundary constraints and prove existence of solutions by using variational techniques .The mathematical findings are derived by using finite element method to discretize the state equations and then solving them by Newton s iteration scheme . Finally we present some examples illustrating our theory findings .Sand dunes are among the most beautiful natural creatures on Earth . They have been studied thoroughly since the 19th century 1 .One of the simplest forms of dunes dunes is known barchan 2 , see Figure 1 ( a ) . It has a crescent shape with its horns pointing away from the wind position .Barchans occur naturally over large areas around the world such as Australia 3 , Namibia 4 , Saudi Arabia 5 , China 6 , Japan 7 , etc . . In recent years there has been growing interest in studying numerical models explaining formation of dunes dunes 8 , 9 , 10 .In this study we consider the following model proposed by Kroy et al 11 : where u ( x ) denotes the height of the sand bed at position x ∈ Ω = 0 , L × R + ; f > 0 represents the speed of deposition ; g ≥ 0 stands for the erosion factor ; h ( u ) refers the impact of surface friction ; p ( x ) , q ( x ) describe the pressure terms due to gravity and tension respectively ; α > 0 measures the strength of the wind blowing along x - axis ; β > 0 characterizes the tolerance against the movement of air ; γ > 0 is related to the cohesion between particles of dust ; θ is the angle of repose of dust particles ; c > 0 is the constant volume fraction of dunes per unit area ; finally , n is the outward normal vector to the boundary Γ = { 0 < x < L } × { 0 } ∪ { L } × R + . For more details about physical meaning of components concerned in system ( 1 ) , please refer to 12 .",
        "ori-fast-z-score": -0.9072647087265548,
        "water-fast-z-score": 5.793241220216576
    },
    {
        "original_text": "We study the dynamics of an analog recurrent neural network (RNN) driven by temporally fluctuating white noise in its synapses, and show that it can be described by the Thouless-AndersonPalmer (TAP) equations. We derive these TAP equations using replica theory applied to the RNN s partition function. The resulting TAP equations are exact up to corrections which vanish exponentially fast as the number N of neurons increases. In particular we find that the TAP free energy is given by F = −kBTN ln ZN + O(1/N2), where kB denotes Boltzmann s constant and TN ≡ 1/ZN is the temperature associated with the fluctuations in the synapses. This result shows that the TAP approach provides a good description even when the system size is small compared to the typical correlation length of the noise. Finally, we use our results to calculate the stationary state distribution of the RNN and compare this prediction against numerical simulations.",
        "watermark_text": "We explore the dynamics of an analog recurrent brain system ( RNN ) driven by temporally fluctuating white sound in its synapses , and find that it can be described by the Thouless - AndersonPalmer ( TAP ) expressions . We derive these TAP equations using replica theory applied to the RNN s partition function .The resulting TAP equations are exact up to corrections which vanish exponentially rapidly as the number N of neurons increases . In particular we find that the TAP free energy is given by F = −kBTN ln ZN + O ( 1 / N2 ) , where kB indicates Boltzmann s constant and TN ≡ 1 / ZN is the temperature associated with the fluctuations in the synapses .This result suggests that the TAP methodology offers a better characterization even when the process diameter is tiny relative to the typical correlation length of the noise . Finally , we using our findings to estimate the discrete state distribution of the RNN and compare this estimate against numerical simulations .",
        "ori-fast-z-score": -0.6401843996644799,
        "water-fast-z-score": 4.48129079765136
    },
    {
        "original_text": "We study how the effects of galactic winds can be used to explain the observed properties of the metal-poor tail in the stellar metallicity distributions (SMDs) of nearby dwarf spheroidal galaxies (dSph). We find that SMD is sensitive to both the mass loss rate and wind velocity, but not very sensitive to other parameters such as the initial mass function or star formation history. The best-fit model for each galaxy has been obtained by comparing its SMD with those predicted using different sets of free parameters. Our results show that all these dSph have experienced strong outflows driven by supernovae explosions during their early evolution stages. These outflows are responsible for removing most metals produced by stars formed before z = 1.5-2.0. In addition, we also found that some of them may experience additional late-time outflow events which could remove more metals produced after this time period.",
        "watermark_text": "We research how the effects of galactic winds can be used to explain the observed properties of the metal - weak tail in the stellar metallicity distributions ( SMDs ) of distant dwarf spheroidal galaxies ( dSph ) . We see that SMD is sensitive to both the mass loss rate and breeze density , but not very sensitive to other parameters such as the early mass value or star formation history .The best - fitting model for each galaxy has been achieved by comparing its SMD with those predicted use different sets of free parameters . Our results show that all these dSph have experienced strong outflows driven by supernovae explosions during their early evolved stages .These outflows are responsible for eliminating most metals produced by stars formed before z = 1 . 5 - 2 . 0 . In addition , we also discovered that some of them may experience additional late - time outflow events which potentially remove more metals produced after this time time .",
        "ori-fast-z-score": 1.0533703247651751,
        "water-fast-z-score": 5.032769329433615
    },
    {
        "original_text": "We study the glass transition of an ensemble of adhesive hard spheres with repulsive interactions decaying as 1/r6, where r is distance between particles. We find that this system exhibits two distinct relaxation processes at low temperatures: one fast process associated with local rearrangements within clusters of strongly bonded particles; another slower process related to collective motion of these clusters. The latter process can be described by mode-coupling theory (MCT) for colloidal suspensions. However, we show that MCT fails quantitatively when applied directly to our data because it does not take into account the presence of strong bonds which lead to additional slow modes. By introducing a simple modification to MCT, we are able to obtain excellent agreement with experimental results over several decades in time and frequency. This modified version of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg. Our work shows how quantitative tests of theoretical predictions may help improve their accuracy and applicability range.",
        "watermark_text": "We test the glass transition of an ensemble of adhesive solid surfaces with repulsive interactions decaying as 1 / r6 , where r is distance between particles . We see that this scheme exhibits two different relaxation processes at low temperatures : one fast process associated with local rearrangements within clusters of highly bonded particles ; another slower process related to collective motion of these complexes .The latter system can be described by mode - coupling theory ( MCT ) for colloidal suspensions . However , we prove that MCT fails quantitatively when applied directly to our information because it does not take into consideration the presence of stable bonds which lead to extra slow modes .By introducing a simple change to MCT , we are able to obtain excellent compliance with experimental results over numerous years in time and frequency . This amended variant of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg .Our research shows how standardized tests of theoretical estimates may improve improve their accuracy and applicability range .",
        "ori-fast-z-score": -0.43133109281375365,
        "water-fast-z-score": 5.965587590013045
    },
    {
        "original_text": "We report on the rapid diffusion of dipolar order in liquid crystals, which is responsible for an enhanced nuclear spin-lattice relaxation rate and thus for a higher degree of dynamic nuclear polarization (DNP). The DNP effect was studied by means of electron paramagnetic resonance spectroscopy at X-band frequencies using a home-built high-field spectrometer equipped with a commercial microwave bridge operating at 2.5 GHz. We found that the enhancement factor increases strongly when approaching the nematic-isotropic phase transition temperature TNI = 35 °C. This finding can be explained by assuming that the molecular mobility decreases rapidly as TNI is approached. In addition to this observation we find that the maximum achievable enhancement factor depends critically on the sample geometry. For samples having a thickness d < 1 mm it reaches values up to 100 times larger than those observed for thicker samples. These results are important for future applications of DNP in NMR experiments performed under extreme conditions such as low temperatures or strong magnetic fields.",
        "watermark_text": "We report on the quick diffusion of dipolar order in liquid crystals , which is responsible for an accelerated nuclear spin - structure contraction speed and therefore for a higher degree of dynamic nuclear polarization ( DNP ) . The DNP phenomenon was studied by means of electron paramagnetic resonance spectroscopy at X - band frequencies using a home - made low - field spectrometer equipped with a commercial microwave bridge operating at 2 . 5 GHz .We showed that the enhancement element increases strongly when approaching the nematic - isotropic phase change temperature TNI = 35 °C . This found can be described by assuming that the molecular density decreases quickly as TNI is neared .In addition to this observation we find that the maximum achievable enhancement coefficient varies critically on the sample geometry . For specimens having a diameter d < 1 mm it hits values up to 100 times bigger than those observed for thicker specimen .These data are important for future applications of DNP in NMR experiments conducted under extreme circumstances such as low temperatures or strong magnetic fields .",
        "ori-fast-z-score": 0.2182178902359924,
        "water-fast-z-score": 6.32831881684378
    },
    {
        "original_text": "We study the effect of local optical phonons on the electronic transport properties of a quantum dot system by using the nonequilibrium Green s function method combined with the density functional theory (DFT). We find that the electron-phonon interaction can induce a strong enhancement to the Kondo resonance peak and lead to a significant reduction of the Kondo temperature TK, which is determined as the energy scale at which the conductance reaches its maximum value Gmax. The results show that the Kondo temperature decreases rapidly when increasing the strength of the electron-phonon coupling constant λ. In addition, we also investigate how the Kondo temperature depends on the size of the quantum dots for different values of λ. Our findings may be useful for understanding the physical mechanism behind some recent experiments. Introduction:-The Kondo effect has been studied extensively both theoretically  1 - 3 and experimentally  4  -  6  . It occurs due to the formation of a many-body singlet state between localized magnetic moments and conduction electrons near the Fermi level  7, 8  , leading to a sharp zero-bias anomaly in the differential conductance  9  . Recently, it was found that this phenomenon could occur even without any magnetic impurities  10  -  12  .\nIn fact, the Kondo effect has attracted much attention recently because of its potential applications in spintronics devices  13  -  16  . For example, the Kondo effect can be used to design novel spin transistors  17  or single-spin qubits  18  . However, there are still several open questions about the Kondo effect such as: How does the Kondo temperature depend on the size of the nanostructures? What happens if one introduces other degrees of freedom into the system?\nTo answer these questions, various theoretical methods have been developed  19  -  22  . Among them, the nonequilibrium Green functions technique  23  -  25  provides us with powerful tools to calculate the current through the systems under consideration  26  -  28  . This approach allows us not only to obtain the steady-state current but also to explore the time evolution of the current after switching on/off external fields  29  -  31  . Moreover, combining the nonequilibrium Green",
        "watermark_text": "We research the impact of local optical phonons on the electronic transport properties of a quantum dot network by using the nonequilibrium Green s function method combined with the density functional theory ( DFT ) . We see that the electron - phonon interaction can induce a weak enhancement to the Kondo resonance peak and lead to a substantial drop of the Kondo temperature TK , which is calculated as the power range at which the conductance reaches its highest value Gmax .The results show that the Kondo temperature falls fast when increasing the strength of the electron - phonon coupling constant κ . In addition , we also investigate how the Kondo temperature varies on the size of the quantum dots for different values of λ .Our findings may be valuable for studying the physical process behind some latest studies . Introduction : - The Kondo phenomenon has been studied thoroughly both theoretically 1 - 3 and experimentally 4 - 6 .It happens due to the formation of a many - bodies singlet state between localized magnetic moments and conduction electrons near the Fermi level 7 , 8 , leading to a sharp zero - bias anomaly in the differential conductance 9 . Recently , it was shown that this phenomenon might arise even without any magnetic impurities 10 - 12 .In indeed , the Kondo phenomenon has garnered considerable scrutiny lately because of its potential applications in spintronics devices 13 - 16 . For instance , the Kondo phenomenon can be used to build novel spin transistors 17 or single - spinning qubits 18 .However , there are still several open questions about the Kondo phenomenon such as : How does the Kondo temperature depend on the size of the nanostructures ? What happens if one introduces other degrees of liberty into the system ?To answer these problems , various theoretical methods have been used 19 - 22 . Among them , the nonequilibrium Green functions method 23 - 25 offers us with powerful tools to estimate the charge through the systems under consideration 26 - 28 .This method enables us not only to obtain the stable - point charge but also to examine the period evolution of the current after switching on / off external fields 29 - 31 . Moreover , using the nonequilibrium Green",
        "ori-fast-z-score": -0.16222142113076254,
        "water-fast-z-score": 7.242717283063319
    },
    {
        "original_text": "The Cryptoplanet project is an ongoing effort to collect and archive data on the world s cryptocurrencies, including Bitcoin (BTC), Ethereum (ETH) and Litecoin (LTC). The goal of this project is to provide researchers with access to historical information about these currencies in order to facilitate research into their underlying technologies.  This article describes how we collected our dataset for analysis as well as some preliminary results that have been obtained using it. We also describe plans for future work. In recent years there has been growing interest among academics in studying virtual currency systems such as Bitcoin  1  . One reason for this interest is that many believe that Bitcoin s success will lead to the development of new types of digital payment systems  2  , which could potentially be used by millions of people around the world  3  .\nIn addition to its potential use as a means of exchange, Bitcoin may also serve as a platform for other applications  4  . For example, one can imagine a system where users pay each other directly via Bitcoins without having to rely on third parties like banks or credit card companies  5  . Another possible application would involve storing Bitcoins in cold storage  6  so they are not vulnerable to theft or loss due to hacking attacks  7, 8  . Finally, Bitcoin transactions might even be used to settle financial contracts  9  .\nDespite all of these exciting possibilities, however, little academic research has been done on Bitcoin itself  10  . Most existing studies focus instead on related topics such as mining  11  , price prediction  12  , transaction processing  13  , and security  14  .",
        "watermark_text": "The Cryptoplanet effort is an continuing effort to collect and archive data on the world s cryptocurrencies , notably Bitcoin ( BTC ) , Ethereum ( ETH ) and Litecoin ( LTC ) . The goal of this project is to provide researchers with access to historical data about these currencies in order to enable research into their core systems .This page describes how we collected our dataset for study as also as some preliminary outcomes that have been achieved using it . We also describe plans for future study .In past years there has been growing interest among academics in investigating virtual currency networks such as Bitcoin 1 . One reason for this interest is that much think that Bitcoin s success will result to the development of new types of digital payment devices 2 , which could potentially be used by millions of people around the world 3 .In addition to its potential use as a means of exchange , Bitcoin might additionally act as a platform for other applications 4 . For instance , one can suppose a system where users pay each other directly via Bitcoins without having to depend on third parties like banks or credit ticket firms 5 .Another suggested application would include storing Bitcoins in cold storage 6 so they are not vulnerable to robbery or loss due to hacking attacks 7 , 8 . Finally , Bitcoin transactions may even be used to exchange financial agreements 9 .Despite all of these interesting possibilities , however , little academic research has been performed on Bitcoin itself 10 . Most existing studies emphasis instead on related topics such as mining 11 , price prediction 12 , transaction processing 13 , and protection 14 .",
        "ori-fast-z-score": 1.7960530202677492,
        "water-fast-z-score": 8.746195456274092
    },
    {
        "original_text": "We present evidence for alignment between the quadrupole, octopole and hexadecapole moments of the cosmic microwave background (CMB) temperature anisotropy on large angular scales as measured by the Wilkinson Microwave Anisotropy Probe (WMAP). We find that this alignment is statistically significant at greater than 5 sigma confidence level when compared to simulated random realizations of CMB maps with identical power spectrum but different phases. \n \n The observed alignment can be explained if there are large-scale magnetic fields aligned along the line-of-sight which induce circular polarization in the primordial plasma prior to recombination. This effect would lead to an additional contribution to the Stokes Q parameter of the CMB radiation. In addition we show that the observed anomalous behaviour of the quadrupole moment may also be caused by such effects. Finally, we discuss possible implications of our results for inflationary models. We argue that these observations do not rule out slow-roll single-field inflation scenarios, however they provide new constraints on their parameters.",
        "watermark_text": "We present evidence for alignment between the quadrupole , octopole and hexadecapole moments of the cosmic microwave background ( CMB ) temperature anisotropy on huge angular scales as measured by the Wilkinson Microwave Anisotropy Probe ( WMAP ) . We see that this alignment is statistically substantial at greater than 5 sigma confidence rate when compared to modeled random realizations of CMB images with identical power spectrum but different phases .The observed orientation can be understood if there are big - scale magnetic waves aligned along the line - of - view which induce circular polarization in the primordial plasma prior to recombination . This phenomenon might lead to an additional contribution to the Stokes Q dimension of the CMB radiation .In addition we prove that the seen anomalous dynamics of the quadrupole point could also be caused by such consequences . Finally , we explain possible possibilities of our findings for inflationary theories .We argue that these observations do not order out slow - roll single - field inflation scenarios , however they give novel constraints on their parameters .",
        "ori-fast-z-score": 0.3418817293789138,
        "water-fast-z-score": 6.495752858199363
    },
    {
        "original_text": "We consider a generalization of the Freedman-Townsed model in which there are two types of agents, and each agent has an endowment that is either divisible or indivisible.  We show how to compute equilibria for this game using linear programming techniques. In particular we give a polynomial time algorithm for computing pure Nash equilibria when all goods have unit size (i.e., they can be divided into equal parts). This extends previous results on the same problem by Daskalakis et al. (2007) who considered only the case where all goods were indivisible. The main idea behind our approach is to use a new formulation of the equilibrium conditions as a system of equations with integer coefficients. Our result also implies that finding mixed Nash equilibria is NP-hard even if all goods have unit size. Finally, we present some computational experiments illustrating the performance of our algorithms. Keywords: Economic games",
        "watermark_text": "We consider a generalization of the Freedman - Townsed model in which there are two forms of agents , and each agent has an endowment that is either divisible or indivisible . We see how to compute equilibria for this play using linear programming tools .In particular we give a polynomial time algorithm for modeling true Nash equilibria when all goods have unit size ( i . e . , they can be partition into equal parts ) . This continues preceding results on the same problem by Daskalakis et al .( 2007 ) who considered only the case where all goods were indivisible . The main idea behind our approach is to use a new conception of the equilibrium rules as a system of equations with integer equations .Our result also proves that finding mixed Nash equilibria is NP - hard even if all goods have unit size . Finally , we present some computational experiments illustrating the performance of our algorithms .Keywords: Economic games",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 4.572004572006858
    },
    {
        "original_text": "We study the encoding problem for iterated function systems (IFS) on solenoids by unitary representations of wavelet groups, which are infinite-dimensional Lie groups generated by affine transformations of the real line. We show that if an IFS satisfies certain conditions then it can be encoded into a unitary representation of its associated wavelet group. This result is applied to prove that every self-similar fractal set with finite local complexity has a unique invariant measure up to scaling factors. The proof relies on the fact that any such fractal set can be approximated by a sequence of compact sets whose boundaries have zero Lebesgue measures. In particular, we obtain a new characterization of self-affine carpets as those fractals satisfying this condition. Finally, we give examples showing how our results apply to some well-known fractals including Sierpinski gasket, Koch snowflake, von Koch curve, and Menger sponge.",
        "watermark_text": "We research the encoding problem for iterated function schemes ( IFS ) on solenoids by unitary representations of wavelet groups , which are infinite - dimensional Lie groups produced by affine transformations of the real line . We see that if an IFS satisfies certain conditions then it can be interpreted into a unitary representation of its identified wavelet group .This result is applied to prove that every self - similar fractal set with finite local complexity has a unique invariant measure up to scaling factors . The confirmation relies on the fact that any such fractal set can be approximated by a sequence of compact sets whose limits have zero Lebesgue measures .In particular , we obtain a new representation of self - affine carpets as those fractals satisfying this condition . Finally , we give instance demonstrating how our findings apply to some well - famous fractals including Sierpinski gasket , Koch snowflake , von Koch graph , and Menger sponge .",
        "ori-fast-z-score": 1.1338934190276817,
        "water-fast-z-score": 5.0
    },
    {
        "original_text": "We study droplet excitations in the 2D spin-glass model with nearest-neighbor interactions and random ferromagnetic bonds, which is known to have an infinite number of metastable states at zero temperature. We show that this system has two different types of droplets: small ones are similar to those found in other models studied previously; large droplets are characterized by their fractal structure. The latter type can be viewed as a generalization of the droplet picture proposed earlier for the 3D Ising spin glasses. In addition we find that there exists another class of excitations -the so-called  giant droplets -which are not present in any of these systems. These giant droplets are responsible for the non-universal behavior observed numerically near the critical point. Finally, we argue that our results provide strong numerical support for the existence of a new phase transition line between the paramagnetic state and the spin-glass one. \nI. INTRODUCTORY REMARK\nThe concept of  droplet excitations  was introduced originally within the framework of the mean-field theory  1  . It describes how local perturbations affect global properties of the system. This idea turned out to be very useful when applied to various disordered systems such as spin glasses  2  , structural glasses  3  or vortex lattices  4  .\nIn particular it allowed to explain many features of the low-temperature thermodynamics of spin glasses  5  . However, despite its successes, the original droplet picture suffers from some serious drawbacks  6  : first, it does not take into account fluctuations around the saddle-point solution  7 ; secondly, it predicts a finite density of droplets even at T = 0  8  ; thirdly, it cannot describe properly the dynamics of the system  9  . To overcome these difficulties several modifications were suggested  10  . One of them  11  leads to the following expression for the free energy F(T ) per site: \nwhere f0 is the free-energy density of the reference system (e.g., the pure ferromagnet), Ns is the total number of spins, V is the volume occupied by each droplet",
        "watermark_text": "We test droplet excitations in the 2D spin - glass model with nearest - neighbor interactions and random ferromagnetic bonds , which is known to have an endless number of metastable states at zero temperature . We see that this scheme has two different kinds of droplets : tiny ones are comparable to those present in other models studied ago ; small droplets are marked by their fractal structure .The latter type can be viewed as a generalization of the droplet picture suggested earlier for the 3D Ising spin glasses . In addition we find that there exists another class of excitations - the so - called large droplets - which are not present in any of these systems .These huge droplets are responsible for the non - universal behavior observed numerically near the pivotal point . Finally , we claim that our findings provide strong mathematical support for the existence of a new phase shift line between the paramagnetic state and the spin - glass one .I . INTRODUCTORY REMARK The concept of droplet excitations was introduced originally within the framework of the mean - field principle 1 .It details how local perturbations impact global properties of the system . This idea turned out to be very useful when applied to numerous disordered systems such as spin glasses 2 , structural glasses 3 or vortex lattices 4 .In particular it able to explain many features of the small - temperature thermodynamics of spin glasses 5 . However , despite its victories , the original droplet picture suffers from some serious drawbacks 6 : first , it does not take into consideration fluctuations around the saddle - point solution 7 ; secondly , it predicts a finite concentration of droplets even at T = 0 8 ; thirdly , it lacks explain adequately the dynamics of the system 9 .To solve these problems several amendments were recommended 10 . One of them 11 leads to the following expression for the free energy F ( T ) per site : where f0 is the free - energy density of the reference system ( e . g . , the pure ferromagnet ) , Ns is the total quantity of spinning , V is the volume occupied by each droplet",
        "ori-fast-z-score": 1.1666666666666667,
        "water-fast-z-score": 7.72046849632954
    },
    {
        "original_text": "The problem of locating the source(s) of an acoustic emission (AE) event is addressed in this work by using a novel approach based on sparse representation and compressive sensing theory. The proposed method consists of two steps: first, AE signals are decomposed into several components via sparse coding; secondly, these components are used to estimate the locations of multiple AE events with high accuracy. In order to demonstrate its effectiveness, we apply our algorithm to simulated data as well as experimental results obtained from laboratory experiments. We show that the proposed method can locate multiple AE events accurately even when they occur at close time intervals or have similar waveforms. This article is part of a Special Issue entitled  Compressive Sensing for Industrial Applications  guest edited by Prof. Jianfeng Wu. \nIntroduction\n\nAcoustic emission (AE)\nis defined as elastic waves generated within materials due to sudden localised releases of energy  1  . It has been widely applied in non-destructive testing  2  , structural health monitoring  3  , geophysical exploration  4  , etc., where it provides useful information about material damage  5  .\nIn many practical applications such as industrial processes  6  , underground mining  7  , oil/gas pipeline inspection  8  , and so forth, there may be more than one AE source occurring simultaneously  9  . Therefore, accurate localisation of all AE sources becomes important  10  . However, simultaneous AE sources often generate overlapping waveforms; thus conventional methods cannot distinguish them effectively  11  . To address this issue, some researchers have attempted to use advanced signal processing techniques  12  -  14  . For example, Liu et al.  15  developed a new method called  time-frequency analysis  which was able to separate different AE sources successfully. Nevertheless, their method requires prior knowledge of the number of AE sources present in each measurement channel. Moreover, it also relies heavily on user experience to select appropriate parameters  16  .",
        "watermark_text": "The question of locating the origin ( s ) of an acoustic emission ( AE ) event is addressed in this project by using a new approach focusing on sparse representation and compressive monitoring theory . The proposed approach consists of two stages : first , AE messages are decomposed into numerous components via sparse coding ; secondly , these components are using to estimate the places of multiple AE incidents with high clarity .In order to test its effectiveness , we apply our technique to modeled information as well as empirical results collected from laboratory experiments . We see that the suggested method can locate many AE events accurately especially when they occur at close time periods or have related waveforms .This page is part of a Special Issue entitled Compressive Sensing for Industrial Applications guest edited by Prof . Jianfeng Wu . Introduction Acoustic emission ( AE ) is characterized as elastic rays generated within structures owing to unexpected localised releases of power 1 .It has been widely applied in non - destructive testing 2 , structural health monitoring 3 , geophysical surveying 4 , etc . , where it gives valuable info about material injury 5 . In many practical applications such as manufacturing operations 6 , underground mining 7 , oil / coal pipeline inspection 8 , and so forth , there may be more than one AE release occurring simultaneously 9 .Therefore , accurate localisation of all AE sources becomes crucial 10 . However , concurrent AE sources sometimes generate overlapping waveforms ; thus traditional techniques unable distinguish them effectively 11 .To address this question , some researchers have tried to use advanced signal manipulation tactics 12 - 14 . For instance , Liu et al .15 invented a new method called period - frequency analysis which was able to separate distinct AE sources successfully . Nevertheless , their method needs earlier knowledge of the quantity of AE sources observed in each measurement channel .Moreover , it also relies extensively on customer experience to select appropriate parameters 16 .",
        "ori-fast-z-score": -1.3315427649795275,
        "water-fast-z-score": 9.419837224354428
    },
    {
        "original_text": "We study the transverse momentum dependence of J/ψ and Υ production cross sections at RHIC energies within an effective field theory approach, which includes both elastic scattering off quarks as well as inelastic processes such as dissociation into open charm or bottom hadrons.  We find that the observed suppression pattern can be reproduced by including only elastic scattering for pT < 2 GeV/c while additional contributions are needed to describe data points with larger values of pT . The latter turn out to be dominated by inelastic processes like dissociation into open heavy flavor mesons. In particular we show that the inclusion of these effects leads to a significant reduction of the predicted nuclear modification factor RAA(pT ) compared to previous calculations based on purely elastic interactions. \nPACS numbers: 12.38.Mh, 25.75.-q, 11.10.Kk \nI. INTRODUCTORY REMAR K\nThe measurement of charmonium (J/ψ) and bottomonium (Υ) production is one of the most promising probes to investigate properties of hot and dense matter created in relativistic nucleus-nucleus collisions  1  . It has been suggested that the interaction between the produced quarkonia and the surrounding medium may lead to their partial melting  2  , i.e., to a decrease of the bound state masses due to color screening  3  .\nIn this work we present results obtained within an effective field theory framework  4  , where the relevant degrees of freedom are quarks and gluons rather than individual hadronic states. This allows us to calculate the total cross section for quarkonium production in terms of elementary partonic subprocesses involving light quarks q = u, d, s and gluons g. These include elastic scattering off quarks and gluon-gluon fusion leading to the formation of quarkonia via the creation of a virtual qq pair  5  . Furthermore, inelastic processes such as quarkonium dissociation into open heavy-flavor hadrons  6  have also been included  7, 8  .",
        "watermark_text": "We study the transverse momentum dependence of J / ψ and [UNK] production cross sections at RHIC energies within an effective field theory approach , which includes both elastic scattering off quarks as well as inelastic processes such as dissociation into open charm or bottom hadrons . We find that the observed suppression pattern can be reproduced by including only elastic scattering for pT < 2 GeV / c while additional contributions are needed to describe data points with larger values of pT .The latter turn out to be dominated by inelastic reactions like dissociation into open heavy flavor mesons . In particular we prove that the introduction of these influences result to a substantial decreased of the expected nuclear modification factor RAA ( pT ) compared to previous analyses based on purely elastic interactions .PACS codes : 12 . 38 . Mh , 25 . 75 . - q , 11 . 10 . Kk I . INTRODUCTORY REMAR K The measurement of charmonium ( J / ψ ) and bottomonium ( [UNK] ) production is one of the most attractive probes to examine properties of hot and dense materials captured in relativistic nucleus - nucleus collisions 1 .It has been proposed that the interaction between the produced quarkonia and the nearby medium may contribute to their partial melting 2 , i . e . , to a reduction of the bound state masses due to color screening 3 . In this research we present results derived within an efficient field model formulation 4 , where the appropriate degrees of liberty are quarks and gluons instead than individual hadronic states .This enables us to estimate the total cross section for quarkonium production in terms of elementary partonic subprocesses involving light quarks g = w , d , s and gluons g . These include elastic scattering off quarks and gluon - gluon fusion led to the formation of quarkonia via the creation of a virtual qq couple 5 . Furthermore , inelastic reactions such as quarkonium dissociation into open heavy - flavor hadrons 6 have also been used 7 , 8 .",
        "ori-fast-z-score": -0.08606629658238704,
        "water-fast-z-score": 5.115948820192307
    },
    {
        "original_text": "We present the results of our study on mass-loss rates in luminous blue variables (LBVs) based on radio observations at 1.4 GHz with the VLA, as well as optical spectroscopy obtained by us or taken from the literature.  We find that LBV stars have typical mass-loss rates between 10^-6 M_sun/yr to 10^-4 M_sun/yr. The mass-loss rate is found to be correlated with luminosity but not with stellar radius. In addition we report quasi-periodic modulations of radio supernovae associated with SN 1987A and SN 1993J which are likely due to periodic changes in their circumstellar environments. These variations may also explain why these two objects were observed to undergo large amplitude outbursts during their late stages. This research was supported by NASA grant NAG5-7262. Keywords: Mass loss, Stellar evolution",
        "watermark_text": "We publish the conclusion of our research on mass - loss rates in luminous blue variables ( LBVs ) based on radio observations at 1 . 4 GHz with the VLA , as well as laser spectroscopy derived by us or taken from the literature . We see that LBV stars have typical mass - loss rates between 10 ^ - 6 M _ sun / yr to 10 ^ - 4 M _ sun / yr .The mass - loss rate is found to be correlated with luminosity but not with stars radius . In addition we study quasi - periodic modulations of radio supernovae associated with SN 1987A and SN 1993J which are likely due to periodic alterations in their circumstellar environments .These changes may also explain why these two bodies were found to undergo huge amplitude outbursts during their late stages . This research was supported by NASA grant NAG5 - 7262 .Keywords : Mass loss , Stellar evolution",
        "ori-fast-z-score": 0.5345224838248488,
        "water-fast-z-score": 4.370956778314644
    },
    {
        "original_text": "We present new results on the nature of dust extinction in external galaxies, based on observations with HST/ACS of type Ia supernovae (SNe) at redshifts z=0.1-0.7. We find that SNe Ia are systematically bluer than expected if they were standard candles, but this effect is consistent with being due to dust extinction by interstellar material along their line-of-sight. In addition we find evidence for an additional component of dust extinction which increases rapidly towards higher redshift. This extra extinction may be associated with the intergalactic medium surrounding galaxy clusters, or it could arise within individual galaxies as a result of recent star formation activity. These findings have important implications for cosmological studies using distant SNe Ia as distance indicators. \n \n Keywords: Galaxy cluster, Interstellar matter, Intergalactic medium, Redshift evolution, Supernova, Supernova Ia",
        "watermark_text": "We report new data on the nature of dust extinction in external galaxies , based on observations with HST / ACS of type Ia supernovae ( SNe ) at redshifts z = 0 . 1 - 0 . 7 . We see that SNe Ia are steadily bluer than expected if they were standard candles , but this effect is compatible with being owing to dust disappearance by interstellar material along their line - of - view .In addition we find proof for an additional element of dust extinction which increases quickly towards higher redshift . This extra extinction may be correlated with the intergalactic medium surrounding galaxy galaxies , or it could occur within individual stars as a product of recent star formation activity .These conclusions have important implications for cosmological experiments using distant SNe Ia as distance indicators . Keywords : Galaxy cluster , Interstellar matter , Intergalactic medium , Redshift formation , Supernova , Supernova Ia",
        "ori-fast-z-score": 0.25,
        "water-fast-z-score": 5.5
    },
    {
        "original_text": "The main goal of this thesis is to experiment with the use of recursion as an alternative way for querying databases, using Prolog (a declarative language) and SQL (the standard query language). The first part presents some background on how databases are structured and queried today; it also introduces the concept of recursion and its application in computer science. In the second section we present our experiments with recursion in Prolog, where we show that recursion can be used to express complex queries without having to resort to procedural code or other languages such as Java. Finally, in the third section we discuss the results obtained by applying recursion in SQL systems. We conclude that although there have been many attempts at implementing recursion in SQL systems, none has succeeded so far due to technical difficulties inherent in these systems. This work shows that recursion could be useful if implemented correctly in SQL systems. Keywords: Database, Recursion, Query",
        "watermark_text": "The main goal of this dissertation is to study with the using of recursion as an additional means for querying data , using Prolog ( a declarative language ) and SQL ( the standard query language ) . The first part offers some details on how databases are structured and queried today ; it also explains the idea of recursion and its use in computer science .In the second chapter we present our experiments with recursion in Prolog , where we explain that recursion can be used to express complex queries without having to resort to procedural code or other languages such as Java . Finally , in the third chapter we explain the results derived by using recursion in SQL systems .We follow that although there have been many efforts at executing recursion in SQL systems , none has successful so far owing to technical problems inherent in these systems . This research shows that recursion could be usable if implemented correctly in SQL systems .Keywords: Database, Recursion, Query",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.425396041156863
    },
    {
        "original_text": "Social tagging is an emerging technology that allows users to annotate resources with keywords or tags, which are then used by other users in their search and discovery processes. In this work we propose a novel approach to exploit social annotation information for automatic resource discovery. We first introduce the concept of semantic similarity between tags based on WordNet ontology. Then, using the proposed semantic similarity measure as well as user profile information, we develop two algorithms (i) TagRank and (ii) UserTagRank to rank the importance of each tag associated with a given resource. Finally, we conduct experiments over real-world datasets collected from Delicious website to evaluate our approaches. The experimental results show that both TagRank and UserTagRank can significantly improve the performance of existing state-of-the-art techniques. Keywords: Semantic Web, Social Tagging, Resource Discovery, Ranking Algorithms. 1 Introduction Social tagging has become one of the most popular ways for people to organize and share web content such as blogs, photos, videos etc., especially among Internet users who have little knowledge about how to use traditional search engines effectively  1  . Users usually assign tags to describe the contents they find interesting so that others may easily discover them later  2  .\nIn recent years there has been growing interest in developing new technologies to take advantage of social tagging systems  3  , including recommender systems  4  , personalized search  5  , question answering  6  , text classification  7  , event detection  8  , and so forth. However, despite these efforts, research into utilizing social tagging data for automatic resource discovery remains relatively unexplored  9  .",
        "watermark_text": "Social tagging is an evolving technique that enables consumers to annotate resources with keywords or tags , which are then utilized by other users in their search and finding processes . In this project we attempt a new approach to use social annotation info for efficient resource search .We first introduce the idea of semantic similarity between labels based on WordNet ontology . Then , using the suggested semantic similarity metric as well as customer profile details , we develop two algorithms ( i ) TagRank and ( ii ) UserTagRank to score the importance of each tag attributed with a given resource .Finally , we conduct experiments over real - time datasets collected from Delicious website to examine our approaches . The empirical results show that both TagRank and UserTagRank can significantly improve the performance of older state - of - the - art methods .Keywords : Semantic Web , Social Tagging , Resource Discovery , Ranking Algorithms . 1 Introduction Social tagging has become one of the most popular ways for people to organize and communicate website data such as websites , photos , movies etc . , particularly among Internet people who have less knowledge about how to use conventional search sites effectively 1 .Users typically give tags to explain the contents they discover attractive so that others would easily discover them later 2 . In recent seasons there has been growing interest in building new strategies to take advantage of social tagging technologies 3 , notably recommender methods 4 , personalized search 5 , question telling 6 , text classification 7 , occasion discovery 8 , and so forth .However , despite these attempts , work into using community tagging data for efficient resource search appears relatively unexplored 9 .",
        "ori-fast-z-score": -2.1213203435596424,
        "water-fast-z-score": 7.950706915615445
    },
    {
        "original_text": "We report on results obtained by INTEGRAL observations during the 2005 outburst of the black hole candidate GRO J1655â€“40 (Nova Muscae 1991). The source was observed in the 20-100 keV range for about 100 days, starting at MJD 53000 and ending at MJD 53300. We have analyzed these data using both ISGRI and SPI instruments aboard INTEGRAL satellite. In addition to the main spectral component which is well described by a power law model modified by an exponential cutoff, we find that there are two additional components present in the spectrum. One of them has been previously reported by other authors but its origin remains unclear. Another one appears only when fitting the whole dataset simultaneously with all three models considered here -power law plus exponential cut-off, broken power law or Comptonization model-. This new feature can be interpreted either as a reflection hump produced by cold material surrounding the central X-ray source or as a broad iron line around 6.4 keV.",
        "watermark_text": "We report on findings obtained by INTEGRAL observations during the 2005 outburst of the dark hole member GRO J1655â€ “ 40 ( Nova Muscae 1991 ) . The source was seen in the 20 - 100 keV range for about 100 months , beginning at MJD 53000 and ending at MJD 53300 .We have analyzed these information using both ISGRI and SPI instruments aboard INTEGRAL satellite . In addition to the main spectral component which is well described by a power law description altered by an exponential cutoff , we find that there are two additional components available in the spectrum .One of them has been previously reported by other researchers but its identity remains unsure . Another one appears only when fitting the whole dataset jointly with all three models described here - energy law plus exponential cutting - off , broken power law or Comptonization model - .This new feature can be interpreted either as a absorption hump produced by cold matter surrounding the main X - ray source or as a broad iron line around 6 . 4 keV .",
        "ori-fast-z-score": 1.212678125181665,
        "water-fast-z-score": 6.305926250944657
    },
    {
        "original_text": "The design and kinematics analysis of parallel kinematic machine tools (PKMTs) is presented in this work using kinetic-static performance criteria. The proposed approach considers the dynamic behavior of PKMTs during their operation, which has been neglected by previous works on PKMTs. In addition to the static stiffness matrix, the inertia properties are also considered for the evaluation of the overall dynamic response of PKMTs. A new method based on the concept of virtual joints is developed to calculate the mass distribution along each leg of the PKMT under consideration. This information can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis. Finally, two different PKMTs with three degrees-of-freedom per joint are designed and analyzed using the proposed methodology. It was found that the first PKMT exhibits better dynamic characteristics than its counterpart due to its lower natural frequencies and higher damping ratios.",
        "watermark_text": "The design and kinematics analysis of parallel kinematic machine tools ( PKMTs ) is detailed in this work using kinetic - static performance criteria . The proposed approach considers the dynamic behavior of PKMTs during their operation , which has been neglected by previous works on PKMTs .In addition to the static stiffness matrix , the inertia characteristics are also considered for the evaluation of the overall dynamic response of PKMTs . A modern algorithm based on the idea of virtual joints is developed to estimate the mass distribution along each leg of the PKMT under consideration .This knowledge can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis . Finally , two different PKMTs with three degrees - of - independence per joint are built and evaluated using the suggested methodology .It was shown that the first PKMT displays better dynamic characteristics than its predecessor due to its lower natural bandwidth and larger damping ratios .",
        "ori-fast-z-score": 1.6059101370939322,
        "water-fast-z-score": 5.27656187902292
    },
    {
        "original_text": "We introduce the notion of intersection bodies in arbitrary dimensions, generalizing the classical concept for dimension two to higher dimensions. We show that intersection bodies are characterized by their Fourier transforms which we call generalized cosine transforms (GCT). The GCTs can be used as an alternative tool to study intersection bodies. In particular, we prove that intersection bodies have positive volume if and only if they are convex. This is done using a new characterization of intersection bodies via their support functions. Finally, we give some examples of intersection bodies in three dimensions. Keywords: Intersection body; Support function; Convexity; Volume; Fourier transform; Three-dimensional space. 1 Introduction Let K n denote the set of all origin-symmetric convex bodies in R n . For any K ∈ K n , let V(K) = |K|/|B n 2 | where | · | denotes Lebesgue measure on R n . Then V : K n →  0, 1  is called the volume functional. A compactly supported continuous function f : S n−1 → C with unit integral will be called a spherical harmonic of degree m. If f has no zeros then it is uniquely determined up to multiplication by a constant. It follows immediately that every spherical harmonic of degree m satisfies the following properties:\n(1) |f (x)| ≤ 1; (2) f (−x) = f (x), x ∈ S n−1 ; (3) (Spherical harmonics form an orthonormal basis.) Definition 1. An origin-symmetric convex body K ∈ K n is said to be an intersection body if there exists a non-negative real number λ such that its surface area measure σ K satisfies",
        "watermark_text": "We introduce the notion of junction bodies in arbitrary dimensions , generalizing the classical concept for dimension two to higher dimensions . We see that intersection bodies are characterized by their Fourier functions which we call generalized cosine transforms ( GCT ) .The GCTs can be used as an additional tool to study junction bodies . In particular , we prove that intersection bodies have positive volume if and only if they are convex .This is accomplished using a new definition of junction bodies via their support functions . Finally , we give some examples of intersection bodies in three dimensions .Keywords : Intersection body ; Support function ; Convexity ; Volume ; Fourier integral ; Three - dimensional space . 1 Introduction Let K n denote the group of all origin - symmetric convex body in R n .For any K ∈ K n , let V ( K ) = | K | / | B n 2 | where | · | indicates Lebesgue measure on R n . Then V : K n → 0 , 1 is called the volume functional .A compactly backed continuous function f : S n−1 → C with unit integral will be called a spherical harmonic of degree m . If g has no zeros then it is uniquely determined up to multiplication by a constant . It follows instantly that every spherical harmonic of degree m satisfies the following properties : ( 1 ) | h ( x ) | ≤ 1 ; ( 2 ) f ( −x ) = g ( x ) , x ∈ S n−1 ; ( 3 ) ( Spherical harmonics form an orthonormal basis . )Definition 1 . An origin - symmetric convex body K ∈ K n is said to be an intersection body if there exists a non - negative real number λ such that its surface area measure σ K satisfies",
        "ori-fast-z-score": 0.19069251784911848,
        "water-fast-z-score": 3.8138503569823694
    },
    {
        "original_text": "We report the first ultrafast electron nanocrystallographic study on size-selected gold nanoparticles (AuNPs). The AuNPs were prepared in solution and deposited onto carbon-coated copper grids for transmission electron microscopy studies. Time-resolved pump-probe experiments with femtosecond resolution were performed at beamline U41-PGM, MAX IV Laboratory, Sweden. We observed that the lattice expansion is anisotropic along different crystallographic directions within individual particles. This observation can be explained by considering the effect of surface stress induced during particle growth. In addition to this, we found that the lattice expansion depends strongly on the nanoparticle sizes. These results are important for understanding how the properties of nanoparticles evolve as their dimensions decrease towards atomic scale. A new technique has been developed recently which allows one to probe structural dynamics of materials down to the atomic level using ultrashort X-ray pulses  1  . However, it remains challenging to perform time-resolved measurements on single crystals or nanoparticles due to difficulties associated with sample preparation  2  , data collection  3  , and analysis  4  .\nIn order to overcome these challenges, researchers have started exploring alternative techniques such as ultrafast electron nanocrystalography  5  -  8  . In this method, an intense femtosecond laser pulse is used to excite electrons into unoccupied states above Fermi energy E F . Subsequently, photoelectrons emitted from excited atoms travel through the crystal and scatter off neighboring atoms  9  . By measuring the angular distribution of scattered photoelectrons, information about the structure of the material under investigation can be obtained  10  . Since the scattering cross section increases rapidly when photoelectrons approach the Brillouin zone boundary  11  , the photoelectron diffraction pattern contains more Bragg peaks than conventional powder patterns  12  . Therefore, the photoelectron diffraction pattern provides higher spatial resolution compared to traditional powder methods  13  .",
        "watermark_text": "We report the first ultrafast electron nanocrystallographic study on size - selected gold nanoparticles ( AuNPs ) . The AuNPs were prepared in solution and deposited onto carbon - etched copper grids for propagation electron microscopy studies .Time - resolved pump - probe studies with femtosecond sensitivity were performed at beamline U41 - PGM , MAX IV Laboratory , Sweden . We observed that the crystal growth is anisotropic along various crystallographic paths within various particles .This assumption can be described by examining the impact of exterior stress resulting during particle growth . In addition to this , we learned that the crystal growth depends strongly on the nanoparticle sizes .These data are important for studying how the properties of nanoparticles develop as their height shift towards atomic scale . A different method has been constructed recently which allows one to probe mechanical mechanics of substances down to the atomic level using ultrashort X - ray pulses 1 .However , it remains challenging to conduct time - resolved calculations on single crystals or nanoparticles due to difficulties related with data preparation 2 , data analysis 3 , and identification 4 . In try to overcome these problems , researchers have started pursuing alternative techniques such as ultrafast electron nanocrystalography 5 - 8 .In this technology , an aggressive femtosecond laser wave is utilized to excite electrons into unoccupied states above Fermi energy E F . Subsequently , photoelectrons sent from excited atoms journey through the crystal and scatter off nearby electrons 9 .By measuring the angular distribution of distributed photoelectrons , info about the composition of the material under investigation can be obtained 10 . Since the scattering cross area grows swiftly when photoelectrons encounter the Brillouin zone boundary 11 , the photoelectron diffraction scheme contains more Bragg peaks than conventional powder schemes 12 .Therefore , the photoelectron diffraction type gives higher spatial resolution compared to conventional powder technique 13 .",
        "ori-fast-z-score": -1.9369494184529936,
        "water-fast-z-score": 7.944299095067362
    },
    {
        "original_text": "We present an overview of our recent work on vector meson production in heavy ion collisions at RHIC and LHC energies, based on holographic QCD models with chiral symmetry breaking (AdS/QCD). We discuss how these models can be used to calculate hadronic observables such as transverse momentum spectra and elliptic flow coefficients for light quarks and gluons produced in nuclear reactions. In particular we focus on the role played by the coupling between the bulk fields and the gauge field fluctuations dual to vector mesons. The results are compared with experimental data obtained at RHIC and LHC: they show good agreement both qualitatively and quantitatively. \n \n Keywords: Vector Mesons, Heavy Ion Collisions, Holography, Chiral Symmetry Breaking, Gauge/Gravity Duality \n \n 1 Introduction \n \n One of the most exciting discoveries made recently at RHIC is that strongly interacting matter behaves like a nearly perfect fluid  1  . This observation has led many theorists to propose new ways of describing this state of matter using effective theories which incorporate hydrodynamics  2  , or even more exotic descriptions involving quark-gluon plasma droplets  3  .\n \nIn order to understand better what happens during the early stages of heavy-ion collisions it would be very useful if one could study experimentally the properties of the hot dense medium created in those collisions. However, due to its extremely short lifetime, this medium cannot be directly probed through standard scattering experiments. Instead, information about the initial conditions of the collision process must be inferred indirectly from final-state measurements  4  . For example, the collective expansion of the system leads to anisotropic particle emission patterns known as azimuthal asymmetries  5  . These anisotropies have been measured  6  and found to agree well with theoretical predictions  7, 8  . \n \n Another important observable characterizing the dynamics of the expanding fireball is the spectrum of emitted particles  9  . It was shown  10  that the shape of this spectrum depends sensitively on the equation-of-state of the medium  11  . Moreover, the observed suppression  12  of high-pT hadrons",
        "watermark_text": "We present an overview of our latest work on vector meson production in heavy atom collisions at RHIC and LHC energies , using on holographic QCD models with chiral symmetry breaking ( AdS / QCD ) . We discuss how these models can be used to estimate hadronic observables such as transverse acceleration spectra and elliptic flow coefficients for light quarks and gluons produced in nuclear compounds .In particular we focus on the part played by the interaction between the bulk fields and the gauge field fluctuations dual to vector mesons . The results are compared with experimental evidence derived at RHIC and LHC : they show good agreement both qualitatively and quantitatively .Keywords : Vector Mesons , Heavy Ion Collisions , Holography , Chiral Symmetry Breaking , Gauge / Gravity Duality 1 Introduction One of the most exciting advances making lately at RHIC is that strongly interacting material behaves like a nearly perfect fluid 1 . This prediction has led many theorists to propose innovative ways of describing this state of matter utilizing effective models which employ hydrodynamics 2 , or especially more exotic representations featuring quark - gluon liquid droplets 3 .In order to explain better what comes during the early stages of large - ion collisions it would be very useful if one might explore experimentally the properties of the hot dense medium produced in those collisions . However , owing to its incredibly small life , this medium unable be closely probed through conventional absorption studies .Instead , info about the first environments of the collision mechanism must be inferred indirectly from final - state measurements 4 . For instance , the collective expansion of the process results to anisotropic particle emission events known as azimuthal asymmetries 5 .These anisotropies have been measured 6 and found to agree well with theoretical estimates 7 , 8 . Another important observable characterizing the dynamics of the increasing fireball is the spectrum of emission particles 9 .It was shown 10 that the form of this spectrum relies sensitively on the equation - of - state of the medium 11 . Moreover , the seen suppression 12 of high - pT hadrons",
        "ori-fast-z-score": 0.8391813582966892,
        "water-fast-z-score": 8.391813582966892
    },
    {
        "original_text": "The recent debate on the future availability of fossil fuels has focused attention on the possible implications of peak oil (the maximum rate at which economically viable quantities can be extracted) for global warming, particularly in relation to the Kyoto Protocol s emissions targets.  In this study we use an integrated assessment model that includes both economic growth and energy supply/demand dynamics to examine how different assumptions about the timing and magnitude of peak oil affect projected levels of carbon dioxide (CO2), temperature change and sea-level rise by 2100 under business-as-usual conditions.   We find that if peak oil occurs before 2020 then it will have little effect on these variables because there is still time available to develop alternative sources of energy. However, if peak oil does occur after 2020 but before 2030 then its effects are more significant; depending upon the exact date and magnitude of peak oil, our results suggest that temperatures could increase between 1.5°C and 3.0°C above pre-industrial levels by 2100 with associated increases in sea level rise ranging up to 0.7 metres.",
        "watermark_text": "The recent debate on the future availability of fossil fuels has concentrated emphasis on the possible implications of peak oil ( the maximum speed at which financially feasible quantities can be extracted ) for global climate , particularly in relation to the Kyoto Protocol s emissions goals . In this study we utilize an unified assessment plan that contains both economic growth and energy demand / demand behavior to examine how various expectations about the timing and magnitude of peak oil impact potential levels of carbon dioxide ( CO2 ) , temperature drop and sea - temperature rise by 2100 under commercial - as - normal environments .We see that if peak oil happens before 2020 then it will have less effect on these parameters because there is already time possible to develop new sources of energy . However , if peak oil does occur after 2020 but before 2030 then its consequences are more considerable ; depending upon the exact period and magnitude of peak oil , our findings show that temperatures may increase between 1 . 5°C and 3 . 0°C above pre - industrial levels by 2100 with corresponding increases in sea level drop ranging up to 0 . 7 metres .",
        "ori-fast-z-score": 0.10153461651336192,
        "water-fast-z-score": 7.552593373581466
    },
    {
        "original_text": "We present new results on the evolution of the dust content in Lyman break galaxies (LBGs) using deep near-infrared data obtained by the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III program. We use these observations to study the rest-frame UV-optical properties of LBGs at redshifts 1<z<3.5. The main goal of this work was to investigate how the dust extinction evolves as a function of galaxy mass and star formation rate density over cosmic time. Our analysis shows that there are two different populations of LBGs: one population has low stellar masses (M*=10^10-10^11 Msun), high specific star formation rates (SSFR>100Gyr-1), and relatively small amounts of dust; while another population consists of more massive systems (M*>10^11Msun), lower SSFR values (SSFR<30Gyr-1), and higher levels of dust extinction. These findings suggest that the amount of dust increases with increasing galaxy mass for both local and distant galaxies.",
        "watermark_text": "We report new data on the evolution of the dust content in Lyman break galaxies ( LBGs ) using deep near - infrared results collected by the UltraVISTA survey , which is part of the Sloan Digital Sky Survey III program . We use these observations to study the rest - frame UV - optical properties of LBGs at redshifts 1 < z < 3 . 5 .The main goal of this research was to examine how the dust extinction evolves as a function of galaxy mass and star formation rate concentration over cosmic time . Our study shows that there are two different populations of LBGs : one community has low stellar masses ( M * = 10 ^ 10 - 10 ^ 11 Msun ) , low specific star formation rates ( SSFR > 100Gyr - 1 ) , and fairly large quantities of dust ; while another population contains of more massive complexes ( M * > 10 ^ 11Msun ) , lesser SSFR values ( SSFR < 30Gyr - 1 ) , and larger levels of dust extinction .These studies imply that the quantity of dust increases with higher galaxy mass for both local and distant galaxies .",
        "ori-fast-z-score": 1.1470786693528088,
        "water-fast-z-score": 5.735393346764043
    },
    {
        "original_text": "We have observed the infrared colors (J-H, H-K) for 16 Mira variables with high resolution spectroscopy in order to investigate their relation to intensity ratios of SiO maser lines at 43 GHz. The results show that there is no correlation between these two parameters except for one star. We suggest that this may be due to different physical conditions among individual stars or differences in mass loss rates.  Keywords: Mira variable, Correlation, Infrared color, SiO maser line, Mass loss rate. 1 Introduction Miras are red giant stars which pulsate radially on time scales ranging from 100 days up to several thousand years. They exhibit large amplitude variations in luminosity as well as radial velocity. Their light curves can be described by a simple sinusoidal function with periods longer than about 300 days  1  . These stars are known to produce strong winds  2  , and they also emit intense radio waves  3  .\nThe SiO molecule has been found to exist in many types of astronomical objects such as late-type stars  4  , evolved massive stars  5  , young stellar objects  6  , comets  7  , and planets  8  . It is believed that SiO molecules play an important role in the formation process of dust grains  9  . SiO masers were first detected toward AGB stars  10  . Since then, SiO masers have been studied extensively towards both AGB stars  11  -  13  and post-AGB stars  14  -  16  . Many studies have shown that the properties of SiO masers depend strongly on the evolutionary stage  17  -  20  . For example, it was reported that the peak flux density decreases rapidly during the transition phase from AGB to post-AGB  21  .",
        "watermark_text": "We have noted the infrared colors ( J - H , H - K ) for 16 Mira variables with high resolution spectroscopy in trying to examine their connection to intensity ratios of SiO maser lines at 43 GHz . The results show that there is no correspondence between these two parameters except for one star .We suggest that this might be due to different physical conditions among individual stars or variations in mass loss pressures . Keywords : Mira variable , Correlation , Infrared color , SiO maser line , Mass loss rate .1 Introduction Miras are red giant stars which pulsate radially on time ranges ranging from 100 hours up to several thousand years . They display large intensity variations in luminosity as well as radial speed .Their light curves can be described by a simple sinusoidal function with periods longer than about 300 days 1 . These galaxies are known to produce violent winds 2 , and they even emit intense radio pulses 3 .The SiO molecule has been shown to exist in multiple types of astronomical bodies such as early - class stars 4 , evolved large planets 5 , early stellar bodies 6 , comets 7 , and planets 8 . It is suspected that SiO compounds play an important role in the formation reaction of dust grains 9 .SiO masers were first detected toward AGB stars 10 . Since then , SiO masers have been studied frequently towards both AGB stars 11 - 13 and post - AGB stars 14 - 16 .Many experiments have shown that the properties of SiO masers depend greatly on the evolutionary stage 17 - 20 . For instance , it was reported that the maximum flux concentration drops rapidly during the shift stage from AGB to post - AGB 21 .",
        "ori-fast-z-score": -0.552344770738994,
        "water-fast-z-score": 7.058578427117228
    },
    {
        "original_text": "We present an analysis of Hawking radiation in terms of Bogoliubov coefficients, which are calculated using WKB wavefunctions for scalar fields on Schwarzschild backgrounds. We show that these results agree with those obtained by other methods when the backreaction is neglected and we also find agreement between our method and previous calculations including backreaction effects at leading order in perturbation theory. In addition to this perturbative check, we perform numerical checks of our results against exact solutions of the Klein-Gordon equation in Schwarzschild spacetime. Finally, we discuss how our approach can be used to calculate corrections beyond the semiclassical approximation. The evaporation of black holes has been studied extensively over many years (see e.g. ), but there remain some open questions about its detailed behaviour. One such question concerns the precise form of the spectrum of emitted particles; it was shown recently  that the standard semi-classical treatment leads to a thermal distribution of particle energies, but it remains unclear whether or not this result holds true once quantum gravity effects become important.",
        "watermark_text": "We present an assessment of Hawking radiation in terms of Bogoliubov coefficients , which are measured using WKB wavefunctions for scalar fields on Schwarzschild backgrounds . We see that these results agree with those achieved by other methods when the backreaction is neglected and we also find agreement between our technique and previous analyses using backreaction effects at leading order in perturbation theory .In addition to this perturbative search , we perform numerical checks of our findings against exact solutions of the Klein - Gordon equation in Schwarzschild spacetime . Finally , we explain how our approach can be used to estimate corrections beyond the semiclassical approximation .The evaporation of black holes has been studied thoroughly over numerous years ( see e . g . ) , but there remain some open questions about its precise behaviour .One such issue concerns the exact form of the spectrum of emitted particles ; it was shown lately that the standard semi - classical treatment leads to a heat distribution of particle intensity , but it remains unsure whether or not this consequence holds true once quantum gravitational changes become crucial .",
        "ori-fast-z-score": 1.3251783128981585,
        "water-fast-z-score": 6.555555555555555
    },
    {
        "original_text": "We present an explicit, physically sound formulation for the dynamical Casimir effect (DCE) in terms of a time-dependent Schrödinger equation with a non-Hermitian effective potential that is derived directly from first principles and has no free parameters.  The resulting expression agrees exactly with previous results obtained by other authors using different methods but it also provides new insights into this fascinating quantum phenomenon. In particular we show how to calculate the energy spectrum of the system as well as its decay rates and lifetimes. We demonstrate our approach on two examples - one involving a single harmonic oscillator coupled to a thermal bath at finite temperature and another where the oscillators are replaced by fermions. Finally, we discuss possible extensions of these ideas beyond the standard model of particle physics. The dynamical Casimir effect (DCE), predicted more than twenty years ago  1-3 , refers to the generation of photons due to vacuum fluctuations when macroscopic objects move or change shape  4  . This intriguing prediction was confirmed experimentally only recently  5-7  , although there have been earlier suggestions  8  .\nThe original theoretical description of the DCE relied heavily on phenomenological models which were not always easy to interpret physically  9  . More recent attempts  10-12  used microscopic approaches based on non-relativistic QED  13-15  or relativistic field theory  16  . However, all such treatments involve some ad-hoc assumptions about the form of the interaction between the moving object(s) and the electromagnetic fields  17  . Here we propose a completely different method that avoids any such approximations and leads to a simple, transparent physical picture of the process. Our starting point is the exact Heisenberg-Langevin equations describing the dynamics of the electric field operatorsÊ(r, t). These can be written in the compact form:",
        "watermark_text": "We present an explicit , physically sound formulation for the dynamical Casimir effect ( DCE ) in terms of a time - dependent Schrödinger equation with a non - Hermitian effective potential that is developed directly from initial principles and has no free parameters . The resulting expression agrees exactly with previous findings obtained by other researchers using separate methods but it also provides new information into this fascinating quantum concept .In particular we prove how to estimate the power spectrum of the system as well as its degradation times and lifetimes . We test our approach on two examples - one utilizing a single harmonic oscillator coupled to a heat shower at finite temperature and another where the oscillators are replaced by fermions .Finally , we investigate possible extensions of these ideas beyond the standard theory of particle theory . The dynamical Casimir effect ( DCE ) , predicted more than twenty years previously 1 - 3 , relates to the generation of photons due to vacuum fluctuations when macroscopic objects moving or change form 4 .This unusual prediction was confirmed experimentally only recently 5 - 7 , although there have been earlier suggestions 8 . The original theoretical formulation of the DCE depended heavily on phenomenological models which were not always easier to predict physically 9 .More current approaches 10 - 12 used microscopic techniques based on non - relativistic QED 13 - 15 or relativistic field principle 16 . However , all such treatments include some ad - hoc assumptions about the form of the interaction between the moved object ( s ) and the electromagnetic forces 17 .Here we attempt a completely different method that avoids any such approximations and leads to a simple , straightforward mechanical picture of the process . Our starting point is the exact Heisenberg - Langevin coefficients governing the dynamics of the electric field [UNK] ( r , t ) .These can be written in the compact form :",
        "ori-fast-z-score": 0.43033148291193524,
        "water-fast-z-score": 7.150554858373488
    },
    {
        "original_text": "We present an absolute calibration of MIPS photometry at 24, 70, and 160 microns using stellar calibrators observed by the Infrared Array Camera (IRAC) onboard the Spitzer Space Telescope. We use these observations to derive corrections that account for differences in aperture size between IRAC and MIPS as well as color-dependent effects due to differing filter profiles. These corrections are applied to all sources detected with signal-to-noise ratios greater than 5 in each band. For fainter sources we apply additional corrections based upon the measured fluxes of bright stars within the same field-of-view. This method is used to calibrate over 1 million objects across the sky. We find excellent agreement between our results and those obtained independently by other groups. Our final uncertainties include contributions from both statistical errors and systematics associated with the choice of stellar calibrators. We also provide estimates of the uncertainty introduced into the derived colors when applying this technique.",
        "watermark_text": "We present an absolute calibration of MIPS photometry at 24 , 70 , and 160 microns using stellar calibrators observed by the Infrared Array Camera ( IRAC ) onboard the Spitzer Space Telescope . We use these observations to derive corrections that explain for variations in aperture size between IRAC and MIPS as well as color - based effects due to distinct filter profiles .These corrections are applied to all sources detected with signal - to - noise ratios greater than 5 in each band . For fainter sources we apply additional corrections based upon the determined fluxes of bright stars within the same field - of - view .This method is utilized to calibrate over 1 million items across the sky . We see better agreement between our findings and those achieved independently by other organizations .Our last uncertainties include contributions from both statistical mistakes and systematics associated with the selection of stars calibrators . We additionally offer estimates of the uncertainty introduced into the derived colors when applying this methodology .",
        "ori-fast-z-score": 1.3643820804812932,
        "water-fast-z-score": 6.077701994871215
    },
    {
        "original_text": "We present an analysis of gravitational lensing by large-scale structure in the universe, as traced by neutral hydrogen (HI) at high redshifts z > 6. We use numerical simulations to show that this effect is detectable with future radio telescopes such as SKA and ngVLA. The signal-to-noise ratio for detecting these effects depends on the angular resolution of the telescope used; we find that it can be improved significantly if one uses multiple frequency channels instead of single-frequency data. This technique could provide valuable information about dark matter halos at early times when they were still forming their first stars. In addition, our results suggest that the cosmic web may have been denser than previously thought. Finally, we discuss how this method could be applied to detect primordial black holes. Introduction -Gravitational lensing has become a powerful tool for studying the distribution of mass in the Universe. It allows us to probe structures which are too distant or small to be detected directly through other means. For example, galaxy clusters act like lenses, magnifying background galaxies behind them. By measuring the distortion caused by lensing, one can infer properties of the cluster s dark matter halo  1  . Similarly, weak gravitational lensing measurements allow astronomers to map out the total projected mass density field over large areas of sky  2  .\nIn recent years there has been growing interest in applying gravitational lensing techniques to study high-redshift objects  3  , including the epoch of reionization  4  . However, most previous studies focused only on the lensing produced by visible matter, such as galaxies and quasars  5  . Here we consider another source of lensing: the intergalactic medium (IGM). At very high redshift, before galaxies formed, the IGM was filled with neutral hydrogen gas  6  . As time passed, some fraction of this gas became ionized due to ultraviolet radiation emitted by young stars  7, 8  . But even today, much of the IGM remains neutral  9  . Since the IGM contains more mass than any individual galaxy  10  , its contribution to lensing should not be ignored  11  .\nThe goal of this",
        "watermark_text": "We present an assessment of gravitational lensing by large - scale structure in the universe , as traced by neutral hydrogen ( HI ) at high redshifts z > 6 . We use numerical simulations to see that this effect is detectable with potential radio telescopes such as SKA and ngVLA .The signal - to - noise proportion for detecting these influences depends on the angular resolution of the telescope used ; we find that it can be improved substantially if one uses multiple wavelength channels instead of multiple - frequency information . This method could give valuable info about black material halos at young times when they were still forming their early stars .In addition , our findings show that the cosmic web possibly have been denser than previously thought . Finally , we talk how this technology could be applied to identify primordial black holes .Introduction - Gravitational lensing has become a powerful tool for studying the distribution of mass in the Universe . It enables us to probe formations which are too distant or small to be identified directly through other methods .For instance , galaxy galaxies act like filters , magnifying background galaxies behind them . By measuring the degradation created by lensing , one can infer characteristics of the cluster s dark matter halo 1 .Similarly , poor gravitational lensing observations allow astronomers to map out the total estimated mass density field over large areas of skies 2 . In recent years there has been growing interest in utilizing gravitational lensing methods to study high - redshift images 3 , notably the epoch of reionization 4 .However , most prior studies focused only on the lensing produced by seen material , such as planets and quasars 5 . Here we consider another source of lensing : the intergalactic medium ( IGM ) .At very high redshift , before stars formed , the IGM was filled with neutral hydrogen liquid 6 . As time passed , some fraction of this gas became ionized owing to ultraviolet radiation emitted by young galaxies 7 , 8 .But even today , part of the IGM remains neutral 9 . Since the IGM contains more mass than any individual galaxy 10 , its contribution to lensing should not be excluded 11 .The goal of this",
        "ori-fast-z-score": 0.636445827340584,
        "water-fast-z-score": 8.854377448471462
    },
    {
        "original_text": "We propose to use photonic molecules, which are composed of two or more coupled microcavities with different resonant wavelengths, as building blocks for novel types of lasers and optoelectronics devices. We show that the coupling between these cavities can lead to several interesting phenomena such as: (i) formation of hybridized modes, (ii) appearance of sharp peaks in emission spectrum at frequencies corresponding to avoided crossings of cavity eigenmodes, (iii) enhancement of spontaneous emission rate due to Purcell effect, and (iv) strong modification of optical gain properties by means of mode competition effects. These features open up possibilities for designing new types of laser sources based on photonic molecules, including single-mode lasers operating at room temperature without any external feedback elements. \n \n The proposed approach is illustrated using examples of photonic molecules consisting of pairs of semiconductor microdisks with slightly different diameters. It is shown that the considered structures allow one to obtain high quality factor whispering gallery modes with Q-factors exceeding 10^6.",
        "watermark_text": "We suggest to use photonic compounds , which are composed of two or more coupled microcavities with varying resonant wavelengths , as building blocks for novel varieties of lasers and optoelectronics equipment . We suggest that the interaction between these cavities can lead to several interesting phenomena such as : ( i ) creating of hybridized modes , ( ii ) creation of sharp peaks in emission spectrum at speeds related to avoided crossings of cavity eigenmodes , ( iii ) enhancement of spontaneous emission speed due to Purcell phenomenon , and ( iv ) weak relaxation of optical loss properties by means of mode rivalry interactions .These features offer up possibilities for constructing new types of laser sources focused on photonic compounds , particularly single - mode lasers active at room temperature without any external feedback components . The proposed approach is depicted using examples of photonic atoms consisting of pairs of semiconductor microdisks with slightly different diameters .It is demonstrated that the considered spaces allow one to obtain high quality factor whispering gallery modes with Q - parameters exceeding 10 ^ 6 .",
        "ori-fast-z-score": 0.8626621856275073,
        "water-fast-z-score": 6.685631938613182
    },
    {
        "original_text": "We study the ground state properties and excitations of the infinite-dimensional Hubbard model with nearest-neighbor hopping on an hypercubic lattice at half-filling by means of the functional renormalization group (FRG). We find that, for large enough interaction strength U , there is a phase transition to a Mott insulator where charge fluctuations are suppressed but spin fluctuations remain finite. The critical value Uc depends strongly on the magnetic field h. For small fields we obtain Uc = 0.5t while for larger fields Uc decreases rapidly as h increases. In addition, we show how the FRG can be used to calculate the single-particle spectral function A(k, ω) which exhibits a gapless dispersion relation near kF . Finally, we discuss possible extensions of our work. Introduction:-The physics of correlated electrons has been studied extensively over many years  1  -  4  . One of the most important models describing this type of behavior is the Hubbard model  5  . It describes interacting fermions moving on a lattice and it was originally introduced to describe the metal-insulator transition observed in doped semiconductors  6  .\nIn recent years much effort has gone into studying the Hubbard model using various numerical techniques such as exact diagonalizations  7  , quantum Monte Carlo  8  or density matrix renormalization groups  9  . However these methods have severe limitations when applied to systems with strong correlations and/or low dimensions  10  . Therefore new analytical approaches are needed to understand the rich physical phenomena associated with the Hubbard model  11  -  13  .\nOne promising approach is based on the functional renormalization-group (FRG), which allows one to treat interactions exactly within a controlled approximation scheme  14  -  16  . This method has recently been successfully applied to several problems including the two-dimensional  17  and three-dimensional  18  Hubbard model. Here we will use the FRG to investigate the ground-state properties and elementary excitations of the infinite-dimensionally extended Hubbard model  19  .",
        "watermark_text": "We research the ground state properties and excitations of the infinite - dimensional Hubbard theory with nearest - neighbor hopping on an hypercubic structure at half - filling by means of the functional renormalization group ( FRG ) . We see that , for large enough interaction strength U , there is a phase shift to a Mott insulator where charge fluctuations are suppressed but momentum fluctuations remain finite .The essential value Uc relies highly on the magnetic force h . For small fields we obtain Uc = 0 . 5t while for larger quantities Uc falls gradually as h rises . In addition , we find how the FRG can be used to estimate the single - nucleus spectral relation A ( h , ω ) which exhibits a gapless dispersion connection near kF .Finally , we explain possible extensions of our work . Introduction : - The physics of coupled electrons has been studied frequently over numerous years 1 - 4 .One of the most important models explaining this kinds of dynamics is the Hubbard theory 5 . It involves interacting fermions moving on a lattice and it was originally created to explain the metal - insulator transition seen in doped semiconductors 6 .In recent years much effort has put into studying the Hubbard theory employing several mathematical techniques such as approximate diagonalizations 7 , quantum Monte Carlo 8 or density function renormalization groups 9 . However these algorithms have severe constraints when applied to systems with high correlations and / or low dimensions 10 .Therefore new analytical approaches are needed to realize the rich physical phenomena associated with the Hubbard theory 11 - 13 . One promising solution is based on the functional renormalization - group ( FRG ) , which allows one to treat relationships exactly within a controlled approximation scheme 14 - 16 .This method has recently been successfully applied to several difficulties notably the two - dimensional 17 and three - dimensional 18 Hubbard theory . Here we will use the FRG to examine the ground - state properties and elementary excitations of the infinite - dimensionally extended Hubbard theory 19 .",
        "ori-fast-z-score": 0.8219949365267865,
        "water-fast-z-score": 8.870294200605638
    },
    {
        "original_text": "We study the existence and stability properties of non-topological solitons in scalar field theories with kinetic self coupling, which are relevant to models for dark matter particles interacting via self-interactions mediated by light bosons.  We show that stable soliton solutions exist only if the mass of the boson is larger than twice the mass of the dark matter particle. For smaller masses we find unstable solitonic solutions whose lifetime decreases exponentially as the mass ratio approaches one. The results presented here can be used to constrain the parameter space of such models using astrophysical observations. Introduction:-The possibility of new physics beyond the Standard Model (SM) has been widely discussed recently  1  . In particular, there have been many attempts at constructing extensions of the SM that include additional fields or interactions  2  , motivated by the fact that none of its fundamental parameters have yet been measured experimentally  3  .\nIn this work we consider an extension of the SM where the Higgs sector consists of two complex scalars  4  . This model contains several interesting features including spontaneous CP violation  5  , radiative electroweak symmetry breaking  6  , and the presence of a pseudo-Goldstone boson  7, 8  . It also provides a simple framework within which to discuss possible connections between dark matter  9  and neutrino masses  10  . Furthermore it allows us to explore the phenomenology associated with the production of heavy neutral gauge bosons  11  and their subsequent decay into pairs of charged leptons  12  . Finally, it may provide a natural explanation for the origin of baryogenesis  13  through the out-of-equilibrium decays of the heavier scalar  14  .\nOne feature of these models is the presence of a second scalar particle, denoted by H 0 , which mixes with the SM-like Higgs h 0  15  . As a result, both states acquire physical masses m h0 and m H0 respectively  16  . If the mixing angle θH is small then mH ≫ mh  17  . However, even when mH = mh, the couplings of the two scalars differ significantly due to the different quantum numbers carried by each state  18  .",
        "watermark_text": "We research the existence and stability properties of non - topological solitons in scalar field theories with kinetic self coupling , which are applicable to descriptions for black matter molecules interacting via self - interactions mediated by light bosons . We see that strong soliton solutions arise only if the mass of the boson is bigger than times the mass of the dark matter object .For lower masses we find unstable solitonic solutions whose lifetime decreases exponentially as the mass ratio approaches one . The results presented here can be used to constrain the parameter space of such theories using astrophysical observations .Introduction : - The possibility of new science beyond the Standard Model ( SM ) has been widely discussed recently 1 . In particular , there have been many efforts at creating extensions of the SM that include extra fields or particles 2 , driven by the fact that none of its essential parameters have ever been measured experimentally 3 .In this research we imagine an extension of the SM where the Higgs sector consists of two complex scalars 4 . This theory incorporates numerous interesting features including spontaneous CP violation 5 , radiative electroweak symmetry breaking 6 , and the presence of a quasi - Goldstone boson 7 , 8 .It additionally offers a simple context within which to consider likely link between dark matter 9 and neutrino masses 10 . Furthermore it allows us to examine the phenomenology linked with the production of large neutral gauge bosons 11 and their resulting degradation into sets of charged leptons 12 .Finally , it could give a natural explanation for the origin of baryogenesis 13 through the out - of - equilibrium decays of the heavier scalar 14 . One feature of these models is the presence of a second scalar object , denoted by H 0 , which mixes with the SM - like Higgs h 0 15 .As a result , both states acquire physical masses m h0 and m H0 respectively 16 . If the mixing angle θH is small then mH [UNK] mh 17 .However , even when mH = mh , the couplings of the two scalars differ significantly due to the different quantum values carried by each state 18 .",
        "ori-fast-z-score": -1.1748539016153647,
        "water-fast-z-score": 5.564047150200578
    },
    {
        "original_text": "In this work, we consider a multiple-input-multiple-output (MIMO) system where each transmitter has limited feedback information about its channel state to the receiver. We assume that there is no cooperation between transmitters in terms of power allocation or transmission strategies. Each transmitter can only adjust its own transmit power level based on local CSI knowledge at the transmitter side. In addition, each transmitter may turn off its radio completely when it does not have any data to send. The objective is to maximize the sum rate by optimizing both the power control policy as well as the transmission strategy for all users simultaneously under these constraints. \n \n First, we derive an upper bound on the achievable sum-rate using finite-rate feedback assuming Gaussian codebooks. Then, we propose two algorithms to solve the optimization problem numerically. Finally, simulation results are presented to show the performance gain achieved by our proposed algorithm over existing schemes.",
        "watermark_text": "In this research , we study a multiple - input - multiple - output ( MIMO ) scheme where each antenna has restricted feedback info about its channel state to the receiver . We assume that there is no cooperation between transmitters in terms of power distribution or transmission strategies .Each antenna can only alter its own transmit energy level based on local CSI information at the transmitter side . In addition , each antenna could switch off its broadcast completely when it does not have any info to carry .The goal is to maximize the sum frequency by optimizing both the power control strategy as well as the transmission strategy for all users simultaneously under these requirements . First , we derive an upper bound on the achievable sum - speed using finite - frequency feedback assuming Gaussian codebooks .Then , we propose two strategies to solve the algorithms issue numerically . Finally , simulation data are presented to see the performance gain achieved by our proposed algorithm over existing strategies .",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 6.114295984380816
    },
    {
        "original_text": "We present new near-infrared photometric data for the Pleiades open cluster obtained with the Infrared Survey Facility (IRSF) on the South African Astronomical Observatory s 1-m telescope at Sutherland in November 2005. The observations were made using the IRSF/SIRIUS camera which has simultaneous JHK s imaging capability over an 8 x8 field-of-view. We have also used archival 2MASS data to supplement our sample. Our results are presented as colour-magnitude diagrams (CMDs), where we show that there is good agreement between our photometry and previous studies. Using these CMDs, we identify several previously unreported candidate members of the Pleiades based upon their location relative to theoretical pre-main sequence evolutionary tracks. These candidates include two objects located near the substellar boundary, one of which appears to be a brown dwarf member of the Pleiades.",
        "watermark_text": "We current new near - infrared photometric data for the Pleiades open cluster received with the Infrared Survey Facility ( IRSF ) on the South African Astronomical Observatory s 1 - m observatory at Sutherland in November 2005 . The images were made using the IRSF / SIRIUS telescope which has simultaneous JHK s optical technology over an 8 x8 field - of - view .We have already applied archival 2MASS information to supplement our sample . Our results are presented as colour - magnitude diagrams ( CMDs ) , where we prove that there is good agreement between our photometry and previous research .Using these CMDs , we identify several already unreported candidate members of the Pleiades based upon their placement relative to theoretical pre - principal sequence evolutionary tracks . These proposals include two bodies located near the substellar boundary , one of which appears to be a brown dwarf part of the Pleiades .",
        "ori-fast-z-score": -1.3363062095621219,
        "water-fast-z-score": 3.841143835488627
    },
    {
        "original_text": "The purpose of this study is to investigate how privacy issues are perceived by users in Europe and what their attitude towards these issues is, when using online learning environments (OLE). The research questions are: \nWhat do students think about privacy?\nHow does student s perception change over time?\nWhich factors influence students  attitudes on privacy? How can we measure it? What are the implications for OLE developers? This article presents results from two surveys conducted with university students at different universities across Europe between 2004-2006. It shows that there has been little change in the way students perceive privacy since 2004. Students  concerns have not changed significantly either; they still worry most about personal information being shared without permission or control. However, some differences were found among countries. In addition, the findings show that gender plays a role as well as age. Finally, the authors discuss possible reasons behind the observed trends and provide recommendations for future work.",
        "watermark_text": "The purpose of this study is to examine how privacy issues are seen by users in Europe and what their attitude towards these problems is , when using internet learning habitats ( OLE ) . The survey problems are : What do students think about privacy ?How does student s perception shift over time ? Which variables influence pupils beliefs on privacy ?How can we measure it?What are the implications for OLE developers?This page presents scores from two polls conducted with university students at different schools across Europe between 2004 - 2006 . It demonstrates that there has been less shift in the way pupils understand privacy since 2004 .Students issues have not altered significantly either ; they still concern most about personal data being communicated without authorization or supervision . However , some differences were found among countries .In addition , the discoveries reveal that gender plays a role as well as aging . Finally , the articles discuss possible reasons behind the reported developments and include recommendations for future projects .",
        "ori-fast-z-score": -0.22360679774997896,
        "water-fast-z-score": 7.9881240965747695
    },
    {
        "original_text": "We present new Hubble Space Telescope (HST) Advanced Camera for Survey (ACS)\ncoronagraphic observations in visible light and near-infrared wavelengths that reveal an extended dusty disk surrounding the Herbig Ae star HD 100546, which is known to harbor a protoplanetary disk with spiral arms. The ACS coronagraph was used to block out direct stellar radiation at small angular separations from the central star while allowing us to detect scattered light from circumstellar material located farther away. We find evidence for two bright rings of emission separated by ~0.5′′ along the major axis of the disk. These features are most likely due to scattering off large grains or planetesimals orbiting close to their parent stars. \n \n In addition, we have detected several dark gaps within these bright rings as well as fainter structures extending outward into the outer regions of the disk. Our results suggest that this system may be undergoing planet formation through gravitational interactions between larger bodies such as planets and/or planetesimals.",
        "watermark_text": "We present new Hubble Space Telescope ( HST ) Advanced Camera for Survey ( ACS ) coronagraphic observations in bright light and near - infrared wavelengths that discover an extended dusty disk surrounding the Herbig Ae star HD 100546 , which is known to harbor a protoplanetary disk with spiral arms . The ACS coronagraph was used to block out direct stellar radiation at small angular separations from the main star while providing us to identify scattered radiation from circumstellar material located farther distant .We see evidence for two faint rings of emission separated by ~ 0 . 5 ′ ′ along the main axis of the disk . These features are most likely due to scattering off large grains or planetesimals orbiting close to their father stars .In addition , we have discovered numerous dark gaps within these dark rings as well as fainter objects extending outward into the inner regions of the disk . Our results propose that this system might be experiencing planet development through gravity interactions between big bodies such as planets and / or planetesimals .",
        "ori-fast-z-score": 0.4472135954999579,
        "water-fast-z-score": 5.590169943749474
    },
    {
        "original_text": "We investigate the effect of intrinsic galaxy alignment (IA) on dark energy parameter constraints using weak lensing tomography with future space-based surveys, such as Euclid and WFIRST. We find that IA introduces significant biases in cosmological parameters when only spectroscopic redshifts are available for calibration purposes. However, we show that these biases can be reduced by including photometric redshifts to calibrate the IA model. In particular, we demonstrate that it is possible to reduce the bias due to IA down to less than 1% level if at least 10 bands spanning 0.4-1 micron are used for photo-z estimation. This requirement becomes more stringent towards higher redshifts where the number density of galaxies decreases rapidly. The results presented here will help guide the design of future experiments aiming to measure dark energy through weak gravitational lensing. Introduction - Weak gravitational lensing has emerged as one of the most promising probes of dark energy  1-3 . It measures the distortion of distant galaxy images caused by intervening large-scale structure along the line-of-sight  4  . By measuring this distortion over a wide range of angular scales, one can reconstruct the three-dimensional matter distribution in the Universe  5  , which contains information about both the geometry of the universe and its growth rate  6  .\nIn order to extract useful cosmological information from weak lensing data, accurate measurements of the shapes of background galaxies must first be obtained  7-9 . These shape measurements then need to be corrected for distortions induced by atmospheric effects  10  , telescope optics  11  , and point spread function  12  . Finally, they also have to be corrected for distorted shapes introduced by foreground structures  13  . Intrinsic galaxy alignments (IAs), i.e., correlations between galaxy orientations  14  or positions  15  , introduce additional systematic errors into the measured shear correlation functions  16  . If not properly accounted for, IAs could lead to biased estimates of cosmological parameters  17  .\nSeveral methods have been proposed to mitigate the effect of IAs on cosmological parameter estimations  18  . One approach involves modeling the observed galaxy ellipticities as a combination of intrinsic",
        "watermark_text": "We explore the impact of intrinsic galaxy alignment ( IA ) on dark energy parameter constraints using weak lensing tomography with potential space - based surveys , such as Euclid and WFIRST . We see that IA introduces considerable biases in cosmological factors when only spectroscopic redshifts are available for calibration purposes .However , we prove that these biases can be reduced by including photometric redshifts to calibrate the IA model . In particular , we prove that it is possible to reduce the bias related to IA down to fewer than 1 % level if at least 10 bands spanning 0 . 4 - 1 micron are using for photo - z estimation .This requirement gets more stringent towards higher redshifts where the number density of galaxies reduces rapidly . The results presented here will assist guide the development of later research trying to measure dark energy through strong gravitational lensing .Introduction - Weak gravitational lensing has emerged as one of the most promising probes of deep energy 1 - 3 . It studies the degradation of distant galaxy images created by intervening large - scale structure along the line - of - view 4 .By measuring this disturbance over a broad variety of angular scales , one can reconstruct the three - dimensional matter distribution in the Universe 5 , which contains information about both the topology of the universe and its expansion speed 6 . In order to extract useful cosmological information from soft lensing data , detailed observations of the shapes of background galaxies must first be obtained 7 - 9 .These shape measurements then need to be corrected for distortions induced by atmospheric effects 10 , telescope optics 11 , and point spread system 12 . Finally , they also have to be corrected for distorted forms imposed by foreground structures 13 .Intrinsic galaxy alignments ( IAs ) , i . e . , correlations between galaxy orientations 14 or positions 15 , introduce extra systematic errors into the measured shear correlation functions 16 . If not adequately accounted for , IAs might lead to biased estimates of cosmological values 17 .Several methods have been proposed to mitigate the impact of IAs on cosmological factor estimations 18 . One approach employs studying the seen universe ellipticities as a combination of intrinsic",
        "ori-fast-z-score": 0.816496580927726,
        "water-fast-z-score": 8.382021125342941
    },
    {
        "original_text": "We present an algorithm for the detection and characterization of unique molecular events in time series data, which is based on identifying all possible pairs of states that can be reached by following different paths through the state space. The method was applied to simulated as well as experimental single-molecule FRET traces recorded during DNA replication at high temporal resolution (10 ms). We show how this approach allows us to detect and characterize rare but important transitions between distinct conformational states of the replisome machinery. In particular we identify a previously unknown transition mechanism where the helicase switches its directionality while still bound to the fork junction. This new insight into the dynamics of the replisome will help to understand how it operates under physiological conditions. \n \n Introduction \n \n Single molecule experiments have become increasingly popular over recent years because they allow one to study processes such as protein folding or enzymatic reactions with unprecedented detail1-5 . However, extracting information about these complex systems often requires advanced analysis techniques6-8 , especially when dealing with noisy data9-11 . Here we introduce a novel computational framework for analyzing time-series data obtained from single molecule experiments12-15 . Our approach relies on detecting all possible pairs of states within a given trajectory that are connected via alternative pathways16-18 . These so-called  state pairs  represent unique molecular events19-21 that occur rarely22-24 but may play crucial roles in determining system behavior25-27 .\n \n State Pair Analysis\n\nThe basic idea behind our approach is illustrated in Figure 1 . Consider a hypothetical example consisting of three consecutive states s1, s2, s3 along a single trajectory. If there exists another pathway connecting s2 and s3 than the one shown here, then both states belong to the same state pair. Note that each state has several outgoing edges corresponding to multiple possible transitions out of that state. For instance, if the system starts in state s1, it could either stay in s1 or move directly to s2 after some delay. Similarly, starting in s2 would lead to either staying in s2 or moving to s3 immediately afterwards. Finally, starting in s3 would always result in returning back to s1. As a consequence, any",
        "watermark_text": "We present an algorithm for the discovery and identification of unique molecular events in time series information , which is based on discovering all possible combinations of states that can be reached by following different paths through the state space . The method was used to modeled as well as experimental single - cell FRET traces recorded during DNA replication at high temporal resolution ( 10 ms ) .We see how this methodology allows us to identify and characterize strange but significant transitions between distinct conformational states of the replisome machinery . In particular we identify a previously unidentified transition process where the helicase changes its directionality while remained tied to the fork intersection .This new insight into the dynamics of the replisome will assist to explain how it operates under physiological circumstances . Introduction Single molecule experiments have developed increasingly popular over recent months because they allow one to study mechanisms such as protein folding or enzymatic reactions with unprecedented detail1 - 5 .However , extracting information about these complex systems often needs advanced analysis techniques6 - 8 , particularly when dealing with noisy data9 - 11 . Here we provide a innovative computational framework for studying moment - series information obtained from small molecule experiments12 - 15 .Our model relies on detecting all possible combinations of states within a given path that are connected via alternative pathways16 - 18 . These so - called state pairs reflect unusual molecular events19 - 21 that occur rarely22 - 24 but might play crucial roles in determining network behavior25 - 27 .State Pair Analysis The basic idea behind our approach is depicted in Figure 1 . Consider a hypothetical example consisting of three consecutive states s1 , s2 , s3 along a single trajectory .If there exists another pathway connecting s2 and s3 than the one given here , then both states belong to the same state pair . Note that each state has numerous outgoing edges relating to multiple possible transitions out of that state .For instance , if the scheme begins in state s1 , it could either stay in s1 or motion directly to s2 after some pause . Similarly , beginning in s2 might lead to either staying in s2 or moving to s3 immediately afterwards .Finally , beginning in s3 would still result in moving return to s1 . As a consequence , any",
        "ori-fast-z-score": -0.22677868380553634,
        "water-fast-z-score": 8.339078479367938
    },
    {
        "original_text": "We present an analysis of the shallow decay segment in X-ray afterglow light curves observed by Swift/XRT, which is based on our previous work (Zhang et al., 2006) . We find that there are two types of shallow decays with different physical origins. The first type has been widely discussed and can be explained as arising from either energy injection or refreshed shocks. However, we show that this scenario cannot explain all cases of shallow decays. In particular, it fails to account for those shallow decays occurring at late times when the external shock emission should have faded away completely. For these events, we propose another explanation -the second type of shallow decays-which may arise from the transition between the relativistic fireball phase and non-relativistic ejecta-dominated phase. This new interpretation naturally explains why some shallow decays occur only at late times while others appear both early and late during the afterglow evolution. \n \n Keywords: Afterglow, Energy injection, Fireball model",
        "watermark_text": "We present an assessment of the narrow degradation segment in X - ray afterglow light curves observed by Swift / XRT , which is based on our previous research ( Zhang et al . , 2006 ) . We see that there are two forms of shallow decays with various physical origins .The first sort has been widely discussed and can be described as occurring from either power injection or refreshed shocks . However , we prove that this situation fails explain all cases of shallow decays .In particular , it fails to explain for those shallow decays originating at late times when the external shock emission should have fading away completely . For these phenomena , we propose another explanation - the second kind of shallow decays - which would occur from the shift between the relativistic fireball phase and non - relativistic ejecta - dominated phase .This new theory naturally explains why some shallow decays occur only at late times while several occur both late and late during the afterglow evolution . Keywords : Afterglow , Energy injection , Fireball model",
        "ori-fast-z-score": -0.808290376865476,
        "water-fast-z-score": 4.50333209967908
    },
    {
        "original_text": "We present an analysis of the distribution of gas, stars and dust in two nearby edge-on spirals with prominent bars (NGC 1365 and NGC 1530). We use high-resolution observations obtained by the Herschel Space Observatory to study the physical conditions of the interstellar medium along these systems. The main results are as follows:  - In both cases we find that the molecular hydrogen is concentrated on the leading edges of the bar, while atomic hydrogen follows closely the stellar light.  - The star formation rate peaks at the ends of the bar where the density of molecular hydrogen increases significantly. This suggests that the gravitational torques induced by the bar can trigger the collapse of dense clouds into new generations of young stars.  - The infrared emission associated with polycyclic aromatic hydrocarbons shows a clear correlation between the location of this component and the regions of active star formation. - The comparison of our data with hydrodynamical simulations indicates that the observed structure of the ISM may be explained if the bar potential has been able to drive significant amounts of cold gas towards its inner Lindblad resonance.",
        "watermark_text": "We present an assessment of the distribution of gas , stars and dust in two distant edge - on spirals with prominent bars ( NGC 1365 and NGC 1530 ) . We use large - resolution measurements obtained by the Herschel Space Observatory to study the physical conditions of the interstellar medium along these systems .The main results are as follows : - In both cases we find that the molecular hydrogen is confined on the led corners of the bar , while nuclear hydrogen takes closely the stellar radiation . - The galaxy formation rate peaks at the ends of the bar where the density of molecular hydrogen rises considerably .This implies that the gravitational torques induced by the bar can cause the decay of dense clouds into new generations of young stars . - The infrared absorption associated with polycyclic aromatic hydrocarbons indicates a clear correlation between the location of this constituent and the regions of active star formation .- The comparison of our information with hydrodynamical simulations indicates that the known composition of the ISM may be described if the bar potential has been able to drive considerable portions of cold gas towards its internal Lindblad resonance .",
        "ori-fast-z-score": 1.4924050144892729,
        "water-fast-z-score": 6.88998622004134
    },
    {
        "original_text": "We present an algorithm to find galaxy groups using photometric redshifts, which is based on the Voronoi tessellation technique (VT). The VT method has been widely used for identifying clusters of galaxies with spectroscopic redshifts but it had not yet been applied to identify galaxy groups with photometric redshifts. We use the Sloan Digital Sky Survey data release five (SDSS DR5) as our input sample. Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available. In this work we have identified more than 12000 galaxy groups at 0 < z < 0.3. These groups contain about 30000 member galaxies. We also provide a catalog containing basic information such as positions, magnitudes, colors, and photometric redshifts for all these groups. \n \n Keywords: Galaxy Group, Photometric Redshift",
        "watermark_text": "We present an algorithm to find galaxy groups using photometric redshifts , which is based on the Voronoi tessellation method ( VT ) . The VT method has been widely using for finding clusters of stars with spectroscopic redshifts but it had not already been used to identify galaxy groups with photometric redshifts .We use the Sloan Digital Sky Survey data release five ( SDSS DR5 ) as our input data . Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available .In this research we have discovered more than 12000 star groups at 0 < z < 0 . 3 . These groups contain about 30000 member galaxies .We additionally offer a list containing essential information such as positions , magnitudes , colors , and photometric redshifts for all these groups . Keywords : Galaxy Group , Photometric Redshift",
        "ori-fast-z-score": -1.2602520756252087,
        "water-fast-z-score": 3.2206441932644223
    },
    {
        "original_text": "We report the detection of three new exoplanet candidates around stars with masses between 1.1 M⊙ and 2.0 M⊙ using high-precision radial-velocity measurements obtained by the High Accuracy Radial velocity Planet Searcher (HARPS) spectrograph on the 3.6-m telescope at La Silla Observatory in Chile. The orbital periods are found to be between 4 days and 12 years. We also present an analysis of the host star properties based on photometric observations made with the CoRoT space mission as well as spectroscopic data taken with HARPS. For two of these systems we find that the planet mass is likely below Neptune s mass but above Mercury s mass. In addition, one system shows evidence for additional bodies in its planetary system. These results demonstrate the power of combining different techniques to detect extrasolar planets. Keywords: Extra-solar planet - HARPS",
        "watermark_text": "We report the observation of three new exoplanet alternatives around stars with masses between 1 . 1 [UNK] and 2 . 0 [UNK] using high - precision radial - speed measurements obtained by the High Accuracy Radial velocity Planet Searcher ( HARPS ) spectrograph on the 3 . 6 - m observatory at La Silla Observatory in Chile . The orbital periods are found to be between 4 hours and 12 years .We additionally offer an assessment of the host star dynamics based on photometric surveys made with the CoRoT space flight as well as spectroscopic data taken with HARPS . For two of these systems we find that the planet mass is probably below Neptune s mass but above Mercury s mass .In addition , one system displays evidence for additional body in its planetary system . These data demonstrate the power of combining different methods to identify extrasolar planets .Keywords: Extra-solar planet - HARPS",
        "ori-fast-z-score": 0.7745966692414834,
        "water-fast-z-score": 5.761659596980319
    },
    {
        "original_text": "We have searched for radio transients with flux densities between 0.1 and 1 mJy at frequencies ranging from 4 to 8 GHz using archival data obtained by the Very Large Array (VLA) over the past 20 years. We find that most of these sources are extragalactic, but we also detect several Galactic objects including pulsars, supernova remnants, and flare stars. The majority of our sample is comprised of previously uncatalogued sources; however, we recover many known variable sources such as blazars and gamma-ray burst afterglows. Our results demonstrate the power of combining large amounts of archival VLA data into one coherent dataset. This work was supported by NSF grant AST-0907860. In this Letter, we present an analysis of all available archived Very Large Array (V LA) observations taken since 1990. These data were collected during various observing programs aimed primarily at studying distant galaxies or nearby star forming regions. However, they contain valuable information about fainter transient phenomena occurring within our Galaxy. By searching through more than 10 000 hours of observation time spread across nearly 2000 epochs, we identify thousands of new faint radio sources which appear only once or twice in each epoch s data set. Most of these sources are extragalaxtic, but we also detect numerous Galactic objects including pulsar wind nebulae, supernova remnants, flare stars, and other types of active galactic nuclei. Many of these newly discovered sources are not included in existing catalogs because their low signal-to-noise ratio makes them difficult to detect when observed individually. However, by combining multiple epochs together, we can boost the sensitivity of our survey enough to detect even very weak signals.",
        "watermark_text": "We have searched for signal transients with flux densities between 0 . 1 and 1 mJy at speeds ranging from 4 to 8 GHz using archival measurements obtained by the Very Large Array ( VLA ) over the previous 20 decades . We see that most of these sources are extragalactic , but we also observe numerous Galactic items including pulsars , supernova remnants , and flare stars .The majority of our sample is comprised of previously uncatalogued sources ; however , we recover several known variable sources such as blazars and gamma - ray flare afterglows . Our results show the power of combining enormous amounts of archival VLA information into one integrated dataset .This project was supported by NSF grant AST - 0907860 . In this Letter , we present an assessment of all available archived Very Large Array ( V LA ) observations made since 1990 .These data were collected during various observing programs aimed exclusively at studying nearby galaxies or neighboring star producing regions . However , they contain significant information about fainter transient phenomena occurring within our Galaxy .By looking through more than 10 000 hours of study distance distributed across nearly 2000 epochs , we identify thousands of new faint radio sources which appear only once or repeatedly in each epoch s information pool . Most of these sources are extragalaxtic , but we also identify numerous Galactic bodies including pulsar wind nebulae , supernova remnants , flare stars , and other types of active galactic nuclei .Many of these newly discovered sources are not included in existing catalogs because their low signal - to - noise proportion creates them harder to identify when observed individually . However , by combining multiple epochs combined , we can boost the sensitivity of our survey sufficiently to identify especially very weak signals .",
        "ori-fast-z-score": 1.3416407864998738,
        "water-fast-z-score": 9.03371462909915
    },
    {
        "original_text": "We consider the asymptotic behavior of the sample autocovariance function and spectral density functions of stationary processes with regularly varying marginal distributions, which are driven by an infinite order moving average process whose coefficients have regularly varying tails. We show that these quantities can be approximated by those of a finite order autoregressive-moving average (ARMA) model in the sense of weak convergence under some conditions on the tail behaviors of the ARMA parameters. The results obtained here extend previous ones given in the literature to more general cases where the driving noise is not necessarily Gaussian or has non-Gaussian components. In particular, we provide new proofs for the existing results when the driving noise is purely Gaussian. Our approach relies heavily on recent developments made in the theory of regular variation and stochastic calculus. As applications, we study two examples of duration-driven LRD models, namely the Cox-Ingersoll-Ross (CIR) model and the Vasicek model.",
        "watermark_text": "We consider the asymptotic activity of the sample autocovariance map and spectral density functions of stationary systems with regularly varying marginal distributions , which are driven by an endless order move average process whose coefficients have regularly varying tails . We see that these quantities can be approximated by those of a finite order autoregressive - moving average ( ARMA ) model in the sense of weak convergence under some conditions on the tail behaviors of the ARMA parameters .The results derived here extend previous ones given in the writings to more general instances where the driving signal is not necessarily Gaussian or has non - Gaussian components . In particular , we provide fresh proofs for the new results when the driving signal is purely Gaussian .Our perspective rely heavily on current developments developed in the theoretical of regular variation and stochastic equations . As applications , we study two examples of duration - based LRD models , namely the Cox - Ingersoll - Ross ( CIR ) model and the Vasicek theory .",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 4.302652729749464
    },
    {
        "original_text": "We study the sound propagation through a one-dimensional (1D) Bose-Einstein condensed gas trapped by an optical lattice potential and interacting with each other via contact interactions. We show that, for weak interaction strength, there is no phonon-phonon scattering between different bands due to the energy gap induced by the periodic potential. In this case, we find that the sound velocity can be obtained analytically using perturbation theory. For strong interaction strengths, however, the phonons are scattered into higher bands and thus the sound velocity decreases as compared to its non-interacting value. The results agree well with numerical calculations based on the Gross-Pitaevskii equation. PACS numbers: 03.75.Dg, 05.30.Jp, 37.10.Gh \nI. INTRODUCTIO N\nThe properties of superfluid helium have been studied extensively since it was discovered more than half century ago  1  . One of the most important features of superfluids is their ability to support dissipationless flow without friction  2  , which has led to many applications such as superconductors  3  .\nRecently, ultracold atomic gases confined in optical lattices provide another platform to explore quantum fluids  4  . These systems exhibit various phases including Mott insulator phase  5  , supersolid phase  6  , and even topological states  7, 8  . Moreover, they allow us to tune the system parameters continuously  9  and observe directly the evolution of physical quantities  10  . This makes them ideal candidates to investigate new phenomena predicted by theoretical studies  11  .\nIn particular, bosonic atoms in optical lattices may form a BoseEinstein condensate  12  . It is known that these condensates behave like superfluids  13  . Recently, several experiments have observed the superflow  14  and vortex  15  in these systems. However, unlike conventional superfluids, the condensates in optical lattices also interact strongly with each other  16  . Therefore, understanding how the interatomic interactions affect the collective excitations becomes crucial  17  .\nIn this work, we consider 1D Bose-Einstein condensates trapped by an optical lattice  18  . By solving the",
        "watermark_text": "We test the music transmission through a one - dimensional ( 1D ) Bose - Einstein condensed gas trapped by an optical lattice potential and evolving with each other via contact interactions . We see that , for weak interaction strength , there is no phonon - phonon absorption between various groups owing to the power gap induced by the periodic potential .In this situation , we find that the audio speed can be obtained analytically using perturbation theory . For strong coupling strengths , however , the phonons are scattered into greater bands and therefore the audio speed reduces as compared to its non - interacting function .The results agree well with numerical measurements based on the Gross - Pitaevskii equation . PACS quantities : 03 . 75 . Dg , 05 . 30 . Jp , 37 . 10 . Gh I . INTRODUCTIO N The properties of superfluid helium have been studied thoroughly since it was known more than quarter century ago 1 .One of the most important features of superfluids is their ability to support dissipationless flow without tension 2 , which has led to many applications such as superconductors 3 . Recently , ultracold atomic fluids confined in laser lattices offers another platform to study quantum fluids 4 .These systems exhibit several stages namely Mott insulator stage 5 , supersolid phase 6 , and even topological states 7 , 8 . Moreover , they allow us to balance the process variables continuously 9 and observe directly the evolution of physical quantities 10 .This gives them ideal candidates to examine novel processes proposed by theoretical experiments 11 . In particular , bosonic atoms in optical lattices might form a BoseEinstein condensate 12 .It is known that these condensates behave like superfluids 13 . Recently , various observations have noted the superflow 14 and vortex 15 in these systems .However , unlike conventional superfluids , the condensates in laser lattices additionally interact heavily with each other 16 . Therefore , studying how the interatomic interactions impact the collective excitations remains crucial 17 .In this study , we solve 1D Bose - Einstein condensates trapped by an optical lattice 18 . By solving the",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 8.736345975703701
    },
    {
        "original_text": "We present an overview of the generic cosmological singularity problem, and its possible solutions in string theory. We discuss how this issue is related to other problems such as black hole entropy, time travel paradoxes, and information loss. Finally we review some recent developments on these topics. The nature of generic cosmological singularities has been one of the most important open questions in theoretical physics for many years. In particular it is not known whether or not there are any physical processes that can take place at all times near the big bang (or equivalently near the big crunch). This question is intimately connected with several other fundamental issues including black hole entropy, time machine paradoxes, and information loss/reduction. It also plays a crucial role in understanding the very early universe. Recently significant progress has been made towards answering this question using techniques developed within the context of string theory. Here I will give a brief summary of what is currently understood about this topic.",
        "watermark_text": "We present an overview of the generic cosmological singularity issue , and its potential solutions in string theory . We discuss how this question is related to other difficulties such as black hole entropy , time trip paradoxes , and information loss .Finally we review some latest advances on these topics . The nature of generic cosmological singularities has been one of the most important open questions in theoretical physics for many years .In particular it is not established whether or not there are any physical processes that can take place at all times near the big bang ( or equivalently near the big crunch ) . This problem is intimately tied with various other fundamental issues including black hole entropy , time computer paradoxes , and information loss / reduction .It additionally serves a crucial role in understanding the very earliest galaxy . Recently significant progress has been achieved towards answering this question using techniques established within the context of string theory .Here I will provide a brief summary of what is currently understood about this discussion .",
        "ori-fast-z-score": 1.118033988749895,
        "water-fast-z-score": 5.366563145999495
    },
    {
        "original_text": "The evolution of galaxies is strongly influenced by their environment, but the physical processes that drive this are not well understood. In particular, it remains unclear how galaxy properties such as morphology or star formation rate depend on large-scale structure in the Universe.  This talk will present results from an ongoing study using data from the Sloan Digital Sky Survey (SDSS) to investigate these issues. The first part of my talk will focus on the relationship between galaxy clustering and luminosity/stellar mass. I will then discuss recent work investigating the dependence of galaxy properties on local density. Finally, I ll show some preliminary results exploring the connection between galaxy properties and dark matter halo masses. My research has been supported by NSF grant AST-0707766. I am currently a postdoctoral fellow at Harvard University working with Prof. David Weinberg. I received my Ph.D. from UCLA under the supervision of Dr. James Bullock.",
        "watermark_text": "The evolution of stars is strongly governed by their environment , but the physical processes that drive this are not well understood . In particular , it remains obscure how star parameters such as morphology or star formation rate depend on huge - scale organization in the Universe .This discussion will present results from an continuing survey employing data from the Sloan Digital Sky Survey ( SDSS ) to examine these problems . The first part of my talk will focus on the relationship between galaxy clustering and luminosity / stars mass .I will then discuss latest work investigating the dependence of galaxy structures on local concentration . Finally , I ll show some preliminary results studying the link between galaxy structures and dark matter halo populations .My research has been supported by NSF grant AST - 0707766 . I am currently a postdoctoral scholar at Harvard University working with Prof . David Weinberg .I received my Ph . D . from UCLA under the guidance of Dr . James Bullock .",
        "ori-fast-z-score": 0.9701425001453319,
        "water-fast-z-score": 6.5484618759809905
    },
    {
        "original_text": "We present an analysis of the ages derived by applying the gyrochronological method to a sample of open clusters with known ages (from literature) in order to assess its reliability as well as possible systematics associated with it. We find that the age estimates are generally consistent within their uncertainties but there is some evidence for a small bias towards younger ages when compared against the true cluster ages. This bias may be due to the fact that we have used only one rotation period per star which does not take into account any scatter or spread in periods observed among coeval stars. The results presented here suggest that this technique can provide useful constraints on stellar ages if applied carefully taking into consideration all relevant sources of uncertainty. Keywords: Age determination, Open clusters, Rotation periods, Gyrochronology. 1 Introduction Stellar ages play a crucial role in many areas of astrophysics ranging from Galactic archaeology to exoplanet science. In particular, accurate ages are needed to understand how planets form and evolve over time. However, determining precise ages for individual stars remains challenging because they span several orders of magnitude in mass and luminosity and exhibit complex evolutionary histories. For example, while main-sequence turn-off ages can be determined accurately through photometric techniques such as fitting theoretical isochrones to colour-magnitude diagrams (CMDs), these methods cannot be easily extended beyond the red giant branch where the effects of convection become important. Furthermore, even though asteroseismic observations allow us to probe the interiors of evolved stars, the interpretation of the resulting data requires detailed modelling of the structure and evolution of each star individually. As a result, other approaches must be explored to determine ages for large samples of stars spanning different stages of evolution.\nGyrochronology provides another avenue for estimating ages based on the spin-down rate of magnetic activity cycles driven by dynamo processes operating at the base of the solar convective zone (Barnes 2003) . It has been shown that the Rossby number R o , defined as the ratio between the rotation period P rot and the convective overturning timescale",
        "watermark_text": "We present an assessment of the years derived by using the gyrochronological method to a sample of open clusters with recorded ages ( from literature ) in order to examine its reliability as well as possible systematics associated with it . We see that the age totals are typically consistent within their uncertainties but there is some evidence for a small prejudice towards older ages when compared against the true cluster ages .This bias could be due to the fact that we have applied only one rotation cycle per star which does not take into consideration any scatter or spread in dates observed among coeval stars . The results presented here suggest that this methods can provide useful limitations on stellar ages if applied deliberately taking into consideration all relevant sources of uncertainty .Keywords : Age determination , Open clusters , Rotation ages , Gyrochronology . 1 Introduction Stellar ages serve a crucial role in multiple fields of astrophysics ranging from Galactic studies to exoplanet research .In particular , detailed years are needed to comprehend how planets form and evolve over time . However , determining exact ages for individual stars becomes challenging because they span many orders of magnitude in mass and luminosity and possess intricate evolutionary histories .For instance , while main - sequence turn - off ages can be determined accurately through photometric strategies such as fitting theoretical isochrones to colour - magnitude diagrams ( CMDs ) , these procedures cannot be easily applied beyond the red dwarf branch where the effects of convection become crucial . Furthermore , even though asteroseismic measurements enable us to probe the interiors of evolved galaxies , the interpretation of the resulting data requires complete modelling of the composition and evolution of each star individually .As a result , other methods require be investigated to estimate ages for large specimens of stars spanning varying stages of evolution . Gyrochronology offers another avenue for estimating years depending on the spin - down frequency of magnetic activity periods caused by dynamo mechanisms operating at the base of the solar convective zone ( Barnes 2003 ) .It has been shown that the Rossby number R o , defined as the proportion between the rotation period P rot and the convective overturning timescale",
        "ori-fast-z-score": 0.15075567228888181,
        "water-fast-z-score": 8.995554457619608
    },
    {
        "original_text": "We report on the fluidization of a thin, horizontally vibrating granular bed by vertical oscillations at low frequency and amplitude. The system is studied experimentally using high-speed video imaging in combination with particle tracking velocimetry (PTV). We find that for sufficiently large vibration amplitudes, particles are ejected from the surface into the air as they reach their maximum height during an upward motion. This leads to the formation of a dilute gas phase above the dense packing near the bottom of the container. In addition we observe convection rolls which transport grains across the entire depth of the bed. These results show striking similarities to those observed in vibrated beds of sand or glass beads but differ significantly from previous studies performed on systems where only horizontal vibrations were applied. Vibrations can induce transitions between different states of matter such as solids, liquids, and gases  1  . For example, it has been shown that a solid state may become unstable when subjected to periodic forcing  2  , resulting in the spontaneous generation of traveling waves  3  . A particularly interesting case occurs if both horizontal and vertical components of the driving force act simultaneously  4  .\nIn this work we study the response of a thin granular layer to simultaneous application of horizontal and vertical vibrations. Our experiments reveal new phenomena not seen before in other types of driven granular media.",
        "watermark_text": "We report on the fluidization of a thin , vertically vibrating granular floor by vertical oscillations at low frequency and amplitude . The system is studied experimentally utilizing large - speed video scanning in combination with particle tracking velocimetry ( PTV ) .We see that for enough large vibration amplitudes , particles are expelled from the surface into the air as they reach their maximum size during an upward moving . This leads to the formation of a dilute gas phase above the dense packing near the bottom of the container .In addition we study circulation rolls which carry grains across the entire depth of the bed . These data demonstrate striking parallels to those observed in vibrated beds of dust or glass bottles but differ significantly from previous analyses performed on structures where only horizontal vibrations were applied .Vibrations can induce changes between various states of matter such as solids , liquids , and gases 1 . For instance , it has been shown that a solid state would remain weak when exposed to periodic forcing 2 , resulting in the spontaneous production of traveling particles 3 .A notably important case occurs if both horizontal and horizontal elements of the driving stress act simultaneously 4 . In this research we study the response of a thin granular layer to continuous application of longitudinal and horizontal vibrations .Our experiments discover new phenomena not seen before in other types of driven granular material .",
        "ori-fast-z-score": 1.3112201362143716,
        "water-fast-z-score": 8.241955141918908
    },
    {
        "original_text": "We present results on the infrared (IR) properties of galaxies obtained by comparing predictions made using a semi-analytic galaxy formation model to observations taken as part of the Spitzer Infrared Nearby Galaxies Survey (SINGS). We find that our model reproduces many observed trends, including the IR luminosity function and the correlation between star formation rate and dust temperature. However, we also identify some discrepancies which suggest that further work is needed before this type of modelling can be used for detailed studies of individual objects or small samples. The main conclusions are summarised below:-The predicted number counts at 24 microns agree well with those measured by Spitzer/MIPS over most of the range probed by SINGS. -Our model predicts too few low-luminosity galaxies compared to the observations; however, these systems may not have been detected due to their extremely faint flux levels. -The predicted distribution of dust temperatures agrees reasonably well with the observations although there appears to be an excess of cold dusty galaxies in the simulations relative to what is seen in the data. -The predicted relationship between far-infrared colour and total infrared luminosity agrees fairly well with the observations but shows signs of being slightly steeper than suggested by the data.",
        "watermark_text": "We report findings on the infrared ( IR ) characteristics of galaxies collected by comparing predictions produced using a semi - analytic galaxy formation theory to observations made as part of the Spitzer Infrared Nearby Galaxies Survey ( SINGS ) . We see that our model reproduces many observed trends , notably the IR luminosity function and the relationship between star formation rate and dust temperature .However , we also identify some discrepancies which show that further work is required before this form of simulation can be used for detailed analyses of individual objects or small samples . The main results are summarised below : - The predicted total counts at 24 microns agree well with those observed by Spitzer / MIPS over most of the range probed by SINGS .- Our model predicts too few poor - luminosity galaxies compared to the surveys ; however , these systems may not have been detected due to their extremely dim flux levels . - The predicted distribution of dust conditions agrees reasonably well with the experiments although there seems to be an accumulation of cold dusty galaxies in the simulations compared to what is seen in the information .- The predicted relationship between far - infrared colour and total infrared luminosity agrees fairly better with the experiments but appears indicators of being somewhat steeper than proposed by the data .",
        "ori-fast-z-score": 1.3065491598369756,
        "water-fast-z-score": 7.4
    },
    {
        "original_text": "We report on the adhesion force between two surfaces made out of the same material, which is caused by triboelectric charging and electrostatic attraction. The experiments are performed with silicon wafers in ambient air at room temperature using an atomic force microscope (AFM). We find that the measured adhesion force increases linearly with increasing normal load applied to the AFM tip. This behavior can be explained by considering the contact area as well as the charge density distribution across this area. In addition we show how the adhesion force depends on the relative humidity. Finally, we discuss possible applications for our findings. Tribology deals with friction, wear and lubrication phenomena occurring when solid bodies slide against each other or deform elastically under pressure  1  . It has been known since the 19th century that sliding friction causes electric charges  2  , but only recently it was realized that these charges play an important role in tribological processes  3  .\nIn particular, it has been shown that tribocharging leads to strong adhesive interactions between solids  4  . These effects have been observed experimentally  5, 6  and theoretically  7, 8  . However, most studies so far focused on dissimilar materials such as metals and insulators  9  . Here we present experimental results showing that even identical materials exhibit significant adhesion if they are brought into contact while being charged electrically  10  .",
        "watermark_text": "We report on the adhesion force between two structures making out of the same material , which is caused by triboelectric locking and electrostatic attraction . The studies are performed with silicon wafers in ambient atmosphere at room temperature using an atomic force microscope ( AFM ) .We see that the measured adhesion force increases linearly with increasing regular stress introduced to the AFM tip . This phenomenon can be described by analyzing the contact area as well as the charge density flow across this area .In addition we explain how the adhesion force depends on the relative humidity . Finally , we study possible solutions for our findings .Tribology concerns with friction , wear and lubrication phenomena occurring when hard body slide against each other or deform elastically under pressure 1 . It has been known since the 19th century that moving friction produces electric charges 2 , but only lately it was understood that these charges serve an important role in tribological reactions 3 .In particular , it has been shown that tribocharging leads to powerful adhesive interactions between solids 4 . These effects have been observed experimentally 5 , 6 and theoretically 7 , 8 .However , most studies so far concentrate on dissimilar materials such as metals and insulators 9 . Here we present experimental studies showing that even identical structures exhibit substantial adhesion if they are brought into contact while being charged electrically 10 .",
        "ori-fast-z-score": 0.10153461651336192,
        "water-fast-z-score": 6.3966808403418005
    },
    {
        "original_text": "The present work is devoted to the study of some aspects of geometry and topology in relativistic cosmology, with particular emphasis on the role played by the Weyl tensor. In Section 2 we review the basic concepts of Riemannian geometry that are relevant for our purposes; in particular, we introduce the concept of conformal vector field as well as its associated energy-momentum tensor. We also discuss how these fields can be used to construct exact solutions of Einstein s equations describing homogeneous but anisotropic universes. In Section 3 we consider the problem of classifying all possible types of singularities which may occur at finite time in spatially closed Friedmann-Robertson-Walker (FRW) models. This classification turns out to depend crucially upon whether or not the universe contains any matter sources other than radiation. Finally, in Section 4 we show that the presence of a non-vanishing Weyl tensor leads to an additional type of singularity which cannot arise if one assumes that the universe consists only of ordinary matter.",
        "watermark_text": "The present work is devoted to the examination of some elements of geometry and topology in relativistic cosmology , with particular importance on the part played by the Weyl vector . In Section 2 we review the fundamental concepts of Riemannian topology that are important for our purposes ; in particular , we investigate the notion of conformal vector field as well as its attendant energy - momentum tensor .We also discuss how these fields can be used to build exact solutions of Einstein s equations representing homogeneous but anisotropic universes . In Section 3 we investigate the question of classifying all possible kinds of singularities which may happen at finite time in spatially closed Friedmann - Robertson - Walker ( FRW ) models .This classification happens out to depend crucially upon whether or not the universe possesses any matter sources other than radiation . Finally , in Section 4 we prove that the presence of a non - vanishing Weyl vector results to an additional type of singularity which cannot arise if one assumes that the universe consists only of normal materials .",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 4.391092135317257
    },
    {
        "original_text": "We report results of X-ray observations with Suzaku satellite of the nucleus of radio-loud active galaxy Centaurus A (NGC 5128). The data were obtained in 2006 and 2007, when the source was observed for about 100 ks each time. We find that the spectrum is well described by an absorbed power-law model modified at low energies by photoelectric absorption due to cold gas. No significant emission lines are detected above 3 keV. Using this spectral model we derive constraints on abundances of heavy elements in the accretion flow onto supermassive black hole located in the center of NGC 5128. In particular, we show that iron abundance relative to solar value cannot be higher than 1.5-2 times its solar value. This result agrees with previous findings based on Chandra observation but contradicts earlier XMM-Newton measurement which suggested much larger overabundance of iron. Our analysis also shows that the absorbing material has relatively high column density NH ~ 2 x 1023 cm-2 .",
        "watermark_text": "We report findings of X - ray observations with Suzaku satellite of the nucleus of radio - loud active galaxy Centaurus A ( NGC 5128 ) . The data were obtained in 2006 and 2007 , when the origin was seen for about 100 ks each time .We see that the spectrum is well described by an absorption power - law theory refined at low energies by photoelectric diffusion owing to cold vapor . No notable emission lines are detected above 3 keV .Using this spectral method we derive restrictions on abundances of heavy metals in the accretion flow onto supermassive black hole located in the center of NGC 5128 . In particular , we prove that iron abundance relative to solar value cannot be higher than 1 . 5 - 2 twice its solar value .This result agrees with previous findings based on Chandra observation but contradicts earlier XMM - Newton measurement which suggested much larger overabundance of metals . Our study also shows that the absorbing material has relatively high column thickness NH ~ 2 x 1023 mm - 2 .",
        "ori-fast-z-score": 1.7888543819998317,
        "water-fast-z-score": 6.037383539249432
    },
    {
        "original_text": "We present the first results on clustering measurements for luminous red galaxies (LRGs) in the redshift range 0.5 <z<0.8, obtained with the Anglo-Australian Observatory s multi-object spectrograph AAOmega. We use data from the 2dF-SDSS LRG and QSO survey to measure the projected correlation function wp(rp). The observed clustering amplitude is consistent with that expected from linear theory predictions based on current cosmological models. This result provides an important test of these models over this redshift range where there are few other constraints available. In addition we find evidence for evolution in the galaxy bias parameter between our two samples separated by ~0.2 Gyrs. These results will be presented in detail elsewhere. \n \n Keywords: Luminous Red Galaxies; Clustering; Bias Evolution; Cosmology. 1 Introduction \n \n A number of recent studies have shown that luminous red galaxies (hereafter LRGs), selected via their optical colours or near-infrared photometry, provide powerful probes of large-scale structure out to high redshifts (e.g., Eisenstein et al. 2001; Wake et al. 2006; Padmanabhan et al. 2007; Blake et al. 2008; Ross et al. 2008) . Their large luminosities mean they can be detected efficiently even at relatively low redshifts, while their red colours make them easy to identify spectroscopically. They also tend to reside in massive dark matter haloes which evolve slowly through cosmic time, making them useful tracers of the underlying mass distribution. As such, they offer unique opportunities to study both the growth of structures as well as the nature of dark energy driving its accelerated expansion (see e.g., Percival & White 2009 , for a review). \n \n Here we report the first measurement of the spatial clustering properties of LRGs in the redshift range 0<z<0.8 made possible by combining data from the Sloan Digital Sky Survey (SDSS) (York et al. 2000) , the Two Degree Field Galaxy Redshift Survey (2dFGRS) (Colless et al.",
        "watermark_text": "We publish the first findings on clustering observations for luminous red objects ( LRGs ) in the redshift region 0 . 5 < z < 0 . 8 , obtained with the Anglo - Australian Observatory s multi - object spectrograph AAOmega . We use data from the 2dF - SDSS LRG and QSO studies to measure the projected relationship value wp ( rp ) .The observed clustering amplitude is compatible with that expected from linear theoretical estimates based on current cosmological models . This result provides an important test of these models over this redshift region where there are few other constraints offered .In addition we find proof for evolution in the galaxy bias variable between our two specimens divided by ~ 0 . 2 Gyrs . These conclusions will be shown in detail elsewhere .Keywords : Luminous Red Galaxies ; Clustering ; Bias Evolution ; Cosmology . 1 Introduction A variety of recent studies have shown that luminous red clusters ( hereafter LRGs ) , selected via their optical colours or near - infrared photometry , provide potent probes of large - scale organization out to large redshifts ( e . g . , Eisenstein et al .2001 ; Wake et al . 2006 ; Padmanabhan et al .2007 ; Blake et al . 2008 ; Ross et al .2008 ) . Their large luminosities guarantee they can be identified efficiently even at fairly little redshifts , while their red colours help them easy to identify spectroscopically .They also seem to live in massive dark matter haloes which evolution gradually through cosmic time , making them useful tracers of the ongoing mass distribution . As such , they give unique possibilities to study both the development of structures as also as the nature of bright energy causing its rapid increase ( saw e . g . , Percival & White 2009 , for a review ) .Here we publish the first measurement of the spatial clustering behavior of LRGs in the redshift region 0 < z < 0 . 8 made possible by combining information from the Sloan Digital Sky Survey ( SDSS ) ( York et al . 2000 ) , the Two Degree Field Galaxy Redshift Survey ( 2dFGRS ) ( Colless et al .",
        "ori-fast-z-score": -0.9610744623271417,
        "water-fast-z-score": 7.0164641544562345
    },
    {
        "original_text": "In this work, we propose an approach to human identification based on the analysis of image attributes and their relationships with each other. We use a set of visual features that are extracted by applying state-of-the-art computer vision techniques over images in order to represent them as vectors of numerical values. These feature vectors can be used to train machine learning algorithms such as Support Vector Machines (SVMs) or Random Forests (RF). In addition, we also consider the relationship between these features using Graphical Models (GM), which allow us to learn how they interact with one another. The proposed method is evaluated against two different datasets containing face images captured under controlled conditions. Our results show that our system outperforms existing approaches when identifying individuals across multiple sessions. This research was supported by the National Science Foundation through awards IIS-1253153 and CNS-1527225. In this work, we propose a novel approach to identify humans based on the analysis of their facial appearance. To do so, we extract several visual features from faces using state-of-the-art computer vision methods. Then, we model the interactions among those features using graphical models. Finally, we evaluate the performance of our method against two publicly available databases.",
        "watermark_text": "In this project , we develop an way to human identification relying on the examination of visual attributes and their connections with each other . We use a group of visual elements that are derived by using state - of - the - art computer vision techniques over images in order to represent them as matrices of numerical values .These feature vectors can be used to train machine understanding algorithms such as Support Vector Machines ( SVMs ) or Random Forests ( RF ) . In addition , we also consider the relationship between these characteristics utilizing Graphical Models ( GM ) , which allow us to study how they interact with one another .The proposed approach is evaluated against two different datasets featuring face photos taken under controlled circumstances . Our results show that our system outperforms previous techniques when identifying persons across multiple sessions .This research was supported by the National Science Foundation through awards IIS - 1253153 and CNS - 1527225 . In this research , we propose a innovative method to identify humans based on the evaluation of their facial form .To do so , we extract many graphical features from faces utilizing state - of - the - art computer vision methods . Then , we study the interactions among those characteristics utilizing graphical descriptions .Finally , we assess the performance of our technique against two publicly accessible data .",
        "ori-fast-z-score": -1.507556722888818,
        "water-fast-z-score": 6.4
    },
    {
        "original_text": "We present results on distance determinations for two galaxies, NGC 3109 and WLM, based on observations made with the Hubble Space Telescope (HST). We have used HST/WFPC2 images taken through filters F555W and F814W to search for Cepheids among young open clusters located within these galaxies. Our survey has resulted in the discovery of four new Cepheids in NGC 3109 and one in WLM. These five Cepheids are all short-period classical pulsators with periods ranging between 4.5 days and 8.6 days. Using the period-luminosity relation derived by Madore & Freedman we find distances to NGC 3109 and W LM that agree well with previous estimates obtained using other methods. \n \n Keywords: Cepheid variables; open cluster; galaxy distance scale; Hubble Space Telescope; Araucaria Project. 1. Introduction \n \n Open clusters provide an important tool for determining extragalactic distances because they contain many stars at nearly identical ages and chemical compositions. In addition, open clusters can be found over a wide range of galactocentric radii, allowing us to probe different environments. However, open clusters are relatively rare objects compared to field stars or globular clusters. Therefore, it is necessary to conduct surveys covering large areas of sky in order to obtain statistically significant samples of open clusters suitable for use as calibrators of the cosmic distance ladder. \n \n The Araucaria Project was initiated in 1998 with the goal of obtaining accurate distances to nearby galaxies via measurements of Cepheid variable stars associated with open clusters. This project uses data collected primarily with the Hubble Space Telescope s WFPC2 camera. A total of eight fields were observed during Cycle 9-10 of the HST program. Each field covers about 0.25 square degrees centered around a target galaxy. For each field, deep exposures were obtained in both the F555W and F850LP bands. Details regarding this project may be found in Pietrzyński et al. (2002) and references therein. \n \n 2. Searching for Cepheids Among Young Open",
        "watermark_text": "We report findings on distance determinations for two galaxies , NGC 3109 and WLM , built on observations made with the Hubble Space Telescope ( HST ) . We have utilized HST / WFPC2 pictures taken through filters F555W and F814W to search for Cepheids among small close galaxies housed within these objects .Our survey has resulted in the discovery of four fresh Cepheids in NGC 3109 and one in WLM . These five Cepheids are all short - process classical pulsators with periods ranging between 4 . 5 weeks and 8 . 6 hours .Using the period - luminosity relation derived by Madore & Freedman we find distances to NGC 3109 and W LM that agree well with previous estimates obtained using other methods . Keywords : Cepheid variables ; open cluster ; galaxy distance scale ; Hubble Space Telescope ; Araucaria Project .1 . Introduction Open clusters provide an important tool for determining extragalactic distances because they contain many stars at nearly identical ages and chemical compositions .In addition , open complexes can be found over a broad variety of galactocentric radii , allowing us to probe different environments . However , open complexes are fairly scarce objects compared to field stars or globular galaxies .Therefore , it is required to conduct surveys covering large areas of skies in order to obtain statistically substantial samples of open complexes suitable for use as calibrators of the cosmic diameter staircase . The Araucaria Project was initiated in 1998 with the objective of acquiring precise lengths to nearby galaxies via measurements of Cepheid variable stars associated with open complexes .This project utilizes information collected principally with the Hubble Space Telescope s WFPC2 telescope . A total of eight fields were detected during Cycle 9 - 10 of the HST project .Each field covers about 0 . 25 square degrees centered around a target galaxy . For each field , deep exposures were obtained in both the F555W and F850LP bands .Details regarding this project would be found in Pietrzyński et al . ( 2002 ) and links therein .2.Searching for Cepheids Among Young Open",
        "ori-fast-z-score": 0.7689218919450849,
        "water-fast-z-score": 7.831560082980487
    },
    {
        "original_text": "We study the solidification process in a model system consisting of particles interacting via repulsive soft-core potentials and subject to an external driving force. We show that, for sufficiently large values of the driving amplitude, the system undergoes a phase transition into a state where it behaves as if it were made up by two coexisting phases with different densities. The low-density phase is characterized by a slow relaxation towards equilibrium which can be described within mean-field theory. In contrast, the high density phase relaxes rapidly toward its stationary configuration. \n \n This behavior resembles closely what happens during the freezing of colloidal suspensions driven out of equilibrium by an applied shear flow. Our results suggest that this analogy may not only hold at the level of static properties but also when considering dynamical features such as the response to perturbations or the presence of aging effects. Finally we discuss possible extensions of our work to more realistic models describing the glassy dynamics observed experimentally in supercooled liquids. \nI. INTRODUCTORY REMARK\nIn recent years there has been growing interest on the possibility of observing analogies between the physics of glasses and other disordered systems  1  . One of these analogies concerns the role played by fluctuations in determining the macroscopic behaviour  2  , another one relates to the existence of metastable states  3  .\nThe aim of this Letter is to investigate whether similarities exist also in terms of dynamic properties. To this end we consider a simple model of glass-forming liquid  4  whose microscopic degrees of freedom are represented by N point-like particles moving in d dimensions under the action of pairwise interactions. These particles interact through a potential energy function U(r) = 4ε 1 − exp{−α(r/σ)}  2 /πσd, where r denotes their separation distance, ε sets the overall scale of energies, α controls the range of interaction (we take here α = 1), while σ fixes the length unit. For simplicity we assume periodic boundary conditions so that the total number of particles remains constant throughout the simulation. As usual, we define the reduced temperature T * ≡ kT/",
        "watermark_text": "We test the solidification mechanism in a model scheme consisting of molecules evolving via repulsive soft - core potentials and subject to an external driving field . We see that , for enough large values of the driving frequency , the system undergoes a phase shift into a state where it behaves as if it were made up by two coexisting phases with varying densities .The lowest - density phase is characterized by a slow relaxation towards equilibrium which can be described within mean - field model . In comparison , the high density phase relaxes rapidly toward its stationary position .This phenomenon resembles closely what comes during the freezing of colloidal suspensions driven out of equilibrium by an imposed shear flow . Our results show that this analogy might not only hold at the level of static properties but also when examining dynamical characteristics such as the response to perturbations or the presence of aging influences .Finally we pursue possible extend of our work to more realistic theories describing the glassy dynamics observed experimentally in supercooled liquids . I .INTRODUCTORY REMARK In recent years there has been growing interest on the prospect of discovering analogies between the physics of glasses and other disordered systems 1 . One of these analogies concerns the part played by fluctuations in determining the macroscopic behaviour 2 , another one refers to the existence of metastable states 3 .The goal of this Letter is to examine whether comparisons exist also in terms of dynamic characteristics . To this end we study a simple simulation of glass - creating solid 4 whose microscopic degrees of liberty are represented by N point - like particles moving in d dimensions under the action of pairwise interactions .These particles react through a potential energy relation U ( r ) = 4ε 1 − exp { −α ( r / π ) } 2 / πσd , where p denotes their separation distance , ε sets the overall scale of energies , α handles the range of interaction ( we took here α = 1 ) , while ρ fixes the length unit . For simplicity we suppose discrete border conditions so that the total number of particles stay constant throughout the model .As usual, we define the reduced temperature T * ≡ kT/",
        "ori-fast-z-score": -1.9826289642953603,
        "water-fast-z-score": 6.913932971601798
    },
    {
        "original_text": "The Chandra X-ray Observatory has observed the supernova remnant (SNR) produced by SN1987A in the Large Magellanic Cloud for over ten years, providing an unprecedented view into this young and energetic object.  The observations have revealed that the blast wave is interacting with dense circumstellar material surrounding the progenitor star at velocities up to 1000 km/sec.  This interaction produces bright knots of emission which are seen as moving outward through the shell of the remnant.  These knots appear to be composed primarily of oxygen-rich ejecta mixed with shocked interstellar gas.  In addition, there appears to be a large amount of hot plasma trapped behind the forward shock front.  We present here new results on these features based on our analysis of data obtained during the first year of the Chandra mission. The Chandra X-ray Observatory has observed  the supernova remnant ( SNR ) produced by SN1987A , in the Large Magellan ic Cloud , for over ten years . It provides an unprecedented view into this y oung and en erg i c obj ect .  T he obse rvations ha ve reve al ed tha t th e b las t wa ve is interactin g wi th d ens e circumstell ar m aterial surroundi ng th e proge nitor star-at-rou nd -velocities up to 1 000 k m/ sec . Thi s interac tion produ ces brigh t kn ots of emi ssion wh ich appea r to be co mp osed pri marily of oxyg ene -rico h ej ec ta mixe d w ith sh ocked int erstel lar ga s .",
        "watermark_text": "The Chandra X - ray Observatory has observed the supernova remnant ( SNR ) produced by SN1987A in the Large Magellanic Cloud for over ten years , providing an remarkable insight into this young and intense object . The studies have revealed that the explosion wave is interacting with heavy circumstellar material surrounding the progenitor star at velocities up to 1000 cm / sec .This coupling generates bright knots of emission which are seen as traveling outward through the shell of the remnant . These knots appear to be composed primarily of oxygen - laden ejecta blended with shocked interstellar gas .In addition , there seems to be a large amount of bright plasma trapped behind the front shock front . We present here new data on these characteristics focusing on our analysis of evidence derived during the first year of the Chandra mission .The Chandra X - ray Observatory has observed the supernova remnant ( SNR ) produced by SN1987A , in the Large Magellan ic Cloud , for over ten years . It provides an remarkable view into this y oung and en erg i c obj ect .T he obse rvations ha ve reve al ed tha t th e f las t wa ve is interactin g wi th d ens e circumstell ar m aterial surroundi ng th e proge nitor star - at - rou nd - velocities up to 1 000 k m / sec . Thi s interac tion produ ces brigh t kn ots of emi ssion wh ich appea r to be co mp osed pri marily of oxyg ene - rico h ej ec ta mixe d w ith sh ocked int erstel lar ga s .",
        "ori-fast-z-score": 1.0425720702853738,
        "water-fast-z-score": 5.421374765483944
    },
    {
        "original_text": "We introduce the concept of algebraic charge liquids, which are defined as ground states of Hamiltonians with local interactions that can be written in terms of fermionic creation and annihilation operators. We show how to construct such models for any finite group G by using an explicit representation of G on the Hilbert space of spinless fermions. The resulting model is exactly solvable when G has no non-trivial subgroups. In this case we find that there exists at least one phase transition between different phases characterized by distinct topological orders. For example, if G = Z2 × Z2 then our construction yields two gapped phases distinguished by their chiral central charges c− = 0 or 1. If G contains a nontrivial subgroup H then the system exhibits gapless excitations corresponding to particles transforming according to irreducible representations (irreps) of H. These results provide new insights into the classification problem of quantum many-body systems.",
        "watermark_text": "We introduce the notion of algebraic charge liquids , which are represented as ground regions of Hamiltonians with local interactions that can be written in terms of fermionic creation and annihilation operators . We see how to build such descriptions for any finite group G by using an explicit representation of G on the Hilbert space of spinless fermions .The resulting theory is precisely solvable when G has no non - trivial subgroups . In this situation we find that there exists at least one phase shift between various phases characterized by separate topological orders .For instance , if G = Z2 × Z2 then our construction gives two gapped phases distinguished by their chiral central charges c− = 0 or 1 . If G contains a nontrivial subgroup H then the system displays gapless excitations corresponding to ions transforming according to irreducible representations ( irreps ) of H . These data provide fresh insights into the characterization question of quantum several - bodies systems .",
        "ori-fast-z-score": -1.5,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "We study the holographic entanglement entropy for three-dimensional de Sitter space with gravitational Chern-Simons term by using the replica trick and the covariant phase-space method. We find that there is no logarithmic correction to the entanglement entropy, which agrees with previous results obtained via other methods. In addition, we show that the first-order corrections are proportional to the square root of the volume enclosed by the entangling surface. Finally, we calculate the second-order corrections and obtain an expression containing two terms. One of them has been previously found in Ref.  Phys. Rev. D 98 (2018) 084011  while another one is new. The latter can be written as a sum over all possible contractions between the Riemann tensor and its derivatives at the boundary points. This result shows that the gravitational Chern-Simons coupling constant plays a role similar to the Newton s constant in four dimensions.",
        "watermark_text": "We explore the holographic entanglement entropy for three - dimensional de Sitter space with gravitational Chern - Simons term by using the replica trick and the covariant phase - space method . We see that there is no logarithmic correction to the entanglement entropy , which agrees with previous findings obtained via other methods .In addition , we find that the first - order corrections are equal to the square root of the volume enclosed by the entangling surface . Finally , we estimate the second - order corrections and find an expression containing two terms .One of them has been previously found in Ref.Phys.Rev.D 98 (2018) 084011  while another one is new.The latter can be written as a sum over all possible contractions between the Riemann tensor and its derivatives at the boundary points . This result suggests that the gravitational Chern - Simons correlation function plays a role similar to the Newton s constant in four dimensions .",
        "ori-fast-z-score": 1.1920791213585393,
        "water-fast-z-score": 3.474396144861517
    },
    {
        "original_text": "We present an optimal design method to find the best occulting mask that can be used in direct imaging searches for extrasolar planets.  The proposed method is based on the concept of entropy maximization, which has been widely applied in many fields such as information theory and statistical mechanics.   We show how this concept can be extended into the field of optics by introducing a new quantity called optical entropy (OE).   By using OE we are able to quantify the amount of information contained within each point spread function produced by different masks.   This allows us to determine the most efficient mask shape with respect to its ability to detect faint companions around bright stars.   ...  more   In order to demonstrate our approach, we have performed numerical simulations to compare the performance of several candidate masks against one another.   Our results indicate that the proposed method provides significant improvement over existing methods when it comes to finding the optimal mask shapes for detecting faint companions around bright host stars.",
        "watermark_text": "We suggest an appropriate design algorithm to find the best occulting mask that can be used in direct imaging searches for extrasolar planets . The proposed approach is based on the idea of entropy maximization , which has been widely applied in different fields such as data physics and statistical mechanics .We see how this concept can be generalized into the field of optics by using a new quantity called optical entropy ( OE ) . By using OE we are able to quantify the quantity of information stored within each point spread function generated by various masks .This enables us to predict the most efficient mask shape with regard to its capacity to identify dim companions around bright stars . . . . more In order to test our approach , we have done mathematical simulations to study the performance of several candidate masks against one another .Our results show that the suggested method provides significant progress over existing techniques when it comes to finding the ideal mask shapes for detecting bright companions around bright host stars .",
        "ori-fast-z-score": -0.10846522890932808,
        "water-fast-z-score": 6.399448505650358
    },
    {
        "original_text": "The Casimir effect is one of the most important manifestations of quantum vacuum fluctuations and has been studied extensively for more than 50 years. The original prediction was made by H.B.G. Casimir, who showed that two parallel uncharged conducting plates attract each other with an attractive force inversely proportional to the fourth power of their separation distance. In this work we study how the magnitude of the Casimir force depends on the optical properties of the boundaries between which it acts. We consider three different cases corresponding to (i) perfectly reflecting mirrors, (ii) dielectric mirrors, and (iii) metallic mirrors. For all these cases we calculate numerically the Casimir energy density using the Lifshitz theory. Our results show that the Casimir force acting between two identical mirrors can be either repulsive or attractive depending on whether they are separated by air or water. This behavior arises due to the fact that the reflection coefficients at the mirror surfaces depend strongly on the surrounding medium.",
        "watermark_text": "The Casimir effect is one of the most important manifestations of quantum vacuum fluctuations and has been studied frequently for more than 50 years . The original forecast was making by H . B . G .Casimir , who demonstrated that two connected uncharged conducting plates attract each other with an attractive force inversely proportional to the fourth power of their separation distance . In this research we study how the severity of the Casimir force depends on the optical properties of the boundaries between which it works .We consider three different instances corresponding to ( i ) completely reflecting mirrors , ( ii ) dielectric windows , and ( iii ) metallic mirrors . For all these cases we estimate numerically the Casimir electricity distribution using the Lifshitz principle .Our results show that the Casimir force acting between two different mirrors can be either repulsive or attractive depending on whether they are apart by air or air . This phenomenon arises owing to the fact that the reflection values at the glass surfaces depend intensely on the nearby medium .",
        "ori-fast-z-score": -0.7171371656006361,
        "water-fast-z-score": 5.259005881071332
    },
    {
        "original_text": "The aim of this article is to present the basic concepts in Riemannian geometry that are needed for understanding the main results presented here.  The first section introduces some notation and definitions used throughout the text.   In particular we define what it means for two points on an n-dimensional manifold M to be close together (in terms of geodesic distance) or far apart.    We also introduce the concept of a local coordinate system at each point p ∈ M which allows us to describe any other point q near p by giving its coordinates with respect to these local charts.   Finally we give a brief description of how one can construct such a coordinate system locally around a given point using parallel transport along curves starting at p.    The second section describes the notion of a vector field X defined over all of M.   This is done by defining a map F : T M → R where T M denotes the tangent bundle of M.   Then we show that if X satisfies certain conditions then there exists a unique smooth function f : M → R such that X = grad(f).   Here grad(f) denotes the gradient of f.   For example, if M is a surface embedded in R3 then X could represent the velocity of a particle moving across M.   If we assume that the particles move according to Newton s laws of motion then the function f would correspond to the potential energy of the system under consideration.   The third section defines the concept of a tensor field as a generalization of vector fields.   Tensor fields allow us to associate several vectors...",
        "watermark_text": "The goal of this page is to provide the fundamental concepts in Riemannian topology that are needed for studying the main results presented here . The first section introduces some terminology and definitions found throughout the text .In particular we define what it means for two points on an n - dimensional manifold M to be close together ( in terms of geodesic length ) or far separated . We additionally introduce the notion of a local coordinate system at each point p ∈ M which allows us to define any other point q near r by giving its coordinates with regard to these local charts .Finally we give a brief description of how one can build such a coordinate system locally around a given point using parallel transport along curves beginning at p . The second chapter explains the notion of a vector field X defined over all of M . This is accomplished by constructing a mapping F : T M → R where T M denotes the tangent bundle of M . Then we prove that if X satisfies certain conditions then there exists a unique smooth function f : M → R such that X = grad ( f ) . Here grad ( f ) denotes the gradient of f . For instance , if M is a surface embedded in R3 then X could represent the velocity of a particle moving across M . If we suppose that the molecules moving according to Newton s rules of movement then the function r would correspond to the potential electricity of the system under consideration .The third chapter explains the idea of a tensor field as a generalization of vector spaces . Tensor varieties allow us to relate several vectors . . .",
        "ori-fast-z-score": -0.1781741612749496,
        "water-fast-z-score": 7.365059028153745
    },
    {
        "original_text": "We propose that the two branches in the mass distribution of neutron stars are due to different mechanisms for their formation, with one branch being formed by accretion-induced collapse (AIC) of white dwarfs into neutron stars, while another is formed through core-collapse supernovae (CCSNe). We show how this scenario can explain both the existence of massive pulsars as well as the absence of such objects in the observed sample of CCSNe remnants. The proposed model also explains why there have been no successful attempts so far at detecting gravitational waves emitted during AIC events. In addition we argue that our model provides an explanation for the apparent discrepancy between the masses inferred from observations of binary systems containing black holes or neutron stars on one hand, and those inferred from measurements of the radii of isolated neutron stars on the other. Finally, we discuss possible observational tests which could be used to verify our hypothesis.",
        "watermark_text": "We suggest that the two branches in the mass distribution of neutron galaxies are owing to different processes for their development , with one branch being created by accretion - caused merger ( AIC ) of white dwarfs into neutron galaxies , while another is formed through core - collapse supernovae ( CCSNe ) . We see how this situation can describe both the existence of large pulsars as well as the absence of such objects in the known sample of CCSNe fragments .The proposed theory even argues why there have been no successful proposals so far at detecting gravitational waves emitted during AIC events . In addition we claim that our model provides an reason for the apparent discrepancy between the masses inferred from measurements of binary systems featuring white holes or neutron galaxies on one hand , and those inferred from measurements of the radii of isolated neutron galaxies on the other .Finally , we explain possible observational tests which could be used to confirm our theory .",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 6.215188768538847
    },
    {
        "original_text": "We present new results on the formation of bipolar lobes by an expanding, rotating surface explosion (a  rotating detonation ). We use two-dimensional hydrodynamic simulations to show that such explosions can form disks with large opening angles if they are not too energetic or fast-expanding. The disk is formed because the outer layers of the star are swept up into a thin shell as it expands outward at high speed; this shell then breaks apart due to Rayleigh-Taylor instabilities. As the shell fragments, material falls back onto the central region of the exploded star forming two opposite jets which break out along the poles of the system. These jets drive the expansion of the bipolar lobes. Our models reproduce many observed properties of the Homunculus: its size, shape, kinematics, chemical composition, and luminosity evolution. In addition, we find that our model predicts a total mass loss rate for η Carinae during the Great Eruption of ~10^−4 M_sun/yr, consistent with observations.",
        "watermark_text": "We report new data on the formation of bipolar lobes by an evolving , moving surface explosion ( a rotating detonation ) . We use two - dimensional hydrodynamic simulations to see that such explosions can form cones with large opening angles if they are not too energetic or fast - expanding .The disk is formed because the exterior layers of the star are swept up into a thin shell as it expands outward at high velocity ; this shell then splits separated due to Rayleigh - Taylor instabilities . As the shell cracks , debris slides back onto the main region of the exploded star producing two opposite jets which break out along the poles of the system .These jets drive the expansion of the bipolar lobes . Our models reproduce many observed properties of the Homunculus : its size , shape , kinematics , chemical composition , and luminosity progression .In addition , we find that our model predicts a total mass loss rate for η Carinae during the Great Eruption of ~ 10 ^ −4 M _ sun / yr , compatible with observations .",
        "ori-fast-z-score": 2.264554068289191,
        "water-fast-z-score": 6.567206798038654
    },
    {
        "original_text": "We present the first detection of relativistically modulated X-ray fluxes from the Galactic Center black hole candidate SgrA*, using data obtained with Chandra and XMM-Newton observatories over an eight-year period (2000-2007). The observed light curves show clear periodic dips on time scales ranging between 20 minutes to several hours that are consistent with being caused by general relativistic effects near the event horizon of this supermassive black hole. We find no evidence for long-term variability or flaring activity during these observations. These results provide strong support for theoretical models where the emission is produced close to the last stable orbit around the central black hole via accretion disk instabilities. This work was supported by NASA grants NAG5-10842, NNG06GH50G, NNX07AH41G, and NSF grant AST-0707765. Subject headings: Black holes -accretion disks -X-rays",
        "watermark_text": "We present the first detection of relativistically modulated X - ray fluxes from the Galactic Center black hole member SgrA * , using data acquired with Chandra and XMM - Newton observatories over an eight - month period ( 2000 - 2007 ) . The observed light curves show consistent continuous dips on time ranges ranging between 20 seconds to several days that are compatible with being affected by general relativistic effects near the event horizon of this supermassive black hole .We see no evidence for large - term variability or flaring activity during these observations . These conclusions provide broad support for theoretical theories where the emission is produced nearly to the last steady orbit around the central black hole via accretion ring instabilities .This project was supported by NASA grants NAG5 - 10842 , NNG06GH50G , NNX07AH41G , and NSF grant AST - 0707765 . Subject headings : Black holes - accretion disks - X - rays",
        "ori-fast-z-score": -1.0327955589886444,
        "water-fast-z-score": 4.131182235954578
    },
    {
        "original_text": "We study mesoscopic fluctuations of the supercurrents flowing through two weakly coupled superconductors with different transparencies and temperatures, using the Usadel equations for quasiclassical Green s functions. We show that the current noise is suppressed by increasing transparency between the leads or decreasing temperature. The suppression can be explained as due to an increase of the effective junction length caused by Andreev reflection at the interface. In addition we find that the shot-noise power decreases when the phase difference across the junction increases. This effect originates from the dependence of the density of states on the phase difference. Finally, we discuss how our results are related to recent experiments performed on diffusive SNS junctions. \nI. INTRODUCTORY REMARK\nThe Josephson effect describes macroscopically coherent transport of Cooper pairs across weak links connecting two superconducting electrodes  1  . It has been observed experimentally over many decades  2  , but only recently have researchers begun to explore its microscopic origins  3  .\nIn this work we consider a system consisting of two weakly-coupled superconductors (S) connected via a normal metal region (N). Such systems are known as diffusive SNS junctures  4  . They exhibit interesting phenomena such as the proximity effect  5  , which causes the formation of a minigap inside the N region  6  . Another important feature of these devices is their ability to carry both charge and spin currents  7, 8  . These properties make them promising candidates for applications ranging from quantum information processing  9  to magnetic field sensing  10  .\nRecently there has been renewed interest in studying the physics of diffusive SNS juncture  11  -  16  . For example, it was shown theoretically that the critical current I c depends strongly on the transparency T = R Q /R N of the NS interfaces  17  where R Q and R N are the resistance quantum and the resistance of the N region respectively. Experimentally, this prediction could not yet be confirmed because of difficulties associated with fabricating clean NS interfaces  18  . However, several groups managed to observe similar effects indirectly  19, 20  .",
        "watermark_text": "We test mesoscopic fluctuations of the supercurrents rushing through two tightly correlated superconductors with varying transparencies and temperatures , using the Usadel equations for quasiclassical Green s functions . We see that the current noise is suppressed by expanding transparency between the leads or decreasing temperature .The suppression can be understood as owing to an increase of the effective junction size caused by Andreev reflection at the interface . In addition we find that the shot - noise power decreases when the phase change across the junction increases .This phenomenon originates from the dependence of the density of states on the phase change . Finally , we talk how our findings are related to recent experiments conducted on diffusive SNS junctions .I . INTRODUCTORY REMARK The Josephson effect explains macroscopically consistent transport of Cooper pairs across weak links connecting two superconducting electrodes 1 .It has been observed experimentally over numerous years 2 , but only lately have researchers begun to examine its microscopic origins 3 . In this research we study a system consisting of two weakly - coupled superconductors ( S ) connected via a normal metal area ( N ) .Such structures are known as diffusive SNS junctures 4 . They show exciting phenomena such as the contact influence 5 , which forms the formation of a minigap inside the N region 6 .Another important feature of these systems is their potential to carry both charge and spin currents 7 , 8 . These properties make them promising candidates for applications extending from molecular data processing 9 to magnetic field monitoring 10 .Recently there has been continued interest in investigating the physics of diffusive SNS juncture 11 - 16 . For instance , it was shown theoretically that the critical potential I c depends strongly on the transparency T = R Q / R N of the NS interfaces 17 where R Q and R N are the tolerance quantum and the resistance of the N region respectively .Experimentally , this measurement came not already be verified because of troubles associated with fabricating safe NS interfaces 18 . However , various groups helped to observe comparable effects indirectly 19 , 20 .",
        "ori-fast-z-score": -0.5895063447465633,
        "water-fast-z-score": 8.446044301071616
    },
    {
        "original_text": "We report on the results of an analysis of data taken by the INTEGRAL satellite in 2003 and 2004 . We find that the hard X-ray emission from this source is modulated with a period of about one year. The amplitude of the modulation is at least 50% (3 sigma). This result suggests that the source may be similar to other galactic sources which show evidence for periodic variability due to accretion onto a neutron star or black hole. \n \n Keywords: High energy astrophysics - Gamma rays - Black holes - Neutron stars - Accreting binaries - Pulsar wind nebulae - Inverse Compton scattering - Galactic center - Galaxy - Supernova remnants - Blazars - AGN - Cosmic rays - Fermi/LAT - TeV blazar - Variability - Periodicities - INTEGRAL - X-rays - Hard X-rays - Soft gamma-ray bursts - Transient objects - Radio pulsar",
        "watermark_text": "We report on the conclusion of an assessment of measurements taken by the INTEGRAL satellite in 2003 and 2004 . We see that the hard X - ray radiation from this source is modulated with a period of about one year .The amplitude of the modulation is at least 50 % ( 3 sigma ) . This result suggests that the origin may be similar to other galactic sources which show proof for periodic variability due to accretion onto a neutron galaxy or black hole .Keywords : High energy astrophysics - Gamma rays - Black holes - Neutron stars - Accreting binaries - Pulsar wind nebulae - Inverse Compton scattering - Galactic center - Galaxy - Supernova remnants - Blazars - AGN - Cosmic rays - Fermi / LAT - TeV blazar - Variability - Periodicities - INTEGRAL - X - radiation - Hard X - radiation - Soft gamma - ray waves - Transient objects - Radio pulsar",
        "ori-fast-z-score": 0.29488391230979427,
        "water-fast-z-score": 3.5386069477175313
    },
    {
        "original_text": "We present fitting formulae for the illumination of accretion disks by hot spots, as seen in Schwarzschild and rotating black holes (Kerr). The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton scattering. We find that the dependence on the spin parameter is weak when the spot size is small compared to the radius at which photons decouple from matter. For larger spots we find that the effect increases strongly towards prograde spins. Our results can be used to estimate the effects of relativistic Doppler boosting and gravitational lensing on observed spectra. They may also provide useful input into models of X-ray reflection spectroscopy. \nIntroduction\n\nAccreting black holes produce bright emission lines in their X-ray spectrum due to reprocessing of hard X-rays emitted near the event horizon by cold material orbiting close to the equatorial plane. These features have been studied extensively over many years both observationally and theoretically (see Reynolds & Nowak 2003 , Done et al 2004 . In particular, they show strong red-shifts indicating that the emitting gas orbits rapidly around the black hole. This rapid rotation causes additional shifts in energy due to relativistic Doppler boosts and gravitational lensing. Relativistic effects become more important if the emitting region has a high degree of rotational support or is viewed nearly face-on. It is therefore necessary to take these effects into account when interpreting observations of such systems. \n\nIn this work we consider the case where the illuminating source is located above the disk surface but below its photosphere. Such sources include magnetic flares produced within the disk itself or active regions associated with the inner edge of the disk. We assume that the disk is optically thick so that all radiation reaching it is absorbed and re-emitted locally. We use Monte Carlo simulations to calculate the emergent flux from the disk under various assumptions about the geometry of the system.\n\nThe main goal of our study was to develop simple analytical expressions describing how the shape of the line profile depends on the properties of the system. To do this we performed extensive numerical calculations covering a wide range",
        "watermark_text": "We present fitting formulae for the illumination of accretion disks by hot spots , as shown in Schwarzschild and rotating black holes ( Kerr ) . The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton absorption .We see that the dependence on the spin vector is weak when the spot size is tiny relative to the radius at which photons decouple from matter . For larger spots we find that the impact grows highly towards prograde spins .Our results can be used to estimate the effects of relativistic Doppler boosting and gravity lensing on measured spectra . They might additionally offer useful input into estimates of X - ray reflection spectroscopy .Introduction Accreting black holes create bright emission lines in their X - ray spectrum due to reprocessing of hard X - rays generated near the event horizon by cold matter orbiting close to the equatorial plane . These features have been studied frequently over numerous years both observationally and theoretically ( saw Reynolds & Nowak 2003 , Done et al 2004 .In particular , they show intense red - shifts suggesting that the emitting gas orbits rapidly around the dark hole . This rapid rotation creates additional shifts in energy due to relativistic Doppler boosts and gravity lensing .Relativistic effects become more essential if the emitting area has a high degree of rotational support or is viewed virtually face - on . It is consequently required to take these consequences into consideration when interpreting observations of such systems .In this research we imagine the case where the illuminating source is situated above the disk boundary but below its photosphere . Such sources include magnetic flares created within the disk itself or active regions associated with the inner boundary of the disk .We assume that the disk is optically dense so that all light reaching it is absorption and re - radiated locally . We use Monte Carlo simulations to estimate the emergent flux from the disk under various statements about the topology of the system .The main goal of our research was to develop primitive analytical expressions relating how the form of the line profile depends on the properties of the system . To do this we performed extensive numerical measurements encompassing a broad range",
        "ori-fast-z-score": -0.1543033499620919,
        "water-fast-z-score": 8.076923076923077
    },
    {
        "original_text": "The space elevator is an important project in the future space exploration, which can provide transportation between Earth orbit and ground with high efficiency. The electrostatic climber (EC) is one key component of the space elevator system that will be used to transport passengers or cargoes up and down along the cable. In this work, we present a novel design concept of EC based on the principle of electrodynamic levitation. A prototype has been built according to our proposed design. It consists of two main parts: the upper platform and lower platform. The upper platform contains four permanent magnets arranged in square shape; while the lower platform includes eight coils connected in series. The experimental results show that the maximum lift force generated by the EC reaches about 1 N at the current density of 0.5 A/mm2 . This value meets the requirement of the space elevator application. Moreover, it also shows good stability when the load changes.",
        "watermark_text": "The space lift is an important project in the future space exploration , which can provide transit between Earth orbit and ground with high efficiency . The electrostatic climber ( EC ) is one key portion of the spacecraft elevator system that will be used to transport passengers or cargoes up and down along the cable .In this project , we present a new design concept of EC based on the principle of electrodynamic levitation . A prototype has been built according to our proposed design .It consists of two principal portions : the higher platform and lower platform . The higher platform includes four permanent magnets grouped in square position ; while the lower platform includes eight coils connected in series .The empirical results show that the maximum lift pressure generated by the EC reaches about 1 N at the current density of 0 . 5 A / mm2 . This value meets the requirement of the space elevator application .Moreover , it also shows excellent stability when the load changes .",
        "ori-fast-z-score": -0.22941573387056174,
        "water-fast-z-score": 3.988620176087328
    },
    {
        "original_text": "We consider the problem of energy-efficient modulation for downlink transmissions over code-division multiple-access (CDMA) networks, where each user has an individual delay constraint and is equipped with a rechargeable battery that can be charged by harvesting ambient radio-frequency signals. We formulate this problem as a noncooperative game between users competing for limited power resources under their own constraints on transmission rates and delays. In particular, we show how to compute Nash equilibria of such games using convex optimization techniques. Our numerical results demonstrate significant gains in terms of both network throughput and energy efficiency compared to conventional schemes based on fixed-rate transmissions. The proposed approach also allows us to quantify tradeoffs among different performance metrics, including average packet delay, outage probability, and energy consumption per bit. This work was supported by NSF grants CNS-0932040 and CCF-0939370. \n \n Code available at http://arxiv.org/abs/1206.5481",
        "watermark_text": "We consider the issue of electricity - efficient modulation for downlink transmissions over code - division multiple - access ( CDMA ) networks , where each consumer has an individual delay constraint and is equipped with a rechargeable battery that can be charged by collecting ambient broadcast - frequency signals . We formulate this situation as a noncooperative contest between operators competing for limited power assets under their own restrictions on transmission rates and delays .In particular , we study how to compute Nash equilibria of such players utilizing convex optimization schemes . Our numerical findings show considerable gains in terms of both network throughput and energy efficiency compared to conventional systems relying on fixed - frequency transmissions .The proposed approach also enables us to quantify tradeoffs among different performance metrics , notably mean packet delay , outage likelihood , and energy consumption per bit . This effort was supported by NSF grants CNS - 0932040 and CCF - 0939370 .Code available at http : / / arxiv . org / abs / 1206 . 5481",
        "ori-fast-z-score": -1.0392304845413263,
        "water-fast-z-score": 5.114896104728048
    },
    {
        "original_text": "In this article, we provide an overview on the recent advances and challenges in energy-efficient resource allocation for wireless networks using game-theoretical approaches. We first introduce some basic concepts related to games and then present several representative works that have been done recently by researchers worldwide. Finally, we conclude with open research issues and future directions. In this article, we provide a survey on the recent advances and remaining challenges in energy-efficient radio resource management (RRM) for wireless networks using game theoretical approaches. The main goal is to show how these techniques can be used to improve network performance while reducing power consumption at each node. To achieve this objective, we first give a brief introduction about the concept of games as well as their applications in communication systems. Then, we review existing work on RRM problems formulated as non-cooperative or cooperative games. Finally, we discuss open research issues and possible future directions. This article is organized into four sections. Section II introduces some background information on games and their application in communications. Section III presents different types of games applied to solve RRM problems. Section IV discusses open research issues and concludes the article.",
        "watermark_text": "In this page , we provide an overview on the recent developments and challenges in electricity - efficient energy management for wireless networks employing game - theory techniques . We first introduce some fundamental concepts related to games and then present many representative works that have been performed recently by researchers worldwide .Finally , we conclude with open work issues and future directions . In this article , we provide a survey on the recent developments and remaining problems in energy - efficient radio resource control ( RRM ) for wireless networks employing game theory techniques .The main goal is to indicate how these tactics can be used to improve network reliability while reducing electricity usage at each node . To achieve this objective , we first offer a brief introduction about the idea of games as well as their implementation in transmission systems .Then , we review current work on RRM questions constructed as non - cooperative or cooperative games . Finally , we review open research concerns and possible future paths .This page is organized into four elements . Section II gives some background data on games and their application in communications .Section III presents different kinds of games applicable to solve RRM challenges . Section IV examines open scientific issues and concludes the article .",
        "ori-fast-z-score": -0.8250286473253902,
        "water-fast-z-score": 7.058578427117228
    },
    {
        "original_text": "We present new high resolution observations of the interstellar medium in the direction of the North Ecliptic Pole, made with the Westerbork Synthesis Radio Telescope at 1.4 GHz. The data reveal an extended filamentary structure that is traced by neutral hydrogen emission lines as well as continuum emission associated with free-free processes. We find evidence for two distinct components to this filamentary structure; one component has a relatively low column density but extends over several degrees on the sky while another component appears more compact and denser. These results are discussed within the context of recent WMAP measurements which show excess microwave emission towards the north ecliptic pole region. This work was supported by NASA grant NAG5-10842. Keywords: ISM, radio astronomy, H I 21 cm line, WMAP, filaments, North Ecliptic Pole Region . \nIntroduction\n\nThe Wilkinson Microwave Anisotropy Probe (WMAP) (Bennett et al., 2003a ) measured significant excesses of microwave emission above the expected cosmic background radiation level along three different lines-of-sight through the northern hemisphere. In particular, there were large excesses observed near the North Ecliptic Poles (NEPs). Subsequent studies have shown that these excesses can be explained by thermal bremsstrahlung emission from ionized gas located between us and distant galaxies (Finkbeiner 2004 , Davies et al 2005 .\nIn addition to the NEP regions, other areas of interest include the Perseus-Pisces supercluster complex (Davies et al 2006) , the Coma cluster (Vogeley & Birkinshaw 1996) and the Virgo Cluster (Taylor et al 2002) . All of these structures contain substantial amounts of hot plasma and it seems likely that they will also contribute significantly to the total foreground signal detected by WMAP. \nObservations of the diffuse galactic radio emission provide important information about the physical conditions in the interstellar medium (ISM), such as temperature, pressure and magnetic field strength. However, due to its faintness relative to point sources, only recently have we",
        "watermark_text": "We report new high resolution measurements of the interstellar material in the direction of the North Ecliptic Pole , made with the Westerbork Synthesis Radio Telescope at 1 . 4 GHz . The data reveal an extended filamentary composition that is traced by neutral hydrogen emission lines as well as continuum emission associated with free - free processes .We get data for two separate constituents to this filamentary composition ; one part has a fairly lowest column thickness but spreads over numerous degrees on the sky while another component appears more compact and denser . These conclusions are discussed within the context of recent WMAP measurements which show additional microwave emission towards the north ecliptic pole region .This project was supported by NASA loan NAG5 - 10842 . Keywords : ISM , radio astronomy , H I 21 cm line , WMAP , filaments , North Ecliptic Pole Region .Introduction The Wilkinson Microwave Anisotropy Probe ( WMAP ) ( Bennett et al . , 2003a ) measured significant excesses of microwave emission above the expected cosmic background radiation level along three different lines - of - view through the northern hemisphere . In particular , there were large excesses observed near the North Ecliptic Poles ( NEPs ) .Subsequent researchers have shown that these excesses can be explained by thermal bremsstrahlung emission from ionized gas located between us and distant galaxies ( Finkbeiner 2004 , Davies et al 2005 . In addition to the NEP regions , other areas of focus involve the Perseus - Pisces supercluster complex ( Davies et al 2006 ) , the Coma cluster ( Vogeley & Birkinshaw 1996 ) and the Virgo Cluster ( Taylor et al 2002 ) .All of these structures hold substantial deposits of hard gas and it appears probably that they will also contribute considerably to the total foreground light detected by WMAP . Observations of the diffuse galactic radio emission reveal important information about the physical conditions in the interstellar medium ( ISM ) , such as temperature , pressure and magnetic field intensity .However , owing to its faintness relative to point sources , only lately have we",
        "ori-fast-z-score": 1.4852968963237645,
        "water-fast-z-score": 6.850168759240548
    },
    {
        "original_text": "We present an approach to the analysis of metabolic networks based on information-theoretic concepts, in particular Shannon s entropy measure. We show that this concept can be extended by considering not only single metabolites but also pairs or higher-order tuples of them as elementary units for measuring entropy. This leads us to define so-called pathway entropies which are used to quantify how much uncertainty is associated with different parts of the network. The proposed method allows one to identify those parts of the network where most of the uncertainty resides. In addition we introduce a novel way of visualizing metabolic networks using these new entropy-based quantities. Finally, we demonstrate our approach by applying it to two examples taken from biochemistry literature. Metabolic networks play important roles in many biological processes such as cell growth and development  1  . They consist of chemical reactions transforming various compounds into each other  2  , e.g., glucose molecules are transformed into energy-rich adenosine triphosphate (ATP) molecules via glycolysis  3  .\nThe study of metabolic networks has been attracting increasing interest over recent years  4  -  8  . One reason for this growing interest lies in their potential use as drug targets  9  . Another motivation comes from the fact that they provide valuable insights into cellular metabolism  10  . For example, the identification of key enzymes involved in certain diseases may help to develop drugs against these diseases  11  . Furthermore, metabolic networks have been shown to exhibit scale-free properties  12  similar to those observed in social systems  13  . These findings suggest that there might exist common principles underlying both types of networks  14  .\nIn order to understand the functioning of metabolic networks better, several mathematical models have been developed  15  -  17  . Amongst others, stoichiometric approaches  18  try to describe all possible states of a given metabolic system mathematically. However, due to the high number of degrees of freedom inherent in such models  19  , it becomes difficult to analyze large metabolic networks  20  . Therefore, alternative methods have been suggested  21  -  23  .",
        "watermark_text": "We present an perspective to the analysis of biological groups based on knowledge - theoretic concepts , in example Shannon s entropy measure . We see that this concept can be generalized by treating not only single metabolites but also pairs or greater - order tuples of them as elementary units for determining entropy .This leads us to define so - called pathway entropies which are using to quantify how many uncertainty is associated with various parts of the network . The proposed approach allows one to identify those parts of the network where most of the doubt lies .In addition we provide a new method of visualizing molecular connections utilizing these new entropy - based quantities . Finally , we prove our approach by using it to two examples taken from biochemistry literature .Metabolic systems play essential roles in different biological pathways such as cell development and growth 1 . They involve of chemical processes transforming various compounds into each other 2 , e . g . , glucose molecules are transformed into energy - rich adenosine triphosphate ( ATP ) molecules via glycolysis 3 .The investigation of biological groups has been drawing rising interest over recent periods 4 - 8 . One reason for this increasing interest lies in their potential use as drug targets 9 .Another motivation comes from the fact that they give valuable insights into cellular metabolism 10 . For instance , the discovery of key enzymes active in different diseases might help to develop medication against these diseases 11 .Furthermore , metabolic networks have been shown to exhibit scale - free properties 12 similar to those observed in social systems 13 . These studies imply that there might exist common principles governing both types of networks 14 .In order to explain the structures of metabolic networks better , various computational models have been created 15 - 17 . Amongst others , stoichiometric methods 18 try to explain all possible states of a given metabolic system mathematically .However , owing to the high number of degrees of autonomy inherent in such studies 19 , it becomes impossible to analyze large metabolic networks 20 . Therefore , alternative techniques have been proposed 21 - 23 .",
        "ori-fast-z-score": -0.909717652294684,
        "water-fast-z-score": 8.743828992755144
    },
    {
        "original_text": "We study the linear stability properties of coronal beams in the presence of background plasma and magnetic field fluctuations, using a multi-fluid model for ions and electrons. We find that the growth rates are strongly dependent on the angle between the wavevector k and the mean magnetic field B 0 . In particular, we show that there is an instability at oblique angles with respect to B 0 , which has been previously overlooked by previous studies based on single-fluid models. The new mode arises due to the coupling between the Alfvénic modes associated with each species (ions and electrons). This mode can be excited even when the electron temperature anisotropy T e? /T ez < 1, where ? denotes directions perpendicular to B 0 .\nThe results presented here may have important implications for understanding the origin of solar radio bursts observed during solar flares. Introduction: Coronal mass ejections (CMEs) are large-scale expulsions of magnetized plasma from the Sun s corona into interplanetary space. They play an essential role in driving geomagnetic storms and are believed to be responsible for many other phenomena such as solar energetic particles  e.g., Reames et al. (1998) , Kahler & Ragot (2007)  , solar radio bursts  e.g., Aschwanden (2004)  , and white-light flares  e.g., Benz (2008)  . CME initiation involves the destabilization of a current sheet formed below the erupting flux rope through reconnection processes  e.g., Forbes & Priest (1995) ; Lin & Forbes (2000); Aulanier et al. (2010)  . However, it remains unclear how this process leads to the acceleration of the bulk plasma outflow along open magnetic fields lines. Recent observations suggest that the initial phase of the eruption is characterized by the formation of a narrow jet-like structure called a  flare loop  or  sheath   e.g., Liu et al. (2009a Liu et al. ( , 2009b ; Cheng et al. (2011); Jiang et al. (2012",
        "watermark_text": "We research the linear stability properties of coronal beams in the presence of background plasma and magnetic force fluctuations , using a multi - fluid model for ions and electrons . We see that the development rates are strongly dependent on the angle between the wavevector k and the mean magnetic force B 0 .In particular , we prove that there is an instability at oblique directions with regard to B 0 , which has been previously overlooked by earlier studies relying on single - fluid models . The new mode occurs due to the interaction between the Alfvénic configurations involved with each species ( atoms and electrons ) .This mode can be excited even when the electron thermal anisotropy T e ? / T ez < 1 , where ?denotes directions perpendicular to B 0 . The results presented here possibly have important implications for studying the origin of solar radio flashes seen during thermal flares .Introduction : Coronal mass ejections ( CMEs ) are big - scale expulsions of magnetized plasma from the Sun s corona into interplanetary space . They play an essential part in causing geomagnetic winds and are considered to be responsible for numerous other processes such as solar energetic particles e . g . , Reames et al .( 1998 ) , Kahler & Ragot ( 2007 ) , sun wireless flare e . g . , Aschwanden ( 2004 ) , and white - light flares e . g . , Benz ( 2008 ) . CME initiation consists the destabilization of a current sheet formed below the erupting flux rope through reconnection pathways e . g . , Forbes & Priest ( 1995 ) ; Lin & Forbes ( 2000 ) ; Aulanier et al .( 2010 ) . However , it remains unsure how this process results to the acceleration of the bulk plasma outflow along open magnetic fields lines .Recent measurements suggest that the first phase of the volcano is characterized by the formation of a thin jet - like structure named a flare loop or sheath e . g . , Liu et al . ( 2009a Liu et al .( , 2009b ; Cheng et al . ( 2011 ) ; Jiang et al .(2012",
        "ori-fast-z-score": -1.007017629956027,
        "water-fast-z-score": 5.202924421439472
    },
    {
        "original_text": "The influence of pulsed magnetic fields on the relaxation processes in HTSC was investigated by measuring the temperature dependence of resistance and Hall coefficient for samples with different oxygen content (d = 0, 1). The results show that the application of pulsed magnetic fields leads to an increase in the resistivity and Hall mobility of the sample with d = 0. This effect is explained as due to the appearance of additional scattering centers caused by defects formed during the process of magnetization reversal. In contrast, no significant changes were observed in the case of the sample with d=1. It can be assumed that this difference is associated with the presence of structural disordering in the crystal lattice of the latter compound. \n \n Keywords: High-Tc Superconductor, Pulsed Magnetic Field, Relaxation Processes, Defects Formation, Magnetoresistance, Hall Effect. Introduction \n \n Investigation of relaxation phenomena in high temperature superconductors under the action of pulsed external magnetic fields has been attracting considerable attention recently  1 - 5  . These studies are important both for understanding the physics of these materials and for practical applications  6  -  8  . \n \n In particular, it should be noted that the investigation of relaxation processes in HTSCs allows one to study the dynamics of defect formation  9  , which plays an important role in determining their transport properties  10  . At present there are several models describing the mechanism of defect generation  11  -  13  . However, none of them takes into account the possibility of defect formation induced by the action of pulsed fields  14  . \nExperimental details\n\nIn our work we used single crystals of two compounds with different oxygen content: HoBa 2 Cu 3 O 7−δ (HBS) and YBa 2 Cu 3 O 6+δ (YBS), grown using the floating zone method  15  . The oxygen concentration in the samples was determined by iodometric titration  16  . The typical size of the samples was about 5 × 4 mm 2 . The measurements were carried out in liquid helium cryostats equipped with pulse magnets  17  . The maximum value of the magnetic induction reached up to B max =",
        "watermark_text": "The impact of pulsed magnetic fields on the relaxation processes in HTSC was investigated by monitoring the temperature dependence of resistance and Hall coefficient for specimens with various oxygen composition ( d = 0 , 1 ) . The results show that the introduction of pulsed magnetic fields leads to an increase in the resistivity and Hall velocity of the sample with d = 0 .This phenomenon is understood as owing to the appearance of added scattering centers caused by defects formed during the process of magnetization reversal . In comparison , no major changes were detected in the case of the sample with d = 1 .It can be assumed that this contrast is associated with the presence of structural disordering in the crystal structures of the latter chemical . Keywords : High - Tc Superconductor , Pulsed Magnetic Field , Relaxation Processes , Defects Formation , Magnetoresistance , Hall Effect .Introduction Investigation of relaxation effects in high heat superconductors under the action of pulsed external magnetic waves has been drawing greater notice lately 1 - 5 . These studies are important both for studying the physics of these structures and for useful use 6 - 8 .In particular , it should be mentioned that the examination of relaxation processes in HTSCs allows one to study the dynamics of defect form 9 , which plays an important role in establishing their transport properties 10 . At currently there are several models explaining the process of defect generation 11 - 13 .However , none of them took into consideration the danger of defect development caused by the activity of pulsed fields 14 . Experimental details In our work we using single crystals of two compounds with varying oxygen composition : HoBa 2 Cu 3 O 7−δ ( HBS ) and YBa 2 Cu 3 O 6 + δ ( YBS ) , grown using the sliding zone method 15 .The oxygen composition in the tests was calculated by iodometric titration 16 . The typical size of the samples was about 5 × 4 mm 2 .The measurements were carried out in pure helium cryostats fitted with pulse magnets 17 . The maximum value of the magnetic induction reached up to B max =",
        "ori-fast-z-score": -1.1832159566199232,
        "water-fast-z-score": 7.268326590665242
    },
    {
        "original_text": "We present an approach to primordial evolution based on the finitary process soup (FPS) model, which is a generalization of the standard quantum field theory. The FPS consists of all possible finite sequences of elementary processes that can be constructed by applying a set of basic operations to a given initial sequence. We show how this formalism allows one to describe and analyze various aspects of primordial evolution such as entropy production, particle creation, time dilation etc., using only few parameters characterizing the initial state. In particular we demonstrate that the FPS provides a natural description for the inflationary scenario with no need to introduce additional fields or particles beyond those already existing within the Standard Model. Finally, we discuss some open problems related to our approach. PACS numbers: 04.60.Kz, 11.10.Wx, 12.20.Ds, 98.80.Cq . \nI. INTRODUCTORY REMARkS\n\nThe idea behind the finitary process soup  1  , also known as the  quantum soup   2  , is very simple - it represents any physical system as a collection of all its possible states. This concept has been used successfully in many areas of physics including statistical mechanics  3  , condensed matter  4  , nuclear  5  and atomic  6  physics, cosmology  7, 8  , quantum gravity  9  , string theory  10, 11  .\nIn this work we apply the FPS formalism to study primordial evolution during the early stages of the universe s expansion. Our main goal will be to develop a general framework allowing us to describe different phenomena associated with the Big Bang without introducing new degrees of freedom not included into the Standard Model  12  . As we shall see below, the FPS naturally leads to a description of the inflationary scenario  13  where the inflaton field  14  emerges as a consequence of the underlying dynamics rather than being introduced ad hoc. \nII. THE FINITARY PROCESS SOUP MODEL AND ITS APPLICATION TO PRIMORDIAL EVOLUTION A. General Description\nLet us start by briefly reviewing the key features of the FPS formalism",
        "watermark_text": "We present an view to primordial evolution based on the finitary process soup ( FPS ) model , which is a generalization of the standard quantum field model . The FPS consists of all possible finite sequences of elementary processes that can be built by using a setting of fundamental operations to a given original sequence .We illustrate how this formalism allows one to explain and analyze numerous elements of primordial development such as entropy production , particle creation , time dilation etc . , using only few parameters characterizing the first state . In particular we prove that the FPS provides a natural characterization for the inflationary scenario with no requirement to introduce extra fields or particles beyond those already emerging within the Standard Model .Finally , we explain some open problems related to our approach . PACS scores : 04 . 60 . Kz , 11 . 10 . Wx , 12 . 20 . Ds , 98 . 80 . Cq .I . INTRODUCTORY REMARkS The idea behind the finitary process soup 1 , sometimes called as the quantum soup 2 , is very simple - it represents any physical system as a collection of all its potential states .This concept has been used successfully in multiple fields of science including statistical mechanics 3 , condensed matter 4 , nuclear 5 and atomic 6 theory , cosmology 7 , 8 , quantum gravitational 9 , string theory 10 , 11 . In this research we apply the FPS formalism to study primordial development during the early stages of the universe s evolution .Our main goal will be to develop a general template allowing us to explain different processes associated with the Big Bang without using new degrees of liberty not incorporated into the Standard Model 12 . As we shall get below , the FPS naturally comes to a description of the inflationary scenario 13 where the inflaton field 14 emerges as a consequence of the fundamental dynamics rather than being established ad hoc .II.THE FINITARY PROCESS SOUP MODEL AND ITS APPLICATION TO PRIMORDIAL EVOLUTION A.General Description Let us begin by briefly examining the key features of the FPS formalism",
        "ori-fast-z-score": 0.6069769786668839,
        "water-fast-z-score": 7.7748158302322405
    },
    {
        "original_text": "We present the results on the metallicity distribution functions (MDFs) for stars at different latitudes and distances from the Galactic plane, based on spectroscopic data obtained by the Sloan Digital Sky Survey (SDSS). We find that MDFs are similar to each other within errors except those at |b| > 30° where there is an excess of metal-poor stars compared to the disk population. The fraction of metal-poor stars increases towards higher latitude. This suggests that the halo component becomes more dominant as one goes farther away from the Galactic plane. In addition we also found that the mean metallicities decrease slightly toward larger distance from the Galactic center. These findings suggest that the outer part of our Galaxy has been formed through accretion processes. \n \n Keywords: Metallicity Distribution Function; Halo; Disk; High Latitude Stars; Sloan Digital Sky Survey \n \n 1 Introduction \n \n It is well known that the Milky Way consists of three main components -the thin disk, thick disk and halo. However, it remains unclear how these components were assembled during its formation history. To understand this process, it is important to study their chemical compositions separately because they may have experienced different evolutionary histories. For example, the age-metallicity relation shows that the halo was formed earlier than the disk(e.g., Twarog 1980), while the abundance ratios such as  Fe/H  show that the halo contains many old low-mass stars which should be destroyed by supernova explosions if the halo had been formed recently like the disk(e. g., Nissen & Schuster 1997). \n \n Many studies have investigated the properties of the halo using various samples of distant halo stars selected mainly from proper motion surveys or photometric parallax measurements. Recently, large spectroscopic surveys such as the Sloan Digital Sky Surveys (SDSS) (York et al. 2000) , RAVE survey (Steinmetz 2003 )and SEGUE survey (Yanny et al. 2009 )have provided us with much better information about the chemical composition of the halo. Using",
        "watermark_text": "We present the conclusion on the metallicity distribution functions ( MDFs ) for stars at different latitudes and distances from the Galactic plane , using on spectroscopic data derived by the Sloan Digital Sky Survey ( SDSS ) . We see that MDFs are comparable to each other within errors except those at | b | > 30° where there is an accumulation of steel - weak stars compared to the disk community .The percentage of metal - low stars increases towards higher latitude . This implies that the halo element increases more prevalent as one goes deeper away from the Galactic jet .In addition we also discovered that the mean metallicities reduce slightly toward larger distance from the Galactic center . These studies imply that the exterior part of our Galaxy has been formed through accretion cycles .Keywords : Metallicity Distribution Function ; Halo ; Disk ; High Latitude Stars ; Sloan Digital Sky Survey 1 Introduction It is well established that the Milky Way consists of three principal components - the narrow disk , thick disk and halo . However , it remains unsure how these constituents were assembled during its formation history .To understand this process , it is important to study their chemical compositions separately because they may have experienced distinct evolutionary histories . For instance , the age - metallicity relation shows that the halo was formed earlier than the disk ( e . g . , Twarog 1980 ) , while the density proportions such as Fe / H indicate that the halo contains much young high - density stars which should be killed by supernova explosions if the halo had been formed recently like the disk ( e . g . , Nissen & Schuster 1997 ) .Many experiments have explored the properties of the halo utilizing diverse samples of distant halo stars selected mainly from proper motion surveys or photometric parallax observations . Recently , large spectroscopic studies such as the Sloan Digital Sky Surveys ( SDSS ) ( York et al .2000 ) , RAVE study ( Steinmetz 2003 ) and SEGUE study ( Yanny et al . 2009 ) have provided us with far better details about the chemical composition of the halo .Using",
        "ori-fast-z-score": -0.26013299085723596,
        "water-fast-z-score": 8.419756985347481
    },
    {
        "original_text": "In this work, we propose an algorithm for blind identification (BI) of distributed antenna systems (DASs). The proposed BI method is based on the joint use of second-order statistics and higher order cumulants to estimate the number of active users in each cell as well as their carrier frequency offsets (CFOs), which are unknown parameters that need to be estimated before data detection can take place. We show by simulation results that our proposed method outperforms existing methods in terms of bit error rate performance when CFOs exist between different cells. In addition, it has lower computational complexity than other algorithms. \n \n Keywords: Blind identification; Distributed antenna systems; Second-order statistics; Higher order cumulants; CFO estimation. 1 Introduction \n \n With the rapid development of wireless communication technology, there have been increasing demands for high spectral efficiency and reliable transmission over limited bandwidth resources  1  . To meet these requirements, multi-antenna techniques such as multiple-input-multiple-output (MIMO)  2  , massive MIMO  3  -  5  , cooperative relaying  6  , and cognitive radio  7  have attracted much attention recently. Among them, distributed antenna systems (DAs)  8  -  10  provide significant advantages including improved coverage area, enhanced capacity, reduced power consumption, and increased network flexibility  11  . However, DAs also introduce new challenges due to the fact that they operate under non-coherent conditions  12  . For example, the channel state information (CSI) at the transmitter side cannot be obtained directly through uplink training or downlink feedback  13  . Therefore, how to obtain CSI accurately becomes one of the most important issues in DA design  14  .\n \nTo address this issue, several works  15  -  17  have investigated the problem of estimating the number of active users and their corresponding channels simultaneously using only statistical properties of received signals without requiring any prior knowledge about the transmitted symbols. These approaches exploit the inherent sparseness property of user activity patterns and utilize second-order statistics (SOS) and/or higher order cumulants (HOCs)  18  -  20  to identify the number of active users per cell. Then, the channel coefficients associated with",
        "watermark_text": "In this research , we propose an algorithm for blind analysis ( BI ) of distributed antenna devices ( DASs ) . The proposed BI approach is based on the joint use of second - order statistics and larger class cumulants to estimate the quantity of active consumers in each cell as also as their carrier signal offsets ( CFOs ) , which are unknown parameters that require to be assessed before data diagnosis can take occur .We suggest by simulation data that our proposed method outperforms current methods in terms of bit error rate capacity when CFOs arise between multiple cells . In addition , it has less computational complexity than other methods .Keywords : Blind identity ; Distributed antenna devices ; Second - order analysis ; Higher class cumulants ; CFO estimation . 1 Introduction With the increasing growth of radio communication techniques , there have been growing requirements for high spectral capacity and reliable transmission over limited bandwidth supplies 1 .To address these requirements , multi - antenna techniques such as multiple - input - multiple - output ( MIMO ) 2 , large MIMO 3 - 5 , joint relaying 6 , and cognitive television 7 have garnered considerable notice lately . Among them , dispersed antenna technologies ( DAs ) 8 - 10 provide significant advantages including increased coverage space , enhanced capacity , enhanced capacity consumption , and increased communication flexibility 11 .However , DAs additionally introduce novel challenges related to the fact that they operate under non - coherent environments 12 . For instance , the channel state information ( CSI ) at the broadcasting side cannot be obtained immediately through uplink conditioning or downlink feedback 13 .Therefore , how to obtain CSI correctly becomes one of the most important problems in DA design 14 . To address this question , various papers 15 - 17 have researched the issue of estimating the total of active participants and their corresponding networks simultaneously employing only statistical characteristics of received transmissions without using any earlier knowledge about the received symbols .These approaches exploit the intrinsic sparseness property of customer activity patterns and use second - order statistics ( SOS ) and / or greater order cumulants ( HOCs ) 18 - 20 to identify the total of active participants per cell . Then , the channel coefficients identified with",
        "ori-fast-z-score": -3.047505999613382,
        "water-fast-z-score": 9.53595439531399
    },
    {
        "original_text": "We present new near-infrared (NIR) spectra for red supergiants and giants, obtained at the European Southern Observatory in La Silla, Chile.  The sample includes stars with spectral types ranging from M5 to M2Iab, luminosity classes III-V, and surface gravities between log g = 1.0 and 3.8 dex. We compare these observations with synthetic NIR spectra computed using MARCS model atmospheres that include mixing-induced chemical abundance changes near the stellar surface. Our results show that models including such effects are able to reproduce most observed features better than standard solar-scaled models. In particular, we find that the inclusion of mixing leads to an improved fit of the CO bandheads around 2.3 microns as well as of several atomic lines. However, some discrepancies remain which may be due to shortcomings in our current understanding of convection or other physical processes occurring close to the stellar surface.",
        "watermark_text": "We present new near - infrared ( NIR ) spectra for red supergiants and giants , obtained at the European Southern Observatory in La Silla , Chile . The sample comprises stars with spectral classes ranging from M5 to M2Iab , luminosity classes III - V , and surface gravities between log f = 1 . 0 and 3 . 8 dex .We link these observations with artificial NIR spectra computed using MARCS model atmospheres that include mixing - caused chemical abundance changes near the stars surface . Our results show that estimates including such effects are able to depict most observed features good than conventional solar - scaled models .In particular , we find that the introduction of mixing gives to an better match of the CO bandheads around 2 . 3 microns as well as of several atomic lines . However , some discrepancies remain which perhaps be due to shortcomings in our future interpretation of convection or other material processes resulting close to the stars interior .",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 5.41602560309064
    },
    {
        "original_text": "We compare the performance of two different methods to simulate non-equilibrium dynamics in polymer systems, namely dissipative particle dynamics (DPD) with either a Nosé-Hoover or a Langevin thermostat. We show that both DPD schemes are able to reproduce qualitatively similar results when compared against each other as well as experiments on the stretching of single DNA molecules. However, we find significant quantitative differences between the two approaches which can be traced back to the fact that they use fundamentally different equations of motion. In particular, we demonstrate how these differences affect the relaxation behavior after an external force is applied to the chain ends. Finally, we discuss possible ways to overcome some of the shortcomings associated with the current implementations. \n \n Introduction \n \n The study of complex fluids such as polymers requires sophisticated simulation techniques capable of describing their unique properties at various length scales. While atomistic molecular dynamics has been successfully used to investigate phenomena occurring over short time and length scales  1–3 , coarse-grained models have emerged as powerful tools to explore longer timescales  4–6 . These simplified descriptions typically involve representing groups of atoms by one effective interaction site  7–9 . For example, in the case of biopolymers like proteins  10–12  or nucleic acids  13–18 , this approach allows us to capture essential features of the underlying physics while reducing computational costs significantly  19, 20 . \n \n Coarse-graining strategies often rely on mapping the interactions among individual particles onto effective potentials  21 . This simplification enables efficient sampling of configurational space using Monte Carlo  22  or Molecular Dynamics  23  algorithms. Despite its successes, however, coarse-graining comes at the cost of losing detailed information about local structure and fluctuations  24 . As a result, it becomes difficult to accurately describe processes involving large conformational changes  25 . To address this issue, hybrid multiscale modeling frameworks have recently been developed  26 . Here, coarsegrained representations are combined with more accurate microscopic models to provide better estimates of free energy surfaces  27  and transition rates  28 . \n \n Another important aspect of coarse-grained models concerns the choice of appropriate",
        "watermark_text": "We contrast the performance of two different methods to simulate non - equilibrium dynamics in polymer systems , namely dissipative particle behavior ( DPD ) with either a Nosé - Hoover or a Langevin thermostat . We see that both DPD strategies are able to predict qualitatively identical outcome when compared against each other as well as experiments on the stretching of multiple DNA molecules .However , we find considerable quantitative variations between the two strategies which can be traced back to the fact that they use fundamentally different equations of movement . In particular , we study how these changes affect the relaxation behavior after an external stress is applied to the chain ends .Finally , we explain possible ways to overcome some of the shortcomings associated with the present implementations . Introduction The investigation of complex materials such as polymers demands sophisticated simulation algorithms suitable of describing their distinct characteristics at several length scales .While atomistic atomic dynamics has been successfully utilized to examine processes arising over short period and duration scales 1 – 3 , coarse - grained models have developed as powerful tools to examine longer timescales 4 – 6 . These simplified descriptions typically involve describing bands of atoms by one effective bonding location 7 – 9 .For instance , in the case of biopolymers like genes 10 – 12 or nucleic acids 13 – 18 , this methodology allows us to capture essential aspects of the fundamental physics while reducing theoretical costs significantly 19 , 20 . Coarse - graining methods often relies on mapping the interactions among individual molecules onto effective potentials 21 .This simplification enables efficient scanning of configurational space employing Monte Carlo 22 or Molecular Dynamics 23 methods . Despite its effectiveness , however , coarse - graining comes at the cost of losing explicit data about local structure and fluctuations 24 .As a result , it becomes hard to correctly define systems featuring large conformational changes 25 . To address this question , hybrid multiscale modeling frameworks have recently been created 26 .Here , coarsegrained representations are coupled with more accurate microscopic predictions to provide better estimates of free energy materials 27 and transfer rates 28 . Another important dimension of rough - grained models concerns the selection of appropriate",
        "ori-fast-z-score": -0.6099942813304187,
        "water-fast-z-score": 8.490698088083718
    },
    {
        "original_text": "We have performed first-principles calculations to investigate the characteristics of phonon transmission across an epitaxial interface between Si and Ge, which are important for thermoelectric applications. We found that the phonon transmission is strongly suppressed at low frequencies due to the mismatch in acoustic impedance between two materials. The suppression becomes more significant as the thickness of Ge layer decreases. In addition, we observed that the phonon transmission exhibits strong anisotropy with respect to incident angle. These results suggest that it may be possible to control thermal transport by tuning the structure of epitaxial interfaces. Epitaxial interfaces play crucial roles in determining physical properties such as electrical conductivity  1  , optical reflectivity  2  , mechanical strength  3  , and thermal conductivity  4  . For example, recent studies on superlattices show that the thermal conductance can be reduced significantly compared to bulk values  5, 6  .\nIn this work, we focus on phonons because they dominate heat conduction in solids  7, 8  . Phonon scattering at epitaxial interfaces has been studied extensively using molecular dynamics (MD) simulations  9  or kinetic theory  10  . However, these approaches cannot provide detailed information about phonon transmission across interfaces since they do not take into account atomic interactions explicitly  11  . On the other hand, density functional theory (DFT), which describes electronic states based on quantum mechanics  12  , allows us to calculate phonon transmission coefficients directly  13  . Therefore, DFT-based methods are suitable for investigating phonon transmission across epi-",
        "watermark_text": "We have done first - principles measurements to examine the properties of phonon communication across an epitaxial connection between Si and Ge , which are important for thermoelectric use . We identified that the phonon communication is strongly restrained at low frequencies owing to the mismatch in sound impedance between two materials .The suppression gets more considerable as the height of Ge coating decreases . In addition , we reported that the phonon propagation displays good anisotropy with regard to incident angle .These data suggest that it could be possible to affect heat transport by tuning the structure of epitaxial interfaces . Epitaxial interfaces play crucial roles in determining physical properties such as mechanical conductivity 1 , optical reflectivity 2 , thermal strength 3 , and thermal conductivity 4 .For instance , recent studies on superlattices indicate that the thermal conductance can be reduced greatly compared to bulk values 5 , 6 . In this research , we focus on phonons because they govern heat conduction in solids 7 , 8 .Phonon splitting at epitaxial interfaces has been studied thoroughly using chemical mechanics ( MD ) simulations 9 or kinetic theory 10 . However , these perspectives cannot offer comprehensive information about phonon communication across interfaces since they do not take into consideration atomic interactions explicitly 11 .On the other hand , density functional theory ( DFT ) , which explains electronic states based on quantum mechanics 12 , allows us to estimate phonon communication equations directly 13 . Therefore , DFT - based methods are suitable for investigating phonon communication across epi -",
        "ori-fast-z-score": -0.7559289460184544,
        "water-fast-z-score": 7.878011364745742
    },
    {
        "original_text": "G-protein-coupled receptors (GPCRs) are one of the largest families of cell surface proteins and play an important role in many physiological processes, including vision, olfaction, taste, hormone secretion, neurotransmission, immune response, inflammation, and cancer.  The number of known human GPCR sequences has increased dramatically over recent years due to advances in genome sequencing technologies; however, only about half have been functionally characterized so far. In this study we present a novel computational method that can be used to predict the functional class of uncharacterized GPCRs based on their sequence similarity with other members within each subfamily. Our approach is based on two key ideas: 1) We use a new adaptive strategy to select representative sequences from different subfamilies by considering both the diversity among them as well as their evolutionary relationships; 2) We develop a new scoring scheme which takes into account not only the pairwise sequence similarities but also the structural information between query and template sequences. Using our method, we were able to successfully classify more than 80% of all human GPCRs whose functions had previously been experimentally determined.",
        "watermark_text": "G - protein - coupled receptors ( GPCRs ) are one of the largest families of cell surface proteins and play an important role in multiple physiological mechanisms , notably vision , olfaction , taste , hormone secretion , neurotransmission , immune reaction , inflammation , and tumors . The amount of known human GPCR sequences has increased significantly over recent months thanks to advances in genome sequencing technologies ; however , only about half have been functionally distinguished so far .In this study we present a innovative computational technique that can be used to predict the functional class of uncharacterized GPCRs based on their sequence similarity with other members within each subfamily . Our solution is based on two fundamental ideas : 1 ) We use a new adaptive approach to select representative sequences from different subfamilies by examining both the complexity among them as well as their evolutionary relationships ; 2 ) We develop a new scoring scheme which assumes into consideration not only the pairwise sequence comparisons but also the structural information between query and template sequences .Using our technique , we were able to effectively classify more than 80 % of all human GPCRs whose functions had earlier been experimentally determined .",
        "ori-fast-z-score": 0.31799936400190804,
        "water-fast-z-score": 5.902918298980975
    },
    {
        "original_text": "In this work, we propose an efficient watermarking scheme for digital images based on the discrete wavelet transform (DWT). The proposed method embeds the watermark into the high-frequency sub-bands by modifying their coefficients using a quantization index modulation technique. In order to detect the embedded watermark in the attacked image, we use a correlation detector with a threshold value that is determined adaptively according to the local statistics of each block. Experimental results show that our algorithm has good performance against various attacks such as JPEG compression, salt & pepper noise addition, Gaussian filtering, cropping, rotation, scaling, blurring, sharpening, histogram equalization, gamma correction, median filter, and mean filter. Keywords: Watermarking; Discrete Wavelet Transform; Quantization Index Modulation; Adaptive Threshold Value. Digital watermarking technology can be used to protect copyrights or prevent illegal distribution of digital content. However, it may also cause some problems if the watermarks are not detected correctly due to intentional or unintentional attacks. Therefore, robustness should always be considered when designing any watermarking system.",
        "watermark_text": "In this research , we propose an efficient watermarking scheme for digital photographs relying on the discrete wavelet transform ( DWT ) . The proposed approach embeds the watermark into the high - frequency sub - bands by modifying their coefficients utilizing a quantization index modulation method .In order to identify the embedded watermark in the attacked image , we utilize a correlation detector with a threshold expression that is calculated adaptively based to the local statistics of each block . Experimental findings show that our technique has good success against several attacks such as JPEG compression , salt & pepper noise addition , Gaussian filtering , cropping , rotation , scaling , blurring , sharpening , histogram equalization , alpha reduction , median filter , and average filter .Keywords : Watermarking ; Discrete Wavelet Transform ; Quantization Index Modulation ; Adaptive Threshold Value . Digital watermarking technology can be used to shield copyrights or avoid illegal distribution of digital content .However , it could also create some problems if the watermarks are not noticed correctly due to deliberate or unintentional hits . Therefore , robustness should always be included when designing any watermarking scheme .",
        "ori-fast-z-score": -1.1470786693528088,
        "water-fast-z-score": 5.888972745734182
    },
    {
        "original_text": "We present exact solutions to the nonholonomic Ricci flows for Einstein spaces with torsion, which are generated by nonlinear connections (N-connections) on principal fiber bundles. The N-connection coefficients depend only on time parameter t and satisfy certain evolution equations. We show that these solutions can be used in order to construct new classes of exact solutions to gravitational field equations in general relativity theory. In particular we find explicit examples of exact solutions describing black holes and wormholes. These results may have important applications in modern cosmology as well as in quantum gravity theories. Keywords: Nonholonomic Ricci flow, Gravity, Black hole, Wormhole, Cosmological model. 1 Introduction.\nThe geometric methods of constructing exact solutions to gravitational field equation in general relativity theory were developed during last decades  1, 2  . It is possible to generate such solutions using various types of symmetries like Killing vectors or tensors, homothetic vector fields etc., see e.g.  3  -  8  .\nIn this work we consider another approach based on so-called nonholonomic frame transforms  9, 10  , when one uses anholonomy coefficients of nonlinear connection (N-connection) instead of usual Christoffel symbols. This method was applied recently in order to study some problems related to modified gravity models  11  -  13  .",
        "watermark_text": "We present precise solutions to the nonholonomic Ricci currents for Einstein spaces with torsion , which are produced by nonlinear links ( N - connections ) on principal fiber bundles . The N - connection coefficients depend only on time variable t and obey certain evolution equations .We see that these solutions can be used in order to build new classes of precise solutions to gravitational field equations in general relativity theory . In particular we find explicit examples of precise solutions involving red holes and wormholes .These conclusions could have important use in modern cosmology as well as in quantum gravitational dynamics . Keywords : Nonholonomic Ricci system , Gravity , Black hole , Wormhole , Cosmological model .1 Introduction . The mathematical techniques of constructing exact solutions to gravitational field function in general relativity theory were developed during last decades 1 , 2 .It is easy to create such solutions use different kinds of symmetries like Killing tensor or tensors , homothetic vector spaces etc . , see e . g . 3 - 8 .In this research we imagine another methodology relying on so - called nonholonomic frame transforms 9 , 10 , when one uses anholonomy values of nonlinear connection ( N - connection ) instead of customary Christoffel characters . This method was used lately in order to study some problems related to revised gravitational models 11 - 13 .",
        "ori-fast-z-score": -1.5540573797716226,
        "water-fast-z-score": 5.633458001672132
    },
    {
        "original_text": "We study the propagation of external control signals through a large class of randomly constructed Boolean networks, which are known to exhibit rich dynamical behaviors including chaos.  We show that for any given initial state, there exists an optimal set of input nodes such that if their states are fixed at 1 or 0, then the resulting system will reach its steady state with minimum number of steps (or equivalently maximum speed). The problem is formulated as finding this optimal set of input nodes by solving a combinatorial optimization problem on graphs. This formulation leads us to develop efficient algorithms based on local search techniques. Our results provide insights into how to design effective control strategies for complex systems modeled by Boolean networks. In addition, we also investigate the effect of noise on the performance of these control strategies. Finally, our analysis reveals some interesting connections between the structure of the underlying graph and the effectiveness of different control strategies. A Boolean network consists of N binary-state variables xi(t) ∈ {0, 1} evolving according to a deterministic update rule specified by a directed graph G = (V , E), where V denotes the set of vertices representing the N variables, and E represents the set of edges connecting pairs of vertices. Each vertex i has K incoming neighbors denoted by Ni = {j : (i, j ) ∈ E}. At each time step t, all the variables synchronously evolve according to the following updating scheme:",
        "watermark_text": "We test the propagation of external control messages through a large class of randomly established Boolean connections , which are known to undergo rich dynamical interactions including chaos . We see that for any given original state , there exists an appropriate collection of input nodes such that if their states are fixed at 1 or 0 , then the resulting system will attain its steady state with minimum number of steps ( or equivalently limit speed ) .The question is implemented as finding this efficient setting of input nodes by solving a combinatorial algorithm question on graphs . This formulation leads us to develop optimal methods using on local search methods .Our results yield insights into how to model optimal control tactics for complex systems modeled by Boolean connections . In addition , we also investigate the impact of noise on the performance of these control tactics .Finally , our analysis reveals some interesting connections between the composition of the underlying graph and the performance of different control tactics . A Boolean network consists of N binary - state components xi ( t ) ∈ { 0 , 1 } evolving due to a deterministic change rule defined by a directed graph G = ( V , E ) , where V denotes the group of vertices representing the N variables , and E represents the group of vertices linking pairs of vertices .Each vertex i has K incoming neighbors denoted by Ni = { j : ( i , j ) ∈ E } . At each time step t , all the variables synchronously evolve according to the following updating scheme :",
        "ori-fast-z-score": 0.3592106040535498,
        "water-fast-z-score": 7.065974808899335
    },
    {
        "original_text": "We present new results on the contribution of BL Lacs (blazars) to the extragalactic gamma-ray background based on data collected by the Fermi Large Area Telescope between August 2008 and December 2010, corresponding to an effective exposure time of 1.6 yr for each source in our sample. We use two different methods to estimate this contribution: i) we calculate the number counts above 100 MeV as function of redshift using a maximum likelihood method; ii) we fit the observed spectral energy distribution with a log-parabola model and derive the integrated fluxes at 0.1 GeV and 10 TeV energies. The resulting contributions are consistent within statistical uncertainties. Our best-fit value is F(>100 MeV) = 2.2 x 10^{−8} ph cm−2 s−1 sr−1 which corresponds to ~20% of the measured EGB intensity. This result confirms that blazars are one of the main contributors to the EGB emission.",
        "watermark_text": "We report new data on the contribution of BL Lacs ( blazars ) to the extragalactic gamma - ray background based on evidence generated by the Fermi Large Area Telescope between August 2008 and December 2010 , corresponding to an effective exposure time of 1 . 6 yr for each source in our sample . We use two different methods to estimate this contribution : i ) we determine the number counts above 100 MeV as function of redshift using a maximum likelihood technique ; ii ) we fit the observed spectral power distribution with a log - parabola simulation and derive the integrated fluxes at 0 . 1 GeV and 10 TeV energies .The resulting contributions are compatible within statistical uncertainties . Our best - fitting value is F ( > 100 MeV ) = 2 . 2 x 10 ^ { −8 } ph cm−2 s−1 sr−1 which equals to ~ 20 % of the measured EGB brightness .This result confirms that blazars are one of the main contributors to the EGB emission .",
        "ori-fast-z-score": -0.40451991747794525,
        "water-fast-z-score": 2.8316394223456167
    },
    {
        "original_text": "We present new structural parameters for 23 globular clusters (GCs) in M31, derived using HST/ACS images taken with the F606W filter. We use these data to test whether GCs follow the same scaling relations as elliptical galaxies do on the so-called  fundamental plane . The results show that most of our sample follows this relation within uncertainties, but we also find some outliers which are likely due to their different formation histories or dynamical states. In addition, we compare our results with those obtained by other authors who used ground-based observations. Our analysis shows that there is no significant difference between the two datasets when they are analyzed consistently. Finally, we discuss possible reasons why previous studies have found conflicting results about the existence of such a relationship among GC systems. This work was supported by NASA grant NAG5-12140. Keywords: Globular cluster; Fundamental Plane",
        "watermark_text": "We report new structural values for 23 globular complexes ( GCs ) in M31 , obtained using HST / ACS images obtained with the F606W filter . We use these information to test whether GCs obey the same scaling relations as elliptical galaxies do on the so - called core plane .The results show that most of our sample follows this relation within uncertainties , but we also find some outliers which are likely due to their different formation histories or dynamical states . In addition , we compare our findings with those acquired by other researchers who used ground - based observations .Our study shows that there is no major difference between the two datasets when they are examined consistently . Finally , we explain possible reasons why previous research have discovered differing results about the existence of such a connection among GC systems .This project was supported by NASA grant NAG5 - 12140 . Keywords : Globular cluster ; Fundamental Plane",
        "ori-fast-z-score": 1.1338934190276817,
        "water-fast-z-score": 5.842005842008763
    },
    {
        "original_text": "We present the first steps towards building a library of synthetic galaxy SEDs (spectral energy distributions) that will be used to classify and parameterize unresolved galaxies in the Gaia data stream, as part of the Data Processing and Analysis Consortium (DPAC). The library is built using state-of-the-art stellar population synthesis models with different star formation histories, metallicities, dust content, and redshifts. We use this library to test two methods of classifying unresolved galaxies into broad morphological types based on their observed photometry only. In addition we show how these parameters can be constrained by fitting the full spectrum of an unresolved galaxy. This work was performed within the framework of the ESA Gaia mission. Keywords: Galaxy evolution; Stellar populations; Spectroscopy. 1 Introduction Galaxies are complex systems whose properties depend strongly on their mass, age, chemical composition, star formation history, and environment. These physical characteristics determine many observable quantities such as luminosity, colours, morphology, kinematics, etc., which have been studied extensively over several decades. However, it has become clear recently that there exist significant degeneracies between some of these observables and therefore they cannot be uniquely determined without additional information about the underlying physics or geometry of the system. For example, the total luminosity of a galaxy depends not only on its current star formation rate but also on its past star formation activity through the integrated light of old stars. Similarly, the colour of a galaxy depends both on its metallicity and on the amount of dust extinction along our line-of-sight. Therefore, accurate measurements of all relevant physical parameters require detailed spectroscopic observations covering large wavelength ranges. Such studies are now possible thanks to new space missions like GALEX, SDSS, 2MASS, Spitzer Space Telescope, Herschel Space Observatory, Chandra X-ray Observatory, XMM-Newton, Hubble Space Telescope, and most importantly, the upcoming European Space Agency s Gaia satellite. Gaia is expected to provide astrometric positions, parallaxes, proper motions, radial velocities, and multi-colour photometry for more than one billion objects",
        "watermark_text": "We present the first steps towards constructing a library of synthetic galaxy SEDs ( spectral energy distributions ) that will be used to classify and parameterize unresolved galaxies in the Gaia data feed , as member of the Data Processing and Analysis Consortium ( DPAC ) . The library is built using state - of - the - art stellar community synthesis estimates with various galaxy formation histories , metallicities , dust content , and redshifts .We use this library to test two means of classifying unresolved galaxies into wide morphological types based on their observed photometry only . In addition we prove how these parameters can be constrained by fitting the full spectrum of an unresolved universe .This research was done within the framework of the ESA Gaia spacecraft . Keywords : Galaxy evolution ; Stellar populations ; Spectroscopy .1 Introduction Galaxies are diverse structures whose characteristics rely heavily on their mass , age , chemical composition , star formation history , and environment . These physical traits determine many observable quantities such as luminosity , colours , morphology , kinematics , etc . , which have been studied frequently over numerous years .However , it has become clear recently that there remain considerable degeneracies between some of these observables and therefore they cannot be uniquely determined without additional information about the fundamental physics or topology of the system . For instance , the total luminosity of a galaxy depends not only on its current star formation rate but also on its past star formation activity through the integrated light of young galaxies .Similarly , the colour of a galaxy depends both on its metallicity and on the extent of dust extinction along our line - of - view . Therefore , detailed observations of all relevant physical factors require comprehensive spectroscopic observations encompassing large wavelength ranges .Such investigations are now able thanks to novel space missions like GALEX , SDSS , 2MASS , Spitzer Space Telescope , Herschel Space Observatory , Chandra X - ray Observatory , XMM - Newton , Hubble Space Telescope , and most importantly , the latest European Space Agency s Gaia satellite . Gaia is expected to provide astrometric positions , parallaxes , proper motions , radial velocities , and multi - colour photometry for more than one billion objects",
        "ori-fast-z-score": 1.643989873053573,
        "water-fast-z-score": 7.893748050080246
    },
    {
        "original_text": "We present an analysis of galaxy clusters selected by their red-sequence galaxies (Gladders & Yee 2005) from the Sloan Digital Sky Survey Data Release 4 (DR4). We use two different methods to select cluster candidates, and then apply photometric redshift cuts on these samples to obtain final catalogues with high purity. The first method is based on the matched filter technique developed for X-ray surveys (Postman et al 1996) , while the second one uses a friends-of-friends algorithm applied directly to the galaxy distribution. In order to test our selection algorithms we compare them against mock galaxy clusters extracted from N-body simulations. Our main results are as follows:  1. Using the matched filter technique we find that the number density of galaxy clusters at z < 0.5 is n(z<0.5) = 3.6 +/- 0.2 x 10-3 h3 Mpc-3 . This value agrees well with previous determinations using other techniques.  2. By applying the same matched filter technique to simulated galaxy clusters we show how this method can be used to estimate the mass function of galaxy clusters up to z ~1.0.",
        "watermark_text": "We present an assessment of galaxy regions selected by their red - sequence galaxies ( Gladders & Yee 2005 ) from the Sloan Digital Sky Survey Data Release 4 ( DR4 ) . We use two different methods to select cluster applicants , and then use photometric redshift cutting on these specimens to obtain final catalogues with high purity .The first method is based on the matched filter technique developed for X - ray observations ( Postman et al 1996 ) , while the second one uses a enemies - of - friends method applied directly to the galaxy distribution . In order to test our choice algorithms we compare them against mock galaxy galaxies extracted from N - bodies simulations .Our main results are as follows : 1 . Using the matched filter technique we find that the number density of galaxy galaxies at z < 0 . 5 is n ( z < 0 . 5 ) = 3 . 6 + / - 0 . 2 x 10 - 3 h3 Mpc - 3 .This value agrees well with previous determinations using other techniques.2.By applying the same matched filter technique to modeled galaxy galaxies we find how this algorithm can be used to estimate the mass value of galaxy galaxies up to z ~ 1 . 0 .",
        "ori-fast-z-score": 1.4924050144892729,
        "water-fast-z-score": 5.9696200579570915
    },
    {
        "original_text": "We consider the problem of learning an unknown distribution over binary strings, where each string is generated by sampling independently at random with replacement according to some fixed probability vector . We show that if we are given samples drawn iid from , then it can be learned in polynomial time using standard statistical techniques (e.g., maximum likelihood). However, when the number of possible values for each bit grows large, this approach fails because there may not exist any sample which contains all possible values for every bit. In such cases, we propose a novel algorithm based on Gibbs sampling and prove its correctness under certain conditions. Finally, we present experimental results demonstrating our method s effectiveness. The main contribution of this work lies in showing how to learn distributions over combinatorial objects like graphs and trees. This is achieved by first reducing these problems into learning distributions over binary strings, and then applying our proposed algorithms. Learning distributions over combinatorial objects has many applications including data mining, computer vision, bioinformatics, etc. .",
        "watermark_text": "We consider the question of knowing an unknown distribution over binary strings , where each string is generated by filtering independently at random with replacement due to some fixed probability vector . We see that if we are given samples picked iid from , then it can be learned in polynomial period using conventional statistical tools ( e . g . , maximum likelihood ) .However , when the quantity of possible values for each bit grows large , this methodology fails because there may not exist any specimen which contains all possible values for every bit . In such cases , we undertake a new algorithm based on Gibbs filtering and find its correctness under certain conditions .Finally , we present research results proving our technique s efficacy . The main impact of this research consists in teaching how to teach distributions over combinatorial objects like graphs and trees .This is achieved by first transforming these problems into knowledge distributions over binary strings , and then applying our proposed methods . Learning distributions over combinatorial objects has numerous uses including data extraction , computer vision , bioinformatics , etc ..",
        "ori-fast-z-score": 0.10369516947304253,
        "water-fast-z-score": 6.947576354693849
    },
    {
        "original_text": "We study the message throughput performance of dynamic peer-to-peer systems with unreliable links and limited bandwidth, where peers are connected to each other via overlay networks. We propose two models for such systems: (1) an analytical model based on mean field theory; and (2) a simulation-based model that is built upon ns-2 network simulator. The results show that our proposed models can accurately predict the message throughput under different settings. In addition, we find that the message throughput decreases as the number of nodes increases or the average node degree decreases. Finally, we compare the message throughputs achieved by three popular overlay routing protocols: flooding, random walk, and epidemic routing. Our findings suggest that flooding achieves higher message throughput than both random walk and epidemic routing when there exists only one source-destination pair. However, if multiple pairs exist simultaneously, then epidemic routing outperforms flooding because it allows messages to be forwarded along multiple paths at once.",
        "watermark_text": "We research the message throughput performance of dynamic peer - to - peer systems with unreliable connectivity and low bandwidth , where peers are connected to each other via overlay networks . We suggest two models for such systems : ( 1 ) an analytical theory based on mean field theory ; and ( 2 ) a simulation - based model that is built upon ns - 2 network simulator .The results show that our proposed models can accurately forecast the message throughput under various contexts . In addition , we find that the message throughput decreases as the number of vertices increases or the average node degree drops .Finally , we compare the message throughputs achieved by three popular overlay routing protocols : storm , random walk , and epidemic routing . Our findings show that flooding achieves higher message throughput than both random walk and epidemic routing when there exists only one origin - destination pair .However , if multiple sets exist independently , then epidemic routing outperforms flooding because it allows messages to be forwarded along multiple paths at once .",
        "ori-fast-z-score": 3.18316353970102,
        "water-fast-z-score": 6.8333094212876695
    },
    {
        "original_text": "We present an analysis of the kinetic Sunyaev-Zeldovich effect (kSZ) due to electrons in our galaxy, using data obtained with the Atacama Cosmology Telescope and the South Pole Telescope. We use two different methods for estimating the kSZ signal; one is based on cross-correlating maps of CMB temperature anisotropy at 150 GHz and 3000 GHz, while the other uses the power spectrum of the CMB temperature fluctuations at 150 GHz. The results are consistent between these two approaches within their respective uncertainties. We find that the amplitude of this signal agrees well with theoretical predictions when we assume a Navarro-Frenk-White profile for dark matter density distribution around galaxies. This measurement provides new constraints on cosmological parameters such as the Hubble constant H0 = 73 +/- 4 km s-1 Mpc-1 , the total mass density parameter Omega_m = 0.27 +/- 0.03 , and the equation-of-state w = -1.06 +/- 0.11 .",
        "watermark_text": "We present an assessment of the kinetic Sunyaev - Zeldovich effect ( kSZ ) due to electrons in our universe , using data acquired with the Atacama Cosmology Telescope and the South Pole Telescope . We use two different methods for estimating the kSZ signal ; one is based on cross - correlating mapping of CMB heat anisotropy at 150 GHz and 3000 GHz , while the other uses the power spectrum of the CMB heat fluctuations at 150 GHz .The results are compatible between these two perspectives within their different uncertainties . We see that the frequency of this signal agrees well with theoretical expectations when we suppose a Navarro - Frenk - White model for black material concentration distribution around galaxies .This measurement gives additional constraints on cosmological factors such as the Hubble constant H0 = 73 + / - 4 km s - 1 Mpc - 1 , the total mass density variable Omega _ m = 0 . 27 + / - 0 . 03 , and the equation - of - state w = - 1 . 06 + / - 0 . 11 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.443310539518174
    },
    {
        "original_text": "We propose an algorithm for reconstructing the signaling network in which each node is associated with multiple time series data, and we assume that only some nodes are observed at any given time point. The proposed method consists of two steps: (1) estimating the state vector by solving a sparse reconstruction problem; (2) inferring the edge set using the estimated states as features. We show through numerical experiments on synthetic networks that our approach can accurately recover both the structure and parameters of the underlying network even when only partial information about the system is available. Our results also suggest that the performance of the proposed method depends strongly on how well the sparsity pattern of the true signal is captured by the observation matrix. Finally, we apply this method to analyze the dynamics of protein phosphorylation in yeast cells responding to heat shock stress. In particular, we identify several key proteins involved in regulating the response process. This work was supported by NIH grant R01GM084283-01A1",
        "watermark_text": "We suggest an algorithm for reconstructing the signaling network in which each node is associated with various time series information , and we suppose that only some nodes are observed at any certain time point . The proposed approach consists of two stages : ( 1 ) estimating the state vector by addressing a sparse reconstruction task ; ( 2 ) inferring the edge setting using the expected states as characteristics .We suggest through quantitative studies on synthetic systems that our approach can accurately recover both the formation and parameters of the underlying systems even when only partial knowledge about the system is accessible . Our results also suggest that the performance of the suggested method depends strongly on how best the sparsity pattern of the true signal is captured by the observation vector .Finally , we apply this technology to analyze the dynamics of gene phosphorylation in yeast cells responding to heat shock pressure . In particular , we identify several key proteins responsible in controlling the response process .This project was supported by NIH funding R01GM084283 - 01A1",
        "ori-fast-z-score": -0.10721125348377948,
        "water-fast-z-score": 7.035623639735144
    },
    {
        "original_text": "We present new observations at 1.4 GHz and 8.5 GHz with the Australia Telescope Compact Array (ATCA) of the radio afterglow associated to the gamma-ray burst GRB030329, which occurred on March 29th 2003. The data were taken between April 2nd and May 8th 2004, i.e., more than one year after the burst event. We find that the source is still brightening in flux density by about 0.5% per day at both frequencies. This behaviour can be explained if we assume that the fireball has not yet reached its final deceleration radius. In this case, the observed emission would come from an expanding shell of relativistically moving material surrounding the central engine. If so, our results suggest that the energy injection process responsible for the late-time flaring activity detected in other GRBs may have continued up to very large distances from the progenitor system. \n \n Keywords: Gamma-Ray Bursts",
        "watermark_text": "We report new images at 1 . 4 GHz and 8 . 5 GHz with the Australia Telescope Compact Array ( ATCA ) of the radio afterglow related to the alpha - ray burst GRB030329 , which occurred on March 29th 2003 . The data were took between April 2nd and May 8th 2004 , i . e . , more than one month after the explosion event .We see that the source is already brightening in flux concentration by about 0 . 5 % per morning at both frequencies . This behaviour can be described if we suppose that the fireball has not already achieved its final deceleration radius .In this example , the seen emission might come from an evolving shell of relativistically moving material surrounding the main motor . If so , our findings show that the power injection mechanism responsible for the late - time flaring activity detected in other GRBs might have continued up to very big distances from the progenitor system .Keywords: Gamma-Ray Bursts",
        "ori-fast-z-score": -1.6035674514745464,
        "water-fast-z-score": 5.258758927213289
    },
    {
        "original_text": "We present new observations and analysis of the Balmer-dominated shocks driven by supernova remnants (SNRs) into dense molecular clouds, which are known as  molecular cloud shocks  or  Balmer-dominated shocks . We find that these shocks have an intermediate temperature between those of typical J-type and C-type shocks. The observed emission lines show prominent P-Cygni profiles with blueshifted absorption features indicating high velocities up to 100 km s-1 . These results suggest that the transition zone is located at the interface between the shocked gas and unshocked ambient medium. In addition, we found that the widths of the Hα line profiles increase toward the center of SNR W28. This indicates that the density structure of the surrounding environment may be more complicated than previously thought. Our study suggests that Balmer-dominated molecular cloud shocks can provide important information on the physical conditions of the interstellar medium around young SNRs.",
        "watermark_text": "We report new studies and investigation of the Balmer - dominated shocks driven by supernova remnants ( SNRs ) into thick molecular clouds , which are known as atom cluster shocks or Balmer - dominated shocks . We see that these shocks have an intermediate heat between those of typical J - class and C - class shocks .The observed emission lines show marked P - Cygni profiles with blueshifted emission elements suggesting high velocities up to 100 km s - 1 . These data suggest that the shift area is situated at the interface between the excited gas and unshocked ambient material .In addition , we recovered that the widths of the Hα line profiles increase toward the center of SNR W28 . This implies that the density structure of the nearby region might be more complicated than previously thought .Our study implies that Balmer - dominated molecular storm shocks can provide important information on the physical conditions of the interstellar medium around early SNRs .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.861993625888845
    },
    {
        "original_text": "We present the results of our analysis of high-resolution optical spectra obtained with HST/STIS for four nearby (z<0.1), X-ray selected, Type Ib/c SNe in order to study their progenitor systems. We find that all four objects show evidence for dense CSM surrounding them at distances ranging between 0.01-0.2 pc. The presence of such material is consistent with theoretical expectations for post-low-velocity-bulge (post-LBV) Wolf-Rayet star winds. In addition we detect narrow emission features which are likely due to interaction between SN ejecta and this wind. These observations provide strong constraints on the nature of the progenitor systems: they require massive WR stars as well as binary companions capable of producing significant mass loss prior to explosion. This work was supported by NASA grant NAG5-10842. We have analyzed high resolution STIS/HST data for 4 nearby (z<0.1; Xray-selected) type Ibc supernovae in an attempt to determine the properties of their progenitor systems. All four objects exhibit dense circumstellar matter (CSM; nH>1020 cm-3 ) within 0.01-0.20 parsecs of the supernova site. Such densities are expected if these explosions occur following the ejection of a low velocity  bulge  during late stages of stellar evolution. Furthermore, we observe narrow emission features which may be associated with shock-heating of the CSM by the expanding supernova remnant. Our findings suggest that these events result from the deaths of massive Wolf Rayet stars surrounded by close binaries.",
        "watermark_text": "We present the conclusion of our analysis of high - resolution optical spectra obtained with HST / STIS for four nearby ( z < 0 . 1 ) , X - ray selected , Type Ib / c SNe in order to study their progenitor structures . We see that all four bodies exhibit indication for thick CSM circling them at distances ranging between 0 . 01 - 0 . 2 pc .The presence of such material is compatible with theoretical expectations for post - low - speed - bulge ( post - LBV ) Wolf - Rayet star winds . In addition we find narrow radiation properties which are likely due to contact between SN ejecta and this wind .These measurements give strong restrictions on the nature of the progenitor structures : they use massive WR galaxies as well as binary companions capable of producing significant mass loss prior to explosion . This research was supported by NASA gift NAG5 - 10842 .We have analyzed high resolution STIS / HST results for 4 nearby ( z < 0 . 1 ; Xray - selected ) type Ibc supernovae in an trying to estimate the properties of their progenitor structures . All four bodies exhibit thick circumstellar matter ( CSM ; nH > 1020 cm - 3 ) within 0 . 01 - 0 . 20 parsecs of the supernova center .Such densities are expected if these fires occur following the ejection of a small velocity bulge during late stages of stars evolution . Furthermore , we study narrow radiation properties which may be involved with shock - heating of the CSM by the evolving supernova remnant .Our findings show that these changes result from the deaths of large Wolf Rayet stars surrounded by tight binaries .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.807983207583857
    },
    {
        "original_text": "We present the first detection of secondary CMB polarization induced by Faraday rotation (FR) in galaxy clusters, using data taken with the Atacama Cosmology Telescope Polarimeter (ACTPol). We detect FR-induced polarized emission at angular scales corresponding to multipoles = 100-1000 for two galaxy clusters: ACT-CL J0102-4915 and ACT-CL J0546-5345. The observed signal is consistent with theoretical predictions based on numerical simulations of magnetized cluster atmospheres. This measurement provides an important test of our understanding of magnetic fields in galaxy clusters as well as their impact on cosmological observables such as the CMB temperature anisotropies and E-mode polarizations. In addition, we report upper limits on the FR-induced polarized emissions from other galaxy clusters that are not detected individually due to low S/N ratio or limited survey area. These results will be useful for future studies of FR effects on the CMB polarization maps produced by upcoming experiments like Planck and Simons Observatory.",
        "watermark_text": "We present the first measurement of secondary CMB polarization induced by Faraday rotation ( FR ) in galaxy clusters , using data taken with the Atacama Cosmology Telescope Polarimeter ( ACTPol ) . We detect FR - caused polarized emission at angular scales corresponding to multipoles = 100 - 1000 for two galaxy regions : ACT - CL J0102 - 4915 and ACT - CL J0546 - 5345 .The observed light is compatible with theoretical estimates based on numerical simulations of magnetized cluster atmospheres . This measurement represents an important test of our knowing of magnetic fields in galaxy galaxies as well as their impact on cosmological observables such as the CMB heat anisotropies and E - mode polarizations .In addition , we publish higher restrictions on the FR - caused polarized impacts from other galaxy galaxies that are not observed individually due to low S / N proportion or restricted observation space . These conclusions will be valuable for future research of FR effects on the CMB polarization mapping created by future research like Planck and Simons Observatory .",
        "ori-fast-z-score": -0.12403473458920847,
        "water-fast-z-score": 5.829632525692798
    },
    {
        "original_text": "We present new measurements of the Hubble constant and the equation-of-state parameter w0 using Chandra X-ray Observatory data for the most massive, dynamically relaxed galaxy clusters in the Universe. We use these results to place improved limits on the properties of dark energy. The sample consists of eight galaxy clusters with redshifts between 0.3 and 1.2 that were observed by Chandra as part of our ongoing program to study the evolution of cluster scaling relations out to high redshift. Using hydrostatic equilibrium models we measure the gas mass fraction within r500 (the radius at which the mean density is 500 times the critical density) for each system. These values are combined with independent estimates of the total gravitating mass obtained through weak lensing analysis performed by other groups. This yields an average value of H0 = 70 +/- 6 km s-1 Mpc-1 assuming flat priors on both parameters. If instead we assume Gaussian priors based on previous determinations of the Hubble constant and baryon content of the universe then this measurement becomes H0 = 68 +/-6 km s-1 Mpc-",
        "watermark_text": "We present new studies of the Hubble constant and the equation - of - state variable w0 using Chandra X - ray Observatory data for the most large , dynamically stable galaxy galaxies in the Universe . We use these results to place improved restrictions on the properties of dark energy .The sample consists of eight galaxy galaxies with redshifts between 0 . 3 and 1 . 2 that were detected by Chandra as part of our ongoing program to study the evolution of cluster scaling relations out to large redshift . Using hydrostatic equilibrium models we measure the gas mass fraction within r500 ( the radius at which the mean concentration is 500 times the critical density ) for each system .These values are coupled with independent estimates of the total gravitating mass obtained through soft lensing investigation performed by other organizations . This yields an mean value of H0 = 70 + / - 6 cm s - 1 Mpc - 1 assuming flat priors on both variables .If instead we assume Gaussian priors based on previous determinations of the Hubble constant and baryon concentration of the universe then this measurement becomes H0 = 68 + / - 6 cm s - 1 Mpc -",
        "ori-fast-z-score": 1.709408646894569,
        "water-fast-z-score": 5.735393346764043
    },
    {
        "original_text": "The driving mechanism for jets and outflows is still an open question, especially when the jet/outflow source has no clear central engine such as black holes or protostars. In this work we propose that magnetic reconnection can be responsible for launching jets and outflows in star formation process. We show that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks driven by the reconnecting current sheet (RCS). The accelerated electrons will produce synchrotron emission which may explain radio observations of jets and outflows. Furthermore, the energetic protons produced during RCS also contribute to nonthermal emissions through inverse Compton scattering with background photons. Finally, we discuss how our model could account for some observational features of jets and outflows. \n \n Keywords: Magnetic reconnection; Jet; Particle acceleration; Shocks; Synchrotron radiation; Nonthermal emission",
        "watermark_text": "The pushing mechanism for rockets and outflows is also an open question , particularly when the jet / outflow source has no clear central fuel such as black holes or protostars . In this research we propose that magnetic reconnection can be responsible for launching jets and outflows in star formation process .We see that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks driven by the reconnecting current sheet ( RCS ) . The driven electrons will generate synchrotron emission which would cause radio observations of jets and outflows .Furthermore , the energetic protons generated during RCS also contribute to nonthermal emissions through inverse Compton absorption with background photons . Finally , we talk how our model could account for some observational characteristics of jets and outflows .Keywords : Magnetic reconnection ; Jet ; Particle acceleration ; Shocks ; Synchrotron emission ; Nonthermal emission",
        "ori-fast-z-score": -0.6509445549041194,
        "water-fast-z-score": 3.8729833462074166
    },
    {
        "original_text": "The effect of three different sugars (trehalose, maltase and sucrose) on the structure and dynamics of lysozyme has been investigated by molecular dynamics simulation at 300 K for 100 ns in each case. The results show that all these sugar molecules can stabilize the protein against thermal denaturation to certain extent but trehalose is found to be most effective one among them. Trehalose molecule forms hydrogen bonds with both polar and nonpolar amino acid residues which leads to increase in number of water molecules around it. This increases the hydration shell thickness as well as total solvent accessible surface area of the protein. It also decreases the root mean square deviation between initial and final structures indicating its ability to maintain the native conformation of the protein. Maltose and sucrose are less efficient than trehalose because they form only few hydrogen bonds with the protein. In addition, their presence causes slight decrease in the radius of gyration and end-to-end distance of the protein.",
        "watermark_text": "The impact of three different sugars ( trehalose , maltase and sucrose ) on the composition and dynamics of lysozyme has been investigated by molecular dynamics simulation at 300 K for 100 ns in each case . The results show that all these syrup molecules can stabilize the protein against thermal denaturation to certain degree but trehalose is found to be most efficient one among them .Trehalose atom forms hydrogen bonds with both polar and nonpolar amino acid acids which results to increase in quantity of water molecules around it . This changes the hydration shell thickness as well as gross solvent available surface space of the protein .It additionally decreases the root average square deviation between initial and final structures representing its capacity to keep the native conformation of the protein . Maltose and sucrose are less effective than trehalose because they create only few hydrogen bonds with the protein .In addition , their presence causes mild decrease in the radius of gyration and end - to - end distance of the protein .",
        "ori-fast-z-score": -0.47140452079103173,
        "water-fast-z-score": 5.103161130233569
    },
    {
        "original_text": "In this work, we revisit some issues on netflow sample and export performance in terms of packet loss rate (PLR) and flow sampling accuracy (FSA). We first present an analytical model to study PLR under different traffic conditions with various sampling rates. Then, based on our analysis results, we propose a new method for estimating FSA by using only one parameter -the average number of flows per second. Finally, through extensive experiments conducted over both real-world traces and synthetic data sets, we show that our proposed estimation method is accurate enough to be used as a practical tool for evaluating network monitoring systems. The rest of this paper is organized as follows. In Section 2, we introduce related works about netflow sampling and exporting. In Section 3, we describe our experimental environment. In Section 4, we analyze the relationship between PLR and sampling rate. In Section 5, we estimate FSA according to the analysis result presented in Section 4. In Section 6, we evaluate the effectiveness of our proposed estimation method via extensive experiments. Finally, conclusions are drawn in Section 7.",
        "watermark_text": "In this research , we revisit some issues on netflow sample and export quality in terms of packet loss rate ( PLR ) and flow sampling accuracy ( FSA ) . We first offer an analytical method to study PLR under various traffic conditions with various sampling rates .Then , using on our analysis results , we propose a new method for estimating FSA by using only one parameter - the average number of flows per second . Finally , through numerous experiments conducted over both real - time traces and synthetic information sets , we prove that our proposed estimation method is accurate sufficient to be used as a practical tool for evaluating network monitoring systems .The rest of this paper is organized as follows . In Section 2 , we provide similar papers about netflow sampling and exporting .In Section 3 , we explain our experimental environment . In Section 4 , we assess the relationship between PLR and sampling rate .In Section 5 , we estimate FSA according to the evaluation result provided in Section 4 . In Section 6 , we assess the performance of our proposed estimation method via extensive experiments .Finally , findings are drawn in Section 7 .",
        "ori-fast-z-score": 1.8973665961010275,
        "water-fast-z-score": 5.9752235693149345
    },
    {
        "original_text": "We present new observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) of two inter-network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25, respectively. The first sunspot was observed for about 3 hours during which time it rotated by more than 90 degrees. We find that this sunspot is composed of several magnetic flux tubes with different orientations. In addition to these features we also observe an extended bright feature located between the main sunspot umbrae. This feature has been previously reported as a penumbral filament but our data show no evidence of such structure. Instead, we interpret this feature as a coronal rain blob. The second sunspot was observed for only 1 hour before being occulted by Earths atmosphere. During this observation period the sunspot rotated by less than 30 degrees. Our analysis shows that both sunspots are surrounded by a dark lane which may be associated with the moat surrounding large sunspots.",
        "watermark_text": "We report new images making with the Atacama Large Millimeter / submillimeter Array ( ALMA ) of two cross - network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25 , respectively . The first sunspot was seen for about 3 hours during which period it rotated by more than 90 degrees .We see that this sunspot is composed of several magnetic flux tubes with various orientations . In addition to these characteristics we also observe an extended bright point located between the main sunspot umbrae .This phenomenon has been previously reported as a penumbral filament but our statistics demonstrate no evidence of such structure . Rather , we view this phenomenon as a coronal weather blob .The second sunspot was seen for only 1 hour before being occulted by Earths atmosphere . During this study interval the sunspot tilted by less than 30 degrees .Our study shows that both sunspots are surrounded by a darkness lane which may be identified with the moat surrounding large sunspots .",
        "ori-fast-z-score": -1.0327955589886444,
        "water-fast-z-score": 5.163977794943222
    },
    {
        "original_text": "We present the results obtained by applying the semi-analytic code VESPA to model the evolution of galaxies in the Millennium Simulation, including chemical enrichment as well as dust extinction effects on their observed properties.  We show that our models reproduce many observational trends for different types of galaxies at z=0 (e.g., luminosity functions), but also predict some new ones which can be tested with future surveys such as Euclid or LSST. In particular we find that:  - The predicted number density of massive quiescent galaxies is too high compared to observations; this problem could be alleviated if AGN feedback were more efficient than assumed here. - Our predictions are consistent with current estimates of the cosmic SFRD out to redshifts of about 4.5, although they tend to overpredict it slightly beyond that redshift. - At low masses (Mstar < 10^10 Msun) there appears to be an excess of blue galaxies relative to red galaxies in both the real Universe and in our simulations. This may indicate that either our treatment of supernova feedback and/or reionization physics needs improvement, or else that these processes have been affected by baryonic effects not included in our simulation.",
        "watermark_text": "We present the results derived by using the semi - analytic coding VESPA to model the evolution of galaxies in the Millennium Simulation , notably chemical enrichment as well as dust extinction effects on their observed properties . We suggest that our designs represent many observational changes for different kinds of stars at z = 0 ( e . g . , luminosity functions ) , but also predict some additional ones which can be evaluated with current surveys such as Euclid or LSST .In particular we find that : - The predicted number density of large quiescent galaxies is too high compared to observations ; this situation could be alleviated if AGN feedback were more efficient than implied here . - Our predictions are compatible with current estimates of the cosmic SFRD out to redshifts of about 4 . 5 , although they tend to overpredict it somewhat beyond that redshift .- At small masses ( Mstar < 10 ^ 10 Msun ) there seems to be an accumulation of blue stars relative to blue stars in both the real Universe and in our simulations . This might suggest that either our treatment of supernova feedback and / or reionization theory requires improvement , or otherwise that these mechanisms have been affected by baryonic effects not involved in our modeling .",
        "ori-fast-z-score": -1.3251783128981585,
        "water-fast-z-score": 5.888888888888889
    },
    {
        "original_text": "The effect of silver and indium on the magnetic properties, electrical resistivity (ER) and Hall coefficient (R H ) has been investigated in La 2/3 Ca 1/3 Mn O 3 . The results show that ER decreases with increasing temperature for all samples while R H increases with decreasing temperature. It is found that both silver and indium doping decrease T C , increase J c and enhance pinning force density F p . Silver doped sample shows higher values of J c than indium doped one at low temperatures but lower value at high temperatures.  These results are explained by considering different effects of silver and indium ions on the microstructure as well as their influence on oxygen vacancies concentration. This work was supported by the National Natural Science Foundation of China under Grant No. 50571040. We would like to thank Prof. Y. M. Wu for his help during this research. Abstract: In this study we have prepared two series of La 2/3 Ca 1/3 MnO 3 :Ag and La 2/3 Ca 1/3 MnO3 :In polycrystalline composite materials using solid state reaction method. X-ray powder diffraction patterns confirm single phase formation without any impurity peaks. The structural parameters such as lattice constant, unit cell volume and bond length were calculated from XRD data. The dc magnetization measurements reveal that Curie temperature (Tc), critical current density (Jc) and pinning force density (Fp) decrease with increasing amount of silver or indium content.",
        "watermark_text": "The impact of silver and indium on the magnetic properties , thermal resistivity ( ER ) and Hall coefficient ( R H ) has been investigated in La 2 / 3 Ca 1 / 3 Mn O 3 . The results show that ER decreases with expanding temperature for all specimens while R H increases with varying temperature .It is found that both silver and indium doping change T C , enhance J c and enhance pinning power concentration F p . Silver doped specimen shows better levels of J c than indium doped one at low temperatures but smaller value at high temperatures .These data are explained by examining different impacts of silver and indium ions on the microstructure as also as their influence on oxygen vacancies density . This research was supported by the National Natural Science Foundation of China under Grant No .50571040.We would like to thank Prof. Y. M. Wu for his help during this research.Abstract : In this study we have formed two sequence of La 2 / 3 Ca 1 / 3 MnO 3 : Ag and La 2 / 3 Ca 1 / 3 MnO3 : In polycrystalline composite materials utilizing solid state process method . X - ray powder diffraction patterns indicate single phase form without any impurity peaks .The structural values such as structure constant , unit cell size and bond length were calculated from XRD information . The dc magnetization calculations reveal that Curie temperature ( Tc ) , vital current density ( Jc ) and pinning power concentration ( Fp ) decline with varying amount of silver or indium content .",
        "ori-fast-z-score": 0.8081220356417685,
        "water-fast-z-score": 7.677159338596802
    },
    {
        "original_text": "The discovery space for astronomical research is vast, with many different types of surveys being conducted at all wavelengths across the electromagnetic spectrum. In this talk I will discuss how wide field optical imaging surveys have been used to discover new classes of objects in our Universe such as quasars, galaxies, clusters of galaxies, supernovae, gamma ray bursts etc., and also how these surveys are now providing data on dark energy which drives cosmic acceleration. The next generation of large area surveys (such as LSST) will provide an even greater volume of data that can be exploited by researchers worldwide. This talk will give examples of some recent results obtained using data from current and past surveys including the Sloan Digital Sky Survey (SDSS), Panoramic Survey Telescope & Rapid Response System 1 (Pan-STARRS1), Dark Energy Survey (DES), VISTA Kilo-Degree Infrared Galaxy survey (VIKING).",
        "watermark_text": "The discovery area for astronomical investigations is vast , with many various types of surveys being performed at all wavelengths across the electromagnetic spectrum . In this talk I will explore how wide field visual imaging observations have been used to find new classes of bodies in our Universe such as quasars , galaxies , clusters of stars , supernovae , alpha ray bursts etc . , and also how these observations are now offering data on dark energy which explains cosmic acceleration .The future generation of large area surveys ( such as LSST ) will provide an much larger volume of statistics that can be exploited by researchers worldwide . This discussion will provide descriptions of some latest findings obtained using data from recent and previous surveys including the Sloan Digital Sky Survey ( SDSS ) , Panoramic Survey Telescope & Rapid Response System 1 ( Pan - STARRS1 ) , Dark Energy Survey ( DES ) , VISTA Kilo - Degree Infrared Galaxy survey ( VIKING ) .",
        "ori-fast-z-score": -1.8325416653445783,
        "water-fast-z-score": 5.093248125762992
    },
    {
        "original_text": "We study anisotropy in the ac response of mesoscopic superconducting films with respect to the direction of an applied magnetic field, using numerical simulations based on the quasiclassical theory for disordered metals and the Usadel equations. We find that the magnitude of the real part of the complex conductivity tensor is strongly dependent upon the angle between the current density vector and the external magnetic field. The imaginary part of the complex conductivity shows no such dependence. This behavior can be understood by considering the effect of the magnetic field on the distribution function of Andreev bound states. Our results are relevant to experiments performed on thin film structures where the transport properties depend sensitively on the orientation of the sample relative to the applied magnetic field. \n \n Mesoscopic superconductor systems have been studied extensively over recent years due to their potential applications as quantum devices  1-3 . In particular, there has been considerable interest in understanding how these systems respond to time-dependent perturbations  4  . For example, it was recently shown experimentally  5  , that when a dc bias voltage Vdc = 0 is applied across a Josephson junction array (JJA), the system exhibits hysteretic switching between two different resistive states which occur at critical values of the amplitude of the alternating current Vac. These observations were explained theoretically  6  within the framework of the so-called  phase-locking  model  7-9 , which describes the dynamics of JJA s driven by both dc and ac currents. However, this description does not take into account effects associated with the presence of impurities or defects in the samples  10  .\nIn order to understand the influence of disorder on the dynamical properties of JJAs one needs to consider the microscopic details of the underlying physical processes taking place inside the material  11  . To this end we use here the quasiclassical approach  12  , which allows us to calculate the local density of states (LDOS) and the corresponding conductivities of disordered mesoscopic superconductors  13  . Within this formalism, the LDOS is determined self-consistently from the solution of the Usadel equation  14  \nwhere D(E) is the",
        "watermark_text": "We research anisotropy in the ac response of mesoscopic superconducting films with regard to the direction of an applied magnetic force , using numerical simulations based on the quasiclassical principle for disordered metals and the Usadel equations . We see that the severity of the real part of the complex conductivity tensor is strongly dependent upon the angle between the current density vector and the external magnetic force .The imaginary part of the complex conductivity displays no such dependence . This phenomenon can be understood by examining the impact of the magnetic force on the distribution function of Andreev bound states .Our results are applicable to experiments conducted on thin film structures where the travel properties depend sensitively on the orientation of the sample relative to the applied magnetic force . Mesoscopic superconductor systems have been studied frequently over recent history owing to their potential applications as quantum devices 1 - 3 .In particular , there has been substantial interest in understanding how these systems behave to time - based perturbations 4 . For instance , it was recently shown experimentally 5 , that when a dc bias voltage Vdc = 0 is applied across a Josephson junction array ( JJA ) , the circuit exhibits hysteretic alternating between two different resistive states which occur at critical values of the frequency of the alternating current Vac .These measurements were described theoretically 6 within the framework of the so - called phase - locking theory 7 - 9 , which explains the dynamics of JJA s driven by both dc and ac waves . However , this description does not take into consideration phenomena associated with the presence of impurities or defects in the samples 10 .In order to comprehend the impact of disorder on the dynamical properties of JJAs one needs to consider the microscopic aspects of the fundamental physical processes taking place inside the material 11 . To this end we utilize here the quasiclassical method 12 , which allows us to estimate the local concentration of states ( LDOS ) and the equivalent conductivities of disordered mesoscopic superconductors 13 .Within this formalism , the LDOS is calculated self - continuously from the solve of the Usadel equation 14 where D ( E ) is the",
        "ori-fast-z-score": -1.087114613009218,
        "water-fast-z-score": 6.833333333333333
    },
    {
        "original_text": "We present an approach to the assimilation of magnetic field observations into numerical models using variational methods. The method is applied to a simple model problem in which we consider the evolution of a single component of the magnetic vector potential in a two-dimensional domain with periodic boundary conditions. We use this example as a testbed to explore how different choices of observation operator affect the quality of the resulting analysis fields. In particular, we compare results obtained by applying our algorithm directly on the state variable (the magnetic vector potential) against those obtained when it is first projected onto a set of basis functions that are chosen to be optimal for representing the solution at each time step. Our experiments show that both approaches yield similar results but that the latter can lead to significant computational savings. Finally, we demonstrate the utility of our approach by performing a series of twin experiments in which synthetic magnetometer measurements are used to update the initial condition of the simulation.",
        "watermark_text": "We present an approach to the assimilation of magnetic field observations into numerical models using variational techniques . The method is applied to a simple simulation problem in which we study the evolution of a single part of the magnetic vector potential in a two - dimensional domain with periodic boundary constraints .We use this example as a testbed to examine how various choosing of observation operator impact the performance of the resulting assessment fields . In particular , we compare findings obtained by using our technique directly on the state variable ( the magnetic vector potential ) against those achieved when it is initially projected onto a setting of basis functions that are chosen to be appropriate for describing the solution at each time step .Our experiments show that both approaches yield similar results but that the latter can lead to significant computational savings . Finally , we prove the utility of our approach by performing a sequence of twin tests in which synthetic magnetometer measurements are applied to modify the early condition of the model .",
        "ori-fast-z-score": -0.8528028654224417,
        "water-fast-z-score": 5.330017908890261
    },
    {
        "original_text": "We study theoretically and numerically the effect of spatial dispersion (SD) on the shape of a light pulse propagating through an InGaAs/GaAs quantum well (QW). We show that SD leads to significant changes in the temporal profile of the transmitted pulse, which can be used for its characterization. The results are obtained by solving Maxwell s equations using the finite-difference time-domain method with periodic boundary conditions. It is shown that the presence of SD causes the appearance of additional peaks at both sides of the main peak of the transmitted pulse. These peaks become more pronounced as the QW width increases. \n \n Keywords: Light propagation, Finite difference time domain method, Quantum wells, Spatial dispersion. 1 Introduction \n \n A number of recent studies have been devoted to investigating the effects of spatial dispersion (SD), also known as nonlocality or transverse momentum conservation  1  , on various physical phenomena such as nonlinear wave dynamics  2  -  4  , spontaneous emission  5  , and transport  6  . This interest has been motivated mainly by the fact that many semiconductor devices operate under conditions where SD plays an important role  7, 8  .\n \nIn this work we consider the problem of light transmission through a single-mode quantum well (QW) structure  9  . Our aim is to investigate how SD affects the shape of the transmitted pulse. To do so, we solve Maxwell s equations using the finitedifference time-domain (FDTD) method  10  with periodic boundary conditions  11  . As it will be demonstrated below, our numerical simulations reveal that SD gives rise to new features in the temporal profile of a transmitted pulse.",
        "watermark_text": "We research theoretically and numerically the impact of spatial dispersion ( SD ) on the morphology of a light pulse propagating through an InGaAs / GaAs quantum well ( QW ) . We see that SD leads to significant improvements in the temporal profile of the transmitted signal , which can be used for its characterization .The results are derived by treating Maxwell s coefficients using the finite - variation time - domain approach with periodic boundary constraints . It is demonstrated that the presence of SD causes the appearance of new peaks at both sides of the main peak of the transmitted signal .These peaks become more pronounced as the QW width rises . Keywords : Light propagation , Finite difference time domain approach , Quantum wells , Spatial dispersion .1 Introduction A couple of recent studies have been focused to investigating the effects of spatial dispersion ( SD ) , sometimes called as nonlocality or transverse momentum conservation 1 , on various physical phenomena such as nonlinear wave interactions 2 - 4 , spontaneous emission 5 , and transport 6 . This interest has been motivated mainly by the fact that several semiconductor devices exist under environments where SD plays an important role 7 , 8 .In this research we study the issue of light transport through a single - mode quantum well ( QW ) structure 9 . Our aim is to examine how SD impacts the form of the transmitted signal .To do so , we solve Maxwell s coefficients utilizing the finitedifference time - domain ( FDTD ) method 10 with periodic boundary constraints 11 . As it will be showed below , our numerical simulations reveal that SD offers rise to novel features in the temporal profile of a broadcast pulse .",
        "ori-fast-z-score": -0.8181818181818182,
        "water-fast-z-score": 6.518573715061334
    },
    {
        "original_text": "We present new measurements of rotational widths (W20) and surface brightnesses (SB) for a sample of galaxies with inclinations between 30°and 80°, drawn from the Sloan Digital Sky Survey Data Release 7. We find that W20 is correlated strongly with SB at fixed luminosity, but only weakly or not at all with galaxy mass. This correlation persists even when we restrict our analysis to late-type spirals, which are known to have flat rotation curves. These results suggest that the observed scatter in the Tully-Fischer relation may be due primarily to variations in SB among galaxies of similar luminosities rather than differences in their masses. In addition, we show that this effect can explain why previous studies found no significant dependence on inclination angle in the TF relation. Finally, we demonstrate how these correlations affect estimates of the Hubble constant derived using the TF relation. Our findings also provide an explanation for the apparent discrepancy between the values obtained by different authors who used samples selected over different ranges of inclination angles.",
        "watermark_text": "We present new measurements of rotational widths ( W20 ) and surface brightnesses ( SB ) for a sample of galaxies with inclinations between 30°and 80° , obtained from the Sloan Digital Sky Survey Data Release 7 . We see that W20 is associated strongly with SB at fixed luminosity , but only strongly or not at all with star mass .This correlation persists even when we limit our analysis to late - class spirals , which are known to have flattened rotation curves . These conclusions show that the seen scatter in the Tully - Fischer relation might be due primarily to variations in SB among galaxies of comparable luminosities rather than differences in their masses .In addition , we prove that this effect can reason why previous research found no considerable dependence on tilt angle in the TF relation . Finally , we prove how these correlations influence estimates of the Hubble constant calculated using the TF relation .Our findings also suggest an reason for the alleged discrepancy between the estimates obtained by various scientists who used data selected over particular ranges of inclination distances .",
        "ori-fast-z-score": -1.5215349135496974,
        "water-fast-z-score": 5.7350162126103985
    },
    {
        "original_text": "We present new observations of the solar atmosphere obtained with the Solar Ultraviolet Imager (SUVI) onboard the Coriolis satellite, which show dynamic fibrils in both H-alpha and CIV lines. The SUVI data are compared to simultaneous ground-based observations made at Big Bear Observatory using the 1-meter telescope equipped with an H-Alpha filter and a Fabry-Perot interferometer tuned to the CIV line. We find that the observed structures have similar properties as those seen previously by other authors but we also see some differences between them. In particular, our results suggest that the fibril structure is more complex than it was thought before. This complexity may be related to the fact that these structures are formed under different physical conditions. Our analysis shows that the observed features can be explained by assuming that they represent plasma flows along magnetic field lines. These flows could play important role in heating up the upper layers of the solar atmosphere.",
        "watermark_text": "We present new surveys of the solar atmosphere acquired with the Solar Ultraviolet Imager ( SUVI ) onboard the Coriolis spacecraft , which show dynamic fibrils in both H - alpha and CIV lines . The SUVI images are compared to simultaneous ground - based observations made at Big Bear Observatory using the 1 - meter telescope fitted with an H - Alpha filter and a Fabry - Perot interferometer tuned to the CIV line .We see that the seen features have related properties as those saw previously by other researchers but we also saw some variations between them . In particular , our findings confirm that the fibril structure is more sophisticated than it was considered before .This difficulty must be connected to the fact that these structures are created under distinct physical conditions . Our study shows that the seen features can be described by assuming that they represent plasma flows along magnetic field lines .These flows could play major part in heating up the higher layers of the solar atmosphere .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.277372492166241
    },
    {
        "original_text": "We show that the answer to this question is no, at least in principle. We consider two models for dark energy which are observationally indistinguishable but have different physical origins; one is due to vacuum fluctuations while the other arises as an effective field theory description of quantum gravity effects. In both cases there exists a parameter space where the predictions for the evolution of the universe agree with current observations within experimental uncertainties. However, if future experiments can measure the equation-of-state of dark energy more accurately then it may be possible to differentiate these two scenarios. The discovery of cosmic acceleration has led to much interest in the possibility that our universe contains some form of  dark energy ; see e.g.,  1  . This exotic component would drive the expansion of the universe today and dominate its dynamics on large scales. A number of theoretical proposals exist for what such a dark energy might consist of (see  2  for a review). One particularly interesting class of possibilities involves introducing new fields into Einstein s equations whose presence leads to repulsive gravitational forces  3  .\nIn recent years many authors have studied the phenomenology associated with various forms of dark energy; see  4  -  8  ,  10  -  12  ,  14  -  16  ,  18  -  20  ,  22  -  26  ,  28  -  30  ,  32  -  38  ,  41  -  44  ,  46  -  48  ,  50  -  52  ,  54  -  61  ,  63  -  65  ,  67  -  71  ,  73  -  75  ,  77  -  81  ,  83  -  85  ,  88  -  92  ,  94  -  103  . Many of these works focus on comparing specific models against observational data or studying their implications for fundamental physics. Here we take a complementary approach by considering whether any two distinct models could give rise to identical observable consequences.",
        "watermark_text": "We see that the response to this question is no , at least in principle . We consider two models for black energy which are observationally indistinguishable but have different physical origins ; one is due to vacuum fluctuations while the other arises as an useful field model representation of quantum gravitational interactions .In both cases there exists a parameter room where the estimates for the evolution of the universe comply with current observations within experimental uncertainties . However , if future research can measure the equation - of - state of dark energy more accurately then it could be possible to differentiate these two scenarios .The observation of universe acceleration has led to great discussion in the prospect that our universe possesses some kind of dark energy ; seeing e . g . , 1 . This exotic component might power the evolution of the universe today and influence its mechanics on huge scales .A variety of theoretical proposals exist for what such a black force may consist of ( hear 2 for a review ) . One especially interesting class of possibilities includes introducing additional fields into Einstein s equations whose presence contributes to repulsive gravitational pressures 3 .In past decades several authors have researched the phenomenology identified with various forms of dark energy ; see 4 - 8 , 10 - 12 , 14 - 16 , 18 - 20 , 22 - 26 , 28 - 30 , 32 - 38 , 41 - 44 , 46 - 48 , 50 - 52 , 54 - 61 , 63 - 65 , 67 - 71 , 73 - 75 , 77 - 81 , 83 - 85 , 88 - 92 , 94 - 103 . Many of these works concentrate on comparing actual models against observational data or exploring their implications for theoretical physics .Here we took a complementary perspective by examining whether any two separate models could give rise to identical observable effects .",
        "ori-fast-z-score": -0.44367825470805694,
        "water-fast-z-score": 8.131727983645296
    },
    {
        "original_text": "We present the results of an optical integral-field spectroscopy (IFS) survey to find high-redshift Damped Lyman Alpha Galaxies (DLAs). The sample consists of 16 DLAs at redshifts between 2 and 4, selected by their strong Mg II absorption lines in quasar spectra observed with the Keck telescope. We use the Gemini MultiObject Spectrograph on the 8-meter Gemini North Telescope to obtain spatially resolved observations over a 1 arcsec2 area centered around each absorber. Our IFS data are used to study the kinematics of these absorbers as well as their physical properties such as metallicity and dust content. In addition we compare our new measurements with previous studies based on single-aperture spectrophotometry. This work is part of the Gemini Observatory program GN-2007B-Q-206. Keywords: High-redshift universe; Galaxy evolution; Absorber-galaxy relationship",
        "watermark_text": "We present the conclusion of an optical integral - field spectroscopy ( IFS ) study to find high - redshift Damped Lyman Alpha Galaxies ( DLAs ) . The sample consists of 16 DLAs at redshifts between 2 and 4 , selected by their weak Mg II absorb lines in quasar spectra observed with the Keck lens .We use the Gemini MultiObject Spectrograph on the 8 - meter Gemini North Telescope to obtain spatially resolved surveys over a 1 arcsec2 region focused around each absorber . Our IFS data are applied to study the kinematics of these absorbers as well as their physical properties such as metallicity and dust content .In addition we compare our new data with previous research based on single - lens spectrophotometry . This research is part of the Gemini Observatory program GN - 2007B - Q - 206 .Keywords : High - redshift universe ; Galaxy evolve ; Absorber - galaxy relationship",
        "ori-fast-z-score": -0.29488391230979427,
        "water-fast-z-score": 3.8334908600273256
    },
    {
        "original_text": "We report on multiwavelength observations of the X-ray, optical and radio afterglows of the short-hard gamma-ray burst (GRB) 050724 detected by Swift satellite at 07:24:06 UT on 24 July 2005. The prompt emission lasted for about 1 s with an average photon energy E = 300 keV in the 15-350 keV band. We find that the temporal decay index is ~1.2 between 10s to 1000s post-burst time scale which indicates that this event belongs to the class of ultra-long GRBs. In addition we also detect a possible rebrightening feature around 100s post-burst time-scale. Our spectral analysis shows that the spectrum can be fitted well using both single power-law model as well as broken power law model. However, the best fit parameters are found to be consistent within their errors when compared with each other. Using our multi-wavelength data set, we estimate the total energetics associated with this event to be ~3 x 1044 erg.",
        "watermark_text": "We report on multiwavelength studies of the X - ray , optical and radio afterglows of the short - hard beta - ray burst ( GRB ) 050724 detected by Swift satellite at 07 : 24 : 06 UT on 24 July 2005 . The prompt emission lasted for about 1 s with an maximum photon energy E = 300 keV in the 15 - 350 keV band .We see that the temporal decay rate is ~ 1 . 2 between 10s to 1000s post - burst time scale which implies that this event belongs to the class of ultra - long GRBs . In addition we also observe a possible rebrightening characteristic around 100s post - burst time - range .Our frequency evaluation demonstrates that the spectrum can be fit well using both single power - law method as also as broken power law method . However , the best fit factors are found to be compatible within their errors when compared with each other .Using our multi - wavelength information pool , we estimate the total energetics associated with this event to be ~ 3 x 1044 erg .",
        "ori-fast-z-score": 2.121320343559643,
        "water-fast-z-score": 6.83536555146996
    },
    {
        "original_text": "We present new exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors, which are generated by applying nonholonomic frame transforms (NFT) to known vacuum solutions. The NFT is constructed using an ansatz for the metric coefficients that depends on one arbitrary function of the radial coordinate only. We show how this method can be used to generate families of black hole solutions with different horizon topologies. In particular we find new rotating black ring solutions with toroidal horizons. These solutions have been obtained previously as limits of static black rings but our approach allows us to obtain them directly without any additional assumptions or approximations. Finally, we discuss some open problems related to these results. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq \nI. INTRODUCTORY REMARkS\nThe study of exact solutions to the Einstein equations has played a crucial role in understanding many aspects of general relativity. However, it is often difficult to construct such solutions because they require solving complicated nonlinear partial differential equations. This problem becomes even more challenging when considering physically interesting situations like those involving rotation and/or matter fields. Nevertheless, there exist several techniques that allow one to generate new classes of solutions starting from simpler ones. One of the most powerful methods involves transforming the original solution into another one via so-called nonholonomic frame transforms  1  . Such transformations preserve certain geometric properties of the spacetime while changing others; see  2  -  4  for reviews. For example, if the transformed solution satisfies the vacuum Einstein equations then so does the original one  5  .\nIn this work we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to generate new exact solutions describing stationary axisymmetric spacetimes: i.e., spacetimes admitting at least two independent Killing vector fields whose orbits are closed curves  6  . Stationary axisymmetric spacetimes play an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars, planets, and black holes  7, 8 ",
        "watermark_text": "We introduce novel exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors , which are produced by using nonholonomic frame transforms ( NFT ) to known vacuum solutions . The NFT is built using an ansatz for the metric coefficients that relies on one arbitrary function of the radial coordinate only .We see how this algorithm can be used to create families of grey hole problems with various horizon topologies . In particular we find unique spinning black ring solutions with toroidal horizons .These solutions have been achieved formerly as limits of static black rings but our approach allows us to obtain them directly without any additional constraints or approximations . Finally , we explain some open problems related to these results .PACS codes : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq I . INTRODUCTORY REMARkS The investigation of precise solutions to the Einstein equations has held a crucial role in understanding several parts of general relativity .However , it is often challenging to build such problems because they demand solving complicated nonlinear partial differential equations . This problem remains especially more challenging when exploring physically exciting situations like those concerning rotation and / or matter forces .Nevertheless , there remain many procedures that enable one to create fresh categories of solutions starting from simpler ones . One of the most popular methods means mapping the previous solve into another one via so - called nonholonomic frame transforms 1 .Such transformations maintain certain geometric properties of the spacetime while altering others ; look 2 - 4 for reviews . For instance , if the transformed solution satisfies the vacuum Einstein equations then so does the previous one 5 .In this research we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to create novel exact solutions governing stationary axisymmetric spacetimes : i . e . , spacetimes admitting at least two independent Killing matrix fields whose orbits are closed curves 6 . Stationary axisymmetric spacetimes serve an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars , planets , and dark holes 7 , 8",
        "ori-fast-z-score": -1.3805369799252667,
        "water-fast-z-score": 7.777427086962838
    },
    {
        "original_text": "The Karlsruhe Tritium Neutrino experiment (KATRIN) is currently under construction at the Karlsruhe Institute for Technology, Germany. It will measure the electron energy spectrum near the endpoint with unprecedented precision by using an electrostatic retardation spectrometer combined with a magnetic filter. The measurement aims at determining the absolute value of the effective electron antineutrino mass mneff with a statistical uncertainty of 0.2 eV/c2 or better. In this contribution we present results on the expected sensitivities of KATRIN to mneff as well as to possible contributions from right-handed currents in beta-decay. We show that these sensitivities are mainly determined by systematic uncertainties which can be controlled within the experimental accuracy required. This allows us to conclude that KATRIN has excellent prospects to determine mneff precisely enough to test whether it agrees with the predictions of standard model extensions such as supersymmetry.",
        "watermark_text": "The Karlsruhe Tritium Neutrino experiment ( KATRIN ) is currently under construction at the Karlsruhe Institute for Technology , Germany . It will measure the electron energy spectrum near the endpoint with incredible precision by using an electrostatic retardation spectrometer together with a magnetic filter .The measurement seeks at determining the absolute significance of the effective electron antineutrino mass mneff with a statistical uncertainty of 0 . 2 eV / c2 or better . In this contribution we present results on the expected sensitivities of KATRIN to mneff as well as to possible contributions from left - handed waves in beta - emission .We suggest that these sensitivities are mainly decided by systematic uncertainties which can be regulated within the empirical precision required . This enables us to observe that KATRIN has excellent potential to identify mneff exactly enough to test whether it agrees with the estimates of standard theory extensions such as supersymmetry .",
        "ori-fast-z-score": -1.1920791213585393,
        "water-fast-z-score": 4.370956778314644
    },
    {
        "original_text": "We present an extension to the standard model that includes gravity, based on Feynman s ideas about quantum gravity. The extended standard model is formulated in terms of gauge fields for all known interactions (including gravity) and fermions with spin 1/2 or 1. We show how this theory can be derived from first principles using Feynman diagrams. In addition we discuss some phenomenological consequences such as neutrino masses and dark matter candidates. Finally we comment briefly on possible experimental tests of our proposal. This work was supported by NSF grant PHY-0456747. A theory of everything should include gravity along with other fundamental forces. Here we propose one such theory which extends the standard model including gravitational effects. Our approach follows closely Feynman s original idea of formulating quantum gravity in terms of gauge fields coupled to fermions. Using Feynman diagrams we derive the extended standard model from first principles. Some phenomenological consequences are discussed, e.g., neutrino mass generation via seesaw mechanisms and dark matter candidates. Possible experiments testing our proposal are also mentioned.",
        "watermark_text": "We introduce an addition to the standard theory that encompasses gravity , built on Feynman s ideas about particle gravity . The extended standard theory is implemented in terms of gauge fields for all known interactions ( including gravity ) and fermions with spin 1 / 2 or 1 .We see how this theory can be derived from first principles utilizing Feynman diagrams . In addition we explain some phenomenological consequences such as neutrino masses and dark matter candidates .Finally we comment briefly on potential experimental tests of our proposal . This project was supported by NSF grant PHY - 0456747 .A description of things should involve gravity along with other fundamental forces . Here we undertake one such idea which extends the standard theory including gravitational interactions .Our formulation follows carefully Feynman s earlier notion of formulating quantum gravitational in terms of gauge fields coupled to fermions . Using Feynman diagrams we derive the extended standard description from first principles .Some phenomenological consequences are discussed , e . g . , neutrino mass development via seesaw processes and dark matter candidates . Possible experiments testing our proposal are also discussed .",
        "ori-fast-z-score": 1.1531133203941102,
        "water-fast-z-score": 8.07179324275877
    },
    {
        "original_text": "Affinity propagation (AP) is an algorithm for clustering that has been shown to be effective in many applications, including bioinformatics and computer vision. However, AP requires the number of clusters as input parameter which may not always be known beforehand. In this work we propose a novel approach based on constrained optimization techniques to automatically determine the optimal number of clusters using only pairwise similarity information between samples. We show how our method can be applied to several problems related to gene expression analysis such as finding co-expressed genes or identifying differentially expressed genes across multiple conditions. Our results demonstrate that our proposed method outperforms state-of-the-art approaches both in terms of accuracy and robustness. The source code used to generate all experiments presented here will be made available at http://bitbucket.org/juanlorenzo/softconstraint-clustering/wiki/Home . Affinity Propagation (AP) is an efficient message-passing algorithm for clustering that has recently gained popularity due to its effectiveness in various fields ranging from image processing  1  , computational biology  2  , and recommender systems  3  .\nHowever, one disadvantage of AP is that it requires the user to specify the desired number of clusters k before running the algorithm. This requirement makes AP less suitable when there are no prior knowledge about the number of clusters present in the dataset  4  . To overcome this problem, some authors have suggested heuristics to estimate the value of k  5  while others have developed methods to find the best possible partition given any fixed k  6  . Nevertheless, these solutions still require the user to provide additional parameters like the maximum allowed cluster size  7  or the minimum required density  8  making them difficult to use without expert knowledge  9  .\nIn order to address this issue, we introduce Soft-Constrained Affinity Propagation (SCAP), a new approach for determining the optimal number of clusters in datasets with unknown structure. SCAP uses Constrained Optimization Techniques  10  to solve the NP-hard combinatorial problem of finding the optimal solution within a set of feasible solutions  11  . More specifically,...",
        "watermark_text": "Affinity propagation ( AP ) is an algorithm for clustering that has been shown to be successful in multiple users , notably bioinformatics and computer vision . However , AP needs the number of clusters as input parameter which would not always be determined beforehand .In this research we attempt a new approach using on constrained optimization tactics to automatically identify the ideal amount of clusters using only pairwise similarity information between samples . We see how our technique can be applied to several difficulties related to gene transcription evaluation such as finding co - expressed proteins or discovering differentially expressed proteins across multiple conditions .Our results show that our proposed approach outperforms state - of - the - art methods both in terms of precision and robustness . The source software using to create all experiments shown here will be made accessible at http : / / bitbucket . org / juanlorenzo / softconstraint - clustering / wiki / Home .Affinity Propagation ( AP ) is an efficient signal - passing algorithm for clustering that has recently gotten popularity due to its effectiveness in different fields ranging from photo processing 1 , computational science 2 , and recommender environments 3 . However , one disadvantage of AP is that it requires the user to predict the desired amount of clusters k before running the method .This requirement creates AP less convenient when there are no previous known about the quantity of clusters present in the dataset 4 . To solve this situation , some writers have suggested heuristics to estimate the value of k 5 while others have developed methods to find the best possible partition given any fixed k 6 .Nevertheless , these solutions still allow the user to provide alternative parameters like the maximum permitted cluster number 7 or the minimum needed width 8 making them harder to use without expert knowledge 9 . In order to eliminate this question , we introduce Soft - Constrained Affinity Propagation ( SCAP ) , a new approach for determining the ideal amount of clusters in datasets with unknown structure .SCAP uses Constrained Optimization Techniques 10 to tackle the NP - hard combinatorial issue of finding the ideal solution within a setting of feasible answers 11 . More specifically , . . .",
        "ori-fast-z-score": -0.23214696976024105,
        "water-fast-z-score": 10.089956834182328
    },
    {
        "original_text": "We present the results of an investigation into the shapes and orientations of molecular cloud cores in the Orion Nebula region using near-infrared polarimetry obtained with the Gemini North telescope. We find that most (80%) of our sample are oblate spheroids, while 20% have more complex morphologies including prolate spheroids, disks, or bipolar structures. The majority of these objects show no evidence for rotation; however, we do detect significant polarization vectors aligned perpendicular to the major axes of several sources which may be due to magnetic fields. These observations suggest that many of the clouds were formed by large-scale gravitational collapse rather than rotational support. This work is supported by NASA grant NNX10AC99G. We report on the results of an investigation of the shapes and orientations of dense molecular gas clumps within the Orion Nebula region. Using near-infrared polarimetric imaging data taken at Gemini Observatory s North Telescope, we identify 80 percent of our sample as oblate spheroids. Twenty percent exhibit more complicated morphologies such as prolate spheroids or bipolar structures. Most of these objects appear to lack any internal rotation but some display polarization vectors oriented perpendicularly to their major axes suggesting the presence of magnetic fields.",
        "watermark_text": "We present the conclusion of an research into the shapes and orientations of molecular dust cores in the Orion Nebula region utilizing near - infrared polarimetry obtained with the Gemini North telescope . We see that most ( 80 % ) of our sample are oblate spheroids , while 20 % have more sophisticated morphologies including prolate spheroids , cones , or bipolar forms .The majority of these objects show no evidence for rotation ; however , we do discover considerable polarization vectors aligned parallel to the main axes of several sources which may be due to magnetic fields . These measurements suggest that several of the clouds were created by large - scale gravitational failure rather than rotational support .This research is backed by NASA grant NNX10AC99G . We report on the conclusion of an research of the shapes and orientations of dense molecular gas clumps within the Orion Nebula region .Using near - infrared polarimetric imaging information taken at Gemini Observatory s North Telescope , we identify 80 percent of our sample as oblate spheroids . Twenty half display more complicated morphologies such as prolate spheroids or bipolar forms .Most of these objects may to lack any internal rotation but some display polarization axes aligned perpendicularly to their major directions indicating the presence of magnetic waves .",
        "ori-fast-z-score": -0.329292779969071,
        "water-fast-z-score": 5.965587590013045
    },
    {
        "original_text": "We present an algorithm to solve the half-space depth problem, which is one of the most fundamental problems in computational geometry. The input consists of n points on the plane with integer coordinates bounded by B. We want to find a point that minimizes its distance to all other points. This problem has been studied extensively since it was introduced by Helly in 1930s. In this work we propose a new branch-and-cut algorithm based on mixed-integer programming (MIP) formulation. Our MIP model uses O(nB) variables and constraints. Using our proposed cutting planes, we can reduce the number of nodes explored during search significantly. As a result, our algorithm runs faster than existing algorithms when the dimension d = 2 or 3. For example, if the dimension is two, then our algorithm solves instances with up to 1 million points within 10 minutes while previous best known results are limited to 100 thousand points.",
        "watermark_text": "We introduce an algorithm to solve the half - space depth problem , which is one of the most important problems in computational geometry . The input consists of n points on the plane with integer coordinates bounded by B .We want to find a spot that minimizes its distance to all other points . This problem has been studied frequently since it was introduced by Helly in 1930s .In this research we propose a new branch - and - cut algorithm based on mixing - integer programming ( MIP ) implementation . Our MIP approach utilizes O ( nB ) parameters and constraints .Using our proposed cutting planes , we can restrict the number of vertices explored during search significantly . As a result , our scheme ran quicker than existing algorithms when the dimension d = 2 or 3 .For instance , if the dimension is two , then our technique solves situations with up to 1 million points within 10 minutes while prior best known data are limited to 100 thousand points .",
        "ori-fast-z-score": -0.5933908290969266,
        "water-fast-z-score": 4.00693842672377
    },
    {
        "original_text": "The purpose of this study is to analyze the real estate market in the city of Las Vegas (LV) by using the Composite Shiller Weiss Indexes (CSWI). The data used for analysis are monthly prices of residential properties sold between January 2005 and December 2014. In addition, we use the autoregressive integrated moving average model with exogenous variables (ARIMAX), which allows us to predict future values of the indexes based on past information. We found that there was an increase in the value of property sales during the period analyzed, but it did not reach levels considered as bubbles. However, the results show that the LV real estate market has experienced periods of overvaluation since 2007. Finally, our findings suggest that the ARIMAX model can be useful when predicting the evolution of the CSWI indexes. Keywords: Real Estate Market; Prediction Modeling; Autoregressive Integrated Moving Average",
        "watermark_text": "The purpose of this study is to analyze the real property market in the cities of Las Vegas ( LV ) by using the Composite Shiller Weiss Indexes ( CSWI ) . The data used for study are monthly prices of housing structures sold between January 2005 and December 2014 .In addition , we utilize the autoregressive integrated moved average model with exogenous parameters ( ARIMAX ) , which allows us to predict upcoming values of the indexes based on past data . We showed that there was an increase in the value of property prices during the period analyzed , but it did not reach levels regarded as bubbles .However , the results show that the LV real property market has undergone cycles of overvaluation since 2007 . Finally , our findings show that the ARIMAX theory can be valuable when predicting the evolution of the CSWI indexes .Keywords: Real Estate Market; Prediction Modeling; Autoregressive Integrated Moving Average",
        "ori-fast-z-score": 1.4832396974191326,
        "water-fast-z-score": 5.879747322073337
    },
    {
        "original_text": "We report on the discovery of an intervening galaxy with a mass M = 1011.5 ± 0.3M⊙ and size R = 1.7 ± 0.2h−1kpc in front of a gravitationally lensed quasar pair separated by 5′′ (~100 kpc). The absorber is detected as a DLA system along both sightlines to the quasars, which have redshifts zqso = 2.962 and zqso = 2. . We use this object to constrain the typical sizes of high-z galaxies. Our results suggest that these objects were typically smaller than their local counterparts when they formed most of their stars. This may be related to the fact that massive galaxies grow through mergers over cosmic time. \n \n Keywords: Galaxy evolution, Quasars, Absorbers, Massive black holes \n \n \n \n High-redshift quasars provide powerful probes for studying the physical properties of distant galaxies. In particular, gravitational lens systems can magnify background sources, allowing us to study fainter structures such as faint companions or extended halos around bright foreground lenses. Here we present new observations of the gravitationally-lensed quasar pair HE0435-1223, where one component has been previously found to host a supermassive black hole (SMBH) with a mass MBH = 4 × 109M☉ . Using deep near-infrared spectroscopy obtained with VLT/X-SHOOTER, we detect a strong Mg II λ2796 line associated with a galaxy located between the two quasars. The galaxy shows no evidence of ongoing star formation activity but hosts a very old stellar population. Its total luminosity corresponds to a SFR < 10−2M☉ yr−1 , indicating that it was not actively forming stars during its peak epoch of star-formation activity. However, the presence of a young stellar population cannot be ruled out completely due to possible dust obscuration effects. From our analysis, we find that the galaxy has a mass M = 1011+0.3−0.4M☉ and radius R =",
        "watermark_text": "We report on the discovery of an intervening galaxy with a mass M = 1011 . 5 ± 0 . [UNK] and size R = 1 . 7 ± 0 . 2h−1kpc in front of a gravitationally lensed quasar pair divided by 5 ′ ′ ( ~ 100 kpc ) . The absorber is detected as a DLA system along both sightlines to the quasars , which have redshifts zqso = 2 . 962 and zqso = 2 . .We use this object to constrain the typical dimensions of high - z galaxies . Our results show that these objects were generally tiny than their nearby rivals when they formed most of their stars .This might be connected to the fact that powerful nuclei grow through mergers over universe time . Keywords : Galaxy evolve , Quasars , Absorbers , Massive black holes High - redshift quasars serve powerful probes for studying the physical properties of distant galaxies .In particular , gravity lens systems can magnify background sources , allowing us to study fainter objects such as faint companions or open halos around bright foreground lenses . Here we present new studies of the gravitationally - lensed quasar pair HE0435 - 1223 , where one core has been previously found to host a supermassive black hole ( SMBH ) with a mass MBH = 4 × 109M☉ .Using deep near - infrared spectroscopy acquired with VLT / X - SHOOTER , we locate a powerful Mg II λ2796 point linked with a galaxy located between the two quasars . The galaxy displays no evidence of ongoing galaxy formation activity but hosts a very ancient stellar community .Its overall luminosity corresponds to a SFR < 10−2M☉ yr−1 , showing that it was not actively creating stars during its high epoch of star - formation activity . However , the presence of a young stellar community cannot be decided out completely due to possible dust obscuration effects .From our analysis , we find that the universe has a mass M = 1011 + 0 . 3−0 . 4M☉ and radius R =",
        "ori-fast-z-score": 1.9917864129354077,
        "water-fast-z-score": 8.215838362577491
    },
    {
        "original_text": "We give an explicit description of the higher algebraic K-groups in terms of certain universal cohomology classes, which are defined by using only the ring structure and the unit element of the underlying commutative ring. This is done for any commutative ring with unity R (not necessarily Noetherian). The main result can be formulated as follows: Let M be a module over R. Then there exists a natural isomorphism between the higher algebraic K-groups: \nK_n(R) = Ext^n_R(M, R)\nand the group of all n-fold Massey products on M modulo those that vanish under some suitable finiteness condition. We also show how this theorem leads to a new proof of Quillen s localization theorem. Finally we discuss applications to the study of equivariant K-theory. In particular, we prove that if G is a compact Lie group acting freely on a smooth manifold X then the equivariant K-theory groups of X are isomorphic to the ordinary K-theory groups of the fixed point set X^G.",
        "watermark_text": "We get an explicit description of the higher algebraic K - fields in terms of certain universal cohomology groups , which are established by using only the ring composition and the unit element of the underlying commutative field . This is accomplished for any commutative field with unity R ( not necessarily Noetherian ) .The main consequence can be stated as follows : Let M be a module over R . Then there exists a natural isomorphism between the higher geometric K - families : K _ k ( R ) = Ext ^ n _ R ( M , R ) and the group of all k - fold Massey products on M modulo those that vanish under some suitable finiteness requirement . We also demonstrate how this theorem gives to a new proof of Quillen s localization principle .Finally we explain applications to the study of equivariant K - theory . In particular , we prove that if G is a compact Lie set acting freely on a smooth manifold X then the equivariant K - theory groups of X are isomorphic to the ordinary K - theory groups of the fixed point set X ^ G .",
        "ori-fast-z-score": 0.23904572186687872,
        "water-fast-z-score": 5.176591682688076
    },
    {
        "original_text": "The author considers the problem of gravitational interaction between bodies in terms of their informational content. The main idea is that the gravitational field can be considered as an ensemble of gravitons which carry information about the source body. Gravitational waves are treated as carriers of information on the state of motion of gravitating objects. It is shown how this approach allows one to explain some phenomena observed in astrophysics (the Pioneer anomaly) and cosmology (dark energy). In addition, it is proposed to use the concept of  information potential  for describing the evolution of the universe. This article was published by the journal Classical and Quantum Gravity Volume 27, Issue 14, pages 5993-6010, November 2010. DOI: 10.1088/0264-9381/27/14/05993/abstract. The following text is taken directly from the original publication. \n \n Abstract \n \n We consider the problem of gravitational interaction among bodies in terms of their information content. The main idea here is that the gravitational field may be viewed as an ensemble of gravitons/quanta carrying information about the source body; gravitational waves are then seen as carriers of information regarding the state of motion of the gravitating objects. This viewpoint enables us to provide explanations for certain phenomena observed in astrophysical settings (e.g., the Pioneer anomaly), as well as in cosmological contexts (e.g., dark energy). Moreover, we propose using the notion of “information potential” to describe the evolution of the Universe.",
        "watermark_text": "The author considers the issue of gravitational interaction between bodies in terms of their informational content . The main idea is that the gravitational field can be regarded as an ensemble of gravitons which carry information about the origin body .Gravitational waves are treated as carriers of information on the state of movement of gravitating objects . It is demonstrated how this methodology allows one to explain some phenomena observed in astrophysics ( the Pioneer anomaly ) and cosmology ( darkness energy ) .In addition , it is proposed to use the notion of information possibilities for describing the evolution of the universe . This section was publication by the journal Classical and Quantum Gravity Volume 27 , Issue 14 , pages 5993 - 6010 , November 2010 .DOI : 10 . 1088 / 0264 - 9381 / 27 / 14 / 05993 / abstract . The following text is taken directly from the original published .Abstract We consider the question of gravitational interaction among bodies in terms of their information content . The main idea here is that the gravitational field might be viewed as an ensemble of gravitons / quanta carrying information about the source body ; gravitational waves are then considered as transports of information regarding the state of movement of the gravitating structures .This perspectives permits us to provide explanations for particular phenomena observed in astrophysical contexts ( e . g . , the Pioneer anomaly ) , as also as in cosmological contexts ( e . g . , darkness energy ) . Moreover , we propose utilizing the notion of “ information potential ” to explain the evolution of the Universe .",
        "ori-fast-z-score": 2.116950987028628,
        "water-fast-z-score": 6.735753140545634
    },
    {
        "original_text": "We present the prospects for high-precision measurement of the 1s2p 3P-1s2s 3S transition in atomic helium with an optical frequency comb (OFC). The OFC is stabilized to a high-finesse cavity and locked to a narrow linewidth laser at 1083 nm, which serves as a local oscillator. We show that this system can be used to measure the absolute frequencies of two transitions in helium with uncertainties below 100 kHz. This will allow us to determine the fine-structure constant α with relative uncertainty better than 2×10−10 by measuring the ratio between these two frequencies. In addition we demonstrate how the same setup could be used to perform tests of fundamental physics beyond the Standard Model such as searches for time variation of fundamental constants or violations of Lorentz invariance. Optical frequency combs are powerful tools for precise metrology  1–3  . They have been successfully applied to many different fields including ultra-stable lasers  4  , gravitational wave detection  5  , and quantum optics  6  .\nIn particular they provide unprecedented possibilities for high-precision measurement  7–9  . Here we propose to use them to improve our knowledge on the value of the fine structure constant  10  . To achieve this goal it is necessary to measure the absolute frequencies f(1s2p 3P1) = 929 072 631 770 Hz  11  and f(1s2s 3S1) = 929 073 761 828 Hz  12  of two transitions in helium. These values were determined previously with uncertainties of about 300 kHz  13  but recent theoretical calculations suggest that their accuracy may be improved significantly  14–18  .",
        "watermark_text": "We present the possibilities for high - precision study of the 1s2p 3P - 1s2s 3S change in nuclear helium with an optical frequency comb ( OFC ) . The OFC is stabilized to a high - finesse cavity and locked to a broad linewidth laser at 1083 nm , which serves as a local oscillator .We see that this scheme can be used to measure the absolute frequencies of two transitions in helium with uncertainties below 100 kHz . This will provide us to estimate the fine - structure constant α with absolute uncertainty better than 2×10−10 by measuring the ratio between these two frequencies .In addition we prove how the same setup could be used to conduct tests of fundamental physics beyond the Standard Model such as searches for moment variation of fundamental constants or violations of Lorentz invariance . Optical frequency combs are powerful tools for precise metrology 1 – 3 .They have been successfully applied to many various fields including ultra - stable lasers 4 , gravity wave detection 5 , and quantum optics 6 . In particular they give unprecedented possibilities for high - precision study 7 – 9 .Here we undertake to use them to improve our information on the value of the fine structure constant 10 . To achieve this goal it is required to measure the absolute frequencies g ( 1s2p 3P1 ) = 929 072 631 770 Hz 11 and f ( 1s2s 3S1 ) = 929 073 761 828 Hz 12 of two transitions in helium .These figures were determined earlier with uncertainties of about 300 kHz 13 but recent theoretical calculations suggest that their sensitivity might be improved dramatically 14 – 18 .",
        "ori-fast-z-score": 0.8700628401410971,
        "water-fast-z-score": 6.477134476605945
    },
    {
        "original_text": "We present the results on morphology and luminosity function for the most luminous galaxy clusters in the Universe, selected by their X-ray emission (the RCS2 sample). We find that these objects are characterized by an elliptical shape with axial ratio q = 0.7 ± 0.1 and by a steep luminosity function dN/dL ∝ L−2.5±0.3 . The observed properties suggest that they may be identified as fossil groups or proto-clusters at z > 1.0 .\nThe data used here were obtained during our observing runs performed at ESO telescopes under programs IDs: 073.A-0505(B), 078.A-0518(C) and 079.A-0739(D) . In this work we study the morphological and photometric properties of the brightest galaxy clusters in the universe. These systems have been detected through their X-ray emission using the ROSAT All Sky Survey (RASS; Voges et al., 1999) , and then followed up spectroscopically to confirm their redshifts and measure their velocity dispersions (see e.g. Rosati et al. , 1998 , Gladders & Yee 2005 , Eisenhardt et al. , 2008 . They represent some of the most massive structures known so far in the universe, being able to host several thousands of galaxies each one. Their high mass makes them ideal targets to investigate how such large scale structures form and evolve over time.",
        "watermark_text": "We present the conclusion on morphology and luminosity function for the most luminous galaxy galaxies in the Universe , selected by their X - ray radiation ( the RCS2 specimen ) . We see that these objects are marked by an elliptical shape with axial ratio g = 0 . 7 ± 0 . 1 and by a steep luminosity function dN / dL [UNK] L−2 . 5±0 . 3 .The observed properties suggest that they may be identified as extinct families or proto - complexes at z > 1 . 0 . The data used here were obtained during our observing walks performed at ESO telescopes under programs IDs : 073 . A - 0505 ( B ) , 078 . A - 0518 ( C ) and 079 . A - 0739 ( D ) .In this research we study the morphological and photometric properties of the brightest galaxy galaxies in the universe . These systems have been detected through their X - ray emission utilizing the ROSAT All Sky Survey ( RASS ; Voges et al . , 1999 ) , and then followed up spectroscopically to confirm their redshifts and track their velocity dispersions ( see e . g .Rosati et al . , 1998 , Gladders & Yee 2005 , Eisenhardt et al ., 2008 . They hold some of the most gigantic structures discovered so far in the universe , being could to host numerous thousands of galaxies each one .Their high mass creates them ideal targets to examine how such large scale structures structure and evolve over time .",
        "ori-fast-z-score": 0.1125087900926024,
        "water-fast-z-score": 5.512930714537517
    },
    {
        "original_text": "We present the first direct determination of the stellar radius in an interacting binary system, using interferometric observations obtained with the VLTI and AMBER instrument. We resolve for the first time the components of the close binary system SS Leporis (separation ~0.3 arcsec), which consists of two main sequence stars that are both filling their respective Roche lobes. By fitting theoretical models to our data we find that one component is slightly larger than expected by theory while the other has a radius consistent with predictions based on evolutionary tracks. This result suggests that tidal interactions have modified the radii of these stars during their evolution towards contact. Our results also show that the orbital inclination angle i = 60 ± 5 degrees, as determined previously through radial velocity measurements, agrees well with our new estimate derived directly from the observed separation between the two stars. Keywords: Interferometry; Binary Stars; Stellar Radius",
        "watermark_text": "We present the first complete measurement of the stellar radius in an interacting binary system , using interferometric observations derived with the VLTI and AMBER method . We resolve for the first time the parts of the distant binary system SS Leporis ( separation ~ 0 . 3 arcsec ) , which consists of two principal sequence stars that are both filling their separate Roche lobes .By fitting theoretical estimates to our information we find that one part is slightly larger than expected by hypothesis while the other has a diameter compatible with predictions based on evolutionary tracks . This result suggests that tidal interactions have modified the radii of these stars during their development towards contact .Our results also demonstrate that the orbital inclination distance i = 60 ± 5 degrees , as determined earlier through radial speed measurements , agrees well with our new estimate calculated directly from the observed separation between the two stars . Keywords : Interferometry ; Binary Stars ; Stellar Radius",
        "ori-fast-z-score": 0.3511234415883917,
        "water-fast-z-score": 4.649905549752772
    },
    {
        "original_text": "The HYPERION project is an effort to combine the results of N-body simulations with those of detailed stellar population synthesis models in order to study how galaxies evolve and form their stars.  In this talk, I will present some recent results on galaxy formation using these techniques. These include studies of:  1) Galaxy mergers at high redshift; 2) The evolution of galactic disks; 3) The effect of AGN feedback on galaxy growth; 4) The assembly history of massive elliptical galaxies. This work was supported by NASA grant NNX10AD65G (PI: D. Katz). My research interests are focused on understanding how galaxies grow over cosmic time through the processes of star formation, black hole accretion, and galaxy mergers. To address this question, we have developed new methods for combining cosmological hydrodynamic simulations with state-of-the-art stellar population synthesis codes that allow us to predict the properties of galaxies as functions of both space and time.",
        "watermark_text": "The HYPERION program is an initiative to mix the results of N - bodies simulations with those of formal galaxy colony synthesis estimates in order to study how clusters evolve and form their stars . In this talk , I will present some latest findings on star formation using these concepts .These include models of : 1 ) Galaxy mergers at high redshift ; 2 ) The migration of galactic cones ; 3 ) The impact of AGN feedback on star development ; 4 ) The assembly history of large elliptical galaxies . This research was supported by NASA award NNX10AD65G ( PI : D . Katz ) .My research interests are focused on understanding how clusters grow over cosmic time through the mechanisms of galaxy formation , white hole accretion , and galaxy mergers . To address this question , we have developed novel techniques for integrating cosmological hydrodynamic simulations with state - of - the - art stellar community synthesis coding that enable us to predict the properties of stars as functions of both space and period .",
        "ori-fast-z-score": -1.5215349135496974,
        "water-fast-z-score": 6.905427684571704
    },
    {
        "original_text": "We study the non-adiabatic current through an open quantum dot connected to two leads with different chemical potentials, which is driven by time-dependent gate voltages applied on both sides of the dot. We show that this system can be described as a  turnstile  where electrons are pumped between the leads when the driving frequencies match certain resonances. The effect is robust against disorder and dephasing. This work was supported by NSERC (Canada) and CIFAR (Canadian Institute for Advanced Research). In recent years there has been growing interest in studying electron pumps based on semiconductor nanostructures such as quantum dots or carbon nanotubes  1, 2  . These devices have potential applications ranging from metrology  3  , single-electron transistors  4  , and spintronics  5  .\nIn these systems, charge carriers are transported across the device via sequential tunneling processes  6  . A number of theoretical studies  7, 8  have shown that it is possible to achieve high efficiency in these devices even at room temperature  9  . However, most previous works focused only on adiabatic pumping  10  , i.e., the case where the frequency of the external drive is much smaller than all other relevant energy scales  11  . Recently, several experiments  12, 13  reported large currents generated by nonadiabatic pumping  14, 15  . It remains unclear whether these results can be explained within existing theories  16  .\nHere we consider a simple model of a quantum dot connected to two metallic leads  see Fig. 1(a)    17  . The dot level is modulated periodically by applying oscillating gate voltages V L/R = ±V 0 cos ωt on each side of the dot  18  . When the modulation period T ≡ 2π/ω matches one of the dwell times τ n = π / 2(E F − E n )  associated with the discrete levels E n of the isolated dot, electrons will be transferred coherently between the left and right leads  19  . Here E F denotes the Fermi energy of the leads  20  . As illustrated schematically in Figs. 1(b-c), depending on",
        "watermark_text": "We explore the non - adiabatic current through an open quantum dot connected to two leads with various chemical potentials , which is powered by time - dependent gate voltages applied on both sides of the dot . We see that this network can be described as a turnstile where electrons are pumped between the leads when the driving energies fit particular resonances .The impact is robust against disorder and dephasing . This research was supported by NSERC ( Canada ) and CIFAR ( Canadian Institute for Advanced Research ) .In past times there has been growing interest in investigating electron pumps built on semiconductor nanostructures such as quantum dots or carbon nanotubes 1 , 2 . These systems have potential applications ranging from metrology 3 , single - ion transistors 4 , and spintronics 5 .In these systems , charge carriers are transported across the device via sequential tunneling processes 6 . A variety of theoretical experiments 7 , 8 have shown that it is easy to achieve high efficiency in these systems even at room temperature 9 .However , most prior papers focused only on adiabatic pumping 10 , i . e . , the case where the frequency of the external drive is much smaller than all other relevant energy scales 11 . Recently , various study 12 , 13 documented large waves generated by nonadiabatic pumping 14 , 15 .It remains unsure whether these results can be described within existing models 16 . Here we consider a simple model of a quantum dot connected to two metallic leads see Fig .1 ( a ) 17 . The dot level is modulated periodically by using oscillating gate voltages V L / R = ±V 0 cos ωt on each side of the dot 18 .When the modulation time T ≡ 2π / ω matches one of the dwell times π n = π / 2 ( E F − E n ) associated with the discrete levels E n of the isolated dot , electrons will be transferred coherently between the left and left leads 19 . Here E F denotes the Fermi energy of the leads 20 .As illustrated schematically in Figs.1(b-c), depending on",
        "ori-fast-z-score": 0.5107539184552492,
        "water-fast-z-score": 6.236810901332355
    },
    {
        "original_text": "We present the results of our analysis on the X-ray spectrum and variability properties of CIV 1549, which is one of the brightest Seyfert galaxies in the sky at soft X-rays (0.5-2 keV). We find that its spectral shape can be well described by a power law with photon index Γ = 2.1 ± 0.2 plus two thermal components; one component has temperature kT = 0.3 +0.4 −0.1 keV while another has higher temperature kT = 3.7 +1.6 −1.1 keV. The luminosity ratio between these two thermal components is L h /L l ≈ 5.9 +2.8 −2.1 . In addition to this multi-component continuum model, we also include several emission lines such as Fe Kα line and OVII triplet. Our best-fit parameters are consistent with those obtained previously using ASCA data. \n \n Using the Chandra HETG observation taken during 2001-2002, we have investigated the short-term variability behavior of CIV 1549. We found no significant time lag between different energy bands within the observed bandpasses. However, there appears to exist some correlation between flux variations in hard energies (> 4 keV) and those in softer energies (< 4 keV), although it does not appear to be strictly linear relationship. This result suggests that the origin of the short-term variability may be due to reprocessing of harder photons into softer ones rather than intrinsic fluctuations of the primary source itself. \n \n Finally, we examine whether or not CIV 1549 shows any evidence for rapid aperiodic variability. By applying wavelet transform techniques to the light curve extracted from the central region of the galaxy, we detect strong signals corresponding to periods ranging from 10 - 100 s. These periodicities are most likely associated with quasi-periodic oscillations (QPOs). \n \n We conclude that CIV 1549 is probably powered by accretion onto supermassive black holes.",
        "watermark_text": "We present the conclusion of our analysis on the X - ray spectrum and variability properties of CIV 1549 , which is one of the brightest Seyfert galaxies in the sky at warm X - radiation ( 0 . 5 - 2 keV ) . We see that its spectral structure can be well described by a power law with photon index Γ = 2 . 1 ± 0 . 2 plus two thermal parts ; one part has temperature kT = 0 . 3 + 0 . 4 −0 . 1 keV while another has higher temperature kT = 3 . 7 + 1 . 6 −1 . 1 keV .The luminosity factor between these two thermal parts is L h / L l ≈ 5 . 9 + 2 . 8 −2 . 1 . In addition to this multi - component continuum model , we also add several emission lines such as Fe Kα line and OVII triplet .Our best - fitting characteristics are compatible with those acquired previously using ASCA information . Using the Chandra HETG measurement done during 2001 - 2002 , we have researched the short - term variability behavior of CIV 1549 .We determined no considerable time lag between various energy bands within the seen bandpasses . However , there seems to appear some correlation between flux variations in hard frequencies ( > 4 keV ) and those in harder frequencies ( < 4 keV ) , although it does not appear to be strictly linear correlation .This result suggests that the origin of the short - term variability may be due to reprocessing of stronger photons into weaker ones instead than intrinsic fluctuations of the primary source itself . Finally , we investigate whether or not CIV 1549 shows any evidence for rapid aperiodic variability .By applying wavelet transform techniques to the light line gathered from the central region of the universe , we identify strong pulses corresponding to periods ranging from 10 - 100 s . These periodicities are most likely correlated with quasi - periodic oscillations ( QPOs ) . We suggest that CIV 1549 is probably powered by accretion onto supermassive black holes .",
        "ori-fast-z-score": 0.3651483716701107,
        "water-fast-z-score": 7.6085975253341545
    },
    {
        "original_text": "We have analyzed peculiar motions of galaxies within the region of the ursa major supercluster (UMS) using data on galaxy redshifts and distances obtained by us with the 6-m telescope at the Special Astrophysical Observatory of Russian Academy of Sciences.  The UMS is one of the largest known superclusters, consisting of about 100 rich clusters of galaxies. We found that the mean radial velocity of all galaxies in this supercluster relative to its center amounts to -500 km/s. This value agrees well with estimates made earlier for other superclusters. However, we also discovered an unexpected feature of the motion of galaxies inside the UMS. Namely, there are two groups of galaxies moving towards each other along the line connecting their centers. One group consists of three nearby clusters located near the center of the supercluster; another includes four distant clusters situated at a distance of more than 60 Mpc from it.",
        "watermark_text": "We have analyzed unusual movements of galaxies within the sector of the ursa major supercluster ( UMS ) using data on star redshifts and lengths taken by us with the 6 - m observatory at the Special Astrophysical Observatory of Russian Academy of Sciences . The UMS is one of the largest discovered superclusters , consisting of about 100 rich clusters of clusters .We showed that the mean radial speed of all galaxies in this supercluster relative to its core amounts to - 500 km / s . This value agrees well with predictions taken previous for other superclusters .However , we also discovered an unexpected feature of the movement of stars inside the UMS . Namely , there are two groups of clusters moved towards each other along the line linking their centers .One group contains of three adjacent complexes positioned near the center of the supercluster ; another includes four distant clusters situated at a distance of more than 60 Mpc from it .",
        "ori-fast-z-score": -1.4569855927715483,
        "water-fast-z-score": 4.201805851511121
    },
    {
        "original_text": "In this work, we propose an energy-efficient cooperative transmission scheme for wireless sensor networks (WSNs). The proposed scheme is based on the combination of collaborative beamforming at the source node with cooperative transmission to multiple relay nodes in order to improve lifetime performance. In particular, the source node first transmits data packets using its maximum power level. Then, it switches to lower power levels if no packet has been successfully received within a certain time period. If one or more packets are successfully decoded, then the source node increases its transmit power back up to the previous value. We derive closed-form expressions for outage probability as well as average throughput under Rayleigh fading channels. Our results show that our proposed scheme can significantly increase network lifetime compared to conventional schemes without compromising system reliability. Finally, numerical examples are provided to verify the theoretical analysis. Keywords: Lifetime improvement; Relay selection; Energy efficiency; Outage probability",
        "watermark_text": "In this project , we propose an energy - efficient joint propagation scheme for wireless sensor networks ( WSNs ) . The proposed system is based on the combination of collaborative beamforming at the source node with coordinated transmission to multiple relay nodes in order to improve life performance .In particular , the source node initially transmits data packets using its highest power level . Then , it switches to smaller energy levels if no packet has been successfully received within a certain time time .If one or more bits are properly decoded , then the source node increases its broadcast capacity back up to the previous value . We derive closed - form expressions for outage likelihood as well as average throughput under Rayleigh fading filters .Our results show that our proposed system can significantly expand network lifetime compared to conventional systems without compromising system efficiency . Finally , numerical examples are provided to confirm the theoretical analysis .Keywords : Lifetime improvement ; Relay choice ; Energy quality ; Outage probability",
        "ori-fast-z-score": 0.105999788000636,
        "water-fast-z-score": 6.11104144857543
    },
    {
        "original_text": "We present an exact quantum-mechanical treatment for the dynamics of open systems in which the system is coupled to many harmonic oscillators representing its surrounding environment.  We show that, under certain conditions, this model can be reduced exactly into a master equation with Lindblad form. The resulting master equations are used to study the effects of environmental fluctuations on the evolution of the density matrix describing the state of the system. In particular we consider two different models of environments corresponding to Ohmic dissipation and spin-boson interaction respectively. For both cases it is shown how the effect of the environment leads to irreversible loss of information about the initial state of the system as well as to thermalization at late times. Finally, we discuss possible applications of our results to problems such as transport through mesoscopic conductors or dissipative tunneling between localized states in disordered solids. Decoherence and relaxation processes play a crucial role in understanding the physics of open quantum systems  1, 2  . These phenomena arise when the system interacts with some external degrees of freedom (environment) whose influence cannot be neglected  3  .\nIn recent years there has been considerable interest in developing theoretical methods capable of treating these effects beyond the perturbative regime  4  . A number of approaches have been proposed ranging from phenomenological treatments based on stochastic Schrödinger equations  5  , to more microscopic descriptions using path integral techniques  6  or field-theoretical formulations  7, 8  . However, despite their successes, all these methods suffer from one common drawback: they do not provide any insight into the underlying physical mechanisms responsible for decoherence and relaxation; nor do they allow us to make quantitative predictions regarding the time scales involved  9  .\nRecently, several authors  10 -12  have suggested that the problem may be tackled within the framework of quantum mechanics itself. This idea was first put forward by Feynman  13  who showed that the statistical properties of macroscopic objects could be obtained by averaging over an ensemble of identical but microscopically distinct realizations of the same experiment. More recently, Leggett  14  introduced a method...",
        "watermark_text": "We present an precise quantum - mechanical explanation for the dynamics of open systems in which the system is linked to many harmonic oscillators describing its surrounding environment . We see that , under certain conditions , this description can be reduced exactly into a master equation with Lindblad form .The resulting master equations are using to study the effects of environmental fluctuations on the evolution of the density graph explaining the state of the system . In particular we investigate two different models of environments corresponding to Ohmic dissipation and spin - boson collision respectively .For both cases it is demonstrated how the impact of the surroundings leads to irreversible loss of information about the first state of the system as well as to thermalization at late times . Finally , we explain possible applied of our findings to problems such as transport through mesoscopic conductors or dissipative tunneling between localized states in disordered solids .Decoherence and relaxation processes take a crucial role in understanding the physics of open quantum systems 1 , 2 . These phenomena arise when the system interacts with some external degrees of autonomy ( surroundings ) whose influence cannot be forgotten 3 .In recent years there has been substantial interest in pursuing theoretical methods suitable of addressing these phenomena beyond the perturbative regime 4 . A variety of methods have been proposed ranging from phenomenological treatments based on stochastic Schrödinger coefficients 5 , to more microscopic descriptions using path integral methods 6 or field - theory formulations 7 , 8 .However , despite their successes , all these algorithms suffer from one common drawback : they do not offer any insight into the fundamental physical mechanisms involved for decoherence and relaxation ; nor do they allow us to make quantitative predictions regarding the period scales involved 9 . Recently , various scientists 10 - 12 have suggested that the issue may be tackled within the framework of quantum mechanics itself .This idea was first put forward by Feynman 13 who demonstrated that the empirical qualities of macroscopic objects may be obtained by averaging over an ensemble of different but microscopically different realizations of the same experiment . More recently , Leggett 14 proposed a technique . . .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.905694150420948
    },
    {
        "original_text": "We relate the notion of information-theoretic security to that of computational indistinguishability, and show how this relationship can be used in practice for proving security properties of cryptographic protocols.  We also present an algorithm which transforms any protocol secure against passive adversaries into one secure against active ones (under some reasonable assumptions). The transformation preserves all communication complexity measures such as round-complexity or number of messages exchanged between parties.   Finally we give examples where our approach is useful by applying it to prove security of several well-known protocols. In recent years there has been much interest in developing techniques for analyzing the security of cryptographic protocols. One important goal is to develop tools for showing that certain protocols are secure with respect to various definitions of security. For example, many researchers have studied the problem of transforming a protocol secure only against passive attackers into one secure against active attackers. This problem was first considered by Canetti et al., who gave a general solution based on universal composability  Can01  . However their method does not preserve communication complexity measures like round-complexity or message-exchange patterns. Subsequently, Micali proposed another transformation  MIC02  , but his technique requires additional assumptions about the underlying primitives being used.",
        "watermark_text": "We relate the notion of communication - theoretic integrity to that of computational indistinguishability , and suggest how this relationship can be used in practice for determining security characteristics of cryptographic protocols . We also demonstrate an algorithm which transforms any protocol secure against passive adversaries into one secure against active ones ( under some reasonable assumptions ) .The transformation maintains all transmission complexity measures such as round - complexity or number of communication received between parties . Finally we give instance where our approach is utilized by using it to prove security of several well - famous protocols .In past decades there has been much interest in improving procedures for evaluating the safety of cryptographic protocols . One important aim is to develop tools for showing that particular protocols are secure with regard to several definitions of security .For instance , many scholars have researched the question of converting a protocol secure only against passive attackers into one stable against active attackers . This problem was first investigated by Canetti et al . , who offered a general solution based on universal composability Can01 .However their method does not retain transmission diversity values like round - complexity or message - transfer patterns . Subsequently , Micali proposed another transformation MIC02 , but his method needs additional observations about the underlying primitives being used .",
        "ori-fast-z-score": -0.2873478855663454,
        "water-fast-z-score": 7.120653320005384
    },
    {
        "original_text": "The main result is the following theorem. \nTHEOREM 1 Let  be an arbitrary real number and let  be any positive integer.  Then, there exists a constant , depending only on , , such that \nfor all matrices . The proof of this theorem will be given in Section 2 below. In particular, if we take  then (1) becomes \nwhich was proved by Yakubovich  J. Math. Anal. Appl., vol. 16, pp. 719-726, (1964) . If we choose  then (1) reduces to \nwhich was established by Popov  Publ. Math. Inst. Steklov, vol. A, no. 3, p. 225-230, (1963)  . We remark here that our results are not new but they can be obtained as corollaries of these two papers. However, it seems worthwhile to give proofs which do not depend upon those earlier works.",
        "watermark_text": "The main consequence is the following theorem . THEOREM 1 Let be an arbitrary real number and consider be any positive integer .Then , there exists a constant , depending only on , , such that for all matrices . The confirmation of this theorem will be provided in Section 2 below .In particular , if we took then ( 1 ) becomes which was confirmed by Yakubovich J . Math .Anal.Appl., vol.16 , pp . 719 - 726 , ( 1964 ) .If we choose  then (1) reduces to \nwhich was established by Popov  Publ.Math.Inst.Steklov, vol.A , no . 3 , p . 225 - 230 , ( 1963 ) .We comment here that our findings are not original but they can be obtained as corollaries of these two papers . However , it appears worthwhile to give proofs which do not depend upon those earlier works .",
        "ori-fast-z-score": -0.16012815380508713,
        "water-fast-z-score": 2.846049894151541
    },
    {
        "original_text": "We present an analysis of the effects that mergers may have on scaling relations between black holes (BHs), galaxies, and other gravitationally bound systems. We use cosmological simulations to study how BH mass is related to galaxy properties in different merger histories. Our results show that mergers can significantly affect these relationships by increasing scatter at fixed luminosity or stellar velocity dispersion. This effect is strongest for low-mass galaxies with high specific star formation rates. In addition, we find that mergers tend to increase the average BH-to-galaxy mass ratio as well as the fraction of active galactic nuclei (AGNs) among massive galaxies. These findings are consistent with observations of AGN host galaxies. Finally, our results suggest that the observed correlation between supermassive BH masses and bulge properties could be driven primarily by the fact that both grow during major mergers. Keywords: Galaxy evolution; Supermassive black hole",
        "watermark_text": "We present an assessment of the effects that mergers might have on scaling relations between black holes ( BHs ) , galaxies , and other gravitationally bound structures . We use cosmological simulations to study how BH mass is related to galaxy structures in different merger histories .Our results show that mergers can significantly affect these interactions by expanding scatter at fixed luminosity or stellar velocity dispersion . This phenomenon is greatest for low - density nuclei with high specific star formation rates .In addition , we find that mergers prefer to raise the average BH - to - star mass ratio as well as the fraction of active galactic nuclei ( AGNs ) among giant galaxies . These conclusions are consistent with observations of AGN host galaxies .Finally , our findings show that the seen correlation between supermassive BH masses and bulge properties might be motivated primarily by the fact that both expand during major mergers . Keywords : Galaxy evolve ; Supermassive black hole",
        "ori-fast-z-score": 0.35603449745815596,
        "water-fast-z-score": 5.5778737935111105
    },
    {
        "original_text": "We study the dynamics of two interacting bosonic species confined to an optical lattice, with one species being initially prepared as a coherent state at each site while the other is initially prepared as a thermal cloud. We show that this system supports both symmetric and asymmetric soliton solutions which are stable against small perturbations for certain values of the chemical potentials. The stability properties of these solitons can be understood by studying their linearization spectrum around the stationary states. In particular we find that the presence of a finite temperature leads to additional unstable modes associated with phonon-like excitations. Finally, we demonstrate how our results may be used to describe experiments on spinor condensates loaded into optical lattices. Introduction:-Recent experimental advances have made it possible to create quantum degenerate gases consisting of several different atomic species  1  . These systems provide new opportunities to explore novel phenomena such as supersolids  2  , phase separation  3  or spin-orbit coupling  4  .\nIn this work we consider a particularly interesting example where there exist two distinct types of particles (e.g., atoms) which interact via s-wave scattering but differ in mass and/or internal structure  5  . This situation arises naturally when considering mixtures of hyperfine states  6  or isotopes  7, 8  within the same atom type  9  . For instance, recent experiments involving 87 Rb and 41 K  10  have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling  11  . Another possibility would involve using 40 K and 6 Li  12  . Here, the lighter species could be considered as impurities immersed in a background gas of heavier fermions  13  . Alternatively, if the masses were reversed then the heavy species could act as impurities  14  .",
        "watermark_text": "We research the dynamics of two interacting bosonic species confined to an optical lattice , with one species being initially made as a coherent state at each site while the other is initially prepared as a heat bubble . We see that this scheme holds both symmetric and asymmetric soliton solutions which are stable against small perturbations for particular values of the chemical potentials .The stability properties of these solitons can be understood by examining their linearization spectrum around the stationary states . In particular we find that the presence of a finite temperature leads to extra weak modes associated with phonon - like excitations .Finally , we prove how our findings may be used to explain studies on spinor condensates stacked into optical lattices . Introduction : - Recent research developments have enabled it able to create quantum degenerate gases composed of several different atomic species 1 .These systems present new opportunities to examine novel processes such as supersolids 2 , phase splitting 3 or spin - orbit resonance 4 . In this research we imagine a particularly exciting example where there exist two different kinds of atoms ( e . g . , atoms ) which interact via s - wave scattering but differ in mass and / or internal structure 5 .This condition occurs naturally when examining mixtures of hyperfine states 6 or isotopes 7 , 8 within the same atom type 9 . For instance , recent experiments concerning 87 Rb and 41 K 10 have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling 11 .Another possibility would include utilizing 40 K and 6 Li 12 . Here , the softer species may be regarded as impurities immersed in a background gas of heavier fermions 13 .Alternatively , if the masses were reversed then the heavy species may function as impurities 14 .",
        "ori-fast-z-score": -0.3481553119113957,
        "water-fast-z-score": 6.5033247714309
    },
    {
        "original_text": "We consider the problem of power allocation in discrete-input delay-limited fading channels with multiple users and time-varying channel gains. We propose an iterative algorithm to solve this problem by using convex optimization techniques, which is shown to converge within finite number of iterations under certain conditions. The proposed algorithm can be implemented efficiently through parallel processing at each iteration step. Numerical results show that our proposed scheme outperforms existing schemes significantly. \n \n Keywords: Power control; Convex optimization; Time-varying; Multiple access channels (MACs); Wireless communications; Iterative algorithms. 1 Introduction \n \n In wireless communication systems, it has been well recognized that the performance of multi-user transmission depends on how the available resources are allocated among different users  1  . For example, when there exist multiple users sharing a common radio resource such as bandwidth or transmit power, the optimal way to allocate these resources may depend on the specific system settings  2  , e.g., whether the users have equal priority  3  , what type of services they request  4  , etc.. Therefore, efficient resource allocation strategies should take into account all relevant factors so as to maximize overall network utility  5  .\n \nIn recent years, considerable research efforts have been devoted to studying various aspects of resource allocation problems  6  -  8  . Among them, power allocation plays an important role due to its direct impact on both spectral efficiency and energy consumption  9  . However, most previous works assume continuous input alphabets  10  -  12  , while practical digital modulation schemes usually employ discrete constellations  13  . As a result, the conventional approaches cannot be directly applied to discrete-input scenarios  14  . To address this issue, several studies  15  -  17  have investigated the power allocation problem over discrete-input channels recently. Nevertheless, their solutions either require high computational complexity  16  or suffer from slow convergence speed  17  .",
        "watermark_text": "We consider the issue of power transfer in discrete - input delay - limited fading channels with many users and period - differing channel gains . We suggest an iterative algorithm to solve this question by using convex optimization schemes , which is demonstrated to converge within finite number of iterations under certain conditions .The proposed algorithm can be executed easily through concurrent processing at each iteration step . Numerical results show that our proposed system outperforms old schemes considerably .Keywords : Power control ; Convex optimization ; Time - increasing ; Multiple access networks ( MACs ) ; Wireless communications ; Iterative strategies . 1 Introduction In wireless communication devices , it has been good recognized that the performance of dual - customer propagation depends on how the provided resources are assigned among different users 1 .For instance , when there reside several users sharing a common radio asset such as bandwidth or transmit energy , the ideal means to allocate these resources may depend on the specific system settings 2 , e . g . , whether the people have equal priority 3 , what type of solutions they demand 4 , etc . . Therefore , efficient resource transfer tactics should take into consideration all relevant variables so as to maximize overall network utility 5 .In recent years , substantial research efforts have been focused to researching various parts of resource consumption issues 6 - 8 . Among them , power distribution plays an important role owing to its significant effect on both spectral capacity and energy consumption 9 .However , most prior compositions take continuous source alphabets 10 - 12 , while contemporary digital modulation schemes typically employ discrete constellations 13 . As a result , the usual techniques lack be directly used to discrete - input models 14 .To address this question , various studies 15 - 17 have researched the power sharing question over discrete - input channels recently . Nevertheless , their solutions either need high computational complexity 16 or suffer from slow convergence speed 17 .",
        "ori-fast-z-score": -1.4615384615384615,
        "water-fast-z-score": 8.795290947839238
    },
    {
        "original_text": "We present the results of an analysis aimed at calibrating mid-infrared (MIR) star formation rate indicators using data obtained with Spitzer and Herschel Space Telescopes, as well as ground-based facilities such as the Infrared Array Camera onboard the Hubble Space Telescope.  We use a sample of galaxies selected to have high signal-to-noise ratio detections in all four IRAC bands (3.6-8 microns), which are used for estimating total infrared luminosities via SED fitting techniques. The sample consists of 29 nearby star-forming galaxies that span a wide range of physical properties including stellar mass, dust temperature, metallicity, and specific star formation rates. Using these observations we derive empirical relations between MIR emission features and total infrared luminosity, which can be used to estimate LIR over a large dynamic range without requiring any assumptions about the shape or slope of galaxy SEDs.",
        "watermark_text": "We publish the conclusion of an assessment aimed at calibrating mid - infrared ( MIR ) star formation rate indicators using data acquired with Spitzer and Herschel Space Telescopes , as well as land - based equipment such as the Infrared Array Camera onboard the Hubble Space Telescope . We use a sample of stars selected to have high signal - to - noise ratio detections in all four IRAC ranges ( 3 . 6 - 8 microns ) , which are using for estimating actual infrared luminosities via SED fitting methods .The sample consists of 29 nearby star - creating stars that cover a broad variety of physical properties including stellar mass , dust temperature , metallicity , and particular galaxy formation rates . Using these observations we derive empirical relations between MIR emission features and total infrared luminosity , which can be used to estimate LIR over a large static range without requiring any constraints about the form or slope of galaxy SEDs .",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We report on X-ray timing observations of the pulsar candidate PSR J1930+1855 located at the center of the supernova remnant (SNR) G54.1+0. \n \n The source was discovered by Chandra and confirmed as a pulsar with XMM-Newton, but its spin period is not stable over time scales longer than one day. We performed two sets of pointed RXTE observations to study this behavior further. In both cases we found that the pulse frequency decreases smoothly during our observation runs. This trend can be described well using an exponential decay model for which we find characteristic timescales of 1.1 days and 0.7 days respectively. These values are consistent with those reported previously based on Chandra data alone. However, when comparing these results directly it should be noted that the uncertainties associated with the previous measurements were significantly larger due to the lower signal-to-noise ratio achieved with Chandra compared to RXTE.",
        "watermark_text": "We report on X - ray timing observations of the pulsar candidate PSR J1930 + 1855 centered at the center of the supernova remnant ( SNR ) G54 . 1 + 0 . The source was studied by Chandra and reported as a pulsar with XMM - Newton , but its spin time is not stable over time ranges shorter than one month .We conducted two sets of pointed RXTE observations to study this behavior further . In both cases we concluded that the heartbeat rate decreases slowly during our observation running .This trend can be described good using an exponential decay model for which we find typical timescales of 1 . 1 days and 0 . 7 weeks respectively . These quantities are compatible with those noted earlier based on Chandra data alone .However , when comparing these results directly it should be mentioned that the uncertainties involved with the previous tests were significantly larger thanks to the smaller signal - to - noise proportion attained with Chandra compared to RXTE .",
        "ori-fast-z-score": 0.4923659639173309,
        "water-fast-z-score": 6.719319439596787
    },
    {
        "original_text": "We have measured the space velocities for eight globular clusters in the southern hemisphere with galactic latitudes less than 20 degrees, using proper motions and radial velocities obtained by various authors over the past decade or so.  The sample includes four open clusters (NGC 2420 , NGC 2516 , NGC 2682 , and NGC 6705 ) as well as four globulars . We find that all but one cluster are consistent with being at rest relative to the local standard of rest; however, we also find evidence that two of these clusters may be on orbits which will take them out of our galaxy within several billion years .  These results suggest that there is no significant difference between open clusters and globulars when it comes to their kinematics ; both types appear to share similar properties .\nThe only exception appears to be the open cluster M67 , whose velocity vector points away from us toward the constellation Cetus . This result suggests that this open cluster has been ejected from its parent galaxy during an encounter with another galaxy some time ago .",
        "watermark_text": "We have analyzed the space velocities for eight globular complexes in the southern hemisphere with galactic latitudes less than 20 degrees , using proper motions and radial velocities collected by various scientists over the previous decade or so . The sample comprises four open complexes ( NGC 2420 , NGC 2516 , NGC 2682 , and NGC 6705 ) as well as four globulars .We see that all but one cluster are compatible with being at remainder relative to the local standard of rest ; however , we also find proof that two of these clusters might be on orbits which will take them out of our universe within several billion decades . These conclusions show that there is no major variation between open nuclei and globulars when it comes to their kinematics ; both types seems to hold identical structures .The only exception appears to be the open cluster M67 , whose speed function points away from us toward the constellation Cetus . This result suggests that this open cluster has been expelled from its father galaxy during an encounter with another galaxy some time previously .",
        "ori-fast-z-score": -1.649915822768611,
        "water-fast-z-score": 4.714045207910317
    },
    {
        "original_text": "We present new results on the displacement of the Sun from the galactic plane based on Hipparcos data and recent determinations of the solar motion with respect to the local standard of rest (LSR). We find that the Sun is displaced by about 0.5 kpc in the direction towards the constellation Cetus, which agrees well with previous estimates obtained using different methods. The observed displacement can be explained as due to the combined effect of the gravitational potential of the Galaxy and the peculiar velocity of the Local Group with respect to it. \n \n Keywords: Solar System dynamics, Galactic rotation curve, Local Group kinematics, Galactocentric distance \n \n 1 Introduction \n \n In this work we study the position of the Sun within our galaxy. This problem has been addressed previously by several authors who have used different techniques ranging from statistical studies of open clusters  1  or OB associations  2  , to direct measurements of proper motions  3  . Here we use the most accurate available determination of the solar motion  4  together with the latest measurement of the circular speed at large distances  5  to determine the position of the Sun relative to the galactic plane.",
        "watermark_text": "We report new data on the movement of the Sun from the galactic plane based on Hipparcos statistics and recent determinations of the sun motion with regard to the local standard of rest ( LSR ) . We see that the Sun is displaced by about 0 . 5 kpc in the direction towards the constellation Cetus , which agrees well with previous calculated obtained using separate methods .The observed displacement can be described as owing to the combined influence of the gravitational potential of the Galaxy and the peculiar speed of the Local Group with regard to it . Keywords : Solar System dynamics , Galactic rotation curve , Local Group kinematics , Galactocentric distance 1 Introduction In this research we study the orientation of the Sun within our universe .This problem has been addressed previously by various scientists who have utilized varying techniques ranging from statistical analyses of close complexes 1 or OB associations 2 , to direct measurements of proper motions 3 . Here we utilize the most accurate available determination of the sun motion 4 together with the latest measurement of the circular distance at large distances 5 to estimate the orientation of the Sun relative to the galactic plane .",
        "ori-fast-z-score": -0.329292779969071,
        "water-fast-z-score": 6.625891564490792
    },
    {
        "original_text": "We have analyzed Chandra observations for eight galaxy clusters with redshifts between 0.1 and 0.3 to determine their radial temperature, density, pressure, entropy, cooling time, and metallicity profiles. We find that all these quantities are well described by single-parameter scaling relations as functions of radius r normalized by the virial radius Rvir.  The best-fit values of the normalization parameters depend on redshift but not significantly so; we therefore adopt fixed values based on our results for the two most distant clusters (z = 0.2 and 0.3) which yield good fits to the other six clusters. Our main conclusions are:  1. All cluster properties show significant evolution out to z ~ 0.3; this is consistent with previous studies using XMM data. 2. The gas fraction fgas(r/Rvir), defined as the ratio of the total thermal energy within a sphere of radius r to its gravitational binding energy, decreases monotonically outwards; it also shows some evidence for evolution with redshift. 3. The electron number density ne(r) increases inwardly toward the center of each cluster until reaching a peak value near r ~ 0.1r200 where r200 denotes the radius enclosing an average overdensity of 200 times the critical density of the universe. Beyond this point, ne(r) declines slowly or remains roughly constant depending on the cluster. 4. The mean molecular weight µe(r) increases outwardly due to the increasing contribution of helium ions relative to hydrogen atoms. 5. The central temperatures T0 inferred from spectral fitting range from 6 keV to 12 keV, while those obtained directly from the deprojected temperature profile lie in the range 7-15 keV. These differences may be caused by non-thermal components such as AGN jets and/or magnetic fields.",
        "watermark_text": "We have analyzed Chandra measurements for eight galaxy galaxies with redshifts between 0 . 1 and 0 . 3 to estimate their radial temperature , density , pressure , entropy , cooling period , and metallicity profiles . We see that all these quantities are better represented by single - parameter scaling relations as functions of radius r normalized by the virial diameter Rvir .The best - fitting values of the normalization coefficients differ on redshift but not considerably so ; we thus choose fixed values based on our findings for the two most distant populations ( z = 0 . 2 and 0 . 3 ) which provide better fits to the other six regions . Our main results are : 1 .All cluster elements exhibit substantial development out to z ~ 0 . 3 ; this is consistent with previous research utilizing XMM data . 2 .The gas fraction fgas ( r / Rvir ) , defined as the proportion of the total heat power within a sphere of radius r to its gravitational binding energy , decreases monotonically outwards ; it also shows some evidence for evolution with redshift . 3 .The electron number density ne ( r ) rises inwardly toward the center of each cluster until reaching a peak value near r ~ 0 . 1r200 where r200 denotes the radius enclosing an mean overdensity of 200 times the critical density of the universe . Beyond this point , ne ( r ) declines slowly or remains fairly constant depending on the cluster .4 . The mean molecular weight µe ( r ) rises outwardly due to the increasing contribution of helium ions relative to hydrogen atoms .5 . The central temperatures T0 inferred from spectral fit range from 6 keV to 12 keV , while those generated directly from the deprojected temperature profile lie in the range 7 - 15 keV .These changes may be caused by non - electrical components such as AGN jets and / or magnetic waves .",
        "ori-fast-z-score": -0.08606629658238704,
        "water-fast-z-score": 6.11070705734948
    },
    {
        "original_text": "The kinematics and dynamics analysis are performed for the hybrid manipulator with three degrees-of-freedom (3-DOF). The proposed manipulator consists of two serial chains, one is driven by an electric motor through gears while another chain is connected to it via spherical joints. In order to obtain the forward kinematics solution, the Denavit-Hartenberg parameters have been used in this study. The inverse kinematics problem has also been solved using the Jacobian matrix method. Finally, the dynamic model of the manipulator was developed based on Lagrange s equation. The results show that the designed manipulator can be applied as a robotic arm in various applications such as industrial robots or rehabilitation devices. Keywords: Forward kinematics, Inverse kinematics, Dynamics modeling, Robotics, Serial chain, Spherical joint, Electric motor, Gearbox, Manipulator, Degrees-of-freedom",
        "watermark_text": "The kinematics and dynamics calculations are performed for the combination manipulator with three degrees - of - independence ( 3 - DOF ) . The proposed manipulator consists of two serial chains , one is powered by an electric motor through gears while another chain is linked to it via triangular joints .In order to obtain the forward kinematics solving , the Denavit - Hartenberg variables have been used in this study . The inverse kinematics problem has additionally been solved using the Jacobian matrix method .Finally , the dynamic model of the manipulator was developed using on Lagrange s equation . The results show that the designed manipulator can be applied as a robotic unit in different applications such as factory robots or reconstruction systems .Keywords : Forward kinematics , Inverse kinematics , Dynamics modeling , Robotics , Serial chain , Spherical joint , Electric car , Gearbox , Manipulator , Degrees - of - freedom",
        "ori-fast-z-score": 0.13736056394868904,
        "water-fast-z-score": 4.626813958590447
    },
    {
        "original_text": "We present an analysis of N-body simulations aimed at understanding how evaporation shapes the mass function (MF) of globular clusters (GCs). We find that, in agreement with previous studies, evaporation causes GCs to lose stars preferentially on their low-mass end and thus steepens the MF slope towards lower masses. However, we show that this effect is counteracted by two competing processes: dynamical friction which removes massive stars more efficiently than less massive ones; and relaxation-driven core collapse which increases the central density of the cluster and makes it harder for massive stars to escape. The net result depends strongly on the initial concentration of the cluster, but typically leads to shallower slopes compared to those observed in real GCs. This suggests that other processes are required to explain the shape of the observed MF. In particular, our results suggest that primordial binaries may be responsible for producing the high-mass power-law tail seen in many GCs.",
        "watermark_text": "We publish an assessment of N - bodies simulations aiming at studying how evaporation shapes the mass function ( MF ) of globular galaxies ( GCs ) . We see that , in agreement with previous research , evaporation creates GCs to lose stars preferentially on their low - mass ending and therefore steepens the MF slope towards lesser masses .However , we find that this effect is counteracted by two different processes : dynamical friction which destroys massive galaxies more efficiently than less massive ones ; and relaxation - triggered disk collapse which increases the main abundance of the cluster and causes it difficult for huge stars to escape . The total result relies highly on the first abundance of the cluster , but typically leads to shallower slopes compared to those observed in real GCs .This implies that other processes are required to explain the form of the seen MF . In particular , our findings confirm that primordial binaries may be responsible for producing the high - mass power - law tail seen in large GCs .",
        "ori-fast-z-score": -1.4444444444444444,
        "water-fast-z-score": 6.184165460191406
    },
    {
        "original_text": "We introduce the notion of an algebra over a monoidal category and show that it is equivalent to the notion of a coalgebra in the dual category, which we call a comonoid.  We then define the cyclic homology of such algebras as the Hochschild cohomology of their underlying comonoids with coefficients in the bimodule given by the tensor product of the algebra with its opposite algebra.  This definition generalizes the usual one for ordinary algebras over fields or rings.   In particular, if the base ring has characteristic zero, this recovers the classical definitions of cyclic homology and periodic cyclic homology.  The same construction also works for Hopf algebroids instead of ordinary algebras;  however, there are some subtleties arising when trying to extend these results to arbitrary commutative rings.    Finally, we give several examples illustrating our constructions. Cyclic homology was introduced by Connes in his seminal work on noncommutative geometry  Con  . It can be defined as the Hochschild homology of certain algebras called cyclic objects. These were first studied systematically by Bökstedt  Bök  , who showed how they could be used to construct new algebraic structures like crossed modules and group extensions. Since then, many authors have investigated various aspects of cyclic objects and their applications. For example, see  Fri1  ,  Fri2  ,  Koc  ,  Lau  ,  Maz  ,  Nee  ,  Sta  .\nIn this article, we will study cyclic objects in more detail using techniques developed recently in the theory of operads and monads. Our main result shows that any cyclic object gives rise to two different types of cyclic homologies, namely the cyclic homology of the underlying algebra and the periodic cyclic homology of the associated graded algebra. Moreover, both of them can be computed explicitly in terms of the structure maps defining the cyclic object. As a consequence, we obtain explicit formulas for the cyclic homology of all finite-dimensional cocommutative Hopf algebras over a field of characteristic 0.",
        "watermark_text": "We introduce the notion of an ring over a monoidal category and know that it is analogous to the notion of a coalgebra in the dual category , which we call a comonoid . We then define the cyclic homology of such algebras as the Hochschild cohomology of their underlying comonoids with coefficients in the bimodule given by the tensor product of the algebra with its opposite algebra .This definition generalizes the usual one for regular algebras over fields or rings . In particular , if the base ring has characteristic zero , this recovers the classical definitions of cyclic homology and regular cyclic homology .The same construction also works for Hopf algebroids rather of simple algebras ; however , there are some subtleties emerging when trying to apply these results to arbitrary commutative rings . Finally , we give numerous instances illustrating our concepts .Cyclic homology was introduced by Connes in his seminal study on noncommutative geometry Con . It can be written as the Hochschild homology of certain algebras called cyclic objects .These were first examined carefully by Bökstedt Bök , who demonstrated how they could be used to build modern algebraic structures like crossed varieties and group extensions . Since then , various papers have researched several topics of cyclic objects and their applications .For instance , see Fri1 , Fri2 , Koc , Lau , Maz , Nee , Sta . In this article , we will explore cyclic objects in more depth employing approaches developed lately in the notion of operads and monads .Our main result suggests that any cyclic object gives rise to two different kinds of cyclic homologies , namely the cyclic homology of the underlying algebra and the periodic cyclic homology of the associated graded module . Moreover , both of them can be computed specifically in terms of the structure maps governing the cyclic object .As a consequence , we obtain formal formulas for the cyclic homology of all finite - dimensional cocommutative Hopf algebras over a field of characteristic 0 .",
        "ori-fast-z-score": -0.4583492485141057,
        "water-fast-z-score": 5.775200531277732
    },
    {
        "original_text": "We present the basic principles for modeling heterogeneous materials using two-point correlation functions (2PCFs). The 2PCF is an important statistical tool in many fields, including physics and engineering sciences. In this work we show how to use it as a basis for describing complex systems with multiple components or phases. We demonstrate that the 2PCF can be used to describe both static and dynamic properties of such systems. Finally, we discuss some applications of our approach. This article is part of a series on  Multiscale Modeling  published by Frontiers in Physics. \nIntroduction\n\nTwo-point correlation function (2PCF) is one of the most fundamental concepts in statistics  1  . It has been widely applied across various disciplines ranging from physics  2  , chemistry  3  , biology  4  , geology  5  , medicine  6  , economics  7  , sociology  8  , etc., to engineering  9  .\nIn recent years there have been several attempts to apply the concept of 2PCF to multiscale modeling  10 -12  . However, these works are mostly focused on developing new numerical methods rather than providing physical insights into the problem at hand. Herein, we propose a novel method based on the concept of 2PCFs which allows us to model heterogeneous materials consisting of different components and/or phases. Our approach provides a general framework for studying the structure-property relationships in such systems. Moreover, it enables us to study their dynamics over a wide range of time scales. \n \n To illustrate the main idea behind our approach let us consider a simple example shown schematically in Figure 1 . Suppose we want to investigate the mechanical response of a composite material made up of three distinct components A, B, C arranged in a periodic manner. Each component consists of randomly distributed spherical particles embedded within a matrix phase. For simplicity, assume that all components have identical volume fractions f = 0.33 but differ in terms of particle size distribution. Specifically, suppose that the average diameter of particles in each component is equal to: dA = 10 nm; dB = 20 nm; DC = 30 nm. As illustrated in Figure 1(a) , the overall microstructure of the",
        "watermark_text": "We present the fundamental principles for modeling heterogeneous materials utilizing two - point coupling curves ( 2PCFs ) . The 2PCF is an important statistical tool in multiple fields , notably physics and engineering studies .In this research we show how to use it as a foundation for describing complex systems with many aspects or stages . We showed that the 2PCF can be used to explain both static and dynamic characteristics of such systems .Finally , we explain some applications of our approach . This section is part of a trilogy on Multiscale Modeling published by Frontiers in Physics .Introduction Two - point coupling function ( 2PCF ) is one of the most important concepts in statistics 1 . It has been widely applied across numerous topics including from science 2 , chemistry 3 , chemistry 4 , geology 5 , medicine 6 , economics 7 , anthropology 8 , etc . , to engineering 9 .In past decades there have been numerous attempts to apply the idea of 2PCF to multiscale simulation 10 - 12 . However , these works are mostly concentrated on developing innovative statistical algorithms instead than providing physical knowledge into the issue at hand .Herein , we develop a new method using on the idea of 2PCFs which allows us to model heterogeneous materials composed of different components and / or stages . Our concept provides a general template for studying the form - property interactions in such systems .Moreover , it allows us to study their processes over a broad variety of time ranges . To explain the main idea behind our approach take us consider a simple example shown schematically in Figure 1 .Suppose we wish to examine the structural response of a composite material consisting up of three different components A , B , C arranged in a periodic manner . Each component consists of randomly distributed spherical atoms embedded within a matrix phase .For simplicity , assume that all components have equal volume fractions r = 0 . 33 but differ in terms of particle size distribution . Specifically , suppose that the average diameter of molecules in each portion is equal to : dA = 10 nm ; dB = 20 nm ; DC = 30 nm .As illustrated in Figure 1(a) , the overall microstructure of the",
        "ori-fast-z-score": 0.5482823149915702,
        "water-fast-z-score": 10.932163332202425
    },
    {
        "original_text": "The origin of the most massive stars is still an open question in astrophysics, as well as their role in shaping galactic evolution. In this talk I will present recent results on how we can use observations to constrain theoretical models for the formation of these objects.  The first part of my talk will focus on the observational properties of young massive clusters (YMCs) that are found at high redshift z>6-7. These YMCs have masses up to 10^8 Msun and sizes of ~1kpc. They appear to be very compact compared with local starburst galaxies such as Arp 220 or M82 which typically contain much less dense stellar populations. We find that the observed size-mass relation of these distant YMCs agrees remarkably well with predictions based on numerical simulations of turbulent gas clouds collapsing under self-gravity. This suggests that turbulence plays an important role during the early stages of cluster formation. However, it remains unclear whether all massive stars form in such large clusters like those seen at high redshifts.",
        "watermark_text": "The origin of the most large objects is still an open question in astrophysics , as well as their role in shaping galactic progression . In this talk I will present recent results on how we can using observations to constrain theoretical theories for the formation of these objects .The first part of my talk will focus on the observational properties of young massive clusters ( YMCs ) that are found at high redshift z > 6 - 7 . These YMCs have masses up to 10 ^ 8 Msun and dimensions of ~ 1kpc .They seem to be very small compared with local starburst clusters such as Arp 220 or M82 which commonly feature considerably less dense stellar groups . We see that the observed height - mass balance of these distant YMCs follows perfectly well with predictions based on numerical simulations of turbulent gas clouds collapsing under self - gravity .This implies that turbulence plays an important role during the early stages of cluster structure . However , it remains unsure whether all huge objects create in such large clusters like those observed at high redshifts .",
        "ori-fast-z-score": 0.7875615306482168,
        "water-fast-z-score": 6.340751391209736
    },
    {
        "original_text": "We report on the measurement of electric fields produced by surface contaminants using neutral atoms as probes. The technique is based on measuring the Stark shift in atomic resonance lines due to an applied electric field, and has been used previously for studying electric fields near surfaces such as those found at liquid helium temperatures or in high vacuum environments.  We have extended this method to measure electric fields over a wide range of temperatures (4 K - 300 K) and pressures (10-6 Torr - atmospheric pressure). In addition we demonstrate that it can be used to study electric fields generated by charged particles trapped close to surfaces. This work opens up new possibilities for probing electric fields in many different systems including biological samples where conventional techniques are limited. Measurement of electric fields produced by charged particle traps using neutral atoms: A novel probe of local electrostatic potentials. Measuring electric fields produced by surface contaminant... Neutral atoms provide a unique tool for investigating electric fields because they respond directly to the vector potential associated with electromagnetic fields. Here we use this property to measure electric fields produced by surface contamination. Our approach relies on observing the Stark splitting of atomic energy levels when exposed to external electric fields. Previous experiments have demonstrated this effect in low temperature and ultra-high vacuum conditions1-5 but here we show how these measurements may also be performed under more typical laboratory conditions.",
        "watermark_text": "We report on the determination of electric forces generated by surface contaminants using neutral compounds as probes . The technique is based on measuring the Stark shift in atomic resonance lines owing to an applied electric field , and has been used earlier for studying electric forces near structures such as those observed at liquid helium concentrations or in high vacuum environments .We have extended this method to measure electric forces over a broad variety of pressures ( 4 K - 300 K ) and pressures ( 10 - 6 Torr - atmospheric pressure ) . In addition we prove that it can be used to study electric forces generated by charged particles caught nearby to surfaces .This research provides up new possibilities for probing electric forces in multiple diverse systems including bio samples where conventional methods are small . Measurement of electric forces generated by charged particle traps involving neutral particles : A innovative investigation of local electrostatic potentials .Measuring electric forces generated by surface contaminant . . . Neutral atoms represent a unique technique for investigating electric forces because they react directly to the vector potential identified with electromagnetic forces .Here we utilize this property to measure electric forces generated by surface contamination . Our solution involves on observing the Stark separation of nuclear electricity levels when exposed to external electric forces .Previous experiments have demonstrated this effect in low heat and ultra - large vacuum conditions1 - 5 but here we give how these measurements may also be performed under more typical laboratory situations .",
        "ori-fast-z-score": 0.08606629658238704,
        "water-fast-z-score": 7.774654685222524
    },
    {
        "original_text": "We report the discovery and characterization of USco 1606-1935, an unusually wide low-mass triple system with two M-dwarfs orbiting each other in a ~2 year period at a distance of about 100 AU (~33 light years). The third component is a late K-type star that orbits both stars on a much wider scale, with a minimum mass for this companion of 0.7 solar masses. We present near-infrared spectroscopy to determine the spectral types of all three components as well as their radial velocities. Our results show that the inner binary has a total mass of only 0.3 solar masses, making it one of the lowest-mass binaries known. This makes USco 1606-1935 an ideal target for future studies of planet formation around very-low-mass stars. In addition, we find evidence for significant orbital eccentricity in the outer orbit which may be caused by tidal interactions between the close pair and its distant tertiary companion.",
        "watermark_text": "We report the discovery and characterization of USco 1606 - 1935 , an exceptionally wide low - mass triple system with two M - dwarfs orbiting each other in a ~ 2 week period at a distance of about 100 AU ( ~ 33 light years ) . The third component is a early K - class star that orbits both stars on a far larger scale , with a minimum mass for this companion of 0 . 7 solar masses .We present near - infrared spectroscopy to obtain the spectral classes of all three components as also as their radial velocities . Our results show that the inner binary has a total mass of only 0 . 3 solar masses , making it one of the smallest - energy binaries discovered .This gives USco 1606 - 1935 an suitable target for future research of planet development around very - low - weight stars . In addition , we find proof for significant orbital eccentricity in the exterior orbit which may be caused by tidal interactions between the close pair and its closest primary companion .",
        "ori-fast-z-score": -1.7320508075688772,
        "water-fast-z-score": 3.2118202741878643
    },
    {
        "original_text": "We consider the statistical properties of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions, power spectra, and probability density functions (PDFs). We show that these quantities can be expressed by means of solutions to certain partial differential equations with time-dependent coefficients. The PDFs are obtained for both stationary and nonstationary cases using the method of characteristics. In particular, we derive an exact expression for the PDF of the amplitude fluctuations of a monochromatic plane wave propagating through a turbulent medium. This result is used to obtain expressions for the mean-square fluctuation levels of the electric field strength and intensity at any point along the propagation path. Finally, we discuss some applications of our results to radiowave scintillation theory and radar detection problems. PACS: 42.65.Tg, 43.20 .Fx, 47.55.+q, 47.60.+j",
        "watermark_text": "We consider the statistical characteristics of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions , power spectra , and likelihood density functions ( PDFs ) . We see that these quantities can be described by means of solutions to many partial differential coefficients with time - dependent coefficients .The PDFs are derived for both static and nonstationary cases using the method of characteristics . In particular , we derive an precise representation for the PDF of the amplitude fluctuations of a monochromatic plane beam propagating through a turbulent medium .This result is utilized to obtain definitions for the mean - square fluctuation concentrations of the electric field intensity and intensity at any point along the propagation path . Finally , we explain some applications of our findings to radiowave scintillation physics and radar detection difficulties .PACS : 42 . 65 . Tg , 43 . 20 . Fx , 47 . 55 . + q , 47 . 60 . + j",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 5.417490779798923
    },
    {
        "original_text": "We study the generation of large-scale magnetic fields in astrophysical plasmas with very small values of the magnetic Prandtl number, Pm = ν/η ≪ 1 (ν is viscosity, η is resistivity). We consider two different types of flows that are relevant for this problem -helically driven turbulence and convection-driven turbulence. In both cases we find that the mean electromotive force has contributions from several terms which scale differently as functions of the Reynolds number Re = UL/ν and the magnetic Reynolds number Rm = URm/η. Here U , L, and Rm are characteristic velocity, length, and magnetic field scales respectively.  For helically driven turbulence these contributions can be grouped into three categories:  The first category includes all terms proportional to Re(Rm)−1/2 . These terms have been studied previously by many authors using various approaches including direct numerical simulations. They represent the contribution of the so-called α-effect due to helical motions. The second category contains all terms proportional to Re1/2 (Rm)−1/4 . This term represents the effect of helicity on the nonlinear evolution of the magnetic fluctuations. Finally, there exists also an additional third category containing all terms proportional to Re3/4 (Rm)−3/8 . It describes the influence of helicity on the linear growth rate of the magnetic fluctuations.",
        "watermark_text": "We explore the generation of large - scale magnetic fields in astrophysical plasmas with very small values of the magnetic Prandtl number , Pm = ν / η [UNK] 1 ( ν is viscosity , η is resistivity ) . We consider two different kinds of flows that are applicable for this question - helically controlled turbulence and convection - powered turbulence .In both cases we find that the mean electromotive pressure has contributions from several terms which scale differently as functions of the Reynolds number Re = UL / ν and the magnetic Reynolds number Rm = URm / η . Here U , L , and Rm are characteristic velocity , length , and magnetic field scales respectively .For helically controlled turbulence these contributions can be grouped into three categories : The first class includes all terms proportional to Re ( Rm ) −1 / 2 . These terms have been studied historically by many writers using numerous methodology including direct numerical simulations .They represent the contribution of the so - called α - effect owing to helical movements . The second class includes all terms proportional to Re1 / 2 ( Rm ) −1 / 4 .This term indicates the impact of helicity on the nonlinear development of the magnetic fluctuations . Finally , there exists additionally an additional third category containing all terms proportional to Re3 / 4 ( Rm ) −3 / 8 .It describes the impact of helicity on the linear expansion frequency of the magnetic fluctuations .",
        "ori-fast-z-score": 0.9332565252573828,
        "water-fast-z-score": 5.421374765483944
    },
    {
        "original_text": "We present new near-infrared (NIR) spectroscopic observations with Keck II/DEIMOS, which cover the entire optical extent of the nearby spiral galaxy M33 out to its last measured isophote at 25 mag arcsec-2 in B-band. We also use archival data obtained by the Infrared Array Camera onboard the Spitzer Space Telescope for our study. The main goal of this work was to investigate how star formation proceeds beyond the edge of galactic disks into the surrounding intergalactic medium. Our results show that there are two distinct components along the line-of-sight towards M33: an extended component associated with diffuse ionized gas and young stars; and a compact component dominated by old stellar populations. Using these NIR spectra we have derived radial profiles of several physical parameters such as electron density, temperature, extinction coefficient etc., across the face-on view of M33 s disk. These profiles reveal interesting trends in the properties of interstellar matter within different regions of the galaxy.",
        "watermark_text": "We use new near - infrared ( NIR ) spectroscopic observations with Keck II / DEIMOS , which cover the entire optical extent of the nearby spiral galaxy M33 out to its last detected isophote at 25 mag arcsec - 2 in B - band . We additionally using archival measurements obtained by the Infrared Array Camera onboard the Spitzer Space Telescope for our research .The main goal of this research was to examine how star formation flows beyond the boundary of galactic disks into the nearby intergalactic medium . Our results show that there are two separate constituents along the line - of - seeing towards M33 : an extended component involved with diffuse ionized gas and older stars ; and a compact component dominated by aged stellar regions .Using these NIR spectra we have derived radial profiles of several physical factors such as electron concentration , temperature , extinction factor etc . , across the face - on vision of M33 s disk . These profiles indicate unusual trends in the properties of interstellar matter within various regions of the universe .",
        "ori-fast-z-score": 0.3511234415883917,
        "water-fast-z-score": 6.50986776965388
    },
    {
        "original_text": "We present new observations of the molecular gas in the central region of the nearby galaxy NGC 891, obtained with the IRAM 30m telescope at 1mm and 3mm wavelengths. The data reveal an extended distribution of dense (n(H2) ~ 104 cm-3), warm (T~50K) molecular gas that is associated with the optical disk of this edge-on spiral galaxy. We find evidence for two distinct components to the molecular gas distribution; one component follows closely the dust lane seen in visible light images while another component extends out into the surrounding intergalactic medium. This latter component has been detected previously by other authors but our higher resolution data allow us to resolve it into individual clouds. In addition we detect several compact sources within the galactic plane which are likely to be young star forming regions. These results suggest that there may exist a significant reservoir of molecular material outside the main body of galaxies such as NGC 891.",
        "watermark_text": "We present new images of the molecular gas in the central region of the nearby galaxy NGC 891 , obtained with the IRAM 30m telescope at 1mm and 3mm wavelengths . The data reveal an extended distribution of dense ( n ( H2 ) ~ 104 mm - 3 ) , warm ( T ~ 50K ) molecular dust that is associated with the optical disk of this edge - on spiral galaxy .We see evidence for two different components to the molecular gas distribution ; one element follows tightly the dust track seen in apparent light photographs while another component moves out into the nearby intergalactic medium . This latter component has been detected earlier by other researchers but our higher resolution data enable us to separate it into single clouds .In addition we locate many compact sources within the galactic plane which are likely to be young galaxy producing regions . These data suggest that there may contain a substantial pool of molecular matter outside the main bodies of stars such as NGC 891 .",
        "ori-fast-z-score": -1.6666666666666667,
        "water-fast-z-score": 6.260990336999411
    },
    {
        "original_text": "We present the results of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe (WMAP) satellite and the Swift observatory in the first year of operation, 2004-05. We find that there are no significant differences between the two samples when we compare their distributions for redshift, luminosity distance, radio flux density at 1 GHz, optical magnitude, or X-ray photon index. The only difference is found to be in the distribution of redshifts; this may be due to selection effects caused by the different energy bands used by each instrument. \n \n Keywords: Blazar, Swift, WMAP, survey, cosmology, statistics, gamma-ray bursts, galaxy clusters, dark matter, dark energy, neutrino mass, cosmic microwave background radiation, anisotropies, large-scale structure, gravitational lensing, relativistic jets, quasar, active galactic nuclei",
        "watermark_text": "We present the conclusion of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe ( WMAP ) satellite and the Swift telescope in the first year of operation , 2004 - 05 . We see that there are no considerable changes between the two specimens when we compare their distributions for redshift , luminosity distance , radio flux concentration at 1 GHz , optical magnitude , or X - ray photon index .The only difference is found to be in the distribution of redshifts ; this might be due to choice influences resulting by the different energy bands used by each instrument . Keywords : Blazar , Swift , WMAP , survey , cosmology , statistics , gamma - ray clusters , galaxy rings , soft material , soft energy , neutrino mass , cosmic microwave background radiation , anisotropies , large - scale structure , gravity lensing , relativistic jets , quasar , active galactic nuclei",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 3.3113308926626095
    },
    {
        "original_text": "We present the first measurement of single-transverse-spin asymmetries (SSA) for hadronic dijets produced at midrapidity in p+p collisions at sqrt(sNN) = 5.02 TeV using data collected by the CMS experiment during 2012 corresponding to an integrated luminosity of 2.3 fb-1 . The SSAs are extracted as functions of jet transverse momentum and rapidity, azimuthal angle between jets, and event centrality. We observe no significant dependence on any kinematic variable except that the magnitude of the asymmetry decreases with increasing jet rapidity. Our results are compared to theoretical predictions based on perturbative QCD calculations including higher-order corrections and parton distribution function uncertainties. \nThe measured values agree well within experimental and theoretical uncertainties. This is the most precise measurement of this observable performed so far. \n \n Introduction \n \n Single transverse-spin asymmetries have been observed in several processes involving polarized protons or neutrons  1  , such as inclusive pion production  2  , semi-inclusive deep-inelastic scattering  3  , Drell-Yan lepton pair production  4  , prompt photon production  5  , and direct photons  6  . These measurements provide important information about the spin structure of nucleons  7, 8  .\n \nIn particular, they can be used to test the validity of factorization theorems  9  which relate hard-scattering cross sections to partonic distributions inside the proton  10  . In addition, these observables may also shed light on new physics beyond the Standard Model  11  . \n \n For example, it has recently been suggested  12  that large single-spin asymmetries could arise due to the interference of two amplitudes describing different helicities of quarks emitted from longitudinally polarized gluons in high-energy pp collisions. Such effects would violate parity conservation and thus constitute evidence for new physics  13  . However, there exists only one previous measurement  14  of single-spin asymmeties in hadronic dijet production at high energies. That study was carried out at RHIC  15  where the center-of-mass energy per nucleon-nucleon collision √sNN=200 GeV is much lower",
        "watermark_text": "We present the first measurement of single - transverse - spinning asymmetries ( SSA ) for hadronic dijets created at midrapidity in p + p collisions at sqrt ( sNN ) = 5 . 02 TeV using data derived by the CMS experiment during 2012 corresponding to an unified luminosity of 2 . 3 fb - 1 . The SSAs are derived as functions of jet transverse momentum and rapidity , azimuthal angle between planes , and event centrality .We see no major dependence on any kinematic variable except that the magnitude of the asymmetry decreases with increasing jet rapidity . Our results are compared to theoretical estimates based on perturbative QCD calculations including higher - order corrections and parton distribution function uncertainties .The measured measures agree well within experimental and theoretical uncertainties . This is the most accurate calculation of this observable performed so far .Introduction Single transverse - spinning asymmetries have been observed in multiple processes involving polarized protons or neutrons 1 , such as inclusive pion production 2 , semi - inclusive dark - inelastic emission 3 , Drell - Yan lepton pair production 4 , prompt photon production 5 , and direct photons 6 . These measurements give important information about the spin composition of nucleons 7 , 8 .In particular , they can be used to test the legitimacy of factorization theorems 9 which compare hard - absorption cross sections to partonic distributions inside the proton 10 . In addition , these observables might additionally bring light on new science beyond the Standard Model 11 .For instance , it has recently been proposed 12 that wide single - spinning asymmetries may arise due to the interference of two amplitudes describing different helicities of quarks emitted from longitudinally polarized gluons in high - energy pp collisions . Such effects would violate parity conservation and therefore constitute evidence for recent science 13 .However , there exists only one previous measurement 14 of single - spinning asymmeties in hadronic dijet production at high energies . That experiment was carried out at RHIC 15 where the center - of - mass electricity per nucleon - nucleon collision √sNN = 200 GeV is much lower",
        "ori-fast-z-score": 0.43685202833051895,
        "water-fast-z-score": 7.077002858954407
    },
    {
        "original_text": "The collective properties of odd-mass nuclei are investigated in terms of the interacting vector boson model (IVBM). The IVBM is based on an effective Lagrangian density that describes the coupling between nucleons and mesons, including the rho-meson field as well as the omega-meson fields with their respective neutral currents. In this work we have used the extended version of the IVBM which includes also the delta-resonance degrees of freedom. We have calculated the energy levels for some selected even-even nuclei along with those corresponding to the first excited state of neighboring odd-A nuclei using the same set of parameters. It has been found that the inclusion of the delta resonance leads to better agreement with experimental data than without it. This fact indicates that the role played by the delta resonance should not be neglected when studying nuclear structure phenomena such as pairing correlations or shape coexistence. Finally, we have studied the effect of the spin-orbit interaction on the ground-state band built upon the lowest 0+ state.",
        "watermark_text": "The collective characteristics of odd - weight ions are examined in terms of the interacting vector boson theory ( IVBM ) . The IVBM is based on an appropriate Lagrangian density that describes the interaction between nucleons and mesons , notably the rho - meson field as well as the omega - meson fields with their different neutral currents .In this research we have utilized the extended version of the IVBM which includes also the delta - resonance degrees of liberty . We have predicted the power concentrations for some selected even - even molecules along with those corresponding to the first excited state of neighboring odd - A nuclei using the same list of constraints .It has been shown that the introduction of the delta resonance results to higher agreement with observation information than without it . This fact suggests that the importance played by the delta resonance should not be forgotten when examining nuclear formation dynamics such as pairing correlations or pattern coexistence .Finally , we have researched the impact of the spin - orbit interaction on the surface - state band building upon the lowest 0 + state .",
        "ori-fast-z-score": -1.9877674693472376,
        "water-fast-z-score": 5.597977259474208
    },
    {
        "original_text": "We study the exact Floquet states of a Bose-Einstein condensate (BEC) in an optical lattice under periodic driving, which is realized by periodically modulating the depth of the optical potential. We show that there are two types of Floquet states depending on whether they have zero or nonzero quasienergies. The former ones correspond to the usual Bloch bands while the latter ones represent the so-called Floquet-Bloch bands. In particular, we find that the Floquet-Bloch band structure can be obtained as a result of hybridization between different Bloch bands with opposite momenta. Furthermore, we investigate how these Floquet states evolve when the system parameters change. Finally, we discuss the stability properties of the Floquet states against small perturbations. Our results provide useful insights into the physics of periodically-driven quantum systems. Introduction:-Recent experimental advances allow for realizing artificial gauge fields  1  , synthetic dimensions  2  , topological phases  3  , and even time crystals  4  . These fascinating phenomena are usually observed in ultracold atomic gases trapped in optical lattices  5  .\nIn this work, we consider a Bose-Einstein Condensate (BEC) confined in such a one-dimensional (1D) optical lattice  6  . By applying external laser beams  7, 8  , it is possible to create a periodic modulation of the optical potential  9  . This leads to a periodic variation of the hopping amplitude J(t), which plays the role of a time-dependent Peierls phase  10  . As a consequence, the effective Hamiltonian describing our system becomes time-periodic  11  . It has been shown recently  12  that the corresponding Schrödinger equation admits solutions known as Floquet states  13  . They describe the evolution of the wave function over one period T = 2π/ω 0 where ω 0 denotes the frequency of the periodic drive  14  . Since the Floquet states are not stationary but rather oscillate at the same frequency as the drive  15  , they may exhibit interesting physical features  16  . For example, Floquet engineering allows us to realize exotic superfluidity  17  , non-Abelian anyons  18  , and Major",
        "watermark_text": "We work the exact Floquet states of a Bose - Einstein condensate ( BEC ) in an optical lattice under periodic forcing , which is realized by periodically modulating the depth of the optical potential . We see that there are two forms of Floquet states varying on whether they have zero or nonzero quasienergies .The former ones relate to the usual Bloch groups while the latter ones represent the so - called Floquet - Bloch groups . In particular , we find that the Floquet - Bloch group structure can be obtained as a result of hybridization between various Bloch groups with opposite momenta .Furthermore , we investigate how these Floquet states evolve when the process variables alter . Finally , we investigate the stability properties of the Floquet states against small perturbations .Our results yield useful insights into the physics of periodically - triggered quantum systems . Introduction : - Recent research developments enable for realizing artificial gauge fields 1 , synthetic dimensions 2 , topological phases 3 , and even period crystals 4 .These strange phenomena are typically observed in ultracold atomic gases locked in optical lattices 5 . In this research , we imagine a Bose - Einstein Condensate ( BEC ) locked in such a one - dimensional ( 1D ) optical lattice 6 .By applying external beam waves 7 , 8 , it is common to create a periodic modulation of the optical potential 9 . This leads to a periodic variation of the hopping frequency J ( t ) , which plays the role of a time - dependent Peierls phase 10 .As a consequence , the effective Hamiltonian describing our system gets time - periodic 11 . It has been shown recently 12 that the associated Schrödinger equation accepts solutions known as Floquet states 13 .They define the evolution of the wave function over one period T = 2π / ω 0 where α 0 denotes the frequency of the periodic drive 14 . Since the Floquet states are not stationary but rather oscillate at the same frequency as the drive 15 , they may exhibit exciting physical features 16 .For instance , Floquet engineering enables us to realize unusual superfluidity 17 , non - Abelian anyons 18 , and Major",
        "ori-fast-z-score": 0.5,
        "water-fast-z-score": 7.333333333333333
    },
    {
        "original_text": "We show that correlation clustering is NP-hard to approximate within any constant factor, even for graphs with maximum degree three and clusters of size at most four.  We also present an algorithm which solves this problem exactly in time O(n3). Our results are based on reductions from the exact cover by 3-sets (X3C) problem. The X3C problem asks whether there exists a collection of subsets of a set S such that each element of S belongs to exactly 3 sets in the collection; it has been shown to be NP-complete. For more information about our work see http://arxiv.org/abs/1206.0571 . \nCorrelation clustering is one of several problems studied under the umbrella of  clustering ; these include k-means clustering, spectral clustering, and graph partitioning. It was introduced independently by Bansal et al., Blum et al., and Dasgupta et al. as follows.   Given a weighted undirected graph G = (V, E), where V denotes the vertices and E denotes the edges, we say that two vertices u, v ∈ V are adjacent if they share an edge e ∈ E. A cluster C ⊆ V is defined as a subset of nodes whose pairwise distances satisfy some threshold t > 0. More formally, given a distance function d : V × V → R+ , let dist(u,v) denote the shortest path between u and v; then, C is said to be a valid cluster if and only if for all pairs of nodes u, v ∈ C:  dist(u,v)  ≤ t",
        "watermark_text": "We see that correlation clustering is NP - hard to approximate within any constant factor , even for graphs with maximum degree three and clusters of diameter at most four . We also demonstrate an algorithm which solves this situation exactly in time O ( n3 ) .Our results are based on reductions from the exact cover by 3 - sets ( X3C ) question . The X3C problem questions whether there exists a family of subsets of a space S such that each element of S belongs to exactly 3 sets in the collection ; it has been shown to be NP - full .For more information about our work see http : / / arxiv . org / abs / 1206 . 0571 . Correlation clustering is one of several problems studied under the umbrella of clustering ; these include k - means clustering , spectral clustering , and graph partitioning .It was introduced independently by Bansal et al . , Blum et al . , and Dasgupta et al . as follows .Given a weighted undirected graph G = ( V , E ) , where V denotes the edges and E denotes the edges , we write that two vertices u , v ∈ V are adjoining if they share an vertex e ∈ E . A cluster C ⊆ V is characterized as a subset of vertices whose pairwise distances satisfy some threshold t > 0 . More generally , given a distance relation d : V × V → R + , let dist ( v , v ) define the longest route between u and v ; then , C is said to be a valid cluster if and only if for all pairs of vertices u , v ∈ C : dist ( v , v ) ≤ t",
        "ori-fast-z-score": -1.0945409092309881,
        "water-fast-z-score": 3.482630165734962
    },
    {
        "original_text": "We present the radio through X-ray spectral energy distributions (SEDs) for 38 quasars with broad absorption lines in their optical spectra, selected from the Sloan Digital Sky Survey Data Release 5 quasar catalog and observed by Chandra and/or XMM-Newton. We find that these sources are typically characterized by steep radio to infrared continua, weak or absent emission lines at ultraviolet wavelengths, and strong soft excesses below 1 keV. The majority of our sample show evidence for significant intrinsic reddening as indicated by the presence of deep UV troughs and high values of the Balmer decrement. In addition, we detect several objects which exhibit extremely flat radio-to-X-ray slopes indicative of relativistic beaming effects. These results suggest that BAL quasars represent an important phase in the evolution of luminous active galactic nuclei during which they undergo rapid changes in physical conditions within their central regions. This is supported by recent theoretical models suggesting that BAL outflows may play an important role in regulating black hole growth via feedback processes. \n \n Keywords: Active Galactic Nuclei",
        "watermark_text": "We present the radio through X - ray spectral power distributions ( SEDs ) for 38 quasars with broad absorption lines in their optical spectra , selected from the Sloan Digital Sky Survey Data Release 5 quasar catalog and detected by Chandra and / or XMM - Newton . We see that these sources are typically characterized by steep radio to laser continua , faint or omitted emitted lines at ultraviolet wavelengths , and strong soft excesses below 1 keV .The majority of our sample present evidence for significant intrinsic reddening as indicated by the presence of deep UV troughs and large values of the Balmer decrement . In addition , we find several bodies which exhibit exceptionally flat radio - to - X - ray curves indicative of relativistic beaming effects .These data suggest that BAL quasars represent an important stages in the evolution of luminous active galactic nuclei during which they undergo rapid variations in physical conditions within their central regions . This is backed by recent theoretical theories suggesting that BAL outflows might play an important role in controlling black hole growth via feedback systems .Keywords: Active Galactic Nuclei",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 5.962965874907927
    },
    {
        "original_text": "The rate at which new mutations are fixed in populations is determined by the balance between natural selection and genetic drift, but how these forces interact to shape the evolution of proteins remains poorly understood.  Here we show that neutral genetic drift can accelerate the fixation of beneficial mutations within genes encoding functionally important regions of proteins. We used deep mutational scanning to measure the fitness effects of all possible single amino acid substitutions for two enzymes (T4 lysozyme and TEM-1 β-lactamase) across their entire sequence space. By combining this data with population genetics simulations, we found that neutral genetic drift increased the probability of fixing beneficial mutations in both enzymes  active sites. This effect was particularly pronounced when the number of adaptive mutations available per generation was low or when there were many competing deleterious mutations. Our results suggest that neutral genetic drift may play an underappreciated role in shaping the evolution of proteins.",
        "watermark_text": "The rate at which new mutations are fixed in populations is governed by the balance between natural selection and genetic drift , but how these forces combine to shape the evolution of proteins appears poorly explored . Here we show that neutral genetic drift can accelerate the fixation of beneficial mutations within genes encoding functionally essential regions of proteins .We utilized deep mutational scanning to measure the fitness impacts of all possible single amino residue substitutions for two enzymes ( T4 lysozyme and TEM - 1 β - lactamase ) across their whole sequence area . By combining this data with population genetics simulations , we identified that neutral genetic drift enhanced the probability of fixing beneficial mutations in both enzymes active sites .This influence was especially pronounced when the proportion of adaptive traits usable per generation was poor or when there were several different deleterious traits . Our results show that neutral genetic drift might play an underappreciated importance in shaping the evolution of proteins .",
        "ori-fast-z-score": -1.4100479758212652,
        "water-fast-z-score": 4.013213469645139
    },
    {
        "original_text": "The effect of light quanta on the physiological response of seedlings subjected to nickel (Ni2+) stress was investigated in this study. The results showed that the growth and photosynthetic characteristics were significantly affected by different treatments, especially when exposed to high concentration of Ni2+ for 24 h. Compared with control group, the shoot length decreased by 39% under 100 μM Ni2+ treatment; however, it increased by 20% after exposure to red light (RL). In addition, the root length also reduced by 44% compared with control plants but increased by 25% following RL illumination. Moreover, the chlorophyll content per unit leaf area declined by 42% due to Ni2+ toxicity while it increased by 34% as a result of RL application. Furthermore, the net photosynthesis rate (Pn), stomatal conductance (gs), intercellular CO2 concentration (Ci), transpiration rate (Tr), and water use efficiency (WUE) all decreased by 46%, 49%, 50%, 51%, and 53% respectively at 100 μM Ni2+ treated plants whereas they increased by 29%, 28%, 30%, 31%, and 32% respectively upon exposure to RL. These findings suggested that the effects of Ni2+ toxicity could be alleviated through the application of RL.",
        "watermark_text": "The impact of light quanta on the metabolic reactions of seedlings subjected to nickel ( Ni2 + ) pressure was investigated in this study . The results showed that the development and photosynthetic characteristics were significantly impacted by various methods , particularly when exposed to large concentration of Ni2 + for 24 h . Compared with control group , the shoot length decreased by 39 % under 100 μM Ni2 + treatment ; however , it increased by 20 % after sensitivity to red light ( RL ) .In addition , the root length also declined by 44 % compared with control plants but improved by 25 % subsequent RL illumination . Moreover , the chlorophyll content per unit leaves area declined by 42 % due to Ni2 + toxicity while it increased by 34 % as a result of RL application .Furthermore , the net photosynthesis percentage ( Pn ) , stomatal conductance ( gs ) , intercellular CO2 density ( Ci ) , transpiration rate ( Tr ) , and water use performance ( WUE ) all decreased by 46 % , 49 % , 50 % , 51 % , and 53 % respectively at 100 μM Ni2 + treated stations whereas they increased by 29 % , 28 % , 30 % , 31 % , and 32 % respectively upon exposure to RL . These studies suggested that the effects of Ni2 + toxicity may be alleviated through the application of RL .",
        "ori-fast-z-score": 0.7977240352174656,
        "water-fast-z-score": 6.039910552360811
    },
    {
        "original_text": "The Spitzer Bright Field (SBF) is an all-sky survey at 3.6, 4.5, 5.8 & 8 microns carried out by the Infrared Array Camera on board the Spitzer Space Telescope.  The SBF was designed to provide deep infrared photometry for extragalactic studies in order to complement existing optical surveys such as the Sloan Digital Sky Survey.   This dataset contains images taken with IRAC channel 1 (3.6 micron), channel 2 (4.5 micron), channel 3 (5.8 micron) and channel 4 (8 micron). Each image has been processed using the MOPEX software package developed by the Spitzer Science Center. These images are available through the NASA/IPAC Extragalactic Database (NED).  For more information about this project please see http://irsa.ipac.caltech.edu/data/SPITZER/docs/sbf/sbf-intro.html",
        "watermark_text": "The Spitzer Bright Field ( SBF ) is an all - skies study at 3 . 6 , 4 . 5 , 5 . 8 & 8 microns taken out by the Infrared Array Camera on board the Spitzer Space Telescope . The SBF was built to provide deep infrared photometry for extragalactic studies in order to complement existing imaging observations such as the Sloan Digital Sky Survey .This dataset contains images took with IRAC channel 1 ( 3 . 6 micron ) , channel 2 ( 4 . 5 micron ) , channel 3 ( 5 . 8 micron ) and channel 4 ( 8 micron ) . Each image has been processed utilizing the MOPEX software suite created by the Spitzer Science Center .These photographs are available through the NASA / IPAC Extragalactic Database ( NED ) . For more information about this project please view http : / / irsa . ipac . caltech . edu / data / SPITZER / docs / sbf / sbf - intro . html",
        "ori-fast-z-score": 0.5222329678670935,
        "water-fast-z-score": 4.700096710803842
    },
    {
        "original_text": "We present the results of an analysis to determine rates, masses, spins, and luminosities for intermediate mass ratio inspiral (IMRI) events detectable with advanced gravitational wave detectors such as Advanced LIGO. We use Monte Carlo simulations to generate IMRIs in galactic binaries that are consistent with current observations of binary pulsars and X-ray binaries. The simulated systems evolve through three phases: detached phase, Roche lobe overflow phase, and common envelope phase. In our simulation we assume that all stars have solar metallicity and initial spin periods of 10 days. For each system generated, we calculate its signal-to-noise ratio using the stationary phase approximation. We find that there will be about one event per year within 100 Mpc with signal-to-noise ratios greater than 8. This is comparable to the rate expected for double neutron star mergers. However, unlike double neutron star mergers which occur at high redshifts, most IMRI events should be detected nearby.",
        "watermark_text": "We publish the results of an assessment to estimate rates , masses , spins , and luminosities for intermediate mass ratio inspiral ( IMRI ) events detectable with sophisticated gravitational wave detectors such as Advanced LIGO . We use Monte Carlo simulations to produce IMRIs in galactic binaries that are compatible with current observations of binary pulsars and X - ray binaries .The simulated systems develop through three stages : detached phase , Roche lobe overflow mode , and shared envelope phase . In our modeling we suppose that all stars have solar metallicity and original spin times of 10 days .For each system generated , we determine its signal - to - noise proportion using the stationary phase approximation . We see that there will be about one incident per year within 100 Mpc with signal - to - noise ratios greater than 8 .This is analogous to the speed anticipated for double neutron star mergers . However , unlike single neutron star mergers which occur at high redshifts , most IMRI events should be identified nearby .",
        "ori-fast-z-score": 0.7071067811865476,
        "water-fast-z-score": 5.815230125149881
    },
    {
        "original_text": "The Kuiper belt is the source region for most short period comets, but its formation remains poorly understood. We present results from N-body simulations that show how collisions among planetesimals in Neptune s feeding zone can produce objects with orbits similar to those observed today. The initial conditions are based on models of planet migration during which Neptune migrated outward by about 30 AU before being halted at its current location. Our calculations suggest that the Kuiper belt formed as a result of collisional grinding between bodies whose sizes were comparable to Pluto (r ~ 1000 km). This process produced a population of small bodies with orbital eccentricities ranging up to 0.3. Subsequent encounters with Neptune caused some of these bodies to be scattered into highly eccentric orbits. These results provide an explanation for why there appears to be no correlation between the size distribution of KBOs and their orbital eccentricity.",
        "watermark_text": "The Kuiper belt is the origin region for most short period comets , but its formation appears poorly known . We publish results from N - bodies simulations that demonstrate how collisions among planetesimals in Neptune s feeding area can generate objects with orbits similar to those observed currently .The initial conditions are based on estimates of planet migration during which Neptune migrated outward by about 30 AU before being stopped at its current site . Our calculations suggest that the Kuiper belt developed as a outcome of collisional grinding between bodies whose sizes were analogous to Pluto ( r ~ 1000 kilometers ) .This process produced a population of tiny bodies with orbital eccentricities ranging up to 0 . 3 . Subsequent experiences with Neptune resulted some of these objects to be scattered into extremely eccentric orbits .These data provide an reason for why there seems to be no correlation between the size distribution of KBOs and their orbital eccentricity .",
        "ori-fast-z-score": -0.9847319278346618,
        "water-fast-z-score": 5.333493587335964
    },
    {
        "original_text": "We consider the problem of designing distributed consensus algorithms in sensor networks where links are randomly generated and can be lost or added over time. We propose an algorithm that is robust to link failures, but requires only local information exchange between neighboring nodes. The proposed algorithm achieves global convergence under mild conditions on network topology. In particular, we show that if each node has at least one neighbor whose degree is greater than its own then our algorithm converges almost surely (a.s.) to the correct value. Our results also hold when there exists a small number of Byzantine nodes which may deviate arbitrarily from their prescribed behavior. Finally, numerical simulations demonstrate the effectiveness of our approach. Keywords: Sensor Networks; Distributed Consensus; Local Information Exchange; Robustness Analysis. 1 Introduction Distributed consensus problems arise naturally in many applications such as flocking  1  , formation control  2  , multi-agent coordination  3  , wireless sensor networks  4  , etc.. A typical example is the average-consensus problem: given a set of n agents connected by communication links, each agent holds some initial data xi(0) ∈ Rm, i = 1, ..., n; it aims to compute the average x̄=1/n∑in=1xi(0). This problem was first studied by Tsitsiklis et al.  5  . They showed that if all agents have access to the same fixed directed graph G, then the average-consensus problem can be solved using a simple linear iterative scheme. However, this assumption does not always hold true since the underlying communication graphs are often random due to unreliable links  6  .\nIn recent years, several researchers have investigated the design of distributed consensus algorithms in dynamic networks  7-10 . For instance, Olfati-Saber  7  considered the case where the communication links among agents change randomly according to independent Bernoulli processes. Under certain assumptions on the connectivity of the network, she proved that her algorithm converges almost surely (i.e., with probability one) to the desired average. Subsequently, Jadbabaie et al.  8  extended these results to undirected networks. More recently,",
        "watermark_text": "We consider the issue of constructing dispersed consensus algorithms in sensor networks where links are randomly generated and can be lost or added over time . We suggest an algorithm that is robust to link errors , but requires only local information transfer between neighboring connections .The proposed algorithm achieves global convergence under mild assumptions on system topology . In particular , we prove that if each node has at least one neighbor whose degree is greater than its own then our algorithm converges almost always ( a . s . ) to the appropriate value .Our results also hold when there exists a small number of Byzantine nodes which may deviate arbitrarily from their appropriate behavior . Finally , numerical simulations prove the ability of our approach .Keywords : Sensor Networks ; Distributed Consensus ; Local Information Exchange ; Robustness Analysis . 1 Introduction Distributed consensus difficulties arise naturally in different applications such as flocking 1 , structure control 2 , multi - agent coordination 3 , wireless sensor networks 4 , etc . . A typical example is the average - consensus problem : considering a setting of n agents connected by communication connections , each agent possesses some initial data xi ( 0 ) ∈ Rm , i = 1 , . . . , n ; it aims to compute the average [UNK] = 1 / [UNK] = 1xi ( 0 ) .This problem was first investigated by Tsitsiklis et al . 5 .They showed that if all agents have access to the same fixed directed graph G , then the average - consensus problem can be answered using a simple linear iterative plan . However , this claim does not always hold false since the underlying communication graphs are often random due to unreliable links 6 .In recent years , various papers have researched the development of distributed agreement algorithms in dynamic networks 7 - 10 . For instance , Olfati - Saber 7 considered the case where the information links among participants change automatically according to individual Bernoulli processes .Under certain assumptions on the connectivity of the network , she proved that her algorithm converges almost always ( i . e . , with probability one ) to the desired average . Subsequently , Jadbabaie et al .8 extended these results to undirected networks . More recently ,",
        "ori-fast-z-score": 1.4791479939068937,
        "water-fast-z-score": 7.597626364883187
    },
    {
        "original_text": "We present deep near-infrared imaging and spectroscopy for two fields in the Hubble Deep Field South (HDF-S) covering an area of 0.5 square degrees each, centered on RA = 03:32:47.6 Dec = -27:48:30 (J2000). The data were obtained with ISAAC at VLT as part of our ESO Large Programme  First Stars First Galaxies . We have detected more than 1000 galaxies down to KsAB = 24 mag over this field using SExtractor. In addition we have spectroscopically confirmed about 100 objects selected by their photometric redshifts between z=0.7-1.3. This is one of the largest samples of high-z galaxies ever assembled. Our sample includes both Lyman-break galaxies and sub-millimeter sources which are likely to be dusty starbursting systems. These results will allow us to study galaxy formation and evolution up to redshift 1.",
        "watermark_text": "We present dark near - infrared imaging and spectroscopy for two fields in the Hubble Deep Field South ( HDF - S ) covering an area of 0 . 5 square degrees each , centered on RA = 03 : 32 : 47 . 6 Dec = - 27 : 48 : 30 ( J2000 ) . The data were obtained with ISAAC at VLT as part of our ESO Large Programme First Stars First Galaxies .We have discovered more than 1000 galaxies down to KsAB = 24 mag over this field using SExtractor . In addition we have spectroscopically confirmed about 100 galaxies designated by their photometric redshifts between z = 0 . 7 - 1 . 3 .This is one of the largest analyses of high - z galaxies yet assembled . Our specimen includes both Lyman - break galaxies and sub - millimeter sources which are likely to be dusty starbursting systems .These data will able us to study galaxy formation and evolution up to redshift 1 .",
        "ori-fast-z-score": 0.9045340337332909,
        "water-fast-z-score": 4.221158824088691
    },
    {
        "original_text": "We study the phase behavior and structure of binary mixtures composed of soft repulsive spheres with attractive depletants, which are modeled as hard-spheres that interact only via excluded volume interactions. We find that these systems exhibit rich phase diagrams including gas-liquid coexistence at low temperatures for all compositions studied here (0.25 < f < 0.75), where f is the fraction of particles made up by the smaller species. The liquid-gas binodal lines shift to higher pressures upon increasing the size ratio between the two components. For large size ratios we observe an additional fluid-fluid transition line along which both fluids have similar densities but different structures. This new fluid state has been observed experimentally in colloidal suspensions containing nonadsorbing polymer chains. Our results show good agreement with experimental data on colloid-polymer mixtures over wide ranges of temperature, pressure, and composition. \nI. INTRODUCTIO N\nThe presence of small particles can dramatically affect the properties of larger ones through depletion forces  1  . These effects play important roles in many physical phenomena such as protein crystallization  2  , gelation  3  , and sedimentation  4  .\nDepending on their sizes relative to each other, the mixture may be either miscible or immiscible  5  . In addition, there exist regions of metastability  6  and even multiple phases  7, 8  . A number of theoretical studies  9  -  11  have investigated the effect of depletion attractions on the phase diagram of simple model systems. However, most of them focused on idealized models neglecting hydrodynamic interactions  12  , finite-size effects  13  , polydispersity  14  , and particle shape  15  . Only recently did some authors  16  take into account more realistic features like Brownian motion  17  , electrostatic repulsion  18  , and van der Waals attraction  19  . Despite this progress, it remains difficult to predict the exact location of the critical point  20  due to strong correlations  21  among the particles  22  . Moreover, the influence of depletion forces on the structural  23  and dynamical  24  properties of complex fluids still needs further investigation  25  .\nIn recent years, experiments  26 ",
        "watermark_text": "We research the phase response and shape of binary mixtures consisting of soft repulsive balls with interesting depletants , which are modeled as hard - spheres that interact only via excluded volume interactions . We see that these systems exhibit rich phase diagrams including gas - fluid coexistence at low temperatures for all compositions studied here ( 0 . 25 < f < 0 . 75 ) , where f is the fraction of molecules making up by the smaller species .The gas - gas binodal lines shift to higher pressures upon increasing the height factor between the two parts . For large size ratios we study an additional liquid - fluid transition line along which both gases have equal densities but different structures .This new fluid state has been observed experimentally in colloidal suspensions containing nonadsorbing polymer complexes . Our results show good agreement with experimental evidence on colloid - polymer mixtures over broad ranges of temperature , pressure , and composition .I . INTRODUCTIO N The appearance of tiny particles can dramatically impact the properties of bigger ones through depletion forces 1 . These effects play essential roles in different physical phenomena such as protein crystallization 2 , gelation 3 , and sedimentation 4 .Depending on their sizes comparative to each other , the mixture might be either miscible or immiscible 5 . In addition , there exist zones of metastability 6 and even multiple components 7 , 8 .A variety of theoretical investigations 9 - 11 have explored the impact of depletion attractions on the phase diagram of simple model structures . However , most of them focused on idealized models neglecting hydrodynamic interactions 12 , finite - length effects 13 , polydispersity 14 , and electron shape 15 .Only lately did some writers 16 taking into consideration more realistic characteristics like Brownian movement 17 , electrostatic repulsion 18 , and van der Waals attraction 19 . Despite this progress , it remains impossible to predict the exact location of the critical position 20 due to powerful correlations 21 among the ions 22 .Moreover , the impact of depletion forces on the structural 23 and dynamical 24 properties of complex fluids already requires further investigation 25 . In recent years , observations 26",
        "ori-fast-z-score": -0.16012815380508713,
        "water-fast-z-score": 8.009821015753255
    },
    {
        "original_text": "We report on observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) that reveal emission lines associated with carbon monoxide and its isotopologue, 13CO, as well as the CN radical toward the quasar host galaxy at redshift 2.56 known as the  Cloverleaf  source.  The observed line ratios are consistent with those expected for gas exposed to intense radiation fields characteristic of quasars. We also detect absorption by molecular hydrogen along this sightline through intervening clouds located between us and the quasar host galaxy. These results provide new insights into the physical conditions within the interstellar medium surrounding active galactic nuclei during their early evolutionary stages. This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited. \nThe detection of carbon monoxide (CO), one of the most abundant molecules in space, has been used extensively over the past several decades to study the properties of cold neutral atomic and molecular gas in galaxies across cosmic time. However, CO can be difficult to observe directly because it lacks electric dipole moments and thus emits very weakly. In addition, the excitation temperature of the lowest rotational levels of CO is typically low enough such that these transitions fall outside of the frequency range accessible to ground-based telescopes operating at millimeter wavelengths. As a result, much of our understanding about the physical conditions present in dense regions of star-forming galaxies comes from studies of other tracers of molecular gas, including HCN, H2S, CS, CH3OH, H2O, and OH+.",
        "watermark_text": "We report on observations made with the Atacama Large Millimeter / submillimeter Array ( ALMA ) that indicate emission lines linked with carbon monoxide and its isotopologue , 13CO , as well as the CN radical toward the quasar host galaxy at redshift 2 . 56 referred as the Cloverleaf source . The observed line proportions are compatible with those expected for gas exposed to intense radiation fields typical of quasars .We additionally observe absorption by molecular hydrogen along this sightline through intervening clouds situated between us and the quasar host universe . These data provide fresh insights into the physical conditions within the interstellar medium underlying active galactic nuclei during their early evolutionary stages .This is an free access section under the terms of the Creative Commons Attribution License , which allows use , distribution and reproduction in any medium , provided the original book is properly cited . The observation of carbon monoxide ( CO ) , one of the most numerous compounds in space , has been used widely over the previous several decades to study the properties of cold neutral atomic and molecular dust in galaxies across cosmic time .However , CO can be harder to observe directly because it lacks magnetic dipole moments and therefore emits very weakly . In addition , the excitation temperature of the lowest rotational concentrations of CO is typically minimum enough such that these changes fall outside of the frequency spectrum accessible to surface - based telescopes active at millimeter wavelengths .As a result , much of our knowing about the physical conditions present in dense areas of galaxy - making clusters comes from studies of other tracers of molecular energy , notably HCN , H2S , CS , CH3OH , H2O , and OH + .",
        "ori-fast-z-score": -1.4485719366802965,
        "water-fast-z-score": 6.9428561869392285
    },
    {
        "original_text": "We present an analysis of optical and infrared photometric data obtained during the recent (2006-2008) outbursts of the dwarf novae system V2051 Oph, which is one of only three known to have exhibited both superoutbursts and normal outbursts in its lifetime.  We find that the light curve of this object shows many similarities with those observed for other SU UMa-type systems but also some significant differences. In particular we note that there are no clear signs of rebrightening following either the first or second superoutburst; nor do we see any evidence for a double-humped structure in the light curves at all phases of these events. The lack of such features may be due to the fact that our observations were made when the system was relatively faint compared to previous studies. However, it should be noted that the orbital period of V2051 Oph is significantly longer than most other SU UMa stars so that the mass transfer rate will be lower by about a factor of ten.",
        "watermark_text": "We present an assessment of optical and infrared photometric data acquired during the recent ( 2006 - 2008 ) outbursts of the dwarf novae component V2051 Oph , which is one of only three known to have exhibited both superoutbursts and normal outbursts in its lifetime . We see that the light curve of this body demonstrates many similarities with those observed for other SU UMa - class systems but also some significant variations .In particular we note that there are no clear indicators of rebrightening following either the first or second superoutburst ; nor do we find any evidence for a twin - humped structure in the light curves at all phases of these events . The absence of such properties may be due to the fact that our observations were made when the system was quite dim relative to previous analyses .However , it should be mentioned that the orbital period of V2051 Oph is significantly greater than most other SU UMa stars so that the mass transfer time will be reduced by about a factor of ten .",
        "ori-fast-z-score": 0.9847319278346618,
        "water-fast-z-score": 6.230641662171566
    },
    {
        "original_text": "The energy spectrum of gamma rays is one of the most important information to understand their origin and propagation in space, since it contains crucial information on the physical processes involved.  In this work we present results obtained with the Tibet ASγ experiment for the determination of the energy spectra of several bright sources detected by the Energetic Gamma Ray Experiment Telescope (EGRET) aboard the Compton Gamma-Ray Observatory satellite. The data were taken between 1997 and 2000 at Yangbajing Cosmic Ray Laboratory (Tibet). We have analyzed about 1 million events collected during these four years. By using Monte Carlo simulations based on CORSIKA code, we estimate that our detector has a detection efficiency above 80% for primary cosmic ray energies greater than 10 TeV. Our analysis shows that the observed fluxes are consistent with power law functions with spectral indices ranging from 2.0 to 3.5. These values agree well with those reported previously by other experiments.",
        "watermark_text": "The energy spectrum of gamma radiation is one of the most important information to comprehend their source and propagation in space , since it contains vital information on the physical processes concerned . In this research we present results derived with the Tibet ASγ experiment for the determination of the power spectra of several bright sources detected by the Energetic Gamma Ray Experiment Telescope ( EGRET ) aboard the Compton Gamma - Ray Observatory satellite .The data were took between 1997 and 2000 at Yangbajing Cosmic Ray Laboratory ( Tibet ) . We have analyzed about 1 million events collected during these four seasons .By using Monte Carlo simulations based on CORSIKA code , we estimate that our camera has a detection efficiency above 80 % for principal cosmic ray energies higher than 10 TeV . Our study shows that the seen fluxes are compatible with power law functions with spectral indices varied from 2 . 0 to 3 . 5 .These quantities agree well with those published previously by other experiments .",
        "ori-fast-z-score": 0.8962581595302719,
        "water-fast-z-score": 5.761659596980319
    },
    {
        "original_text": "We report on our analysis of the outburst mechanism of SGR 1806-20, which is one of three known magnetars (neutron stars with superstrong magnetic fields). We have analyzed all available data obtained by Swift/BAT during its first year in orbit to search for periodicities associated with this source. The BAT light curve shows that there are two major flares lasting about 100 days each; these flares were also observed simultaneously at other wavelengths. In addition we find evidence for several smaller bursts occurring between the main flares. Using an improved version of the method developed by Israel et al. (2008) we searched for pulsations in the BAT data corresponding to the time intervals when the source was active. No significant signal could be found above background noise levels down to a limit of 1 mCrab (3σ), but we did detect a weak signal below 0.5 mCrab. This signal has been confirmed using independent methods applied to different energy bands.",
        "watermark_text": "We report on our analysis of the outburst mechanism of SGR 1806 - 20 , which is one of three known magnetars ( neutron galaxies with superstrong magnetic fields ) . We have analyzed all available data acquired by Swift / BAT during its initial season in orbit to search for periodicities associated with this source .The BAT signal curve shows that there are two major flares lasting about 100 days each ; these flares were also observed concurrently at other wavelengths . In addition we find proof for numerous smaller bursts happening between the main flares .Using an better version of the method developed by Israel et al . ( 2008 ) we searched for pulsations in the BAT signal related to the period intervals when the source was active .No meaningful wave possible be found above background noise values down to a limit of 1 mCrab ( 3σ ) , but we did detect a weak noise below 0 . 5 mCrab . This signal has been confirmed using separate methods applied to different energy bands .",
        "ori-fast-z-score": -0.36650833306891567,
        "water-fast-z-score": 4.608176875690327
    },
    {
        "original_text": "Spin-based electronics is an emerging field that has attracted considerable attention in recent years, due to its potential for applications such as high-density data storage and high-speed information processing.  In this review article we discuss the basic concepts underlying bipolar spintronic devices based on semiconductor heterostructures with ferromagnetic contacts. We first introduce the physics behind spin injection into semiconductors using tunnel barriers or Schottky diodes. Then we describe how these injected spins can be manipulated by means of external magnetic fields and/or electric currents. Finally, we present some examples of spintronic devices including spin-LEDs, spin transistors, and spin-logic circuits. The main focus will be put on GaAs-based structures but also other materials systems are discussed briefly. This article is intended to provide a comprehensive overview of the state-of-the-art research in the field of bipolar spintronics. It should serve both as a guide for newcomers interested in learning about the fundamentals of spin transport phenomena at interfaces between metals and semiconductors, and as a reference source for researchers working in related areas.",
        "watermark_text": "Spin - based computing is an developing field that has garnered considerable scrutiny in recent years , owing to its potential for applications such as high - density data storage and large - speed information processing . In this review article we explain the fundamental concepts governing bipolar spintronic systems based on semiconductor heterostructures with ferromagnetic contacts .We first introduce the physics behind spin injection into semiconductors using tunnel fences or Schottky diodes . Then we explain how these injected spinning can be manipulated by means of external magnetic waves and / or electric currents .Finally , we present some examples of spintronic systems including spin - LEDs , spin transistors , and spin - logic devices . The main attention will be place on GaAs - based assemblies but also other materials systems are discussed briefly .This page is intended to provide a comprehensive overview of the state - of - the - art studies in the field of bipolar spintronics . It should serve both as a reference for newcomers interested in knowing about the fundamentals of spin transport phenomena at connections between metals and semiconductors , and as a reference source for researchers working in related fields .",
        "ori-fast-z-score": 0.4216370213557839,
        "water-fast-z-score": 5.902918298980975
    },
    {
        "original_text": "We study the conservation laws for linear parabolic equations with constant coefficients in one space dimension, which are given by Noether s theorem as integrals over time of certain densities that depend on solutions to the equation. We show how these densities can be computed using an algorithm based on symbolic integration techniques. The resulting expressions have been implemented into a computer program called CONSINTEP (Conservation Laws INTerpreter) written in Maple. This software is available at http://math.univ-lyon1.fr/~boudjema/consintep/index.html . Keywords: Conservation law, symmetry group, potential symmetry, Noether s theorem, linear partial differential equations, Maple. 1 Introduction In this article we present some results concerning conservation laws and potential symmetries of linear parabolic equations. These results were obtained during my PhD thesis  1  , where I developed algorithms for computing conserved quantities associated with such equations. Here we give a brief overview of our main results. \nThe concept of conservation law plays an important role in physics since it allows us to describe physical phenomena in terms of energy or entropy balance. For example, if u(x, t) denotes the temperature distribution inside a rod at position x ∈  0, 1  and time t ≥ 0 then the total amount of heat contained within the rod satisfies the following equation: \nwhere c > 0 is a positive constant describing the thermal conductivity of the material. If we assume that there exists no source term f = 0, i.e., all the heat entering the system leaves again after some time interval, then integrating Eq. (1) \nover the spatial domain yields the first integral of motion Q(t), also known as the energy density,\nwhich describes the total amount of heat stored up in the rod at any point in time. Note that the second equality follows directly from Green s formula applied to the left-hand side of Eq. (2).",
        "watermark_text": "We research the conservation laws for linear parabolic equations with constant coefficients in one space dimension , which are given by Noether s theorem as integrals over time of certain densities that rely on solutions to the equation . We see how these densities can be computed using an algorithm based on symbolic analysis methods .The resulting statements have been implemented into a computer program named CONSINTEP ( Conservation Laws INTerpreter ) published in Maple . This program is accessible at http : / / math . univ - lyon1 . fr / ~ boudjema / consintep / index . html .Keywords : Conservation law , symmetry class , potential symmetry , Noether s theorem , linear partial differential coefficients , Maple . 1 Introduction In this article we present some developments relating conservation laws and potential symmetries of linear parabolic equations .These conclusions were obtained during my PhD doctoral 1 , where I derived methods for modeling conserved quantities associated with such equations . Here we give a brief overview of our major results .The concept of protection law serves an important role in science since it allows us to explain physical phenomena in terms of power or entropy balance . For instance , if u ( x , t ) denotes the temperature distribution inside a rod at position x ∈ 0 , 1 and time t ≥ 0 then the total quantity of temperature contained within the rod satisfies the following equation : where k > 0 is a positive variable describing the thermal conductivity of the metal .If we suppose that there exists no source term h = 0 , i . e . , all the heat exiting the system leaves again after some time interval , then integrating Eq . ( 1 ) over the spatial domain yields the first integral of movement Q ( t ) , sometimes called as the electricity density , which expresses the total quantity of warmth used up in the rod at any point in time .Note that the second equality follows directly from Green s method applied to the leave - hand half of Eq . ( 2 ) .",
        "ori-fast-z-score": -1.0650014966747527,
        "water-fast-z-score": 6.205374015050718
    },
    {
        "original_text": "We present optical variability measurements for infrared power law-selected galaxies and X-ray sources in the Chandra Deep Field South (CDFS). We use data obtained with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts, rest-frame absolute magnitudes, stellar masses, star formation rates, and specific star-formation rates for these objects over an eight-year baseline. The sample consists of 16,000 galaxies at 0 < z < 5 selected by their mid-infrared colors using Spitzer/IRAC observations as well as 1,500 X-ray point sources detected in deep Chandra observations. We find that both galaxy samples show significant levels of intrinsic variation on timescales ranging from days to years. For example, we detect more than 50% of our IRAC-selected galaxies at 3.6 microns and 80% at 4.5 microns showing >0.1 mag variations between epochs separated by one year or less. These results are consistent with previous studies which have found similar levels of variability among optically-selected quasars. However, we also find evidence suggesting that this level of variability is not driven solely by AGN activity but may be associated with other physical processes such as mergers and/or interactions within the host galaxy itself.",
        "watermark_text": "We present optical variability observations for laser power law - selected galaxies and X - ray sources in the Chandra Deep Field South ( CDFS ) . We use data acquired with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts , rest - frame absolute magnitudes , stellar masses , sun formation rates , and particular galaxy - formation rates for these objects over an eight - month baseline .The sample consists of 16 , 000 galaxies at 0 < z < 5 selected by their mid - infrared colors using Spitzer / IRAC measurements as also as 1 , 500 X - ray point sources detected in deep Chandra measurements . We see that both star samples show considerable rates of intrinsic variation on timescales ranging from hours to decades .For instance , we find more than 50 % of our IRAC - selected galaxies at 3 . 6 microns and 80 % at 4 . 5 microns showing > 0 . 1 mag variations between epochs separated by one decade or less . These conclusions are compatible with previous research which have discovered similar rates of variability among optically - selected quasars .However , we also find proof suggesting that this level of variability is not driven solely by AGN activity but might be involved with other structural processes such as mergers and / or relationships within the host universe itself .",
        "ori-fast-z-score": -1.2939932784412609,
        "water-fast-z-score": 5.682196434640312
    },
    {
        "original_text": "We present an approach to the modeling and simulation of combining concepts, which is based on quantum field theory (QFT) in Fock space. The basic idea behind our model is that each concept can be represented by its own QFT with specific properties. In order to combine two or more concepts we have to couple these fields together. We show how this coupling leads to new states representing combinations of concepts. Furthermore, we discuss some possible applications for our model such as combinatorial optimization problems and computational linguistics. Finally, we give examples illustrating the usefulness of our approach. Keywords: Quantum field theory, Fock space, Combining concepts, Computational linguistics, Optimization problem. 1 Introduction Quantum mechanics has been successfully applied to many different areas ranging from physics over chemistry to biology  1  . However, there are still open questions about the foundations of quantum mechanics  2  , especially concerning the interpretation of measurement results  3  .\nIn recent years, researchers started applying quantum mechanical models also to other disciplines like computer science  4  , cognitive psychology  5  , neuroscience  6  , economics  7  , etc.. For example, it was shown that quantum mechanical models could help solving certain NP-hard problems  8  . Moreover, quantum mechanical models were used to explain human decision making  9  and learning processes  10  .",
        "watermark_text": "We present an view to the description and modeling of combining ideas , which is based on quantum field theory ( QFT ) in Fock space . The basic idea behind our model is that each idea can be described by its own QFT with particular features .In order to mix two or more ideas we have to mix these fields together . We see how this bonding gives to different states representing combinations of concepts .Furthermore , we explain some possible users for our model such as combinatorial algorithm issues and mathematical linguistics . Finally , we give examples illustrating the usefulness of our approach .Keywords : Quantum field model , Fock space , Combining principles , Computational linguistics , Optimization problem . 1 Introduction Quantum theory has been successfully application to many various fields ranging from science over chemistry to biology 1 .However , there are still open questions about the foundations of quantum mechanics 2 , particularly concerning the interpretation of measurement data 3 . In past decades , researchers began application quantum mechanical models also to other disciplines like digital science 4 , cognitive psychology 5 , neuroscience 6 , economics 7 , etc . . For instance , it was shown that quantum mechanical models could assist solving specific NP - hard problems 8 .Moreover , quantum mechanical models were used to explain brain judgment makes 9 and educational processes 10 .",
        "ori-fast-z-score": -0.29002094671369905,
        "water-fast-z-score": 7.627700713964739
    },
    {
        "original_text": "The intramolecular structure of polymers is studied by means of the molecular dynamics simulation method for several model systems with different chain lengths, degrees of branching, and types of interactions between monomers. It has been found that the intramolecular correlation function can be represented as a sum of two terms corresponding to short- and long-range contributions. The latter term describes the contribution of segments separated by distances larger than the average distance between neighboring chains. This term depends on the number density of chains and their length. In addition, it was shown that this term decreases exponentially at large separations. The dependence of the first four moments of the segmental size distribution on temperature and pressure are calculated using the results obtained previously. These dependences were compared with experimental data available in literature. Good agreement between theory and experiment is observed. \n \n Keywords: Polymer melt, Intramolecular structure, Correlation functions, Segmental size distribution",
        "watermark_text": "The intramolecular structure of polymers is studied by means of the molecular dynamics simulation method for numerous model models with various chain lengths , degrees of branching , and types of interactions between monomers . It has been shown that the intramolecular relationship value can be described as a sum of two terms corresponding to short - and long - range contributions .The latter term describes the contribution of segments apart by distances bigger than the average distance between neighboring lines . This term relies on the number density of chains and their length .In addition , it was shown that this term drops exponentially at large separations . The dependence of the first four moments of the segmental size distribution on temperature and pressure are measured using the results derived earlier .These dependences were compared with observation information available in literature . Good agreement between theoretical and experiment is observed .Keywords : Polymer melt , Intramolecular structure , Correlation properties , Segmental size distribution",
        "ori-fast-z-score": 0.7977240352174656,
        "water-fast-z-score": 4.817730411281796
    },
    {
        "original_text": "The flicker noise is the low-frequency fluctuations observed in electrical resistance and other transport properties of metals at temperatures below 1 K.  The theory developed by Altshuler, Aronov, and Khmelnitsky (AAK) explains this phenomenon as arising due to electron-electron interactions within the metal film.  In their original work they assumed that electrons are scattered elastically off impurities or phonons.  However, recent experiments have shown that there can be significant inelastic scattering between electrons which leads to additional contributions to the resistivity.  Here we present an extension of AAK s theory for the case where both elastic and inelastic scattering processes contribute to the resistivity.  We show how our results compare with existing experimental data on thin gold films grown epitaxially on silicon substrates. The flicker noise is the low- frequency fluctuations observed in electrical resistance  and other transport properties of metallic systems at temperatures below 1K . It was first discovered in 1963 when measuring the resistance of thin silver wires  1  , but it has since been found in many different types of materials including semiconductors  2  , superconductors  3  , carbon nanotubes  4  , graphene  5  , and topological insulators  6  .\nIn order to explain these observations, Altshuler et al. (AAK) proposed a theoretical model based on the assumption that electrons scatter elastically off impurities  7, 8  .  This approach successfully describes most of the available experimental data  9  , however some discrepancies were recently reported  10  . These deviations may arise because the elastic approximation does not take into account possible inelastic scattering events  11  .",
        "watermark_text": "The flicker sound is the small - frequency fluctuations found in electrical resistance and other transport properties of metals at conditions below 1 K . The theory advanced by Altshuler , Aronov , and Khmelnitsky ( AAK ) presents this phenomenon as occurring due to ion - atom relationships within the metal film . In their early research they thought that electrons are scattered elastically off impurities or phonons .However , recent experiments have shown that there can be considerable inelastic scattering between electrons which results to significant contributions to the resistivity . Here we present an extension of AAK s concept for the case where both elastic and inelastic scattering mechanisms lead to the resistivity .We see how our findings compare with existing experimental evidence on thin gold films grown epitaxially on silicon substrates . The flicker sound is the small - frequency fluctuations detected in electrical resistance and other transport properties of metallic circuits at conditions below 1K .It was first discovered in 1963 when monitoring the tolerance of short metal wires 1 , but it has since been seen in multiple diverse kinds of substances including semiconductors 2 , superconductors 3 , silicon nanotubes 4 , graphene 5 , and topological insulators 6 . In try to explain these observations , Altshuler et al .( AAK ) proposed a conceptual theory based on the assumption that electrons scatter elastically off impurities 7 , 8 . This method effectively describes most of the provided experimental evidence 9 , however some discrepancies were recently noted 10 .These deviations might arise because the elastic equation does not take into consideration proposed inelastic scattering events 11 .",
        "ori-fast-z-score": -1.044073795327749,
        "water-fast-z-score": 8.693182879212225
    },
    {
        "original_text": "The stretching of homopolymer chains is studied by molecular dynamics simulations in the presence of an external force applied to one end of each chain.  The results are compared with those obtained for polyelectrolyte chains, which have been shown previously to exhibit similar behavior under tension.   It is found that both types of polymer chains show qualitatively similar behavior when stretched at low temperatures and high forces; however, there are significant differences between them at higher temperatures or lower forces.   ... This article was originally published on ArXiv.org s preprint server. Read more about this research at: http://arxiv.org/abs/cond-mat/0405033 . \nAuthors:  Yi-Chun Chen , Shih-Chieh Wu , Chia-Hui Lee , Hsinchu, Taiwan .\nAffiliation: Institute of Physics ,  Academia Sinica,  Taipei, Taiwan .\nEmail: yichun@phys.sinica.edu.tw",
        "watermark_text": "The extension of homopolymer bars is studied by molecular dynamics simulations in the presence of an external stress introduced to one end of each chain . The results are compared with those achieved for polyelectrolyte rings , which have been shown previously to undergo similar behavior under pressure .It is found that both types of polymer chains show qualitatively identical performance when stretched at low temperatures and low forces ; however , there are significant variations between them at higher temperatures or lower forces . . . .This section was originally published on ArXiv . org s preprint server . Read more about this research at : www : / / arxiv . org / abs / cond - mat / 0405033 .Authors:  Yi-Chun Chen , Shih-Chieh Wu , Chia-Hui Lee , Hsinchu, Taiwan .Affiliation: Institute of Physics ,  Academia Sinica,  Taipei, Taiwan .Email: yichun@phys.sinica.edu.tw",
        "ori-fast-z-score": 0.282842712474619,
        "water-fast-z-score": 4.142857142857143
    },
    {
        "original_text": "We present an algorithm for the numerical evaluation of Feynman diagrams with arbitrary numbers of external particles and internal loops, which is based on the concept of  partonic subdiagrams . The method allows to perform calculations in QCD beyond leading order accuracy without any approximations or assumptions about the kinematics of the process under consideration. We demonstrate its applicability by calculating the next-to-leading-order corrections to the production cross section of heavy quarks at hadron colliders. In this talk we will discuss how one can gain analytic control over parton showers using the concept of  partons  as fundamental degrees of freedom. This approach has been developed recently within the framework of Soft-Collinear Effective Theory (SCET)  1  . It provides a systematic way to resum large logarithms associated with collinear splittings into multiple jets  2  , thereby improving our understanding of jet physics  3  .\nThe basic idea behind SCET is that physical observables are described by matrix elements involving soft and/or collinear fields only  4  . These fields have nontrivial transformation properties under boosts along the beam axis  5  . They allow us to separate hard interactions from soft radiation  6  . As a result, it becomes possible to systematically factorize contributions to scattering amplitudes into  hard functions  describing short-distance dynamics  7, 8  and  semi-hard functions  encoding information about the emission of soft gluons  9  .",
        "watermark_text": "We present an algorithm for the numerical identification of Feynman diagrams with arbitrary numbers of external particles and internal loops , which is based on the idea of partonic subdiagrams . The method enables to conduct measurements in QCD beyond trailing order accuracy without any approximations or assumptions about the kinematics of the process under consideration .We test its applicability by calculating the second - to - leading - order corrections to the production cross section of large quarks at hadron colliders . In this talk we will explore how one can obtain analytic control over parton showers using the idea of partons as essential degrees of liberty .This method has been constructed recently within the framework of Soft - Collinear Effective Theory ( SCET ) 1 . It provides a comprehensive way to resum big logarithms associated with collinear splittings into multiple jets 2 , thereby improving our appreciation of flight mechanics 3 .The basic idea behind SCET is that physical observables are explained by matrix elements featuring soft and / or collinear fields only 4 . These fields have nontrivial transformation qualities under boosts along the laser axis 5 .They allow us to separate hard interactions from soft light 6 . As a result , it becomes possible to deliberately factorize contributions to scattering amplitudes into hard functions describing short - distance dynamics 7 , 8 and semi - hard functions encoding information about the emission of deep gluons 9 .",
        "ori-fast-z-score": 0.5129891760425771,
        "water-fast-z-score": 6.874054958970533
    },
    {
        "original_text": "The Internet is growing at an unprecedented rate, and with it comes increasing demands on network applications to provide reliable services in spite of failures that can occur anywhere along their execution paths. In this work we present a language-based approach for improving robustness by automatically detecting errors in protocol implementations using static analysis techniques. We show how our technique can be used to detect common types of implementation errors such as buffer overflow vulnerabilities or incorrect handling of exceptional conditions. Our results demonstrate that our method achieves high precision (>90%) while maintaining reasonable recall (~60%). Finally, we evaluate the performance overheads associated with our approach and find them to be negligible compared to existing approaches based on dynamic testing. The Internet continues to grow at an unprecedented rate, leading to increased demand for reliable services despite failures occurring anywhere along application execution paths. This work presents a languagebased approach for improving robustness through automatic detection of errors in protocol implementations via static analysis techniques. We describe how our technique can be applied to detect common types of error including buffer overflows and improper treatment of exceptional cases. Our experimental evaluation shows that our approach has very high precision (> 90%), while still achieving reasonable recall (~ 60%). Finally, we measure the performance overheads of our approach and find them negligible when compared against other state-of-the-art approaches relying on dynamic testing.",
        "watermark_text": "The Internet is growing at an remarkable speed , and with it comes greater demands on internet solutions to provide quality services in spite of failures that can occur anywhere along their execution paths . In this research we present a language - based model for improving robustness by automatically detecting failure in protocol implementations using static analysis methods .We indicate how our technique can be used to identify typical types of implementation errors such as buffer overflow vulnerabilities or incomplete processing of exceptional conditions . Our results show that our technique achieves high clarity ( > 90 % ) while maintaining reasonable recall ( ~ 60 % ) .Finally , we assess the performance overheads associated with our approach and find them to be negligible compared to existing techniques based on dynamic monitoring . The Internet continues to expand at an remarkable speed , leading to greater need for good services despite failures occurring anything along application implementation paths .This research provides a languagebased approach for improving robustness through automatic diagnosis of errors in protocol implementations via static analysis methods . We define how our technique can be applied to identify specific kinds of mistake including buffer overflows and improper management of exceptional cases .Our research assessment demonstrates that our approach has very high clarity ( > 90 % ) , while nevertheless improving stable remember ( ~ 60 % ) . Finally , we measure the performance overheads of our approach and find them negligible when compared against other state - of - the - art methods using on dynamic analysis .",
        "ori-fast-z-score": 1.6296434287653334,
        "water-fast-z-score": 9.51908100741907
    },
    {
        "original_text": "Epsilon Aurigae is an F-type main sequence star with a mass of 1.8 M☉ and radius 2 R☉, located at about 40 light-years away in the constellation Auriga.  It has been known for many years to be surrounded by dusty material that obscures its visible spectrum.   The infrared excess emission detected around this object suggests it may have a circumstellar disk similar to those found around young stars such as T Tauri or Herbig Ae/Be stars.   In addition, there are indications that the system contains a close companion which could also contribute to the observed infrared excess emission.    We present new photometric observations obtained using the United Kingdom Infrared Telescope (UKIRT) on Mauna Kea over the period 1997-2001 covering wavelengths between 0.9-2.5 microns.  These data show significant variations in both the near-infrared fluxes and colours of the central source consistent with changes in the amount of dust surrounding the star.  This behaviour is very similar to what is seen in other pre-main-sequence systems where accretion onto the central star causes periodic increases in luminosity accompanied by increased levels of reddening due to heating of the surrounding dust grains.   Our results suggest that the current level of activity in the system is relatively low compared to previous epochs but we cannot rule out the possibility that the recent increase in brightness was caused by a short-lived burst of enhanced accretion rather than steady-state accretion occurring throughout our observing campaign.",
        "watermark_text": "Epsilon Aurigae is an F - class major sequence star with a mass of 1 . 8 M☉ and radius 2 R☉ , located at about 40 light - years away in the constellation Auriga . It has been known for thousands decades to be accompanied by dusty matter that obscures its visible spectrum .The infrared excess emission detected around this body suggests it could have a circumstellar disk comparable to those observed around young galaxies such as T Tauri or Herbig Ae / Be stars . In addition , there are indications that the system contains a close companion which could also contribute to the seen infrared excess emission .We report new photometric surveys obtained using the United Kingdom Infrared Telescope ( UKIRT ) on Mauna Kea over the period 1997 - 2001 covering wavelengths between 0 . 9 - 2 . 5 microns . These data demonstrate considerable variations in both the near - infrared fluxes and colours of the main source consistent with shifts in the quantity of dust surrounding the star .This behaviour is very related to what is seen in other pre - principal - sequence complexes where accretion onto the main star causes periodic increases in luminosity followed by increased levels of reddening due to heating of the nearby dust grains . Our results show that the present degree of intensity in the system is fairly lowest relative to previous epochs but we cannot leave out the idea that the recent rise in intensity was due by a brief - lived pulse of enhanced accretion instead than steady - phase accretion occurring throughout our observing mission .",
        "ori-fast-z-score": -0.8466487815452375,
        "water-fast-z-score": 6.6791181655235405
    },
    {
        "original_text": "We present the first measurement of the angular power spectrum of polarized dust emission at millimeter wavelengths, using data taken with the BICEP2 experiment in Antarctica during 2010 and 2011. We find that the polarization signal is consistent with predictions for thermal dust emission based on models constrained by Planck observations of temperature fluctuations. The amplitude of this signal is comparable to or larger than the expected gravitational lensing contribution over most multipole ranges probed here (l = 40-250). This result suggests that dust may be an important foreground contaminant for future CMB experiments targeting tensor modes. \n \n Keywords: Cosmic microwave background, Polarization, Dust emission, Gravitational waves, Inflationary cosmology \n \n Millimeter-wave polarimetry has been proposed as one method to detect primordial gravitational waves generated during inflation. However, it remains unclear whether polarized dust emission will limit our ability to extract such signals from current and upcoming CMB experiments. Here we report measurements made with the Bicep2/Keck Array collaboration s instrument operating at 150 GHz. These results are used to constrain the properties of interstellar dust grains through their effect on the polarized radiation they emit.",
        "watermark_text": "We present the first measurement of the angular power spectrum of polarized dust radiation at millimeter wavelengths , using data taken with the BICEP2 study in Antarctica during 2010 and 2011 . We see that the polarization frequency is compatible with predictions for thermal dust absorption based on models constrained by Planck measurements of temperature fluctuations .The amplitude of this signal is analogous to or larger than the expected gravitational lensing impact over most multipole distances probed here ( l = 40 - 250 ) . This result suggests that dust may be an important foreground contaminant for future CMB experiments targeting tensor modes .Keywords : Cosmic microwave background , Polarization , Dust absorption , Gravitational waves , Inflationary cosmology Millimeter - wave polarimetry has been proposed as one method to identify primordial gravitational waves generated during inflation . However , it remains unsure whether polarized dust absorption will limit our ability to extract such signals from recent and upcoming CMB experiments .Here we publish observations made with the Bicep2 / Keck Array collaboration s instrument operating at 150 GHz . These data are using to constrain the properties of interstellar dust grains through their effect on the polarized emission they emit .",
        "ori-fast-z-score": 1.9126494315742406,
        "water-fast-z-score": 6.260990336999411
    },
    {
        "original_text": "The collision between the Milky Way and its nearest neighbor, M31 (Andromeda), is predicted to occur in about 4 billion years.  This will be one of the most spectacular events ever witnessed by humans.   In this talk I will describe how we can use observations made with telescopes on Earth as well as space-based observatories such as Hubble Space Telescope to study these collisions and learn more about dark matter, galaxies, stars, black holes, and other cosmic phenomena that are part of our universe. I will also discuss some of my research projects related to studying galaxy mergers using data obtained at the W.M. Keck Observatory located on Mauna Kea, Hawaii. Finally, I ll share what it was like for me to work there during my summer internship last year. Keywords: Dark Matter, Galaxy merger, Black Hole, Cosmic Evolution, Cosmology, Astrophysics",
        "watermark_text": "The interaction between the Milky Way and its closest neighbor , M31 ( Andromeda ) , is predicted to event in about 4 billion years . This will be one of the most dramatic events ever experienced by humans .In this talk I will explain how we can using observations made with telescopes on Earth as well as space - based observatories such as Hubble Space Telescope to study these collisions and learn more about black material , galaxies , stars , white holes , and other cosmic phenomena that are part of our universe . I will also discuss some of my research projects related to researching star mergers using data received at the W . M .Keck Observatory located on Mauna Kea , Hawaii . Finally , I ll share what it was like for me to work there during my summer apprenticeship last year .Keywords : Dark Matter , Galaxy merger , Black Hole , Cosmic Evolution , Cosmology , Astrophysics",
        "ori-fast-z-score": 0.848528137423857,
        "water-fast-z-score": 4.808326112068523
    },
    {
        "original_text": "The Standard Model is in excellent agreement with all current experimental data, but it leaves many questions unanswered and fails to provide an explanation for some phenomena observed experimentally.  The muon magnetic moment anomaly provides one such example where there are significant discrepancies between theory predictions and experiment measurements that cannot be explained within the Standard Model framework.   In this talk I will present the physics case for the new g-2 experiment at Fermilab which aims to measure the anomalous magnetic moment of the muon more accurately than ever before by using a novel technique based on laser cooling and trapping techniques developed over recent years.   ... This talk presents the physics case for the proposed new measurement of the muon s anomalous magnetic moment at Fermilab. It describes how the use of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous experiments. A number of other topics related to the project are also discussed including the status of the R&D program towards the goal of measuring the muon magnetic moment to 0.5 parts per million accuracy.",
        "watermark_text": "The Standard Model is in good agreement with all recent experimental evidence , but it leaves many issues unanswered and fails to provide an reason for some phenomena observed experimentally . The muon magnetic point anomaly gives one such example where there are significant discrepancies between theoretical estimates and observation observations that cannot be described within the Standard Model framework .In this talk I will present the physics case for the new g - 2 study at Fermilab which aims to measure the anomalous magnetic motion of the muon more accurately than ever before by using a innovative method based on laser cooling and trapping techniques established over recent generations . . . .This discussion presents the physics case for the suggested novel measurement of the muon s anomalous magnetic force at Fermilab . It details how the using of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous study .A variety of other topics related to the project are also discussed including the status of the R & D program towards the objective of calculating the muon magnetic moment to 0 . 5 parts per million accuracy .",
        "ori-fast-z-score": 1.5096588248481377,
        "water-fast-z-score": 7.701031252562294
    },
    {
        "original_text": "We report scanning magnetoresistance microscopy (SMRM) measurements on an atom chip with gold wires and microtraps fabricated by focused ion beam milling. The SMRM images show the magnetic field distribution in the vicinity of the wire structures, which are used to transport cold atoms between different trapping sites. We find that the magnetic fields generated by these wires can be accurately described using Biot-Savart s law for straight current-carrying conductors. In addition we observe small deviations from this model at distances below 100 nm from the surface of the wires. These deviations may arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their surfaces. Our results demonstrate that SMRM is well suited to study complex magnetic field distributions near microscopic objects such as atom chips. Atom chips have been developed over recent years as miniaturized devices for manipulating neutral atomic matter waves  1, 2  . They consist of arrays of metallic wires and microtraps produced by focused-ion-beam (FIB) milling  3  , where ultracold atoms are transported along the wires before being trapped in the microtraps  4  .\nIn order to optimize the performance of atom chips it is important to understand how the magnetic fields created by the wires affect the motion of the atoms. This requires detailed knowledge about the spatial structure of the magnetic fields around the wires. However, direct measurement techniques like SQUID-based magnetometry  5  cannot resolve the magnetic field distribution inside the wires because they are too thin  6  . Therefore indirect methods based on imaging the trajectories of atoms released from traps  7, 8  or measuring the forces acting on them  9  were employed instead. Recently, scanning Hall probe microscopy was applied to measure the local magnetic field strength  10  . Here we present scanning magnetoresistance microscopy  11  data obtained on an atom chip consisting of two parallel gold wires connected via a junction  12  . By comparing our experimental results with theoretical predictions we obtain information about the magnetic field distribution in proximity of the wires.",
        "watermark_text": "We report scanning magnetoresistance microscopy ( SMRM ) observations on an atom chip with gold wires and microtraps fabricated by concentrated ion beam milling . The SMRM pictures show the magnetic field spread in the vicinity of the wire structures , which are applied to transport cold molecules between various trap places .We see that the magnetic waves generated by these cables can be correctly explained following Biot - Savart s law for straight current - transporting conductors . In addition we study small deviations from this description at distances below 100 nm from the surface of the wires .These deviations might arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their edges . Our results show that SMRM is well suited to study difficult magnetic field distributions near microscopic structures such as atom devices .Atom devices have been created over recent years as miniaturized devices for manipulating neutral atomic matter waves 1 , 2 . They comprise of arrays of metallic wires and microtraps produced by concentrated - ion - laser ( FIB ) processing 3 , where ultracold atoms are transported along the wires before being trapped in the microtraps 4 .In order to optimize the performance of atom devices it is important to realize how the magnetic waves created by the wires affect the movement of the atoms . This requires complete understanding about the spatial shape of the magnetic waves around the wires .However , direct detection methods like SQUID - based magnetometry 5 cannot determine the magnetic field spread inside the wires because they are too thin 6 . Therefore indirect approaches derived on observing the trajectories of atoms released from nets 7 , 8 or tracking the forces working on them 9 were utilized instead .Recently , scanning Hall probe microscopy was used to measure the local magnetic force force 10 . Here we present scan magnetoresistance microscopy 11 data derived on an molecular computer comprised of two connected gold wires coupled via a junction 12 .By matching our experimental results with theoretical predictions we obtain knowledge about the magnetic force density in proximity of the wires .",
        "ori-fast-z-score": -0.6923076923076923,
        "water-fast-z-score": 8.590007875090548
    },
    {
        "original_text": "We show that the Pioneer anomaly, which is an anomalous acceleration observed in radio tracking data for two spacecrafts launched by NASA (Pioneer 10/11), can be explained if we assume that there exists a conformal symmetry breaking effect at large distances from our solar system. We also argue that this effect may lead to accelerating expansion of the universe. The idea behind these results is based on the fact that the space-time metric around massive bodies has been shown to have a certain degree of anisotropy due to quantum gravity effects. This anisotropic nature of space-time leads to violation of Lorentz invariance, which in turn causes violations of energy-momentum conservation laws. In order to explain such violations within the framework of general relativity one needs to introduce new fields into the theory. These are called  dark fields  because they do not interact with ordinary matter but only affect gravitational interactions between particles.",
        "watermark_text": "We suggest that the Pioneer anomaly , which is an anomalous velocity observed in radio search information for two spacecrafts delivered by NASA ( Pioneer 10 / 11 ) , can be described if we suppose that there exists a conformal symmetry breaking phenomenon at large distances from our solar body . We additionally claim that this effect could lead to accelerating expansion of the universe .The idea behind these results is based on the fact that the space - time metric around large bodies has been shown to have a certain degree of anisotropy owing to quantum gravitational influences . This anisotropic nature of space - time leads to compliance of Lorentz invariance , which in turn causes breach of power - momentum conservation laws .In order to explain such defects within the framework of general relativity one needs to introduce different fields into the theory . These are called darkness fields because they do not interact with normal matter but only affect gravitational interactions between particles .",
        "ori-fast-z-score": 0.46499055497527714,
        "water-fast-z-score": 6.0448772146786025
    },
    {
        "original_text": "We report on an exceptional flare detected by Swift/XRT at t ~ 1 day post-burst, which lasted for more than 100 ks (~20 hr). The flare was followed up with observations performed with XMM-Newton/EPIC-pn between 2.5 days to 3 months post-burst. We find that this flare is best described as a superposition of two components: one component lasting about 50 ks peaking around 10^-3 s and another component lasting about 70 ks peaking around 5 x 10^4 s. Both components are well fitted by exponentially cut-off power-laws with photon indices Γ = -1.6 ± 0.1 and -2.2 ± 0.3 respectively. No significant spectral evolution during either of these flares has been found. This flare is among the most energetic ever seen in any gamma-ray burst.",
        "watermark_text": "We report on an exceptional burst detected by Swift / XRT at t ~ 1 day post - flare , which occurred for more than 100 ks ( ~ 20 hr ) . The flare was followed up with observations performed with XMM - Newton / EPIC - pn between 2 . 5 weeks to 3 weeks following - flare .We see that this flare is better depicted as a superposition of two parts : one element lasting about 50 ks peaking roughly 10 ^ - 3 s and another component lasting about 70 ks peaking roughly 5 x 10 ^ 4 s . Both components are better fitted by exponentially drop - off power - laws with photon indices Γ = - 1 . 6 ± 0 . 1 and - 2 . 2 ± 0 . 3 respectively . No notable spectral evolution during either of these flares has been determined .This burst is among the most intense yet shown in any gamma - ray flare .",
        "ori-fast-z-score": -0.8320502943378437,
        "water-fast-z-score": 4.900980294098034
    },
    {
        "original_text": "The question is not new, but it has been recently revived by the publication of two papers in Nature and Science that claim to show that biodiversity loss leads to ecosystem collapse.  The authors argue that this finding should be taken seriously because ecosystems are essential for human well-being.   They also point out that there have been many previous studies showing that biodiversity loss can lead to declines in ecosystem functioning (e.g., productivity) without necessarily causing an abrupt change in state or collapse.    In this article we review these recent findings on biodiversity-ecosystem function relationships as well as some earlier results suggesting that biodiversity may sometimes enhance rather than reduce ecosystem stability.  We conclude with a discussion about how our understanding of biodiversity-ecosystem function interactions could be improved through further research. Biodiversity loss is one of humanity s greatest challenges today. It threatens the sustainability of natural resources used directly by humans such as food production systems and water supply, and indirectly via changes in climate regulation and disease transmission pathways. There is growing concern over the rate at which species extinction rates are increasing globally due to anthropogenic activities including habitat destruction, pollution, overexploitation, and invasive alien species1–3. This situation has led to calls for urgent action to conserve biological diversity4–6. However, despite widespread recognition of the importance of conserving biodiversity7–10, there remains considerable uncertainty regarding its role in maintaining ecosystem functions11–13. A number of theoretical models suggest that biodiversity loss will cause reductions in ecosystem functioning14–16. For example, Tilman et al. (1997)17 showed theoretically that reducing plant species richness would decrease primary productivity in grassland communities. Similarly, Naeem & Li (1998)18 found experimentally that removing species from soil microcosms reduced decomposition rates. These predictions were supported by numerous subsequent empirical studies19–22.",
        "watermark_text": "The question is not current , but it has been lately revived by the publication of two papers in Nature and Science that argue to find that ecosystem failure leads to biodiversity breakdown . The authors argue that this determination should be taken seriously because ecosystems are essential for human well - being .They especially note out that there have been many earlier findings indicating that fauna loss can lead to declines in ecological functioning ( e . g . , output ) without necessarily creating an unexpected change in state or failure . In this page we review these recent results on biodiversity - ecological structure interactions as well as some earlier findings indicating that fauna might often improve instead than limit ecological stability .We end with a debate about how our appreciation of wildlife - ecological structure interactions might be improved through further studies . Biodiversity loss is one of humanity s worst problems currently .It damages the safety of natural assets used directly by humans such as feed production systems and water supply , and indirectly via alterations in climate control and illness transmission pathways . There is growing awareness over the pace at which species extinction frequencies are growing globally due to anthropogenic efforts including habitat damage , contamination , overexploitation , and invasive alien species1 – 3 .This problem has led to calls for urgent action to conserve biological diversity4 – 6 . However , despite widespread appreciation of the importance of conserving biodiversity7 – 10 , there exists considerable uncertainty regarding its function in maintaining ecosystem functions11 – 13 .A variety of theoretical theories indicate that biodiversity losing will cause reductions in ecological functioning14 – 16 . For instance , Tilman et al .( 1997 ) 17 showed theoretically that decreasing plant population richness would affect basic efficiency in prairie systems . Similarly , Naeem & Li ( 1998 ) 18 found experimentally that removing species from soil microcosms lowered oxidation rates .These predictions were endorsed by various subsequent empirical studies19 – 22 .",
        "ori-fast-z-score": -2.0893227278421693,
        "water-fast-z-score": 9.779496623899794
    },
    {
        "original_text": "We present the results for positronium ground state energy and wave function obtained by solving relativistic Schrödinger equation with Coulomb potential using variational method. The calculations are performed within two different approximations, namely nonrelativistic limit (NR) and first order perturbation theory (PT1). In NR approximation we use Hylleraas type trial wave functions which include spin dependent terms up to second power of inter particle distance. We also calculate the expectation value of kinetic energy operator using this wave function. In PT1 approximation we use Hyllraas type trial wave functions including spin dependent terms up to third power of inter particle distance alongwith one electron Dirac orbitals as basis set. Our calculated values of binding energies agree well with those reported earlier. \n\n\nThe author is grateful to Prof. S. K. Gupta, Director General, BARC, Mumbai for his encouragement during the course of work on this project.",
        "watermark_text": "We present the results for positronium ground state energy and wave function achieved by solving relativistic Schrödinger equation with Coulomb potential using variational technique . The calculations are performed within two different approximations , namely nonrelativistic limit ( NR ) and first order perturbation theory ( PT1 ) .In NR method we utilize Hylleraas kind trial wave functions which contain spin dependent terms up to second power of inter particle length . We also obtain the expectation value of kinetic power operator using this wave function .In PT1 approximation we utilize Hyllraas type trial wave parameters including spin dependent terms up to third power of inter quantum time alongwith one particle Dirac orbitals as basis set . Our measured measures of bound energies agree well with those published earlier .The author is thankful to Prof . S . K . Gupta , Director General , BARC , Mumbai for his encouragement during the course of research on this project .",
        "ori-fast-z-score": -0.9058216273156765,
        "water-fast-z-score": 3.396831102433787
    },
    {
        "original_text": "We introduce the notion of ``abstract factorials  , which are functions that can be used to represent and manipulate sets of integers in an efficient manner.  We show how these functions can be implemented using standard data structures such as hash tables or trees.   Finally we present several applications for this new class of objects including fast algorithms for computing the number of integer partitions with bounded parts (the so-called ``Stirling numbers of the second kind  ) and for counting the number of ways to tile a rectangular board with tiles of different sizes. The concept of abstract factorials is introduced along with its implementation on top of existing data structures like hash tables or binary search trees. Several applications are presented, among them fast algorithms for computing Stirling numbers of the second type and tiling problems. This work was supported by NSF grant CCF-0634420. 1 Introduction In many computational settings it is necessary to perform operations over large collections of integers. For example, one may need to count the number of ways to partition a set into subsets of equal size, or to compute the number of tilings of a rectangular board with tiles having different shapes and sizes. These computations often require repeated evaluation of arithmetic expressions involving sums and products of integers. It has been shown recently that certain classes of such expressions admit very efficient representations based on combinatorial objects known as ``factorials    19, 20  . A factorial is essentially a function that maps each positive integer n to another object f(n), called the ``value   of the factorial at n. Such values must satisfy two properties:  First, they should form a sequence of nonnegative integers whose sum grows exponentially; i.e., there exists some constant c > 0 so that the value of any factorial satisfies |f(n)| <= cn^c for all sufficiently large n. Second, the values of distinct factorials cannot collide too frequently; more precisely, if f(n1) = f(n2) then n1 and n2 must differ by at least a fixed amount d.",
        "watermark_text": "We introduce the notion of ` ` abstract factorials , which are functions that can be used to represent and manipulate collections of numbers in an efficient manner . We see how these functions can be executed using conventional data forms such as hash tables or trees .Finally we present many applications for this new category of objects including rapid algorithms for calculation the number of integer partitions with bounded parts ( the so - called ` ` Stirling numbers of the second kind ) and for counting the proportion of ways to mosaic a square floor with tiles of different sizes . The concept of abstract factorials is proposed along with its use on top of older data systems like hash tables or binary search forests .Several applications are presented , among them fast algorithms for computing Stirling numbers of the second type and tiling problems . This work was supported by NSF grant CCF - 0634420 .1 Introduction In many computational contexts it is required to conduct operations over large libraries of numbers . For instance , one may need to count the quantity of ways to split a setting into subsets of equal size , or to compute the number of tilings of a square board with tiles having various shapes and shapes .These computations usually require repeated evaluation of algebraic expressions involving amounts and products of numbers . It has been shown lately that particular categories of such functions accept very efficient representations based on combinatorial objects called as ` ` factorials 19 , 20 .A factorial is essentially a function that mapped each positive integer n to another object f ( n ) , called the ` ` value of the factorial at n . Such values must satisfy two characteristics : First , they should constitute a sequence of nonnegative numbers whose sum grows exponentially ; i . e . , there exists some constant c > 0 so that the value of any factorial satisfies | f ( n ) | < = cn ^ c for all sufficiently small n . Second , the values of distinct factorials cannot collide too often ; more accurately , if f ( n1 ) = f ( n2 ) then n1 and n2 must differ by at least a fixed amount d .",
        "ori-fast-z-score": -1.7905475715715027,
        "water-fast-z-score": 6.2092042056506624
    },
    {
        "original_text": "We study the ground state properties and excitations in the spin-1/2 Heisenberg antiferromagnet on the square lattice with nearest-neighbor interactions only, using exact diagonalization (ED) for small clusters up to 12 sites as well as density-matrix renormalization group (DMRG) calculations for larger systems. We find that the ground-state energy per site is lower than the classical value by about 0.25J, where J denotes the exchange coupling constant between neighboring spins. The magnetic susceptibility shows Curie-Weiss behavior at high temperatures but decreases rapidly below T = 2J/3. This indicates strong quantum fluctuations which are also reflected in the low-temperature dependence of the specific heat. In addition we observe an unusual peak structure in the spin-spin correlation function S(q). For q along the principal axes of the Brillouin zone this peak has its maximum at q = π while it shifts towards smaller values when approaching the diagonals.",
        "watermark_text": "We research the ground state properties and excitations in the spin - 1 / 2 Heisenberg antiferromagnet on the square lattice with nearest - neighbor interactions only , using accurate diagonalization ( ED ) for large clusters up to 12 locations as well as density - vector renormalization group ( DMRG ) estimates for larger systems . We see that the ground - state energy per site is lower than the classical value by about 0 . 25J , where J refers the transfer coupling constant between neighboring spins .The magnetic susceptibility displays Curie - Weiss behavior at high temperatures but decreases quickly below T = 2J / 3 . This implies deep quantum fluctuations which are also reflected in the small - temperature dependence of the specific heat .In addition we encounter an peculiar peak structure in the spin - spinning correlation function S ( q ) . For q along the primary axes of the Brillouin zone this peak has its highest at q = π while it shifts towards lesser values when approaching the diagonals .",
        "ori-fast-z-score": 0.4588314677411235,
        "water-fast-z-score": 5.505977612893481
    },
    {
        "original_text": "We study entanglement properties of the Toric Code model in two dimensions, which is defined on a square lattice with periodic boundary conditions. We consider both ground state and thermal states for this system. In particular we calculate the von Neumann entropy S(A) = −TrρA ln ρA associated to different regions A of the lattice as well as the mutual information I(A; B) between any pair of disjoint regions A and B. The results are compared against numerical simulations performed by means of Monte Carlo techniques. For the ground state it turns out that there exists an area law for the von Neumann entropy, i.e., S(A) ∝ L−d−1 where d denotes the dimension of region A and L its linear size. Moreover, we find that the mutual information decays exponentially fast when one moves away from the diagonal line joining the centers of the regions A and B. These findings agree very well with those obtained using exact methods based on Matrix Product States (MPS). Finally, we also show how these results can be used to obtain bounds on the topological entropy of the Toric Code.",
        "watermark_text": "We explore entanglement properties of the Toric Code model in two dimensions , which is characterized on a square lattice with periodic border conditions . We consider both ground state and thermal states for this process .In particular we estimate the von Neumann entropy S ( A ) = −TrρA ln ρA associated to different regions A of the lattice as well as the mutual information I ( A ; B ) between any pair of disjoint regions A and B . The results are compared against quantitative simulations conducted by means of Monte Carlo methods .For the ground state it turns out that there exists an area law for the von Neumann entropy , i . e . , S ( A ) [UNK] L−d−1 where d indicates the dimension of zone A and L its linear size . Moreover , we find that the mutual intelligence decays exponentially rapidly when one moves away from the diagonal line joining the centers of the regions A and B .These conclusions follow very best with those acquired using accurate methods based on Matrix Product States ( MPS ) . Finally , we also demonstrate how these results can be used to obtain limits on the topological entropy of the Toric Code .",
        "ori-fast-z-score": 0.5773502691896257,
        "water-fast-z-score": 5.114896104728048
    },
    {
        "original_text": "We study the distribution of the largest fragment in a fragmentation process, which is an important quantity for understanding how to optimize data transmission over networks and storage systems.  We show that this distribution can be approximated by a power law with exponent 1 + 1/(2 - p), where p is the probability that two fragments merge into one when they are adjacent on disk (the so-called  mergeability parameter ). This result explains why previous studies have found different exponents depending on whether or not merging was allowed. The approximation also allows us to derive closed-form expressions for other quantities such as the mean size of the largest fragment and its variance. Finally, we use our results to explain some recent experimental findings about file sizes in peer-to-peer systems. In many applications involving data transmission over networks and distributed storage systems, it is useful to understand how large the largest fragment will become during the course of the system s evolution. For example, if a network node has to transmit a certain amount of information within a given time limit, then knowing what fraction of the total data needs to be transmitted at any point in time may help improve performance. Similarly, in distributed storage systems, knowing the expected size of the largest fragment helps determine how much space each node should reserve for storing replicas.",
        "watermark_text": "We consider the distribution of the greatest fragment in a fragmentation process , which is an important quantity for knowledge how to optimize data communication over networks and storage systems . We see that this distribution can be approximated by a power law with exponent 1 + 1 / ( 2 - p ) , where p is the probability that two fragments mix into one when they are adjoining on disk ( the so - called mergeability coefficient ) .This result provides why previous research have discovered different exponents depending on whether or not merging was allowed . The method also enables us to derive closed - form expressions for other quantities such as the mean size of the greatest fragment and its variance .Finally , we utilize our findings to explain some latest empirical results about file sizes in peer - to - peer systems . In many applications using data communication over networks and distributed storage systems , it is important to realize how large the greatest fragment will become during the course of the program s evolution .For instance , if a network node has to transmit a certain quantity of information within a given time limitation , then understanding what fraction of the total data needs to be transmitted at any point in time might help increase efficiency . Similarly , in distributed storage systems , knowing the expected size of the greatest fragment allows determine how many space each node should reserve for storing replicas .",
        "ori-fast-z-score": 2.3312620206007844,
        "water-fast-z-score": 7.739789908394605
    },
    {
        "original_text": "We study the nonlinear dynamics of infectious diseases transfer in a population, where individuals are divided into three classes: susceptible (S), infected (I) and recovered/removed (R). We consider two different models: SIR model and SEIR model. In both cases we assume that there is no birth or death in the population. The main goal of this work is to investigate how the disease spreads through the population depending on its parameters. For example, if the infection rate is too high then it may lead to an epidemic outbreak. On the other hand, if the recovery rate is very large compared to the infection rate then the number of infectives will decrease rapidly. Finally, we show some numerical simulations which illustrate our results. \n \n Keywords: Nonlinear dynamics, infectious diseases, tuberculosis, SIR model, SEIR model. 1 Introduction \n \n Many mathematical models have been developed over time to describe the spread of infectious diseases within populations  1–3  . These models can be used as tools to understand the transmission mechanisms of these diseases and help public health authorities make decisions about prevention strategies  4  .\n \nIn particular, many researchers have studied the effects of vaccination programs  5–7  , quarantine  8, 9  and isolation  10, 11  on the evolution of epidemics. Other studies focus on the impact of environmental factors such as temperature  12, 13  , humidity  14, 15  and rainfall  16  on the propagation of pathogens. \nThe majority of existing works use deterministic models based on ordinary differential equations  17  . However, stochastic models  18, 19  and agent-based models  20, 21  also exist. Agent-based models allow us to take into account individual behaviors  22  while stochastic models provide more realistic descriptions of random events  23  . \n \nIn this article, we propose new mathematical models describing the spread of infectious diseases in a closed population. Our aim is to analyze the influence of various parameters on the behavior of the system. More specifically, we want to determine whether the disease will die out naturally or cause an epidemic outbreak. To do so, we first introduce the basic reproduction number R0  24  , which represents the average number",
        "watermark_text": "We explore the nonlinear dynamics of infectious infections transmission in a population , where persons are split into three categories : affected ( S ) , infected ( I ) and returned / deleted ( R ) . We consider two different models : SIR model and SEIR model .In both cases we suppose that there is no birth or dying in the population . The main goal of this research is to examine how the infection spreads through the population depending on its characteristics .For instance , if the infection rate is too big then it could lead to an outbreak outbreak . On the other hand , if the return speed is very huge compared to the infection rate then the quantity of infectives will decrease rapidly .Finally , we give some numerical simulations which illustrate our findings . Keywords : Nonlinear dynamics , infectious deaths , tuberculosis , SIR model , SEIR model .1 Introduction Many numerical models have been created over time to explain the spread of infectious infections within communities 1 – 3 . These methods can be used as tools to explain the spreading patterns of these diseases and help public medical institutions making decisions about prevention plans 4 .In particular , many scientists have researched the effects of vaccination programs 5 – 7 , quarantine 8 , 9 and isolation 10 , 11 on the evolution of epidemics . Other studies emphasis on the impact of environmental factors such as temperature 12 , 13 , moisture 14 , 15 and rainfall 16 on the propagation of pathogens .The majority of older studies use deterministic theories based on ordinary differential equations 17 . However , stochastic systems 18 , 19 and agent - based models 20 , 21 also exist .Agent - based methods help us to take into consideration individual behaviors 22 while stochastic theories provide more realistic descriptions of random events 23 . In this page , we propose additional mathematical models explaining the spread of infectious infections in a closed population .Our aim is to analyze the impact of several variables on the response of the system . More specifically , we want to estimate whether the infection will die out naturally or lead an outbreak outbreak .To do so , we first introduce the fundamental reproduction number R0 24 , which equals the average number",
        "ori-fast-z-score": -0.6172133998483676,
        "water-fast-z-score": 10.338324447460158
    },
    {
        "original_text": "We present new bolometer observations at 1.1mm wavelength for three clouds observed as part of the Spitzer Infrared Nearby Galaxies Survey (SINGS) legacy program. The data were obtained with the Bolocam instrument on the Caltech Submillimeter Observatory to study star formation across large scales within these clouds. We find that the dust continuum emission is well correlated with infrared extinction maps derived from 2MASS near-infrared photometry. Using this correlation we derive an average dust temperature of 14K over each cloud. This value agrees very well with previous estimates based on single-dish submillimeter measurements. We also use our data to estimate the total mass contained in dense cores identified by the Herschel Space Observatory s Photodetector Array Camera & Spectrometer (PACS). Our results show good agreement between the masses estimated using PACS 70 micron fluxes and those determined directly from the Bolocam data.",
        "watermark_text": "We report new bolometer observations at 1 . 1mm wavelength for three clouds observed as part of the Spitzer Infrared Nearby Galaxies Survey ( SINGS ) legacy program . The data were obtained with the Bolocam technique on the Caltech Submillimeter Observatory to study star formation across large scales within these clouds .We see that the dust continuum emission is well associated with infrared extinction maps obtained from 2MASS near - infrared photometry . Using this relationship we derive an estimated dust temperature of 14K over each dust .This value agrees very best with previous accounts based on single - dish submillimeter calculations . We additionally using our information to estimate the total mass found in dense cores identified by the Herschel Space Observatory s Photodetector Array Camera & Spectrometer ( PACS ) .Our results show good agreement between the masses predicted using PACS 70 micron fluxes and those estimated directly from the Bolocam data .",
        "ori-fast-z-score": 1.3858697343671664,
        "water-fast-z-score": 5.417490779798923
    },
    {
        "original_text": "The PVLAS collaboration has recently reported results on light-by-light scattering in vacuum, which are inconsistent with Standard Model predictions.  In this note we discuss possible interpretations of these data within the framework of quantum field theory and string theory. We argue that the most natural interpretation is to assume that the observed effect arises due to new particles coupling to photons via an effective dimension-8 operator. The required mass scale for such particles can be as low as 10 GeV or even lower if one assumes that they couple only weakly to ordinary matter. If confirmed by further experiments, these observations would have profound implications both for particle physics phenomenology and cosmological models. The PVLAS collaboration has recently announced their measurement of light-by-light scattering in vacuo  1  . This process violates parity conservation at tree level and thus cannot occur in the Standard Model (SM)  2  , but it could arise through loop effects  3  .\nIn particular, the authors report observing a signal consistent with the SM prediction  4  \nwhere G F = 1.1663787(6) × 10−5GeV−2 is Fermi s constant  5  , θ W ≈ 0.23 is the weak mixing angle  6  , m e is the electron mass, and M Pl ≡ 1/ √ 8πG N ≈ 2×10 18 GeV is the reduced Planck mass  7, 8  . However, the measured value of the cross section exceeds the theoretical expectation by more than three standard deviations,\nThis discrepancy between experiment and theory may indicate the presence of new physics beyond the SM  9  .",
        "watermark_text": "The PVLAS collaboration has recently announced findings on light - by - light diffusion in vacuum , which are inconsistent with Standard Model expectations . In this note we explain possible interpretations of these information within the framework of quantum field theory and string theory .We argue that the most natural interpretation is to assume that the seen effect arises owing to new objects coupling to photons via an efficient dimension - 8 operator . The expected mass scale for such particles can be as low as 10 GeV or even smaller if one assumes that they couple only weakly to normal matter .If confirmed by further studies , these observations would have profound implications both for electron physics phenomenology and cosmological predictions . The PVLAS collaboration has recently announced their observation of light - by - light diffusion in vacuo 1 .This process violates parity conservation at forest level and therefore cannot occur in the Standard Model ( SM ) 2 , but it could occur through ring effects 3 . In particular , the writers report studying a signal compatible with the SM prediction 4 where G F = 1 . 1663787 ( 6 ) × 10−5GeV−2 is Fermi s constant 5 , θ W ≈ 0 . 23 is the strong mixing angle 6 , m e is the electron mass , and M Pl ≡ 1 / √ 8πG N ≈ 2×10 18 GeV is the reduced Planck mass 7 , 8 .However , the measured value of the cross area approaches the theoretical expectation by more than three standard deviations , This discrepancy between experiment and theory could indicate the presence of new science beyond the SM 9 .",
        "ori-fast-z-score": -0.9534625892455924,
        "water-fast-z-score": 4.461042580036746
    },
    {
        "original_text": "We present the results of 3D radiation hydrodynamic simulations of accretion disks around black holes, performed with our new code RHD3DPHOTON. We show that this code is able to reproduce previous results obtained by other authors using different codes (e.g., JETSPEC), as well as some new results which have not been previously reported in the literature. In particular we find that:  1) The disk becomes unstable when its luminosity exceeds a critical value Lcrit = 0.1LEdd.  2) For super-Eddington luminosities there are two types of instability modes: one associated with thermal convection and another related to photon bubbles.  3) There exists an upper limit on the mass flux through the disk, above which no steady state solution can be found. This result has important implications for models of AGN feedback. 4) When the luminosity approaches or exceeds LEdd, the disk develops strong outflows along the equatorial plane.",
        "watermark_text": "We present the results of 3D radiation hydrodynamic simulations of accretion balls around black holes , conducted with our new code RHD3DPHOTON . We see that this code is could to repeat earlier findings obtained by other researchers using specific coding ( e . g . , JETSPEC ) , as well as some fresh results which have not been previously reported in the literature .In particular we find that : 1 ) The disk gets unstable when its luminosity exceeds a critical number Lcrit = 0 . 1LEdd . 2 ) For ultra - Eddington luminosities there are two forms of instability modes : one related with thermal convection and another linked to photon bubbles .3 ) There exists an upper maximum on the mass flux through the disk , above which no continuous state solution can be found . This result has useful consequences for models of AGN feedback .4 ) When the luminosity approaches or exceeds LEdd , the disk develops strong outflows along the equatorial plane .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.333493587335964
    },
    {
        "original_text": "We report on the X-ray properties of the young, nearby (d = 11 pc), low-mass binary system 2MASS J1101-2677AB discovered by Burgasser et al. (2007) . The primary component is an M8 dwarf with T eff ~ 2600 K and log g ~ 5.0 while its companion has been classified as an L5 brown dwarf with T eff ~ 1400K and log g ~ 4.2. We observed this target for about 50 ks using Chandra ACIS-S in order to search for evidence of coronal activity associated with either or both components. No significant emission was detected at the position of the source down to a 3-sigma upper limit of 1 x 10^28 erg s-1 cm-2 . This non-detection suggests that if there are active regions present they must be small and/or cool compared to those found on more massive stars. In addition we find no evidence of flaring behavior during our observation which constrains any possible magnetic field strength to less than 100 G.",
        "watermark_text": "We report on the X - ray characteristics of the early , neighboring ( d = 11 pc ) , low - weight binary system 2MASS J1101 - 2677AB discovered by Burgasser et al . ( 2007 ) .The main component is an M8 dwarf with T eff ~ 2600 K and log f ~ 5 . 0 while its companion has been classified as an L5 brown dwarf with T eff ~ 1400K and log f ~ 4 . 2 . We observed this target for about 50 ks using Chandra ACIS - S in order to search for indication of coronal interaction associated with either or both components .No much emitted was seen at the position of the source down to a 3 - sigma upper maximum of 1 x 10 ^ 28 erg s - 1 cm - 2 . This non - measurement indicates that if there are active regions present they must be small and / or cold relative to those observed on more massive stars .In addition we find no evidence of flaring behavior during our experiment which constrains any proposed magnetic force power to fewer than 100 G .",
        "ori-fast-z-score": -1.1338934190276817,
        "water-fast-z-score": 4.75
    },
    {
        "original_text": "The geochemical behavior of uranium (U) and thorium (Th), which are radioactive elements, is discussed in relation to their influence on the origin and evolution of the crust of earth as well as biological evolution.  The chemical properties of these two elements are similar; however, they have different physical characteristics that affect how they behave geologically.  Uranium has an atomic number of 92 with a half-life of 4.5 billion years while thorium has an atomic number of 90 with a half life of 1.4 billion years.   Both elements occur naturally throughout the Earth s crust but at varying concentrations depending upon the rock type.  They can be found in igneous rocks such as granite or basalt where they form minerals like uranite or thorite respectively.  These minerals may also contain other trace metals including lead, silver, gold, copper, zinc, arsenic, selenium, molybdenum, cadmium, mercury, bismuth, antimony, tellurium, cobalt, nickel, manganese, iron, vanadium, chromium, tungsten, titanium, zirconium, niobium, tantalum, hafnium, rhenium, osmium, iridium, platinum, palladium, rhodium, ruthenium, and iridium.  Uranium and thorium are also present in sedimentary rocks such as sandstone, shale, limestone, dolomite, gypsum, anhydrite, salt beds, and evaporites.  Sedimentary rocks are formed by weathering processes when water erodes...",
        "watermark_text": "The geochemical behavior of uranium ( U ) and thorium ( Th ) , which are radioactive elements , is mentioned in relation to their influence on the origin and evolution of the crust of earth as well as biological evolution . The chemical properties of these two compounds are comparable ; however , they have different biological traits that affect how they react geologically .Uranium has an atomic number of 92 with a half - life of 4 . 5 billion decades while thorium has an atomic number of 90 with a half lifetime of 1 . 4 billion decades . Both compounds occur readily throughout the Earth s crust but at different amounts depending upon the stone type .They can be found in igneous rocks such as granite or basalt where they create minerals like uranite or thorite respectively . These rocks could also contain other trace metals including lead , silver , gold , copper , zinc , arsenic , selenium , molybdenum , cadmium , mercury , bismuth , antimony , tellurium , cobalt , nickel , manganese , iron , vanadium , chromium , tungsten , titanium , zirconium , niobium , tantalum , hafnium , rhenium , osmium , iridium , platinum , palladium , rhodium , ruthenium , and iridium .Uranium and thorium are also occur in sedimentary formations such as sandstone , shale , marble , dolomite , gypsum , anhydrite , salt beds , and evaporites . Sedimentary stones are created by weathering reactions when water erodes . . .",
        "ori-fast-z-score": -1.4814874939752933,
        "water-fast-z-score": 4.216541329006604
    },
    {
        "original_text": "We present new multiwavelength observations of the debris disk surrounding the nearby star AU Mic, which is located at an age of ~10 Myr in the constellation Pictor (~25 pc). The system has been studied extensively over many decades using ground-based optical imaging techniques as well as space-based infrared photometry and spectroscopy. We have obtained high-resolution images with the Hubble Space Telescope s Wide Field Camera 3 (WFC3) near-infrared camera to study the dust distribution on small scales. These data are complemented by archival Spitzer Infrared Array Camera (IRAC), Herschel Photodetector Array Camera & Spectrometer (PACS), and Submillimeter Array (SMA) observations that probe larger spatial scales. Our results show that there exists a large amount of cold dust within 1 AU of the central star, but no evidence for warm dust emission beyond this radius. This suggests that the inner edge of the outer disk may be truncated due to tidal forces exerted by the planet candidate AU Mic b.",
        "watermark_text": "We report new multiwavelength studies of the rubble disk surrounding the nearby star AU Mic , which is situated at an age of ~ 10 Myr in the constellation Pictor ( ~ 25 pc ) . The system has been studied frequently over numerous years employing ground - based optical detection methods as well as space - based infrared photometry and spectroscopy .We have achieved high - resolution images with the Hubble Space Telescope s Wide Field Camera 3 ( WFC3 ) near - infrared camera to study the dust flow on small scales . These data are complemented by archival Spitzer Infrared Array Camera ( IRAC ) , Herschel Photodetector Array Camera & Spectrometer ( PACS ) , and Submillimeter Array ( SMA ) observations that examine bigger spatial scales .Our results show that there exists a large number of cold matter within 1 AU of the main star , but no evidence for cool dust absorption beyond this radius . This implies that the inner boundary of the inner disk might be truncated due to tidal factors exerted by the planet candidate AU Mic b .",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 4.935819976516537
    },
    {
        "original_text": "We present new observations with the Atacama Large Millimeter/submillimeter Array (ALMA) that reveal an extended region of disturbed molecular gas surrounding the active galactic nucleus (AGN) of NGC 5194, also known as M51a or Whirlpool Galaxy. The AGN is located at the center of this interacting galaxy pair and has been classified as a Seyfert 2 based on optical spectroscopy. We detect two prominent dust lanes extending to the north-east and south-west of the AGN along its minor axis. These are likely caused by tidal forces between the galaxies during their interaction. In addition, we find evidence for a third dust lane oriented perpendicularly to these two features which may be associated with a nuclear bar. Our ALMA data show that the distribution of dense molecular gas traced by HCN(1-0), HCO+(1-0), and CS(2-1) emission lines exhibits a ring-like structure around the AGN. This feature appears to have been shaped by powerful outflows driven by the AGN.",
        "watermark_text": "We present new experiments with the Atacama Large Millimeter / submillimeter Array ( ALMA ) that indicate an extended region of disturbed molecular gas surrounding the active galactic nucleus ( AGN ) of NGC 5194 , commonly known as M51a or Whirlpool Galaxy . The AGN is situated at the center of this interacting galaxy couple and has been classified as a Seyfert 2 using on optical spectroscopy .We detect two notable dust lanes stretching to the north - west and south - west of the AGN along its minor axis . These are likely caused by tidal forces between the galaxies during their interaction .In addition , we find proof for a third dust track focused perpendicularly to these two structures which may be correlated with a atomic bar . Our ALMA results show that the distribution of dense molecular vapor traced by HCN ( 1 - 0 ) , HCO + ( 1 - 0 ) , and CS ( 2 - 1 ) emission lines exhibits a ring - like structure around the AGN .This structure appears to have been shaped by massive outflows driven by the AGN .",
        "ori-fast-z-score": -0.48507125007266594,
        "water-fast-z-score": 4.85071250072666
    },
    {
        "original_text": "We report on the Swift satellite s rapid response to the gamma-ray burst (GRB) 060614, which was detected by the Burst Alert Telescope at 07:41:06 UT June 14 2006 and localized within 1 arcmin in less than 3 minutes. The X-ray telescope began observing the field about 10 s later; optical photometry started about 20 s after that. We find no evidence for any unusual behavior during or immediately following this event. In particular we do not see any indication of a supernova component associated with it as has been seen in some other events. However, our data show that there is a very bright fading source coincident with the position determined by Swift/XRT. This source shows clear signs of being dominated by emission lines characteristic of a Wolf-Rayet star. Our results are consistent with those reported previously using ground-based telescopes. \n \n Keywords: Gamma ray bursts, Afterglows",
        "watermark_text": "We report on the Swift satellite s rapid response to the gamma - ray burst ( GRB ) 060614 , which was detected by the Burst Alert Telescope at 07 : 41 : 06 UT June 14 2006 and localized within 1 arcmin in fewer than 3 seconds . The X - ray observatory commenced observing the field about 10 s later ; imaging photometry begun about 20 s after that .We see no evidence for any strange activity during or immediately surrounding this event . In particular we do not see any evidence of a supernova component involved with it as has been seen in some other events .However , our statistics demonstrate that there is a very bright fading source coincident with the orientation determined by Swift / XRT . This source shows clear signs of being dominated by radiation patterns characteristic of a Wolf - Rayet star .Our results are compatible with those confirmed previously used ground - based telescopes . Keywords : Gamma ray bursts , Afterglows",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.598123172175427
    },
    {
        "original_text": "We present an approach to predict the structural network organization in the cerebral cortex based on local node features, such as their position within the brain s surface or volume, and global topological characteristics. We use this method to study how different types of nodes are connected with each other across species (human, macaque monkey) and modalities (diffusion MRI tractography). Our results show that our model can accurately reproduce known patterns of cortico-cortical connections between areas, including those observed in humans but not yet described for monkeys. The proposed framework is general enough to be applied to any type of data where information about individual nodes  positions and pairwise interactions exists. This includes both anatomical and functional imaging datasets, which will allow us to investigate the relationship between structure and function at multiple scales. \n \n Introduction \n \n Brain connectomics aims to map all neuronal elements into a single comprehensive description of the human brain  1  . In recent years, advances in neuroimaging techniques have allowed researchers to obtain detailed maps of the brain s structural  2  , metabolic  3  , and functional  4  architecture. These new technologies provide unprecedented opportunities to understand how the brain works by studying its large-scale organization  5  .\n \nHowever, despite these advancements, there remains significant uncertainty regarding the precise nature of the relationships among neurons  6  . For example, it has been shown that some regions of the brain communicate more frequently than others  7-9 , while others exhibit higher levels of synchrony  10  . However, we still do not know whether these differences reflect specific wiring rules  11  or simply arise due to random fluctuations  12  . \n \n Here, we propose a novel computational framework to address this problem using machine learning methods  13  . Specifically, we aim to develop models capable of predicting the strength of connection between pairs of nodes given only information about their location and topology  14  . To achieve this goal, we first construct a set of training examples consisting of pairs of nodes whose interaction strengths are known  15  . Then, we train a classifier to learn the mapping between node features and edge weights  16  . Finally, we apply the trained model to unseen test cases  17  to infer unknown interactions",
        "watermark_text": "We present an way to predict the structural network structure in the brain cortex relying on local node characteristics , such as their placement within the brain s surface or volume , and global topological traits . We use this technology to study how various types of networks are connected with each other across taxa ( human , macaque mouse ) and modalities ( diffusion MRI tractography ) .Our results show that our model can accurately demonstrate established trends of cortico - cortical relationships between locations , notably those observed in humans but not already explained for monkeys . The proposed framework is basic enough to be applied to any type of data where information about individual nodes positions and pairwise relationships exists .This contains both anatomical and physiological imaging datasets , which will let us to examine the relationship between organization and function at multiple scales . Introduction Brain connectomics aims to map all neuronal components into a single comprehensive account of the human neural 1 .In recent years , advances in neuroimaging techniques have permitted investigators to obtain detailed maps of the brain s structural 2 , cellular 3 , and functional 4 architecture . These new approaches provide unprecedented possibilities to realize how the brain acts by examining its large - scale organization 5 .However , despite these advancements , there exists significant confusion regarding the exact nature of the relationships among neurons 6 . For instance , it has been shown that some regions of the brain communicate more frequently than others 7 - 9 , while many exhibit greater levels of synchrony 10 .However , we also do not understand whether these changes reflect specific wiring requirements 11 or simply arise due to random fluctuations 12 . Here , we propose a new computational framework to tackle this question using computer learning techniques 13 .Specifically , we attempt to develop models capable of predicting the strength of connection between pairs of nodes given only data about their direction and configuration 14 . To achieve this goal , we first build a setting of testing instances consisting of pairs of nodes whose interaction abilities are known 15 .Then , we train a classifier to teach the mapping between node characteristics and edge weights 16 . Finally , we apply the trained model to unseen test situations 17 to infer unknown interactions",
        "ori-fast-z-score": -0.9662823901213162,
        "water-fast-z-score": 9.092421632741246
    },
    {
        "original_text": "The electrochemical properties of materials are often strongly influenced by their phase transitions, which can be difficult to predict using conventional methods. In this work we present an approach that uses cyclic voltammetry (CV) data collected at different temperatures as input into a machine learning model in order to examine the thermodynamic stability of phases within a material system. We demonstrate our method on two prototypical systems - Fe3O4 and LiFePO4 - where it is able to successfully identify metastable phases and accurately predict equilibrium compositions across wide temperature ranges. The results showcase how CV-based approaches could provide new insights into complex chemical phenomena such as solid state reactions or battery degradation mechanisms. \n \n Introduction \n \n Many important physical processes occur through changes in crystal structure driven by thermal fluctuations  1  . These include transformations between polymorphs  2  , amorphous states  3  , and even liquid crystalline structures  4  . Such structural rearrangements have been shown to significantly affect the electrical  5  , optical  6  , magnetic  7  , mechanical  8  , and catalytic  9  properties of materials. As a result, understanding these transformations has become increasingly important for applications ranging from energy storage  10  to catalysis  11  .\n \nIn many cases, however, predicting the outcome of a transformation requires knowledge about its underlying free energies  12  . This information cannot always be obtained directly via experimentation due to kinetic barriers  13  , making computational techniques  14  particularly useful  15  . Unfortunately, most current theoretical models  16  require extensive parameterization  17  and/or detailed experimental characterization  18  before they can be applied effectively  19  . Moreover, while some recent studies  20  have demonstrated successes with deep neural networks  21  , there remains significant uncertainty regarding whether these approaches will generalize well  22  . \n \n Herein, we propose a novel approach based on cyclic voltammetry  23  that allows us to probe the thermodynamics of phase transformations without requiring any prior assumptions about the nature of the transition  24  . Our technique relies on collecting CV data over a range of temperatures  25  and then training a supervised  26  machine learning algorithm  27  to learn relationships between the measured currents  28  and the corresponding Gibbs free energies  29  . Once trained,...",
        "watermark_text": "The electrochemical qualities of substances are often strongly governed by their phase transitions , which can be challenging to predict using conventional methods . In this research we present an perspective that using cyclic voltammetry ( CV ) evidence generated at different temperatures as input into a machine learning model in order to examine the thermodynamic stability of phases within a solid system .We test our technique on two prototypical solutions - Fe3O4 and LiFePO4 - where it is ability to effectively identify metastable layers and correctly forecast stable compositions across wide temperature scales . The results display how CV - based methods could give innovative perspectives into complex chemical processes such as solid state reactions or battery reduction structures .Introduction Many significant physical processes arise through alterations in crystal composition driven by temperature fluctuations 1 . These include transformations between polymorphs 2 , amorphous states 3 , and even liquid crystalline structures 4 .Such structural rearrangements have been shown to significantly affect the electrical 5 , optical 6 , thermal 7 , thermal 8 , and catalytic 9 properties of substances . As a result , studying these transformations has become rapidly crucial for applications extending from power processing 10 to catalysis 11 .In many situations , however , predicting the result of a transformation requires knowledge about its underlying free energies 12 . This knowledge cannot often be obtained immediately via experimentation owing to kinetic limits 13 , making computational approaches 14 particularly useful 15 .Unfortunately , most current theoretical theories 16 require extensive parameterization 17 and / or extensive theoretical characterization 18 before they can be applied effectively 19 . Moreover , while some latest studies 20 have demonstrated successes with deep neural systems 21 , there exists significant doubt regarding whether these theories will generalize well 22 .Herein , we develop a innovative method built on cyclic voltammetry 23 that enables us to probe the thermodynamics of phase transformations without requiring any earlier predictions about the nature of the transfer 24 . Our practice relies on gathering CV measurements over a range of conditions 25 and then testing a controlled 26 machine learning algorithm 27 to find relationships between the measured currents 28 and the associated Gibbs free energies 29 .Once trained,...",
        "ori-fast-z-score": -1.6583123951777,
        "water-fast-z-score": 9.144286605749508
    },
    {
        "original_text": "We present the results on systematic uncertainties in determination of hadronic parameters using QCD Sum Rules (QSR). We consider two types of uncertainties: theoretical and experimental ones. Theoretical uncertainty is estimated by varying renormalization scale, Borel mass parameter and threshold value used to separate ground state contribution from excited states one. Experimental error comes mainly from errors in input values for quark masses and decay constants. In addition we take into account also dependence of final result on choice of interpolating current. For each type of uncertainty we calculate its effect separately as well as total uncertainty which includes all sources mentioned above. Finally we compare our results with those presented recently in literature. \n \n Keywords: Systematics, Uncertainty, Hadronic Parameters, QCD Sum Rules, Quark Masses, Decay Constants. 1 Introduction \n \n In this work we study systematic uncertainties in determination of various hadronic parameters like masses, decay constants etc., using QCD Sum Rules  1  . This method allows us to obtain information about properties of low-lying resonances starting from first principles - Quantum Chromodynamics (QCD)  2  , without any additional assumptions or models. It has been successfully applied to many different processes involving light quarks such as: pion form factor  3  , nucleon electromagnetic  4  and axial  5  form factors  6  , semileptonic decays  7, 8  , heavy-light mesons  9  , charmonium  10  and bottomonium  11  systems  12  .\n \nThe main idea behind QCD Sum Rules is that correlation function constructed out of currents corresponding to particular quantum numbers can be represented as dispersion relation over physical spectrum of particles contributing to it. Then, after applying double Borel transformation  13  , i.e. transforming both variables p^2 and q^2 simultaneously  14  , where p is momentum flowing through initial state and q is momentum transferred between initial and final states, one obtains so-called phenomenological representation  15  :",
        "watermark_text": "We report the conclusion on systematic uncertainties in calculation of hadronic variables using QCD Sum Rules ( QSR ) . We consider two forms of uncertainties : theoretical and experimental ones .Theoretical uncertainty is calculated by varying renormalization scale , Borel mass factor and threshold factor used to separate ground state contribution from excited states one . Experimental error results mainly from errors in input estimates for quark masses and decay constants .In addition we took into consideration also dependence of last result on choosing of interpolating current . For each type of uncertainty we estimate its impact independently as well as maximum uncertainty which includes all sources discussed above .Finally we compare our findings with those provided recently in literature . Keywords : Systematics , Uncertainty , Hadronic Parameters , QCD Sum Rules , Quark Masses , Decay Constants .1 Introduction In this project we study systematic uncertainties in calculation of several hadronic variables like masses , decay constants etc . , using QCD Sum Rules 1 . This method enables us to obtain knowledge about properties of low - lying resonances coming from first principles - Quantum Chromodynamics ( QCD ) 2 , without any additional constraints or models .It has been successfully introduced to many various reactions involving light quarks such as : pion form factor 3 , nucleon electromagnetic 4 and axial 5 form factors 6 , semileptonic decays 7 , 8 , heavy - heavy mesons 9 , charmonium 10 and bottomonium 11 systems 12 . The main idea behind QCD Sum Rules is that correlation function formed out of currents associated to specified quantum numbers can be described as dispersion relation over physical spectrum of molecules contributing to it .Then , after applying dual Borel transformation 13 , i . e . transforming both variables q ^ 2 and q ^ 2 simultaneously 14 , where p is momentum flowing through initial state and q is momentum transferred between initial and final states , one obtains so - called phenomenological representation 15 :",
        "ori-fast-z-score": -1.110664955031789,
        "water-fast-z-score": 6.236810901332355
    },
    {
        "original_text": "We present the sensitivity analysis of hybrid differential stereoscopy (HDS) in spectral imaging systems, which is based on the combination of two different techniques to obtain 3D information and has been recently proposed as an alternative method to conventional triangulation-based approaches.  We show that HDS can be considered as a generalization of other existing methods such as structured light or time-of-flight cameras by introducing additional degrees of freedom into the system design. In particular, we demonstrate how these parameters affect the performance of the technique when applied to hyperspectral data sets acquired with a pushbroom sensor mounted onto a satellite platform. Finally, we provide some guidelines about optimal values of those parameters depending on the application requirements. © 2014 Optical Society. Published by SPIE under the terms of the CC BY 3.0 license. The ability to acquire accurate three-dimensional (3D) information at high frame rates opens up new possibilities in many fields including remote sensing, medical diagnostics, surveillance, robotics, etc., where fast response times are required  1  . Among all available technologies, stereo vision stands out due to its low cost and simplicity  2  , but it suffers from inherent limitations related to the need of having textured surfaces within the scene  3  .\nIn recent years, several alternatives have emerged to overcome this problem  4  -  6  . One of them consists of using multiple images taken simultaneously from slightly displaced viewpoints  7  . This approach allows one to recover depth maps even if there is no texture in the scene  8  . However, the accuracy achieved depends strongly on the baseline between the camera positions  9  . Another possibility relies on the use of active illumination  10  , although this solution may not always be practical because of safety concerns  11  . A third option involves the use of coded patterns  12  , which require special hardware  13  .",
        "watermark_text": "We present the sensitivity analysis of hybrid differential stereoscopy ( HDS ) in spectral scan systems , which is based on the combination of two different methods to obtain 3D information and has been lately advocated as an additional method to conventional triangulation - based methods . We suggest that HDS can be regarded as a generalization of other existing techniques such as structured light or time - of - flight images by using new degrees of liberty into the system structure .In particular , we prove how these parameters affect the performance of the method when applied to hyperspectral information sets purchased with a pushbroom sensor deployed onto a spacecraft platform . Finally , we provide some guidelines about ideal values of those variables depending on the user requirements .© 2014 Optical Society . Published by SPIE under the terms of the CC BY 3 . 0 license .The able to acquire precise three - dimensional ( 3D ) details at high frame rates opens up new possibilities in different fields including distant detection , medical diagnostics , surveillance , robotics , etc . , where fast response periods are required 1 . Among all available systems , surround vision stands out due to its low cost and simplicity 2 , but it suffers from inherent limitations associated to the necessity of having textured edges within the picture 3 .In recent years , various options have arose to overcome this situation 4 - 6 . One of them consists of using multiple photos taken concurrently from somewhat displaced viewpoints 7 .This method enables one to extract depth mapping even if there is no texture in the image 8 . However , the accuracy achieved depends strongly on the baseline between the photographer positions 9 .Another possibility relies on the using of active light 10 , although this solution might not always be possible because of security concerns 11 . A third possibility requires the using of programmed zones 12 , which require extra architecture 13 .",
        "ori-fast-z-score": -0.6531972647421809,
        "water-fast-z-score": 9.748859854176581
    },
    {
        "original_text": "We present the first exact solution for the axisymmetric, stationary and force-free magnetic field structure around a rapidly-rotating neutron star with arbitrary inclination angle between its rotation and magnetic axes. The model is based on the assumption that the stellar surface is covered by a thin layer of plasma which corotates with the star at all latitudes. We show how this solution can be used to calculate the X-ray light curves produced by hot spots located at different latitudes above the stellar surface. In particular we demonstrate that the observed phase shifts between the peaks of soft X-rays (0.5-2 keV) and hard X-rays (2-10 keV), as well as their relative amplitudes are reproduced very accurately if one assumes that both emission components originate from two antipodal hot spots located near the magnetic poles. This result suggests that the observed X-ray pulsations may be caused by the rotational modulation of the local emissivity rather than by the Doppler effect due to bulk motion of matter within the emitting regions. \n \n Keywords: Force-free fields, Pulsar wind nebulae",
        "watermark_text": "We present the first accurate solution for the axisymmetric , stationary and force - free magnetic field system around a rapidly - spinning neutron galaxy with arbitrary orientation angle between its rotation and magnetic axes . The model is based on the assumption that the stellar surface is enclosed by a thin layer of liquid which corotates with the star at all latitudes .We see how this solution can be used to estimate the X - ray light patterns created by hot centers situated at different latitudes above the stellar surface . In particular we prove that the observed phase change between the peaks of hard X - rays ( 0 . 5 - 2 keV ) and hard X - rays ( 2 - 10 keV ) , as well as their relative amplitudes are reconstructed very correctly if one suppose that both emission parts originate from two antipodal hot areas situated near the magnetic poles .This result suggests that the seen X - ray pulsations may be caused by the rotational modulation of the local emissivity rather than by the Doppler impact owing to bulk movement of matter within the emitting regions . Keywords : Force - free forces , Pulsar wind nebulae",
        "ori-fast-z-score": -1.7457431218879391,
        "water-fast-z-score": 4.58257569495584
    },
    {
        "original_text": "We present multi-instrument observations of solar coronal plasma flows, which are obtained by combining data from the Extreme Ultraviolet Imager (EUVI) onboard STEREO-A and -B with those from the Helioseismic and Magnetic Imager (HMI), Atmospheric Imaging Assembly (AIA), and Interface Region Imaging Spectrograph (IRIS). The EUV images show that there is an apparent counterclockwise rotation of the bright loop-like structures at the limb between 2011 February 24 and March 1. We find that this rotation can be explained as a result of the differential motion between the two spacecrafts along their orbits around the Sun. By applying a cross-correlation technique to the EUVI 171 Å intensity profiles observed simultaneously by both satellites, we obtain the velocity field across the solar disk for each time step during the period under study. In addition, we use HMI magnetograms to calculate the magnetic flux density distribution over the solar surface. Our results reveal that the plasma flow patterns are closely related to the photospheric magnetic fields.",
        "watermark_text": "We present multi - instrument observations of solar coronal plasma flows , which are derived by combining information from the Extreme Ultraviolet Imager ( EUVI ) onboard STEREO - A and - B with those from the Helioseismic and Magnetic Imager ( HMI ) , Atmospheric Imaging Assembly ( AIA ) , and Interface Region Imaging Spectrograph ( IRIS ) . The EUV photos suggest that there is an apparent counterclockwise rotation of the faint loop - like structures at the limb between 2011 February 24 and March 1 .We see that this rotation can be described as a effect of the differential motion between the two spacecrafts along their orbits around the Sun . By applying a cross - correlation method to the EUVI 171 Å intensity profiles observed concurrently by both spacecraft , we obtain the velocity field across the planetary disk for each time step during the period under research .In addition , we utilize HMI magnetograms to estimate the magnetic flux concentration distribution over the sun surface . Our results show that the plasma circulation trends are tightly related to the photospheric magnetic waves .",
        "ori-fast-z-score": -0.12803687993289598,
        "water-fast-z-score": 5.249512077248736
    },
    {
        "original_text": "We present an algorithm for creating a hierarchical grid spatial index using images as the basis for its construction.  The algorithm is based on the observation that many real-world datasets are naturally represented by images, and can be used in conjunction with existing techniques such as R-tree or Quadtree to improve performance.   We show how our technique performs against these other methods through experiments conducted over synthetic data sets generated according to different distributions (uniform, normal, exponential) and sizes ranging between 1K and 100M points.   Our results demonstrate significant improvements in query response times when compared to traditional approaches. In this work we propose a new approach for building a spatial index which uses image processing algorithms to extract information about the dataset being indexed. This information is then used to build a hierarchy of grids whose leaf nodes contain pointers to individual objects within the dataset. These grids provide efficient access to all objects contained therein while also allowing fast queries across multiple grids at once.",
        "watermark_text": "We present an algorithm for producing a hierarchical grid spatial indicator employing images as the foundation for its design . The algorithm is based on the observation that several real - time datasets are naturally represented by pictures , and can be used in partnership with existing techniques such as R - tree or Quadtree to achieve performance .We see how our technique performs against these other methods through experiments conducted over synthetic information sets generated according to different distributions ( uniform , normal , exponential ) and dimensions ranging between 1K and 100M points . Our results show considerable improvements in query reply times when compared to conventional approaches .In this project we propose a new approach for building a spatial indicator which uses image processing algorithms to extract information about the dataset being indexed . This knowledge is then utilized to build a hierarchy of grids whose leaf nodes contain pointers to individual objects within the dataset .These grids allow faster entry to all items contained therein while also enabling rapid queries across multiple grids at once .",
        "ori-fast-z-score": 0.8728715609439696,
        "water-fast-z-score": 6.9829724875517565
    },
    {
        "original_text": "The aim of this talk is to present some recent results on the relation between integrability in quantum field theory, statistical mechanics or mathematical physics and the existence of special geometric structures (complex algebraic curves) which are associated with these models. \nWe will discuss how such geometries can be used for solving exactly certain physical problems by using techniques coming from algebraic geometry like Riemann surfaces, theta functions etc.. We will also explain why it seems that many interesting integrable models have an underlying structure of a Riemann surface. Finally we will give examples where this connection has been made explicit. The talk will include several new results obtained recently by the author together with his collaborators. This work was partially supported by the DFG under grant SFB/TR9. Integrable systems play an important role in various branches of mathematics as well as theoretical physics. In particular they appear naturally when studying solvable lattice models in statistical mechanics or quantum field theories. It turns out that there exists a deep relationship between integrability and the presence of special geometric structures called algebraic curves. These curves provide powerful tools for solving exactly certain physical questions via methods from algebraic geometry like Riemann Surfaces, Theta Functions,...",
        "watermark_text": "The goal of this talk is to provide some latest findings on the relation between integrability in quantum field theory , statistical mechanics or computational physics and the existence of unique geometric objects ( complex algebraic shapes ) which are identified with these models . We will explore how such geometries can be used for solving exactly certain physical problems by using techniques come from algebraic topology like Riemann surfaces , theta functions etc . . We will also explain why it appears that several interesting integrable models have an underlying composition of a Riemann surface .Finally we will provide descriptions where this link has been made explicit . The talk will include several current conclusions acquired previously by the writer together with his collaborators .This research was partially backed by the DFG under grant SFB / TR9 . Integrable systems play an important role in different areas of math as well as conceptual science .In particular they appear naturally when examining solvable lattice models in statistical mechanics or quantum field theories . It turns out that there exists a profound connection between integrability and the presence of unique geometric objects called algebraic curves .These curves provide potent tools for solving exactly certain physical problems via tools from algebraic topology like Riemann Surfaces , Theta Functions , . . .",
        "ori-fast-z-score": -0.5773502691896257,
        "water-fast-z-score": 6.543303050815759
    },
    {
        "original_text": "We study the effect of Rashba spin-orbit interaction on the spin Hall conductivity (SHC) for an interacting two-dimensional electron system with parabolic dispersion and Zeeman splitting in presence of a uniform external magnetic field applied normal to the plane of motion. We show that SHC is independent of temperature, chemical potential and strength of disorder provided the Fermi energy lies within the Zeeman gap. The results are obtained by using the Kubo formula combined with the self-consistent Born approximation. It has been shown recently that the spin current can be generated without any net charge flow when electrons move through a nonmagnetic material under the influence of spin-orbit coupling  1  . This phenomenon known as spin Hall effect was first predicted theoretically  2  , and later observed experimentally  3  .\nThe origin of this effect is due to the fact that the spin-orbit interaction causes a transverse force which deflects the trajectories of moving particles leading to a finite spin polarization at the edges  4  . In recent years there have been several theoretical studies devoted to understand various aspects of spin Hall effect  5  -  8  . However most of these works were done either in absence or weak magnetic fields where the Landau levels do not play significant role  9  . On the other hand it is well known that the Landau level quantization plays important role in determining many physical properties such as magnetoresistance  10  , optical absorption  11  etc., especially near the quantum limit  12  . Therefore it would be interesting to investigate how the Landau levels affect the spin Hall effect.",
        "watermark_text": "We explore the impact of Rashba spin - orbit interaction on the spin Hall conductivity ( SHC ) for an interacting two - dimensional electron structure with parabolic dispersion and Zeeman splitting in presence of a consistent external magnetic current applied normal to the plane of movement . We see that SHC is independent of temperature , chemical potential and strength of disorder provided the Fermi energy rests within the Zeeman gap .The results are derived by using the Kubo formula coupled with the self - stable Born algorithm . It has been shown lately that the spin current can be formed without any gross charge flow when nuclei move through a nonmagnetic material under the effects of spin - orbit bonding 1 .This phenomenon known as spin Hall phenomenon was first expected theoretically 2 , and later observed experimentally 3 . The origin of this effect is due to the fact that the spin - orbit interaction produces a transverse force which deflects the trajectories of moving particles leading to a finite spin polarization at the edges 4 .In past decades there have been numerous conceptual research devoted to study various parts of spin Hall phenomenon 5 - 8 . However most of these works were done either in absence or strong magnetic fields where the Landau concentrations do not play substantial role 9 .On the other hand it is well established that the Landau level quantization takes key importance in establishing much mechanical parameters such as magnetoresistance 10 , optical reflection 11 etc . , particularly near the quantum limit 12 . Therefore it would be interesting to examine how the Landau concentrations influenced the spin Hall phenomenon .",
        "ori-fast-z-score": -0.2683281572999747,
        "water-fast-z-score": 7.723027987151322
    },
    {
        "original_text": "We study how the properties of active galactic nuclei (AGNs) affect their radio morphologies, and in particular whether they can explain the observed difference between Fanaroff-Riley type I (FRI) and II (FRII). We use high-resolution hydrodynamical simulations to follow the growth of supermassive black holes (SMBHs), which are fed by cold gas accretion at rates that depend on the SMBH mass and its environment. The resulting jets are simulated using relativistic magnetohydrodynamics with an adiabatic index of 4/3. Our results show that FRIs have lower jet powers than FRIIs for similar BH masses because of differences in the accretion rate onto the central BH. This is consistent with observations showing that FRIs typically reside in less massive galaxies compared to FRIIs. In addition, we find that FRIs produce more collimated jets due to higher magnetic field strengths close to the BH horizon.",
        "watermark_text": "We research how the properties of active galactic nuclei ( AGNs ) impact their television morphologies , and in particular whether they can describe the seen distinction between Fanaroff - Riley type I ( FRI ) and II ( FRII ) . We use large - resolution hydrodynamical simulations to follow the formation of supermassive black holes ( SMBHs ) , which are fed by cold gas accretion at levels that rely on the SMBH weight and its climate .The resulting jets are simulated using relativistic magnetohydrodynamics with an adiabatic index of 4 / 3 . Our results show that FRIs have smaller jet powers than FRIIs for related BH masses because of differences in the accretion rate onto the main BH .This is consistent with observations indicating that FRIs typically exist in fewer large galaxies compared to FRIIs . In addition , we find that FRIs produce more collimated jets resulting to higher magnetic force abilities next to the BH horizon .",
        "ori-fast-z-score": -0.2581988897471611,
        "water-fast-z-score": 4.816989706290483
    },
    {
        "original_text": "The geometric frustration in the spin-1/2 triangular lattice is studied by means of neutron powder diffraction, magnetization measurements, specific heat data, and first-principles calculations for two new compounds Sr3NiRhO 6 and Sr 3 Ni Pt O 6 . The results show that both compounds are antiferromagnetic insulators with Néel temperatures TN = 5 K (Sr3NiRhO6) and T N = 7 K (Sr3NiPtO6). In addition to the expected collinear antiferromagnetism, we find evidence for noncollinear ordering in Sr3NiRhO6: First, there is an additional weak reflection at Q = 1.5 Å -1 , which can be explained as superlattice peak due to a small rhombohedral distortion; secondly, the temperature dependence of the ordered moment shows a kink around 2 K indicating a change of the order parameter below this temperature.",
        "watermark_text": "The geometric problems in the spin - 1 / 2 triangular lattice is studied by means of neutron dust diffraction , magnetization calculations , detailed heat observations , and first - principles measurements for two new compounds Sr3NiRhO 6 and Sr 3 Ni Pt O 6 . The results show that both salts are antiferromagnetic insulators with Néel pressures TN = 5 K ( Sr3NiRhO6 ) and T N = 7 K ( Sr3NiPtO6 ) .In addition to the expected collinear antiferromagnetism , we find proof for noncollinear ordering in Sr3NiRhO6 : First , there is an additional strong absorption at Q = 1 . 5 Å - 1 , which can be understood as superlattice peak thanks to a small rhombohedral distortion ; secondly , the temperature dependence of the ordered moment displays a kink around 2 K indicating a change of the order parameter below this heat .",
        "ori-fast-z-score": 0.5773502691896258,
        "water-fast-z-score": 5.10527470242631
    },
    {
        "original_text": "We present new observations of the nuclear region in the nearby radio galaxy NGC315, made using the Chandra X-ray Observatory (CXO) and the Very Large Array (VLA). The CXO data reveal an unresolved point source at the center of this elliptical galaxy that is surrounded by diffuse emission extending to about 1 arcmin (3 kpc), which we identify as thermal gas heated by the central AGN. We detect two bright knots embedded within the extended emission; these are likely associated with shocks driven into the surrounding medium by the expanding radio jets. Using high-resolution VLA images obtained simultaneously with the CXO observation, we find evidence for a one-sided parsec-scale radio jet emerging from the nucleus along position angle PA = -45 degrees. This jet has been previously detected on larger scales out to several kiloparsecs. In addition, there appears to be another fainter component of the radio jet located further south-west than the main knot.",
        "watermark_text": "We present new images of the atomic region in the nearby radio star NGC315 , made using the Chandra X - ray Observatory ( CXO ) and the Very Large Array ( VLA ) . The CXO data reveal an unresolved point origin at the center of this elliptical galaxy that is flanked by diffuse emission stretching to about 1 arcmin ( 3 kpc ) , which we identify as heat gas cooled by the main AGN .We detect two faint knots embedded within the extended emission ; these are likely correlated with shocks driven into the nearby medium by the increasing radio jets . Using long - resolution VLA images obtained simultaneously with the CXO observation , we find proof for a one - sided parsec - scale radio jet developing from the nucleus along position angle PA = - 45 degrees .This jet has been previously observed on larger scales out to several kiloparsecs . In addition , there seems to be another fainter component of the radio jet located further west - west than the main knot .",
        "ori-fast-z-score": -0.47140452079103173,
        "water-fast-z-score": 4.391092135317257
    },
    {
        "original_text": "We present near-infrared (NIR) spectroscopy obtained with Subaru/HDS on day +16 after explosion for the peculiar type Ib supernova SN2006jc, which shows prominent dust formation in its dense shell. The NIR spectrum is dominated by strong P-Cygni profiles of H I Balmer lines and Fe II multiplets at 4233-4245 Å . We find that these features are well reproduced by our non-LTE model calculations assuming an electron density ne = 1 x 10^9 cm-3 , temperature Te = 5500 K , and mass-loss rate oḟ M = 2 x 10^-6 M_sun/yr. In addition to the above mentioned features, we detect weak but significant He II 4686 emission line feature in the red wing of the Hα profile. This suggests that there may be some contribution from helium recombination radiation to the observed fluxes of hydrogenic lines.",
        "watermark_text": "We use near - infrared ( NIR ) spectroscopy acquired with Subaru / HDS on week + 16 after explosion for the unusual type Ib supernova SN2006jc , which shows significant dust form in its dense shell . The NIR spectrum is dominated by strong P - Cygni profiles of H I Balmer bands and Fe II multiplets at 4233 - 4245 Å .We see that these characteristics are better illustrated by our non - LTE model calculations assuming an electron concentration ne = 1 x 10 ^ 9 centimeters - 3 , temperature Te = 5500 K , and mass - loss rate [UNK] M = 2 x 10 ^ - 6 M _ sun / yr . In addition to the above mentioned properties , we perceive slight but significant He II 4686 absorption line feature in the red wing of the Hα profile .This implies that there may be some influence from helium recombination emission to the seen fluxes of hydrogenic lines .",
        "ori-fast-z-score": -1.4832396974191326,
        "water-fast-z-score": 4.08248290463863
    },
    {
        "original_text": "We present an algorithm for finding galaxy clusters using only photometric redshifts and no spectroscopic information, based on identifying overdensities of galaxies with similar colours. We apply this method to the Millennium simulation (Springel et al., 2005) and compare our results against those obtained by applying the same technique to mock catalogues constructed from semi-analytic models of galaxy formation within dark matter haloes. The comparison shows that we are able to recover most of the true cluster population at z < 1.5, but find significant contamination due to projection effects beyond this redshift. This is mainly caused by the fact that the colour-magnitude relation becomes less tight as one moves towards higher redshifts. Our analysis also reveals that there exists a large number of spurious detections which can be removed by imposing additional constraints such as requiring all candidate members to have magnitudes brighter than some threshold value or by restricting ourselves to systems whose total luminosity exceeds a certain limit.",
        "watermark_text": "We present an algorithm for finding galaxy galaxies using only photometric redshifts and no spectroscopic information , relying on establishing overdensities of clusters with similar colours . We use this algorithm to the Millennium scenario ( Springel et al . , 2005 ) and compare our findings against those achieved by using the same technique to mock catalogues generated from semi - analytic models of galaxy formation within dark matter haloes .The comparison shows that we are able to regain most of the true cluster population at z < 1 . 5 , but discover considerable contamination owing to projection influences beyond this redshift . This is mainly caused by the fact that the colour - magnitude correspondence gets less tight as one moves towards higher redshifts .Our study also reveals that there exists a large number of spurious detections which can be removed by imposing extra constraints such as requiring all candidate members to have magnitudes brighter than some threshold value or by restricting ourselves to systems whose total luminosity exceeds a certain limitation .",
        "ori-fast-z-score": 0.6974858324629157,
        "water-fast-z-score": 6.0448772146786025
    },
    {
        "original_text": "We present new spectroscopic observations for nine cataclysmic variable stars (CVs) obtained with the HIRES spectrograph on Keck I telescope in Hawaii, and compare them to previous results. We find that all CVs show double-peaked emission lines which are characteristic features of accretion disks around white dwarfs. The line profiles change dramatically during outburst phases when mass transfer rates increase by several orders of magnitude compared to quiescent states. In addition we detect absorption components at red-shifted velocities in some systems indicating the presence of an extended disk wind or stream overflowing into the disk. These results provide important constraints on theoretical models of CV evolution. \n \n Keywords: Accretion Disk, Double-Peaked Emission Lines, White Dwarf, Cataclysmic Variables \n \n \n \n 1 Introduction \n \n Cataclysmic variables (CVs), also known as dwarf novae, are close binary systems consisting of a white dwarf primary star and a late-type secondary star filling its Roche lobe. Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it forms an accretion disk surrounding the compact object. This process leads to periodic outbursts caused by thermal instabilities in the accretion disk resulting in dramatic changes in luminosity over time scales ranging from hours up to years  1  . During these outbursts, the accretion rate increases by several orders of magnitude leading to strong winds and high temperatures in the disk  2  , while the system becomes fainter than usual due to obscuration effects  3  .\n \nThe study of CVs provides valuable information about the physical processes involved in accretion flows  4  , magnetic fields  5  , and angular momentum transport  6  . Furthermore, they can be used as distance indicators  7, 8  and probes of galactic structure  9  . \n \n 2 Observations & Data Reduction \n \n Our sample consists of 9 CVs observed between 2004 and 2007 using the High Resolution Echelle Spectrometer (HIRES)  10  mounted on the 10 m Keck I telescope located on Mauna Kea",
        "watermark_text": "We introduce novel spectroscopic observations for nine cataclysmic variable stars ( CVs ) obtained with the HIRES spectrograph on Keck I telescope in Hawaii , and compare them to previous findings . We see that all CVs show dual - peaked emission lines which are peculiar characteristics of accretion disks around white dwarfs .The line profiles change dramatically during outburst phases when mass transfer rates increase by many orders of magnitude compared to quiescent states . In addition we perceive absorption elements at red - shifted velocities in some systems suggesting the presence of an extended disk dust or stream overflowing into the disk .These conclusions provide important restrictions on theoretical theories of CV evolution . Keywords : Accretion Disk , Double - Peaked Emission Lines , White Dwarf , Cataclysmic Variables 1 Introduction Cataclysmic variables ( CVs ) , sometimes called as dwarf novae , are open binary complexes consisting of a black dwarf secondary star and a early - class secondary star occupying its Roche lobe .Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it creates an accretion disk surrounding the compact body . This process results to periodic outbursts caused by temperature instabilities in the accretion disk resulting in spectacular changes in luminosity over time ranges ranging from hours up to days 1 .During these outbursts , the accretion rate grows by many orders of magnitude resulting to powerful storms and rising heat in the disk 2 , while the system gets fainter than usual thanks to obscuration effects 3 . The investigation of CVs provides valuable info about the physical processes responsible in accretion movements 4 , magnetic waves 5 , and spatial velocity transport 6 .Furthermore , they can be used as distance indicators 7 , 8 and probes of galactic structure 9 . 2 Observations & Data Reduction Our specimen consists of 9 CVs seen between 2004 and 2007 utilizing the High Resolution Echelle Spectrometer ( HIRES ) 10 installed on the 10 m Keck I telescope located on Mauna Kea",
        "ori-fast-z-score": -1.0215078369104984,
        "water-fast-z-score": 8.057794831959724
    },
    {
        "original_text": "We present an approach for self-organization in networks based on multi-agent systems (MAS). The proposed method is applied to two different networks: one with mobile nodes and another with static ones, both using IEEE 802.11b as their communication protocol. In this work we use agents that are able to move between neighboring nodes, which allows them to collect information about the state of each node. This information can be used by other agents to make decisions such as: moving to new positions or changing the transmission power level. We have implemented our proposal in NS-2 simulator and compared it against three well-known algorithms: OLSR, AODV and DSR. Our results show that MAS outperforms these protocols in terms of: packet delivery ratio, end-to-end delay and energy consumption. Keywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio",
        "watermark_text": "We present an approach for self - organization in networks based on multi - agent systems ( MAS ) . The proposed approach is applied to two different organizations : one with mobile connections and another with static ones , both using IEEE 802 . 11b as their networking protocol .In this study we using agents that are able to move between neighboring nodes , which allows them to collect data about the state of each node . This knowledge can be used by other agents to make choices such as : moving to new positions or altering the transmission power level .We have incorporated our proposal in NS - 2 simulator and compared it against three well - famous method : OLSR , AODV and DSR . Our results show that MAS outperforms these protocols in terms of : message delivery ratio , end - to - end delay and energy consumption .Keywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio",
        "ori-fast-z-score": 1.6378460497066512,
        "water-fast-z-score": 4.913538149119954
    },
    {
        "original_text": "We present the first 3D kinematic analysis of an isolated supergranule in the photosphere using high-resolution observations obtained with Hinode/SOT and SDO/HMI instruments. The results show that the observed supergranule is characterized by a strong upflow at its center, surrounded by weaker downflows. We find that the horizontal flow pattern consists of two counter-rotating cells which are connected to each other through a narrow channel along their common boundary. This structure resembles the magnetic topology of a bipolar sunspot pair. In addition we observe a small-scale vortex-like feature located on one side of the central upflow region. Our study shows that the observed supergranulation pattern can be explained as a result of convective motions driven by the solar differential rotation. Keywords: Solar activity, Sunspots, Photometry, Magnetism, Granulation, Convection, Dynamo theory, Magnetic fields",
        "watermark_text": "We present the first 3D kinematic analysis of an exposed supergranule in the photosphere using high - resolution measurements obtained with Hinode / SOT and SDO / HMI instruments . The results show that the known supergranule is characterized by a powerful upflow at its core , flanked by softer downflows .We see that the horizontal flow pattern consists of two counter - spinning chambers which are connected to each other through a thin channel along their common boundary . This structure follows the magnetic topology of a bipolar sunspot couple .In addition we study a small - scale vortex - like feature centered on one end of the main upflow center . Our study shows that the seen supergranulation rhythm can be described as a outcome of convective movements driven by the solar differential rotation .Keywords : Solar influence , Sunspots , Photometry , Magnetism , Granulation , Convection , Dynamo theory , Magnetic fields",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 5.858500994137074
    },
    {
        "original_text": "We present an analytical model for the growth, radial drift and fragmentation of dust grains in protoplanetary disks that evolve under the combined effects of viscous accretion onto the central star and photoevaporation by external radiation fields. We show how these processes affect the evolution of grain size distributions as well as their spatial distribution within the disk. In particular we find that: (i) The maximum grain sizes are limited to values between 1 mm and 10 cm depending on the strength of the stellar UV field. (ii) Grains grow faster at larger distances from the star due to lower gas densities and higher temperatures. (iii) Fragmentation is more efficient closer to the star where the local pressure maxima lead to enhanced collisional velocities.  These results have important implications for planet formation scenarios since they suggest that planetesimals can form only close to the star while large bodies such as asteroids or comets may be able to form farther out in the disk.",
        "watermark_text": "We present an analytical theory for the development , radial drift and fragmentation of dust grains in protoplanetary disks that develop under the combined influences of viscous accretion onto the main star and photoevaporation by external emission fields . We see how these mechanisms affect the evolution of grain length distributions as well as their temporal distribution within the disk .In particular we find that : ( i ) The maximum grain sizes are limited to values between 1 mm and 10 mm depending on the strength of the stellar UV field . ( ii ) Grains grow better at larger distances from the star due to higher gas densities and larger temperatures .( iii ) Fragmentation is more efficient closer to the star where the local pressure maxima lead to greater collisional velocities . These conclusions have important implications for planet development schemes since they show that planetesimals can form only close to the star while huge bodies such as asteroids or comets might be possible to form farther out in the disk .",
        "ori-fast-z-score": -0.11547005383792514,
        "water-fast-z-score": 4.50333209967908
    },
    {
        "original_text": "The hypercube model is used to describe the evolution of life in terms of its complexity, speed, and stability.  The model shows that there are limits imposed by protein stability on how complex an organism can be as well as how fast it evolves molecularly.   It also suggests that these limits may have been reached during the Cambrian explosion about 540 million years ago when most animal phyla appeared simultaneously. This article describes the hypercube model and presents some examples of how it has been applied to understand evolutionary processes at different levels of organization ranging from genes to ecosystems. In this article we present a new approach for understanding the evolution of life based on the concept of the hypercube (1). We argue that the evolution of life can be described in three dimensions: complexity, speed, and stabilization. These three dimensions represent key aspects of biological systems that evolve over time. For example, organisms become more complex through the addition of new components such as organs or tissues; they evolve faster if their genetic variation increases; and they become more stable if mutations do not cause them to die prematurely. Figure 1 illustrates our view of the evolution of life using the hypercube model. Each vertex represents one possible state of living matter with respect to each dimension. As shown in Fig. 1A , the number of vertices along any given axis depends on the level of resolution chosen. At higher resolutions, the number of states increases exponentially. For instance, if we consider only two states per dimension—simple versus complex, slow versus fast, unstable versus stable—the total number of possible combinations would be four (2 x 2 x 2 = 8), which corresponds to eight types of living matter. However, if we increase the resolution so that we now include four states per dimension—very simple versus simple versus complex versus very complex, very slow versus slow versus fast versus very fast,...",
        "watermark_text": "The hypercube concept is utilized to explain the evolution of life in terms of its complexity , speed , and stability . The model shows that there are restrictions imposed by molecular stability on how difficult an organism can be as well as how fast it evolves molecularly .It additionally indicates that these limits might have been achieved during the Cambrian explosion about 540 million months previously when most animal phyla appeared simultaneously . This paragraph explains the hypercube model and provides some examples of how it has been used to explain evolutionary processes at different levels of organization ranging from genes to environments .In this article we present a new approach for studying the evolution of life based on the idea of the hypercube ( 1 ) . We argue that the evolution of life can be described in three dimensions : complexity , speed , and stabilization .These three dimensions represent crucial factors of biological systems that develop over time . For instance , animals get more sophisticated through the adding of new components such as bodies or tissues ; they develop faster if their genetic variation rises ; and they become more stable if mutations do not cause them to death prematurely .Figure 1 illustrates our view of the evolution of life using the hypercube view . Each vertex depicts one possible state of living life with regard to each dimension .As seen in Fig . 1A , the number of vertices along any certain axis determines on the level of resolution picked .At higher resolutions , the quantity of states varies exponentially . For instance , if we consider only two states per dimension — simple versus compound , slow versus fast , unstable versus stable — the total number of possible combinations may be four ( 2 x 2 x 2 = 8 ) , which equals to eight types of living matter .However , if we increase the resolution so that we now include four states per dimension — very simple versus easy versus compound versus very difficult , very slow versus slow versus fast versus very quickly , . . .",
        "ori-fast-z-score": 0.31622776601683794,
        "water-fast-z-score": 7.329426778023636
    },
    {
        "original_text": "We present the results of an unbiased survey for compact HII regions in the southern Galactic plane using data obtained with the Australia Telescope Compact Array (ATCA). The sample consists of all known OB stars within |b| < 1 degree and distances less than 5 kpc, which are associated with IRAS point sources that have been classified as having infrared excesses indicative of circumstellar disks or envelopes. We detect over 100 new compact HII regions at frequencies between 2.1 GHz and 6.0 GHz. These objects range in size from 0.01 pc to 0.5 pc and their luminosities vary by more than four orders of magnitude. Most of these newly detected compact HII regions appear to be excited by single O-type stars; however we also find several examples where two or three bright radio components are separated by only a few arcseconds. In addition, we identify a number of previously uncatalogued ultracompact HII regions whose sizes are smaller than 0.01 pc.",
        "watermark_text": "We present the conclusion of an unbiased survey for compact HII locations in the southern Galactic jet using data acquired with the Australia Telescope Compact Array ( ATCA ) . The sample consists of all known OB stars within | b | < 1 degree and altitudes lower than 5 kpc , which are identified with IRAS point bodies that have been classified as having infrared excesses indicative of circumstellar disks or envelopes .We detect over 100 new compact HII zones at speeds between 2 . 1 GHz and 6 . 0 GHz . These objects range in height from 0 . 01 pc to 0 . 5 pc and their luminosities vary by more than four orders of magnitude .Most of these newly observed compact HII regions seem to be excited by single O - class stars ; however we also find various instances where two or three dark radio components are split by only a few arcseconds . In addition , we identify a number of previously uncatalogued ultracompact HII zones whose sizes are smaller than 0 . 01 pc .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.993438317382943
    },
    {
        "original_text": "We present new results on modelling the effects of clumps in stellar winds on their observed linear and circular polarization signatures, using Monte Carlo radiative transfer simulations. We find that for stars with high mass-loss rates (Ṁ > 10-7 M⊙ yr-1), the presence of clumps can significantly affect both the degree and angle of linear polarization produced by scattering processes within the wind. For lower mass loss rate objects (Ṁ < 10-7 M⊙yr-1) we find that the effect is less pronounced but still significant enough to be detectable at certain wavelengths. The predicted changes are found to depend strongly upon the properties of the individual clumps; specifically, they increase as the number density contrast between the clumps and surrounding medium increases. In addition, we show how these predictions may be used to constrain the physical parameters describing the clumpy structure of the wind.  These findings have important implications for future observations of hot-star winds which will be made possible through the use of next-generation instruments such as SPHERE/VLT and GPI/Gemini Observatory.",
        "watermark_text": "We report new data on modelling the effects of clumps in stellar winds on their observed linear and circular polarization signatures , using Monte Carlo radiative transfer simulations . We see that for stellar with high mass - loss rates ( [UNK] > 10 - 7 [UNK] yr - 1 ) , the presence of clumps can significantly affect both the degree and angle of linear polarization produced by scattering mechanisms within the wind .For lower mass loss temperature objects ( [UNK] < 10 - 7 [UNK] - 1 ) we find that the impact is less noticeable but still significant enough to be detectable at certain wavelengths . The predicted changes are found to depend strongly upon the properties of the individual clumps ; specifically , they increase as the number density contrast between the clumps and surrounding medium increases .In addition , we show how these predictions may be used to constrain the physical factors describing the clumpy composition of the wind . These insights have important implications for future discoveries of bright - star winds which will be made possible through the using of next - generation satellites such as SPHERE / VLT and GPI / Gemini Observatory .",
        "ori-fast-z-score": 0.6546536707079772,
        "water-fast-z-score": 3.709704134011871
    },
    {
        "original_text": "We study the decay amplitudes for charmless hadronic B decays into a scalar meson and an axial-vector or tensor meson in the framework of QCD factorization with generalized form factors at large recoil.  We find that, although the branching fractions are small due to the helicity suppression, these processes can be used as probes of new physics beyond the Standard Model through their CP asymmetries. \nPACS numbers: 11.15.Tk, 12.38.Qk, 13 .25.Hw \nI. INTRODUCTORY REMAR K\nIn this work we will consider the following two types of charmless hadronic:  B → S V (S = P , A 0 ;V = T 1 )andB → SV(S=P;V=A1). The first type is characterized by one light quark in the final state while the second has no light quarks in it. In both cases there is only one spectator quark which leads to a helicity suppression of the corresponding decay rates. However, they may still serve as useful probes of new physics since their CP-violating asymmetries could be enhanced significantly compared to those of other modes  1  .\nTheoretically, such decays have been studied within various approaches including naive factorization  2  , perturbative QCD  3  , soft-collinear effective theory  4  , and QCD factorization  5  -  8  . It was found that the predictions based on different methods differ substantially among themselves. For example, using naive factorization, Ref.  2  predicted Br(B − →K * 0 π − )/Br(B − →Kπ)=0.27 ±0.04, whereas Refs.  6, 7  obtained values around 0.1−0.2. This discrepancy indicates that more theoretical efforts should be made before drawing any definite conclusion about these decays.",
        "watermark_text": "We research the decay amplitudes for charmless hadronic B decays into a scalar meson and an axial - vector or vector meson in the framework of QCD factorization with generalized form factors at large recoil . We see that , although the branching fractions are small owing to the helicity suppression , these mechanisms can be used as probes of new dynamics beyond the Standard Model through their CP asymmetries .PACS numbers : 11 . 15 . Tk , 12 . 38 . Qk , 13 . 25 . Hw I . INTRODUCTORY REMAR K In this study we will explore the following two forms of charmless hadronic : B → S V ( S = P , A 0 ; V = T 1 ) andB → SV ( S = P ; V = A1 ) .The first sort is characterized by one light quark in the last position while the second has no light quarks in it . In both cases there is only one spectator quark which results to a helicity suppression of the associated decay rates .However , they may still provide as helpful probes of new theory since their CP - breaking asymmetries may be enhanced considerably compared to those of other modes 1 . Theoretically , such decays have been studied within various approaches including naive factorization 2 , perturbative QCD 3 , soft - collinear effective theory 4 , and QCD factorization 5 - 8 .It was shown that the estimates based on various methods varies dramatically among themselves . For instance , using naive factorization , Ref .2 observed Br ( B − →K * 0 π − ) / Br ( B − →Kπ ) = 0 . 27 ±0 . 04 , whereas Refs . 6 , 7 obtained values around 0 . 1−0 . 2 .This discrepancy implies that more theoretical efforts should be made before drew any explicit conclusion about these decays .",
        "ori-fast-z-score": 0.3375263702778072,
        "water-fast-z-score": 6.484597134749389
    },
    {
        "original_text": "We present an open-source framework, called Bubblesched, that allows to build portable thread schedulers for hierarchical multiprocessors (HMPs). The main idea is to use bubbles as scheduling units and schedule them on different levels in HMP hierarchy using a set of rules. We have implemented two schedulers: one based on work stealing and another one based on load balancing. Both schedulers are able to run efficiently on top of Bubblesched without any modifications. Our experimental results show that both schedulers outperform state-of-the-art solutions by up to 3Â times when running parallel applications with fine-grained tasks. In addition, we demonstrate how our scheduler can be used to implement efficient task-parallel algorithms such as graph coloring or matrix multiplication. This research was supported by Russian Science Foundation grant 14-50-00040. We present an opensource framework, called Bubblesched: it allows to build portable threadschedulers for hierarchicalmultiprocessors(HMPs)andrunefficientlyonthemwithoutanymodifications.Theframeworkusesbubblesastheschedu-lingsunitsandschedulethemonthelevelsofHMPhierarchyusingasetofrules.Wehaveimplementedtwo-schedulers:onebasedonstealingworkandanotheronesupportedbyloadbalancing.BothschedulersexecutesuccessfullyontopofBubbleschedwithouthavingtobemodified.Ourexperimentalresultsshowthatbothschedulersoutperformstate-oftheartsolutionsupto3timeswhenrunningparallelapplicationswithfinegrainetasks.Inaddition,weillustratethattheframeworkcanbeusedtomakeefficienttask-parallelandalgorithmssuchastask-coloringanoregularmatrixmultiplication.",
        "watermark_text": "We create an free - source framework , entitled Bubblesched , that enables to build portable thread schedulers for hierarchical multiprocessors ( HMPs ) . The main idea is to use bubbles as booking units and pattern them on various levels in HMP hierarchy following a setting of rules .We have adopted two schedulers : one based on work stealing and another one based on load balancing . Both schedulers are able to run efficiently on top of Bubblesched without any modifications .Our research results show that both schedulers outperform state - of - the - art applications by up to 3Â times when ran parallel programs with fine - grained assignments . In addition , we prove how our scheduler can be used to execute easy problem - parallel techniques such as graph coloring or vector multiplication .This research was supported by Russian Science Foundation award 14 - 50 - 00040 . We create an opensource platform , entitled Bubblesched : it allows to build portable threadschedulers for hierarchicalmultiprocessors ( HMPs ) andrunefficientlyonthemwithoutanymodifications . Theframeworkusesbubblesastheschedu - lingsunitsandschedulethemonthelevelsofHMPhierarchyusingasetofrules . Wehaveimplementedtwo - schedulers : onebasedonstealingworkandanotheronesupportedbyloadbalancing . BothschedulersexecutesuccessfullyontopofBubbleschedwithouthavingtobemodified . Ourexperimentalresultsshowthatbothschedulersoutperformstate - oftheartsolutionsupto3timeswhenrunningparallelapplicationswithfinegrainetasks . Inaddition , weillustratethattheframeworkcanbeusedtomakeefficienttask - parallelandalgorithmssuchastask - coloringanoregularmatrixmultiplication .",
        "ori-fast-z-score": -0.6108472217815261,
        "water-fast-z-score": 5.497624996033735
    },
    {
        "original_text": "We present mixed hyperbolic-second-order parabolic formulations for the Einstein field equations in vacuum and electrovacuum, which are suitable to be solved numerically by means of finite difference methods on Cartesian grids with adaptive mesh refinement (AMR). The formulation is based on an auxiliary variable that allows us to split the evolution system into two subsystems, one hyperbolic and another second-order parabolic. We show how this splitting can be used to construct stable numerical schemes using standard techniques such as Kreiss-Oliger dissipation or artificial viscosity. In addition we discuss several issues related to the implementation of these schemes within the AMR framework provided by the Cactus Computational Toolkit. Finally, we present some preliminary results obtained with our new code. This work was supported by CONACyT grant No. 164710. Keywords: Adaptive Mesh Refinement, Numerical relativity",
        "watermark_text": "We present mixed hyperbolic - second - order parabolic formulations for the Einstein field equations in vacuum and electrovacuum , which are suitable to be answered numerically by means of finite difference methods on Cartesian grids with adaptive mesh refinement ( AMR ) . The implementation is based on an auxiliary variable that enables us to split the evolution system into two subsystems , one hyperbolic and another second - order parabolic .We see how this splitting can be used to build stable numerical theories employing conventional methods such as Kreiss - Oliger dissipation or artificial viscosity . In addition we explain several topics related to the implementation of these schemes within the AMR framework presented by the Cactus Computational Toolkit .Finally , we present some preliminary results acquired with our new code . This project was supported by CONACyT grant No .164710.Keywords: Adaptive Mesh Refinement, Numerical relativity",
        "ori-fast-z-score": 1.632993161855452,
        "water-fast-z-score": 5.258758927213289
    },
    {
        "original_text": "We present an alternative description of the electron in terms of its position and velocity, which is based on the idea that it moves along a helical trajectory around the nucleus. The new approach leads to a simple analytical expression for the energy levels of the helium atom as well as for the wave functions corresponding to these states. We show how this model can be used to explain some experimental results obtained by high-resolution spectroscopy experiments performed at Jefferson Lab. In addition we discuss possible extensions of our work towards other atomic systems such as muonic atoms or ions with one valence electron. Helium has been studied extensively over many decades both experimentally and theoretically. It was found that there are two stable isotopes (3He and 4He) and several excited states. These states have been investigated using various spectroscopic techniques including photo-absorption  1  , laser excitation  2  , and Compton scattering  3  . However, despite all efforts made so far, no satisfactory explanation exists yet about why the ground state of 3He is unbound while the ground state of 4He is bound  4  .\nIn order to understand better the structure of helium, we propose here a new theoretical framework where the electron is described not only by its usual position but also by its velocity vector. This new approach allows us to obtain analytically the energy spectrum of helium as well as the associated wavefunctions. Our formalism is inspired by the so-called Bohmian mechanics  5  , which describes particles moving along trajectories instead of following classical equations of motions  6  .",
        "watermark_text": "We introduce an different characterization of the electron in terms of its position and speed , which is based on the idea that it travels along a helical trajectory around the nucleus . The modern perspective results to a simple analytical expression for the power concentrations of the helium atom as well as for the wave functions associated to these states .We see how this description can be used to explain some experimental results acquired by high - resolution spectroscopy investigations undertaken at Jefferson Lab . In addition we explain possible extend of our work towards other nuclear systems such as muonic atoms or ions with one valence electron .Helium has been studied frequently over numerous years both experimentally and theoretically . It was shown that there are two stable isotopes ( 3He and 4He ) and many excited states .These states have been investigated using numerous spectroscopic techniques including photo - absorption 1 , laser excitation 2 , and Compton absorption 3 . However , despite all efforts made so far , no satisfactory excuse exists yet about why the ground state of 3He is unbound while the ground state of 4He is bound 4 .In order to explain better the composition of helium , we undertake here a new theoretical framework where the electron is characterized not only by its traditional position but also by its velocity tensor . This new approach allows us to obtain analytically the power spectrum of helium as well as the associated wavefunctions .Our formalism is influenced by the so - called Bohmian theory 5 , which explains particles moving along trajectories rather of following classical equations of motions 6 .",
        "ori-fast-z-score": -0.27975144247209416,
        "water-fast-z-score": 7.243550686553699
    },
    {
        "original_text": "We present an accurate and efficient fundamental-measure density-functional (FMT) approach to describe fluids composed of rigidly-aligned hard hexagons, which are relevant as model systems for liquid crystals or colloidal suspensions with anisotropic interactions. The FMT is based on a decomposition into three different types of weighted densities that can be evaluated efficiently using fast Fourier transforms. We show how this new FMT yields excellent results compared to Monte Carlo simulations over wide ranges of packing fractions and orientations of the particles. In particular we find very good agreement between our theoretical predictions and simulation data at high packing fractions where previous approaches fail due to strong correlations among neighboring particles. Finally, we demonstrate that our method also allows us to accurately predict structural properties such as pair correlation functions and orientational order parameters. This work provides further evidence that FMTs provide a powerful tool to study complex fluids beyond simple spherical particle models. \nI. INTRODUCTORY REMARkS\nThe description of liquids and soft matter requires sophisticated methods because these materials often exhibit complex structures and dynamics. Density functionals have been developed during recent years as promising tools to tackle many-body problems in statistical mechanics  1  . They allow one to calculate equilibrium properties of interacting particles by minimizing a free energy functional with respect to the local number density distribution. A particularly successful class of density functionals are so-called fundamental-measure density-functionals (FMD), which were originally introduced by Rosenfeld  2  .\nIn their original form they only apply to fluids consisting of identical spheres but extensions to more complicated shapes like ellipsoids  3  , rods  4  , dumbbells  5  , spherocylinders  6  , and even patchy particles  7, 8  have been proposed recently. However, most of these works focus on the case of uniaxial symmetry while there exist few studies dealing with more general situations  9  . Here we consider a system of rigidly-aligned",
        "watermark_text": "We present an accurate and elegant universal - measure density - functional ( FMT ) approach to define liquid consist of rigidly - aligned hard hexagons , which are applicable as model structures for solid crystals or colloidal suspensions with anisotropic interactions . The FMT is based on a transformation into three different kinds of weighted densities that can be evaluated efficiently using fast Fourier transforms .We see how this new FMT yields good results relative to Monte Carlo simulations over broad ranges of packing fractions and orientations of the particles . In particular we find very best agreement between our theory assumptions and modeling data at high packing fractions where earlier approaches fail due to good correlations among neighboring particles .Finally , we prove that our technique also enables us to correctly calculate structural properties such as couple correlation functions and orientational order variables . This research provides further evidence that FMTs represent a powerful tool to study complex fluids beyond straightforward spherical particle models .I . INTRODUCTORY REMARkS The description of liquids and soft material requires sophisticated methods because these structures often exhibit intricate structures and dynamics .Density functionals have been proposed during recent years as promising tools to tackle many - bodies problems in mathematical mechanics 1 . They allow one to estimate equilibrium properties of interacting interactions by minimizing a free energy functional with regard to the local number density density .A notably notable family of density functionals are so - called fundamental - measure density - functionals ( FMD ) , which were first developed by Rosenfeld 2 . In their original form they only applicable to liquid full of different balls but extensions to more complicated forms like ellipsoids 3 , rods 4 , dumbbells 5 , spherocylinders 6 , and also patchy particles 7 , 8 have been proposed lately .However , most of these works concentrate on the case of uniaxial symmetry while there remain few experiments focusing with more general situations 9 . Here we consider a system of rigidly - aligned",
        "ori-fast-z-score": -2.8823067684915684,
        "water-fast-z-score": 6.205346816570694
    },
    {
        "original_text": "We present an approach to extract the underlying physics from large sets of experimental data by using machine learning techniques and statistical analysis. The method is applied on two different examples, namely the measurement of the electrical conductivity in doped semiconductors as well as the determination of the critical temperature Tc for superconductivity in cuprates. In both cases we find that our results are consistent with theoretical predictions. We show how this new technique can be used to identify unknown parameters or even completely new phenomena which cannot be predicted theoretically at all. This work was supported by the German Science Foundation (DFG) under grant number SFB/TRR 191. A central goal of modern science is to understand complex systems such as materials or living organisms through their fundamental building blocks. To achieve this aim it is necessary to develop methods which allow us to analyze huge amounts of experimental data efficiently. Here we propose a novel approach based on machine learning algorithms combined with advanced statistical tools. Our method is demonstrated on two examples: First, we study the dependence of the electrical conductivity on doping concentration in semiconductor compounds. Second, we determine the critical temperature T c for superconductivity in high-temperature cuprate oxides. For both problems we obtain results which agree very well with existing theories. Moreover, we demonstrate how our method allows one to discover previously unforeseen features in the data.",
        "watermark_text": "We present an way to extract the fundamental theory from huge sets of experimental evidence by using computer learning techniques and statistical analysis . The method is applied on two different examples , notably the determination of the electrical conductivity in doped semiconductors as well as the determination of the significant heat Tc for superconductivity in cuprates .In both cases we find that our findings are compatible with theoretical expectations . We see how this new technique can be used to identify unseen conditions or even completely new events which cannot be described theoretically at all .This project was supported by the German Science Foundation ( DFG ) under grant number SFB / TRR 191 . A central goal of modern science is to explain complex systems such as materials or living organisms through their major building frames .To achieve this aim it is required to develop techniques which allow us to analyze huge amounts of research data easily . Here we undertake a innovative method built on machine computing methods coupled with sophisticated statistical tools .Our method is demonstrated on two examples : First , we study the relationship of the electrical conductivity on doping concentration in semiconductor compounds . Second , we determine the significant heat T c for superconductivity in high - temperature cuprate oxides .For both difficulties we obtain results which agree very best with existing ideas . Moreover , we prove how our technique permits one to identify formerly unforeseen features in the information .",
        "ori-fast-z-score": -0.3682298471593294,
        "water-fast-z-score": 7.98489954161323
    },
    {
        "original_text": "We present an evolutionary model that describes the evolution of regulatory mechanisms controlling cell division rates in growing populations. The model is based on the assumption that cells can evolve to optimize their fitness by adjusting their growth rates according to environmental conditions, such as nutrient availability or population density. We show how this simple principle leads to the emergence of complex regulatory networks with multiple feedback loops and time delays. Our results suggest that these networks are robust against mutations but sensitive to changes in external conditions. This may explain why many organisms have evolved similar regulatory circuits despite differences in their genetic backgrounds. \nAuthor: Jens Palsson (University of California San Diego); David Botstein (Stanford University)\nSource: Science Express Online - ScienceDirect URL: http://arxiv.org/abs/1106.0571 DOI: 10.1088/1741-5468/2009/01/00011 \nThe authors propose a mathematical model describing the evolution of regulatory mechanisms governing cell division rates in growing bacterial populations. They assume that bacteria can evolve to maximize their fitness by optimizing their growth rates under different environmental conditions, including nutrient availability and population density. Their analysis shows how this simple principle gives rise to complex regulatory networks containing multiple feedback loops and time-delays.",
        "watermark_text": "We present an evolutionary model that describes the evolution of regulatory mechanisms governing cell division rates in expanding populations . The model is based on the assumption that cells can evolve to optimize their fitness by adjusting their development rates according to environmental conditions , such as nutrient abundance or population density .We suggest how this simple assumption results to the emergence of complex regulatory circuits with many feedback loops and period delays . Our results show that these networks are robust against mutations but sensitive to changes in external conditions .This might explain why many bacteria have adapted related regulatory circuits despite differences in their genetic backgrounds . Author : Jens Palsson ( University of California San Diego ) ; David Botstein ( Stanford University ) Source : Science Express Online - ScienceDirect URL : www : / / arxiv . org / abs / 1106 . 0571 DOI : 10 . 1088 / 1741 - 5468 / 2009 / 01 / 00011 The authors propose a mathematical structure describing the evolution of regulatory mechanisms governing cell division rates in expanding bacterial populations .They assume that bacteria can evolve to maximize their fitness by optimizing their development rates under various climate circumstances , notably nutrient abundance and population density . Their analysis shows how this simple law giving rise to complex regulatory circuits containing several feedback loops and period - errors .",
        "ori-fast-z-score": 0.9622504486493763,
        "water-fast-z-score": 6.670481774415078
    },
    {
        "original_text": "We report water vapor (H2O) and silicon monoxide (SiO) maser emission toward the central star of the protoplanetary  nebula OH231.8+4.2, which is associated with an infrared source IRAS 18286-1231. The H2O masers are distributed over a region of ~0.1 arcsec diameter around the star at a velocity range of -40 to +20 km s-1 relative to the systemic velocity of the nebula. We detected SiO masers only on one side of the star within 0.05 arcsec radius at velocities ranging between -50 and -30 km s-1. These results suggest that the H2O masers trace shocked gas near the stellar surface while the SiO masers arise from outflowing material along the polar axis.  This work was supported by Grants-in-Aid for Scientific Research (No. 15740160)  from MEXT Japan.",
        "watermark_text": "We report wood vapor ( H2O ) and silicon monoxide ( SiO ) maser emission toward the main star of the protoplanetary nebula OH231 . 8 + 4 . 2 , which is associated with an infrared source IRAS 18286 - 1231 . The H2O masers are distributed over a region of ~ 0 . 1 arcsec diameter around the star at a speed range of - 40 to + 20 km s - 1 relative to the systemic speed of the nebula .We observed SiO masers only on one side of the star within 0 . 05 arcsec radius at velocities ranging between - 50 and - 30 kilometers s - 1 . These data suggest that the H2O masers trace shocked liquid near the stellar surface while the SiO masers occur from outflowing matter along the polar axis .This project was supported by Grants - in - Aid for Scientific Research ( No . 15740160 ) from MEXT Japan .",
        "ori-fast-z-score": 0.6324555320336759,
        "water-fast-z-score": 3.794733192202055
    },
    {
        "original_text": "We present an explanation to the observed anomalies in globular cluster luminosity functions (GCLFs) and mass-to-light ratios, based on the assumption that these clusters are composed by two different populations with distinct chemical compositions.  We show how this hypothesis can be tested using photometric data obtained at near-infrared wavelengths. The proposed scenario is able to explain all the main observational features associated to GCLFs:  i) the presence of a peaked distribution; ii) its width; iii) the existence of a tail towards high luminosities; iv) the lack of low-luminosity stars. In addition, it also explains why some GCs have very large values of M/LV . Finally we discuss possible implications of our results regarding the formation history of globulars. Keywords: Globular cluster, Mass-to-light ratio, Luminosity function, Chemical composition, Near-infrared",
        "watermark_text": "We present an explanation to the reported anomalies in globular cluster luminosity functions ( GCLFs ) and mass - to - light proportions , relying on the assumption that these clusters are composed by two different populations with distinct chemical compositions . We see how this hypothesis can be evaluated using photometric data derived at near - infrared wavelengths .The proposed theory is could to explain all the main observational characteristics attributed to GCLFs : i ) the presence of a peaked distribution ; ii ) its height ; iii ) the existence of a tail towards high luminosities ; iv ) the lack of high - luminosity stars . In addition , it also explains why some GCs have very huge values of M / LV .Finally we explain possible implications of our findings pertaining the formation history of globulars . Keywords : Globular cluster , Mass - to - light density , Luminosity function , Chemical composition , Near - infrared",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 4.6475800154489
    },
    {
        "original_text": "The dust around the star Beta Pictoris is being studied by astronomers at Harvard University, using data collected with NASA s Spitzer Space Telescope.  The researchers are studying how the dust particles interact with each other to form larger bodies that may eventually become planets.   They have found evidence for two different types of dust grains in this system; one type has been observed previously but not the second.    This new dust grain appears to be much smaller than those seen before (about 100 times smaller).   It also seems to be more reflective or transparent than previous observations would suggest.   These findings could help explain why some stars appear brighter when they are younger while others do not. Astronomers are trying to understand how planetary systems form.  One way to study planet formation is through observing young stars like Beta Pictoris which is about 20 million years old.  Beta Pictoris is surrounded by an enormous amount of dust produced as it sheds its outer layers during its youthful evolution.   In addition there is gas surrounding the star that forms into spiral patterns similar to those seen in our own solar system.   Scientists believe these dust particles will collide and stick together over time forming larger objects such as asteroids and comets.   Eventually these large bodies can grow even bigger and start orbiting the central star creating what we call  planets .   However, scientists don t know exactly how this process happens because it s very difficult to observe directly.   Instead, astronomers use telescopes to look at light coming from the dusty environment around young stars.   By analyzing the light emitted by the dust particles,...",
        "watermark_text": "The dust around the star Beta Pictoris is being studied by astronomers at Harvard University , using data taken with NASA s Spitzer Space Telescope . The scientists are studying how the dust particles react with each other to form bigger bodies that might eventually form planets .They have discovered evidence for two different kinds of dust grains in this system ; one sort has been observed previously but not the second . This new powder grain tends to be much smaller than those observed before ( about 100 times smaller ) .It therefore seems to be more reflective or reflective than prior measurements might suggest . These studies could explain explain why some stars appear warmer when they are younger while many do not .Astronomers are trying to comprehend how planetary structures form . One method to study planet development is through watching small stars like Beta Pictoris which is about 20 million years old .Beta Pictoris is surrounded by an enormous quantity of dust created as it sheds its outer layers during its young evolution . In addition there is gas covering the star that forms into spiral patterns comparable to those observed in our own solar body .Scientists think these cloud particles will collide and stick together over time forming big objects such as asteroids and comets . Eventually these massive bodies can develop much bigger and get orbiting the main star producing what we call planets .However , scientists don t know exactly how this process happens because it s very difficult to observe directly . Instead , astronomers use telescopes to see at energy coming from the dry environment around young galaxies .By analyzing the light emitted by the dust particles,...",
        "ori-fast-z-score": 0.43685202833051895,
        "water-fast-z-score": 9.400193421607684
    },
    {
        "original_text": "The purpose of this article is to present an overview of some recent results in quantum field theory (QFT) on curved spaces with noncommutative coordinates. The main motivation for studying QFTs on such spaces comes from string theories which are formulated as open strings attached to D-branes whose positions can be described by noncommuting matrices. In particular we will focus our attention on the so-called Groenewold-Moyal plane which is defined as the space generated by two non-commuting coordinates satisfying the commutation relations  qμ(x), qν(y)  = iθμνρqρ(xy). We will show that it is possible to define a covariant derivative operator acting on fields living on the GroenewoldMoyal plane. This allows us to introduce a notion of spinor fields on the Groenewold- Moyal plane. Moreover we will discuss how one can construct gauge invariant actions for these fields. Finally we will study the action of the discrete symmetries C,P,T and CP T .",
        "watermark_text": "The purpose of this page is to provide an overview of some latest findings in quantum field theory ( QFT ) on curved spaces with noncommutative coordinates . The main motivation for studying QFTs on such spaces coming from string theories which are formulated as open strings attached to D - branes whose positions can be described by noncommuting matrices .In particular we will focus our focus on the so - called Groenewold - Moyal plane which is characterized as the space generated by two non - commuting coordinates satisfying the commutation operators qμ ( x ) , qν ( y ) = iθμνρqρ ( xy ) . We will show that it is possible to define a covariant derivative operator acting on fields living on the GroenewoldMoyal plane .This enables us to introduce a concept of spinor fields on the Groenewold - Moyal plane . Moreover we will explore how one can build gauge invariant operations for these fields .Finally we will explore the operation of the discrete symmetries C , P , T and CP T .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.810003810005715
    },
    {
        "original_text": "We study the Leonard triple systems, which are finite sets of points in projective space over a field such that any three distinct points determine a line.  We show how to construct all Leonard triples with parameters (n = 3m + 1) or (n = 3m+2), where m is an integer greater than zero.   In particular we prove that there exist exactly two non-isomorphic Leonard triples for each n = 3m+1 and one non isomorphic Leonard triple for each n = 3(m+1).    Finally, we give some applications of our results on Leonard triples to the theory of hypercubes.    Keywords: Leonard systems; Projective geometry; Hypercube; Finite geometries. The research leading to these results has received funding from the European Research Council under the European Union s Seventh Framework Programme (FP/2007-2013) / ERC Grant Agreement n o 291085. This article is part of the themed issue  Finite Geometries .",
        "watermark_text": "We work the Leonard triple systems , which are finite collections of points in projective space over a field such that any three separate points determine a line . We see how to build all Leonard triples with parameters ( n = 3m + 1 ) or ( n = 3m + 2 ) , where m is an integer larger than zero .In particular we prove that there exist exactly two non - isomorphic Leonard triples for each n = 3m + 1 and one non isomorphic Leonard triple for each k = 3 ( m + 1 ) . Finally , we give some applications of our findings on Leonard triples to the theory of hypercubes .Keywords : Leonard systems ; Projective geometry ; Hypercube ; Finite geometries . The studies leading to these results has obtained support from the European Research Council under the European Union s Seventh Framework Programme ( FP / 2007 - 2013 ) / ERC Grant Agreement n o 291085 .This page is part of the themed article Finite Geometries .",
        "ori-fast-z-score": -1.0434983894999017,
        "water-fast-z-score": 3.015113445777636
    },
    {
        "original_text": "We present an efficient algorithm for computing the sign function of a large sparse complex matrix, which is based on the Lanczos bidiagonalization process with partial reorthogonalization. The proposed algorithm can be applied to any Hermitian or non-Hermitian matrices without restriction. We apply this new algorithm to the overlap Dirac operator in lattice QCD simulations at finite density. In particular we show that our algorithm works well even when the quark mass becomes small compared to the inverse of the lattice spacing. This work was supported by Grants-in-Aid for Scientific Research (No. 20340040) from MEXT Japan. PACS numbers: 11.15.Ha, 12.38.Qk, 12.39.Fe, 14.20 .Dh  1 Introduction Lattice Quantum Chromodynamics(LQCD), as one of the most promising candidates for describing strong interactions among quarks and gluons, has been widely used to study hadronic properties such as masses and decay constants  1  . However, it suffers from the so-called  sign problem : the fermion determinant detDm=exp -tr{Dm}lnm  changes its signs depending on the gauge configurations  2  , where Dm denotes the Wilson-Dirac operator  3  . Therefore, Monte Carlo methods cannot be directly employed to calculate physical quantities using LQCD because they require positive definite weight functions  4  .\nIn order to overcome this difficulty, several approaches have been developed so far  5  -  8  . Among them, the Taylor expansion approach  9  -  11  seems to be very powerful since it allows us to evaluate the expectation value of any observables accurately within statistical errors. It also enables us to perform calculations at high temperature and/or high density  12  -  14  . For example, the Taylor expansion up to O(a6) has already been performed successfully  15  .",
        "watermark_text": "We present an efficient algorithm for calculation the sign function of a large sparse complex matrix , which is based on the Lanczos bidiagonalization process with partial reorthogonalization . The proposed algorithm can be applied to any Hermitian or non - Hermitian matrices without limitation .We use this new algorithm to the overlap Dirac operator in lattice QCD simulations at finite density . In particular we prove that our algorithm works well even when the quark mass becomes tiny relative to the inverse of the lattice spacing .This project was supported by Grants - in - Aid for Scientific Research ( No . 20340040 ) from MEXT Japan .PACS scores : 11 . 15 . Ha , 12 . 38 . Qk , 12 . 39 . Fe , 14 . 20 . Dh 1 Introduction Lattice Quantum Chromodynamics ( LQCD ) , as one of the most attractive candidates for describing strong coupling among quarks and gluons , has been widely using to study hadronic properties such as masses and decay constants 1 . However , it suffers from the so - called sign problem : the fermion determinant detDm = exp - tr { Dm } lnm varies its signs depending on the gauge modes 2 , where Dm denotes the Wilson - Dirac operator 3 .Therefore , Monte Carlo methods never be directly used to estimate mechanical numbers using LQCD because they use positive definite weight functions 4 . In order to overcome this obstacle , various approaches have been proposed so far 5 - 8 .Among them , the Taylor expansion method 9 - 11 seems to be very potent since it allows us to analyze the expectation value of any observables correctly within statistical errors . It additionally lets us to conduct measurements at high heat and / or large velocity 12 - 14 .For instance , the Taylor expansion up to O ( a6 ) has already been performed successfully 15 .",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.4835456068700275
    },
    {
        "original_text": "We propose that the vacuum state is not empty but contains fluctuations in spacetime, which we call holographic noise (HN). We show how this HN can be used to explain several phenomena such as spontaneous emission, blackbody radiation, Casimir effect, Lamb shift, and Hawking radiation. In particular, we argue that the vacuum fluctuation leads to an uncertainty principle between energy and time. This implies that there are no particles with zero mass or spin. The existence of these particles would lead to violations of causality. Finally, we discuss some possible experimental tests for our proposal. Vacuum fluctuations play important roles in quantum field theory. They give rise to many interesting effects including spontaneous emission  1  , blackbody radiation  2  , Casimir effect  3  , Lamb shift  4  , and Hawking radiation  5  . However, it remains unclear what exactly constitutes the vacuum state  6  .\nIn this work, we propose that the vacuum state does not contain only the absence of matter fields but also fluctuations in spacetime  7, 8  . These fluctuations may be viewed as virtual gravitons  9  . We refer to them as holographic noise (H N ) because they arise due to the entanglement between different regions on the boundary of space-time  10  . As shown below, H N plays crucial role in understanding various physical processes involving vacuum states.\nThe main idea behind our approach is illustrated by Fig.  1(a) . Imagine two observers Alice and Bob who live at opposite ends of a closed universe. Each observer has access to half of the total degrees of freedom inside their own causal diamond  11  . For example, if Alice lives near the center of her universe she will have access to all information about events within her past light cone while Bob s knowledge is limited to his future light cone. Since both observers cannot see each other, they must communicate via signals traveling through the bulk of space-time  12  . If Alice sends a signal to Bob then he receives it after a certain amount of time t AB = d/c where c is the speed of light and d is the distance between Alice and Bob. On the other hand, if Bob sends",
        "watermark_text": "We suggest that the vacuum state is not filled but contains fluctuations in spacetime , which we call holographic noise ( HN ) . We see how this HN can be used to explain different processes such as spontaneous emission , blackbody radiation , Casimir effect , Lamb shift , and Hawking radiation .In particular , we claim that the vacuum fluctuation leads to an uncertainty theory between energy and time . This implies that there are no particles with zero mass or spin .The existence of these objects would result to violations of causality . Finally , we talk some possible experimental tests for our proposal .Vacuum fluctuations represent crucial roles in quantum field theory . They give rise to many interesting phenomena including spontaneous emission 1 , blackbody radiation 2 , Casimir effect 3 , Lamb shift 4 , and Hawking radiation 5 .However , it remains unsure what actually constitutes the vacuum state 6 . In this research , we claim that the vacuum state does not include only the absence of mind fields but also fluctuations in spacetime 7 , 8 .These fluctuations might be viewed as virtual gravitons 9 . We refer to them as holographic disturbance ( H N ) because they occur due to the entanglement between various regions on the boundary of space - time 10 .As seen below , H N plays crucial role in understanding various mechanical phenomena involving vacuum states . The main idea behind our approach is illustrated by Fig .1 ( a ) . Imagine two observers Alice and Bob who living at different edges of a closed world .Each observer has entry to half of the total degrees of autonomy inside their own causal diamond 11 . For instance , if Alice resides near the center of her universe she will have access to all information about events within her past light cone while Bob s knowledge is limited to his future dark cone .Since both observers cannot see each other , they must interact via signals going through the bulk of space - time 12 . If Alice sends a signal to Bob then he gets it after a certain amount of time t AB = d / c where l is the speed of light and d is the distance between Alice and Bob .On the other hand , if Bob sends",
        "ori-fast-z-score": 1.8717134551736667,
        "water-fast-z-score": 8.111071056538128
    },
    {
        "original_text": "We study the orbital evolution and stability properties of oligarchic co-orbitals in the Solar System, i.e., bodies with masses comparable to that of Jupiter which are trapped on orbits close to those of Neptune or Uranus for billions of years.  We show how these objects can be identified by their long-term dynamical behavior as well as by their current positions relative to Neptune s orbit. The existence of such bodies is confirmed by numerical integrations over timescales up to 10 billion years using the symplectic N-body code SyMBA. In addition we find that there exist at least two other stable regions where oligarchs may reside. These results suggest that the Solar System contains several dozen oligarchic co-orbitals:  - At least four known trans-Neptunian objects (Pluto, Charon, Haumea, Makemake) have been found to exhibit this type of dynamics; - There exists another region around 30 AU containing three additional bodies (Sedna, 2000 CR 105 , 2003 SQ 317 ); - Finally, our simulations indicate that there might also be an additional group of oligarchs located between 50-60 AU.",
        "watermark_text": "We research the orbital evolution and stability properties of oligarchic co - orbitals in the Solar System , i . e . , bodies with masses similar to that of Jupiter which are locked on orbits close to those of Neptune or Uranus for billions of years . We see how these objects can be identified by their long - term dynamical behavior as well as by their current positions close to Neptune s orbit .The formation of such objects is predicted by numerical integrations over timescales up to 10 billion years employing the symplectic N - bodies code SyMBA . In addition we find that there exist at least two other stable parts where oligarchs might live .These data suggest that the Solar System includes several several oligarchic co - orbitals : - At least four known trans - Neptunian planets ( Pluto , Charon , Haumea , Makemake ) have been seen to contain this form of dynamics ; - There exists another region around 30 AU holding three extra bodies ( Sedna , 2000 CR 105 , 2003 SQ 317 ) ; - Finally , our simulations confirm that there might additionally be an additional family of oligarchs located between 50 - 60 AU .",
        "ori-fast-z-score": -1.3643820804812932,
        "water-fast-z-score": 5.0854241181575475
    },
    {
        "original_text": "We consider an entropy penalization method in order to estimate the density function f of a random variable X with values on Rd . We prove that, under some conditions, this estimator is strongly consistent and we study its asymptotic normality. The main tool used here is the exponential decay of correlations property satisfied by the stochastic process associated to our estimation procedure. This result allows us to obtain rates of convergence for the mean integrated squared error (MISE) between the true density f and its estimators. Finally, numerical experiments are performed in dimension 1 and 2. Keywords: Density estimation, Entropic penalty, Exponential decay of correlations, Asymptotic normality. Mathematics Subject Classification (2010): 60C05, 60F10, 62G20. 1 Introduction Let X be a real-valued random vector defined on a probability space (Ω , A , P). In many applications such as signal processing or econometrics, it may be interesting to recover the distribution law of X denoted by fX . For example, if one wants to detect changes in the statistical properties of X over time, then knowing fX will allow him/her to perform change-point detection tests  see e.g., Chen et al. (2013), Fryzlewicz & Subba Rao (2014) . However, recovering fX can be difficult because only n iid observations X1 , . . . , Xn of X are available. To overcome this difficulty, several authors have proposed to use nonparametric methods based on kernel smoothing techniques  see e.g. , Silverman (1981) , Wand & Jones (1995)  . More precisely, let K : R →  0, 1  be a given kernel function satisfying certain regularity assumptions which will be specified later. Then, the classical kernel density estimator of fX at x ∈ Rd is defined bŷ fbK (x) =",
        "watermark_text": "We consider an entropy penalization techniques in order to estimate the density function f of a random variable X with values on Rd . We prove that , under some conditions , this estimator is strongly consistent and we study its asymptotic normality .The main technique useful here is the exponential decay of correlations property satisfied by the stochastic mechanism associated to our estimation method . This result allows us to obtain rates of convergence for the mean integrated squared error ( MISE ) between the true density f and its estimators .Finally , numerical studies are performed in dimension 1 and 2 . Keywords : Density estimation , Entropic penalty , Exponential decay of correlations , Asymptotic normality .Mathematics Subject Classification ( 2010 ) : 60C05 , 60F10 , 62G20 . 1 Introduction Let X be a real - valued random function characterized on a probability space ( Ω , A , P ) .In many applications such as signal filtering or econometrics , it could be interesting to extract the distribution law of X denoted by fX . For instance , if one wants to identify changes in the statistical characteristics of X over time , then understanding fX will provide him / her to conduct change - point detection tests see e . g . , Chen et al .( 2013 ) , Fryzlewicz & Subba Rao ( 2014 ) . However , returning fX can be challenging because only n iid observations X1 , ..., Xn of X are available . To solve this challenge , various published have proposed to use nonparametric techniques based on kernel smoothing methods see e . g ., Silverman ( 1981 ) , Wand & Jones ( 1995 ) . More specifically , let K : R → 0 , 1 be a given kernel map satisfying particular regularity assumptions which will be specified later .Then , the classical kernel density estimator of fX at x ∈ Rd is given bŷ fbK ( x ) =",
        "ori-fast-z-score": -0.5619514869490164,
        "water-fast-z-score": 5.315277406969789
    },
    {
        "original_text": "We present the first results on black hole accretion using our new numerical scheme, which is based on an implicit-explicit time integration method and uses adaptive mesh refinement (AMR). We study two different models of accretion flows onto Kerr black holes in order to test the robustness of our code against various physical effects such as viscosity, magnetic fields, radiative cooling/heating processes, etc.. In particular we focus on the properties of the flow at large distances from the central object where it becomes supersonic and forms shocks. Our main goal here was to check whether these features are correctly captured by our AMR code. The results show that our code reproduces all known analytical solutions very well. \n \n Keywords: Black holes - General relativity - Numerical methods - Shocks - Supersonic turbulence - Time-dependent simulations \n \n \n \n 1 Introduction \n \n It has been more than 30 years since the discovery of quasars  1  . Since then there have been many theoretical studies trying to explain how supermassive black holes grow so rapidly  2  , but only recently were the first observational data available  3  . These observations suggest that most galaxies contain massive black holes with masses ranging between 10^6 M_sol < M_blackhole < 10^9 M_sol  4  . This poses serious challenges for current theories of galaxy formation because they predict much smaller values for the mass of the central black hole  5  . \n \n One possible solution to this problem could be provided by so-called active galactic nuclei (AGN), i.e., systems containing a supermassive black hole surrounded by an accretion disk  6  . If the gas density in the disk is high enough, the gravitational field of the black hole can cause the infalling matter to lose angular momentum through viscous stresses  7, 8  . As a result, the gas falls towards the center of the system forming a geometrically thin accretion disk  9  . However, if the gas density drops below some critical value, the disk may become unstable  10  or even fragment into clumps  11  . Such instabilities lead to the development of large-scale",
        "watermark_text": "We publish the first findings on dark hole accretion use our new numerical system , which is based on an implicit - explicit time integration approach and using adaptive mesh refinement ( AMR ) . We research two different models of accretion flows onto Kerr white holes in order to test the robustness of our code against several physical effects such as viscosity , magnetic fields , radiative cooling / cooling systems , etc . .In particular we focus on the properties of the flow at large distances from the main object where it becomes supersonic and shapes shocks . Our main goal here was to examine whether these characteristics are correctly captured by our AMR code .The results show that our code reproduces all known theoretical solutions very best . Keywords : Black holes - General relativity - Numerical methods - Shocks - Supersonic turbulence - Time - dependent simulations 1 Introduction It has been more than 30 centuries since the discovery of quasars 1 .Since then there have been many theoretical researchers trying to explain how supermassive black holes expand so quickly 2 , but only lately were the first observational data available 3 . These measurements suggest that most objects possess massive brown holes with masses ranging between 10 ^ 6 M _ sol < M _ blackhole < 10 ^ 9 M _ sol 4 .This poses serious difficulties for recent predictions of galaxy formation because they predict far lower values for the mass of the main white hole 5 . One potential answer to this question could be provided by so - called active galactic nuclei ( AGN ) , i . e . , structures featuring a supermassive black hole accompanied by an accretion ring 6 .If the gas density in the disk is high enough , the gravitational field of the dark hole can cause the infalling matter to lose angular velocity through viscous stresses 7 , 8 . As a result , the gas drops towards the center of the system producing a geometrically thin accretion cone 9 .However , if the gas density decreases below some essential value , the disk might turn volatile 10 or maybe fragment into clumps 11 . Such instabilities lead to the development of large - scale",
        "ori-fast-z-score": 0.8835412617927487,
        "water-fast-z-score": 9.397666148159237
    },
    {
        "original_text": "We present results for angular distributions in the photoionization process of H-, He+ and Li2+ by circularly polarized photons at different energies. The calculations are performed within the framework of relativistic distorted wave theory using an accurate numerical method to solve the Dirac equation with Coulomb potential. We show that our theoretical predictions agree well with available experimental data. In addition we have studied the influence of nuclear spin effects on these observables. Finally, we discuss how this information can be used as a tool to determine the fine structure constant. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium provided that the original work is properly cited. \n \n Two-photon ionization plays an important role in many physical processes such as laser-matter interaction or astrophysical phenomena like stellar winds. It has been shown recently that it also constitutes one of the most promising methods to measure the fine-structure constant α  1  . For example, the measurement of the ratio between the cross sections corresponding to transitions into n=2 and n=3 states of heliumlike ions provides a determination of α with relative uncertainty below 10 −6  2  .\n \nIn order to perform precise measurements of the fine-structure constant through twophoton ionization experiments, it is necessary to understand theoretically all relevant aspects involved in the process. Among them, the study of the angular dependence of the emitted electrons represents a key issue since it allows us to discriminate among different contributions coming from different parts of the atomic spectrum  3  . Moreover, the comparison between experiment and theory requires high accuracy both in the calculation of the total cross section and its angular distribution  4  . \n \n In recent years there has been considerable progress in the development of computational techniques able to provide highly accurate results for the total cross section  5  , but only few works  6  -  8  have addressed the problem of calculating the angular distribution of the emitted electron. Most of those previous investigations were carried out within the nonrelativistic regime where the final state was described by means of the Schr",
        "watermark_text": "We present results for angular distributions in the photoionization process of H - , He + and Li2 + by circularly polarized photons at different energies . The calculations are performed within the framework of relativistic twisted wave theory employing an accurate numerical technique to correct the Dirac integral with Coulomb potential .We see that our theory estimates agree well with existing experimental evidence . In addition we have researched the impact of nuclear spin effects on these observables .Finally , we talk how this data can be used as a tool to obtain the fine structure constant . This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( http : / / creativecommons . org / patents / by / 3 . 0 ) , which allows unrestricted sale , distribution , and reproduction in any medium provided that the original piece is properly cited .Two - photon ionization serves an important role in different physical processes such as laser - matter collision or astrophysical processes like stellar winds . It has been shown lately that it also constitutes one of the most attractive approaches to measure the fine - structure constant α 1 .For instance , the observation of the proportion between the cross sections corresponding to transitions into n = 2 and n = 3 states of heliumlike atoms provides a calculation of α with relative uncertainty below 10 −6 2 . In order to conduct accurate measurements of the fine - structure constant through twophoton ionization tests , it is required to explain theoretically all relevant details used in the process .Among them , the observation of the angular dependence of the emitted particles represents a key issue since it allows us to discriminate among different contributions come from different areas of the atomic spectrum 3 . Moreover , the comparison between experiment and theory requires large accuracy both in the determination of the total cross area and its angular distribution 4 .In recent years there has been substantial development in the development of computational approaches able to provide highly precise conclusions for the total cross area 5 , but only few papers 6 - 8 have treated the issue of calculating the angular distribution of the emitted particle . Most of those previous investigations were carried out within the nonrelativistic regime where the last state was described by means of the Schr",
        "ori-fast-z-score": 0.5291502622129182,
        "water-fast-z-score": 9.24879613166262
    },
    {
        "original_text": "We present an analysis of the fundamental physical parameters (mass, luminosity and size) for a sample of young star clusters in the nearby spiral galaxy M33 using HST/ACS data. We find that these objects are consistent with being gravitationally bound open clusters or associations. The mass distribution is well described by a power law dN/dM ~ M^{-3} between 10^6 to 5 x 10^7 solar masses. This result suggests that cluster formation proceeds hierarchically on all scales within this range. In addition we find evidence for two distinct populations of massive clusters; one population has ages less than 100 Myr while another older population appears to be coeval at ages greater than 300 Myr. These results suggest that there may have been multiple episodes of intense cluster formation over the past few hundred million years. Finally, we compare our observations to theoretical models of cluster evolution and find good agreement when assuming a Kroupa IMF.",
        "watermark_text": "We present an assessment of the fundamental physical factors ( mass , luminosity and size ) for a sample of young galaxy galaxies in the nearby spiral galaxy M33 utilizing HST / ACS data . We see that these objects are compatible with being gravitationally locked open complexes or associations .The mass distribution is well described by a power law dN / dM ~ M ^ { - 3 } between 10 ^ 6 to 5 x 10 ^ 7 solar masses . This result suggests that cluster structure proceeds hierarchically on all scales within this range .In addition we find data for two separate populations of large clusters ; one group has ages less than 100 Myr while another older population seems to be coeval at ages greater than 300 Myr . These data suggest that there may have been multiple cycles of aggressive cluster structure over the previous few hundred million years .Finally , we compare our observations to theoretical theories of cluster evolution and find good agreement when assuming a Kroupa IMF .",
        "ori-fast-z-score": 0.23249527748763857,
        "water-fast-z-score": 5.427092530382482
    },
    {
        "original_text": "We present an analytic solution to the steady state distribution for the mechanistic home-range model developed by Moorcroft et al. (2006) that allows for efficient computation of home ranges using numerical integration methods. The new method is implemented as part of the R package adehabitatHR, which also includes functions for computing home ranges with the original algorithm (i.e., without the analytical solution). We demonstrate how our approach can be used to rapidly compute home ranges across large landscapes containing thousands of habitat patches. Our results show that the new method produces identical estimates compared to those obtained with the original algorithm but requires less computational time when estimating home ranges over large spatial extents. Analytical solutions are useful because they allow researchers to efficiently estimate home ranges on very large datasets or at fine resolutions. \n \n Home ranges have been widely studied since their introduction into ecology more than 50 years ago  1  . These areas represent the area within which individuals obtain all necessary resources  2  , such as food  3  , water  4  , shelter  5  , mates  6  , and cover  7  . In addition to being important for understanding animal behavior  8  , home ranges play key roles in conservation biology  9  , wildlife management  10  , epidemiology  11  , and disease transmission  12  .\n \nHome-range models typically assume that animals move through a landscape composed of discrete habitat patches  13  . Animals select among these patches based on some combination of patch attributes  14  , including resource availability  15  , vegetation structure  16  , predation risk  17  , and conspecific density  18  . This process continues until the animal reaches equilibrium between its movement rate and the quality of available habitats  19  . \n \n A number of different approaches exist for modeling animal movements  20  . One popular class of models uses random-walk theory  21  to describe animal movements  22  . Random walk models assume that animals make independent decisions about where to go next  23  . However, this assumption may not always hold true  24  . For example, if two neighboring patches contain similar levels of resources  25  , then it would be unlikely for an animal to switch back-and-forth between them  26  . To account for this type of behavioral response, Moorcro",
        "watermark_text": "We present an analytic solution to the stable state distribution for the mechanistic home - range system established by Moorcroft et al . ( 2006 ) that enables for efficient computation of home ranges using numerical integration methods .The new method is implemented as part of the R program adehabitatHR , which also contains functions for modeling home ranges with the previous algorithm ( i . e . , without the empirical approach ) . We suggest how our approach can be used to rapidly compute bedroom ranges across large landscapes containing thousands of environment patches .Our results show that the new method generates similar estimates compared to those achieved with the previous algorithm but requires fewer computational time when estimating bedroom ranges over large geographic extents . Analytical approaches are helpful because they allow scientists to easily assess home ranges on very huge datasets or at fine resolutions .Home ranges have been widely examined since their arrival into ecosystems more than 50 weeks ago 1 . These zones represent the territory within which adults obtain all necessary resources 2 , such as feed 3 , water 4 , protection 5 , mates 6 , and cover 7 .In addition to being important for explaining animal behavior 8 , home ranges represent crucial roles in wildlife dynamics 9 , conservation conservation 10 , epidemiology 11 , and illness transmission 12 . Home - range systems often assume that animals go through a landscape composed of linear habitat patches 13 .Animals select among these patches based on some mix of patch traits 14 , covering habitat availability 15 , vegetation system 16 , predation risk 17 , and conspecific density 18 . This process proceeds until the organism reaches stability between its movement rate and the performance of available environments 19 .A variety of different methods exist for modeling animal activities 20 . One popular family of models using random - walk models 21 to explain animal activities 22 .Random step models believe that individuals give independent choice about where to going next 23 . However , this assumption must not always hold false 24 .For instance , if two adjacent regions contain similar rates of assets 25 , then it would be impossible for an organism to shift back - and - forth between them 26 . To account for this form of behavioral reaction , Moorcro",
        "ori-fast-z-score": -1.7230995806825715,
        "water-fast-z-score": 10.625780747542525
    },
    {
        "original_text": "The fitting problem is one of the most important problems in cosmology, which has been studied for more than 50 years.  The main goal of this work was to study the effect of different types of initial conditions on the evolution of density perturbations in an expanding universe with a positive cosmological constant (dark energy).  We have used two methods to solve numerically the Einstein equations coupled to the matter fields:  the standard method based on the expansion of the metric tensor into spherical harmonics; and the new method developed by us that uses the expansion of the metric into Chebyshev polynomials.  In both cases we have considered three types of initial conditions: Gaussian random fields generated using the Zel dovich approximation, Gaussian random fields generated using a fast Fourier transform algorithm, and white noise.  Our results show that all these models give similar predictions at late times when they are evolved up to z = 0.5.  However, there are some differences between them at early times.  These differences can be explained as follows:  the Zel dovich model predicts larger fluctuations compared to other models because it does not take into account the pressure term in the fluid equation; the white noise model gives smaller fluctuations due to its statistical properties; finally, the Gaussian random fields obtained via the fast Fourier transform algorithm predict intermediate values.  This result shows that the choice of the initial conditions may affect significantly the final value of the power spectrum of primordial density fluctuations predicted by inflationary theories.",
        "watermark_text": "The fit problem is one of the most important problems in cosmology , which has been studied for more than 50 centuries . The main goal of this research was to study the impact of different kinds of initial conditions on the evolution of density perturbations in an evolving galaxy with a positive cosmological constant ( darkness energy ) .We have utilized two means to solve numerically the Einstein equations coupled to the matter fields : the standard method based on the contraction of the metric tensor into spherical harmonics ; and the new method developed by us that using the contraction of the metric into Chebyshev polynomials . In both cases we have analyzed three sorts of initial conditions : Gaussian random fields generated using the Zel dovich approximation , Gaussian random fields generated utilizing a slow Fourier integral method , and gray noise .Our results show that all these models make comparable predictions at late times when they are evolved up to z = 0 . 5 . However , there are some variations between them at early periods .These changes can be described as follows : the Zel dovich theory predicts larger fluctuations compared to other models because it does not take into consideration the pressure term in the liquid equation ; the red noise model gives larger fluctuations owing to its statistical characteristics ; finally , the Gaussian random fields obtained via the fast Fourier shift technique achieve intermediate values . This result suggests that the selection of the early conditions might impact significantly the finished value of the power spectrum of primordial density fluctuations suggested by inflationary theories .",
        "ori-fast-z-score": 0.18107149208503706,
        "water-fast-z-score": 7.181818181818182
    },
    {
        "original_text": "We present new methods to determine the mass-loss rate in evolved stars (AGB) using radio observations at centimeter wavelengths, and compare these results with those obtained by infrared dust emission measurements. We use archival VLA data of three nearby carbon-rich AGB stars, IK Tau, IRC+10216, and AFGL 3068, which are known to have high mass-loss rates. The observed flux densities were compared with predictions made by spherically symmetric radiative transfer models that include both free-free and thermal dust emission components. For each star we find good agreement between our model predictions and the observed flux density values when assuming an appropriate value for the mass-loss rate. Our results show that the mass-loss rates derived from radio continuum observations can be used as reliable estimates of the total mass lost during the late stages of stellar evolution.  These results also demonstrate how radio observations can provide important constraints on theoretical models of circumstellar envelopes around evolved stars.",
        "watermark_text": "We introduce novel techniques to estimate the mass - loss rate in evolution stars ( AGB ) using radio observations at centimeter wavelengths , and compare these results with those achieved by infrared dust absorption observations . We use archival VLA information of three distant carbon - rich AGB stars , IK Tau , IRC + 10216 , and AFGL 3068 , which are known to have high mass - loss rates .The observed flux densities were compared with predictions provided by spherically symmetric radiative transfer methods that include both free - free and thermal dust radiation parts . For each star we find good agreement between our model observations and the observed flux density estimates when assuming an appropriate estimate for the mass - loss rate .Our results show that the mass - loss rates derived from radio continuum measurements can be used as reliable estimates of the total mass losses during the last phases of stars evolution . These data even demonstrate how radio observations can provide important restrictions on theoretical theories of circumstellar envelopes around evolved galaxies .",
        "ori-fast-z-score": 0.3144854510165755,
        "water-fast-z-score": 5.7655666019705505
    },
    {
        "original_text": "We report on the observation of electronic spin transport across macroscopic distances (several millimeters) in suspended single-layer graphene devices at room temperature.  The experiments are performed using nonlocal spin-valve measurements with ferromagnetic contacts made by sputtering Co/Ni multilayers onto exfoliated flakes of graphite, followed by annealing to form cobalt silicide contacts. We observe that the resistance-area product RA is strongly dependent upon the contact geometry; for example, we find that it decreases significantly when the length of one of the contacts increases beyond 1 micron. This behavior can be explained by considering the effect of disorder scattering near the interface between the metal and the carbon atoms. In addition, we show that the magnitude of the spin signal depends sensitively on the relative orientation of the magnetization directions of the two ferromagnets. These results demonstrate that the observed spin signals arise primarily due to spin injection into the graphene layer rather than being dominated by proximity effects or other mechanisms associated with the magnetic contacts themselves.",
        "watermark_text": "We report on the observation of electronic spin travel across macroscopic distances ( several millimeters ) in suspended single - substrate graphene structures at room temperature . The studies are performed using nonlocal spin - valve measurements with ferromagnetic contacts produced by sputtering Co / Ni multilayers onto exfoliated flakes of graphite , followed by annealing to form cobalt silicide links .We recognize that the tolerance - area product RA is strongly dependent upon the contact shape ; for example , we find that it decreases dramatically when the length of one of the contacts increases beyond 1 micron . This activity can be described by examining the impact of disorder absorption near the interface between the metal and the metal atoms .In addition , we find that the magnitude of the spin signal relies sensitively on the relative attitude of the magnetization directions of the two ferromagnets . These data demonstrate that the known spin signals arise principally due to spinning injection into the graphene layer instead than being dominated by proximity effects or other mechanisms associated with the magnetic links themselves .",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 5.128225940683707
    },
    {
        "original_text": "We present new near-infrared (NIR) polarimetric observations of the GG Tau system, which reveal that its circumstellar disk is highly structured and contains several bright regions with different polarization properties. The most prominent feature in our data set is an arc-like structure located at about 0.5 arcsec to the south-east of the central binary star. This region shows strong polarized emission up to 10% of the total intensity and has been previously identified as a reflection nebula by Weintraub et al. (1993) . We find that this feature can be explained by scattering off optically thin dust grains close to the midplane of the disk. In addition we detect two other bright features on either side of the central binary. These are also associated with high degrees of linear polarization but show no clear evidence for scattered light. Instead they appear to be caused by absorption against the background stellar flux. Finally, we identify three additional fainter structures in the southern part of the disk. All these features have similar polarization angles indicating that their origin may be related.",
        "watermark_text": "We present new near - infrared ( NIR ) polarimetric studies of the GG Tau component , which confirm that its circumstellar disk is heavily compressed and features several bright regions with various polarization properties . The most notable feature in our information pool is an arc - like structure located at about 0 . 5 arcsec to the south - eastward of the main binary star .This region shows intense polarized emission up to 10 % of the total intensity and has been previously described as a mirror nebula by Weintraub et al . ( 1993 ) .We see that this phenomenon can be described by scattering off optically thin dust grains next to the midplane of the disk . In addition we locate two other bright features on either front of the main binary .These are also associated with high levels of linear polarization but display no clear proof for dispersed light . Rather they appear to be caused by absorption against the background stellar flow .Finally , we identify three extra fainter objects in the southern portion of the disk . All these structures have parallel polarization angles indicating that their source may be connected .",
        "ori-fast-z-score": -0.5488212999484517,
        "water-fast-z-score": 6.846754616640485
    },
    {
        "original_text": "We report on five new planets discovered by the NASA K2 mission, which were found in the sample of targets observed during Campaigns 1 and 2 (C1/K2). The planet candidates are all located within 100 pc of Earth with periods ranging between 3 days to 16 years. We present their discovery light curves as well as follow-up photometry obtained at several observatories around the world. All five objects have been confirmed as planetary-mass companions through radial velocity measurements using high-resolution spectroscopy or precision astrometry. \n \n Keywords: Planetary systems - Discovery methods - Radial velocities - Astrometry - Transits - Exoplanet - K2 Mission - Nearby stars - TESS - PLATO - HARPS-N - SPECULOOS \n \n \n \n Five intermediate-period planets from the N2K sample \nThe NASA Kepler space telescope has revolutionized our understanding of extrasolar planets over its primary mission that lasted for four years . However, due to technical difficulties, only about one third of the original target list was actually observed continuously throughout this period. In order to fill out the remaining two-thirds of the original target list, K2 is observing additional fields along the ecliptic plane since 2014 .\nIn this work we report on five new planets detected by K2 , which were found among the sample of targets observed in campaigns 1 and 2 ( C1/K2 ) . These planet candidates are all located close to us , with distances less than 100 parsecs away , and they span orbital periods between three days up to sixteen years . Their masses range from 0 . 5 to 4 times Jupiter  s mass .  \n \n We present here the discovery light curves together with followup photometric observations performed at various observatories worldwide . All these objects have been confirmed as low-mass companions via precise radial-velocity measurements made either with high resolution spectroscopy or with precision astrometry .",
        "watermark_text": "We report on five new planets discovered by the NASA K2 flight , which were found in the sample of targets observed during Campaigns 1 and 2 ( C1 / K2 ) . The planet candidates are all located within 100 pc of Earth with periods ranging between 3 days to 16 days .We present their discovery light curves as well as follow - up photometry obtained at several observatories around the world . All five objects have been confirmed as planetary - mass companions through radial speed measurements involving high - resolution spectroscopy or precision astrometry .Keywords : Planetary systems - Discovery methods - Radial velocities - Astrometry - Transits - Exoplanet - K2 Mission - Nearby galaxies - TESS - PLATO - HARPS - N - SPECULOOS Five intermediate - time planets from the N2K survey The NASA Kepler space telescope has revolutionized our knowing of extrasolar stars over its primary mission that lasted for four seasons . However , owing to technical problems , only about one third of the actual target list was actually seen continuously throughout this time .In order to fill out the remaining two - half of the original target roster , K2 is monitoring extra fields along the ecliptic plane since 2014 . In this research we publish on five new objects discovered by K2 , which were found among the sample of targets observed in campaigns 1 and 2 ( C1 / K2 ) .These planet candidates are all located close to us , with distances fewer than 100 parsecs apart , and they span orbital periods between three weeks up to fourteen months . Their masses range from 0 .5 to 4 times Jupiter s mass . We present here the discovery light curves combined with followup photometric surveys performed at numerous observatories worldwide .All these objects have been confirmed as low - weight companions via accurate radial - speed measurements made either with high resolution spectroscopy or with accuracy astrometry .",
        "ori-fast-z-score": 0.9838699100999074,
        "water-fast-z-score": 7.423745685299301
    },
    {
        "original_text": "We present an improved abundance determination for the black hole binary nova Sco X-1, based on high-resolution optical spectroscopy obtained with UVES at VLT-UT2 in November 2004 and January 2005. The new data are combined with previously published results to derive abundances for CNO elements as well as FeI and FeII lines. We find that our best-fit model is consistent with previous studies within their uncertainties. However, we obtain significantly lower values for carbon and oxygen than those reported by Gies & Bolton (1986) . This discrepancy may be due to differences between the adopted atmospheric models or atomic data used in these two analyses. \n \n Keywords: Black holes - Abundance ratios - X-ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar winds - Mass transfer -X-ray emission - Accretion disks - Novae - Supernovae",
        "watermark_text": "We report an updated abundance calculation for the dark hole binary nova Sco X - 1 , using on high - resolution optical spectroscopy achieved with UVES at VLT - UT2 in November 2004 and January 2005 . The revised data are coupled with former reported results to derive abundances for CNO objects as well as FeI and FeII lines .We see that our better - fitting model is compatible with previous research within their uncertainties . However , we obtain significantly reduced estimates for carbon and oxygen than those observed by Gies & Bolton ( 1986 ) .This discrepancy may be due to differences between the preferred atmospheric models or atomic data used in these two analyses . Keywords : Black holes - Abundance ratios - X - ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar weather - Mass transmission - X - ray radiation - Accretion disks - Novae - Supernovae",
        "ori-fast-z-score": -0.7878385971583353,
        "water-fast-z-score": 5.3452248382484875
    },
    {
        "original_text": "Carbon nanotubes (CNTs) are promising materials for field emission devices due to their unique physical and chemical properties, such as high aspect ratio, low work function, and excellent mechanical strength.  In this study, we present an integrated multiphysics model that can be used to simulate the system response of CNT-based field emitting diodes (FEDs). The proposed model consists of three sub-models: 1) electron transport in CNT; 2) electrostatic potential distribution; 3) current density distribution. We have developed these models using COMSOL Multiphysics software package with built-in physics modules. To verify our simulation results, we fabricated a CNT-FED device by growing vertically aligned CNTs onto silicon substrate via plasma-enhanced chemical vapor deposition method followed by sputtering gold film over them. Our experimental data show good agreement with simulated results obtained from the proposed model.",
        "watermark_text": "Carbon nanotubes ( CNTs ) are promising technologies for field emission materials due to their different mechanical and biological qualities , such as great aspect value , low work function , and good mechanical strength . In this study , we present an unified multiphysics description that can be used to simulate the process response of CNT - based field emitting diodes ( FEDs ) .The proposed theory involves of three sub - models : 1 ) electron transport in CNT ; 2 ) electrostatic potential distribution ; 3 ) power density flow . We have developed these models using COMSOL Multiphysics programming package with built - in physics elements .To obtain our modeling results , we fabricated a CNT - FED device by spreading vertically aligned CNTs onto silicon substrate via plasma - augmented molecular vapor deposition system followed by sputtering gold film over them . Our research data demonstrate excellent compliance with simulated findings obtained from the suggested model .",
        "ori-fast-z-score": -1.3764944032233704,
        "water-fast-z-score": 5.9648090806346055
    }
]