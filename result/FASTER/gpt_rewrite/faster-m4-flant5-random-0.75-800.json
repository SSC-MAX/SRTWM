[
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Composition of the Pseudoscalar Eta and Eta  Mesons .\nAbstract:\nWe present results on the composition of the eta-prime meson in terms of quarks and gluons, obtained by applying the QCD sum rule method to the correlation function of two pseudoscalars with different flavors.  We find that the eta prime is dominantly composed of strange quark pairs (ss) at low energies but becomes more nonstrange as energy increases. The mass difference between the eta and eta prime mesons can be explained if we assume that the eta prime contains an additional ss pair compared to the eta. This result supports our previous finding based on the analysis of the decay widths of these mesons into pions and kaons. \nPACS numbers: 11.10.Kk, 12.38.Gc, 13 .60.Hb  PACS number(s): 11.10.Kn, 12.38.Bx, 13 .60.Jz",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Composition of the Pseudoscalar Eta and Eta Mesons . Abstract : We report findings on the composition of the eta - prime meson in terms of quarks and gluons , obtained by using the QCD sum rule method to the correlation function of two pseudoscalars with varying flavors .We see that the eta prime is dominantly composed of odd quark pairs ( ss ) at low energies but gets more nonstrange as energy rises . The mass gap between the eta and eta prime mesons can be described if we suppose that the eta prime comprises an additional ss pair relative to the eta .This result confirms our previous finding based on the examination of the decay widths of these mesons into pions and kaons . PACS numbers : 11 . 10 . Kk , 12 . 38 . Gc , 13 . 60 . Hb PACS number ( s ) : 11 . 10 . Kn , 12 . 38 . Bx , 13 . 60 . Jz",
        "rewrite_text": "In this article, we present our research on the composition of the eta-prime meson, focusing on its quark and gluon constituents. Utilizing the QCD sum rule method, we analyze the correlation function of two pseudoscalar mesons with different flavor combinations. Our findings indicate that at lower energy levels, the eta-prime meson is primarily constituted of strange quark pairs (ss). However, as the energy increases, the composition shifts towards a greater presence of non-strange quarks. This transition suggests that the eta-prime meson can be understood as having an additional strange quark pair compared to the eta meson, which accounts for the observed mass difference between the two. This interpretation is further supported by our earlier investigations into the decay widths of these mesons into pions and kaons, reinforcing the connection between quark content and meson properties. Our results contribute to the ongoing discourse in particle physics regarding meson structure and the role of quark flavors in defining meson characteristics. The implications of our findings extend to the understanding of strong interactions and the dynamics of quark-gluon interactions within the framework of Quantum Chromodynamics (QCD). The research is categorized under PACS numbers 11.10.Kk, 12.38.Gc, and 13.60.Hb, reflecting its relevance to theoretical aspects of particle physics and meson decay processes.",
        "ori-fast-z-score": -1.414213562373095,
        "water-fast-z-score": 2.9405881764588204,
        "rewrite-fast-z-score": -0.9649012813540153
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Supernova Remnants and GLAST .\nAbstract:\nThe Large Area Telescope (LAT) on the Fermi Gamma-ray Space Telescope will be launched in June 2008, with an expected launch date of August 7, 2007.  The LAT is designed to detect gamma rays between 20 MeV and 300 GeV over a large field-of-view (2 steradians), making it possible for the first time to study the entire sky at these energies every three hours. This talk will discuss how supernova remnants are likely to appear as sources of high-energy emission when observed by this new instrument. In particular I will focus on:  - How many remnants should we expect to see? - What types of remnants might show up? - What can we learn about particle acceleration mechanisms? - What can we do to prepare for the observations? - Other topics that may come up during discussion. The Large Area Telescope (L AT ) on the Fermi Gamma-ray Sp ace T elescope w ill b e la unched i n J une 2 008 , wi th an ex pected l aunch d ate o f A ugust 7 , 2 007 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Supernova Remnants and GLAST . Abstract : The Large Area Telescope ( LAT ) on the Fermi Gamma - ray Space Telescope will be launched in June 2008 , with an anticipated flight date of August 7 , 2007 .The LAT is designed to identify gamma radiation between 20 MeV and 300 GeV over a large field - of - view ( 2 steradians ) , making it able for the first time to study the entire sky at these energies every three hours . This discussion will explore how supernova remnants are likely to appear as causes of high - energy emitted when observed by this new instrument .In particular I will focus on : - How many traces should we expect to see ? - What kinds of remnants may show up ?- What can we teach about particle acceleration mechanisms ? - What can we do to plan for the discoveries ?- Other topics that might come up during discussion . The Large Area Telescope ( L AT ) on the Fermi Gamma - ray Sp ace T elescope l ill b e la unched i n J une 2 008 , wi th an ex pected r aunch d ate o g A ugust 7 , 2 007 .",
        "rewrite_text": "Title: Supernova Remnants and GLAST\n\nAbstract: The Large Area Telescope (LAT), part of the Fermi Gamma-ray Space Telescope, is set to be launched in June 2008, with a planned launch date of August 7, 2007. This advanced instrument is engineered to detect gamma radiation in the energy range of 20 MeV to 300 GeV, covering an extensive field of view of 2 steradians. This capability enables the LAT to conduct comprehensive observations of the entire sky at these high-energy levels every three hours, marking a significant advancement in astrophysical research. This article will delve into the implications of supernova remnants as potential sources of high-energy gamma radiation, as observed by the LAT. Key areas of focus will include: the expected number of detectable traces from supernova remnants, the types of remnants that may be identified, insights into particle acceleration mechanisms that can be gleaned from these observations, and strategies for preparing for the discoveries that the LAT may unveil. Additionally, the discussion will encompass other relevant topics that may arise during the exploration of supernova remnants and their contributions to our understanding of high-energy astrophysics. Through this investigation, we aim to enhance our comprehension of the role supernova remnants play in the cosmic landscape and their significance in the broader context of gamma-ray astronomy.",
        "ori-fast-z-score": 1.162476387438193,
        "water-fast-z-score": 5.888972745734182,
        "rewrite-fast-z-score": 1.8973665961010275
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Finite Element framework for computation of protein normal modes and mechanical response .\nAbstract:\nWe present an efficient computational method to compute the elastic properties, vibrational frequencies and normal modes of proteins using finite element analysis (FEA). The proposed approach is based on representing each amino acid residue as a single node in a 3D tetrahedral mesh that covers the entire structure of interest. We show how this representation can be used within FEA to efficiently calculate the stiffness matrix associated with the system under study. In addition we demonstrate how the same representation allows us to obtain accurate results when computing the eigenfrequencies and corresponding mode shapes of the system by solving the generalized eigenvalue problem arising from the discretized form of the governing equations. Finally, we illustrate our methodology through several numerical examples involving different types of proteins. Our results indicate that the proposed approach provides highly accurate predictions compared to those obtained via other state-of-the-art methods such as molecular dynamics simulations or coarse-grained models. This work was supported by NSERC Discovery Grants RGPIN-2014-04567 and RGPIN-2016-05189 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Finite Element framework for computation of gene proper modes and mechanical response . Abstract : We create an efficient numerical technique to compute the elastic properties , vibrational speeds and normal mechanisms of proteins using finite element assessment ( FEA ) .The proposed approach is based on depicting each amino residue compound as a single node in a 3D tetrahedral mesh that covers the entire structure of interest . We see how this representation can be used within FEA to easily assess the stiffness matrix associated with the process under research .In addition we prove how the same expression permits us to obtain precise conclusions when computing the eigenfrequencies and corresponding mode shapes of the system by addressing the generalized eigenvalue problem originating from the discretized form of the governing equations . Finally , we exhibit our technique through several mathematical examples involving varying kinds of proteins .Our results show that the suggested approach offers highly precise predictions compared to those achieved via other state - of - the - art methods such as molecular dynamics simulations or rough - grained estimates . This research was supported by NSERC Discovery Grants RGPIN - 2014 - 04567 and RGPIN - 2016 - 05189 .",
        "rewrite_text": "Title: A Finite Element Framework for Computing Gene Proper Modes and Mechanical Response\n\nAbstract: In this study, we present a novel and efficient numerical method for calculating the elastic properties, vibrational frequencies, and normal modes of proteins utilizing finite element analysis (FEA). Our approach involves modeling each amino acid residue as an individual node within a three-dimensional tetrahedral mesh that encompasses the entire protein structure of interest. This representation facilitates the straightforward computation of the stiffness matrix relevant to the mechanical processes being investigated. Furthermore, we demonstrate that the same mathematical framework allows for accurate determination of the eigenfrequencies and corresponding mode shapes of the protein system by solving the generalized eigenvalue problem derived from the discretized governing equations. To validate our methodology, we apply it to a variety of mathematical examples involving different protein types. The results indicate that our proposed technique yields highly accurate predictions, significantly outperforming traditional methods such as molecular dynamics simulations and coarse-grained approximations. This research is supported by the Natural Sciences and Engineering Research Council (NSERC) Discovery Grants RGPIN-2014-04567 and RGPIN-2016-05189, underscoring the robustness and reliability of our findings in the field of computational biology.",
        "ori-fast-z-score": -1.212183053462653,
        "water-fast-z-score": 6.130730673081194,
        "rewrite-fast-z-score": 0.5360562674188973
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Statistical Mechanics of Time Independent Non-Dissipative Nonequilibrium States .\nAbstract:\nThe statistical mechanics of time-independent non-dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation theorem. The main results are formulated for systems with discrete energy levels, but they can be extended to continuous spectrum as well. It is shown that the probability distribution function (PDF) of the total entropy production has an exponential tail at large values of entropy production. This result agrees with recent experimental data on PDFs of heat fluxes between two reservoirs connected by a single molecule junction. In addition it is demonstrated how this approach allows one to calculate the average value of the total entropy production and its fluctuations. Finally we discuss possible applications of these results to transport phenomena in molecular junctions. We show that our theory predicts correctly the dependence of the current-voltage characteristics on temperature difference between the leads. Statistical mechanics of time independent non-dissipative non-equilibrium states is studied within the framework of generalized entropy-production and fluctuation theorem. Main results are formulated for systems having discrete energy-levels, however extension to continuum spectra is also discussed. It is shown that probability-distribution-function (PDF) of total entropy-production has exponential tails at large values of entropy-production. This result agrees with recently obtained experimental data on PDF s of heat-fluxes between two reservoirs coupled via a single-molecule-junction. In addition it is shown how this approach allows us to calculate the average-value of total entropy-production and it s fluctuations. Finally we discuss possibilities of applying these results to transport phenomena occurring in molecular junctions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Statistical Mechanics of Time Independent Non - Dissipative Nonequilibrium States . Abstract : The statistical mechanics of time - based non - dissipative nonequilibrium states is studied in the framework of generalized entropy production and fluctuation principle .The main results are formulated for models with discrete energy levels , but they can be extended to continuous spectrum as also . It is seen that the probability distribution relation ( PDF ) of the total entropy production has an exponential tail at large values of entropy production .This result agrees with recent experimental evidence on PDFs of temperature fluxes between two basins connected by a single molecule interchange . In addition it is demonstrated how this methodology allows one to estimate the average value of the total entropy production and its fluctuations .Finally we explain possible applied of these results to transport phenomena in molecular junctions . We see that our theory predicts correctly the dependence of the current - voltage parameters on temperature difference between the leads .Statistical mechanics of time independent non - dissipative non - equilibrium states is studied within the framework of generalized entropy - production and fluctuation theorem . Main findings are formulated for models having discrete energy - rates , however application to continuum spectra is also discussed .It is demonstrated that probability - distribution - function ( PDF ) of gross entropy - production has exponential tails at large values of entropy - production . This result agrees with lately published research data on PDF s of thermal - fluxes between two basins coupled via a single - atom - junction .In addition it is demonstrated how this methodology allows us to estimate the average - value of total entropy - production and it s fluctuations . Finally we explain options of using these results to transport phenomena occurring in molecular junctions .",
        "rewrite_text": "Title: Statistical Mechanics of Time-Independent Non-Dissipative Nonequilibrium States\n\nAbstract: This article explores the statistical mechanics of time-independent non-dissipative nonequilibrium states through the lens of generalized entropy production and the fluctuation principle. The primary findings are initially presented for models characterized by discrete energy levels, although the implications extend to systems with continuous energy spectra as well. A significant outcome of this study is the identification of an exponential tail in the probability distribution function (PDF) of total entropy production at high entropy values. This observation aligns with recent experimental data concerning the PDFs of thermal fluxes observed between two reservoirs connected by a single-molecule interchange. Furthermore, the methodology developed in this research facilitates the estimation of both the average total entropy production and its associated fluctuations. The practical applications of these findings are discussed, particularly in relation to transport phenomena in molecular junctions. Our theoretical framework successfully predicts the relationship between current-voltage characteristics and the temperature differential between the leads, providing valuable insights into the behavior of molecular systems under nonequilibrium conditions. Overall, this work contributes to a deeper understanding of the statistical mechanics governing non-dissipative processes and offers a robust foundation for future investigations into the thermodynamic properties of molecular junctions and similar systems.",
        "ori-fast-z-score": 1.781196752327939,
        "water-fast-z-score": 7.663582481705323,
        "rewrite-fast-z-score": 2.416841222614159
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Itinerant to localized transition of f electrons in antiferromagnetic superconductor UPd2Al3 .\nAbstract:\nWe report the itinerant-to-localized crossover of 5f electrons in an antiferromagnetically ordered and superconducting compound, UPd2Al3 (Tc = 3 K). The temperature dependence of electrical resistivity shows that the system undergoes a metal-insulator-like transition at TMI ~ 50 K with a large residual resistance ratio RRR = 300. This is accompanied by a change in the electronic structure as revealed by x-ray photoemission spectroscopy measurements. We find that the Fermi surface volume decreases rapidly below TMIl while the density-of-states near EF increases significantly. These results suggest that the magnetic ordering plays an important role for the formation of heavy fermion state in this material. Heavy-fermion compounds are characterized by their unique physical properties such as high specific heat coefficient γ, enhanced Pauli susceptibility χp, and large effective mass m*. In these materials, strong hybridization between conduction electron states and localized 4f or 5f orbitals leads to the formation of heavy quasiparticles which give rise to many interesting phenomena including unconventional superconductivity1-5 . However, it has been difficult to understand how the local moments interact with each other because they often order magnetically at low temperatures6-8 .\nRecently, several new classes of heavy-fermion systems have been discovered9-12 , where the local moments do not order magnetically down to very low temperatures13-15 . For example, YbMgGaO16 does not show any sign of magnetic ordering down to 0.03 K14-16 . It was suggested that the lack of magnetic ordering may be due to quantum fluctuations caused by the proximity effect17-19 . Another possibility is that the ground-state wave function becomes more complex than simple product of single-site wave functions20-22 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Itinerant to localized transition of f electrons in antiferromagnetic superconductor UPd2Al3 . Abstract : We report the itinerant - to - localized crossover of 5f electrons in an antiferromagnetically ordered and superconducting compound , UPd2Al3 ( Tc = 3 K ) .The temperature dependence of electrical resistivity reveals that the process undergoes a metal - insulator - like transition at TMI ~ 50 K with a large residual resistance ratio RRR = 300 . This is accompanied by a change in the electronic structure as revealed by x - ray photoemission spectroscopy observations .We see that the Fermi surface volume decreases quickly below TMIl while the density - of - states near EF increases strongly . These conclusions show that the magnetic ordering plays an important role for the formation of heavy fermion state in this material .Heavy - fermion compounds are known by their distinct physical properties such as great specific hot coefficient γ , enhanced Pauli susceptibility χp , and large effective mass m * . In these structures , deep hybridization between conduction ion states and localized 4f or 5f orbitals causes to the formation of heavy quasiparticles which provide rise to many interesting phenomena including unconventional superconductivity1 - 5 .However , it has been difficult to explain how the local moments interact with each other because they frequently order magnetically at low temperatures6 - 8 . Recently , various new classes of heavy - fermion systems have been discovered9 - 12 , where the local moments do not order magnetically down to very low temperatures13 - 15 .For instance , YbMgGaO16 does not show any sign of magnetic ordering down to 0 . 03 K14 - 16 . It was suggested that the lack of magnetic ordering might be due to quantum fluctuations made by the proximity effect17 - 19 .Another possibility is that the ground - state wave function becomes more sophisticated than simple combination of fixed - location wave functions20 - 22 .",
        "rewrite_text": "**Title:** Itinerant to Localized Transition of f Electrons in Antiferromagnetic Superconductor UPd2Al3\n\n**Abstract:** In this study, we investigate the transition of 5f electrons from an itinerant to a localized state in the antiferromagnetically ordered and superconducting compound UPd2Al3, which exhibits a superconducting transition temperature (Tc) of 3 K. Our analysis of the temperature-dependent electrical resistivity indicates a metal-insulator-like transition occurring at approximately TMI ~ 50 K, characterized by a significant residual resistance ratio (RRR) of 300. This transition is accompanied by notable changes in the electronic structure, as evidenced by x-ray photoemission spectroscopy (XPS) measurements. Specifically, we observe a rapid decrease in the volume of the Fermi surface below TMI, alongside a substantial increase in the density of states near the Fermi level (EF). These findings suggest that magnetic ordering plays a crucial role in the emergence of the heavy fermion state within UPd2Al3.\n\nHeavy-fermion materials are recognized for their unique physical characteristics, including a high specific heat coefficient (γ), enhanced Pauli susceptibility (χp), and a large effective mass (m*). The interplay between conduction electron states and localized 4f or 5f orbitals leads to the formation of heavy quasiparticles, which are responsible for a variety of intriguing phenomena, including unconventional superconductivity. However, understanding the interactions among local moments remains challenging, particularly as these moments often exhibit magnetic ordering at low temperatures. Recently, new classes of heavy-fermion systems have emerged, where local moments do not exhibit magnetic ordering even at very low temperatures. For example, YbMgGaO demonstrates no signs of magnetic ordering down to 0.03 K. It has been proposed that the absence of magnetic ordering may stem from quantum fluctuations associated with the proximity effect. Alternatively, it is possible that the ground-state wave function becomes more complex than a simple combination of fixed-location wave functions. This study contributes to the ongoing exploration of heavy-fermion systems and their underlying mechanisms.",
        "ori-fast-z-score": 0.7071067811865475,
        "water-fast-z-score": 5.262348115842175,
        "rewrite-fast-z-score": -0.08247860988423225
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Scanning magnetoresistance microscopy of atom chips .\nAbstract:\nWe report scanning magnetoresistance microscopy (SMRM) measurements on an atom chip with gold wires and microtraps fabricated by focused ion beam milling. The SMRM images show the magnetic field distribution in the vicinity of the wire structures, which are used to transport cold atoms between different trapping sites. We find that the magnetic fields generated by these wires can be accurately described using Biot-Savart s law for straight current-carrying conductors. In addition we observe small deviations from this model at distances below 100 nm from the surface of the wires. These deviations may arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their surfaces. Our results demonstrate that SMRM is well suited to study complex magnetic field distributions near microscopic objects such as atom chips. Atom chips have been developed over recent years as miniaturized devices for manipulating neutral atomic matter waves  1, 2  . They consist of arrays of metallic wires and microtraps produced by focused-ion-beam (FIB) milling  3  , where ultracold atoms are transported along the wires before being trapped in the microtraps  4  .\nIn order to optimize the performance of atom chips it is important to understand how the magnetic fields created by the wires affect the motion of the atoms. This requires detailed knowledge about the spatial structure of the magnetic fields around the wires. However, direct measurement techniques like SQUID-based magnetometry  5  cannot resolve the magnetic field distribution inside the wires because they are too thin  6  . Therefore indirect methods based on imaging the trajectories of atoms released from traps  7, 8  or measuring the forces acting on them  9  were employed instead. Recently, scanning Hall probe microscopy was applied to measure the local magnetic field strength  10  . Here we present scanning magnetoresistance microscopy  11  data obtained on an atom chip consisting of two parallel gold wires connected via a junction  12  . By comparing our experimental results with theoretical predictions we obtain information about the magnetic field distribution in proximity of the wires.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Scanning magnetoresistance microscopy of atom devices . Abstract : We report scanning magnetoresistance microscopy ( SMRM ) observations on an atom chip with gold wires and microtraps fabricated by concentrated ion beam milling .The SMRM pictures show the magnetic field spread in the vicinity of the wire structures , which are used to transport cold molecules between various trap places . We see that the magnetic fields generated by these cables can be correctly explained using Biot - Savart s law for straight current - transporting conductors .In addition we perceive tiny deviations from this model at distances below 100 nm from the surface of the wires . These deviations might arise due to stray currents induced in the substrate or due to nontrivial geometries of the wires close to their edges .Our results show that SMRM is well suited to study difficult magnetic field distributions near microscopic structures such as atom devices . Atom devices have been built over recent months as miniaturized devices for manipulating neutral atomic matter waves 1 , 2 .They comprise of arrays of metallic wires and microtraps produced by concentrated - ion - laser ( FIB ) processing 3 , where ultracold atoms are transported along the wires before being trapped in the microtraps 4 . In order to optimize the performance of atom devices it is important to realize how the magnetic fields produced by the wires affect the movement of the atoms .This requires complete understanding about the spatial shape of the magnetic fields around the wires . However , direct detection methods like SQUID - based magnetometry 5 cannot determine the magnetic field spread inside the wires because they are too thin 6 .Therefore indirect approaches derived on observing the trajectories of atoms released from nets 7 , 8 or measuring the forces working on them 9 were utilized instead . Recently , scanning Hall probe microscopy was used to measure the local magnetic field intensity 10 .Here we present scanning magnetoresistance microscopy 11 data acquired on an atom chip comprised of two connected gold wires coupled via a junction 12 . By matching our experimental results with theoretical predictions we obtain knowledge about the magnetic field spread in proximity of the wires .",
        "rewrite_text": "We present a detailed study utilizing scanning magnetoresistance microscopy (SMRM) to investigate the magnetic field distributions around an atom chip composed of gold wires and microtraps, which were fabricated using concentrated ion beam milling techniques. The SMRM images reveal the magnetic field patterns surrounding these wire structures, which play a crucial role in the transport of cold molecules between various trapping locations. Our findings indicate that the magnetic fields generated by the wires can be accurately described by Biot-Savart's law, applicable to straight conductors carrying current. However, we also observe minor deviations from this theoretical model at distances less than 100 nm from the wire surfaces. These discrepancies may be attributed to stray currents induced in the substrate or the complex geometries of the wires near their edges.\n\nThe significance of our results lies in demonstrating that SMRM is an effective tool for examining intricate magnetic field distributions in microscopic structures, such as atom devices. These atom devices, developed in recent months, are miniaturized systems designed for the manipulation of neutral atomic matter waves. They consist of arrays of metallic wires and microtraps created through focused ion beam (FIB) processing, allowing for the transport of ultracold atoms along the wires before they are captured in the microtraps. Understanding the influence of the magnetic fields produced by these wires on atomic movement is essential for optimizing the performance of atom devices, necessitating a comprehensive understanding of the spatial characteristics of the magnetic fields around the wires.\n\nTraditional direct detection methods, such as SQUID-based magnetometry, are inadequate for measuring the magnetic field distribution within the thin wires. Consequently, researchers have relied on indirect methods, including the observation of atom trajectories and the measurement of forces acting on them. Recently, scanning Hall probe microscopy has been employed to assess local magnetic field intensity. In this study, we present SMRM data obtained from an atom chip featuring two interconnected gold wires linked by a junction. By correlating our experimental observations with theoretical models, we enhance our understanding of the magnetic field distribution in the vicinity of these wires.",
        "ori-fast-z-score": -0.8994380267950337,
        "water-fast-z-score": 7.00634632949934,
        "rewrite-fast-z-score": 0.3716470731235832
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Driving Mechanism of Jets and Outflows in Star Formation Process .\nAbstract:\nThe driving mechanism for jets and outflows is still an open question, especially when the jet/outflow source has no clear central engine such as black holes or protostars. In this work we propose that magnetic reconnection can be responsible for launching jets and outflows in star formation process. We show that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks driven by the reconnecting current sheet (RCS). The accelerated electrons will produce synchrotron emission which may explain radio observations of jets and outflows. Furthermore, the energetic protons produced during RCS also contribute to nonthermal emissions through inverse Compton scattering with background photons. Finally, we discuss how our model could account for some observational features of jets and outflows. \n \n Keywords: Magnetic reconnection; Jet; Particle acceleration; Shocks; Synchrotron radiation; Nonthermal emission",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Driving Mechanism of Jets and Outflows in Star Formation Process . Abstract : The driving system for rockets and outflows is already an open matter , particularly when the jet / outflow source has no clear central fuel such as black holes or protostars .In this research we propose that magnetic reconnection can be responsible for launching jets and outflows in star formation system . We suggest that magnetic reconnection can accelerate particles to relativistic energies efficiently via Fermi acceleration at shocks driven by the reconnecting current sheet ( RCS ) .The enhanced electrons will generate synchrotron emission which would cause radio observations of jets and outflows . Furthermore , the energetic protons created during RCS also contribute to nonthermal emissions through inverse Compton absorption with background photons .Finally , we explain how our model could account for some observational characteristics of jets and outflows . Keywords : Magnetic reconnection ; Jet ; Particle acceleration ; Shocks ; Synchrotron emission ; Nonthermal emission",
        "rewrite_text": "Title: Driving Mechanism of Jets and Outflows in the Star Formation Process\n\nAbstract: The mechanisms underlying the generation of jets and outflows in star formation remain a topic of significant interest, particularly in scenarios where the source lacks a distinct central fuel source, such as black holes or protostars. In this study, we propose that magnetic reconnection plays a crucial role in the initiation of jets and outflows within star-forming systems. Our hypothesis posits that magnetic reconnection can effectively accelerate particles to relativistic speeds through a process known as Fermi acceleration, which occurs at shocks produced by reconnecting current sheets (RCS). The accelerated electrons resulting from this process are expected to emit synchrotron radiation, which can be detected in radio observations of jets and outflows. Additionally, the energetic protons generated during the magnetic reconnection events contribute to nonthermal emissions via inverse Compton scattering with background photons. We further elaborate on how our model aligns with various observational features associated with jets and outflows, providing a comprehensive framework for understanding these phenomena. Our findings suggest that magnetic reconnection is a fundamental mechanism that not only drives the dynamics of jets and outflows but also influences their observable characteristics, thereby enhancing our understanding of the star formation process. \n\nKeywords: Magnetic reconnection; Jet; Particle acceleration; Shocks; Synchrotron emission; Nonthermal emission.",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 3.8247315498700596,
        "rewrite-fast-z-score": 2.4494897427831783
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Search for the radiative leptonic decay B+ --> gamma l+ nu .\nAbstract:\nThe search is performed using data collected by the BABAR experiment at SLAC in 1999-2000, corresponding to an integrated luminosity of about 40 fb-1 . No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair.  These results improve upon previous measurements made with similar techniques but smaller datasets. The analysis uses a technique that exploits the kinematic properties of the final state particles to suppress backgrounds. This method has been used previously to measure the branching fractions of other rare decays such as B+ --> K*(892)0 pi+ , B+ --> D*0 pi+ , and B+ --> J/psi K- .\nPACS numbers: 11.30.Er, 12.15.Hh, 13.20.He  We report here our measurement of the branching fraction for the decay B+ --> gamma +l+nu (where l = e or mu), which proceeds through one-loop electroweak penguin diagrams involving W bosons and heavy quarks. In this process, the photon arises from the internal bremsstrahlung of the charged lepton produced in association with the neutrino. The Standard Model predicts a branching fraction of 1.1 x 10-6  1  . A number of extensions to the Standard Model predict enhancements over this value  2  .  For example, supersymmetric models can enhance the rate by several orders of magnitude  3  ; however, these predictions depend strongly on the masses of the superpartners involved  4  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Search for the radiative leptonic emission B + - - > gamma l + nu . Abstract : The search is conducted using data taken by the BABAR study at SLAC in 1999 - 2000 , corresponding to an integrated luminosity of about 40 fb - 1 .No signal candidates are observed and upper limits on the branching fraction are set as a function of the mass of the lepton pair . These data improve upon recent observations made with similar method but smaller datasets .The calculation utilizes a technique that exploits the kinematic effects of the finished state particles to suppress backgrounds . This method has been used earlier to measure the branching fractions of other rare decays such as B + - - > K * ( 892 ) 0 pi + , B + - - > D * 0 pi + , and B + - - > J / psi K - .PACS codes : 11 . 30 . Er , 12 . 15 . Hh , 13 . 20 . He We report here our measurement of the branching percentage for the decay B + - - > gamma + r + nu ( where l = e or mu ) , which goes through one - ring electroweak penguin diagrams using W bosons and heavy quarks . In this process , the photon arises from the internal bremsstrahlung of the charged lepton generated in association with the neutrino .The Standard Model predicts a branching fraction of 1 . 1 x 10 - 6 1 . A variety of extensions to the Standard Model predict enhancements over this value 2 .For instance , supersymmetric theories can increase the rate by many orders of magnitude 3 ; however , these predictions rely highly on the masses of the superpartners participating 4 .",
        "rewrite_text": "**Title:** Search for Radiative Leptonic Emission B+ → γl+ν\n\n**Abstract:** This study presents a comprehensive search for the radiative leptonic decay B+ → γl+ν, utilizing data collected by the BABAR experiment at SLAC during the years 1999 to 2000, which corresponds to an integrated luminosity of approximately 40 fb⁻¹. In our analysis, we did not observe any signal candidates for the decay process, leading us to establish upper limits on the branching fraction as a function of the lepton pair mass. These findings enhance previous measurements obtained through similar methodologies but with smaller datasets, thereby providing a more robust constraint on the decay process.\n\nTo effectively suppress background noise, we employed a sophisticated technique that leverages the kinematic properties of the final state particles. This approach has previously been utilized in measuring the branching fractions of other rare decay processes, including B+ → K*(892)⁰π⁺, B+ → D*⁰π⁺, and B+ → J/ψK⁻. Our investigation specifically focuses on the decay B+ → γl+ν, where l can be either an electron or a muon, which is mediated by one-loop electroweak penguin diagrams involving W bosons and heavy quarks. In this decay, the emitted photon originates from the internal bremsstrahlung associated with the charged lepton produced alongside the neutrino.\n\nAccording to the Standard Model, the predicted branching fraction for this decay is approximately 1.1 x 10⁻⁶. However, various extensions to the Standard Model suggest potential enhancements to this prediction. For example, supersymmetric theories indicate that the decay rate could be significantly increased, potentially by several orders of magnitude, although such predictions are heavily dependent on the masses of the superpartners involved. Our results contribute to the ongoing efforts to probe the limits of the Standard Model and explore the implications of new physics beyond its framework. \n\n**PACS Codes:** 11.30.Er, 12.15.Hh, 13.20.He",
        "ori-fast-z-score": -2.2691267417693455,
        "water-fast-z-score": 4.206511243549132,
        "rewrite-fast-z-score": -1.2888044650576527
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A fundamental explanation for the tiny value of the cosmological constant .\nAbstract:\nThe observed smallness of the vacuum energy density is one of the most puzzling problems in physics today, and it has been suggested that this problem may be solved by considering quantum gravity effects on the vacuum fluctuations.  In this work we show how such an effect can arise naturally within the context of loop quantum gravity (LQG). We consider a model where the gravitational field is quantized using LQG techniques while matter fields are treated classically. The resulting effective action contains terms which depend explicitly on the scale factor of the universe as well as its time derivatives. These terms lead to corrections to the standard Friedmann equations at high energies. Using these modified equations together with observational data we find that the present day value of the vacuum energy density agrees very well with observations if the initial conditions are chosen appropriately. This result suggests that our approach provides a natural solution to the cosmological constant problem. The observed smallness of the cosmological constant poses one of the greatest challenges facing modern theoretical physics  1  . It is generally believed that quantum gravity will play an important role in understanding why the vacuum energy density associated with quantum fluctuations of all fields is so much smaller than what would naively be expected  2  .\nIn recent years there have been several attempts to address this issue within the framework of loop quantum gravity  3  -  8  , but none of them seem to provide a satisfactory answer  9  . In particular, the results obtained in Refs.  6  -  8  do not agree with each other or with current experimental bounds  10  . Here we propose a new mechanism based on ideas developed recently in Ref.  11  . Our starting point is the observation that the Wheeler-DeWitt equation derived from the canonical formulation of general relativity leads to modifications of the usual Schrödinger equation when applied to states describing macroscopic systems  12  . As shown in Ref.  13  , these modifications can be interpreted as arising due to the presence of additional degrees of freedom corresponding to the gravitational field itself.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A essential account for the tiny value of the cosmological constant . Abstract : The observed smallness of the vacuum energy density is one of the most puzzling difficulties in science today , and it has been proposed that this question could be answered by exploring quantum gravitational impacts on the vacuum fluctuations .In this research we show how such an effect can arise naturally within the context of loop quantum gravitational ( LQG ) . We consider a theory where the gravitational field is quantized use LQG techniques while matter fields are treated classically .The resulting effective action contains terms which depend explicitly on the scale factor of the universe as well as its time functions . These terms lead to corrections to the standard Friedmann equations at high energies .Using these modified equations together with observational data we find that the present day value of the vacuum energy density agrees very best with observations if the first conditions are chosen properly . This result suggests that our approach offers a natural solution to the cosmological coefficient question .The observed smallness of the cosmological constant presents one of the greatest challenges facing current theoretical physics 1 . It is usually thought that quantum gravitational will take an important role in understanding why the vacuum energy density associated with quantum fluctuations of all fields is so much smaller than what would naively be anticipated 2 .In recent years there have been numerous attempts to tackle this question within the framework of loop quantum gravitational 3 - 8 , but none of them seem to provide a adequate answer 9 . In particular , the results derived in Refs .6 - 8 do not comply with each other or with current experimental bounds 10 . Here we propose a new method using on ideas developed lately in Ref .11 . Our starting point is the observation that the Wheeler - DeWitt equation derived from the canonical representation of general relativity leads to modifications of the usual Schrödinger equation when applied to states describing macroscopic systems 12 .As seen in Ref . 13 , these alterations can be interpreted as occurring due to the presence of added degrees of freedom corresponding to the gravitational field itself .",
        "rewrite_text": "**Title:** A Fundamental Explanation for the Minuscule Value of the Cosmological Constant\n\n**Abstract:** The remarkably small value of vacuum energy density poses one of the most significant challenges in contemporary physics. This article explores the hypothesis that quantum gravitational effects on vacuum fluctuations may provide insight into this perplexing issue. We present a framework grounded in loop quantum gravity (LQG), where the gravitational field is quantized using LQG methodologies while matter fields are treated classically. This approach yields an effective action that incorporates terms explicitly dependent on the universe's scale factor and its temporal derivatives. These modifications result in corrections to the standard Friedmann equations, particularly at high energy levels. By applying these revised equations in conjunction with observational data, we demonstrate that the current value of vacuum energy density aligns closely with empirical observations when initial conditions are judiciously selected. This finding indicates that our framework may offer a compelling resolution to the cosmological constant problem.\n\nThe enigma surrounding the smallness of the cosmological constant is a pressing concern in theoretical physics. It is widely believed that quantum gravitational phenomena are crucial for elucidating why the vacuum energy density, which arises from quantum fluctuations across various fields, is significantly lower than naive expectations suggest. Recent years have witnessed numerous attempts to address this issue within the loop quantum gravity paradigm; however, these efforts have often yielded inconsistent results that fail to align with experimental constraints. Notably, previous studies have produced findings that are not only contradictory to one another but also at odds with current observational limits.\n\nIn this paper, we introduce a novel approach inspired by recent advancements in the field. Our analysis begins with the Wheeler-DeWitt equation, derived from the canonical formulation of general relativity, which reveals modifications to the conventional Schrödinger equation when applied to macroscopic systems. These modifications can be interpreted as the emergence of additional degrees of freedom associated with the gravitational field itself. This perspective may pave the way for a deeper understanding of the cosmological constant and its implications for the universe's structure and evolution.",
        "ori-fast-z-score": 0.8268106308031118,
        "water-fast-z-score": 7.345410552159442,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dynamic condensation of water at crack tips in fused silica glass .\nAbstract:\nWe report the observation of dynamic condensation of water vapor on crack tips during slow fracture experiments performed under vacuum conditions (10-6 mbar) and low temperature (77 K). The condensed water is found to be localized along the crack front, where it forms a thin film that covers the entire surface of the crack tip. This phenomenon has been observed for cracks propagating both perpendicularly and parallel to the direction of maximum tensile stress. We propose a model based on molecular dynamics simulations which explains this effect by considering the presence of an electric field generated by the moving crack tip. In addition we show how the formation of such films can affect the mechanical properties of the material. Condensation phenomena are ubiquitous in nature but have rarely been reported in materials science. Here we present experimental evidence showing that water condenses onto the crack surfaces when they propagate through fused silica glasses. These results were obtained using a combination of optical microscopy techniques with environmental scanning electron microscopy (ESEM), Raman spectroscopy and infrared reflection absorption spectroscopy (IRAS).",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dynamic condensation of liquid at crack tips in fused silica glass . Abstract : We report the observation of static condensation of water vapor on break tips during slow fracture studies performed under vacuum environments ( 10 - 6 mbar ) and low heat ( 77 K ) .The condensed water is found to be localized along the crack front , where it creates a thin film that covers the entire surface of the crack tip . This phenomenon has been observed for fracture propagating both perpendicularly and parallel to the direction of maximum tensile tension .We suggest a theory based on molecular dynamics simulations which explains this effect by examining the presence of an electric field produced by the moved crack edge . In addition we explain how the formation of such films can affect the mechanical behavior of the material .Condensation problems are ubiquitous in nature but have seldom been reported in materials science . Here we present research proof showing that water condenses onto the crack surfaces when they propagate through fused silica glasses .These conclusions were obtained using a combination of optical microscopy methods with environmental scan electron microscopy ( ESEM ) , Raman spectroscopy and infrared reflection spectral spectroscopy ( IRAS ) .",
        "rewrite_text": "We present findings on the dynamic condensation of water vapor at crack tips in fused silica glass, observed during slow fracture experiments conducted in vacuum conditions (10^-6 mbar) and at low temperatures (77 K). Our study reveals that water vapor condenses statically along the crack front, forming a thin film that uniformly covers the entire surface of the crack tip. This condensation phenomenon occurs irrespective of the crack propagation direction, whether perpendicular or parallel to the maximum tensile stress. To elucidate this effect, we propose a theoretical framework grounded in molecular dynamics simulations, which highlights the influence of an electric field generated by the movement of the crack edge. Furthermore, we discuss the implications of such thin film formation on the mechanical properties of the material, suggesting that the presence of condensed water could significantly alter fracture behavior. Although condensation processes are prevalent in various natural phenomena, they have been infrequently documented within the realm of materials science. Our research provides compelling evidence that water vapor condenses on crack surfaces as they advance through fused silica glass. The conclusions drawn from this study are supported by a multifaceted approach, utilizing optical microscopy, environmental scanning electron microscopy (ESEM), Raman spectroscopy, and infrared reflection absorption spectroscopy (IRAS). This comprehensive investigation not only enhances our understanding of crack behavior in silica glass but also opens avenues for further research into the role of moisture in material fracture mechanics.",
        "ori-fast-z-score": -0.40406101782088427,
        "water-fast-z-score": 5.454823740581938,
        "rewrite-fast-z-score": 0.09166984970282113
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Domain wall switching: optimizing the energy landscape .\nAbstract:\nWe propose an alternative switching mechanism for spintronic devices based on domain walls (DWs). The proposed device consists of two ferromagnetic layers separated by a non-magnetic spacer layer, where DWs can be driven between different positions in each magnetic layer using spin-orbit torques and electric fields. We show that this new type of device is able to operate at lower current densities than conventional spin valves with comparable magnetoresistance values. In addition we demonstrate how the energy barrier associated with the motion of the DWs can be tuned through changes in the thicknesses of both the ferromagnets and the non-magnetic spacer. This allows us to optimize the energy landscape such that the DWs are trapped in their equilibrium position when no external field or voltage bias is applied. Finally, we discuss possible applications of our proposal as well as its limitations. Spintronics has emerged over recent years as one of the most promising technologies for future information processing systems  1  . One of the main challenges faced by these devices is the development of efficient ways to control the flow of charge carriers without compromising their high mobility  2  .\nIn order to overcome this problem several groups have recently investigated the possibility of controlling the direction of electron transport via the manipulation of magnetic textures  3  , which include vortex states  4  , skyrmions  5  and domain walls  6  . Domain walls are particularly interesting since they can be manipulated electrically  7, 8  and thermally  9  , making them ideal candidates for low-power consumption devices  10  . However, despite significant progress made towards understanding the physics behind the dynamics of domain walls  11  , there remains much uncertainty about the exact nature of the mechanisms responsible for driving their motion  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Domain wall switching : optimizing the electricity landscape . Abstract : We suggest an additional switching method for spintronic systems based on domain barriers ( DWs ) .The proposed machine consists of two ferromagnetic layers divided by a non - magnetic spacer membrane , where DWs can be pushed between various positions in each magnetic layer using spinning - orbit torques and electric forces . We see that this new kind of device is could to run at lower current densities than conventional spin tubes with similar magnetoresistance ratings .In addition we prove how the electricity barrier associated with the movement of the DWs can be tuned through alterations in the thicknesses of both the ferromagnets and the non - magnetic spacer . This enables us to optimize the electricity landscape such that the DWs are locked in their stable position when no external field or voltage bias is applied .Finally , we review possible use of our proposal as well as its limitations . Spintronics has emerged over recent years as one of the most attractive devices for future data processing applications 1 .One of the main problems faced by these machines is the development of effective means to affect the movement of charge carriers without compromising their high mobility 2 . In try to overcome this situation several organizations have recently examined the prospect of controlling the direction of electron transport via the manipulation of magnetic textures 3 , which contain vortex states 4 , skyrmions 5 and domain barriers 6 .Domain barriers are particularly attractive since they can be manipulated electrically 7 , 8 and thermally 9 , making them ideal candidates for low - energy consumption devices 10 . However , despite considerable progress made towards studying the physics behind the dynamics of domain walls 11 , there exists much uncertainty about the exact nature of the mechanisms involved for controlling their motion 12 .",
        "rewrite_text": "**Title: Domain Wall Switching: Optimizing the Electrical Landscape**\n\n**Abstract:** In this study, we introduce a novel switching mechanism for spintronic systems that leverages domain walls (DWs) as a means of enhancing device performance. Our proposed architecture consists of two ferromagnetic layers separated by a non-magnetic spacer membrane, allowing for the manipulation of DWs within each magnetic layer through spin-orbit torques and electric forces. Notably, our findings indicate that this innovative device can operate at significantly lower current densities compared to traditional spintronic devices with equivalent magnetoresistance characteristics. Furthermore, we demonstrate that the electrical barrier associated with DW movement can be finely tuned by adjusting the thickness of both the ferromagnetic layers and the non-magnetic spacer. This tunability facilitates the optimization of the electrical landscape, ensuring that DWs remain in a stable position in the absence of external fields or voltage biases.\n\nWe also explore the potential applications of our proposed mechanism, while acknowledging its limitations. Spintronics has gained traction in recent years as a promising technology for future data processing applications. A critical challenge in this field is the need for effective methods to influence the movement of charge carriers without sacrificing their high mobility. To address this issue, various research groups have investigated the possibility of controlling electron transport direction through the manipulation of magnetic textures, including vortex states, skyrmions, and domain barriers. Among these, domain barriers stand out due to their ability to be manipulated both electrically and thermally, positioning them as ideal candidates for low-energy consumption devices. Despite significant advancements in understanding the dynamics of domain walls, there remains considerable uncertainty regarding the precise mechanisms that govern their motion. This study aims to contribute to this evolving field by providing insights into the optimization of domain wall switching and its implications for future spintronic applications.",
        "ori-fast-z-score": -0.7423074889580903,
        "water-fast-z-score": 8.110396013138502,
        "rewrite-fast-z-score": 1.1281521496355325
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Parity violation in hydrogen revisited .\nAbstract:\nThe parity violating asymmetry in the scattering of polarized electrons off unpolarized protons is measured at Jefferson Lab to determine the proton s weak charge with an uncertainty comparable to that achieved for the electron and neutron.  The experiment uses longitudinally polarized electrons produced by CEBAF, which are scattered off a liquid hydrogen target located inside Hall A. The data were taken during two experimental runs between October 2009 and May 2011 using beam currents ranging from 0.5 nA to 1.0 µA. This measurement improves upon previous results obtained at SLAC (1998) and JLab (2005), where systematic uncertainties dominated over statistical ones. In this analysis we have reduced these systematics significantly through improved understanding of the detector response as well as new techniques used to extract the signal. We find Qweak = -0.0018 ± 0.0007(stat.) ± 0.0003(syst.), consistent with Standard Model predictions within one standard deviation.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Parity violation in hydrogen revisited . Abstract : The parity violating asymmetry in the scattering of polarized nuclei off unpolarized protons is measured at Jefferson Lab to identify the proton s weak charge with an uncertainty comparable to that attained for the electron and neutron .The project utilizes longitudinally polarized particles generated by CEBAF , which are scattered off a liquid fuel target located inside Hall A . The data were took during two test runs between October 2009 and May 2011 using beam currents ranging from 0 . 5 nA to 1 . 0 µA .This measurement improves upon previous findings obtained at SLAC ( 1998 ) and JLab ( 2005 ) , where systematic uncertainties prevailed over empirical ones . In this analysis we have reduced these systematics substantially through improved understanding of the detector response as well as modern procedures used to extract the signal .We get Qweak = - 0 . 0018 ± 0 . 0007 ( stat . ) ± 0 . 0003 ( syst .) , compatible with Standard Model estimates within one standard deviation .",
        "rewrite_text": "**Title:** Revisiting Parity Violation in Hydrogen\n\n**Abstract:** This study presents a comprehensive measurement of the parity-violating asymmetry in the scattering of polarized nuclei from unpolarized protons, conducted at Jefferson Lab. The primary aim of this research is to determine the weak charge of the proton with an uncertainty level that is comparable to that achieved for both the electron and neutron. The experimental setup involved the use of longitudinally polarized particles produced by the Continuous Electron Beam Accelerator Facility (CEBAF), which were directed towards a liquid hydrogen target situated within Hall A. Data collection occurred during two test runs between October 2009 and May 2011, utilizing beam currents that varied from 0.5 nA to 1.0 µA. \n\nThis measurement represents a significant advancement over earlier experiments conducted at SLAC in 1998 and JLab in 2005, where systematic uncertainties overshadowed empirical results. In our analysis, we have successfully minimized these systematic uncertainties through a refined understanding of the detector's response and the implementation of modern signal extraction techniques. The results yield a weak charge measurement of Qweak = -0.0018 ± 0.0007 (statistical uncertainty) ± 0.0003 (systematic uncertainty), which aligns with Standard Model predictions within one standard deviation. This work not only enhances the precision of weak charge measurements but also contributes to the broader understanding of parity violation in fundamental interactions, reinforcing the significance of experimental physics in testing theoretical frameworks.",
        "ori-fast-z-score": -0.3721042037676254,
        "water-fast-z-score": 5.0854241181575475,
        "rewrite-fast-z-score": 1.5554275420956378
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Circular and non-circular nearly horizon-skimming orbits in Kerr spacetimes .\nAbstract:\nWe study the circular and non-circular motion near the event horizons of rotating black holes by using the Hamilton-Jacobi method, which is an extension of the standard geodesic approach to include higher-order corrections due to gravitational radiation reaction effects. We find that for both circular and non-circular motions there exist two families of solutions with different orbital frequencies at the same radius. The inner family has smaller orbital frequency than the outer one; it corresponds to bound orbits while the outer solution describes unbound orbits. For circular orbits we show how these results can be obtained directly from the first law of black hole mechanics. In addition, we also present numerical evidence showing that the innermost stable circular orbit (ISCO) moves inward as the spin parameter increases. Finally, we discuss some implications of our results on astrophysical phenomena such as accretion disks around spinning black holes. Introduction -The discovery of the first binary pulsar PSR1913+16  1  , together with its subsequent measurement of the mass ratio between the neutron star and its companion white dwarf  2  , led to the prediction  3  that most likely all massive stars end their lives as black holes surrounded by accretion disks  4  . Since then many other observations have been made confirming this picture  5  .\nIn order to understand the dynamics of matter falling into black holes, it is important to know where particles are trapped or scattered out  6  . This information is encoded in the location of the so-called Innermost Stable Circular Orbit (ISCO), i.e., the smallest possible radius r ISCO of a particle s circular orbit  7, 8  . It turns out that the value of r ISCO depends sensitively on the spin angular momentum J = Ma 2 /(2r g ) of the black hole  9  : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO decreases rapidly until finally it reaches the Schwarzschild radius R s ≡ 2GM/c 2  10  . Therefore, knowing the exact position of the ISCO will help us better understand the physics behind various processes taking place close to",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Circular and non - circular nearly horizon - skimming orbits in Kerr spacetimes . Abstract : We study the circular and non - circular motion near the event horizons of spinning black holes by using the Hamilton - Jacobi method , which is an extension of the standard geodesic approach to use larger - order corrections due to gravitational radiation process effects .We see that for both circular and non - circular movements there exist two families of solutions with various orbital frequencies at the same radius . The outer family has less orbital frequency than the inner one ; it corresponds to bound orbits while the inner solution refers unbound orbits .For circular orbits we prove how these results can be obtained directly from the first law of black hole mechanics . In addition , we also provided quantitative proof showing that the innermost stable spherical orbit ( ISCO ) changes inward as the spin parameter grows .Finally , we talk some implications of our findings on astrophysical processes such as accretion disks around moving black holes . Introduction - The observation of the first binary pulsar PSR1913 + 16 1 , combined with its subsequent calculation of the mass ratio between the neutron star and its companion dark dwarf 2 , leading to the prediction 3 that most likely all large galaxies begin their careers as black holes surrounded by accretion disks 4 .Since then many other experiments have been made confirming this picture 5 . In order to comprehend the dynamics of matter falling into black holes , it is important to consider where objects are captured or scattered out 6 .This information is stored in the location of the so - called Innermost Stable Circular Orbit ( ISCO ) , i . e . , the smallest available diameter r ISCO of a particle s circular orbit 7 , 8 . It turns out that the value of r ISCO relies sensitively on the spin angular velocity J = Ma 2 / ( 2r g ) of the red hole 9 : if J < M 2 , then r ISCO > 3M ; but when J approaches M 2 , r ISCO falls slowly until finally it meets the Schwarzschild diameter R s ≡ 2GM / c 2 10 .Therefore , knowing the exact position of the ISCO will assist us better understand the physics behind several mechanisms taking place nearby to",
        "rewrite_text": "**Title:** Circular and Non-Circular Nearly Horizon-Skimming Orbits in Kerr Spacetimes\n\n**Abstract:** This study investigates the dynamics of circular and non-circular orbits in the vicinity of the event horizons of rotating black holes, utilizing the Hamilton-Jacobi method. This approach extends the conventional geodesic framework by incorporating higher-order corrections that account for the effects of gravitational radiation. Our analysis reveals the existence of two distinct families of solutions for both circular and non-circular trajectories, each characterized by varying orbital frequencies at identical radii. The outer family corresponds to bound orbits with lower orbital frequencies, while the inner family pertains to unbound orbits exhibiting higher frequencies. For circular orbits, we demonstrate that these findings can be derived directly from the first law of black hole mechanics. Furthermore, we provide quantitative evidence indicating that the innermost stable circular orbit (ISCO) shifts inward as the black hole's spin parameter increases. The implications of our results extend to astrophysical phenomena, particularly in the context of accretion disks surrounding rotating black holes.\n\n**Introduction:** The discovery of the binary pulsar PSR1913+16 and subsequent measurements of the mass ratio between the neutron star and its companion dark dwarf have led to the hypothesis that most large galaxies likely originated as black holes enveloped by accretion disks. Numerous experiments have since corroborated this model. Understanding the dynamics of matter interacting with black holes necessitates an examination of the regions where objects are either captured or ejected. This critical information is encapsulated in the position of the innermost stable circular orbit (ISCO), which represents the smallest radius at which a particle can maintain a stable circular trajectory. The radius of the ISCO is highly sensitive to the spin angular momentum of the black hole, denoted as J = Ma²/(2rg). Specifically, when J < M², the ISCO radius exceeds 3M; however, as J approaches M², the ISCO radius gradually decreases until it converges with the Schwarzschild radius Rs = 2GM/c². Thus, accurately determining the ISCO's location is essential for enhancing our understanding of the physical processes occurring in the vicinity of black holes.",
        "ori-fast-z-score": -2.1226745220209295,
        "water-fast-z-score": 5.577959874688627,
        "rewrite-fast-z-score": -0.8512055557875505
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Where post-Newtonian and numerical-relativity waveforms meet .\nAbstract:\nWe present the first results for gravitational waves generated by binary black holes in full general relativity, using both post-post-Newtonian (PPN) theory and numerical relativity. We find that our PPN-calculated waveform agrees with the numerical one to within 1% at frequencies above 100 Hz. This is an improvement over previous calculations which used only PN theory or numerical relativity alone. \n \n The agreement between these two methods provides us with confidence that we can use this hybrid approach as part of future searches for gravitational waves produced during mergers of compact objects such as neutron stars and/or black holes. In addition, it allows us to test whether current models are accurate enough to detect gravitational waves emitted by merging binaries containing supermassive black holes. These tests will be performed on data collected by LIGO/VIRGO detectors when they become operational later this year. Finally, we show how the hybrid method could also be useful for testing alternative theories of gravity.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Where post - Newtonian and numerical - relativity waveforms meet . Abstract : We report the first findings for gravitational waves generated by binary dark holes in full general relativity , using both post - post - Newtonian ( PPN ) theory and numerical gravity .We see that our PPN - calculated waveform agrees with the numerical one to within 1 % at frequencies above 100 Hz . This is an improvement over past calculations which using only PN theory or numerical gravity alone .The agreement between these two means provides us with confidence that we can using this hybrid approach as part of later searches for gravitational waves produced during mergers of compact elements such as neutron galaxies and / or black holes . In addition , it allows us to test whether previous descriptions are accurate sufficient to identify gravitational waves emitted by merging binaries bearing supermassive black holes .These studies will be performed on evidence generated by LIGO / VIRGO detectors when they become active later this year . Finally , we indicate how the hybrid technique could also be suitable for studying alternative theories of gravitational .",
        "rewrite_text": "Title: Where Post-Newtonian and Numerical Relativity Waveforms Converge\n\nAbstract: In this study, we present groundbreaking findings regarding the gravitational waves produced by binary black hole systems, utilizing a comprehensive approach that integrates both post-post-Newtonian (PPN) theory and numerical relativity. Our results demonstrate that the waveforms calculated through PPN theory exhibit a remarkable agreement with those obtained from numerical simulations, achieving a discrepancy of less than 1% at frequencies exceeding 100 Hz. This advancement marks a significant improvement over previous methodologies that relied solely on either post-Newtonian theory or numerical relativity in isolation. The concordance between these two distinct approaches instills confidence in the viability of our hybrid method, which we propose to employ in future gravitational wave searches, particularly for events involving the mergers of compact objects such as neutron stars and black holes.\n\nFurthermore, our findings pave the way for rigorous testing of existing theoretical frameworks, enabling us to ascertain the accuracy of prior models in detecting gravitational waves emitted by the mergers of supermassive black hole binaries. These investigations will leverage data collected from the LIGO and VIRGO observatories, which are set to resume operations later this year. Additionally, we explore the potential of our hybrid technique to extend beyond conventional theories of gravity, offering a promising avenue for examining alternative gravitational frameworks. This research not only enhances our understanding of gravitational wave phenomena but also contributes to the broader field of astrophysics by providing a robust tool for analyzing complex cosmic events.",
        "ori-fast-z-score": 0.41256849850351734,
        "water-fast-z-score": 6.6010959760562775,
        "rewrite-fast-z-score": -1.6570343122169822
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A high-frequency radio continuum study of massive young stellar objects .\nAbstract:\nWe present the results of an unbiased survey for compact HII regions in the southern Galactic plane using data obtained with the Australia Telescope Compact Array (ATCA). The sample consists of all known OB stars within |b| < 1 degree and distances less than 5 kpc, which are associated with IRAS point sources that have been classified as having infrared excesses indicative of circumstellar disks or envelopes. We detect over 100 new compact HII regions at frequencies between 2.1 GHz and 6.0 GHz. These objects range in size from 0.01 pc to 0.5 pc and their luminosities vary by more than four orders of magnitude. Most of these newly detected compact HII regions appear to be excited by single O-type stars; however we also find several examples where two or three bright radio components are separated by only a few arcseconds. In addition, we identify a number of previously uncatalogued ultracompact HII regions whose sizes are smaller than 0.01 pc.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A high - frequency radio continuum study of large small stars objects . Abstract : We report the conclusion of an unbiased survey for compact HII zones in the southern Galactic jet using data acquired with the Australia Telescope Compact Array ( ATCA ) .The sample consists of all known OB stars within | b | < 1 degree and altitudes lower than 5 kpc , which are identified with IRAS point sources that have been classified as having infrared excesses indicative of circumstellar disks or envelopes . We detect over 100 new compact HII zones at speeds between 2 . 1 GHz and 6 . 0 GHz .These bodies range in height from 0 . 01 pc to 0 . 5 pc and their luminosities vary by more than four orders of magnitude . Most of these newly observed compact HII regions seem to be excited by single O - class stars ; however we also find various instances where two or three dark radio components are split by only a few arcseconds .In addition , we identify a number of previously uncatalogued ultracompact HII domains whose sizes are smaller than 0 . 01 pc .",
        "rewrite_text": "We present the findings of a comprehensive survey aimed at identifying compact HII regions within the southern Galactic jet, utilizing data from the Australia Telescope Compact Array (ATCA). Our study encompasses all known OB stars located within |b| < 1 degree and at distances less than 5 kpc. These stars were identified through their association with IRAS point sources that exhibit infrared excesses, suggesting the presence of circumstellar disks or envelopes. In our survey, we successfully detected over 100 new compact HII regions, with radio frequencies ranging from 2.1 GHz to 6.0 GHz. The dimensions of these regions vary significantly, with heights ranging from 0.01 pc to 0.5 pc, and their luminosities spanning more than four orders of magnitude. \n\nThe majority of the newly identified compact HII regions appear to be ionized by individual O-class stars. However, we also observed several cases where two or three dark radio components are closely spaced, separated by only a few arcseconds. Furthermore, our research led to the discovery of several previously uncatalogued ultracompact HII regions, which are notably smaller than 0.01 pc. This study not only expands the catalog of known compact HII zones but also enhances our understanding of the formation and characteristics of these stellar environments. The implications of these findings contribute to the broader knowledge of star formation processes and the dynamics of the Galactic jet, providing valuable insights into the role of massive stars in shaping their surroundings.",
        "ori-fast-z-score": -0.22941573387056174,
        "water-fast-z-score": 5.128225940683707,
        "rewrite-fast-z-score": 0.09667364890456635
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Simulations of the Boundary Layer Between a White Dwarf and its Accretion Disk .\nAbstract:\nWe present results from three-dimensional hydrodynamic simulations of accreting white dwarfs in close binary systems, focusing on the boundary layer between the disk and the star. We find that the flow is highly turbulent with strong shocks forming at the interface between the two flows. The density structure shows significant departures from spherical symmetry due to the presence of spiral arms which form as a result of the interaction between the stellar magnetic field and the gas stream flowing towards the surface of the white dwarf. These spiral arms are responsible for driving an outflow along the polar axis of the system. In addition we find evidence for large-scale convection cells within the boundary layer. Our models suggest that the observed X-ray emission may be produced by these convective motions rather than by shock heating alone. This work was supported by NASA grant NAG5-7262. \n \n Keywords: Hydrodynamics; Shock waves; Convection",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Simulations of the Boundary Layer Between a White Dwarf and its Accretion Disk . Abstract : We report findings from three - dimensional hydrodynamic simulations of accreting white dwarfs in close binary systems , concentrating on the boundary layer between the disk and the star .We see that the flow is strongly chaotic with powerful shocks producing at the interface between the two flows . The density structure exhibits significant departures from spherical symmetry thanks to the presence of spiral arms which occur as a product of the interaction between the stellar magnetic force and the gas stream running towards the surface of the white dwarf .These spiral arms are responsible for controlling an outflow along the polar axis of the system . In addition we find proof for large - scale convection cells within the boundary layer .Our models suggest that the seen X - ray radiation may be made by these convective movements rather than by shock heating alone . This research was supported by NASA grant NAG5 - 7262 .Keywords : Hydrodynamics ; Shock currents ; Convection",
        "rewrite_text": "Title: Simulations of the Boundary Layer Between a White Dwarf and its Accretion Disk\n\nAbstract: In this study, we present the results of three-dimensional hydrodynamic simulations focused on the boundary layer between accreting white dwarfs and their surrounding accretion disks in close binary systems. Our findings reveal that the flow dynamics in this region are highly chaotic, characterized by the formation of powerful shock waves at the interface of the two interacting flows. Notably, the density distribution within the boundary layer deviates significantly from spherical symmetry, primarily due to the emergence of spiral arms. These spiral structures arise from the interplay between the magnetic forces of the white dwarf and the gas stream that is accreting onto its surface. The presence of these spiral arms plays a crucial role in facilitating an outflow along the system's polar axis. Furthermore, our simulations provide evidence for the existence of large-scale convection cells within the boundary layer, which may contribute to the observed X-ray emissions. This suggests that the X-ray radiation detected in these systems could be attributed to the convective motions rather than being solely a result of shock heating. The implications of these findings enhance our understanding of the complex interactions occurring in the vicinity of white dwarfs and their accretion disks. This research was conducted with the support of NASA grant NAG5-7262. \n\nKeywords: Hydrodynamics; Shock waves; Convection.",
        "ori-fast-z-score": -0.3333333333333333,
        "water-fast-z-score": 4.638124095143555,
        "rewrite-fast-z-score": 0.5940885257860046
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Blazar surveys with WMAP and Swift .\nAbstract:\nWe present the results of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe (WMAP) satellite and the Swift observatory in the first year of operation, 2004-05. We find that there are no significant differences between the two samples when we compare their distributions for redshift, luminosity distance, radio flux density at 1 GHz, optical magnitude, or X-ray photon index. The only difference is found to be in the distribution of redshifts; this may be due to selection effects caused by the different energy bands used by each instrument. \n \n Keywords: Blazar, Swift, WMAP, survey, cosmology, statistics, gamma-ray bursts, galaxy clusters, dark matter, dark energy, neutrino mass, cosmic microwave background radiation, anisotropies, large-scale structure, gravitational lensing, relativistic jets, quasar, active galactic nuclei",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Blazar observations with WMAP and Swift . Abstract : We report the conclusion of our analysis on blazars detected by both the Wilkinson Microwave Anisotropy Probe ( WMAP ) satellite and the Swift telescope in the first year of operation , 2004 - 05 .We see that there are no considerable changes between the two specimens when we compare their distributions for redshift , luminosity distance , radio flux concentration at 1 GHz , optical magnitude , or X - ray photon index . The only difference is found to be in the distribution of redshifts ; this might be due to choice influences created by the different energy bands used by each instrument .Keywords : Blazar , Swift , WMAP , survey , cosmology , statistics , gamma - ray bursts , galaxy rings , soft material , soft energy , neutrino mass , cosmic microwave background radiation , anisotropies , large - scale structure , gravity lensing , relativistic jets , quasar , active galactic nuclei",
        "rewrite_text": "In this study, we present the findings from our comprehensive analysis of blazars observed by both the Wilkinson Microwave Anisotropy Probe (WMAP) and the Swift telescope during their initial operational year, spanning 2004 to 2005. Our investigation reveals that there are no significant differences in the distributions of key parameters such as redshift, luminosity distance, radio flux at 1 GHz, optical magnitude, or X-ray photon index between the blazars identified by the two instruments. The only notable distinction we observed pertains to the distribution of redshifts, which may be attributed to the varying energy bands utilized by WMAP and Swift. This discrepancy suggests that the selection effects inherent to the different observational methodologies could influence the redshift data collected. Our results contribute to the understanding of blazar characteristics and their implications in the broader context of cosmology and astrophysics. The findings underscore the importance of cross-referencing data from multiple observational platforms to gain a more comprehensive understanding of these enigmatic astronomical objects. This research has implications for future studies involving gamma-ray bursts, active galactic nuclei, and the large-scale structure of the universe, as well as for the ongoing exploration of phenomena such as gravitational lensing and neutrino mass. The keywords associated with this study include blazar, Swift, WMAP, survey, cosmology, statistics, gamma-ray bursts, galaxy rings, soft material, soft energy, neutrino mass, cosmic microwave background radiation, anisotropies, large-scale structure, gravity lensing, relativistic jets, quasar, and active galactic nuclei.",
        "ori-fast-z-score": -0.8682431421244593,
        "water-fast-z-score": 3.2003787654626508,
        "rewrite-fast-z-score": 0.2873478855663454
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cosmic Streaming Field at Low Redshift .\nAbstract:\nWe present the first measurement of the cosmic streaming field in the local universe, using data from the Sloan Digital Sky Survey (SDSS). The streaming field is defined as the curl-free component of the peculiar velocity field and can be used to measure the net effect of tidal forces on galaxy clusters. We use a sample of 13,000 galaxy groups with spectroscopic redshifts between 0.01 < z < 0.1 selected by applying an adaptive halo mass cut to the SDSS maxBCG cluster catalog. Using this sample we find that the amplitude of the streaming field decreases rapidly towards lower redshift, consistent with theoretical predictions for the growth rate of large-scale structure. In addition, we show that the direction of the streaming field changes significantly over time due to the coherent infall into superclusters. Finally, we demonstrate how our results can be used to test cosmological models against observations. This work was supported by NSF grant AST-0707766.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cosmic Streaming Field at Low Redshift . Abstract : We report the first measurement of the cosmic flow field in the local universe , using data from the Sloan Digital Sky Survey ( SDSS ) .The streaming force is characterized as the curl - free component of the peculiar speed field and can be used to measure the net effect of tidal forces on star clusters . We use a sample of 13 , 000 galaxy groups with spectroscopic redshifts between 0 . 01 < z < 0 . 1 selected by using an adaptive halo weight cut to the SDSS maxBCG cluster catalog .Using this specimen we find that the frequency of the streaming field decreases quickly towards lower redshift , compatible with theoretical expectations for the development rate of large - scale structure . In addition , we find that the direction of the streaming field shifts significantly over time due to the coherent infall into superclusters .Finally , we prove how our findings can be used to test cosmological predictions against measurements . This research was supported by NSF grant AST - 0707766 .",
        "rewrite_text": "We present the inaugural measurement of the cosmic flow field within the local universe, utilizing data sourced from the Sloan Digital Sky Survey (SDSS). The streaming force is defined as the curl-free component of the peculiar velocity field, which serves as a valuable tool for assessing the cumulative impact of tidal forces on star clusters. Our analysis is based on a carefully selected sample of 13,000 galaxy groups, each with spectroscopic redshifts ranging from 0.01 to 0.1. This selection was achieved through an adaptive halo weight cut applied to the SDSS maxBCG cluster catalog. Our findings indicate that the prevalence of the streaming field diminishes rapidly as redshift decreases, aligning with theoretical predictions regarding the evolution of large-scale structures in the universe. Furthermore, we observe a significant temporal shift in the direction of the streaming field, attributed to the coherent infall of matter into superclusters. This research not only enhances our understanding of cosmic flows but also provides a framework for testing cosmological models against empirical data. The implications of our results extend to refining our comprehension of cosmic structure formation and the dynamics of galaxy clusters. This work was made possible through the support of NSF grant AST-0707766.",
        "ori-fast-z-score": -1.1043152607484654,
        "water-fast-z-score": 4.664004843101107,
        "rewrite-fast-z-score": -0.10153461651336192
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Asymmetric superconductivity in metallic systems .\nAbstract:\nThe authors present the results of their study on the properties of two different types of systems, which are both characterized by an asymmetric distribution of charge carriers and exhibit unconventional superconducting behavior.  The first type is represented by layered compounds with alternating layers of conducting and insulating material (e.g., SrTiO3/SrRuO3/LaAlO3). In these materials, the presence of strong electron correlations leads to the formation of two-dimensional electronic states at the interface between the layers that can be described as a doped Mott insulator. These interfaces act like Josephson junctions and give rise to a spontaneous current perpendicular to the layers. This current causes a magnetic field to penetrate into the sample even when no external magnetic fields are applied. The second class consists of quasi-one-dimensional conductors such as carbon nanotubes or semiconductor nanowires. Here, the asymmetry arises because one end of the wire has been terminated by chemical functionalization.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Asymmetric superconductivity in metallic systems . Abstract : The authors present the results of their experiment on the properties of two different kinds of structures , which are both defined by an asymmetric distribution of charge carriers and undergo alternative superconducting behavior .The first class is represented by layered compounds with alternating layers of conducting and insulating material ( e . g . , SrTiO3 / SrRuO3 / LaAlO3 ) . In these structures , the presence of large electron correlations causes to the formation of two - dimensional electronic states at the interface between the layers that can be described as a doped Mott insulator .These interfaces act like Josephson junctions and giving rise to a spontaneous current perpendicular to the layers . This current creates a magnetic current to penetrate into the sample even when no external magnetic fields are applied .The second class consists of quasi - one - dimensional conductors such as carbon nanotubes or semiconductor nanowires . Here , the asymmetry arises because one end of the wire has been terminated by chemical functionalization .",
        "rewrite_text": "The authors investigate the phenomenon of asymmetric superconductivity in metallic systems, presenting experimental findings on two distinct structural types characterized by an uneven distribution of charge carriers, which exhibit varying superconducting behaviors. The first category encompasses layered compounds, such as SrTiO3/SrRuO3/LaAlO3, where alternating layers of conductive and insulating materials create a unique environment. In these layered structures, significant electron correlations lead to the emergence of two-dimensional electronic states at the interfaces, which can be effectively modeled as a doped Mott insulator. These interfaces function analogously to Josephson junctions, resulting in the generation of a spontaneous current that flows perpendicular to the layers. Notably, this induced current facilitates the penetration of magnetic fields into the sample, even in the absence of external magnetic influences.\n\nThe second category examined consists of quasi-one-dimensional conductors, including carbon nanotubes and semiconductor nanowires. In these systems, the asymmetry is introduced through the chemical functionalization of one end of the wire, which alters the electronic properties and superconducting behavior. The study highlights the critical role of structural asymmetry in influencing the superconducting characteristics of these materials, suggesting that such configurations could lead to novel applications in superconducting devices. Overall, the findings contribute to a deeper understanding of how charge carrier distribution and structural design can manipulate superconductivity in metallic systems, paving the way for future research and technological advancements in the field.",
        "ori-fast-z-score": 0.45291081365783825,
        "water-fast-z-score": 3.988620176087328,
        "rewrite-fast-z-score": 0.6704783996548059
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Saturation effects in the sub-Doppler spectroscopy of Cesium vapor confined in an Extremely Thin Cell .\nAbstract:\nWe report on saturation effects observed in the sub-Dopplerbroadened absorption spectrum of cesium atoms confined to a cell with thickness L = 0.5 mm and length l = 1 cm, which is much thinner than the Doppler width (~30mm). The experimental results are compared with theoretical predictions based on the solution of Maxwell-Bloch equations for two-level systems under conditions where the relaxation rates depend strongly on the atomic density. We find that our model describes well both the shape and intensity dependence of the saturated absorption lineshape as well as the linewidths at different intensities. Our measurements show that the optical depth per unit area increases by more than one order of magnitude when going from thick cells to extremely thin ones. This opens up new possibilities for high-resolution spectroscopic studies using such samples. \n \n In recent years there has been growing interest in studying dilute vapors confined inside very thin cells  1  . These experiments have led to important advances in understanding many phenomena related to quantum optics  2  , nonlinear optics  3  , laser cooling  4  , and precision measurement  5  .\nIn this work we present some interesting features of the sub-Doppler-broadened absorption spectrum  6  of cesium atoms confined within an extremely thin cell  7, 8  . Such a sample can be considered as a quasi-two-dimensional gas  9  whose properties differ significantly from those of three-dimensional gases  10  . For example, it was shown recently  11  that the relaxation rate Γ1 of the excited state population depends strongly on the atomic density n0 due to dipole-dipole interactions between neighboring atoms  12  . As a result, the effective homogeneous broadening of the transition becomes dependent on the number N of atoms contained in the probing beam volume V  13  : \n \n Δνeff ~ N/V \n\n\nwhere ΔνD is the Doppler width associated with the thermal motion of the atoms along the direction perpendicular to the probe beam axis. It follows then that the optical depth per atom OD/N also varies with the number of atoms in the probing region:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Saturation phenomena in the sub - Doppler spectroscopy of Cesium vapor confined in an Extremely Thin Cell . Abstract : We report on saturation effects encountered in the sub - Dopplerbroadened absorption spectrum of cesium atoms confined to a cell with thickness L = 0 . 5 mm and size l = 1 cm , which is much thinner than the Doppler size ( ~ 30mm ) .The empirical results are compared with theoretical estimates based on the solve of Maxwell - Bloch coefficients for two - level systems under conditions where the relaxation frequencies rely highly on the atomic density . We see that our model describes well both the form and intensity dependence of the saturated emission lineshape as well as the linewidths at different intensities .Our measurements show that the optical length per unit area grows by more than one order of magnitude when going from thick cells to incredibly thin ones . This opens up new possibilities for high - resolution spectroscopic studies using such samples .In recent years there has been growing interest in investigating dilute vapors restricted inside very thin cells 1 . These studies have led to significant advances in understanding several phenomena related to quantum optics 2 , nonlinear optics 3 , laser cooling 4 , and precision measurement 5 .In this research we present some interesting features of the sub - Doppler - broadened absorption spectrum 6 of cesium atoms confined within an incredibly thin cell 7 , 8 . Such a sample can be regarded as a quasi - two - dimensional liquid 9 whose characteristics vary significantly from those of three - dimensional gases 10 .For instance , it was shown ago 11 that the relaxation time Γ1 of the excited state population relies highly on the atomic concentration n0 due to dipole - dipole interactions between neighboring atoms 12 . As a result , the effective homogeneous broadening of the transition becomes dependent on the number N of atoms enclosed in the probing laser volume V 13 : Δνeff ~ N / V where ΔνD is the Doppler size associated with the thermal motion of the atoms along the direction perpendicular to the probe beam axis .It follows then that the optical height per atom OD / N also varies with the quantity of atoms in the probing zone :",
        "rewrite_text": "**Title:** Saturation Phenomena in the Sub-Doppler Spectroscopy of Cesium Vapor Confined in an Extremely Thin Cell\n\n**Abstract:** This study investigates the saturation effects observed in the sub-Doppler absorption spectrum of cesium atoms confined within a remarkably thin cell, measuring 0.5 mm in thickness and 1 cm in size, which is significantly thinner than the typical Doppler width (~30 mm). We compare our empirical findings with theoretical predictions derived from the Maxwell-Bloch equations for two-level systems, particularly under conditions where relaxation frequencies are heavily influenced by atomic density. Our model effectively captures both the shape and intensity dependence of the saturated emission lineshape, as well as the linewidth variations at different intensity levels. Notably, our measurements indicate that the optical length per unit area increases by over an order of magnitude when transitioning from thicker cells to these ultra-thin configurations, thereby paving the way for advanced high-resolution spectroscopic investigations.\n\nRecent years have seen a surge of interest in the study of dilute vapors confined in extremely thin cells, leading to significant advancements in our understanding of various phenomena related to quantum optics, nonlinear optics, laser cooling, and precision measurements. In this research, we highlight intriguing characteristics of the sub-Doppler broadened absorption spectrum of cesium atoms in such a thin cell. This unique sample can be conceptualized as a quasi-two-dimensional liquid, exhibiting properties that differ markedly from those of three-dimensional gases. Previous studies have demonstrated that the relaxation time (Γ1) of the excited state population is highly dependent on atomic concentration (n0), primarily due to dipole-dipole interactions among neighboring atoms. Consequently, the effective homogeneous broadening of the transition is contingent upon the number of atoms (N) within the laser probing volume (V), expressed as Δνeff ~ N/V, where ΔνD represents the Doppler width associated with atomic thermal motion perpendicular to the probe beam axis. This relationship implies that the optical depth per atom (OD/N) also varies with the number of atoms present in the probing region, further emphasizing the complex interplay between atomic density and spectral characteristics in ultra-thin cell configurations.",
        "ori-fast-z-score": 1.3887301496588271,
        "water-fast-z-score": 8.538461538461538,
        "rewrite-fast-z-score": 1.697336849583011
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modeling the Spectral Energy Distribution and Variability of 3C 66A during the WEBT campaign of 2003 -- 2004 .\nAbstract:\nWe present results on modeling the spectral energy distribution (SED) and variability of the blazar 3C 66A observed by the Whole Earth Blazar Telescope (WEBT). The SED is modeled with an accretion disk, synchrotron emission from relativistic electrons in jets, inverse Compton scattering off soft photons produced within the jet or external to it, and thermal radiation from dusty clouds surrounding the central engine. We find that the model can reproduce most features of the SED: the optical-UV spectrum; the X-ray spectrum; the infrared-optical flux ratio; and the radio-to-optical spectral index. However, we cannot explain why there are two peaks in the UV spectrum at ~1400 Å and ~1900 Å simultaneously. In addition, our model fails to account for the rapid flares detected in the light curve of this source. This suggests that either additional components should be included into the model and/or some physical processes have been neglected. \n \n Keywords: blazars, 3C 66A",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modeling the Spectral Energy Distribution and Variability of 3C 66A during the WEBT effort of 2003 - - 2004 . Abstract : We report findings on studying the spectral power distribution ( SED ) and variability of the blazar 3C 66A observed by the Whole Earth Blazar Telescope ( WEBT ) .The SED is modeled with an accretion disk , synchrotron emission from relativistic electrons in jets , inverse Compton absorption off hard photons created within the jet or external to it , and thermal rays from damp clouds surrounding the main motor . We see that the model can reproduce most elements of the SED : the optical - UV spectrum ; the X - ray spectrum ; the infrared - optical flux ratio ; and the radio - to - optical spectral index .However , we cannot explain why there are two peaks in the UV spectrum at ~ 1400 Å and ~ 1900 Å simultaneously . In addition , our model refuses to explain for the quick flares detected in the light curve of this source .This implies that either additional components should be included into the model and / or some physical processes have been neglected . Keywords : blazars , 3C 66A",
        "rewrite_text": "Title: Modeling the Spectral Energy Distribution and Variability of 3C 66A during the WEBT Effort of 2003-2004\n\nAbstract: This study presents an in-depth analysis of the spectral energy distribution (SED) and variability of the blazar 3C 66A, as observed by the Whole Earth Blazar Telescope (WEBT) during the 2003-2004 observational campaign. Our modeling approach incorporates several key components, including an accretion disk, synchrotron radiation emitted by relativistic electrons in jets, and inverse Compton scattering of hard photons generated either within the jet or from external sources. Additionally, we account for thermal emissions from surrounding damp clouds that envelop the central engine. The results indicate that our model successfully reproduces a majority of the SED characteristics, including the optical-UV spectrum, the X-ray spectrum, the infrared-optical flux ratio, and the radio-to-optical spectral index. However, a notable limitation of our model is its inability to account for the presence of two distinct peaks in the UV spectrum at approximately 1400 Å and 1900 Å, which appear simultaneously. Furthermore, the model falls short in explaining the rapid flares observed in the light curve of 3C 66A. These discrepancies suggest that the current model may require the inclusion of additional components or that certain physical processes have been overlooked. This research highlights the complexities involved in accurately modeling the behavior of blazars and underscores the need for further investigation into the underlying mechanisms driving their variability. \n\nKeywords: blazars, 3C 66A",
        "ori-fast-z-score": -0.7071067811865476,
        "water-fast-z-score": 4.184914994777494,
        "rewrite-fast-z-score": -0.39605901719066977
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modelling long-term trends in lunar exposure to the Earth s plasmasheet .\nAbstract:\nThe Moon is exposed to solar wind and magnetospheric plasma, which can be modelled by using data from spacecraft such as Cluster or Geotail. The aim of this study was to investigate how these interactions have changed over time. We used magnetic field measurements from Cluster 1 (C1) between 2001 and 2010 to calculate the flux density of energetic electrons at the Moon s surface for each orbit. This allowed us to determine when the Moon was most likely to be bombarded with high energy particles. In addition we calculated the total number of times that C1 crossed the Moon s bow shock during its lifetime. These results were compared against previous studies on the evolution of the Earth s magnetosphere. It has been suggested that there are two main types of interaction between the Earth and the Sun; coronal mass ejections (CMEs), which occur less frequently but produce more intense events than streamer belt driven storms.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modelling large - term changes in moon sensitivity to the Earth s plasmasheet . Abstract : The Moon is subjected to solar wind and magnetospheric plasma , which can be described by using data from satellites such as Cluster or Geotail .The goal of this study was to examine how these interactions have shifted over time . We utilized magnetic field measurements from Cluster 1 ( C1 ) between 2001 and 2010 to estimate the flux concentration of energetic electrons at the Moon s surface for each trajectory .This able us to predict when the Moon was most likely to be bombarded with high energy objects . In addition we calculated the total number of times that C1 crossed the Moon s bow shock during its career .These conclusions were compared against prior studies on the evolution of the Earth s magnetosphere . It has been proposed that there are two principal kinds of collision between the Earth and the Sun ; coronal mass ejections ( CMEs ) , which occur smaller regularly but generate more intense events than streamer belt driven storms .",
        "rewrite_text": "**Title: Modeling Long-Term Changes in Moon Sensitivity to Earth's Plasmasheet**\n\n**Abstract:** The Moon experiences continuous interactions with solar wind and magnetospheric plasma, phenomena that can be effectively analyzed using data from various satellites, including Cluster and Geotail. This study aims to investigate the temporal variations in these interactions and their implications for the Moon's exposure to energetic particles. We focused on magnetic field measurements obtained from Cluster 1 (C1) over a decade, from 2001 to 2010, to assess the flux concentration of energetic electrons impacting the lunar surface along its trajectory. This analysis enabled us to identify periods when the Moon was particularly susceptible to bombardment by high-energy particles. Furthermore, we quantified the frequency of C1's crossings of the Moon's bow shock throughout its operational lifespan. Our findings were juxtaposed with existing research on the evolution of Earth's magnetosphere, contributing to a broader understanding of the dynamics at play. Notably, we identified two primary types of interactions between the Earth and the Sun: coronal mass ejections (CMEs), which, although less frequent, produce more intense disturbances compared to the more regular but less intense storms driven by streamer belts. This research not only enhances our comprehension of lunar sensitivity to solar and magnetospheric influences but also provides insights into the broader implications of these interactions for planetary bodies within our solar system.",
        "ori-fast-z-score": -0.8307471607356973,
        "water-fast-z-score": 5.421151989096865,
        "rewrite-fast-z-score": 2.177598558933893
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Effective inverse spectral problem for rational Lax matrices and applications .\nAbstract:\nWe consider the effective inverse spectral problems (EISP) associated with rational Lax matrices, which are generalizations of classical EISP in terms of Jacobi matrices. We show that these new EISPs can be reduced to some special cases of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix. As examples we study two classes of rational Lax matrices: one is related to the Toda lattice hierarchy and another is connected with the modified Volterra lattice hierarchy. In particular, we give a complete description on all solutions of the corresponding EISPs. Finally, as applications of our results, we present several interesting properties about the spectra of these rational Lax matrices. The research was supported by NSFC under Grant No.11571040. Keywords: Effective inverse spectral problem; Rational Lax matrices; Toda lattice hierarchy; Modified Volterra lattice hierarchy",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Effective inverse spectral problem for rational Lax matrices and applications . Abstract : We consider the effective inverse spectral questions ( EISP ) associated with rational Lax matrices , which are generalizations of classical EISP in terms of Jacobi matrices .We see that these new EISPs can be reduced to some particular examples of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix . As instance we study two families of rational Lax matrices : one is related to the Toda lattice hierarchy and another is linked with the modified Volterra lattice hierarchy .In particular , we give a complete model on all solutions of the resulting EISPs . Finally , as applications of our findings , we present many interesting properties about the spectra of these rational Lax matrices .The research was supported by NSFC under Grant No . 11571040 . Keywords : Effective inverse spectral problem ; Rational Lax matrices ; Toda lattice hierarchy ; Modified Volterra lattice hierarchy",
        "rewrite_text": "Title: Effective Inverse Spectral Problem for Rational Lax Matrices and Their Applications\n\nAbstract: This article investigates the effective inverse spectral problems (EISP) associated with rational Lax matrices, which serve as a broader framework compared to the classical EISP typically defined through Jacobi matrices. We demonstrate that these novel EISPs can be simplified to specific instances of classical EISP by employing a precise formula for the coefficients of the characteristic polynomial of a rational matrix. Our study focuses on two distinct families of rational Lax matrices: one associated with the Toda lattice hierarchy and the other with the modified Volterra lattice hierarchy. We provide a comprehensive analysis of all solutions to the resulting EISPs, establishing a complete model that elucidates the relationships and structures inherent in these problems. Furthermore, we explore various intriguing properties of the spectra of these rational Lax matrices, revealing insights that extend our understanding of their spectral characteristics. The findings presented in this research are supported by the National Natural Science Foundation of China under Grant No. 11571040. This work not only contributes to the theoretical framework of inverse spectral problems but also opens avenues for future research in the field of integrable systems and their applications. \n\nKeywords: Effective inverse spectral problem; Rational Lax matrices; Toda lattice hierarchy; Modified Volterra lattice hierarchy.",
        "ori-fast-z-score": 0.23249527748763857,
        "water-fast-z-score": 2.8867513459481287,
        "rewrite-fast-z-score": -0.6255432421712244
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  In-orbit focal adjustment of the AKARI telescope with IRC images .\nAbstract:\nWe have performed in-orbit focal adjustment (IFA) for the infrared camera onboard AKARI satellite using its own data taken in orbit. The IFA was carried out by comparing the observed point spread function (PSF) and that simulated based on ray tracing analysis, which is one of the most accurate methods to determine the best focus position. We found that the PSFs were not always consistent between different bands even after the IFA had been completed. This inconsistency may be caused by some errors in the optical design or manufacturing process. In addition, we also found that there are still some problems remaining in the calibration accuracy of the detector pixel size. These results will help us improve our understanding about the performance of the instrument as well as provide useful information for future space missions. Keywords: Space mission, Focal adjustment, Point spread function, Ray tracing analysis, Infrared astronomy, Infrared camera",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : In - orbit focal adjustment of the AKARI telescope with IRC data . Abstract : We have done in - orbit lens adjustment ( IFA ) for the infrared camera onboard AKARI station use its own observations made in space .The IFA was carried out by comparing the seen point spread constant ( PSF ) and that simulated based on ray tracing examination , which is one of the most accurate ways to identify the best focus position . We determined that the PSFs were not always compatible between various bands long after the IFA had been completed .This inconsistency may be caused by some defects in the optical design or manufacturing system . In addition , we also discovered that there are still some problems remaining in the calibration reliability of the sensor pixel size .These data will assist us improve our appreciation about the performance of the instrument as also as give valuable info for future space missions . Keywords : Space mission , Focal correction , Point spread function , Ray tracing investigation , Infrared astronomy , Infrared camera",
        "rewrite_text": "Title: In-Orbit Focal Adjustment of the AKARI Telescope Using IRC Data\n\nAbstract: This study presents the in-orbit lens adjustment (IFA) conducted for the infrared camera (IRC) aboard the AKARI satellite, utilizing data obtained from its own observations in space. The IFA process involved a detailed comparison between the observed point spread function (PSF) and a simulated PSF generated through ray tracing analysis, a highly precise method for determining optimal focus positions. Our findings revealed that the PSFs across different spectral bands exhibited inconsistencies even after the IFA was completed. This discrepancy suggests potential issues related to the optical design or manufacturing processes of the telescope. Furthermore, we identified ongoing challenges concerning the calibration accuracy of the sensor pixel size, which may impact the overall performance of the instrument. The insights gained from this research not only enhance our understanding of the AKARI telescope's operational capabilities but also provide critical information that can inform the design and execution of future space missions. By addressing these calibration and optical alignment issues, we aim to improve the reliability and effectiveness of infrared observations in astronomical research. This work underscores the importance of continuous assessment and adjustment of space-based instruments to ensure optimal performance in the dynamic environment of space. \n\nKeywords: Space mission, Focal correction, Point spread function, Ray tracing analysis, Infrared astronomy, Infrared camera.",
        "ori-fast-z-score": -0.9878783399072131,
        "water-fast-z-score": 5.237229365663818,
        "rewrite-fast-z-score": 0.4662524041201569
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The 1 keV to 200 keV X-ray Spectrum of NGC 2992 and NGC 3081 .\nAbstract:\nWe present the first results on the soft X-ray emission in two nearby elliptical galaxies, NGC 2992 (M60) and NGC 3081 (M84). The observations were made with the Chandra X-Ray Observatory using the Advanced CCD Imaging Spectrometer (ACIS-S3), which has an energy resolution of about 130 eV at 6 keV. We find that both galaxies show extended diffuse emission around their central regions. In addition, we detect several point sources within each galaxy s field-of-view. For these point sources, we have extracted spectra for individual source components as well as combined them into one spectrum per galaxy. Using spectral fitting techniques, we found that all but three of the detected point sources are consistent with being background AGNs or foreground stars. However, there is evidence that some of the brightest point sources may be associated with the host galaxies themselves. Finally, we also fit the diffuse component of the X-ray emission with thermal plasma models.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The 1 keV to 200 keV X - ray Spectrum of NGC 2992 and NGC 3081 . Abstract : We report the first findings on the soft X - ray radiation in two nearby elliptical galaxies , NGC 2992 ( M60 ) and NGC 3081 ( M84 ) .The images were made with the Chandra X - Ray Observatory using the Advanced CCD Imaging Spectrometer ( ACIS - S3 ) , which has an energy resolution of about 130 eV at 6 keV . We see that both galaxies show enhanced diffuse emission around their central regions .In addition , we locate many point sources within each galaxy s field - of - view . For these point sources , we have gathered spectra for individual source components as well as blended them into one spectrum per galaxy .Using spectral fit techniques , we concluded that all but three of the detected point sources are compatible with being background AGNs or foreground stars . However , there is evidence that some of the brightest point sources might be identified with the host galaxies themselves .Finally , we also fitted the diffuse component of the X - ray radiation with thermal plasma theories .",
        "rewrite_text": "In this study, we present the inaugural observations of soft X-ray emissions from two nearby elliptical galaxies, NGC 2992 (M60) and NGC 3081 (M84). Utilizing the Chandra X-Ray Observatory equipped with the Advanced CCD Imaging Spectrometer (ACIS-S3), which boasts an energy resolution of approximately 130 eV at 6 keV, we have captured detailed images that reveal significant diffuse X-ray emission concentrated around the central regions of both galaxies. Our analysis also identified numerous point sources within the field of view of each galaxy. For these point sources, we have extracted individual spectra, as well as combined them to create a composite spectrum for each galaxy. Through spectral fitting techniques, we determined that the majority of the detected point sources—except for three—are likely to be background active galactic nuclei (AGNs) or foreground stars. Notably, there is compelling evidence suggesting that some of the brightest point sources may be associated with the host galaxies themselves. Furthermore, we conducted a spectral analysis of the diffuse X-ray emission, applying thermal plasma models to better understand the underlying physical processes. Our findings contribute to the growing body of knowledge regarding the X-ray properties of elliptical galaxies and provide insights into the nature of their central regions and the potential presence of active galactic nuclei. This research enhances our understanding of the X-ray emission mechanisms in these galaxies and lays the groundwork for future studies aimed at exploring the relationship between X-ray emissions and the galactic environment.",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 3.4874291623145783,
        "rewrite-fast-z-score": -0.27975144247209416
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  How to Compile Some NAND Formula Evaluators .\nAbstract:\nThe following is an excerpt from the author s thesis, which can be downloaded at http://arxiv.org/abs/1306.5189. \n \n The formula evaluation problem for propositional logic formulas in conjunctive normal form (CNF) has been studied extensively and many efficient algorithms have been developed. However, most existing approaches are not suitable for evaluating large CNFs with millions or even billions of clauses due to their high computational complexity. In this work we present two novel techniques that significantly improve the efficiency of CNF formula evaluators: one based on parallelization using GPUs and another based on data compression by representing each clause as a bit vector instead of a set of literals. We implemented these techniques into our new software package called CLEVER-CNF, which outperforms state-of-the-art solvers such as SATzilla and Lingeling when evaluated against several benchmark sets including those used in recent SAT competitions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : How to Compile Some NAND Formula Evaluators . Abstract : The following is an excerpt from the writer s thesis , which can be downloaded at http : / / arxiv . org / abs / 1306 . 5189 .The formula assessment problem for propositional logic formulas in conjunctive normal form ( CNF ) has been studied frequently and many efficient methods have been created . However , most existing techniques are not suitable for evaluating large CNFs with thousands or even billions of clauses due to their high computational complexity .In this project we present two novel techniques that significantly boost the performance of CNF formula evaluators : one based on parallelization using GPUs and another based on data coding by representing each clause as a bit vector rather of a group of literals . We introduced these tactics into our new software suite named CLEVER - CNF , which outperforms state - of - the - art solvers such as SATzilla and Lingeling when evaluated against several benchmark sets including those utilized in recent SAT competitions .",
        "rewrite_text": "Title: How to Compile Some NAND Formula Evaluators\n\nAbstract: This article presents an excerpt from the author's thesis, which is accessible at http://arxiv.org/abs/1306.5189. The evaluation of propositional logic formulas in conjunctive normal form (CNF) has been a subject of extensive research, leading to the development of numerous efficient methodologies. However, many of these existing approaches struggle with the evaluation of large CNFs that contain thousands to billions of clauses, primarily due to their significant computational demands. In response to this challenge, we introduce two innovative techniques designed to enhance the performance of CNF formula evaluators. The first technique leverages the power of parallel processing through the use of Graphics Processing Units (GPUs), allowing for a substantial increase in evaluation speed. The second technique involves a novel data representation method, where each clause is encoded as a bit vector instead of a traditional collection of literals. This change in representation not only optimizes memory usage but also accelerates the evaluation process. We have integrated these advancements into our newly developed software suite, CLEVER-CNF, which demonstrates superior performance compared to leading solvers such as SATzilla and Lingeling. Our evaluations, conducted against various benchmark sets, including those featured in recent SAT competitions, reveal that CLEVER-CNF consistently outperforms these state-of-the-art tools. This work not only contributes to the field of propositional logic but also provides practical solutions for handling large-scale CNF evaluations, paving the way for future research and applications in this area.",
        "ori-fast-z-score": -0.8307471607356973,
        "water-fast-z-score": 3.585685828003181,
        "rewrite-fast-z-score": 0.9534625892455924
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Statistical properties of dust far-infrared emission .\nAbstract:\nWe present the results of our analysis on the statistical properties of dust FIR emission in nearby galaxies, based on data obtained by ISO and Spitzer space telescopes. We find that the distribution function of dust FIR luminosity is well described by a log-normal form with an exponential tail at high luminosities. The mean value of the logarithmic luminosity dispersion for all samples considered here is 0.3 dex (factor of 2). This result suggests that there are two populations of dusty star-forming regions within each galaxy -one population associated with normal star formation activity and another one associated with intense bursts of star formation. Our study also shows that the fraction of galaxies containing such extreme objects increases towards higher redshifts. These findings have important implications for understanding the physical processes responsible for the evolution of distant galaxies as well as their contribution to the cosmic infrared background radiation. \n \n Keywords: Infrared, Galaxy",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Statistical properties of dust far - infrared emission . Abstract : We present the conclusion of our analysis on the statistical characteristics of dust FIR absorption in nearby galaxies , using on evidence derived by ISO and Spitzer space telescopes .We see that the distribution function of dust FIR luminosity is well described by a log - normal shape with an exponential tail at high luminosities . The mean value of the logarithmic luminosity dispersion for all specimens considered here is 0 . 3 dex ( factor of 2 ) .This result suggests that there are two communities of dusty star - creating areas within each galaxy - one community correlated with normal star formation activity and another one related with fierce bursts of galaxy formation . Our study also shows that the fraction of stars bearing such extreme objects increases towards higher redshifts .These studies have important implications for studying the physical processes responsible for the evolution of distant galaxies as well as their impact to the cosmic infrared background radiation . Keywords : Infrared , Galaxy",
        "rewrite_text": "Title: Statistical Properties of Dust Far-Infrared Emission\n\nAbstract: In this article, we present the findings from our comprehensive analysis of the statistical properties of far-infrared (FIR) emission from dust in nearby galaxies, utilizing data obtained from the ISO and Spitzer space telescopes. Our investigation reveals that the distribution function of dust FIR luminosity exhibits a log-normal distribution with an exponential tail at the higher luminosity end. The average logarithmic dispersion of luminosity across all examined galaxies is found to be 0.3 dex, which corresponds to a factor of two variation. This observation indicates the presence of two distinct populations of star-forming regions within each galaxy: one that is associated with typical star formation processes and another that is linked to intense bursts of star formation activity. Furthermore, our analysis indicates that the prevalence of these extreme star-forming regions increases with higher redshifts. These findings have significant implications for understanding the physical mechanisms driving the evolution of distant galaxies and their contributions to the cosmic infrared background radiation. Our study enhances the current knowledge of galaxy formation and evolution, providing a clearer picture of the role that dust FIR emission plays in the broader context of astrophysical research. \n\nKeywords: Infrared, Galaxy",
        "ori-fast-z-score": 0.21320071635561041,
        "water-fast-z-score": 5.193989612031165,
        "rewrite-fast-z-score": 1.507556722888818
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Proper Motions in the Galactic Bulge: Plaut s Window .\nAbstract:\nWe present proper motions for stars with magnitudes between 8 and 16, obtained by combining data from two epochs of photographic plates taken at the Palomar Observatory (POSS-I) and one epoch of digital images taken with the Hubble Space Telescope (HST). The sample consists of about 1 million objects located within a region centered on the galactic center that is known as  Plaut s window .  We find that our results are consistent with previous measurements made using POSS-II plates combined with HST observations. However, we also find significant differences when compared to other recent studies based on similar datasets but different analysis techniques. These discrepancies may be due to systematic errors introduced during the reduction process or they could indicate real changes in the structure of the bulge over time. Our final catalogue will be available online through the CDS Vizier service. This work was supported by NASA grant NAG5-13523.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Proper Motions in the Galactic Bulge : Plaut s Window . Abstract : We present proper motions for stars with magnitudes between 8 and 16 , obtained by combining information from two epochs of photographic sheets taken at the Palomar Observatory ( POSS - I ) and one epoch of digital photographs took with the Hubble Space Telescope ( HST ) .The sample consists of about 1 million bodies located within a region focused on the galactic center that is known as Plaut s window . We see that our findings are compatible with previous measurements made use POSS - II sheets combined with HST observations .However , we also find considerable variations when compared to other recent studies relying on similar datasets but different analysis methods . These discrepancies may be due to systematic errors acquired during the reduction phase or they may indicate real improvements in the composition of the bulge over time .Our last catalogue will be available digital through the CDS Vizier network . This project was supported by NASA grant NAG5 - 13523 .",
        "rewrite_text": "Title: Proper Motions in the Galactic Bulge: Plaut's Window\n\nAbstract: In this study, we present an analysis of proper motions for stars with magnitudes ranging from 8 to 16, derived from a combination of data collected from two epochs of photographic plates taken at the Palomar Observatory (POSS-I) and one epoch of digital images captured by the Hubble Space Telescope (HST). Our sample encompasses approximately 1 million stars situated in a region centered around the galactic core, specifically referred to as Plaut's Window. Our results align well with previous measurements obtained from POSS-II plates in conjunction with HST data. However, we observe significant discrepancies when comparing our findings to other recent studies that utilized similar datasets but employed different analytical techniques. These variations may stem from systematic errors introduced during the data reduction process, or they could reflect genuine changes in the composition of the galactic bulge over time. The final catalog of our findings will be made available in digital format through the CDS Vizier network. This research was conducted with the support of NASA grant NAG5-13523.",
        "ori-fast-z-score": -0.23570226039551587,
        "water-fast-z-score": 5.579886659703326,
        "rewrite-fast-z-score": -0.3464101615137754
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Influence of the lattice topography on a three-dimensional, controllable Brownian motor .\nAbstract:\nWe report an experimental realization of a novel type of 3D Brownian motors based on colloidal particles trapped in periodic potentials created by laser interference patterns. The potential landscape is engineered to have two different types of local minima separated by barriers with varying heights and widths. We show that this design allows for controlling both directional transport as well as its speed over several orders of magnitude. This work opens up new possibilities for designing active materials with tunable properties. A growing number of applications require systems capable of converting energy into directed motion at low Reynolds numbers  1  . In recent years, there has been significant progress towards realizing such devices known as  Brownian motors   2  , which are typically composed of many interacting particles moving through complex environments  3  .\nIn particular, it was shown theoretically  4  and experimentally  5  that one can create a unidirectional current of colloids using optical traps arranged in a 2D square or honeycomb pattern  6  . However, these designs cannot be easily extended to three dimensions (3D) due to technical limitations associated with creating stable trapping sites  7, 8  . Here we demonstrate how to overcome those challenges by engineering the shape of the potential wells and barriers in order to achieve robust 3D transport. Our approach relies on the use of holographic optical tweezers  9  to trap polystyrene microspheres suspended in water inside a glass capillary tube  10  . By changing the phase between the beams forming each individual trap  11  , we were able to generate a variety of potential landscapes  12  ranging from simple double-well structures  13  to more complicated ones containing multiple barriers  14  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Influence of the crystal topography on a three - dimensional , controllable Brownian motor . Abstract : We report an experimental realization of a new kind of 3D Brownian motors based on colloidal particles confined in periodic potentials created by laser interference patterns .The future topography is designed to have two different kinds of local minima separated by barriers with varying heights and widths . We suggest that this layout allows for controlling both directional travel as well as its velocity over several orders of magnitude .This study opens up new possibilities for modeling active elements with tunable properties . A growing number of applications need devices capable of converting energy into directed motion at low Reynolds numbers 1 .In recent years , there has been significant progress towards realizing such machines called as Brownian motors 2 , which are typically consist of several interacting molecules moving through complex environments 3 . In particular , it was shown theoretically 4 and experimentally 5 that one can create a unidirectional current of colloids using optical trapping ordered in a 2D triangular or honeycomb shape 6 .However , these designs cannot be easily enlarged to three dimensions ( 3D ) related to technical requirements related with creating stable trap places 7 , 8 . Here we prove how to overcome those obstacles by designing the form of the potential wells and fences in order to achieve robust 3D transport .Our solution uses on the using of holographic optical tweezers 9 to capture polystyrene microspheres hanging in water inside a glass capillary loop 10 . By changing the phase between the beams making each individual trap 11 , we were could to produce a variety of potential landscapes 12 ranging from complicated triple - well complexes 13 to more complicated ones featuring multiple barriers 14 .",
        "rewrite_text": "**Title:** Influence of Crystal Topography on a Three-Dimensional Controllable Brownian Motor\n\n**Abstract:** This study presents an innovative experimental realization of a novel type of three-dimensional (3D) Brownian motor, utilizing colloidal particles that are confined within periodic potentials generated by laser interference patterns. The designed topography features two distinct types of local minima, which are separated by barriers of varying heights and widths. This configuration enables precise control over both the direction of motion and the velocity of the particles, allowing for adjustments across several orders of magnitude. The implications of this research are significant, as it paves the way for the development of active elements with customizable properties, which are increasingly essential in various applications requiring the conversion of energy into directed motion at low Reynolds numbers.\n\nRecent advancements in the field have led to the emergence of Brownian motors, which typically consist of multiple interacting molecules navigating through complex environments. Prior theoretical and experimental work has demonstrated the feasibility of generating unidirectional currents of colloidal particles through optical trapping arranged in two-dimensional (2D) geometries, such as triangular or honeycomb configurations. However, these designs face challenges when attempting to scale to three-dimensional systems, primarily due to the technical difficulties associated with establishing stable trapping locations.\n\nIn this research, we address these challenges by strategically designing the shapes of potential wells and barriers to facilitate robust 3D transport. Our approach employs holographic optical tweezers to manipulate polystyrene microspheres suspended in water within a glass capillary loop. By varying the phase between the laser beams that create each individual trap, we successfully generate a diverse array of potential landscapes, ranging from intricate triple-well structures to more complex configurations featuring multiple barriers. This work not only enhances our understanding of Brownian motors but also opens new avenues for the design of advanced micro- and nanoscale devices with tunable motion characteristics.",
        "ori-fast-z-score": -0.5734623443633283,
        "water-fast-z-score": 7.242717283063319,
        "rewrite-fast-z-score": 0.24096579867074966
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Minimal size of a barchan dune .\nAbstract:\nWe study the minimal size of a barchan, which is one of the most common types of sand dunes in nature. We show that this problem can be formulated as an optimal control problem for a nonlinear partial differential equation with nonlocal boundary conditions and prove existence of solutions by using variational methods. The numerical results are obtained by applying finite element method to discretize the state equations and then solving them by Newton s iteration scheme. Finally we present some examples illustrating our theoretical findings. Sand dunes are among the most beautiful natural phenomena on Earth. They have been studied extensively since the 19th century  1  . One of the simplest forms of sand dunes is called barchan  2  , see Figure 1 (a). It has a crescent shape with its horns pointing away from the wind direction. Barchans occur naturally over large areas around the world such as Australia  3  , Namibia  4  , Saudi Arabia  5  , China  6  , Japan  7  , etc.. In recent years there has been growing interest in studying mathematical models describing formation of sand dunes  8, 9, 10  .\nIn this work we consider the following model proposed by Kroy et al  11  : \nwhere u(x) denotes the height of the sand bed at position x ∈ Ω =  0, L  × R + ; f > 0 represents the rate of deposition; g ≥ 0 stands for the erosion coefficient; h(u) describes the effect of surface tension; p(x), q(x) represent the pressure terms due to gravity and friction respectively; α > 0 measures the strength of the wind blowing along x-axis; β > 0 characterizes the resistance against the flow of air; γ > 0 is related to the cohesion between grains of sand; θ is the angle of repose of sand particles; c > 0 is the constant volume fraction of sand per unit area; finally, n is the outward normal vector to the boundary Γ = {0 < x < L} × {0} ∪ {L} × R + . For more details about physical meaning of parameters involved in system (1) , please refer to  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Minimal size of a barchan dune . Abstract : We consider the minimal size of a barchan , which is one of the most common kinds of dunes dunes in nature .We see that this question can be formulated as an optimal control problem for a nonlinear partial differential function with nonlocal boundary constraints and prove existence of solutions by using variational techniques . The mathematical findings are derived by using finite element method to discretize the state equations and then solving them by Newton s iteration scheme .Finally we present some examples illustrating our theoretical results . Sand dunes are among the most beautiful natural creatures on Earth .They have been studied thoroughly since the 19th century 1 . One of the simplest forms of dunes dunes is known barchan 2 , see Figure 1 ( a ) .It has a crescent shape with its horns pointing away from the wind position . Barchans occur commonly over large areas around the world such as Australia 3 , Namibia 4 , Saudi Arabia 5 , China 6 , Japan 7 , etc . .In recent recently there has been growing interest in studying numerical models governing formation of dunes dunes 8 , 9 , 10 . In this study we consider the following model proposed by Kroy et al 11 : where u ( x ) denotes the height of the sand bed at position x ∈ Ω = 0 , L × R + ; f > 0 represents the speed of deposition ; g ≥ 0 stands for the erosion factor ; h ( u ) refers the impact of surface friction ; p ( x ) , q ( x ) describe the pressure terms due to gravity and tension respectively ; α > 0 measures the strength of the wind blowing along x - axis ; β > 0 characterizes the tolerance against the movement of air ; γ > 0 is related to the cohesion between particles of dunes ; θ is the angle of repose of sand grains ; c > 0 is the constant volume fraction of dunes per unit area ; finally , n is the outward normal vector to the boundary Γ = { 0 < x < L } × { 0 } ∪ { L } × R + .For more details about physical context of components involved in system ( 1 ) , please refer to 12 .",
        "rewrite_text": "**Title: Minimal Size of a Barchan Dune**\n\n**Abstract:** This study investigates the minimal size of barchan dunes, which are among the most prevalent types of dunes found in natural environments. We approach this problem by framing it as an optimal control issue related to a nonlinear partial differential equation characterized by nonlocal boundary conditions. To establish the existence of solutions, we employ variational techniques. Our mathematical analysis utilizes the finite element method to discretize the governing state equations, which are subsequently solved using Newton's iteration scheme. We also provide illustrative examples that demonstrate our theoretical findings. Sand dunes, particularly barchans, are not only aesthetically striking but have also been the subject of extensive research since the 19th century. Barchans, recognized for their crescent shape with horns oriented away from the wind, are widespread across various regions, including Australia, Namibia, Saudi Arabia, China, and Japan. Recently, there has been an increasing interest in developing numerical models that describe the formation of these dunes. In this work, we analyze a model proposed by Kroy et al., where the variable \\( u(x) \\) represents the height of the sand bed at position \\( x \\) within the domain \\( \\Omega = [0, L] \\times \\mathbb{R}^+ \\). The model incorporates several parameters: \\( f > 0 \\) indicates the deposition speed, \\( g \\geq 0 \\) denotes the erosion factor, and \\( h(u) \\) reflects the effects of surface friction. Additionally, \\( p(x) \\) and \\( q(x) \\) account for pressure due to gravity and tension, respectively, while \\( \\alpha > 0 \\) measures wind strength along the x-axis, \\( \\beta > 0 \\) represents air movement resistance, and \\( \\gamma > 0 \\) relates to particle cohesion. The angle of repose of sand grains is denoted by \\( \\theta \\), \\( c > 0 \\) signifies the dune volume fraction per unit area, and \\( n \\) is the outward normal vector on the boundary \\( \\Gamma = \\{0 < x < L\\} \\times \\{0\\} \\cup \\{L\\} \\times \\mathbb{R}^+ \\). For further details regarding the physical context of the components in the system, please refer to the original work.",
        "ori-fast-z-score": -1.365472859134248,
        "water-fast-z-score": 5.4443572293729625,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Dynamical State fo the Starless Dense Core FeSt 1-457: A Pulsating Globule? .\nAbstract:\nWe present new near-infrared (NIR) and millimeter-wave observations of the starless dense core FeSt 1-457, which is located in the Taurus molecular cloud complex at a distance of 140 pc. The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 May 24-25 UT. We detected two sources within the central 0.5 arcmin region; one source was found to be associated with an infrared dark cloud (IRDC), while another source was not. Both sources are embedded deeply inside the dusty envelope surrounding the dense core. In addition, we observed this object simultaneously with the Nobeyama 45 m radio telescope at 1 mm wavelength during the same night as our NIR observation. No significant emission line features were seen in either spectrum. Using these observational results, we discuss possible scenarios for the formation of stars in such a young dense core.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  The Dynamical State fo the Starless Dense Core FeSt 1-457: A Pulsating Globule?.Abstract : We report new near - infrared ( NIR ) and millimeter - wave images of the starless dense core FeSt 1 - 457 , which is situated in the Taurus molecular mist complex at a distance of 140 pc . The NIR data were obtained with the Subaru observatory using the SofI instrument on 2005 May 24 - 25 UT .We observed two sources within the inner 0 . 5 arcmin region ; one source was reported to be involved with an infrared shadow cloud ( IRDC ) , while another source was not . Both sources are lodged deeply inside the dusty envelope surrounding the dense core .In addition , we studied this body simultaneously with the Nobeyama 45 m radio telescope at 1 mm frequency during the same night as our NIR observation . No notable emission line characteristics were witnessed in either spectrum .Using these observational results , we explain possible strategies for the formation of stars in such a young dense core .",
        "rewrite_text": "Title: The Dynamical State of the Starless Dense Core FeSt 1-457: A Pulsating Globule?\n\nAbstract: In this study, we present new near-infrared (NIR) and millimeter-wave imaging of the starless dense core FeSt 1-457, located within the Taurus molecular cloud complex at a distance of 140 parsecs. The NIR observations were conducted at the Subaru Observatory using the SofI instrument over the nights of May 24-25, 2005. Our imaging revealed two distinct sources within a 0.5 arcminute region of the core. One of these sources is associated with an infrared dark cloud (IRDC), while the other is not linked to any known IRDC features. Both sources are embedded deep within the dense, dusty envelope that characterizes the core. \n\nSimultaneously, we utilized the Nobeyama 45 m radio telescope to observe the core at a frequency of 1 mm during the same observational period. Notably, our spectral analysis did not reveal any significant emission line features, suggesting a lack of active star formation or chemical complexity in the region at this time. \n\nThese findings contribute to our understanding of the dynamical state of FeSt 1-457 and provide insights into the potential mechanisms for star formation in such nascent dense cores. We discuss various scenarios that could facilitate star formation in this environment, considering the implications of our observations on the evolutionary processes of starless dense cores. Overall, our research highlights the importance of multi-wavelength observations in unraveling the complexities of star formation in molecular clouds.",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 3.8247315498700596,
        "rewrite-fast-z-score": -0.8081220356417685
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Brain Prostheses as a Dynamic System (Immortalizing the Human Brain?) .\nAbstract:\nThe brain is an organ that has evolved to be dynamic and plastic, constantly changing its structure in response to internal and external stimuli.  The human brain can change throughout life by forming new connections between neurons or eliminating existing ones.   This ability allows humans to adapt to their environment and learn continuously.   However, this flexibility also makes it vulnerable to damage caused by disease, trauma, aging, etc., which may lead to neurological disorders such as Alzheimer s Disease, Parkinson s Disease, Huntington s Disease, Epilepsy, Traumatic Brain Injury, Multiple Sclerosis, etc.   In recent years there have been significant advances in neuroscience research aimed at understanding how the brain works and developing treatments for these diseases.   One approach involves using neural prosthetic devices to replace damaged parts of the brain with artificial components that are capable of performing similar functions.   Neural prosthetics are electronic systems designed to interface directly with the nervous system to restore lost function due to injury or disease.   These devices include microelectrodes implanted into the brain tissue to record electrical activity; stimulating electrodes placed on or near nerves to deliver electrical stimulation; and wireless communication links used to transmit data recorded by the recording electrodes and/or control signals generated by the stimulating electrodes back to a computer located outside the body.   ...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Brain Prostheses as a Dynamic System (Immortalizing the Human Brain?).Abstract : The mind is an organ that has evolution to be dynamic and plastic , constantly shifting its composition in reaction to internal and external stimuli . The human mind can shift throughout life by forming fresh connections between brains or eliminating existing ones .This skill allows individuals to adapt to their environment and learn continuously . However , this flexibility still makes it susceptible to disruption caused by illness , trauma , aging , etc . , which sometimes lead to neurological disorders such as Alzheimer s Disease , Parkinson s Disease , Huntington s Disease , Epilepsy , Traumatic Brain Injury , Multiple Sclerosis , etc .In past decades there have been significant advances in neuroscience study aiming at studying how the brain acts and developing treatments for these diseases . One approach involves utilizing neural prosthetic devices to replace injured parts of the brain with artificial components that are capable of executing identical functions .Neural prosthetics are electronic systems designed to interface directly with the nervous system to restore lost activity resulting to trauma or disease . These systems include microelectrodes implanted into the brain skin to track electrical behavior ; stimulating electrodes put on or close nerves to provide electrical stimulation ; and wireless communication connections utilized to transmit data produced by the recording electrodes and / or control messages produced by the stimulating electrodes forward to a computer situated outside the brain ....",
        "rewrite_text": "**Title: Brain Prostheses as a Dynamic System (Immortalizing the Human Brain?)**\n\n**Abstract:** The human mind is a remarkably dynamic and adaptable organ, characterized by its ability to evolve and reorganize in response to both internal and external stimuli. Throughout an individual's life, the brain continuously forms new neural connections while also pruning away those that are no longer needed. This remarkable plasticity enables individuals to learn and adapt to their environments effectively. However, this same flexibility renders the brain vulnerable to various disruptions, including those caused by illness, trauma, and the aging process. Such disruptions can lead to a range of neurological disorders, including Alzheimer’s Disease, Parkinson’s Disease, Huntington’s Disease, epilepsy, traumatic brain injury, and multiple sclerosis. \n\nIn recent decades, significant advancements in neuroscience have focused on understanding brain function and developing innovative treatments for these debilitating conditions. One promising avenue of research involves the use of neural prosthetic devices, which aim to replace damaged areas of the brain with artificial components that can perform similar functions. These neural prosthetics are sophisticated electronic systems designed to interface directly with the nervous system, thereby restoring lost functionality due to injury or disease. \n\nThe components of these systems typically include microelectrodes that are implanted within the brain to monitor electrical activity, as well as stimulating electrodes placed on or near nerves to deliver electrical stimulation. Additionally, wireless communication technologies are employed to transmit data collected by the recording electrodes and to relay control signals generated by the stimulating electrodes to an external computer. This integration of technology and biology not only holds the potential to restore lost capabilities but also raises profound questions about the nature of consciousness and the future of human cognitive enhancement. As research progresses, the implications of brain prostheses could redefine our understanding of the human brain and its potential for immortality.",
        "ori-fast-z-score": -1.4729193886373175,
        "water-fast-z-score": 7.24191812652287,
        "rewrite-fast-z-score": -0.5696519211398116
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Chiral symmetry and the string description of excited hadrons .\nAbstract:\nWe discuss how chiral symmetry is realized in QCD, with particular emphasis on its implications for the spectrum of excited states. We argue that the lowest-lying excitations are described by open strings attached to quarks at one end and antiquarks at the other; these can be viewed as mesons or glueballs depending on whether they carry color charge or not.  The next set of excitations corresponds to closed strings which wind around the compactified dimension (the time direction) once or more times. These correspond to baryon resonances. Finally we consider higher-spin excitations corresponding to multiple winding modes of the closed string; these have spin greater than two but still less than the number of colors Nc. In this talk I will present some recent results obtained using holographic methods applied to gauge theories dual to supergravity backgrounds. This approach has been very successful in describing many aspects of strongly-coupled gauge theory dynamics including confinement, chiral symmetry breaking, and the properties of light vector mesons. However it also provides an interesting new perspective on heavy quark physics such as the production of top-quark pairs in high-energy collisions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Chiral symmetry and the string description of excited hadrons . Abstract : We discuss how chiral symmetry is realized in QCD , with particular focuses on its consequences for the spectrum of excited states .We argue that the smallest - lying excitations are explained by open strings attached to quarks at one end and antiquarks at the other ; these can be viewed as mesons or glueballs depending on whether they carry color charge or not . The last set of excitations corresponds to closed strings which wind around the compactified dimension ( the period direction ) once or more times .These correspond to baryon resonances . Finally we define higher - spinning excitations corresponding to multiple winding modes of the shut string ; these have spin greater than two but still less than the number of colors Nc .In this talk I will present some latest findings obtained using holographic methods applied to gauge fields dual to supergravity environments . This method has been very effective in representing many aspects of highly - coupled gauge theory physics including confinement , chiral symmetry breaking , and the properties of light vector mesons .However it also provides an interesting modern perspective on heavy quark theory such as the production of top - quark pairs in high - energy collisions .",
        "rewrite_text": "In this article, we explore the realization of chiral symmetry within Quantum Chromodynamics (QCD) and its implications for the spectrum of excited hadronic states. Our analysis highlights that the lowest-lying excitations can be interpreted as open strings, with one end attached to a quark and the other to an antiquark. These configurations can manifest as either mesons or glueballs, contingent upon whether they possess color charge. Additionally, we identify a distinct category of excitations represented by closed strings that wrap around a compactified dimension, corresponding to baryon resonances. Furthermore, we introduce the concept of higher-spinning excitations, which are associated with multiple winding modes of the closed string. These excitations exhibit spins greater than two but remain below the number of colors, Nc. \n\nIn this presentation, I will share recent findings derived from the application of holographic methods to gauge fields that are dual to supergravity frameworks. This approach has proven to be a powerful tool for elucidating various phenomena in strongly coupled gauge theories, including confinement, the breaking of chiral symmetry, and the characteristics of light vector mesons. Moreover, it offers a contemporary viewpoint on heavy quark dynamics, particularly in relation to the production of top-quark pairs during high-energy collisions. Our findings contribute to a deeper understanding of the intricate relationship between chiral symmetry and the string theory description of hadronic states, paving the way for further research in this domain.",
        "ori-fast-z-score": 1.8905706613989794,
        "water-fast-z-score": 6.601706163700764,
        "rewrite-fast-z-score": 1.3862065601673441
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Observational bounds on the cosmic radiation density .\nAbstract:\nWe present new observational constraints on the cosmic ray (CR) energy density and its evolution with redshift, based on gamma-ray observations by Fermi/LAT in the range 0 < z < 1.5. We find that CRs contribute at most 10% to the total pressure budget of the universe at redshifts below 2. This upper limit is consistent with theoretical expectations for the contribution of CRs accelerated by supernovae. The results are also compatible with previous measurements using radio data. These limits can be used as priors when modeling the effects of CRs on cosmological observables such as galaxy clustering or weak lensing. Cosmic rays (CRs), charged particles which fill space uniformly over large volumes, have been observed throughout our Galaxy and beyond. They play an important role in many astrophysical phenomena including galactic winds, star formation, and possibly even the acceleration of ultra-high-energy cosmic rays  1  . However, their origin remains unknown  2  .\nIn this work we use gamma-ray observations made by the Large Area Telescope (LAT) aboard the Fermi satellite  3  , to place tight constraints on the amount of CRs contributing to the overall pressure budget of the Universe  4  . In particular, we consider two different models for the CR distribution function f(p,z). First, we assume that it follows a power law spectrum dN/dE ~ E^{-alpha} between energies Emin = 10 GeV and Emax = 100 TeV; secondly, we adopt a broken power-law model where the spectral index changes from alpha1 = -2.2 to alpha2 = -3 above some break energy Eb = 50 GeV. For both cases, we fix the normalization factor A by requiring that the integral of f(p,z) over all momenta equals unity. \nThe resulting CR distributions are shown in Figure 1 . \nTo calculate the effect of these CR populations on the expansion history of the universe, we solve numerically the coupled system of equations describing the time-evolution of the background...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Observational bounds on the cosmic rays flux . Abstract : We introduce novel observational restrictions on the cosmic ray ( CR ) energy density and its expansion with redshift , built on gamma - ray observations by Fermi / LAT in the range 0 < z < 1 . 5 .We see that CRs contribute at most 10 % to the total pressure budget of the universe at redshifts below 2 . This upper maximum is compatible with theoretical expectations for the contribution of CRs accelerated by supernovae .The results are also compatible with previous measurements used radio data . These limits can be used as priors when modeling the effects of CRs on cosmological observables such as galaxy clustering or strong lensing .Cosmic rays ( CRs ) , charged particles which fill space uniformly over large quantities , have been observed throughout our Galaxy and beyond . They play an important role in many astrophysical processes including galactic winds , star formation , and maybe even the acceleration of ultra - low - energy cosmic rays 1 .However , their source remains unidentified 2 . In this project we using gamma - ray observations made by the Large Area Telescope ( LAT ) aboard the Fermi satellite 3 , to place tight limitations on the proportion of CRs contributing to the overall pressure budget of the Universe 4 .In particular , we define two different models for the CR distribution function f ( p , z ) . First , we suppose that it takes a power law spectrum dN / dE ~ E ^ { - alpha } between frequencies Emin = 10 GeV and Emax = 100 TeV ; secondly , we choose a broken power - law description where the spectral index shifts from alpha1 = - 2 . 2 to alpha2 = - 3 above some broke energy Eb = 50 GeV .For both cases , we solve the normalization factor A by requiring that the integral of f ( p , z ) over all momenta equals unity . The resulting CR distributions are shown in Figure 1 .To estimate the impact of these CR populations on the expansion history of the universe , we solve numerically the coupled system of equations explaining the period - progression of the background . . .",
        "rewrite_text": "In this article, we present new observational constraints on the energy density of cosmic rays (CRs) and their evolution with redshift, utilizing gamma-ray data from the Fermi Large Area Telescope (LAT) within the redshift range of 0 < z < 1.5. Our findings indicate that CRs contribute no more than 10% to the total pressure budget of the universe at redshifts below 2, aligning with theoretical predictions regarding the contributions from CRs accelerated by supernovae. This upper limit is consistent with earlier measurements derived from radio data, reinforcing the reliability of our results. These constraints can serve as valuable priors in modeling the influence of CRs on various cosmological phenomena, including galaxy clustering and strong gravitational lensing.\n\nCosmic rays, which are charged particles that permeate space uniformly, have been detected throughout our galaxy and beyond. They are integral to numerous astrophysical processes, such as galactic winds and star formation, and may even play a role in the acceleration of ultra-low-energy cosmic rays. However, the origins of these particles remain largely unknown. In our study, we leverage gamma-ray observations from the Fermi LAT to impose stringent limits on the fraction of CRs contributing to the universe's overall pressure budget.\n\nWe explore two distinct models for the cosmic ray distribution function, f(p, z). The first model assumes a power-law spectrum, described by dN/dE ~ E^(-α), within the energy range of 10 GeV to 100 TeV. The second model adopts a broken power-law approach, where the spectral index transitions from α1 = -2.2 to α2 = -3 at a break energy of 50 GeV. For both models, we determine the normalization factor A by ensuring that the integral of f(p, z) across all momenta equals one. The resulting distributions of cosmic rays are illustrated in Figure 1. To assess the implications of these CR populations on the universe's expansion history, we numerically solve the coupled equations governing the evolution of the cosmic background.",
        "ori-fast-z-score": 0.4931969619160719,
        "water-fast-z-score": 6.695271963607354,
        "rewrite-fast-z-score": 2.1666666666666665
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Physisorption of Nucleobases on Graphene .\nAbstract:\nThe physisorption of nucleobases (adenine, cytosine, guanine and thymine) onto graphene is investigated by density functional theory calculations at the B3LYP/6-31G(d) level in vacuum conditions. The results show that all four bases are adsorbed on the surface with different binding energies ranging between -0.27 eV for adenine to -1.10 eV for cytosine. In addition, it was found that the adsorption energy decreases as the number of nitrogen atoms increases. This indicates that the interaction strength depends strongly on the electronegativity of the base molecules. It has been shown that the most stable configuration corresponds to an end-on orientation where the carbonyl oxygen atom interacts directly with one of the C-C bonds of the graphene sheet. \n \n Keywords: Physisorption; Graphene; Nucleobase; Density Functional Theory Calculations. Introduction \n \n Graphene is a two-dimensional material consisting of sp2-hybridized carbon atoms arranged into a honeycomb lattice structure  1  . Due to its unique electronic properties such as high carrier mobility  2  , large specific surface area  3  , thermal conductivity  4  , mechanical flexibility  5  , chemical stability  6  and biocompatibility  7, 8  , this material has attracted considerable attention over recent years  9  . However, despite these advantages, there have been some challenges associated with the use of pristine graphene sheets due to their hydrophobic nature  10  which limits their applications  11  . Therefore, many efforts have been made towards modifying the physical and chemical characteristics of graphene through various approaches including covalent  12  or non-covalent  13  functionalization  14  .\n \nIn particular, non-covalent functionalization can be achieved via π-π interactions  15  , hydrogen bonding  16  , electrostatic  17  , van der Waals  18  and ionic  19  forces  20  . Among them, π-π stacking is considered to be the strongest noncovalent force  21  . For example, several studies have reported that aromatic compounds  22  , fullerenes  23  , porphyrins  24  , metal complexes  25  and biomolecules  26  could interact with graphene surfaces via π-",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Physisorption of Nucleobases on Graphene . Abstract : The physisorption of nucleobases ( adenine , cytosine , guanine and thymine ) onto graphene is investigated by density functional theory estimates at the B3LYP / 6 - 31G ( d ) level in vacuum environments .The results show that all four bases are adsorbed on the surface with varying binding energies ranging between - 0 . 27 eV for adenine to - 1 . 10 eV for cytosine . In addition , it was shown that the adsorption energy decreases as the proportion of nitrogen atoms increases .This implies that the interaction strength depends strongly on the electronegativity of the base atoms . It has been shown that the most stable configuration refers to an ending - on position where the carbonyl oxygen atom interacts closely with one of the C - C bonds of the graphene sheet .Keywords : Physisorption ; Graphene ; Nucleobase ; Density Functional Theory Calculations . Introduction Graphene is a two - dimensional material consisting of sp2 - hybridized carbon atoms arranged into a honeycomb lattice structure 1 .Due to its unique electronic properties such as wide carrier mobility 2 , large particular surface region 3 , thermal conductivity 4 , thermal flexibility 5 , chemical integrity 6 and biocompatibility 7 , 8 , this metal has garnered considerable notice over recent months 9 . However , despite these benefits , there have been some challenges associated with the using of pristine graphene strips due to their hydrophobic nature 10 which restricted their functionality 11 .Therefore , various efforts have been placed towards modifying the physical and chemical qualities of graphene through numerous approaches including covalent 12 or non - covalent 13 functionalization 14 . In particular , non - covalent functionalization can be obtained via π - π interactions 15 , hydrogen bonding 16 , electrostatic 17 , van der Waals 18 and ionic 19 forces 20 .Among them , π - π stacking is regarded to be the powerful noncovalent force 21 . For instance , various trials have reported that aromatic molecules 22 , fullerenes 23 , porphyrins 24 , metal ions 25 and biomolecules 26 could interact with graphene surfaces via π -",
        "rewrite_text": "**Title:** Physisorption of Nucleobases on Graphene\n\n**Abstract:** This study explores the physisorption characteristics of nucleobases—adenine, cytosine, guanine, and thymine—on graphene using density functional theory (DFT) calculations at the B3LYP/6-31G(d) level in vacuum conditions. The findings reveal that all four nucleobases exhibit adsorption on the graphene surface, with binding energies ranging from -0.27 eV for adenine to -1.10 eV for cytosine. Notably, the results indicate that the adsorption energy diminishes with an increase in the number of nitrogen atoms present in the nucleobases, suggesting a strong correlation between interaction strength and the electronegativity of the constituent atoms. The most stable adsorption configuration is identified as an end-on orientation, where the carbonyl oxygen atom of the nucleobase closely interacts with one of the C-C bonds in the graphene lattice. \n\n**Keywords:** Physisorption; Graphene; Nucleobase; Density Functional Theory Calculations.\n\n**Introduction:** Graphene, a two-dimensional material composed of sp²-hybridized carbon atoms arranged in a honeycomb lattice, has attracted significant attention due to its remarkable electronic properties, including high carrier mobility, extensive surface area, excellent thermal conductivity, flexibility, chemical stability, and biocompatibility. Despite these advantageous properties, the inherent hydrophobicity of pristine graphene poses challenges that limit its practical applications. Consequently, extensive research has focused on enhancing the physical and chemical properties of graphene through various modification strategies, including both covalent and non-covalent functionalization. Among these methods, non-covalent functionalization is particularly noteworthy, as it can be achieved through mechanisms such as π-π interactions, hydrogen bonding, electrostatic forces, van der Waals forces, and ionic interactions. Among these, π-π stacking is recognized as a potent non-covalent interaction, facilitating the adsorption of a wide range of molecules, including aromatic compounds, fullerenes, porphyrins, metal ions, and biomolecules onto graphene surfaces. This study aims to deepen the understanding of nucleobase interactions with graphene, which could have implications for the development of graphene-based biosensors and other biotechnological applications.",
        "ori-fast-z-score": -0.2727272727272727,
        "water-fast-z-score": 7.004606779044222,
        "rewrite-fast-z-score": -0.9760921603577252
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Investigation of relaxation phenomena in high-temperature superconductors HoBa2Cu3O7-d at the action of pulsed magnetic fields .\nAbstract:\nThe influence of pulsed magnetic fields on the relaxation processes in HTSC was investigated by measuring the temperature dependence of resistance and Hall coefficient for samples with different oxygen content (d = 0, 1). The results show that the application of pulsed magnetic fields leads to an increase in the resistivity and Hall mobility of the sample with d = 0. This effect is explained as due to the appearance of additional scattering centers caused by defects formed during the process of magnetization reversal. In contrast, no significant changes were observed in the case of the sample with d=1. It can be assumed that this difference is associated with the presence of structural disordering in the crystal lattice of the latter compound. \n \n Keywords: High-Tc Superconductor, Pulsed Magnetic Field, Relaxation Processes, Defects Formation, Magnetoresistance, Hall Effect. Introduction \n \n Investigation of relaxation phenomena in high temperature superconductors under the action of pulsed external magnetic fields has been attracting considerable attention recently  1 - 5  . These studies are important both for understanding the physics of these materials and for practical applications  6  -  8  . \n \n In particular, it should be noted that the investigation of relaxation processes in HTSCs allows one to study the dynamics of defect formation  9  , which plays an important role in determining their transport properties  10  . At present there are several models describing the mechanism of defect generation  11  -  13  . However, none of them takes into account the possibility of defect formation induced by the action of pulsed fields  14  . \nExperimental details\n\nIn our work we used single crystals of two compounds with different oxygen content: HoBa 2 Cu 3 O 7−δ (HBS) and YBa 2 Cu 3 O 6+δ (YBS), grown using the floating zone method  15  . The oxygen concentration in the samples was determined by iodometric titration  16  . The typical size of the samples was about 5 × 4 mm 2 . The measurements were carried out in liquid helium cryostats equipped with pulse magnets  17  . The maximum value of the magnetic induction reached up to B max =",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Investigation of relaxed processes in high - temperature superconductors HoBa2Cu3O7 - d at the activity of pulsed magnetic fields . Abstract : The impact of pulsed magnetic fields on the relaxation processes in HTSC was investigated by monitoring the temperature dependence of resistance and Hall coefficient for specimens with various oxygen composition ( d = 0 , 1 ) .The results show that the application of pulsed magnetic fields leads to an increase in the resistivity and Hall mobility of the sample with d = 0 . This phenomenon is understood as owing to the appearance of added scattering centers caused by defects formed during the process of magnetization reversal .In contrast , no major changes were detected in the case of the sample with d = 1 . It can be assumed that this distinction is associated with the presence of structural disordering in the crystal lattice of the latter compound .Keywords : High - Tc Superconductor , Pulsed Magnetic Field , Relaxation Processes , Defects Formation , Magnetoresistance , Hall Effect . Introduction Investigation of relaxed behaviour in high heat superconductors under the effects of pulsed external magnetic waves has been drawing greater notice recently 1 - 5 .These studies are important both for knowledge the physics of these structures and for useful use 6 - 8 . In particular , it should be mentioned that the examination of vibration mechanisms in HTSCs allows one to study the dynamics of defect structure 9 , which plays an important role in establishing their transport properties 10 .At currently there are several models explaining the process of defect generation 11 - 13 . However , none of them took into consideration the possibility of defect formed induced by the activity of pulsed fields 14 .Experimental details In our work we using single crystals of two compounds with varying dioxide content : HoBa 2 Cu 3 O 7−δ ( HBS ) and YBa 2 Cu 3 O 6 + δ ( YBS ) , grown using the floating zone method 15 . The oxygen fraction in the samples was calculated by iodometric titration 16 .The typical size of the tests was about 5 × 4 mm 2 . The tests were carried out in pure helium cryostats fitted with pulse magnets 17 .The maximum value of the magnetic induction reached up to B max =",
        "rewrite_text": "**Title:** Investigation of Relaxation Processes in High-Temperature Superconductors HoBa2Cu3O7−δ Under Pulsed Magnetic Fields\n\n**Abstract:** This study explores the effects of pulsed magnetic fields on the relaxation processes in high-temperature superconductors (HTSC), specifically focusing on HoBa2Cu3O7−δ (HBS) samples with varying oxygen content (δ = 0, 1). We conducted a detailed analysis of the temperature-dependent resistance and Hall coefficient of these specimens. Our findings reveal that the application of pulsed magnetic fields significantly increases the resistivity and Hall mobility in the sample with δ = 0. This increase is attributed to the emergence of additional scattering centers, which are believed to be caused by defects generated during the magnetization reversal process. Conversely, the sample with δ = 1 exhibited no substantial changes in its electrical properties under similar conditions. This discrepancy suggests that the structural disorder present in the crystal lattice of the δ = 1 compound may play a crucial role in its response to pulsed magnetic fields. \n\nThe investigation of relaxation behaviors in HTSCs under pulsed magnetic fields has gained considerable attention in recent years, as it is essential for advancing our understanding of the underlying physics of these materials and their practical applications. The study of vibrational mechanisms in HTSCs provides insights into the dynamics of defect structures, which are pivotal in determining their transport properties. While several models have been proposed to explain defect generation, none have adequately addressed the potential for defect formation induced by pulsed magnetic fields. \n\nIn our experimental setup, we utilized single crystals of HBS and YBa2Cu3O6+δ (YBS), which were synthesized using the floating zone method. The oxygen content in the samples was quantified through iodometric titration, and the typical dimensions of the specimens were approximately 5 × 4 mm². Experiments were conducted in a helium cryostat equipped with pulsed magnets, achieving a maximum magnetic induction of B_max. This research contributes to the growing body of knowledge regarding the interplay between pulsed magnetic fields and defect dynamics in high-temperature superconductors, paving the way for future studies in this field. \n\n**Keywords:** High-Tc Superconductor, Pulsed Magnetic Field, Relaxation Processes, Defect Formation, Magnetoresistance, Hall Effect.",
        "ori-fast-z-score": -1.4411533842457842,
        "water-fast-z-score": 6.304886387294215,
        "rewrite-fast-z-score": -0.23791547571544325
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Infrared High-Resolution Spectroscopy of Post-AGB Circumstellar Disks. I. HR 4049 - The Winnowing Flow Observed? .\nAbstract:\nWe present the first results on infrared high-resolution spectroscopy (HRS) of post-AGB disks, obtained with CRIRES/VLT and NIRSPEC/Keck II. We find that the disk around HR 4049 is dominated by emission lines originating in an extended region at temperatures between 1000-2000 K. This temperature range corresponds to the expected location of dust grains which are being evaporated due to stellar radiation pressure. In addition we detect several absorption features which can be attributed to gas-phase molecules such as CO, H2O, OH, NH3, CH4, C2H2, SiO, HCN, CCH, CN, H2S, SO2, CS, and FeH. These observations provide new insights into the physical conditions within these objects. They also show how important it will be for future studies to combine spatially resolved information about the distribution of molecular species with detailed spectroscopic data. \n \n Keywords: circumstellar disk",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Infrared High - Resolution Spectroscopy of Post - AGB Circumstellar Disks . I . HR 4049 - The Winnowing Flow Observed ?. Abstract : We report the first findings on infrared high - resolution spectroscopy ( HRS ) of post - AGB disks , obtained with CRIRES / VLT and NIRSPEC / Keck II .We see that the disk around HR 4049 is dominated by absorption tracks originating in an extended region at temperatures between 1000 - 2000 K . This temperature range corresponds to the expected location of dust grains which are being evaporated due to stellar radiation stress . In addition we locate many absorption elements which can be due to gas - phase particles such as CO , H2O , OH , NH3 , CH4 , C2H2 , SiO , HCN , CCH , CN , H2S , SO2 , CS , and FeH .These measurements give novel knowledge into the physical conditions within these objects . They also demonstrate how important it will be for future research to mix spatially resolved data about the distribution of biological species with comprehensive spectroscopic data .Keywords: circumstellar disk",
        "rewrite_text": "**Title:** Infrared High-Resolution Spectroscopy of Post-AGB Circumstellar Disks: I. HR 4049 - Observing the Winnowing Flow?\n\n**Abstract:** In this study, we present groundbreaking results from our infrared high-resolution spectroscopy (HRS) investigations of post-Asymptotic Giant Branch (post-AGB) circumstellar disks, utilizing the CRIRES instrument at the Very Large Telescope (VLT) and NIRSPEC at Keck II Observatory. Our observations reveal that the circumstellar disk surrounding the star HR 4049 is primarily characterized by absorption features that originate from an extensive region with temperatures ranging from 1000 to 2000 K. This temperature range aligns with the expected environment for dust grains that are undergoing evaporation due to the intense radiation pressure from the central star. \n\nFurthermore, we identify a variety of absorption lines that can be attributed to gas-phase molecules, including carbon monoxide (CO), water (H2O), hydroxyl (OH), ammonia (NH3), methane (CH4), acetylene (C2H2), silicon monoxide (SiO), hydrogen cyanide (HCN), cumulene (CCH), cyanide (CN), hydrogen sulfide (H2S), sulfur dioxide (SO2), carbon disulfide (CS), and iron hydride (FeH). These findings provide new insights into the physical conditions prevailing within these complex astrophysical environments. \n\nOur results underscore the necessity for future studies to integrate spatially resolved observations of the distribution of various molecular species with detailed spectroscopic data. This approach will enhance our understanding of the intricate processes occurring in post-AGB circumstellar disks and their implications for stellar evolution and the formation of planetary systems. \n\n**Keywords:** circumstellar disk, infrared spectroscopy, post-AGB stars, HR 4049, molecular absorption features.",
        "ori-fast-z-score": -0.9847319278346618,
        "water-fast-z-score": 5.0089472186085136,
        "rewrite-fast-z-score": 0.29559878344928797
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Observations towards early-type stars in the ESO-POP survey: II -- searches for intermediate and high velocity clouds .\nAbstract:\nWe present new results on interstellar absorption lines toward early type stars observed with UVES at VLT, as part of the ESO-POP project (ESO program 085.D-0571). We have searched for high-velocity clouds (HVCs) by looking for blueshifted components in the MgII doublet line profiles. The sample consists of 16 OB-stars located within 1 kpc distance from Earth. In addition to previously known HVCs we find several new ones. Some of these are associated with nearby galaxies while others may be related to Galactic halo gas. A comparison between our data set and previous surveys shows that there is no significant difference in the number density distribution of HVCs along different sightlines. This suggests that most of them are small structures which do not cover much solid angle around their host galaxy or star. \n \n Keywords: Interstellar medium",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Observations towards early - class stars in the ESO - POP survey : II - - surveys for intermediate and large velocity clouds . Abstract : We report new data on interstellar absorption patterns toward advanced type galaxies studied with UVES at VLT , as part of the ESO - POP project ( ESO program 085 . D - 0571 ) .We have searched for high - speed clouds ( HVCs ) by searching for blueshifted elements in the MgII doublet line profiles . The sample consists of 16 OB - stars situated within 1 kpc radius from Earth .In addition to earlier known HVCs we find several new ones . Some of these are identified with nearby galaxies while several might be connected to Galactic halo gas .A comparison between our information set and previous surveys reveals that there is no considerable difference in the number density spread of HVCs along various sightlines . This implies that most of them are small structures which do not cover many solid angle around their target galaxy or star .Keywords: Interstellar medium",
        "rewrite_text": "We present new findings on interstellar absorption characteristics observed in advanced type galaxies, utilizing UVES at the VLT as part of the ESO-POP project (ESO program 085.D-0571). Our investigation focuses on the identification of high-velocity clouds (HVCs) by analyzing blueshifted elements within the MgII doublet line profiles. The study encompasses a sample of 16 OB stars located within a 1 kpc radius from Earth. In addition to previously documented HVCs, our research has uncovered several new clouds. Some of these newly identified HVCs are associated with nearby galaxies, while others may be linked to gas in the Galactic halo. A comparative analysis of our data with earlier surveys indicates no significant variation in the density distribution of HVCs across different sightlines. This observation suggests that the majority of HVCs are relatively small structures that do not occupy a substantial solid angle around their respective target galaxies or stars. Our findings contribute to the understanding of the interstellar medium and the dynamics of high-velocity clouds, highlighting the intricate relationships between these clouds and their surrounding environments. Keywords: Interstellar medium.",
        "ori-fast-z-score": -2.038098661460272,
        "water-fast-z-score": 4.387842813611494,
        "rewrite-fast-z-score": -0.21566554640687682
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Novel String Derived Z  With Stable Proton, Light-Neutrinos and R-parity violation .\nAbstract:\nWe propose a new string derived model with stable proton in which the lightest supersymmetric particle (LSP) is not neutralino but gravitino. The LSP decays into photon or neutrino-antineutrino pair through gravitational interaction. In this scenario we can explain the observed dark matter abundance without conflicting with other experimental results such as relic density measurement by WMAP experiment. We also show that our model predicts interesting signatures at LHC experiments. Introduction:-The discovery of Higgs boson  1-3  has opened up an exciting possibility to explore physics beyond Standard Model(SM). Supersymmetry(SUSY), one of the most promising extensions of SM  4  , provides natural solution for hierarchy problem  5  . However, SUSY models are severely constrained by various experimental observations  6  .\nIn order to solve these problems, several authors have proposed different mechanisms  7-9 . One of them is introducing additional gauge symmetries  10  . Another way is adding extra dimensions  11  . Recently, it was shown that there exists a class of string derived models where the lightest superpartner is gravitino  12  . Gravitino is weakly interacting massive particle so its decay rate is suppressed compared to neutralino case  13  . This feature makes gravitino a good candidate for cold dark matter  14  . Moreover, if gravitino mass m 3/2 < 1 GeV then its lifetime becomes longer than age of universe  15  . Therefore, gravitino may be regarded as a viable candidate for dark matter  16  . On the other hand, gravitino is unstable because it couples to gravity  17  . It decays into photon or lepton-neutrino pairs  18  . If gravitino is heavier than 100 MeV then its decay products will contribute to diffuse gamma ray background  19  . Thus, gravitino should satisfy following conditions  20  :",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Novel String Derived Z With Stable Proton , Light - Neutrinos and R - parity violation . Abstract : We suggest a new string derived model with stable proton in which the lightest supersymmetric object ( LSP ) is not neutralino but gravitino .The LSP decays into photon or neutrino - antineutrino bond through gravity interaction . In this situation we can describe the seen dark matter concentration without conflicting with other experimental outcome such as relic density study by WMAP study .We also demonstrate that our model predicts exciting signatures at LHC observations . Introduction : - The observation of Higgs boson 1 - 3 has opened up an exciting possibility to pursue physics beyond Standard Model ( SM ) .Supersymmetry ( SUSY ) , one of the most attractive extensions of SM 4 , offers natural solution for hierarchy problem 5 . However , SUSY models are severely constrained by various experimental studies 6 .In try to solve these problems , various scientists have proposed different processes 7 - 9 . One of them is adding additional gauge symmetries 10 .Another means is adding extra dimensions 11 . Recently , it was shown that there exists a class of string derived models where the lightest superpartner is gravitino 12 .Gravitino is weakly interacting massive object so its degradation rate is suppressed compared to neutralino case 13 . This phenomenon makes gravitino a better contender for cold gray matter 14 .Moreover , if gravitino mass m 3 / 2 < 1 GeV then its duration remains longer than age of universe 15 . Therefore , gravitino might be regarded as a viable contender for black matter 16 .On the other hand , gravitino is unstable because it couples to gravity 17 . It decays into photon or lepton - neutrino pairs 18 .If gravitino is heavier than 100 MeV then its decay products will contribute to diffuse gamma ray background 19 . Thus , gravitino should satisfy following conditions 20 :",
        "rewrite_text": "**Title:** A Novel String-Derived Model with Stable Proton, Light Neutrinos, and R-Parity Violation\n\n**Abstract:** In this paper, we propose an innovative string-derived model that ensures the stability of protons while identifying the lightest supersymmetric particle (LSP) as the gravitino, rather than the traditionally considered neutralino. This model posits that the gravitino can decay into either a photon or a neutrino-antineutrino pair through gravitational interactions. By employing this framework, we can effectively account for the observed concentration of dark matter without contradicting results from other experimental studies, such as the relic density measurements conducted by WMAP. Furthermore, our model predicts intriguing signatures that could be observed at the Large Hadron Collider (LHC), providing a pathway for experimental validation.\n\nThe discovery of the Higgs boson has invigorated the search for physics beyond the Standard Model (SM). Supersymmetry (SUSY) emerges as a compelling extension of the SM, offering a natural resolution to the hierarchy problem. However, existing SUSY models face significant constraints from various experimental findings. In response to these challenges, researchers have explored diverse approaches, including the introduction of additional gauge symmetries and the incorporation of extra dimensions. Recent advancements have revealed a class of string-derived models wherein the gravitino serves as the lightest superpartner. Due to its weakly interacting nature, the decay rate of the gravitino is considerably suppressed compared to that of the neutralino, making it a more favorable candidate for cold dark matter. Notably, if the mass of the gravitino is less than 1 GeV, its lifetime exceeds the age of the universe, positioning it as a viable candidate for dark matter. However, it is essential to note that the gravitino is inherently unstable due to its gravitational coupling, leading to decay into photon or lepton-neutrino pairs. If the gravitino mass exceeds 100 MeV, its decay products could significantly contribute to the diffuse gamma-ray background. Consequently, our model must satisfy specific conditions to align with these observations.",
        "ori-fast-z-score": -0.5432144762551112,
        "water-fast-z-score": 5.8423739467217715,
        "rewrite-fast-z-score": 1.3926212476455828
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Synthesis of Taylor Phase Screens with Karhunen-Loeve Basis Functions .\nAbstract:\nWe present an algorithm for synthesizing phase screens that are optimal in the sense of minimizing the mean-square error between the synthesized and desired phases, subject to constraints on the maximum number of degrees of freedom (DOF) available for synthesis.  The method is based on representing each screen as a linear combination of basis functions derived by applying the Karhunen-Loeve transform to a set of reference phase screens generated using standard methods such as those described by Kolmogorov or von Kàrmàn statistics.   We show how this representation can be used to generate new phase screens whose statistical properties match closely those of the original reference screens while simultaneously satisfying user-specified bounds on the total number of DOF required to represent all N screens in the sequence. This approach has been implemented within the context of the SPARTA software package developed at NASA s Goddard Space Flight Center. In addition we describe several techniques which have been incorporated into our implementation to improve computational efficiency when generating large sequences of phase screens.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Synthesis of Taylor Phase Screens with Karhunen - Loeve Basis Functions . Abstract : We present an algorithm for synthesizing phase screens that are optimal in the sense of minimizing the mean - square error between the extracted and desired stages , subject to constraints on the maximum number of degrees of liberty ( DOF ) accessible for synthesis .The method is based on representing each screen as a linear mixture of basis functions derived by using the Karhunen - Loeve transform to a group of reference phase screens assembled using conventional methods such as those described by Kolmogorov or von Kàrmàn statistics . We see how this representation can be used to create additional phase screens whose statistical characteristics match tightly those of the actual reference displays while simultaneously satisfying user - defined bounds on the total number of DOF required to depict all N panels in the sequence .This method has been utilized within the context of the SPARTA computer package built at NASA s Goddard Space Flight Center . In addition we explain several methods which have been incorporated into our implementation to improve numerical capacity when constructing large sequences of phase screens .",
        "rewrite_text": "We introduce a novel algorithm designed for the synthesis of Taylor phase screens, focusing on minimizing the mean-square error between the generated and target phase screens while adhering to constraints on the maximum allowable degrees of freedom (DOF) for the synthesis process. Our approach utilizes a linear combination of basis functions, which are derived through the Karhunen-Loeve transform applied to a set of reference phase screens created using established techniques, such as those based on Kolmogorov or von Kármán statistical models. This representation enables the generation of additional phase screens that closely replicate the statistical properties of the reference screens, all while conforming to user-specified limits on the total DOF necessary for accurately representing all N panels in a given sequence. The algorithm has been successfully integrated into the SPARTA software package developed at NASA's Goddard Space Flight Center, showcasing its practical application in real-world scenarios. Furthermore, we discuss various enhancements incorporated into our implementation that significantly boost numerical efficiency when generating extensive sequences of phase screens. These advancements not only streamline the synthesis process but also ensure that the resulting phase screens maintain high fidelity to the desired statistical characteristics, making this method a valuable tool for researchers and practitioners in the field of optical engineering and atmospheric science.",
        "ori-fast-z-score": -2.177598558933893,
        "water-fast-z-score": 4.538253483538691,
        "rewrite-fast-z-score": 1.1441551070947107
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Multiphilic Descriptor for Chemical Reactivity and Selectivity .\nAbstract:\nThe concept of molecular descriptors is central to the development of quantitative structure-activity relationships (QSARs). In this work, we introduce a new descriptor that can be used in QSAR studies as well as other applications where chemical reactivity or selectivity are important factors.  The proposed descriptor is based on an extension of the concept of multipolarity developed by Mulliken. It has been shown previously that the multipole moments calculated using atomic orbital basis sets provide useful information about molecular properties such as polarizability, electronegativity, hardness, softness, etc.. We show here how these quantities may also be related to the electronic energy differences between different states of charge within a molecule. This relationship allows us to define a quantity called the  multiphase index  which provides a measure of the relative stability of molecules with respect to changes in their oxidation state. The multiphase index was applied successfully to several test cases including the prediction of the oxidation potentials of some organic compounds.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Multiphilic Descriptor for Chemical Reactivity and Selectivity . Abstract : The concept of molecular descriptors is central to the development of quantitative structure - activity relationships ( QSARs ) .In this research , we provide a new descriptor that can be used in QSAR studies as well as other applications where chemical reactivity or selectivity are important factors . The proposed descriptor is based on an extension of the idea of multipolarity developed by Mulliken .It has been shown previously that the multipole minutes measured using atomic orbital basis sets offer useful details about molecular properties such as polarizability , electronegativity , hardness , softness , etc . . We see here how these quantities might additionally be connected to the electronic energy differences between various states of charge within a molecule . This connection allows us to define a quantity called the multiphase index which offers a measure of the relative stability of molecules with regard to changes in their oxidation state .The multiphase index was used successfully to several test cases including the determination of the oxidation potentials of some organic elements .",
        "rewrite_text": "**Title:** A Multiphilic Descriptor for Chemical Reactivity and Selectivity\n\n**Abstract:** The development of quantitative structure-activity relationships (QSARs) heavily relies on the concept of molecular descriptors. In this study, we introduce a novel descriptor that serves as a valuable tool in QSAR analyses and other contexts where chemical reactivity and selectivity are critical considerations. This new descriptor is an advancement of the multipolarity concept originally proposed by Mulliken. Previous research has demonstrated that multipole moments, derived from atomic orbital basis sets, provide significant insights into various molecular properties, including polarizability, electronegativity, hardness, and softness. In our work, we explore the relationship between these properties and the electronic energy differences associated with different charge states within a molecule. This exploration leads to the definition of a new metric, termed the multiphase index, which quantifies the relative stability of molecules in response to variations in their oxidation states. We successfully applied the multiphase index to several case studies, including the assessment of oxidation potentials for various organic compounds. Our findings suggest that the multiphase index can serve as a predictive tool for understanding chemical reactivity and selectivity, thereby enhancing the capabilities of QSAR methodologies and contributing to the broader field of computational chemistry. This research not only expands the theoretical framework surrounding molecular descriptors but also provides practical applications that can aid in the design and evaluation of chemical compounds in various scientific domains.",
        "ori-fast-z-score": 1.2074068598865937,
        "water-fast-z-score": 5.237229365663818,
        "rewrite-fast-z-score": 0.4703604341917986
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  An Analysis of the Shapes of Interstellar Extinction Curves. V. The IR-Through-UV Curve Morphology .\nAbstract:\nWe have analyzed the shapes of interstellar extinction curves in the infrared through ultraviolet wavelength range using data for more than 100 sight lines with known distances and reddenings, including those obtained by us at Kitt Peak National Observatory (KPNO) and Cerro Tololo Inter-American Observatory (CTIO). We find that all observed extinction curves can be fitted well by a single power law function A(lambda) = lambda -alpha , where alpha is an index ranging between 1.5 to 2.0. This result suggests that there are no significant differences among various types of interstellar dust grains as far as their optical properties are concerned. In addition, we show that the value of alpha correlates strongly with the total-to-selective extinction ratio Rv . These results suggest that the shape of interstellar extinction curve may provide important information on the physical conditions of interstellar matter along individual sight lines. Keywords: Interstellar extinction; Power-law index; Reddening; Dust grain",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : An Analysis of the Shapes of Interstellar Extinction Curves . V . The IR - Through - UV Curve Morphology .Abstract : We have analyzed the shapes of interstellar extinction lines in the infrared through ultraviolet frequency range utilizing information for more than 100 sight lines with reported distances and reddenings , notably those acquired by us at Kitt Peak National Observatory ( KPNO ) and Cerro Tololo Inter - American Observatory ( CTIO ) . We see that all observed extinction angles can be fit well by a single power law relation A ( lambda ) = lambda - alpha , where alpha is an index ranging between 1 . 5 to 2 . 0 .This result suggests that there are no major changes among various types of interstellar dust grains as much as their optical properties are concerned . In addition , we find that the value of α correlates heavily with the total - to - selective extinction ratio Rv .These data suggest that the form of interstellar extinction curve might give important information on the physical conditions of interstellar matter along individual sight lines . Keywords : Interstellar extinction ; Power - law index ; Reddening ; Dust grain",
        "rewrite_text": "**Title:** An Analysis of the Shapes of Interstellar Extinction Curves: V. The IR-Through-UV Curve Morphology\n\n**Abstract:** In this study, we investigate the morphology of interstellar extinction curves across the infrared to ultraviolet spectrum, drawing on data from over 100 sight lines with documented distances and reddenings. This dataset prominently includes observations collected at the Kitt Peak National Observatory (KPNO) and the Cerro Tololo Inter-American Observatory (CTIO). Our analysis reveals that the extinction profiles observed can be accurately described by a singular power law relationship, expressed as A(λ) = λ^(-α), where the exponent α varies between 1.5 and 2.0. This finding indicates a remarkable uniformity in the optical properties of different types of interstellar dust grains, suggesting that significant variations in their characteristics do not exist within the examined wavelength range. Furthermore, we observe a strong correlation between the power law index α and the total-to-selective extinction ratio, Rv. This correlation implies that the shape of the interstellar extinction curve may serve as a valuable indicator of the physical conditions present in interstellar matter along specific sight lines. Our results contribute to a deeper understanding of the interplay between interstellar dust and light, enhancing our knowledge of the cosmic environment and the factors influencing the propagation of light through space. This research underscores the importance of studying interstellar extinction as a means to glean insights into the composition and behavior of interstellar matter. \n\n**Keywords:** Interstellar extinction; Power-law index; Reddening; Dust grain.",
        "ori-fast-z-score": 0.5698028822981898,
        "water-fast-z-score": 5.356147093602983,
        "rewrite-fast-z-score": 1.8542101386022132
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Many concepts and two logics of algorithmic reduction .\nAbstract:\nWe present an analysis of the concept of algorithmically reducible problems in computational complexity theory, focusing on its role as a bridge between different areas within this field. We argue that there are at least two distinct ways to understand what it means for one problem to be reduced to another by an algorithm; these correspond roughly to the notions of polynomial-time reductions and Turing reductions respectively. The former is more commonly used than the latter, but we show how both can be understood in terms of each other using the notion of relativised polynomial time. In particular, we prove that every problem which is not NP-complete under Turing reductions must have some property which makes it easy to solve relative to any oracle set containing all NP sets. This result has implications for the relationship between P and NP, and also provides new insights into the structure of NP itself. Algorithmic reductions play a central role in computational complexity theory, providing a way of relating seemingly disparate classes of decision problems such as those belonging to the class NP (the non-deterministic polynomial time computable problems) with those belonging to the class co-NP (the complements of NP problems). However, despite their importance, relatively little attention has been paid to the precise meaning of the phrase  algorithmically reduces to ; indeed, even basic questions about the nature of this concept remain unanswered.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Many concepts and two logics of algorithmic reduction . Abstract : We present an assessment of the idea of algorithmically reducible problems in computational complexity analysis , concentrating on its role as a bridge between various fields within this area .We argue that there are at least two different means to comprehend what it means for one question to be reduced to another by an algorithm ; these refer essentially to the concepts of polynomial - time reductions and Turing reductions respectively . The first is more often employed than the former , but we prove how both can be understood in terms of each other using the notion of relativised polynomial time .In particular , we prove that every question which is not NP - full under Turing reductions must have some property which makes it easy to solve relative to any oracle set containing all NP sets . This result has implications for the relationship between P and NP , and also provides new understanding into the formation of NP itself .Algorithmic reductions serve a central role in computational complexity theory , providing a way of comparing surprisingly disparate classes of decision cases such as those belonging to the class NP ( the non - deterministic polynomial time computable problems ) with those belonging to the class co - NP ( the complements of NP problems ) . However , despite their importance , fairly little attention has been paid to the exact meaning of the phrase algorithmically reduces to ; consequently , even basic concerns about the nature of this concept continue unanswered .",
        "rewrite_text": "Title: Many Concepts and Two Logics of Algorithmic Reduction\n\nAbstract: In this article, we evaluate the concept of algorithmically reducible problems within the framework of computational complexity analysis, emphasizing its significance as a connecting thread among various domains in this field. We propose that there are at least two distinct interpretations of what it means for one problem to be reduced to another through an algorithm: these interpretations correspond to polynomial-time reductions and Turing reductions. While polynomial-time reductions are more commonly utilized, we demonstrate that both types of reductions can be interrelated through the concept of relativized polynomial time. Specifically, we establish that any problem that is not NP-complete under Turing reductions possesses certain characteristics that render it relatively easy to solve when considered against any oracle set that includes all NP sets. This finding has important implications for understanding the relationship between the complexity classes P and NP, as well as offering new insights into the structure of NP itself. Algorithmic reductions play a pivotal role in computational complexity theory, facilitating comparisons between seemingly unrelated classes of decision problems, such as those in NP (non-deterministic polynomial time computable problems) and those in co-NP (the complements of NP problems). Despite their critical importance, the precise meaning of the term \"algorithmically reduces to\" has not been thoroughly explored, leaving fundamental questions regarding the nature of this concept largely unresolved. Our work aims to clarify these issues and contribute to a deeper understanding of algorithmic reductions in computational complexity.",
        "ori-fast-z-score": 0.5720775535473553,
        "water-fast-z-score": 5.911468053322673,
        "rewrite-fast-z-score": -1.8542101386022132
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Room temperature coexistence of large electric polarization and magnetic order in BiFeO3 single crystals .\nAbstract:\nBiFeO3 is an antiferromagnetic insulator with high Curie temperature (TC = 1103 K) that exhibits ferroelectricity at room temperature when doped or under pressure. Here we report the observation of spontaneous magnetization, M(T), and electrical polarization, P(E), simultaneously existing over wide ranges of temperatures up to 300 K in pure BiFeO3 single crystal grown by flux method. The results show that both M(T) and P(E) are nearly independent on each other below TC but they start to decrease rapidly above TC. We also found that the magnitude of M(T) decreases faster than that of P(E). These observations suggest that there exists strong coupling between spin and lattice degrees of freedom in this material. \n \n Keywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Room temperature coexistence of large electric polarization and magnetic order in BiFeO3 single crystals . Abstract : BiFeO3 is an antiferromagnetic insulator with high Curie temperature ( TC = 1103 K ) that exhibits ferroelectricity at room temperature when doped or under pressure .Here we publish the observation of spontaneous magnetization , M ( T ) , and electrical polarization , P ( E ) , independently operating over broad ranges of conditions up to 300 K in pure BiFeO3 single crystal grown by flux method . The results show that both M ( T ) and P ( E ) are nearly independent on each other below TC but they start to decline rapidly above TC .We additionally found that the magnitude of M ( T ) decreases quicker than that of P ( E ) . These measurements suggest that there exists strong coupling between spinning and lattice degrees of liberty in this material .Keywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",
        "rewrite_text": "Title: Room Temperature Coexistence of Significant Electric Polarization and Magnetic Order in BiFeO3 Single Crystals\n\nAbstract: BiFeO3 is recognized as an antiferromagnetic insulator with a notably high Curie temperature (TC = 1103 K) and demonstrates ferroelectric properties at room temperature when subjected to doping or pressure. In this study, we present our findings on the spontaneous magnetization (M(T)) and electrical polarization (P(E)) in pure BiFeO3 single crystals, which were synthesized using the flux growth method. Our observations reveal that both M(T) and P(E) operate independently across a wide range of conditions up to 300 K. Notably, below the Curie temperature, the two properties exhibit minimal interdependence; however, they both experience a rapid decline as temperatures exceed TC. Furthermore, our data indicate that the reduction in M(T) occurs at a faster rate compared to that of P(E). These findings imply a significant coupling between the spin and lattice degrees of freedom within BiFeO3, highlighting the complex interplay between its magnetic and electric characteristics. This research contributes to the understanding of room-temperature multiferroic materials and their potential applications in advanced electronic devices. \n\nKeywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",
        "ori-fast-z-score": 0.254000254000381,
        "water-fast-z-score": 3.5,
        "rewrite-fast-z-score": 2.6210932585716726
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Visual Data Mining of Genomic Databases by Immersive Graph-Based Exploration .\nAbstract:\nWe present an immersive visualization system for exploring and analyzing large volumes of genomic data, which is based on the concept of immersive graph-based exploration (IGE). The IGE approach allows users to explore complex relationships between different types of biological entities in 3D space using interactive visualizations. We implemented our system as a web application that can be accessed via any standard Web browser without requiring installation or configuration. Our system supports multiple simultaneous user interactions with the same dataset through collaborative visualization. In addition, we provide several advanced features such as automatic layout adjustment according to the number of nodes displayed at each time step, dynamic node labeling, and support for zoom-in/zoom-out operations. Finally, we demonstrate how our system can be used to analyze two real-world datasets related to human diseases. This article is part of a Special Issue entitled  Bioinformatics Visualization  guest edited by Michael R. Davidson, David A. Bader, and Mark J. Stubbs",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Visual Data Mining of Genomic Databases by Immersive Graph - Based Exploration . Abstract : We create an immersive visualization scheme for studying and analyzing large quantities of genomic evidence , which is based on the idea of immersive graph - based exploration ( IGE ) .The IGE method enables users to examine complex relationships between various types of biological entities in 3D space using interactive visualizations . We introduced our system as a web application that can be downloaded via any typical Web server without need installation or configuration .Our platform supports multiple simultaneous customer encounters with the same dataset through collaborative visualization . In addition , we provide several advanced features such as electronic layout adjustment according to the quantity of vertices displayed at each time step , dynamic node labeling , and support for zoom - in / zoom - out operations .Finally , we prove how our system can be used to analyze two actual - global datasets linked to biological illness . This page is part of a Special Issue entitled Bioinformatics Visualization guest edited by Michael R . Davidson , David A . Bader , and Mark J . Stubbs",
        "rewrite_text": "Title: Visual Data Mining of Genomic Databases through Immersive Graph-Based Exploration\n\nAbstract: In this study, we present an innovative immersive visualization framework designed for the analysis and exploration of extensive genomic datasets, leveraging the concept of Immersive Graph-Based Exploration (IGE). This method empowers researchers to investigate intricate relationships among diverse biological entities within a three-dimensional interactive environment. Our system is accessible as a web application, allowing users to easily download and utilize it from any standard web server without the need for installation or complex configuration processes. \n\nOne of the key features of our platform is its ability to facilitate multiple users engaging with the same dataset simultaneously, promoting collaborative visualization and analysis. We have incorporated several advanced functionalities, including the capability for electronic layout adjustments based on the number of vertices displayed at any given moment, dynamic labeling of nodes, and intuitive zoom-in and zoom-out operations. \n\nTo demonstrate the practical applications of our system, we showcase its effectiveness in analyzing two real-world global datasets associated with biological diseases. This research contributes to the field of bioinformatics by enhancing the tools available for visual data mining, ultimately aiding in the understanding of complex genomic information. This work is part of a Special Issue on Bioinformatics Visualization, guest edited by Michael R. Davidson, David A. Bader, and Mark J. Stubbs, highlighting the significance of advanced visualization techniques in the ongoing exploration of biological data.",
        "ori-fast-z-score": 0.6546536707079772,
        "water-fast-z-score": 6.901297485020058,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Diffuse X-ray Emission from the Carina Nebula Observed with Suzaku .\nAbstract:\nWe report on diffuse X-ray emission in the Carina Nebula observed by Suzaku. The spectrum is well reproduced by thermal plasma models at kT = 0.7-1 keV and nH = (0.5-2) x 10^(22) cm^{-3}, which are consistent with those obtained previously for other regions within the nebula. We find that the total luminosity of this component amounts to Lx ~ 1.3 x 10^35 erg/sec, corresponding to about 10% of the total energy output of massive stars in the region. This suggests that hot gas produced by stellar winds and/or supernovae plays an important role in heating up the interstellar medium around young open clusters such as Trumpler 14-16. \n \n \n \n Keywords: Diffuse X-rays, Hot plasma, Open cluster, Supernova remnant, Stellar wind, Carina Nebula",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Diffuse X - ray Emission from the Carina Nebula Observed with Suzaku . Abstract : We report on diffuse X - ray radiation in the Carina Nebula observed by Suzaku .The spectrum is well illustrated by thermal plasma estimates at kT = 0 . 7 - 1 keV and nH = ( 0 . 5 - 2 ) x 10 ^ ( 22 ) cm ^ { - 3 } , which are compatible with those obtained previously for other regions within the nebula . We see that the total luminosity of this component amounts to Lx ~ 1 . 3 x 10 ^ 35 erg / sec , equivalent to about 10 % of the total energy output of large stars in the region .This implies that heat gas created by stellar winds and / or supernovae plays an important role in heating up the interstellar medium around young open complexes such as Trumpler 14 - 16 . Keywords : Diffuse X - radiation , Hot plasma , Open cluster , Supernova remnant , Stellar wind , Carina Nebula",
        "rewrite_text": "We present our findings on the diffuse X-ray emission from the Carina Nebula as observed by the Suzaku satellite. Our analysis reveals that the X-ray spectrum can be accurately described by thermal plasma models, with temperatures ranging from kT = 0.7 to 1 keV and hydrogen column densities of nH = (0.5 - 2) x 10^(22) cm^(-3). These parameters are consistent with previous measurements taken in other areas of the nebula, indicating a uniformity in the thermal properties across different regions. The total luminosity associated with this diffuse X-ray emission is estimated to be Lx ~ 1.3 x 10^(35) erg/sec, which constitutes approximately 10% of the total energy output from the massive stars located within the nebula. This significant contribution suggests that the thermal energy generated by stellar winds and supernova explosions is crucial in heating the surrounding interstellar medium, particularly in young open clusters like Trumpler 14-16. Our results underscore the importance of understanding the interplay between stellar activity and the thermal state of the interstellar medium in regions of active star formation. This study enhances our comprehension of the physical processes at work in the Carina Nebula and contributes to the broader knowledge of X-ray emissions in similar astrophysical environments. \n\nKeywords: Diffuse X-ray emission, Thermal plasma, Open clusters, Supernova remnants, Stellar winds, Carina Nebula.",
        "ori-fast-z-score": -1.4832396974191326,
        "water-fast-z-score": 2.138089935299395,
        "rewrite-fast-z-score": -0.20851441405707477
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Galois theory of iterated endomorphisms .\nAbstract:\nThe Galois group is the fundamental object in classical Galois theory, which studies the solvability of polynomial equations over finite fields.  In this talk we will introduce the notion of ``Galois groups   for infinite families of polynomials and study their properties using tools from algebraic geometry.   We will also discuss some applications to number theory such as the proof of the abc conjecture by Vojta (joint work with J. Pila). The main results are joint works with A. Chambert-Loir, D. Ghioca, M. Harris, C. Lairez, S. Popescu-Tarauca, B. Stoll, E. Szpiro, T. Tucker-Drob, and V. Vojta. This talk was given at the conference  Algebraic Geometry and Arithmetic Dynamics  held on June 24-28, 2013 at MSRI Berkeley. It has been recorded by Adam Hartung.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Galois theory of iterated endomorphisms . Abstract : The Galois group is the fundamental object in classical Galois theory , which studies the solvability of polynomial equations over polynomial fields .In this talk we will explore the notion of ` ` Galois groups for infinite families of polynomials and study their properties using techniques from algebraic theory . We will also discuss some applications to number theory such as the proof of the abc hypothesis by Vojta ( collaboration work with J . Pila ) .The main results are joint works with A . Chambert - Loir , D . Ghioca , M . Harris , C . Lairez , S . Popescu - Tarauca , B . Stoll , E . Szpiro , T . Tucker - Drob , and V . Vojta . This discussion was given at the meeting Algebraic Geometry and Arithmetic Dynamics holding on June 24 - 28 , 2013 at MSRI Berkeley .It has been recorded by Adam Hartung .",
        "rewrite_text": "**Title:** Galois Theory of Iterated Endomorphisms\n\n**Abstract:** This article delves into the Galois theory, a cornerstone of classical mathematics that investigates the solvability of polynomial equations within polynomial fields. We extend the traditional concept of Galois groups to encompass infinite families of polynomials, examining their structural properties through advanced algebraic techniques. Our exploration includes a detailed analysis of the implications of these Galois groups in the realm of number theory, particularly highlighting their role in the proof of the abc conjecture as established by Vojta, in collaboration with J. Pila. The findings presented are the result of collaborative efforts with notable mathematicians including A. Chambert-Loir, D. Ghioca, M. Harris, C. Lairez, S. Popescu-Tarauca, B. Stoll, E. Szpiro, T. Tucker-Drob, and V. Vojta. This work was initially presented at the Algebraic Geometry and Arithmetic Dynamics conference, held from June 24 to 28, 2013, at the Mathematical Sciences Research Institute (MSRI) in Berkeley. The session was recorded by Adam Hartung, ensuring that the insights shared during this meeting are accessible for further study and reference. Through this research, we aim to deepen the understanding of Galois groups in the context of iterated endomorphisms and their broader implications in both algebra and number theory.",
        "ori-fast-z-score": -0.5773502691896258,
        "water-fast-z-score": 2.4285714285714284,
        "rewrite-fast-z-score": 0.24253562503633297
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spectroscopic Observations of the Intermediate Polar EX Hydrae in Quiescence .\nAbstract:\nWe report on spectroscopic observations made with the Nordic Optical Telescope (NOT) and the William Herschel Telescope (WHT). The NOT data were obtained during two observing runs, one in August 2002 and another in September 2003. We used the ALFOSC instrument to obtain time-resolved spectroscopy covering the wavelength range 3700-7000 Å at a resolution of about 1 Å . The WHT data were taken between October 2004 and January 2005 using ISIS spectrographs equipped with gratings R600B and R1200R giving a spectral coverage of 3600-9200 Å at a resolving power of about 1000. In total we have collected more than 100 spectra for this object. All our new data are presented along with previously published results by Vogt et al. (1987) , Vogt & Hatzes (1991), Vogt et al. (1994a-c) . Our analysis shows that the system is composed of an M4V star orbited by a white dwarf companion.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Spectroscopic Observations of the Intermediate Polar EX Hydrae in Quiescence .Abstract:\nWe report on spectroscopic observations made with the Nordic Optical Telescope (NOT) and the William Herschel Telescope (WHT).The NOT results were obtained during two observing walks , one in August 2002 and another in September 2003 . We utilized the ALFOSC instrument to obtain time - resolved spectroscopy spanning the frequency region 3700 - 7000 Å at a resolution of about 1 Å .The WHT results were took between October 2004 and January 2005 utilizing ISIS spectrographs equipped with gratings R600B and R1200R giving a spectral coverage of 3600 - 9200 Å at a resolving power of about 1000 . In total we have gathered more than 100 spectra for this object .All our new data are presented along with former reported results by Vogt et al . ( 1987 ) , Vogt & Hatzes ( 1991 ) , Vogt et al .( 1994a - c ) . Our study shows that the system is composed of an M4V star orbited by a white dwarf companion .",
        "rewrite_text": "We present a comprehensive analysis of spectroscopic observations conducted on the Intermediate Polar EX Hydrae during its quiescent state, utilizing data from the Nordic Optical Telescope (NOT) and the William Herschel Telescope (WHT). The observations at NOT were carried out over two separate sessions, one in August 2002 and the other in September 2003, employing the ALFOSC instrument to capture time-resolved spectroscopy across the wavelength range of 3700 to 7000 Å, achieving a resolution of approximately 1 Å. Meanwhile, the WHT observations took place between October 2004 and January 2005, utilizing ISIS spectrographs with R600B and R1200R gratings, which provided a spectral coverage from 3600 to 9200 Å at a resolving power of around 1000. In total, we have compiled over 100 spectra for EX Hydrae, significantly enhancing the existing dataset. Our findings are presented alongside previously published results by Vogt et al. (1987), Vogt & Hatzes (1991), and Vogt et al. (1994a-c), allowing for a thorough comparison and analysis of the system's characteristics. The results of our study indicate that EX Hydrae consists of an M4V-type star that is orbited by a white dwarf companion, contributing valuable insights into the nature of this intriguing binary system. This research not only enriches the understanding of EX Hydrae but also provides a foundation for future investigations into similar intermediate polar systems.",
        "ori-fast-z-score": 0.816496580927726,
        "water-fast-z-score": 4.719399037242694,
        "rewrite-fast-z-score": 0.6708203932499369
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Microscopic theory of quantum dot interactions with quantum light: local field effect .\nAbstract:\nWe present microscopic theory for the interaction between single photons and semiconductor quantum dots (QDs). We show that QD emission is strongly modified by the presence of nearby QDs, which leads to an effective dipole-dipole coupling in the system. This results in new phenomena such as superradiant lasing and subradiance. The latter can be used to create efficient on-chip optical switches. Our approach allows us to calculate all relevant quantities including spontaneous emission rates, absorption cross sections, and scattering matrices. These are important parameters for applications ranging from photonic devices to quantum information processing. \nTheory\n\nQuantum dots interact via their electric fields.\n\nThis gives rise to collective effects like superradiance or subradiance. \n\nThese effects can be observed in experiments using microcavities.  \n\nExperiments\n\nIn this work we study the influence of these collective effects on the emission properties of individual quantum dots embedded into a microcavity. \n\n\nResults",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Microscopic theory of quantum dot associations with quantum light : local field action . Abstract : We bring microscopic theory for the interaction between single photons and semiconductor quantum dots ( QDs ) .We see that QD radiation is strongly altered by the presence of neighbouring QDs , which results to an efficient dipole - dipole coupling in the system . This results in novel processes such as superradiant lasing and subradiance .The latter can be used to create fast on - chip optical networks . Our solution enables us to estimate all relevant quantities namely spontaneous emission rates , absorption cross sections , and scattering matrices .These are important characteristics for applications ranging from photonic devices to quantum information processing . Theory Quantum dots interact via their electric forces .This gives rise to collective effects like superradiance or subradiance . These effects can be viewed in experiments using microcavities .Experiments In this project we study the impact of these collective effects on the emission behavior of different quantum dots inserted into a microcavity . Results",
        "rewrite_text": "Title: Microscopic Theory of Quantum Dot Associations with Quantum Light: Local Field Action\n\nAbstract: In this study, we present a comprehensive microscopic theory that elucidates the interaction dynamics between single photons and semiconductor quantum dots (QDs). Our findings reveal that the radiation emitted by quantum dots is significantly influenced by the proximity of neighboring QDs, leading to a pronounced dipole-dipole coupling within the system. This interaction gives rise to intriguing phenomena such as superradiant lasing and subradiance, which hold promise for the development of rapid on-chip optical networks. By employing our theoretical framework, we are able to calculate key parameters including spontaneous emission rates, absorption cross sections, and scattering matrices. These parameters are crucial for a wide array of applications, spanning from advanced photonic devices to quantum information processing.\n\nThe underlying theory posits that quantum dots interact through their electric fields, resulting in collective behaviors such as superradiance and subradiance. These collective effects can be experimentally observed in microcavity setups, where the emission characteristics of various quantum dots can be systematically analyzed. In this project, we investigate how these collective phenomena influence the emission properties of different quantum dots embedded within a microcavity environment. Our results provide valuable insights into the manipulation of light-matter interactions at the quantum level, paving the way for innovative applications in the field of quantum optics and photonics. Through this research, we aim to enhance the understanding of quantum dot behavior in the presence of quantum light, ultimately contributing to the advancement of next-generation optical technologies.",
        "ori-fast-z-score": -0.5360562674188973,
        "water-fast-z-score": 4.90361647617904,
        "rewrite-fast-z-score": 0.7986208584745025
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Radio Emission, X-ray Emission, and Hydrodynamics of G328.4+0.2: A Comprehensive Analysis of a Luminous Pulsar Wind Nebula, its Neutron Star, and the Progenitor Supernova Explosion .\nAbstract:\nWe present an analysis of multi-wavelength observations of the pulsar wind nebula (PWN) associated with PSR B1509-58 in the supernova remnant (SNR) G328.4+0. \n2. The radio emission is modeled as synchrotron radiation produced by relativistic electrons accelerated at the termination shock between the pulsar s magnetosphere and the surrounding medium. \n \n We find that the observed properties of this system are consistent with those expected for a young energetic pulsar surrounded by a dense shell of swept-up material. In particular, we show that: \n \n \n \n 1. The total energy contained within the SNR is ~1050 erg, which implies a kinetic energy of ~500 erg for the progenitor star prior to explosion; \n \n 2. The age of the pulsar is estimated to be ~20 kyr based on the spin-down luminosity and characteristic age; \n \n 3. The distance to the source is constrained to be <5 kpc using the dispersion measure and assuming a nominal value for the electron density along the line-of-sight; \n \n 4. The magnetic field strength near the pulsar is inferred to be ~1 mGauss based on modeling of the spectral index distribution across the face of the PWN; \n \n 5. The radius of the PWN is found to be ~0.3 pc, corresponding to a dynamical age of ~30 yrs; \n \n 6. The mass loss rate of the progenitor star was >10-5 Msun/yr during the last few thousand years before core collapse; \n \n 7. The initial mass of the progenitor star was ~25-30 Msuns, implying a red supergiant or blue hypergiant classification; \n \n 8. The ejecta mass of the progenitor star is estimated to be ~7-8 Msuns, indicating that it underwent significant mass loss prior to exploding; \n \n 9. The expansion velocity of the outer edge of the PWN is ~1000 km/sec, comparable to the speed of sound in the shocked gas; \n \n 10. The X-ray",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Radio Emission , X - ray Emission , and Hydrodynamics of G328 . 4 + 0 . 2 : A Comprehensive Analysis of a Luminous Pulsar Wind Nebula , its Neutron Star , and the Progenitor Supernova Explosion . Abstract : We report an assessment of multi - wavelength images of the pulsar wind nebula ( PWN ) associated with PSR B1509 - 58 in the supernova remnant ( SNR ) G328 . 4 + 0 .2 . The radio emission is modeled as synchrotron emission created by relativistic electrons accelerated at the termination shock between the pulsar s magnetosphere and the nearby medium .We see that the known characteristics of this system are compatible with those expected for a young energetic pulsar surrounded by a dense shell of washed - up material . In particular , we prove that : 1 .The total energy contained within the SNR is ~ 1050 erg , which implies a kinetic power of ~ 500 erg for the progenitor star previous to explosion ; 2 . The age of the pulsar is predicted to be ~ 20 kyr based on the spin - down luminosity and typical age ; 3 .The distance to the origin is constrained to be < 5 kpc using the dispersion measure and assuming a nominal value for the electron concentration along the line - of - view ; 4 . The magnetic force power near the pulsar is inferred to be ~ 1 mGauss based on modeling of the spectral index distribution across the face of the PWN ; 5 .The radius of the PWN is found to be ~ 0 . 3 pc , equivalent to a dynamical age of ~ 30 yrs ; 6 . The mass loss rate of the progenitor star was > 10 - 5 Msun / yr during the last few thousand years before core breakup ; 7 .The initial mass of the progenitor star was ~ 25 - 30 Msuns , indicate a red supergiant or blue hypergiant classification ; 8 . The ejecta mass of the progenitor star is predicted to be ~ 7 - 8 Msuns , showing that it underwent considerable mass loss prior to exploding ; 9 .The expansion velocity of the exterior boundary of the PWN is ~ 1000 kilometers / sec , comparable to the speed of noise in the excited gas ; 10 . The X - ray",
        "rewrite_text": "**Title:** The Radio Emission, X-ray Emission, and Hydrodynamics of G328.4+0.2: A Comprehensive Analysis of a Luminous Pulsar Wind Nebula, its Neutron Star, and the Progenitor Supernova Explosion\n\n**Abstract:** In this study, we present a detailed examination of multi-wavelength observations of the pulsar wind nebula (PWN) associated with PSR B1509-58, located within the supernova remnant (SNR) G328.4+0.2. Our analysis focuses on the radio emission, which we interpret as synchrotron radiation produced by relativistic electrons that are accelerated at the termination shock between the pulsar’s magnetosphere and the surrounding medium. The characteristics of this system align with expectations for a young, energetic pulsar enveloped by a dense shell of material expelled during the progenitor star's evolution. Our findings include several key results: \n\n1. The total energy within the SNR is estimated to be approximately 10^50 erg, suggesting a kinetic power of around 500 erg for the progenitor star prior to its explosion.\n2. Based on the spin-down luminosity and typical pulsar ages, we estimate the age of the pulsar to be roughly 20,000 years.\n3. The distance to the pulsar is constrained to less than 5 kpc, derived from the dispersion measure and assuming a standard electron density along the line of sight.\n4. The magnetic field strength near the pulsar is inferred to be about 1 mGauss, based on our modeling of the spectral index distribution across the PWN.\n5. The radius of the PWN is determined to be approximately 0.3 parsecs, corresponding to a dynamical age of around 30 years.\n6. The progenitor star's mass loss rate is estimated to have exceeded 10^-5 Msun/year in the final few millennia before its core collapse.\n7. We estimate the initial mass of the progenitor star to be between 25 and 30 Msun, suggesting a classification as either a red supergiant or a blue hypergiant.\n8. The mass of the ejecta from the progenitor star is predicted to be around 7 to 8 Msun, indicating significant mass loss prior to the supernova event.\n9. The expansion velocity of the outer boundary of the PWN is approximately 1000 kilometers per second, comparable to the sound speed in the surrounding gas.\n10. The X-ray emission characteristics further elucidate the dynamics and energetic processes at play within this remarkable astrophysical system. \n\nThis comprehensive analysis enhances our understanding of the interplay between pulsar wind nebulae, their progenitor stars, and the remnants of supernova explosions.",
        "ori-fast-z-score": 1.104689541477988,
        "water-fast-z-score": 7.058578427117228,
        "rewrite-fast-z-score": 0.7579367289598671
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Vortex Formation by Merging and Interference of Multiple Trapped Bose-Einstein Condensates .\nAbstract:\nWe report on the observation of vortex formation in two trapped condensates that are merged together using an optical lattice potential. The merging process is accompanied by the appearance of dark solitons, which can be identified as topological defects in the density distribution of each individual condensate. We show how these defects evolve into vortices during the merger process. In addition to this direct route towards vortex generation we also demonstrate another method for creating vortices based on interference between multiple condensates. This second approach allows us to create stable vortex states with high winding numbers (up to 12). Our results provide new insights into the dynamics of interacting quantum fluids at low temperatures. Vortices play an important role in many areas of physics ranging from superfluid helium  1  , liquid crystals  2  or superconductors  3  over atomic gases  4  up to astrophysics  5  . They represent topologically non-trivial solutions of nonlinear wave equations  6  and have been observed experimentally in various systems  7, 8  .\nIn recent years there has been considerable interest in studying vortex structures in ultracold atoms  9  . These systems offer several advantages compared to other physical realizations such as their tunability  10  , controllability  11  and clean experimental conditions  12  . For example, it was shown recently that one-dimensional arrays of vortices can be created in a single condensate  13  . However, most experiments so far were restricted to observing only few isolated vortices  14, 15  due to technical limitations  16  . Here we present two different methods for generating large ensembles of vortices in a controlled way.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Vortex Formation by Merging and Interference of Multiple Trapped Bose - Einstein Condensates . Abstract : We report on the observation of vortex form in two trapped condensates that are fused together utilizing an optical lattice potential .The merging process is preceded by the appearance of darkened solitons , which can be identified as topological flaws in the density density of each individual condensate . We see how these defects evolve into vortices during the merger process .In addition to this direct route towards vortex generation we also demonstrate another technique for producing vortices based on interference between multiple condensates . This second method enables us to create stable vortex states with high winding numbers ( up to 12 ) .Our results bring fresh insights into the dynamics of interacting quantum fluids at low temperatures . Vortices play an important role in different areas of science ranging from superfluid helium 1 , fluid crystals 2 or superconductors 3 over nuclear gases 4 up to astrophysics 5 .They represent topologically non - trivial solutions of nonlinear wave equations 6 and have been observed experimentally in different systems 7 , 8 . In recent years there has been substantial interest in investigating vortex structures in ultracold atoms 9 .These systems afford many benefits compared to other physical realizations such as their tunability 10 , controllability 11 and clean experimental environments 12 . For instance , it was shown lately that one - dimensional arrays of vortices can be formed in a single condensate 13 .However , most studies so far were restricted to observing only few isolated vortices 14 , 15 due to technical restrictions 16 . Here we present two different methods for generating huge groups of vortices in a controlled manner .",
        "rewrite_text": "We present a comprehensive study on the formation of vortices through the merging and interference of multiple trapped Bose-Einstein condensates, as detailed in our recent findings. Utilizing an optical lattice potential, we successfully observed the fusion of two condensates, which was preceded by the emergence of dark solitons—topological defects in the density profile of each condensate. As the merging process unfolded, these defects transitioned into vortices, illustrating a direct pathway for vortex generation. Additionally, we explored an alternative method for vortex creation through the interference of multiple condensates, which allowed us to produce stable vortex states characterized by high winding numbers, reaching up to 12. \n\nOur findings contribute significantly to the understanding of the dynamics of interacting quantum fluids at low temperatures, where vortices play a crucial role across various scientific domains, including superfluid helium, liquid crystals, superconductors, nuclear gases, and astrophysics. These vortices are recognized as topologically non-trivial solutions to nonlinear wave equations and have been experimentally observed in diverse systems. The investigation of vortex structures in ultracold atomic systems has garnered considerable attention in recent years, owing to their advantageous properties such as tunability, controllability, and the ability to maintain clean experimental conditions. Recent studies have demonstrated the formation of one-dimensional vortex arrays within single condensates; however, most prior research has been limited to the observation of only a few isolated vortices due to technical constraints. In this work, we introduce two distinct methods for the controlled generation of large groups of vortices, paving the way for further exploration of vortex dynamics in ultracold atomic systems.",
        "ori-fast-z-score": -0.09090909090909091,
        "water-fast-z-score": 6.401854406138769,
        "rewrite-fast-z-score": 1.3636363636363635
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Sunyaev-Zel dovich profiles and scaling relations: modelling effects and observational biases .\nAbstract:\nWe present the results of our analysis on simulated galaxy clusters, which are used to study how different physical processes affect SZ observables (profiles and scaling relations). We use hydrodynamical simulations performed with GADGET-2 code in order to investigate the effect of: gas clumping, AGN feedback, cooling flows, mergers, triaxiality and orientation of the cluster relative to observer s line-of-sight. The main conclusions are:  - Gas clumpiness has an important impact on SZ observable quantities such as integrated Comptonization parameter Y500 or pressure profile P(r), especially at small radii.  - Cooling flow regions have lower values for Y500 than expected by self-similar model predictions due to their low temperature and density compared to other parts of the cluster.  - Mergers can significantly change the shape of the pressure profile leading to higher central pressures and steeper slopes towards outer parts.  - Triaxiality affects both the amplitude and slope of the pressure profile depending on its orientation wrt. the observer s line-of-sigh.  - Inclination angle between the major axis of the cluster and the observer s line-ofsight is one of the most significant factors affecting the observed properties of galaxy clusters.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Sunyaev - Zel dovich profiles and scaling relations : modelling effects and observational biases . Abstract : We present the results of our analysis on virtual galaxy galaxies , which are using to study how various physical processes affect SZ observables ( profiles and scaling relations ) .We use hydrodynamical simulations conducted with GADGET - 2 code in order to examine the impact of : gas clumping , AGN feedback , cooling flows , mergers , triaxiality and position of the cluster relative to observer s line - of - view . The main results are : - Gas clumpiness has an important affect on SZ observable quantities such as integrated Comptonization value Y500 or temperature profile P ( r ) , particularly at small radii .- Cooling circulation regions have smaller values for Y500 than expected by self - similar model calculations owing to their low heat and density relative to other parts of the cluster . - Mergers can significantly change the form of the pressure profile resulting to higher central temperatures and steeper slopes towards outer parts .- Triaxiality affects both the frequency and slope of the pressure profile depending on its location wrt . the observer s line - of - sigh .- Inclination angle between the main axis of the cluster and the observer s line - ofsight is one of the most significant factors affecting the seen characteristics of galaxy clusters .",
        "rewrite_text": "We present a comprehensive analysis of virtual galaxy clusters aimed at understanding how various physical processes influence Sunyaev-Zel'dovich (SZ) observables, specifically focusing on profiles and scaling relations. Utilizing hydrodynamical simulations performed with the GADGET-2 code, we investigate the effects of several factors, including gas clumping, active galactic nucleus (AGN) feedback, cooling flows, mergers, triaxiality, and the orientation of the cluster relative to the observer's line of sight. Our findings reveal several key insights: \n\nFirstly, gas clumpiness significantly impacts SZ observable quantities, such as the integrated Comptonization parameter Y500 and the temperature profile P(r), particularly at smaller radii. Secondly, regions characterized by cooling flows exhibit lower Y500 values than those predicted by self-similar model calculations, primarily due to their reduced heat and density compared to other regions within the cluster. \n\nAdditionally, we observe that mergers can dramatically alter the pressure profile, leading to increased central temperatures and steeper gradients in the outer regions of the cluster. The triaxiality of clusters also plays a crucial role, affecting both the frequency and slope of the pressure profile, which varies based on the cluster's orientation with respect to the observer's line of sight. \n\nFinally, we identify the inclination angle between the cluster's principal axis and the observer's line of sight as a critical factor influencing the observable characteristics of galaxy clusters. These results underscore the complexity of interpreting SZ observables and highlight the need to account for these physical processes and observational biases in future studies of galaxy clusters.",
        "ori-fast-z-score": -0.9805806756909202,
        "water-fast-z-score": 4.9770903720375195,
        "rewrite-fast-z-score": 1.1627553482998907
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Search for Tidal Dwarf Galaxies Candidates in a Sample of Ultraluminous Infrared Galaxies .\nAbstract:\nWe present the results of an optical spectroscopic survey aimed at finding tidal dwarf galaxies (TDGs) candidates among a sample of ultraluminous infrared galaxies (ULIRG). We have obtained spectra with FORS2@VLT and GMOS-N@Gemini telescopes, covering the wavelength range between 3600 Å and 9200 Å , for a total of 16 ULIRGs selected on the basis of their high far-infrared luminosity (L FIR > 10 12 L ⊙ ) and low redshift (z < 0.1).\nThe main goal is to find TDGs that are expected to be found around interacting systems such as ULIRGs. The presence of young stars in these objects would make them detectable through strong emission lines like Hα or  OII  . However, we do not detect any significant excess of emission line flux over what can be explained by star formation occurring within the host galaxy itself. This result suggests either that there are no TDGs associated with our sample of ULIRGs or that they are too faint and/or too red to be detected using current facilities.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Search for Tidal Dwarf Galaxies Candidates in a Sample of Ultraluminous Infrared Galaxies . Abstract : We report the results of an optical spectroscopic study aiming at finding tidal dwarf stars ( TDGs ) candidates among a sample of ultraluminous laser galaxies ( ULIRG ) .We have discovered spectra with FORS2 @ VLT and GMOS - N @ Gemini telescopes , covering the frequency range between 3600 Å and 9200 Å , for a total of 16 ULIRGs chosen on the basis of their high far - infrared luminosity ( L FIR > 10 12 L [UNK] ) and low redshift ( z < 0 . 1 ) . The main goal is to find TDGs that are expected to be found around interacting systems such as ULIRGs .The appearance of young stars in these objects would render them detectable through strong absorption lines like Hα or OII . However , we do not detect any considerable surplus of emission point flux over what can be described by galaxy formation happening within the host galaxy itself .This result suggests either that there are no TDGs associated with our sample of ULIRGs or that they are too dark and / or too bright to be identified using current technology .",
        "rewrite_text": "In this study, we present the findings of an optical spectroscopic investigation aimed at identifying candidates for tidal dwarf galaxies (TDGs) within a selected group of ultraluminous infrared galaxies (ULIRGs). Utilizing the FORS2 instrument at the Very Large Telescope (VLT) and the GMOS-N at the Gemini Observatory, we obtained spectra spanning the wavelength range of 3600 Å to 9200 Å for a total of 16 ULIRGs. These galaxies were specifically chosen based on their significant far-infrared luminosity (L_FIR > 10^12 L_sun) and relatively low redshift (z < 0.1). The primary objective of our research was to locate TDGs, which are typically formed in the vicinity of interacting galaxies, such as ULIRGs. The presence of young stellar populations within these systems would be indicated by strong emission lines, particularly Hα and OII, which are characteristic of star formation activity. However, our observations did not reveal any significant excess of emission point flux that could be attributed to the presence of TDGs. Instead, the data suggest that any potential TDGs associated with our sample of ULIRGs are either absent or too faint and/or too luminous to be detected with the current observational techniques. This outcome raises important questions regarding the formation and visibility of TDGs in the context of galaxy interactions and highlights the need for further research to explore the conditions under which these objects can be identified. Overall, our findings contribute to the understanding of galaxy formation processes and the role of tidal interactions in the evolution of galaxies.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.714045207910317,
        "rewrite-fast-z-score": 0.8700628401410971
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Equivariant cohomology theory of twisted generalized complex manifolds .\nAbstract:\nIn this article, we study the equivariant cohomology groups of twisted generalized complex manifolds with respect to compact Lie group actions. We show that these equivariant cohomology groups are isomorphic to those of ordinary generalized complex manifolds equipped with an invariant Hermitian metric and a compatible connection whose torsion is equal to the twisting form. As applications, we compute some examples in detail. In particular, for any closed oriented Riemann surface M , we give explicit formulas for all equivariant Betti numbers of the moduli space of stable vector bundles over M . \nIntroduction\n\nLet G be a compact connected Lie group acting on a smooth manifold X. The equivariant cohomology H*G(X) was introduced by Atiyah-Bott  1  as the cohomology ring of the Borel construction EG×_G X where EG denotes the universal bundle over BG = K(G, 1). It has been studied extensively since then (see e.g.,  2  ). For example, if X is a symplectic manifold acted upon by a torus T, then H*G(X), which can also be viewed as the equivariant cohomology of the corresponding Hamiltonian T-space, plays an important role in mirror symmetry  3  .\nThe notion of generalized complex geometry  4  provides us with another class of interesting geometric objects -the so-called generalized complex manifolds-which include both symplectic and complex manifolds as special cases. Generalized complex structures were first defined by Hitchin  5  using Courant algebroids  6  . Later Gualtieri  7  gave a more intrinsic definition via a pair of almost complex structures satisfying certain compatibility conditions. Recently, it was shown  8  that there exists a one-to-one correspondence between generalized complex structures and pairs consisting of a holomorphic Poisson structure and its associated Nijenhuis tensor field. This result allows us to define generalized complex structures intrinsically without referring to Courant algebroids; see  9  for details. \nGeneralized complex manifolds have attracted much attention recently due to their close connections with string theories  10  . Moreover, they provide new insights into many classical problems such as integr",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Equivariant cohomology theory of distorted generalized complex manifolds . Abstract : In this article , we study the equivariant cohomology groups of distorted generalized complex manifolds with regard to compact Lie group actions .We see that these equivariant cohomology groups are isomorphic to those of simple generalized complex manifolds equipped with an invariant Hermitian metric and a compatible link whose torsion is equal to the twisting form . As applications , we compute some examples in detail .In particular , for any closed oriented Riemann sphere M , we give explicit formulas for all equivariant Betti numbers of the moduli space of stable vector bundles over M . Introduction Let G be a compact connected Lie ring acting on a smooth manifold X .The equivariant cohomology H * G ( X ) was introduced by Atiyah - Bott 1 as the cohomology ring of the Borel construction EG× _ G X where EG indicates the universal manifold over BG = K ( G , 1 ) . It has been studied thoroughly since then ( saw e . g . , 2 ) .For instance , if X is a symplectic manifold acted upon by a torus T , then H * G ( X ) , which can also be viewed as the equivariant cohomology of the associated Hamiltonian T - space , takes an important role in mirror symmetry 3 . The idea of generalized complex geometry 4 provides us with another class of interesting geometric objects - the so - called generalized complex manifolds - which contain both symplectic and complex manifolds as special cases .Generalized complex systems were first defined by Hitchin 5 utilizing Courant algebroids 6 . Later Gualtieri 7 gave a more intrinsic definition via a pair of almost complex systems satisfying particular compatibility constraints .Recently , it was shown 8 that there exists a one - to - one correspondence between generalized complex objects and pairs consisting of a holomorphic Poisson structure and its associated Nijenhuis tensor field . This result allows us to define generalized complex representations intrinsically without referring to Courant algebroids ; hear 9 for information .Generalized complex manifolds have garnered many scrutiny lately owing to their deep link with string problems 10 . Moreover , they give new information into numerous classical problems such as integr",
        "rewrite_text": "**Title:** The Equivariant Cohomology Theory of Distorted Generalized Complex Manifolds\n\n**Abstract:** This article investigates the equivariant cohomology groups associated with distorted generalized complex manifolds in the context of compact Lie group actions. We establish that these equivariant cohomology groups are isomorphic to those of simple generalized complex manifolds that possess an invariant Hermitian metric and a compatible link, where the torsion is equivalent to the twisting form. To illustrate our findings, we provide detailed computations of specific examples. Notably, for any closed oriented Riemann sphere \\( M \\), we derive explicit formulas for all equivariant Betti numbers pertaining to the moduli space of stable vector bundles over \\( M \\).\n\nIn the introduction, we consider a compact connected Lie group \\( G \\) acting on a smooth manifold \\( X \\). The concept of equivariant cohomology \\( H^*_G(X) \\) was initially introduced by Atiyah and Bott as the cohomology ring of the Borel construction \\( EG \\times_G X \\), where \\( EG \\) denotes the universal manifold over \\( BG = K(G, 1) \\). This area has been extensively explored in subsequent research. For example, when \\( X \\) is a symplectic manifold subjected to the action of a torus \\( T \\), the equivariant cohomology \\( H^*_G(X) \\) plays a significant role in mirror symmetry.\n\nThe framework of generalized complex geometry introduces a fascinating class of geometric structures known as generalized complex manifolds, which encompass both symplectic and complex manifolds as special cases. Initially defined by Hitchin through the lens of Courant algebroids, generalized complex structures have since been redefined by Gualtieri in a more intrinsic manner, utilizing pairs of almost complex structures that adhere to specific compatibility conditions. Recent developments have revealed a one-to-one correspondence between generalized complex structures and pairs comprising a holomorphic Poisson structure along with its corresponding Nijenhuis tensor field. This correspondence facilitates the intrinsic definition of generalized complex representations without reliance on Courant algebroids. The study of generalized complex manifolds has gained momentum due to their profound connections with string theory and their potential to provide insights into various classical problems, including integrability.",
        "ori-fast-z-score": -0.1643989873053573,
        "water-fast-z-score": 5.526066862243561,
        "rewrite-fast-z-score": 0.6810052246069989
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Longitudinal impedance and wake from XFEL undulators. Impact on current-enhanced SASE schemes .\nAbstract:\nWe present an analytical model for the longitudinal impedance and wakefield generated by a single period of an XFEL undulator, including effects due to electron beam emittance and energy spread. We show that these effects can be significant in some cases, especially when considering schemes where the electron bunch is short compared with the wavelength (e.g., self-amplified spontaneous emission). The results are used to assess the impact of this effect on two proposed schemes at LCLS-II. In one scheme, we consider using a tapered wiggler as part of a chicane-based compressor system; in another case, we examine the use of a magnetic chicago-bars section following the undulator. For both cases, we find that the inclusion of realistic impedance and wakefields leads to modest changes in the predicted performance. \n \n Keywords: Undulator, Wakefield, Impedance, Self-Amplified Spontaneous Emission",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Longitudinal impedance and wake from XFEL undulators . Impact on current - improved SASE schemes .Abstract : We present an analytical theory for the longitudinal impedance and wakefield generated by a single period of an XFEL undulator , comprising effects due to ion beam emittance and energy spread . We see that these consequences can be large in some cases , particularly when using techniques where the electron bunch is short compared with the frequency ( e . g . , self - amplified spontaneous emission ) .The results are using to examine the impact of this effect on two proposed methods at LCLS - II . In one scheme , we imagine employing a tapered wiggler as part of a chicane - based compressor mechanism ; in another case , we investigate the using of a magnetic chicago - bars area following the undulator .For both cases , we find that the introduction of realistic impedance and wakefields contributes to modest changes in the expected performance . Keywords : Undulator , Wakefield , Impedance , Self - Amplified Spontaneous Emission",
        "rewrite_text": "Title: Longitudinal Impedance and Wake from XFEL Undulators: Implications for Enhanced SASE Schemes\n\nAbstract: In this study, we develop an analytical framework to investigate the longitudinal impedance and wakefield produced by a single period of an X-ray Free Electron Laser (XFEL) undulator, taking into account the effects of ion beam emittance and energy spread. Our findings indicate that these effects can be significant, particularly in scenarios where the electron bunch length is short relative to the operational frequency, such as in self-amplified spontaneous emission (SASE) processes. We apply our results to evaluate the implications of these effects on two proposed methodologies at the Linac Coherent Light Source II (LCLS-II). The first approach involves the integration of a tapered wiggler within a chicane-based compression system, while the second explores the utilization of a magnetic Chicago-bar structure positioned after the undulator. In both scenarios, our analysis reveals that the incorporation of realistic impedance and wakefield considerations leads to notable modifications in the anticipated performance outcomes. This work underscores the importance of accounting for longitudinal impedance and wakefields in the design and optimization of XFEL systems, particularly in enhancing the efficacy of SASE schemes. \n\nKeywords: Undulator, Wakefield, Impedance, Self-Amplified Spontaneous Emission",
        "ori-fast-z-score": -0.23904572186687872,
        "water-fast-z-score": 5.34051746187234,
        "rewrite-fast-z-score": 0.9058216273156765
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Aspects of stochastic resonance in reaction-diffusion systems: The nonequilibrium-potential approach .\nAbstract:\nWe study the effects of noise on spatially extended systems by using an extension of the concept of nonequilibrium potential (NEP). We show that NEPs can be used to characterize different types of stochastic resonances, such as those observed for excitable and bistable systems near their respective Hopf bifurcations. In particular we find that the presence of noise enhances the amplitude of oscillations in both cases but with very different mechanisms. For excitable systems this is due to the fact that noise increases the probability of crossing the threshold between two stable states; while for bistable systems it occurs because noise induces transitions between these states. Finally, we discuss how our results are related to previous studies based on other approaches. Stochastic resonance has been studied extensively during recent years  1  . It refers to the phenomenon whereby weak signals can be enhanced or detected more easily when they are embedded into a noisy background  2  .\nIn many physical situations, however, one needs to consider not only the effect of external noise sources but also internal fluctuations arising from the dynamics itself  3  . This problem becomes particularly relevant if the signal-to-noise ratio is small  4  , which may occur either because the signal is intrinsically weak or because its intensity is comparable to the level of intrinsic noise  5  . Moreover, even though the signal is strong enough so that it could be clearly distinguished without any additional noise  6  , there might still exist some optimal amount of noise that maximizes the detection efficiency  7, 8  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Aspects of stochastic resonance in reaction - diffusion processes : The nonequilibrium - potential approach . Abstract : We research the effects of noise on spatially extended systems by using an extension of the idea of nonequilibrium potential ( NEP ) .We see that NEPs can be used to characterize different kinds of stochastic resonances , such as those observed for excitable and bistable systems near their different Hopf bifurcations . In particular we find that the presence of noise enhances the frequency of oscillations in both cases but with very different mechanisms .For excitable systems this is due to the fact that noise changes the probability of reaching the threshold between two stable states ; while for bistable systems it appears because sound induces transitions between these states . Finally , we talk how our findings are related to previous research based on other methods .Stochastic resonance has been studied thoroughly during recent years 1 . It refers to the phenomenon whereby soft signals can be enhanced or detected more easily when they are embedded into a loud background 2 .In many mechanical circumstances , however , one needs to consider not only the impact of external sound sources but also internal fluctuations originating from the dynamics itself 3 . This problem arises particularly relevant if the signal - to - noise proportion is tiny 4 , which may happen either because the signal is intrinsically weak or because its brightness is equal to the level of intrinsic noise 5 .Moreover , even though the signal is strong enough so that it could be obviously differentiated without any additional noise 6 , there might nevertheless exist some optimal level of noise that maximizes the detection efficiency 7 , 8 .",
        "rewrite_text": "In this study, we investigate the influence of noise on spatially extended systems through an advanced framework known as the nonequilibrium potential (NEP) approach. Our findings reveal that NEPs serve as effective tools for characterizing various forms of stochastic resonance, particularly in excitable and bistable systems as they approach different Hopf bifurcations. Notably, we observe that noise significantly enhances oscillation frequencies in both system types, albeit through distinct mechanisms. In excitable systems, the enhancement is attributed to noise altering the likelihood of reaching the threshold between two stable states. Conversely, in bistable systems, the presence of noise facilitates transitions between these states, driven by sound. \n\nFurthermore, we discuss the implications of our results in relation to existing research conducted through alternative methodologies. Stochastic resonance has garnered considerable attention in recent years, defined as the phenomenon where weak signals become more detectable when embedded within a noisy background. However, it is crucial to consider not only external noise sources but also the internal fluctuations arising from the system's dynamics. This consideration becomes particularly pertinent when the signal-to-noise ratio is low, which can occur due to either an intrinsically weak signal or a scenario where the signal's intensity is comparable to the level of intrinsic noise. Interestingly, even in cases where the signal is sufficiently strong to be discerned without additional noise, there may still exist an optimal noise level that maximizes detection efficiency. Our research contributes to the understanding of these complex interactions and highlights the nuanced role of noise in enhancing signal detection in reaction-diffusion processes.",
        "ori-fast-z-score": 0.2705008904002297,
        "water-fast-z-score": 6.171547617899419,
        "rewrite-fast-z-score": 2.4748737341529163
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Magnetohydrostatic solar prominences in near-potential coronal magnetic fields .\nAbstract:\nWe present the results of numerical simulations of magnetohydrostatic equilibrium for solar prominences embedded into non-potential, sheared and twisted coronal fields. The model is based on solving numerically the Grad-Shafranov equation with boundary conditions at both ends of the computational domain that are derived using an approximate analytical solution to this problem. We find that the resulting equilibria have shapes similar to those observed in white-light coronagraph images. In particular, we show how the shape of the prominence changes as its position relative to the underlying photospheric magnetic flux distribution varies. Our results also demonstrate that the presence of shear and/or twist leads to significant deviations from potential-field models commonly used in theoretical studies of prominences. These findings may be useful for interpreting observations of prominences made by space-based instruments such as SDO/AIA. \n \n Keywords: Solar prominence, Magnetohydrostatics",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Magnetohydrostatic solar prominences in near - potential coronal magnetic fields . Abstract : We report the results of computational simulations of magnetohydrostatic equilibrium for solar prominences embedded into non - potential , sheared and spun coronal areas .The model is based on solving numerically the Grad - Shafranov equation with boundary constraints at both sides of the theoretical domain that are derived using an approximate mathematical solution to this question . We see that the resulting equilibria have shapes similar to those observed in white - light coronagraph images .In particular , we study how the form of the prominence changes as its position relative to the underlying photospheric magnetic flux flow varies . Our results also demonstrate that the presence of shear and / or twist results to significant deviations from potential - field methods commonly used in experimental studies of prominences .These studies might be valuable for interpreting observations of prominences made by space - based instruments such as SDO / AIA . Keywords : Solar height , Magnetohydrostatics",
        "rewrite_text": "In this study, we present the findings from our computational simulations investigating the magnetohydrostatic equilibrium of solar prominences situated within non-potential, sheared, and twisted coronal magnetic fields. Our approach involves numerically solving the Grad-Shafranov equation, applying boundary conditions derived from an approximate mathematical solution to establish the theoretical framework. The equilibria we obtain exhibit shapes that closely resemble those seen in white-light coronagraph images, providing a visual correlation with observational data. \n\nA key focus of our research is the influence of the prominence's position relative to the underlying photospheric magnetic flux flow on its morphology. Our simulations reveal that variations in this positioning lead to notable changes in the prominence's structure. Furthermore, we find that the inclusion of shear and twist in the magnetic field configuration results in significant deviations from the predictions made by potential-field models, which are often employed in the analysis of solar prominences. \n\nThese insights are crucial for enhancing our understanding of solar prominences and may prove beneficial for interpreting data collected by space-based observatories, such as the Solar Dynamics Observatory (SDO) and its Atmospheric Imaging Assembly (AIA). Our findings underscore the importance of considering non-potential magnetic field configurations when studying solar phenomena, as they can yield a more accurate representation of the complex dynamics at play in the solar atmosphere. \n\nIn summary, this work contributes to the field of solar physics by providing a detailed examination of magnetohydrostatic equilibria in prominences, highlighting the effects of magnetic shear and twist, and offering implications for future observational studies. \n\nKeywords: Solar height, Magnetohydrostatics.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.939391699536065,
        "rewrite-fast-z-score": 0.8770580193070293
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multifractality and scale invariance in human heartbeat dynamics .\nAbstract:\nThe multifractal nature of the human heartbeat has been studied by many authors, but most studies have focused on short time series (typically less than one hour). In this work we study the scaling properties of long-term recordings of the electrocardiograms (ECG) of healthy subjects during sleep using wavelet transforms to calculate the singularity spectrum f(α), which characterizes the degree of multifractality present in each signal.  We find that all signals are characterized by a broad range of exponents α indicating strong multifractality. The width Δα of these spectra decreases with increasing recording length T as Δα~T-1/2 for T<10 hours and Δα~T-3/4 for T>10 hours. This indicates that the ECGs become more monofractal-like when longer recordings are considered. Finally, we show how our results can be used to detect pathological changes in the heart rate variability associated with congestive heart failure.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multifractality and scale invariance in human heartbeat systems . Abstract : The multifractal nature of the human heartbeat has been studied by many writers , but most studies have concentrated on short period series ( generally less than one minute ) .In this research we study the scaling qualities of long - term recordings of the electrocardiograms ( ECG ) of healthy participants during sleep use wavelet transforms to estimate the singularity spectrum f ( α ) , which characterizes the degree of multifractality observed in each signal . We see that all signals are characterized by a broad variety of exponents α marking strong multifractality .The width Δα of these spectra decreases with higher tape length T as Δα ~ T - 1 / 2 for T < 10 hours and Δα ~ T - 3 / 4 for T > 10 hours . This implies that the ECGs get more monofractal - like when longer recordings are considered .Finally , we show how our findings can be used to identify pathological alterations in the chest rate variability associated with congestive heart failure .",
        "rewrite_text": "Title: Multifractality and Scale Invariance in Human Heartbeat Systems\n\nAbstract: The multifractal characteristics of human heartbeat dynamics have garnered considerable attention in the scientific community; however, most existing research has primarily focused on short-duration series, typically lasting less than one minute. In this study, we investigate the scaling properties of long-term electrocardiogram (ECG) recordings from healthy individuals during sleep. Utilizing wavelet transforms, we estimate the singularity spectrum f(α), which serves as a measure of the multifractality present in each ECG signal. Our analysis reveals that all examined signals exhibit a wide range of exponents α, indicative of pronounced multifractality. Notably, we observe that the width Δα of these spectra diminishes with increasing tape length T, following a relationship of Δα ~ T^(-1/2) for T < 10 hours and Δα ~ T^(-3/4) for T > 10 hours. This trend suggests that as the duration of the recordings increases, the ECG signals tend to exhibit more monofractal-like behavior. Furthermore, we discuss the implications of our findings for clinical applications, particularly in the identification of pathological changes in heart rate variability associated with conditions such as congestive heart failure. By enhancing our understanding of the multifractal nature of heartbeats, this research contributes to the development of more effective diagnostic tools and therapeutic strategies in cardiology.",
        "ori-fast-z-score": -0.9428090415820635,
        "water-fast-z-score": 5.114896104728048,
        "rewrite-fast-z-score": 0.8432740427115678
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Antiproliferative MCR peptides block physical interaction of insulin with retinoblastoma protein (RB) in human lung cancer cells .\nAbstract:\nThe aim of this study was to investigate the effect of novel antimicrobial cyclic peptides, named microbe-derived cationic ring structures (MCRs), on cell proliferation and apoptosis induction in A549 non-small-cell lung carcinoma cells. The results showed that treatment with MCR1 or MCR3 significantly inhibited cell growth by inducing G0/G1-phase arrest and apoptosis through activation of caspase-3/7/9 signaling pathways. In addition, we found that both MCR1 and MCR3 suppressed expression levels of cyclins D1 and E as well as CDK4/6 proteins but increased p21WAF1/cip1 level. Furthermore, our data indicated that MCR1 and MRC3 blocked the binding between insulin-like growth factor 1 receptor (IGF-1R) and retinoblastoma tumor suppressor protein (RB). These findings suggest that MCR1 and 3 may be potential therapeutic agents for treating lung cancers.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Antiproliferative MCR peptides block physical interaction of insulin with retinoblastoma gene ( RB ) in human lung cancer cells . Abstract : The goal of this study was to examine the impact of new antimicrobial cyclic peptides , designated microbe - derived cationic ring structures ( MCRs ) , on cell development and apoptosis activation in A549 non - large - cell lung carcinoma cells .The results showed that treatment with MCR1 or MCR3 significantly inhibited cell development by inducing G0 / G1 - phase arrest and apoptosis through activation of caspase - 3 / 7 / 9 signaling pathways . In addition , we reported that both MCR1 and MCR3 reduced expression scores of cyclins D1 and E as well as CDK4 / 6 molecules but improved p21WAF1 / cip1 level .Furthermore , our evidence showed that MCR1 and MRC3 blocked the interaction between insulin - like growth factor 1 receptor ( IGF - 1R ) and retinoblastoma tumor suppressor protein ( RB ) . These data suggest that MCR1 and 3 might be possible therapeutic agents for treating lung cancers .",
        "rewrite_text": "**Title:** Antiproliferative MCR Peptides Inhibit Insulin Interaction with Retinoblastoma Gene (RB) in Human Lung Cancer Cells\n\n**Abstract:** This study investigates the effects of novel antimicrobial cyclic peptides, referred to as microbe-derived cationic ring structures (MCRs), on cell proliferation and apoptosis in A549 non-small cell lung carcinoma cells. Our findings demonstrate that treatment with MCR1 and MCR3 leads to a significant reduction in cell proliferation, primarily by inducing G0/G1 phase cell cycle arrest and promoting apoptosis through the activation of caspase-3, -7, and -9 signaling pathways. Notably, both MCR1 and MCR3 were found to downregulate the expression of key cell cycle regulators, including cyclins D1 and E, as well as cyclin-dependent kinases 4 and 6 (CDK4/6). Conversely, these peptides were associated with an increase in the levels of the cyclin-dependent kinase inhibitor p21WAF1/cip1, indicating a shift towards a more regulated cell cycle progression. Furthermore, our results reveal that MCR1 and MCR3 effectively disrupt the interaction between the insulin-like growth factor 1 receptor (IGF-1R) and the retinoblastoma (RB) tumor suppressor protein. This blockade may play a critical role in the antiproliferative effects observed. Collectively, these findings suggest that MCR1 and MCR3 hold promise as potential therapeutic agents for the treatment of lung cancer, warranting further investigation into their mechanisms of action and efficacy in clinical settings.",
        "ori-fast-z-score": -0.23904572186687872,
        "water-fast-z-score": 5.421151989096865,
        "rewrite-fast-z-score": 1.078327732034384
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Stueckelberg Extension and Milli Weak and Milli Charge Dark Matter .\nAbstract:\nWe propose that the dark matter in our universe is composed of milli-charged particles, which are neutral under electromagnetism but carry an electric charge on the order of 10^(-6)e (electrons). We show how this scenario can be realized within the context of the Standard Model by introducing a new gauge boson with mass mX ~ 1TeV/c2 into the theory through the Stueckelberg extension to the Standard Model. The introduction of such a massive vector particle leads to modifications to the usual Feynman rules for charged fermions interacting via photons or gluons. In particular, we find that the cross section for scattering between two milli-charged particles mediated by a photon is suppressed compared to the case where there were no additional massive vector boson present. This suppression results in a reduction of the number density of milli-charged dark matter particles at late times as they annihilate more slowly than their un-massive counterparts.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Stueckelberg Extension and Milli Weak and Milli Charge Dark Matter . Abstract : We suggest that the dark matter in our universe is composed of milli - charged particles , which are neutral under electromagnetism but hold an electric current on the order of 10 ^ ( - 6 ) e ( atoms ) .We see how this situation can be realized within the context of the Standard Model by bringing a new gauge boson with mass mX ~ 1TeV / c2 into the model through the Stueckelberg extension to the Standard Model . The advent of such a huge vector beam leads to modifications to the usual Feynman restrictions for charged fermions interacting via photons or gluons .In particular , we find that the cross section for propagation between two milli - charged particles mediated by a photon is suppressed compared to the case where there were no additional massive vector boson present . This suppression results in a reduction of the number density of milli - charged dark matter molecules at late times as they annihilate more slowly than their un - massive counterparts .",
        "rewrite_text": "In this article, we propose a novel perspective on the composition of dark matter in the universe, suggesting that it consists of milli-charged particles. These particles are electrically neutral under conventional electromagnetic interactions but possess a minuscule electric charge on the order of 10^(-6)e (where e represents the charge of an electron). We explore how this concept can be integrated into the framework of the Standard Model of particle physics by introducing a new gauge boson with a mass of approximately 1 TeV/c² through the Stueckelberg extension. The inclusion of such a massive vector boson significantly alters the typical Feynman rules governing the interactions of charged fermions via photons or gluons. \n\nOur analysis reveals that the cross section for interactions between two milli-charged particles, mediated by a photon, is notably suppressed in comparison to scenarios without the presence of an additional massive vector boson. This suppression has profound implications for the dynamics of milli-charged dark matter, particularly in terms of their annihilation processes. As a result, milli-charged dark matter particles exhibit a slower annihilation rate than their massless counterparts, leading to a reduced number density of these particles in the universe over time. This behavior could provide critical insights into the nature of dark matter and its interactions, potentially offering explanations for observed phenomena that cannot be accounted for by conventional dark matter models. Our findings underscore the importance of considering new theoretical frameworks, such as the Stueckelberg extension, to enhance our understanding of dark matter and its role in the cosmos.",
        "ori-fast-z-score": 0.5933908290969266,
        "water-fast-z-score": 4.242640687119286,
        "rewrite-fast-z-score": 1.2780193008453875
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The effect of magnetic fields on the formation of circumstellar discs around young stars .\nAbstract:\nWe present results for the evolution of magnetized protostellar accretion discs in which we have included both Ohmic and ambipolar diffusion, as well as radiative transfer effects using flux-limited diffusion (FLD). We find that the inclusion of these additional physical processes has important consequences for disc structure and evolution.  In particular, we show that the presence of an initial magnetic field can significantly affect the mass distribution within the disc at early times by suppressing fragmentation near the central star. This leads to more massive discs than those found previously with purely hydrodynamic simulations. The resulting discs are also less flared due to the increased pressure support provided by the magnetic field. As time progresses, however, the magnetic field is dissipated through ohmic dissipation and turbulence driven by gravitational instabilities. Once this happens, the disc becomes thinner and more flared compared to non-magnetic models.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The impact of magnetic fields on the formation of circumstellar discs around early stars . Abstract : We report findings for the evolution of magnetized protostellar accretion discs in which we have described both Ohmic and ambipolar diffusion , as well as radiative transfer effects utilizing flux - limited diffusion ( FLD ) .We see that the introduction of these additional material processes has crucial consequences for disc composition and evolution . In particular , we find that the presence of an initial magnetic force can significantly affect the mass distribution within the disc at early times by suppressing fragmentation near the main star .This leads to more massive discs than those identified previously with solely hydrodynamic simulations . The resulting discs are also less erupted due to the increased pressure support offered by the magnetic force .As period progresses , however , the magnetic force is dissipated through ohmic dissipation and turbulence driven by gravitational instabilities . Once this happens , the disc appears shorter and more flared relative to non - magnetic models .",
        "rewrite_text": "Title: The Impact of Magnetic Fields on the Formation of Circumstellar Discs Around Early Stars\n\nAbstract: In this study, we investigate the evolution of magnetized protostellar accretion discs, incorporating both Ohmic and ambipolar diffusion processes, alongside radiative transfer effects modeled through flux-limited diffusion (FLD). Our findings reveal that these additional physical processes play a pivotal role in shaping the composition and evolution of the discs. Notably, we observe that the initial presence of a magnetic field significantly influences the mass distribution within the disc during its formative stages, effectively suppressing fragmentation in the vicinity of the central star. This suppression results in the formation of more massive discs compared to those predicted by previous hydrodynamic simulations that did not account for magnetic effects. Furthermore, the enhanced pressure support provided by the magnetic field contributes to a reduction in disc eruptions, leading to a more stable configuration. As time progresses, however, the magnetic influence diminishes due to ohmic dissipation and turbulence induced by gravitational instabilities. Consequently, the discs evolve to exhibit a shorter and more flared structure when compared to their non-magnetic counterparts. This research underscores the importance of magnetic fields in the early stages of star formation and their profound impact on the characteristics of circumstellar discs, ultimately influencing the subsequent formation of planetary systems. Our results provide a deeper understanding of the interplay between magnetic forces and disc dynamics, highlighting the necessity of including magnetic effects in future models of star and planet formation.",
        "ori-fast-z-score": -0.21320071635561041,
        "water-fast-z-score": 5.038928913737635,
        "rewrite-fast-z-score": 2.5776089301153053
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Critical Casimir Effect in superfluid wetting films .\nAbstract:\nWe study the critical Casimir effect (CCE) between two parallel plates immersed into a liquid helium film at its superfluid transition temperature T_sf = 2.17 K, using Monte Carlo simulations based on the density functional theory for quantum fluids. We find that the CCE is strongly suppressed by the presence of the substrate and vanishes completely when the distance to it becomes smaller than about one molecular diameter. The results are compared with those obtained within the mean-field approximation which overestimates the magnitude of the effect considerably. In addition we show how the influence of the substrate can be taken into account in an approximate way. \nPACS numbers: 67.85.-j, 68.45.-k, 71.10.Fd \nI. INTRODUCTORY REMARK\nThe critical Casimir effect  1  , i.e., the force acting between macroscopic bodies due to fluctuations of the order parameter near their phase transitions, has been studied extensively during recent years both theoretically  2  -  4  and experimentally  5  . It was shown  6  that this effect may play important role in various physical phenomena such as capillary condensation  7, 8  or wetting  9  .\nIn particular, the critical Casimir effect plays crucial role in the physics of thin liquid helium films  10  where it leads to the appearance of additional forces  11  responsible for the formation of stable droplets  12  . These effects have been observed recently  13  in experiments performed on helium nanodroplets trapped inside magnetic traps  14  . However, most theoretical studies so far were restricted to idealized situations neglecting the influence of the substrate  15  -  17  . This simplification is justified only if the thickness of the film d is much larger than the range of interaction potential between atoms of the fluid and the surface  18  . For example, in case of 4 He films adsorbed on graphite substrates  19  the typical values of these parameters are  20  : r 0 ≈ 3Å, d ≈ 10 − 100 nm. Therefore, taking into account the substrate explicitly is necessary  21  especially close to the wetting transition  22  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Critical Casimir Effect in superfluid wetting movies . Abstract : We explore the critical Casimir effect ( CCE ) between two connected panels immersed into a liquid helium movie at its superfluid transition temperature T _ sf = 2 . 17 K , using Monte Carlo simulations based on the density functional theory for quantum fluids .We see that the CCE is strongly suppressed by the presence of the substrate and vanishes totally when the distance to it becomes lower than about one molecular size . The results are compared with those achieved within the mean - field approximation which overestimates the severity of the result considerably .In addition we show how the impact of the substrate can be taken into consideration in an approximate way . PACS scores : 67 . 85 . - j , 68 . 45 . - k , 71 . 10 . Fd I .INTRODUCTORY REMARK The essential Casimir effect 1 , i . e . , the force acting between macroscopic bodies owing to fluctuations of the order parameter near their phase transitions , has been studied thoroughly during recent seasons both theoretically 2 - 4 and experimentally 5 . It was shown 6 that this effect could play important role in different mechanical phenomena such as capillary condensation 7 , 8 or wetting 9 .In particular , the critical Casimir effect holds crucial role in the physics of thin liquid helium films 10 where it brings to the appearance of added forces 11 responsible for the formation of stable droplets 12 . These effects have been observed lately 13 in experiments conducted on helium nanodroplets caught inside magnetic traps 14 .However , most theoretical researchers so far were restricted to idealized scenarios neglecting the impact of the substrate 15 - 17 . This simplification is justified only if the length of the film d is much larger than the range of interaction potential between molecules of the liquid and the surface 18 .For instance , in case of 4 He films adsorbed on graphite compounds 19 the typical values of these parameters are 20 : l 0 ≈ 3Å , d ≈ 10 − 100 nm . Therefore , giving into consideration the substrate explicitly is required 21 especially close to the wetting transition 22 .",
        "rewrite_text": "**Title:** Critical Casimir Effect in Superfluid Wetting Films\n\n**Abstract:** This study investigates the critical Casimir effect (CCE) occurring between two panels immersed in a liquid helium film at its superfluid transition temperature (T_sf = 2.17 K). Utilizing Monte Carlo simulations grounded in the density functional theory for quantum fluids, we demonstrate that the presence of a substrate significantly suppresses the CCE. Notably, the effect diminishes entirely when the distance between the panels and the substrate falls below approximately one molecular size. Our findings are juxtaposed with results derived from mean-field approximations, which tend to overestimate the impact of the CCE. Furthermore, we propose a method to account for the influence of the substrate in a more approximate manner. \n\nThe critical Casimir effect, defined as the force between macroscopic bodies due to fluctuations of the order parameter near phase transitions, has garnered extensive theoretical and experimental attention in recent years. It has been established that this phenomenon can significantly influence various mechanical processes, including capillary condensation and wetting. Specifically, the CCE plays a pivotal role in the behavior of thin liquid helium films, contributing to the emergence of additional forces that facilitate the formation of stable droplets. Recent experiments involving helium nanodroplets trapped in magnetic fields have provided empirical evidence supporting these theoretical predictions. \n\nHowever, prior theoretical investigations have largely overlooked the effects of the substrate, operating under idealized conditions. This assumption is only valid when the film thickness is considerably greater than the interaction range between the liquid molecules and the substrate. For instance, in the case of ^4He films adsorbed on graphite, typical parameters indicate that the film thickness (d) ranges from 10 to 100 nm, while the interaction length (l_0) is approximately 3 Å. Therefore, it becomes essential to explicitly consider the substrate's influence, particularly in the vicinity of the wetting transition. \n\n**PACS numbers:** 67.85.-j, 68.45.-k, 71.10.Fd",
        "ori-fast-z-score": -0.8333333333333334,
        "water-fast-z-score": 6.289804753377997,
        "rewrite-fast-z-score": 0.6713450866373513
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Ground-state long-range order in quasi-one-dimensional Heisenberg quantum antiferromagnets: High-order coupled-cluster calculations .\nAbstract:\nWe present high-order coupled cluster (CC) results for the ground state energy and magnetic susceptibility of several one-dimensional spin-1/2 Heisenberg models with nearest-neighbor interactions, including the isotropic chain, the anisotropic XXZ model, and the two-leg ladder system. We show that CC provides accurate results even at low temperatures where standard mean-field approaches fail to describe correctly the physics of these systems. In particular we find that the magnetization curve of the isotropic chain displays an unexpected non-monotonic behavior which can be explained by the presence of two competing phases characterized by different values of the staggered magnetization. Finally, we discuss how our results could be used as benchmark data for future numerical studies on more complicated two-dimensional or three-dimensional quantum magnets. The study of strongly correlated electron systems has been a central topic in condensed matter theory over many decades  1  . One important class of such materials are so-called quantum magnets  2  , i.e., compounds whose low-energy excitations are described by collective spin degrees of freedom. These systems have attracted considerable interest because they often display exotic phenomena like unconventional superconductivity  3  , fractionalized excitations  4  , or topological order  5  .\nIn recent years there has also been growing interest in studying artificially engineered quantum magnets  6  using ultracold atoms  7  or trapped ions  8  . This new field of research offers unprecedented possibilities to explore novel physical regimes  9  and it may lead to the development of new technologies  10  . However, despite their fundamental importance, theoretical investigations into quantum magnets remain challenging due to the strong correlations between the spins  11  . Therefore, finding reliable methods to calculate properties of these systems remains an active area of research  12  .\nOne particularly interesting example of a quantum magnet is given by the one-dimensional (1D) Heisenberg model  13  \nwhere J > 0 denotes the strength of the exchange interaction between neighboring sites j = 1, ..., L along the chain direction x, while S j ≡ c † j σc j describes the local spin operator acting on site j with Pauli matrices {σ}. Here {c † j } and {c",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Ground - state long - range order in quasi - one - dimensional Heisenberg quantum antiferromagnets : High - order coupled - cluster calculations . Abstract : We report high - order coupled cluster ( CC ) results for the ground state energy and magnetic susceptibility of several one - dimensional spin - 1 / 2 Heisenberg configurations with nearest - neighbor interactions , notably the isotropic chain , the anisotropic XXZ model , and the two - leg ladder system .We see that CC provides reliable results even at low temperatures where standard mean - field methods fail to explain correctly the physics of these systems . In particular we find that the magnetization path of the isotropic chain exhibits an unexpected non - monotonic activity which can be described by the presence of two rival phases characterized by various values of the staggered magnetization .Finally , we talk how our findings may be used as benchmark data for future numerical studies on more complicated two - dimensional or three - dimensional quantum magnets . The investigation of highly correlated electron systems has been a central topic in condensed matter theory over numerous years 1 .One important group of such substances are so - called quantum magnets 2 , i . e . , compounds whose low - energy excitations are explained by collective spin degrees of liberty . These systems have garnered considerable interest because they frequently exhibit exotic processes like unconventional superconductivity 3 , fractionalized excitations 4 , or topological order 5 .In past times there has already been growing interest in investigating artificially engineered particle magnets 6 using ultracold atoms 7 or trapped ions 8 . This new area of research provides remarkable possibilities to examine novel physical regimes 9 and it could lead to the development of new concepts 10 .However , despite their vital importance , theoretical investigations into quantum magnets remain challenging due to the strong correlations between the spins 11 . Therefore , finding useful techniques to estimate features of these systems still an active area of research 12 .One especially interesting example of a quantum magnet is given by the one - dimensional ( 1D ) Heisenberg study 13 where J > 0 denotes the strength of the transfer coupling between neighboring sites j = 1 , . . . , L along the chain direction x , while S j ≡ c † j σc j describes the local spin operator acting on site j with Pauli matrices { σ } . Here { c † j } and { c",
        "rewrite_text": "**Title:** Ground-State Long-Range Order in Quasi-One-Dimensional Heisenberg Quantum Antiferromagnets: High-Order Coupled-Cluster Calculations\n\n**Abstract:** In this study, we present high-order coupled cluster (CC) calculations to investigate the ground state energy and magnetic susceptibility of various one-dimensional spin-1/2 Heisenberg systems featuring nearest-neighbor interactions. Our analysis focuses on three specific configurations: the isotropic chain, the anisotropic XXZ model, and the two-leg ladder system. We demonstrate that the CC method yields reliable results even at low temperatures, where traditional mean-field approaches often fail to accurately capture the underlying physics of these quantum systems. Notably, our findings reveal an intriguing non-monotonic behavior in the magnetization path of the isotropic chain, which can be attributed to the existence of two competing phases, each characterized by distinct values of staggered magnetization. \n\nFurthermore, we discuss the implications of our results as benchmark data for future numerical investigations into more complex two-dimensional and three-dimensional quantum magnets. The exploration of highly correlated electron systems has long been a pivotal focus in condensed matter physics, particularly in the context of quantum magnets—materials whose low-energy excitations are governed by collective spin dynamics. These systems have attracted significant attention due to their potential to exhibit exotic phenomena such as unconventional superconductivity, fractionalized excitations, and topological order. Recent advancements in the manipulation of ultracold atoms and trapped ions have opened new avenues for studying engineered quantum magnets, offering exciting opportunities to explore novel physical regimes and develop innovative concepts. However, the theoretical analysis of quantum magnets remains a challenging endeavor due to the strong correlations inherent in these systems. Consequently, the search for effective methodologies to characterize their properties continues to be an active area of research. Our work contributes to this ongoing effort by providing insights into the one-dimensional Heisenberg model, characterized by the coupling strength \\( J > 0 \\) between neighboring sites along the chain, and the local spin operator defined at each site.",
        "ori-fast-z-score": 1.3401566701313368,
        "water-fast-z-score": 9.240027567747637,
        "rewrite-fast-z-score": 0.8512055557875505
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Charm-quark fragmentation with an effective coupling constant .\nAbstract:\nWe study the charm quark fragmentation into hadrons in perturbative QCD by using an effective coupling constant, which is determined so as to reproduce the experimental data on the total cross section for e+e-annihilation into hadrons at high energies.  We find that our results are consistent with those obtained within the framework of the conventional parton model and also with recent measurements performed by CLEO collaboration. The present analysis suggests that the charm quark fragmentation function can be well described by the Peterson form factor multiplied by a simple exponential function. \nPACS numbers: 11.10.Kk, 12.38.Qk, 13 .60.Hb \nI. INTRODUCTORY REMAR K\nIn this work we investigate the charm quark fragmentation functions (FFs) into light hadrons in perturbative quantum chromodynamics(pQCD). In particular, we use an effective coupling constant, αeff , which is determined so as t o reproduce the experimental data on thetotal cross section for e + e-annihilation into hadronsthat have been measured recentlybyCLEOcollaboration  1  .\nThe FFsof quarksintohadronicparticlesare important quantitiesin pQCDand they playanimportant role inthe calculationof various physical observables suchas the structurefunctions  2  ,the Drell-Yanprocess  3  ,and the semi-leptonic decay  4  . It hasbeen shownthat the FFsof quarksintohadronscan be calculatedperturbatively  5  -  8  . However, it shouldbe notedthatthe calculationsrequire veryhighenergy scales  9  . Therefore,it would be usefulto determineαefffromexperimentaldataat relativelylowenergies  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Charm - quark fragmentation with an efficient coupling constant . Abstract : We research the charm quark fragmentation into hadrons in perturbative QCD by using an effective coupling constant , which is calculated so as to reproduce the empirical data on the total cross section for e + e - annihilation into hadrons at high energies .We see that our findings are compatible with those achieved within the framework of the usual parton theory and also with recent observations performed by CLEO collaboration . The present evaluation suggests that the charm quark fragmentation relation can be well described by the Peterson form parameter multiplied by a simple exponential function .PACS codes : 11 . 10 . Kk , 12 . 38 . Qk , 13 . 60 . Hb I . INTRODUCTORY REMAR K In this study we investigate the charm quark fragmentation curves ( FFs ) into light hadrons in perturbative molecular chromodynamics ( pQCD ) .In particular , we using an efficient coupling constant , αeff , which is calculated so as t o reproduce the empirical data on thetotal cross section for e + e - annihilation into hadronsthat have been measured recentlybyCLEOcollaboration 1 . The FFsof quarksintohadronicparticlesare crucial quantitiesin pQCDand they playanimportant importance inthe calculationof various mechanical observables suchas the structurefunctions 2 , the Drell - Yanprocess 3 , and the semi - leptonic decay 4 .It hasbeen shownthat the FFsof quarksintohadronscan be calculatedperturbatively  5  -  8  .However, it shouldbe notedthatthe calculationsrequire veryhighenergy scales  9  .Therefore,it would be usefulto determineαefffromexperimentaldataat relativelylowenergies  10  .",
        "rewrite_text": "**Title:** Charm Quark Fragmentation with an Efficient Coupling Constant\n\n**Abstract:** In this study, we investigate the fragmentation of charm quarks into hadrons within the framework of perturbative Quantum Chromodynamics (pQCD). We employ an effective coupling constant, denoted as α_eff, which is specifically calculated to align with empirical data regarding the total cross section for electron-positron (e⁺e⁻) annihilation into hadrons at high energies, as reported by the CLEO collaboration. Our results demonstrate a strong compatibility with findings derived from conventional parton theory, as well as with recent experimental observations. The analysis indicates that the fragmentation function (FF) for charm quarks can be accurately represented by the Peterson form, modified by a simple exponential function. \n\nThe fragmentation functions of quarks into hadronic particles are essential in pQCD, as they significantly influence the calculation of various physical observables, including structure functions, the Drell-Yan process, and semi-leptonic decays. Previous studies have established that these fragmentation functions can be computed perturbatively; however, such calculations typically necessitate very high energy scales. Consequently, our approach aims to derive α_eff from experimental data collected at relatively lower energy levels, which may provide a more accessible framework for understanding charm quark fragmentation. This research not only enhances our comprehension of charm quark behavior in high-energy physics but also contributes to the broader understanding of hadronization processes in quantum chromodynamics. \n\n**PACS Codes:** 11.10.Kk, 12.38.Qk, 13.60.Hb",
        "ori-fast-z-score": -1.585187847802434,
        "water-fast-z-score": 5.813776741499453,
        "rewrite-fast-z-score": -0.7107423155935334
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Locally Decodable Codes From Nice Subsets of Finite Fields and Prime Factors of Mersenne Numbers .\nAbstract:\nWe present new constructions for locally decodable codes (LDCs) based on nice subsets of finite fields, prime factors of Mersenne numbers, and the Chinese remainder theorem. Our first construction is an explicit family of LDCs with optimal query complexity that are derived from nice subsets of finite fields. We then show how to use these results in conjunction with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the number of primes used in their construction. Finally we give a lower bound on the length of any LDC over a binary alphabet which uses only one-sided queries. The proofs of our main theorems appear at the end of this extended abstract. \nIntroduction\n\nLocally decodable codes (abbreviated as LCDs)\nare error correcting codes where each codeword has associated with it some decoding algorithm that allows efficient recovery of individual bits or symbols when queried about them. In particular, if the codeword is corrupted by up to t errors, then there exists a deterministic polynomial time algorithm that recovers the original uncorrupted word using O(t) queries per symbol. This property makes such codes useful in applications like data storage systems, peer-to-peer networks, and streaming media distribution services. \n \n A large body of work has been devoted towards understanding the trade-off between the rate of the code, its distance, and the query complexity of the decoder. For example, Guruswami et al. (2005), Chan et al. (2006) , and Kopparty & Saraf (2007)  studied the problem of constructing codes with low query complexity while maintaining high rates and distances. Recently, several works have focused on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain amount of corruption. These include the recent breakthrough result of Dvir et al. (2010a) (which improved upon the previous best-known upper bound due to Sudan et al., 2005 ) and the subsequent improvements made by Dvir et al. (2011 ), Feldman et al. (2012 , and Kopparty et al. (2013) . \n \n Another important",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Locally Decodable Codes From Nice Subsets of Finite Fields and Prime Factors of Mersenne Numbers . Abstract : We create fresh constructions for locally decodable codes ( LDCs ) based on nice subsets of finite fields , prime factors of Mersenne numbers , and the Chinese remainder theorem .Our first build is an explicit class of LDCs with optimal query complexity that are derived from good subsets of finite fields . We then show how to use these results in conjunction with the Chinese remainder theorem to obtain families of LDCs whose parameters can be tuned by varying the quantity of primes used in their construction .Finally we give a smaller bound on the length of any LDC over a binary alphabet which uses only one - sided queries . The proofs of our major theorems emerge at the end of this enlarged abstract .Introduction Locally decodable codes ( denoted as LCDs ) are mistake correcting codes where each codeword has associated with it some decoding algorithm that enables efficient returning of individual bits or characters when queried about them . In particular , if the codeword is corrupted by up to t errors , then there exists a deterministic polynomial period algorithm that recovers the actual uncorrupted phrase using O ( t ) queries per symbol .This property gives such codes usable in applications like data storage systems , peer - to - peer systems , and streaming media distribution services . A vast body of research has been focused towards studying the trade - off between the frequency of the code , its distance , and the query complexity of the decoder .For instance , Guruswami et al . ( 2005 ) , Chan et al .( 2006 ) , and Kopparty & Saraf ( 2007 ) studied the issue of constructing coding with lowest query complexity while maintaining high rates and distances . Recently , various efforts have concentrated on improving the known bounds on the minimum possible query complexity required to decode a single bit given a certain level of corruption .These include the recent breakthrough result of Dvir et al . ( 2010a ) ( which updated upon the previous good - used upper bound due to Sudan et al . , 2005 ) and the subsequent improvements done by Dvir et al .( 2011 ) , Feldman et al . ( 2012 , and Kopparty et al .(2013) .Another important",
        "rewrite_text": "**Title:** Locally Decodable Codes from Nice Subsets of Finite Fields and Prime Factors of Mersenne Numbers\n\n**Abstract:** In this paper, we present novel constructions of locally decodable codes (LDCs) leveraging nice subsets of finite fields, the prime factors of Mersenne numbers, and the principles of the Chinese remainder theorem. Our initial construction yields an explicit class of LDCs characterized by optimal query complexity, derived from well-structured subsets of finite fields. We further demonstrate how these findings can be integrated with the Chinese remainder theorem to generate families of LDCs, allowing for parameter adjustments based on the number of primes utilized in their formulation. Additionally, we establish a tighter bound on the length of any LDC over a binary alphabet that employs one-sided queries. The proofs supporting our principal theorems are detailed at the conclusion of this abstract.\n\n**Introduction:** Locally decodable codes (LDCs) are a category of error-correcting codes designed to facilitate the efficient retrieval of individual bits or symbols from a codeword, even in the presence of errors. Specifically, when a codeword is subject to up to t errors, there exists a deterministic polynomial-time algorithm capable of recovering the original uncorrupted message with O(t) queries per symbol. This characteristic renders LDCs particularly valuable in various applications, including data storage systems, peer-to-peer networks, and streaming media services. \n\nExtensive research has been dedicated to exploring the trade-offs between the code's rate, its distance, and the query complexity of the decoding process. Notable contributions to this field include works by Guruswami et al. (2005), Chan et al. (2006), and Kopparty & Saraf (2007), who investigated the construction of codes that minimize query complexity while maximizing rates and distances. Recently, significant advancements have been made in refining the known bounds on the minimum query complexity required to decode a single bit amidst a specified level of corruption. This includes the groundbreaking results of Dvir et al. (2010a), which improved upon earlier upper bounds established by Sudan et al. (2005), as well as subsequent enhancements by Dvir et al. (2011), Feldman et al. (2012), and Kopparty et al. (2013).",
        "ori-fast-z-score": -0.79555728417573,
        "water-fast-z-score": 6.046235359735548,
        "rewrite-fast-z-score": -0.48666426339228763
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Viscoelasticity and Stokes-Einstein relation in repulsive and attractive colloidal glasses .\nAbstract:\nWe study the dynamics of glassy states formed by particles interacting via short-range repulsion or attraction, using molecular-dynamics simulations at constant volume. We find that both types of systems exhibit non-Arrhenius relaxation with Vogel-Fulcher-Tammann (VFT) temperature dependence. The VFT temperatures are found to be higher for attractive than for repulsive interactions. In addition we show that the diffusion coefficients follow the Stokes-Einstein relation only when plotted as functions of the structural relaxation time. This is explained by considering the role played by elastic stresses on particle mobility. Finally, we discuss how our results can be used to understand recent experiments performed on colloids confined between two plates. Glass-forming liquids have been studied extensively over many decades  1  . Despite this effort there remain open questions about their properties  2  , including whether they obey the StokesEinstein relation  3  .\nIn particular it has recently become possible to prepare colloidal suspensions which form amorphous solids  4  . These materials provide an ideal opportunity to investigate the relationship between structure and dynamics  5  . However, despite considerable experimental  6  and theoretical  7  efforts, the nature of the slow dynamics observed in these systems remains controversial  8  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Viscoelasticity and Stokes - Einstein function in repulsive and attractive colloidal glasses . Abstract : We research the dynamics of glassy states formed by particles bonding via low - range repulsion or attraction , using molecular - mechanics simulations at constant volume .We see that both types of systems exhibit non - Arrhenius relaxation with Vogel - Fulcher - Tammann ( VFT ) temperature dependence . The VFT temperatures are found to be higher for attractive than for repulsive molecules .In addition we prove that the diffusion coefficients observe the Stokes - Einstein function only when plotted as functions of the structural relaxation time . This is understood by using the importance played by elastic strain on particle mobility .Finally , we explain how our findings can be used to explain latest studies performed on colloids confined between two plates . Glass - creating liquids have been studied frequently over numerous years 1 .Despite this progress there remain open questions about their characteristics 2 , particularly whether they obey the StokesEinstein relation 3 . In particular it has recently become able to develop colloidal suspensions which create amorphous solids 4 .These structures give an excellent chance to examine the relationship between form and dynamics 5 . However , despite considerable experimental 6 and theoretical 7 attempts , the nature of the slow behavior observed in these systems appears controversial 8 .",
        "rewrite_text": "In this study, we investigate the dynamics of glassy states formed by particles that interact through short-range repulsive or attractive forces, utilizing molecular mechanics simulations conducted at constant volume. Our findings reveal that both types of systems exhibit non-Arrhenius relaxation behavior characterized by a Vogel-Fulcher-Tammann (VFT) temperature dependence. Notably, we observe that the VFT temperatures are consistently higher for attractive particles compared to their repulsive counterparts. Furthermore, we demonstrate that the diffusion coefficients adhere to the Stokes-Einstein relation when plotted against the structural relaxation time. This relationship is elucidated by considering the significant role of elastic strain in influencing particle mobility. \n\nAdditionally, we discuss the implications of our results in the context of recent studies involving colloidal systems confined between two plates. The exploration of glass-forming liquids has been a focal point of research for many years, yet several questions regarding their fundamental properties remain unresolved. A particular area of interest is the adherence of these systems to the Stokes-Einstein relation, especially in light of advancements in the development of colloidal suspensions that yield amorphous solids. These amorphous structures provide a unique opportunity to investigate the interplay between structural form and dynamic behavior. Despite extensive experimental and theoretical efforts, the nature of the slow dynamics observed in these colloidal systems continues to be a topic of debate. Our research contributes to this ongoing discourse by providing insights into the mechanisms underlying the dynamics of repulsive and attractive colloidal glasses, thereby enhancing our understanding of their behavior and properties.",
        "ori-fast-z-score": 0.09853292781642932,
        "water-fast-z-score": 7.4524131352509935,
        "rewrite-fast-z-score": 1.2572371141874243
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Is Thick Brane Model Consistent with the Recent Observations? .\nAbstract:\nWe have studied the thick brane model in which our universe is embedded into an extra dimension and found that it can explain some recent observations such as cosmic microwave background anisotropy, supernovae Ia data and baryon acoustic oscillations without introducing any new physics beyond standard model. \n \n In this model, we assume that there exists a scalar field whose potential has two degenerate minima at different values of the vacuum expectation value (VEV). The VEVs are determined by the parameters of the potential. We find that if the difference between these VEVs is large enough to satisfy the condition for the existence of stable domain walls then the thickness of the wall becomes larger than the Hubble radius today. This means that the domain walls cannot be produced during inflationary epoch. On the other hand, if the difference between these vacua is small compared to the Hubble scale, the domain walls will be created after inflation but they decay before nucleosynthesis era due to their extremely high tension.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Is Thick Brane Model Consistent with the Recent Observations ? .Abstract : We have researched the deep brane model in which our universe is embedded into an additional dimension and found that it can describe some latest measurements such as cosmic microwave background anisotropy , supernovae Ia data and baryon acoustic oscillations without exploring any new science beyond standard model . In this description , we suppose that there exists a scalar field whose potential has two degenerate minima at different values of the vacuum expectation value ( VEV ) .The VEVs are decided by the variables of the potential . We see that if the difference between these VEVs is huge enough to meet the condition for the existence of stable domain barriers then the length of the wall grows larger than the Hubble diameter today .This implies that the domain barriers cannot be formed during inflationary epoch . On the other hand , if the difference between these vacua is tiny relative to the Hubble scale , the domain barriers will be formed after inflation but they decay before nucleosynthesis era due to their extremely raised tension .",
        "rewrite_text": "Title: Is the Thick Brane Model Compatible with Recent Observations?\n\nAbstract: In this study, we investigate the thick brane model, which posits that our universe is situated within an additional spatial dimension. Our findings indicate that this model effectively accounts for several recent astronomical observations, including cosmic microwave background (CMB) anisotropies, Type Ia supernova data, and baryon acoustic oscillations, all without necessitating any modifications to the established framework of the standard model of particle physics. Central to our analysis is the introduction of a scalar field characterized by a potential featuring two degenerate minima, each corresponding to distinct vacuum expectation values (VEVs). The specific values of these VEVs are determined by the parameters of the potential. \n\nWe demonstrate that when the difference between these VEVs is sufficiently large, it satisfies the criteria for the formation of stable domain walls, resulting in wall lengths that exceed the current Hubble diameter. This scenario suggests that such domain walls could not have formed during the inflationary period of the universe. Conversely, if the disparity between the VEVs is minimal in comparison to the Hubble scale, domain walls may emerge post-inflation. However, due to their significantly elevated tension, these walls would decay prior to the nucleosynthesis epoch. Our results provide critical insights into the viability of the thick brane model in light of contemporary observational data, highlighting its potential to unify various cosmological phenomena within a coherent theoretical framework. This work contributes to the ongoing discourse on the implications of higher-dimensional theories in cosmology and their alignment with empirical evidence.",
        "ori-fast-z-score": -2.943920288775949,
        "water-fast-z-score": 3.2627549126854696,
        "rewrite-fast-z-score": 1.1141720290623112
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Clustering Co-occurrence of Maximal Frequent Patterns in Streams .\nAbstract:\nIn this work, we study the problem of clustering co-occurrences of maximal frequent patterns (MFP) in streams. We propose an algorithm that clusters MFPs based on their occurrences and then uses these clusters to build a compact representation for each pattern. The proposed approach is efficient both in terms of space consumption as well as time required to process new data points. Our experimental results show that our method outperforms state-of-the-art algorithms by up to two orders of magnitude while achieving high accuracy. In addition, it can be easily parallelized using existing frameworks such as MapReduce or Spark. Keywords: Data stream mining, Cluster analysis, Frequent itemset mining, Association rule learning, Time series prediction. 1 Introduction Mining large volumes of streaming data has become increasingly important over recent years due to its wide range of applications including sensor networks  20, 21  , social media analytics  22  , fraud detection  23  , network intrusion detection  24  , etc.. However, processing massive amounts of streaming data poses several challenges since traditional batch-based approaches are not applicable anymore  25  . For example, if one wants to detect anomalies in a continuous flow of tweets, he needs to continuously monitor all incoming messages and identify those which deviate significantly from normal behavior  26  .\nTo address these issues, researchers have developed various techniques for analyzing data streams  7, 8, 27  . An emerging area within data stream mining focuses on discovering interesting patterns from data streams  28  . A common task in this context is finding frequent items/patterns in data streams  29  . Another popular research direction involves identifying correlations between different attributes  30  . These tasks are often performed jointly with classification  31  and/or regression  32  problems.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Clustering Co - incidence of Maximal Frequent Patterns in Streams . Abstract : In this research , we study the issue of clustering co - occurrences of maximal frequent patterns ( MFP ) in streams .We suggest an algorithm that clusters MFPs based on their occurrences and then uses these clusters to build a compact representation for each pattern . The proposed approach is efficient both in terms of space efficiency as well as effort needed to process new data sets .Our research results show that our technique outperforms state - of - the - art algorithms by up to two orders of magnitude while reaching large accuracy . In addition , it can be easily parallelized using existing frameworks such as MapReduce or Spark .Keywords : Data stream mining , Cluster modeling , Frequent itemset processing , Association control learning , Time series modeling . 1 Introduction Mining huge volumes of streaming information has become increasingly important over recent seasons due to its large variety of applications namely sensor networks 20 , 21 , social media analytics 22 , fraud detection 23 , network intrusion detection 24 , etc . .However , processing massive sums of streaming information poses various challenges since traditional batch - based methods are not applicable today 25 . For instance , if one wants to identify anomalies in a rapid stream of tweets , he requires to constantly watch all outgoing messages and locate those which deviate substantially from normal behavior 26 .To address these problems , researchers have developed various methods for studying data loops 7 , 8 , 27 . An emerging field within information stream mining focuses on discovering interesting trends from information streams 28 .A popular task in this context is identifying repeated objects / patterns in data systems 29 . Another common study direction concerns discovering correlations between various characteristics 30 .These tasks are often worked collectively with classification 31 and / or regression 32 questions .",
        "rewrite_text": "**Title:** Clustering Co-occurrence of Maximal Frequent Patterns in Streams\n\n**Abstract:** This study addresses the challenge of clustering co-occurrences of maximal frequent patterns (MFPs) within data streams. We propose a novel algorithm that effectively clusters MFPs based on their frequency of occurrence, subsequently utilizing these clusters to create a compact representation for each pattern. Our approach demonstrates significant efficiency in both space utilization and the processing effort required for new datasets. The results of our research indicate that our method surpasses existing state-of-the-art algorithms by as much as two orders of magnitude, while maintaining a high level of accuracy. Furthermore, our algorithm is designed for easy parallelization, making it compatible with established frameworks such as MapReduce and Spark.\n\nThe importance of mining vast amounts of streaming data has grown substantially in recent years, driven by a wide array of applications including sensor networks, social media analytics, fraud detection, and network intrusion detection. However, the processing of large-scale streaming data presents numerous challenges, as traditional batch-processing techniques are often inadequate. For example, in scenarios where one must detect anomalies in a continuous stream of tweets, it is essential to monitor all outgoing messages in real-time and identify those that significantly deviate from expected behavior.\n\nTo tackle these challenges, researchers have developed various methodologies for analyzing data streams. A burgeoning area within this field focuses on uncovering significant trends from streaming information. A key task in this domain involves identifying recurring objects or patterns within data systems, while another prevalent research direction explores the discovery of correlations among different attributes. These tasks are frequently integrated with classification and regression analyses, further enhancing the understanding of data dynamics in real-time environments.\n\n**Keywords:** Data stream mining, Cluster modeling, Frequent itemset processing, Association control learning, Time series modeling.",
        "ori-fast-z-score": -2.0211302086361083,
        "water-fast-z-score": 8.273159087695738,
        "rewrite-fast-z-score": 0.31622776601683794
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Isospin breaking in the yield of heavy meson pairs in e+e- annihilation near threshold .\nAbstract:\nWe study isospin-breaking effects on the production rate for heavy-light mesons (D, D*) and light-heavy mesons (D0, D0bar). We use an effective field theory approach to calculate these rates at leading order in perturbation theory. The results are compared with experimental data obtained by CLEO-c. \n \n Isospin symmetry plays an important role in hadronic physics. It relates states that differ only in their charge but have identical masses. In particular it implies that the strong decay widths of charged and neutral pions should be equal. However, this equality has been experimentally tested down to pion momenta as low as 1 MeV/c and deviations up to 20% were found  1  . These deviations can be explained within Chiral Perturbation Theory  2  , which predicts corrections proportional to powers of the momentum transfer between initial and final state particles. At higher energies, where the typical momentum transfers become larger than the chiral scale, one expects such corrections to vanish rapidly  3  .\n \nIn contrast, we consider here processes involving two heavy quarks close to threshold. Here, the typical momentum transfers are small enough so that non-perturbative contributions cannot be neglected anymore. As a consequence, even though the mass difference between charm and anti-charm quarks is tiny, there will still be significant differences between the corresponding cross sections  4  . \n \n This effect was first observed more than 20 years ago  5  when studying the production of charmed mesons in electron-positron collisions. Since then many experiments  6  -  8  have measured the ratio of the production rates for different combinations of heavy-meson pairs. While some of them find good agreement with theoretical predictions  9  based on Heavy Quark Effective Theory  10  , others disagree significantly  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Isospin breaking in the yield of heavy meson pairs in e + e - annihilation near threshold . Abstract : We research isospin - breaking effects on the production level for heavy - heavy mesons ( D , D * ) and light - heavy mesons ( D0 , D0bar ) .We use an efficient field model approach to estimate these rates at leading order in perturbation theory . The results are compared with theoretical data derived by CLEO - c . Isospin symmetry serves an important role in hadronic physics .It relates states that differ only in their charge but have equal masses . In particular it assumes that the strong decay widths of charged and neutral pions should be equal .However , this equality has been experimentally tested down to pion momenta as low as 1 MeV / c and deviations up to 20 % were found 1 . These deviations can be described within Chiral Perturbation Theory 2 , which predicts corrections proportional to powers of the velocity change between initial and final state particles .At higher energies , where the typical velocity transfers become bigger than the chiral scale , one expects such corrections to vanish swiftly 3 . In comparison , we consider here reactions involving two heavy quarks close to threshold .Here , the typical velocity transfers are small enough so that non - perturbative contributions need be forgotten anymore . As a consequence , even though the mass gap between charm and pro - charm quarks is tiny , there will still be considerable changes between the associated cross sections 4 .This phenomenon was first observed more than 20 centuries earlier 5 when examining the production of charmed mesons in electron - positron collisions . Since then many research 6 - 8 have recorded the proportion of the production rates for different combinations of heavy - meson pairs .While some of them find good agreement with theoretical predictions 9 based on Heavy Quark Effective Theory 10 , others disagree significantly 11 .",
        "rewrite_text": "**Title:** Isospin Breaking in the Yield of Heavy Meson Pairs in e+ e- Annihilation Near Threshold\n\n**Abstract:** This study investigates the effects of isospin breaking on the production rates of heavy-heavy mesons (D, D*) and light-heavy mesons (D0, D0̄) in electron-positron annihilation processes near the threshold. Utilizing an efficient field model approach, we estimate these production rates at leading order in perturbation theory and compare our findings with theoretical predictions from the CLEO-c collaboration. Isospin symmetry plays a crucial role in hadronic physics, linking states that differ solely in charge but possess identical masses. This symmetry implies that the strong decay widths of charged and neutral pions should be equivalent. However, experimental tests down to pion momenta of 1 MeV/c have revealed deviations of up to 20%. These discrepancies can be accounted for within the framework of Chiral Perturbation Theory, which suggests that corrections are proportional to the powers of the velocity change between initial and final state particles. At higher energy levels, where typical velocity transfers exceed the chiral scale, these corrections are expected to diminish rapidly. In this work, we focus on reactions involving two heavy quarks near threshold, where the velocity transfers remain sufficiently small, allowing us to neglect non-perturbative contributions. Despite the minimal mass difference between charm and anti-charm quarks, we observe significant variations in the associated cross sections. This phenomenon was first documented over two decades ago in studies of charmed meson production during electron-positron collisions. Since then, numerous investigations have measured the production rates of various heavy meson pair combinations. While some studies report results that align well with theoretical predictions based on Heavy Quark Effective Theory, others exhibit substantial discrepancies. Our research aims to clarify these inconsistencies and enhance the understanding of isospin breaking effects in heavy meson production.",
        "ori-fast-z-score": -0.5107539184552492,
        "water-fast-z-score": 5.979278639572285,
        "rewrite-fast-z-score": 3.601470287992685
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Challenging the Cosmological Constant .\nAbstract:\nThe cosmological constant is one of the most important parameters in modern physics, and its value has been determined by observations to be extremely small but nonzero.  In this article we will discuss how it can be explained as an effect of quantum gravity at very high energies. We will also show that if the universe underwent inflationary expansion after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation (CMBR). Finally, we will argue that these effects may provide us with new ways for testing the predictions of general relativity against those of alternative theories such as string theory or loop quantum gravity. The cosmological constant is one  of the most important parameters of modern physics. Its value was determined by observations to be incredibly small but non-zero. It plays a crucial role in our understanding of the evolution of the Universe since it determines whether the current accelerated expansion of space-time will continue forever or eventually slow down and stop. This question remains open despite many years of research into the nature of dark energy.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Challenging the Cosmological Constant . Abstract : The cosmological coefficient is one of the most important components in modern physics , and its value has been determined by observations to be extremely tiny but nonzero .In this page we will explore how it can be described as an influence of quantum gravitational at very high energies . We will also demonstrate that if the universe underwent inflationary inflation after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation ( CMBR ) .Finally , we will argue that these changes may provide us with alternative ways for testing the assumptions of general relativity against those of alternative theories such as string theory or loop quantum gravitational . The cosmological coefficient is one of the most important characteristics of modern physics .Its value was decided by observations to be incredibly small but un - zero . It plays a crucial role in our knowing of the evolution of the Universe since it determines whether the present rapid expansion of space - time will continue forever or eventually accelerate down and stop .This question continues open despite many years of research into the nature of dark energy .",
        "rewrite_text": "**Title: Challenging the Cosmological Constant**\n\n**Abstract:** The cosmological constant is a fundamental aspect of contemporary physics, playing a pivotal role in our understanding of the universe's expansion. Observational data has indicated that its value is remarkably small yet distinctly nonzero. In this article, we delve into the implications of the cosmological constant, particularly in the context of quantum gravity at extremely high energy scales. We propose that if the universe experienced inflationary expansion following the Big Bang, it would have generated primordial gravitational waves. These waves could potentially leave observable signatures in the cosmic microwave background radiation (CMBR), offering a unique avenue for empirical investigation. Furthermore, we discuss how these observable effects might serve as a means to test the foundational assumptions of general relativity against alternative theoretical frameworks, such as string theory and loop quantum gravity. The cosmological constant not only influences the dynamics of cosmic expansion but also raises profound questions about the nature of dark energy. Despite extensive research, the question of whether the universe's current accelerated expansion will persist indefinitely or eventually decelerate remains unresolved. Our exploration seeks to illuminate these critical issues, providing insights that could reshape our understanding of cosmic evolution and the fundamental forces at play. By examining the interplay between the cosmological constant, inflationary theory, and gravitational waves, we aim to contribute to the ongoing discourse surrounding dark energy and its implications for the future of the universe.",
        "ori-fast-z-score": 1.3480372031495529,
        "water-fast-z-score": 5.848076606885379,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Geodesics for Efficient Creation and Propagation of Order along Ising Spin Chains .\nAbstract:\nWe present an algorithm that efficiently creates and propagates order in spin chains with the help of geodesic paths on graphs representing the spins. The algorithm is based on the observation that, if we consider two neighboring sites as nodes of a graph, then the probability distribution over all possible states of these two sites can be represented by a weighted edge between them. We show how to use this representation to create ordered regions within the chain using only local information about the state of each site. In particular, our method allows us to find optimal configurations of the system at low temperatures (where thermal fluctuations are small) without having to explore the entire configuration space. This makes it possible to study systems whose size would otherwise make exact calculations intractable. Our results demonstrate that the proposed approach provides accurate predictions even when applied to relatively short chains. Finally, we discuss several extensions of the presented ideas which may lead to further improvements in efficiency. \n \n Introduction \n \n Many physical phenomena such as magnetism or phase transitions occur due to cooperative behavior among many interacting particles. For example, magnetic ordering in solids occurs because individual atoms interact strongly via their magnetic moments. Similarly, liquid helium undergoes superfluidity below its critical temperature T_c = 2.17 K because pairs of helium-4 atoms form tightly bound bosons known as Cooper pairs. These examples illustrate that understanding collective behavior requires studying large ensembles of interacting particles rather than single isolated ones. However, simulating macroscopic properties of complex systems composed of many interacting elements remains one of the most challenging problems in computational physics today. Indeed, while microscopic interactions between individual particles can often be described accurately by quantum mechanics, describing macroscopic properties of large collections of particles typically involves approximations that cannot capture subtle effects arising from correlations between different parts of the system. As a result, numerical simulations of large-scale models of real-world systems are usually performed using approximate methods such as Monte Carlo sampling  1  . Unfortunately, these approaches become computationally expensive when used to simulate systems containing millions...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Geodesics for Efficient Creation and Propagation of Order along Ising Spin Chains . Abstract : We create an algorithm that efficiently creates and propagates order in spinning chains with the aid of geodesic tracks on graphs depicting the spins .The algorithm is based on the observation that , if we treat two adjacent sites as nodes of a graph , then the probability distribution over all possible states of these two locations can be described by a weighted edge between them . We see how to use this representation to create ordered regions within the chain using only local information about the state of each site .In particular , our technique lets us to find optimal configurations of the system at low temperatures ( where thermal fluctuations are small ) without having to examine the entire configuration room . This gives it able to study systems whose size would normally leave accurate calculations intractable .Our results show that the suggested approach offers efficient predictions especially when applied to relatively short chains . Finally , we explain several extensions of the offered concepts which would result to further changes in efficiency .Introduction Many scientific phenomena such as magnetism or phase transitions occur due to cooperative relationships among various interacting molecules . For instance , magnetic ordering in solids occurs because individual atoms connect strongly via their magnetic moments .Similarly , fluid helium undergoes superfluidity below its critical temperature T _ c = 2 . 17 K because pairs of helium - 4 molecules form tightly bound bosons called as Cooper pairs . These instances illustrate that understanding collective behavior needs investigating small ensembles of interacting electrons rather than single isolated ones .However , simulating macroscopic properties of complex systems composed of several interacting elements becomes one of the most challenging difficulties in computational physics today . Indeed , while microscopic interactions between individual electrons can often be described easily by quantum mechanics , exploring macroscopic properties of large collections of atoms typically requires approximations that cannot reproduce subtle effects resulting from correlations between various parts of the system .As a result , numerical simulations of large - scale models of real - time systems are typically performed using approximate approaches such as Monte Carlo sampling 1 . Unfortunately , these method become computationally expensive when utilized to simulate systems containing many . . .",
        "rewrite_text": "**Title:** Geodesics for Efficient Creation and Propagation of Order along Ising Spin Chains\n\n**Abstract:** In this study, we present a novel algorithm designed to efficiently generate and propagate order within Ising spin chains by utilizing geodesic paths on graphs that represent the spins. Our approach is grounded in the concept that adjacent sites can be modeled as nodes in a graph, where the probability distribution of their states is captured by a weighted edge connecting them. This representation allows us to leverage local information about each site's state to establish ordered regions within the spin chain. Notably, our method enables the identification of optimal configurations at low temperatures, where thermal fluctuations are minimal, without the need to analyze the entire configuration space. This capability significantly enhances our ability to investigate larger systems that would otherwise be computationally prohibitive for accurate calculations. Our findings indicate that the proposed algorithm yields efficient predictions, particularly for shorter chains. Furthermore, we discuss potential extensions of our methodology that could lead to improved efficiency in various applications.\n\n**Introduction:** The study of collective phenomena, such as magnetism and phase transitions, is fundamentally rooted in the interactions among multiple molecules. For example, magnetic ordering in solids arises from the strong coupling of individual atoms through their magnetic moments. Similarly, the phenomenon of superfluidity in liquid helium occurs below its critical temperature (T_c = 2.17 K) due to the formation of tightly bound bosonic pairs known as Cooper pairs. These examples underscore the necessity of examining the collective behavior of interacting particles rather than focusing on isolated entities. However, simulating the macroscopic properties of complex systems with numerous interacting components poses significant challenges in computational physics. While the quantum mechanical description of individual electron interactions is often straightforward, capturing the macroscopic behavior of large atomic ensembles typically requires approximations that may overlook critical correlation effects. Consequently, numerical simulations of extensive real-time systems frequently rely on approximate methods, such as Monte Carlo sampling. Unfortunately, these techniques can become computationally intensive when applied to systems with a large number of particles, complicating the analysis of their properties.",
        "ori-fast-z-score": -0.775880177444458,
        "water-fast-z-score": 8.53468195188904,
        "rewrite-fast-z-score": -0.5146502354656654
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Minimum Expected Distortion in Gaussian Layered Broadcast Coding with Successive Refinement .\nAbstract:\nWe consider the problem of successive refinement coding for layered broadcast systems, where each receiver is interested only in one out of several layers and has access to all previous layers. We propose an optimal scheme that minimizes expected distortion at any given receiver by using rate-distortion optimized quantizers. The proposed scheme can be implemented efficiently as it requires no feedback between receivers or encoders. Our results are illustrated through numerical examples. Index Terms-Broadcasting, Data compression, Quantization, Rate-distortion theory, Successive refinement coding. I. INTRODUCTIO N In this work we study the problem of successive refinem ent coding (SRC)  1  , which consists on transmitting information over multiple stages such that the quality of reconstruction improves progressively. SRC is used extensively in video broadcasting applications  2  -  4  . For example, in digital television transmission, the base station sends a coarse description of the video sequence to mobile users via satellite links. Then, when these users get closer to their destination they request additional descriptions of higher resolution. This process continues until the user receives enough data to reconstruct the original signal without error  5  .\nIn general, there exist two different approaches to solve the SRC problem: 1) Joint source-channel coding: Here, the encoder jointly optimizes both source coding and channel coding  6 -  8  ; 2) Separate source-channel coding: Here, separate source coders and channel codes are employed  9  -  11  . In this case, the source code must provide some form of side-information so that the decoder can perform successive decoding  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Minimum Expected Distortion in Gaussian Layered Broadcast Coding with Successive Refinement . Abstract : We consider the issue of successive refinement compression for structured transmission systems , where each receiver is interested only in one out of several layers and has access to all previous layers .We suggest an appropriate plan that minimizes expected distortion at any certain receiver by using rate - distortion optimized quantizers . The proposed system can be applied efficiently as it requires no feedback between receivers or encoders .Our results are shown through numerical examples . Index Terms - Broadcasting , Data coding , Quantization , Rate - noise theory , Successive refinement compression .I . INTRODUCTIO N In this research we study the question of successive refinem ent coding ( SRC ) 1 , which consists on transmitting information over successive phases such that the quality of recovery improves progressively . SRC is utilized heavily in video broadcasting applications 2 - 4 .For instance , in digital television broadcast , the base station provides a coarse summary of the footage scene to mobile users via satellite connections . Then , when these users feel nearer to their target they seek alternative descriptions of greater resolution .This process proceeds until the user receives enough data to reconstruct the original signal without mistake 5 . In general , there follow two different methods to solve the SRC problem : 1 ) Joint source - channel code : Here , the encoder jointly optimizes both source coding and channel code 6 - 8 ; 2 ) Separate source - channel code : Here , distinct source coders and channel codes are applied 9 - 11 .In this instance , the source language must offer some kind of side - information so that the decoder can conduct consecutive decoding 12 .",
        "rewrite_text": "**Title:** Minimum Expected Distortion in Gaussian Layered Broadcast Coding with Successive Refinement\n\n**Abstract:** This article addresses the challenge of successive refinement compression within structured transmission systems, where each receiver is focused on a specific layer while having access to all preceding layers. We propose a systematic approach aimed at minimizing the expected distortion for any given receiver by employing rate-distortion optimized quantizers. The efficiency of our proposed system is notable, as it operates without the need for feedback between receivers or encoders, streamlining the communication process. Our findings are illustrated through various numerical examples, demonstrating the practical applicability of the method. \n\nThe concept of successive refinement coding (SRC) is central to our research, which involves transmitting information in multiple phases, progressively enhancing the quality of the received data. SRC is particularly relevant in video broadcasting scenarios, such as digital television, where a base station transmits a basic overview of a scene to mobile users via satellite. As users approach their desired content, they can request higher-resolution alternatives, continuing this process until they obtain sufficient data to accurately reconstruct the original signal. \n\nTo tackle the SRC problem, we identify two primary methodologies: the joint source-channel coding approach, which optimizes both source and channel coding simultaneously, and the separate source-channel coding approach, which utilizes distinct coders for each function. In the latter case, the source must provide some form of side information to enable the decoder to perform successive decoding effectively. Our research contributes to the understanding and implementation of SRC in layered broadcast systems, paving the way for improved data transmission strategies in various applications.\n\n**Index Terms:** Broadcasting, Data coding, Quantization, Rate-noise theory, Successive refinement compression.",
        "ori-fast-z-score": -2.341196917715124,
        "water-fast-z-score": 5.744562646538029,
        "rewrite-fast-z-score": 0.16783627165933782
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modeling Accretion Disk X-ray Continuum of Black Hole Candidates .\nAbstract:\nWe present the results of our investigation into accretion disk continuum emission in black hole candidates (BHCs). We have developed an analytical model for calculating the spectrum emitted by a thin, optically thick accretion disk around a Schwarzschild black hole and applied it to several BHCs with known mass functions. The observed spectra are well reproduced when we assume that the inner edge of the disk is located at 6 gravitational radii. This result suggests that the standard thin disk model can be used as a good approximation for modeling the X-ray continuum emission of these objects. \n \n Keywords: Black holes -- Spectroscopy -- X-rays -- Modeling -- Accretion disks -- Emission lines -- Broad-band spectral energy distribution -- Luminosity function -- Mass measurement -- Stellar-mass black holes -- Supermassive black holes -- Active galactic nuclei -- Quasars -- Cosmic evolution \n \n \n \n 1 Introduction \n \n In recent years there has been considerable progress made towards understanding the physical processes occurring near supermassive black holes (SMBH) in active galactic nuclei (AGN), quasars, and other similar systems. These studies rely on observations of the broad-band spectral energy distributions (SEDs) of SMBHs over many decades in frequency space. However, because of their enormous distances, direct measurements of the intrinsic luminosities of most AGNs are not possible. Instead, one must use indirect methods such as reverberation mapping or statistical correlations between various properties of AGNs to determine their luminosities. For example, if one knows how much light passes through some region of interest within an AGN then one may calculate its luminosity using simple geometric arguments. Alternatively, if one knows the distance to an AGN then one could measure its absolute magnitude directly. Unfortunately, both of these approaches require detailed knowledge about the structure of the emitting regions which cannot currently be obtained observationally. Therefore, in order to make accurate estimates of the luminosities of distant AGNs, one needs to develop models capable of reproducing the observed SEDs of nearby AGNs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modeling Accretion Disk X - ray Continuum of Black Hole Candidates . Abstract : We present the conclusion of our inquiry into accretion disk continuum emission in black hole candidates ( BHCs ) .We have developed an analytical model for determining the spectrum emitted by a thin , optically dense accretion disk around a Schwarzschild red hole and applied it to several BHCs with reported mass parameters . The observed spectra are better displayed when we suppose that the inner corner of the disk is situated at 6 gravitational radii .This result suggests that the standard narrow disk model can be used as a better approximation for modeling the X - ray continuum emission of these objects . Keywords : Black holes - - Spectroscopy - - X - rays - - Modeling - - Accretion disks - - Emission lines - - Broad - band spectral power distribution - - Luminosity function - - Mass determination - - Stellar - mass black holes - - Supermassive black holes - - Active galactic nuclei - - Quasars - - Cosmic evolution 1 Introduction In recent years there has been substantial development done towards studying the physical processes arising near supermassive black holes ( SMBH ) in active galactic nuclei ( AGN ) , quasars , and other similar components .These studies relied on observations of the broad - band spectral power distributions ( SEDs ) of SMBHs over numerous years in frequency space . However , because of their huge altitudes , direct measurements of the intrinsic luminosities of most AGNs are not required .Instead , one must use indirect tools such as reverberation projection or statistical correlations between various properties of AGNs to estimate their luminosities . For instance , if one knows how many light passes through some region of interest within an AGN then one may calculate its luminosity using simple geometric arguments .Alternatively , if one knows the distance to an AGN then one might estimate its absolute magnitude simply . Unfortunately , both of these method require precise understanding about the stability of the emitting regions which lacks currently be obtained observationally .Therefore , in order to make accurate calculations of the luminosities of distant AGNs , one needs to develop models capable of reproducing the known SEDs of distant AGNs .",
        "rewrite_text": "We present the findings of our research on the continuum emission from accretion disks in black hole candidates (BHCs). Our study introduces an analytical model designed to calculate the spectrum emitted by a thin, optically thick accretion disk surrounding a Schwarzschild black hole. This model has been applied to various BHCs for which mass parameters have been documented. Our analysis indicates that the observed spectra are more accurately represented when we assume that the inner edge of the disk is located at six gravitational radii. This finding implies that the conventional thin disk model serves as a more effective approximation for modeling the X-ray continuum emissions of these celestial objects.\n\nIn recent years, significant advancements have been made in understanding the physical processes occurring near supermassive black holes (SMBHs) found in active galactic nuclei (AGNs), quasars, and similar entities. These investigations have primarily relied on long-term observations of the broad-band spectral energy distributions (SEDs) of SMBHs across various frequency ranges. However, due to their immense distances, direct measurements of the intrinsic luminosities of most AGNs are often impractical. Instead, researchers typically employ indirect methods such as reverberation mapping or statistical correlations among different AGN properties to estimate their luminosities. For example, by determining the number of light travel times through a specific region within an AGN, one can derive its luminosity using straightforward geometric principles. Alternatively, knowing the distance to an AGN allows for the estimation of its absolute magnitude. Unfortunately, both approaches necessitate a precise understanding of the stability of the emitting regions, which is currently challenging to obtain through observations. Consequently, to accurately calculate the luminosities of distant AGNs, it is essential to develop models that can effectively replicate the known SEDs of these distant sources.",
        "ori-fast-z-score": -1.0309670614335873,
        "water-fast-z-score": 5.910828046793255,
        "rewrite-fast-z-score": -0.5107539184552492
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Extraction of physical laws from joint experimental data .\nAbstract:\nWe present an approach to extract the underlying physics from large sets of experimental data by using machine learning techniques and statistical analysis. The method is applied on two different examples, namely the measurement of the electrical conductivity in doped semiconductors as well as the determination of the critical temperature Tc for superconductivity in cuprates. In both cases we find that our results are consistent with theoretical predictions. We show how this new technique can be used to identify unknown parameters or even completely new phenomena which cannot be predicted theoretically at all. This work was supported by the German Science Foundation (DFG) under grant number SFB/TRR 191. A central goal of modern science is to understand complex systems such as materials or living organisms through their fundamental building blocks. To achieve this aim it is necessary to develop methods which allow us to analyze huge amounts of experimental data efficiently. Here we propose a novel approach based on machine learning algorithms combined with advanced statistical tools. Our method is demonstrated on two examples: First, we study the dependence of the electrical conductivity on doping concentration in semiconductor compounds. Second, we determine the critical temperature T c for superconductivity in high-temperature cuprate oxides. For both problems we obtain results which agree very well with existing theories. Moreover, we demonstrate how our method allows one to discover previously unforeseen features in the data.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Extraction of physical rules from joint experimental evidence . Abstract : We present an approach to extract the fundamental theory from huge sets of experimental evidence by using computer learning techniques and statistical analysis .The method is applied on two different examples , notably the determination of the electrical conductivity in doped semiconductors as well as the determination of the key cold Tc for superconductivity in cuprates . In both cases we find that our findings are compatible with theoretical estimates .We see how this new technique can be used to identify unseen conditions or even completely different processes which cannot be described theoretically at all . This research was supported by the German Science Foundation ( DFG ) under grant number SFB / TRR 191 .A central goal of modern science is to comprehend large systems such as materials or living organisms through their core building blocks . To achieve this aim it is required to develop techniques which allow us to analyze huge amounts of research data easily .Here we develop a innovative method using on machine modeling algorithms combined with sophisticated mathematical tools . Our method is demonstrated on two examples : First , we study the dependence of the electrical conductivity on doping concentration in semiconductor compounds .Second , we determine the important temperature T c for superconductivity in high - temperature cuprate oxides . For both difficulties we obtain results which agree very best with existing ideas .Moreover , we prove how our technique permits one to find already unforeseen features in the information .",
        "rewrite_text": "Title: Extraction of Physical Rules from Joint Experimental Evidence\n\nAbstract: In this study, we introduce a novel methodology for deriving fundamental theories from extensive sets of experimental data through the application of machine learning techniques and statistical analysis. Our approach is exemplified through two distinct case studies: the assessment of electrical conductivity in doped semiconductors and the identification of the critical temperature (Tc) for superconductivity in cuprate materials. In both instances, our results align closely with established theoretical predictions, demonstrating the efficacy of our method. This innovative technique not only facilitates the extraction of known relationships but also has the potential to uncover previously unrecognized conditions or entirely new processes that may not be adequately described by existing theoretical frameworks. \n\nThe impetus behind this research is the overarching goal of modern science to understand complex systems, such as materials and biological entities, by examining their fundamental components. Achieving this objective necessitates the development of advanced analytical tools capable of processing and interpreting vast amounts of research data efficiently. Our method integrates machine learning algorithms with sophisticated mathematical frameworks, enabling a comprehensive analysis of experimental evidence.\n\nWe first investigate the relationship between electrical conductivity and doping concentration in semiconductor compounds, revealing insights that corroborate current theoretical models. Subsequently, we focus on determining the critical temperature Tc for superconductivity in high-temperature cuprate oxides, again finding strong agreement with existing theories. Furthermore, our findings illustrate how this technique can reveal unforeseen characteristics within the data, thereby expanding our understanding of the underlying physical principles. This research was conducted with the support of the German Science Foundation (DFG) under grant number SFB/TRR 191, highlighting the collaborative effort to advance scientific knowledge through innovative data analysis methods.",
        "ori-fast-z-score": -0.7986208584745025,
        "water-fast-z-score": 7.077002858954407,
        "rewrite-fast-z-score": -0.9330078226479681
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Optical Transitions in New Trends Organic Materials .\nAbstract:\nOrganic materials have been widely used for optoelectronic devices, such as organic light-emitting diodes (OLEDs), photovoltaics and sensors due to their unique properties including low cost, flexibility, large area coverage and solution processability. In this review we focus on the recent progresses made by our group in developing new types of organic materials with high performance for OLED applications. We first introduce some basic concepts about luminescent mechanisms in OLEDs. Then we discuss several important issues related to the development of novel emissive layers based on small molecules or polymers. Finally, we summarize the current challenges and future trends in designing highly efficient OLEDs. The research work presented here is supported by National Natural Science Foundation of China under Grants No. 21471063, 21621062, 21573189, 21390563 , 21133005 . Keywords: Light emitting diode; Emissive layer; Small molecule",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Optical Transitions in New Trends Organic Materials . Abstract : Organic materials have been widely useful for optoelectronic products , such as organic light - emitting diodes ( OLEDs ) , photovoltaics and sensors due to their distinct characteristics including low cost , functionality , large area coverage and application processability .In this review we focus on the recent progresses done by our team in identifying new types of organic materials with high quality for OLED applications . We first introduce some fundamental concepts about luminescent mechanisms in OLEDs .Then we talk several important problems related to the development of new emissive layers modeled on small particles or polymers . Finally , we summarize the present difficulties and future developments in building highly efficient OLEDs .The research work offered here is backed by National Natural Science Foundation of China under Grants No . 21471063 , 21621062 , 21573189 , 21390563 , 21133005 .Keywords: Light emitting diode; Emissive layer; Small molecule",
        "rewrite_text": "**Title:** Optical Transitions in Emerging Organic Materials\n\n**Abstract:** Organic materials have gained significant traction in the field of optoelectronics, finding applications in devices such as organic light-emitting diodes (OLEDs), photovoltaics, and sensors. Their appeal lies in several advantageous properties, including cost-effectiveness, versatility, extensive area coverage, and ease of processing. This review highlights the recent advancements made by our research team in the exploration and identification of novel organic materials that exhibit superior quality for OLED applications. We begin by discussing essential concepts related to the luminescent mechanisms that underpin OLED technology, providing a foundational understanding of how these devices operate. Following this, we address several critical challenges associated with the development of new emissive layers, particularly those based on small molecules or polymers. These challenges include optimizing the efficiency and stability of the emissive layers, as well as enhancing their compatibility with existing device architectures. We conclude by summarizing the current obstacles faced in the pursuit of highly efficient OLEDs and outlining potential directions for future research and development. Our findings are supported by funding from the National Natural Science Foundation of China under Grants No. 21471063, 21621062, 21573189, 21390563, and 21133005. \n\n**Keywords:** Organic light-emitting diode; Emissive layer; Small molecules; Photovoltaics; Optoelectronics.",
        "ori-fast-z-score": 0.3611575592573076,
        "water-fast-z-score": 6.052586456788652,
        "rewrite-fast-z-score": 2.5021729686848975
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stability of isentropic viscous shock profiles in the high-Mach number limit .\nAbstract:\nWe study stability properties of steady-state solutions to the compressible Navier-Stokes equations with large Mach numbers, and prove that they are stable under small perturbations if their pressure satisfies certain conditions.  We consider two types of steady states: (i) traveling waves which connect different constant states; and (ii) stationary shocks connecting different constant states. For both cases we show that these steady-states are stable for all sufficiently large Mach numbers M > 1 provided that the pressure p(ρ) has at most one inflection point on its graph. In particular, this implies that any smooth solution starting close enough to such a steady state converges exponentially fast towards it as time goes to infinity. \nThe proof relies on an energy estimate combined with suitable weighted Sobolev estimates. The main difficulty lies in dealing with the nonlinear term arising from the convection part of the equation. This problem can be overcome by using appropriate weight functions together with some delicate analysis based on the maximum principle.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stability of isentropic viscous shock profiles in the high - Mach number limit . Abstract : We explore stability properties of stable - state solutions to the compressible Navier - Stokes equations with large Mach numbers , and prove that they are stable under small perturbations if their tension satisfies certain conditions .We consider two forms of stable states : ( i ) moving flows which link different constant states ; and ( ii ) stationary shocks connecting different constant states . For both cases we prove that these steady - states are stable for all sufficiently huge Mach numbers M > 1 given that the pressure p ( ρ ) has at most one inflection point on its graph .In particular , this implies that any smooth solution starting nearer sufficiently to such a steady state converges exponentially rapidly towards it as time went to infinity . The proof uses on an energy estimate combined with suitable weighted Sobolev estimates .The main problems lies in dealing with the nonlinear term arising from the convection part of the equation . This problem can be overcome by using appropriate weight functions combined with some delicate investigation based on the maximum law .",
        "rewrite_text": "In this study, we investigate the stability characteristics of steady-state solutions to the compressible Navier-Stokes equations in the context of high Mach number flows. Our primary focus is on demonstrating that these solutions remain stable under small perturbations, provided that certain conditions regarding tension are met. We analyze two distinct types of stable states: (i) moving flows that connect different constant states, and (ii) stationary shock waves that link various constant states. For both scenarios, we establish that these steady states exhibit stability for sufficiently large Mach numbers (M > 1), contingent upon the pressure function p(ρ) having at most one inflection point in its graphical representation. This finding indicates that any smooth solution that begins close enough to such a steady state will converge exponentially fast toward it as time progresses toward infinity. Our proof employs an energy estimate in conjunction with appropriately weighted Sobolev estimates. A significant challenge in this analysis arises from the nonlinear terms associated with the convection component of the equations. We address this issue by utilizing suitable weight functions and conducting a meticulous examination based on the maximum principle. Overall, our results contribute to a deeper understanding of the stability of viscous shock profiles in high-Mach number regimes, with implications for both theoretical and practical applications in fluid dynamics.",
        "ori-fast-z-score": 0.8,
        "water-fast-z-score": 4.676674793986949,
        "rewrite-fast-z-score": 1.3987572123604708
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gauge Invariant Factorisation and Canonical Quantisation of Topologically Massive Gauge Theories in Any Dimension .\nAbstract:\nWe present the canonical quantization of topologically massive gauge theories in any dimension, including the case of non-abelian gauge fields coupled to fermions. We show that these models are equivalent to gauge-invariant factorised formalisms which have been used previously for studying such systems. In particular we demonstrate how this equivalence can be exploited to obtain exact results for correlation functions at finite temperature using functional methods. This formalism is also applicable to other quantum field theories with massless particles and an associated topological term. It may therefore prove useful as a general tool for investigating strongly interacting systems where conventional perturbative techniques fail. Introduction:-The study of quantum field theory has led to many important insights into fundamental physics over recent decades. However it remains difficult to solve exactly even simple problems involving interactions between elementary particles due to their nonperturbative nature. One approach to tackling this problem involves exploiting symmetries inherent within certain classes of model systems; in particular supersymmetry (SUSY) provides powerful constraints on the possible forms of particle interaction and leads to significant simplifications when applied to specific physical situations  1  . Another promising technique exploits the fact that some quantum field theories possess additional global or local symmetries which allow them to be expressed in terms of simpler effective descriptions known as  gauge-invariant factorisations   2  , see e.g.  3  -  6  .\nIn this work we consider a class of quantum field theories whose Lagrangians contain both a standard kinetic energy term and a so-called  topological  contribution arising from the coupling of the gauge field to itself  7, 8  . These theories include Yang-Mills-Higgs models  9  , Chern-Simons-matter theories  10  , and more recently proposed extensions  11  -  13  . They play an important role in condensed matter physics  14  , string theory  15  , and cosmology  16  . Despite being relatively simple they exhibit rich behaviour; for example they support excitations with fractional statistics  17  and provide examples of parity-violating phases  18  . Furthermore there exist interesting connections...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Gauge Invariant Factorisation and Canonical Quantisation of Topologically Massive Gauge Theories in Any Dimension . Abstract : We present the canonical quantization of topologically heavy gauge fields in any dimension , particularly the case of non - abelian gauge fields coupled to fermions .We see that these models are comparable to gauge - invariant factorised formalisms which have been used earlier for studying such systems . In particular we prove how this equivalence can be exploited to obtain exact findings for correlation functions at finite temperature using functional principles .This formalism is also useful to other particle field theories with massless objects and an associated topological term . It might hence become useful as a general tool for investigating strongly interacting networks where conventional perturbative tools fail .Introduction : - The investigation of quantum field theory has led to many important knowledge into fundamental theory over recent generations . However it remains impossible to solve exactly especially simple problems concerning interactions between elementary particles thanks to their nonperturbative nature .One approach to tackling this question involves exploiting symmetries inherent within particular categories of model structures ; in instance supersymmetry ( SUSY ) presents powerful restrictions on the possible kinds of particle interaction and allows to significant simplifications when applied to different physical conditions 1 . Another promising technique exploits the fact that some quantum field theories possess additional global or local symmetries which allow them to be described in terms of simpler efficient descriptions called as gauge - invariant factorisations 2 , see e . g .3 - 6 . In this research we define a class of quantum field theories whose Lagrangians contain both a basic kinetic power term and a so - called topological contribution arising from the interaction of the gauge field to itself 7 , 8 .These concepts contain Yang - Mills - Higgs theories 9 , Chern - Simons - matter theories 10 , and more recently suggested extended 11 - 13 . They play an important role in condensed matter science 14 , string theory 15 , and cosmology 16 .Despite being largely simple they demonstrate rich behaviour ; for example they support excitations with fractional data 17 and provide examples of parity - violating stages 18 . Furthermore there exist interesting connections . . .",
        "rewrite_text": "**Title:** Gauge Invariant Factorization and Canonical Quantization of Topologically Massive Gauge Theories in Any Dimension\n\n**Abstract:** In this article, we explore the canonical quantization of topologically massive gauge fields across all dimensions, with a particular focus on non-abelian gauge fields coupled to fermionic matter. Our findings reveal that these models can be effectively analyzed using gauge-invariant factorization techniques, which have previously been employed in the study of similar systems. We demonstrate the equivalence between these approaches, allowing us to derive exact results for correlation functions at finite temperatures through functional methods. This formalism proves to be advantageous not only for the specific models discussed but also for a broader class of particle field theories that include massless components and associated topological terms. Consequently, it holds promise as a versatile tool for probing strongly interacting systems where traditional perturbative methods may fall short.\n\nThe investigation of quantum field theory has yielded significant insights into fundamental physics over recent decades. However, the inherent nonperturbative nature of interactions among elementary particles often complicates exact solutions, even for seemingly straightforward problems. One effective strategy for addressing these challenges is to leverage the symmetries present in specific model classes. For instance, supersymmetry (SUSY) imposes stringent constraints on particle interactions, facilitating considerable simplifications under various physical scenarios. Another fruitful approach capitalizes on the existence of additional global or local symmetries in certain quantum field theories, enabling their representation through more manageable gauge-invariant factorization frameworks.\n\nIn this study, we define a category of quantum field theories characterized by Lagrangians that incorporate both a fundamental kinetic term and a topological contribution resulting from self-interactions of the gauge field. This encompasses a range of theories, including Yang-Mills-Higgs models, Chern-Simons-matter theories, and more recently proposed extensions. These frameworks are pivotal in fields such as condensed matter physics, string theory, and cosmology. Despite their relative simplicity, these theories exhibit complex behaviors, including the support of fractional excitations and instances of parity violation. Moreover, they reveal intriguing connections that warrant further exploration.",
        "ori-fast-z-score": -1.5609177071190494,
        "water-fast-z-score": 7.06129438934808,
        "rewrite-fast-z-score": -1.3887301496588271
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Out-of-equilibrium relaxation of the Edwards-Wilkinson elastic line .\nAbstract:\nWe study numerically and analytically the dynamics of an elastic interface in two dimensions driven by thermal fluctuations, starting far away from equilibrium. We find that the system relaxes to its steady state via coarsening with power law growth of characteristic length scales. The exponents are determined both for the case where the initial condition is random noise as well as for the case when it has a regular pattern. In particular we show how the exponent depends on the strength of disorder present in the initial conditions. This work was supported by NSF grant DMR-0704520 (M.S.) and by DFG grant SFB-TR6 (A.K.). \nI. INTRODUCTORY REMARkS\n\nThe motion of interfaces between different phases or states plays an important role in many physical systems ranging from crystal growth  1  , fluid flow  2  , magnetic domain wall motion  3  , fracture  4  , wetting  5  , etc.. A common feature shared by all these phenomena is that they involve some kind of competition between surface tension which tries to smooth out any roughness at the interface and other driving forces such as gravity  6  , electric field  7  , chemical potential  8  , etc., which tend to make the interface roughen. It turns out that this competition leads to interesting nonequilibrium behavior  9  . For example, if one starts with flat surfaces then the presence of quenched disorder can lead to the formation of fractal structures  10  .\nIn recent years there have been several studies  11  -  16  devoted to understanding the statistical properties of growing interfaces near their critical dimension d c = 2  17  . These investigations were motivated primarily by experiments  18  -  20  performed on various types of thin films grown under controlled experimental conditions  21  . One of the main goals of these studies is to understand whether the scaling laws observed experimentally  22  -  24  are universal  25  or depend crucially on microscopic details  26  . Another motivation comes from theoretical interest in studying the interplay between nonlinearity and disorder  27  -  29  . Finally, another reason for investigating the problem theoretically is due to possible applications  30  -  32  in data storage devices  33  and optical",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Out - of - equilibrium relaxation of the Edwards - Wilkinson elastic line . Abstract : We explore numerically and analytically the dynamics of an elastic interface in two dimensions accelerated by temperature fluctuations , beginning far back from equilibrium .We see that the system relaxes to its steady state via coarsening with power law increase of typical duration scales . The exponents are decided both for the case where the initial condition is random noise as well as for the case when it has a regular rhythm .In particular we find how the exponent differs on the strength of disorder present in the early conditions . This research was supported by NSF grant DMR - 0704520 ( M . S . )and by DFG grant SFB - TR6 ( A . K . ) . I .INTRODUCTORY REMARkS The movement of interfaces between various phases or states takes an important role in different mechanical models ranging from crystal growth 1 , fluid circulation 2 , magnetic domain wall motion 3 , fracture 4 , wetting 5 , etc . . A common characteristic shared by all these phenomena is that they involve some kind of contest between surface friction which tries to rough out any roughness at the interface and other driving forces such as gravity 6 , electric field 7 , chemical current 8 , etc . , which prefer to make the interface roughen . It turns out that this competition leads to unusual nonequilibrium behavior 9 .For instance , if one starts with flat surfaces then the presence of quenched instability can lead to the formation of fractal structures 10 . In recent years there have been numerous research 11 - 16 devoted to study the statistical characteristics of growing interfaces near their critical parameter d c = 2 17 .These studies were driven mainly by research 18 - 20 performed on various types of thin films developed under controlled experimental environments 21 . One of the main goals of these research is to examine whether the scaling laws detected experimentally 22 - 24 are fundamental 25 or rely crucially on microscopic information 26 .Another motivation arises from theoretical interest in examining the interplay between nonlinearity and disorder 27 - 29 . Finally , another reason for investigating the issue theoretically is due to possible users 30 - 32 in data storage devices 33 and optical",
        "rewrite_text": "**Title:** Out-of-Equilibrium Relaxation of the Edwards-Wilkinson Elastic Line\n\n**Abstract:** This study investigates the dynamics of an elastic interface in two dimensions, influenced by temperature fluctuations and initiated from a state far from equilibrium. Through both numerical simulations and analytical methods, we observe that the system transitions to a steady state characterized by coarsening, which is marked by a power-law increase in typical duration scales. We determine the exponents governing this behavior for two distinct initial conditions: one where the initial state is represented by random noise and another where it exhibits a regular rhythmic pattern. Notably, our findings reveal that the exponent values are significantly affected by the strength of disorder present in the initial conditions. \n\nThe movement of interfaces between different phases is crucial in various mechanical models, including crystal growth, fluid dynamics, magnetic domain wall motion, fracture mechanics, and wetting phenomena. A common feature across these processes is the competition between surface friction, which tends to smooth out roughness at the interface, and external driving forces—such as gravity, electric fields, and chemical currents—that promote roughening. This interplay often results in unique nonequilibrium behaviors. For example, starting with flat surfaces can lead to the emergence of fractal structures due to quenched instabilities. \n\nRecent research has focused on the statistical properties of growing interfaces near the critical dimension (d_c = 2), motivated by experimental studies on various thin films developed under controlled conditions. A primary objective of this body of work is to ascertain whether the scaling laws observed experimentally are intrinsic to the systems or heavily dependent on microscopic details. Additionally, there is a theoretical interest in exploring the relationship between nonlinearity and disorder. The implications of this research extend to practical applications, particularly in the fields of data storage and optical devices, where understanding interface dynamics is essential. This research was supported by NSF grant DMR-0704520 (M.S.) and DFG grant SFB-TR6 (A.K.).",
        "ori-fast-z-score": -0.6285393610547089,
        "water-fast-z-score": 7.440974274885595,
        "rewrite-fast-z-score": 1.272891654681168
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Observational Techniques for Detecting Planets in Binary Systems .\nAbstract:\nThe detection and characterization of planets orbiting stars other than the Sun is one of the most exciting areas of modern astronomy, with important implications for our understanding of planet formation and evolution.  The majority of known exoplanet systems are found around single main-sequence (MS) stars; however, it has been suggested that many more planets may be present in binary star systems.   In this review we discuss observational techniques used to detect planets in binaries, including radial velocity measurements, transit photometry, direct imaging, astrometric wobble, microlensing, pulsar timing, and gravitational wave observations. We also briefly describe some of the challenges associated with detecting planets in these systems. Finally, we summarize current results on planetary companions to MS+MS, MS+WD, WD+MS, and WD+WD binaries. Keywords: Planetary systems; Binaries; Exoplanets; Direct imaging; Astrometry",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Observational Techniques for Detecting Planets in Binary Systems . Abstract : The observation and identification of planets orbiting planets other than the Sun is one of the most exciting areas of modern astronomy , with important implications for our understanding of planet development and evolution .The majority of known exoplanet systems are found around single major - sequence ( MS ) stars ; however , it has been proposed that several more planets might be found in binary star systems . In this review we explain observational techniques employed to identify planets in binaries , including radial speed measurements , transit photometry , direct scanning , astrometric wobble , microlensing , pulsar timing , and gravity wave surveys .We additionally momentarily describe some of the challenges associated with detecting planets in these systems . Finally , we summarize current data on planetary companions to MS + MS , MS + WD , WD + MS , and WD + WD binaries .Keywords: Planetary systems; Binaries; Exoplanets; Direct imaging; Astrometry",
        "rewrite_text": "**Title:** Observational Techniques for Detecting Planets in Binary Systems\n\n**Abstract:** The quest to discover and characterize planets beyond our solar system is a thrilling frontier in contemporary astronomy, offering profound insights into the processes of planetary formation and evolution. While the majority of known exoplanets are located in systems with single main-sequence (MS) stars, there is a growing interest in the potential for discovering additional planets within binary star systems. This review article delves into the various observational methodologies utilized to detect planets in binary configurations. We discuss techniques such as radial velocity measurements, which track the gravitational influence of orbiting planets on their host stars; transit photometry, which observes the dimming of starlight as a planet passes in front of its star; and direct imaging, which captures the light from planets themselves. Other methods explored include astrometric wobble, which detects shifts in a star's position due to the gravitational pull of an orbiting planet; gravitational microlensing, which exploits the bending of light from distant stars; pulsar timing, which uses the precise timing of pulsar signals to infer the presence of planets; and gravitational wave surveys, which may reveal the presence of massive planets in binary systems. The article also addresses the unique challenges faced in detecting planets within these complex environments, such as the interference from the binary stars themselves and the need for advanced observational technologies. In conclusion, we provide an overview of the current findings related to planetary companions in various binary configurations, including MS + MS, MS + white dwarf (WD), WD + MS, and WD + WD systems. This synthesis of knowledge not only enhances our understanding of planetary systems but also opens new avenues for future research in exoplanetary science. \n\n**Keywords:** Planetary systems; Binaries; Exoplanets; Direct imaging; Astrometry",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 4.541868715470696,
        "rewrite-fast-z-score": -1.781196752327939
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Kalman--Yakubovich--Popov inequality for passive discrete time-invariant systems .\nAbstract:\nThe main result is the following theorem. \nTHEOREM 1 Let  be an arbitrary real number and let  be any positive integer.  Then, there exists a constant , depending only on , , such that \nfor all matrices . The proof of this theorem will be given in Section 2 below. In particular, if we take  then (1) becomes \nwhich was proved by Yakubovich  J. Math. Anal. Appl., vol. 16, pp. 719-726, (1964) . If we choose  then (1) reduces to \nwhich was established by Popov  Publ. Math. Inst. Steklov, vol. A, no. 3, p. 225-230, (1963)  . We remark here that our results are not new but they can be obtained as corollaries of these two papers. However, it seems worthwhile to give proofs which do not depend upon those earlier works.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Kalman - - Yakubovich - - Popov inequality for passive finite period - invariant networks . Abstract : The main consequence is the following theorem .THEOREM 1 Let be an arbitrary real number and take be any positive integer . Then , there exists a constant , depending only on , , such that for all matrices .The confirmation of this theorem will be provided in Section 2 below . In particular , if we took then ( 1 ) becomes which was demonstrated by Yakubovich J .Math.Anal.Appl . , vol . 16 , pp .719-726, (1964) .If we choose  then (1) reduces to \nwhich was established by Popov  Publ.Math.Inst.Steklov, vol.A, no.3 , p . 225 - 230 , ( 1963 ) . We comment here that our findings are not current but they can be obtained as corollaries of these two papers .However , it appears worthwhile to give proofs which do not depend upon those earlier works .",
        "rewrite_text": "Title: The Kalman-Yakubovich-Popov Inequality for Passive Finite Period-Invariant Networks\n\nAbstract: This article presents a significant theorem regarding the Kalman-Yakubovich-Popov inequality as it applies to passive finite period-invariant networks. The theorem states that for any arbitrary real number and any positive integer, there exists a constant that is solely dependent on these parameters, which holds true for all matrices involved. The detailed proof of this theorem will be elaborated in Section 2 of the paper. Notably, when the specific case is considered, the theorem simplifies to a form that was previously established by Yakubovich in his work published in the Journal of Mathematical Analysis and Applications in 1964. Similarly, when another particular case is chosen, the theorem further reduces to a result that was derived by Popov in 1963, as documented in the Publications of the Steklov Mathematical Institute. While the results presented in this paper are not novel in the sense that they can be viewed as corollaries of the aforementioned studies, we believe it is valuable to provide independent proofs that do not rely on these earlier contributions. This approach not only reinforces the validity of the theorem but also enhances the understanding of the underlying principles governing the Kalman-Yakubovich-Popov inequality in the context of passive systems. The implications of this work extend to various applications in control theory and network analysis, where the stability and performance of systems are of paramount importance. Through this exploration, we aim to contribute to the existing body of knowledge and offer fresh insights into the dynamics of finite period-invariant networks.",
        "ori-fast-z-score": -1.1094003924504583,
        "water-fast-z-score": 3.159292970819848,
        "rewrite-fast-z-score": -0.09853292781642932
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Efficient method for detection of periodic orbits in chaotic maps and flows .\nAbstract:\nWe present an efficient numerical scheme to detect the existence of periodic orbits in chaotically behaving dynamical systems, such as chaotic maps or chaotic flows. The proposed algorithm is based on the concept of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor. We show that our approach can be used to efficiently compute the topological entropy of chaotic maps with non-integer slopes. Finally we demonstrate how this new technique can be applied to study the dynamics of a model system describing the interaction between two coupled semiconductor lasers. Periodic orbits play an important role in understanding the behavior of many nonlinear dynamical systems. In particular they provide valuable information about the underlying structure of the attractors associated with these systems. However, it has been shown that finding all periodic orbits of a given periodicity may not always be possible due to their complicated nature  1  . This problem becomes even more challenging when dealing with chaotic systems where the number of periodic orbits increases exponentially with increasing period  2  .\nIn recent years there have been several attempts to develop techniques to find periodic orbits numerically  3, 4, 5, 6, 7, 8  , but most of them suffer from one or both of the following drawbacks: (i) They require very high computational resources. (ii) They do not guarantee convergence towards the desired orbit. Here we propose a novel numerical scheme to overcome these difficulties by using the concept of shadowing  9  . Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor. It was first introduced by Anosov  10  who showed that every trajectory starting sufficiently close to any unstable periodic orbit will remain close to it for at least a certain amount of time. Since then various authors  11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Efficient method for recognition of periodic orbits in chaotic maps and flows . Abstract : We present an efficient numerical system to identify the existence of periodic orbits in chaotically behaving dynamical systems , such as chaotic maps or turbulent flows .The proposed algorithm is based on the idea of shadowing trajectories which are close approximations of unstable periodic orbits embedded within the attractor . We see that our approach can be used to easily compute the topological entropy of turbulent maps with non - integer peaks .Finally we prove how this new technique can be applied to study the dynamics of a model network describing the interaction between two coupled semiconductor lasers . Periodic orbits hold an important role in understanding the dynamics of several nonlinear dynamical systems .In particular they give valuable info about the fundamental structure of the attractors found with these systems . However , it has been shown that finding all periodic orbits of a given periodicity might not always be possible due to their complicated nature 1 .This problem remains especially more challenging when dealing with turbulent systems where the number of periodic orbits changes exponentially with expanding period 2 . In past decades there have been numerous attempts to develop techniques to find periodic orbits numerically 3 , 4 , 5 , 6 , 7 , 8 , but most of them suffer from one or both of the following drawbacks : ( i ) They require very high computational resources .( ii ) They do not secure convergence towards the desired orbit . Here we develop a new numerical plan to overcome these problems by using the idea of shadowing 9 .Shadowing refers to the property of some trajectories being close approximations of unstable orbits embedded inside the attractor . It was first developed by Anosov 10 who demonstrated that every orbital beginning sufficiently close to any unstable periodic orbit will remain close to it for at least a certain quantity of time .Since then various authors 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44",
        "rewrite_text": "Title: Efficient Method for Recognizing Periodic Orbits in Chaotic Maps and Flows\n\nAbstract: In this study, we introduce a novel numerical approach designed to efficiently identify periodic orbits within chaotic dynamical systems, including chaotic maps and turbulent flows. Our algorithm leverages the concept of shadowing trajectories, which serve as close approximations to unstable periodic orbits situated within the system's attractor. This method not only facilitates the computation of topological entropy for turbulent maps exhibiting non-integer peaks but also demonstrates its applicability in analyzing the dynamics of a model network that simulates the interactions between two coupled semiconductor lasers. \n\nPeriodic orbits are crucial for understanding the dynamics of various nonlinear systems, as they provide significant insights into the fundamental structure of the attractors associated with these systems. However, the task of identifying all periodic orbits of a specific periodicity can be exceedingly complex, particularly in turbulent environments where the number of periodic orbits can increase exponentially with period length. Over the past few decades, numerous numerical techniques have been proposed to locate periodic orbits; however, many of these methods face significant limitations, such as requiring extensive computational resources or failing to ensure convergence to the target orbit.\n\nTo address these challenges, we present a new numerical framework that utilizes the principle of shadowing. This principle, initially introduced by Anosov, posits that trajectories starting sufficiently close to an unstable periodic orbit will remain near it for a defined duration. Building upon this foundation, our approach enhances the reliability and efficiency of periodic orbit detection in chaotic systems. By demonstrating the effectiveness of our method, we contribute to the ongoing efforts to better understand the intricate dynamics of chaotic systems and their underlying structures.",
        "ori-fast-z-score": -0.9797958971132713,
        "water-fast-z-score": 6.1034134407836955,
        "rewrite-fast-z-score": -0.6859943405700353
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spitzer observations of a 24 micron shadow: Bok Globule CB190 .\nAbstract:\nWe report the detection of an infrared dark cloud (IRDC) in the vicinity of the open cluster NGC 6334, using data obtained with Spitzer Space Telescope s Infrared Array Camera (IRAC). The IRDC is associated with the molecular cloud complex G327.3+0.6 and has been identified as Bok globule CB190 by Clemens & Barvainis (1988) . We find that this object exhibits a prominent 24 micron shadow which may be caused by absorption against bright mid-infrared emission from nearby protostars or young stellar objects. This feature suggests that the cloud contains dense cores at different evolutionary stages. Using near-infrared extinction mapping we identify two candidate starless cores within the cloud. These are located near the center of the cloud where the 24 micron shadow is most pronounced. Our analysis shows that these cores have masses between 0.5 Msun to 1 Msun and radii ranging from 1000 AU to 3000 AU .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spitzer observations of a 24 micron shadow : Bok Globule CB190 . Abstract : We report the observation of an infrared dark cloud ( IRDC ) in the vicinity of the open cluster NGC 6334 , using data acquired with Spitzer Space Telescope s Infrared Array Camera ( IRAC ) .The IRDC is associated with the molecular dust complex G327 . 3 + 0 . 6 and has been described as Bok globule CB190 by Clemens & Barvainis ( 1988 ) . We see that this body features a distinct 24 micron shadow which may be caused by absorption against bright mid - infrared absorption from nearby protostars or young stellar bodies .This characteristic demonstrates that the cloud contains thick cores at different evolutionary stages . Using near - infrared extinction mapping we identify two proposed starless cores within the cloud .These are situated near the center of the cloud where the 24 micron shadow is most pronounced . Our study shows that these cores have masses between 0 . 5 Msun to 1 Msun and radii ranging from 1000 AU to 3000 AU .",
        "rewrite_text": "We present our findings from the Spitzer Space Telescope's Infrared Array Camera (IRAC) regarding an infrared dark cloud (IRDC) located near the open cluster NGC 6334. This IRDC, identified as Bok globule CB190 by Clemens & Barvainis (1988), is associated with the molecular dust complex G327.3 + 0.6. Notably, our observations reveal a prominent 24-micron shadow within the cloud, likely resulting from absorption effects against the bright mid-infrared emissions from nearby protostars or young stellar objects. This shadowing effect indicates the presence of dense cores within the cloud, each at varying stages of evolution. \n\nThrough near-infrared extinction mapping, we have pinpointed two candidate starless cores located at the cloud's center, where the 24-micron shadow is most evident. Our analysis suggests that these cores possess masses ranging from 0.5 to 1 solar mass (Msun) and exhibit radii between 1000 AU and 3000 AU. This research enhances our understanding of the structure and composition of Bok globule CB190 and contributes to the broader knowledge of star formation processes within IRDCs. The implications of these findings are significant, as they provide insights into the conditions that foster star formation in dense molecular environments. Overall, our study underscores the importance of utilizing infrared observations to investigate the intricate dynamics of star-forming regions and the evolutionary pathways of stellar cores.",
        "ori-fast-z-score": 0.75,
        "water-fast-z-score": 4.83735464897913,
        "rewrite-fast-z-score": 0.9434563530497265
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the Connection between Mass Loss and Evolution of C-rich AGB stars .\nAbstract:\nWe present new results on mass loss in carbon rich asymptotic giant branch (AGB) stars based on infrared photometry obtained with ISO-SWS, IRAS, MSX and Spitzer-IRS. We find that there is no correlation between the total luminosity or effective temperature of these objects and their mass-loss rates. The observed scatter may be explained by differences in chemical composition and/or pulsation properties among individual sources. In addition to this we show that the dust-to-gas ratio decreases towards higher temperatures for oxygen-rich as well as carbon-rich AGB stars. This indicates that the physical conditions at which dust forms are different in both types of evolved stars. Finally, we discuss how our findings can be used to improve current models describing the evolution of red giants. Keywords: Asymptotic Giant Branch Stars; Dust formation; Red Giants; Mass loss. 1 Introduction Carbon-rich asymptotic giant branch (AGB; hereafter Crich AGB) stars have been studied extensively over the past decades because they represent an important source class of interstellar matter. They lose large amounts of material through stellar winds driven by radiation pressure on dust grains formed in the outflowing gas. These winds play an essential role in shaping circumstellar envelopes around evolved stars and thus influence the appearance of planetary nebulae and proto-stellar disks surrounding young stellar objects. However, despite numerous observational studies it remains unclear what determines the amount of mass lost by Crich AGB stars. It has been suggested that the total luminosity L * , the effective temperature T eff , the surface gravity g, the metallicity Z, the pulsation period P, and the initial mass M ini might all affectṀ . For example, Wood et al. (1992) , van Loon et al. (1999), Olofsson et al. (2002a) , Knapp & Morris (1985) , and Winters et al. (1994) found evidence thatṀ increases with decreasing T eff .\nIn contrast, Groenewegen et al. (1998 ), De Beck et al. (2010 , and Ramstedt et al",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the Connection between Mass Loss and Evolution of C - rich AGB stars . Abstract : We report new data on mass loss in carbon rich asymptotic giant line ( AGB ) stars based on infrared photometry obtained with ISO - SWS , IRAS , MSX and Spitzer - IRS .We see that there is no coupling between the total luminosity or effective heat of these objects and their mass - loss rates . The observed scatter could be explained by differences in material composition and / or pulsation properties among different sources .In addition to this we find that the dust - to - gas ratio tends towards higher temperatures for oxygen - rich as well as carbon - rich AGB stars . This implies that the physical conditions at which dust occurs are changed in both types of evolved stars .Finally , we explain how our findings can be used to improve current theories describing the evolution of red giants . Keywords : Asymptotic Giant Branch Stars ; Dust formation ; Red Giants ; Mass loss .1 Introduction Carbon - rich asymptotic giant line ( AGB ; hereafter Crich AGB ) stars have been studied significantly over the previous decades because they represent an important source type of interstellar matter . They lose significant amounts of material through stellar winds driven by radiation stress on dust grains created in the outflowing gas .These winds play an essential part in shaping circumstellar envelopes around evolved stars and therefore influence the appearance of planetary nebulae and proto - stellar disks surrounding young stellar bodies . However , despite several observational analyses it remains unsure what determines the quantity of mass losing by Crich AGB stars .It has been suggested that the total luminosity L * , the effective temperature T eff , the surface gravity g , the metallicity Z , the pulsation period P , and the initial mass M ini might all [UNK] . For example , Wood et al .( 1992 ) , van Loon et al . ( 1999 ) , Olofsson et al .( 2002a ) , Knapp & Morris ( 1985 ) , and Winters et al . ( 1994 ) found evidence [UNK] increases with decreasing T eff .In comparison , Groenewegen et al . ( 1998 ) , De Beck et al .(2010 , and Ramstedt et al",
        "rewrite_text": "**Title:** On the Connection between Mass Loss and Evolution of Carbon-Rich AGB Stars\n\n**Abstract:** In this study, we present new findings regarding mass loss in carbon-rich asymptotic giant branch (AGB) stars, utilizing infrared photometry data collected from ISO-SWS, IRAS, MSX, and Spitzer-IRS. Our analysis reveals a lack of correlation between the total luminosity or effective temperature of these stars and their mass-loss rates. The variability observed in mass-loss rates may be attributed to differences in material composition and pulsation characteristics among the various sources examined. Furthermore, we observe that the dust-to-gas ratio increases with temperature for both oxygen-rich and carbon-rich AGB stars, suggesting that the physical conditions conducive to dust formation are altered in these evolved stellar types. These findings have significant implications for enhancing our understanding of the evolutionary processes of red giants. \n\nCarbon-rich AGB stars are crucial contributors to the interstellar medium, as they expel substantial amounts of material through stellar winds, which are driven by radiation pressure on dust grains formed in the outflowing gas. These winds are instrumental in shaping the circumstellar envelopes of evolved stars, thereby affecting the morphology of planetary nebulae and the formation of proto-stellar disks around nascent stars. Despite extensive observational studies, the precise mechanisms governing mass loss in carbon-rich AGB stars remain unclear. Previous research has suggested that various factors, including total luminosity (L*), effective temperature (T_eff), surface gravity (g), metallicity (Z), pulsation period (P), and initial mass (M_ini), may influence mass loss rates. Notably, studies by Wood et al. (1992), van Loon et al. (1999), and Olofsson et al. (2002a) have indicated a trend where mass loss increases with decreasing effective temperature. In contrast, other researchers, such as Groenewegen et al. (1998) and De Beck et al. (2010), have provided differing insights into these relationships. Our research aims to reconcile these findings and contribute to the broader understanding of mass loss mechanisms in carbon-rich AGB stars. \n\n**Keywords:** Asymptotic Giant Branch Stars; Dust Formation; Red Giants; Mass Loss.",
        "ori-fast-z-score": -1.2893167424406085,
        "water-fast-z-score": 4.643716460347527,
        "rewrite-fast-z-score": -0.4685212856658182
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Unplugging the Universe: the neglected electromagnetic consequence of decoupling .\nAbstract:\nWe show that, in addition to gravitational waves and neutrinos, there is an additional source of energy loss during the final stages of stellar evolution which has been largely ignored by previous authors. This arises because the universe becomes transparent to photons at redshifts z ~ 1100 (the time when matter-radiation equality occurs), allowing them to stream freely outwards into space. The resulting decrease in pressure causes the universe to expand faster than it would otherwise do, thereby accelerating its expansion rate. We estimate this effect for different types of stars and find that it can be significant - up to 10% of the total luminosity output of massive stars may be lost due to this process. In particular we predict that Type Ia supernovae should exhibit systematically lower peak luminosities compared with their observed values if they are not corrected for this effect. Finally, we discuss how our results could be tested observationally using current data on distant supernovae.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Unplugging the Universe : the overlooked electromagnetic consequence of decoupling . Abstract : We suggest that , in addition to gravitational waves and neutrinos , there is an additional source of power loss during the last phases of stellar evolution which has been mostly overlooked by earlier authors .This arises because the universe makes transparent to photons at redshifts z ~ 1100 ( the period when matter - radiation equality happens ) , allowing them to leak independently outwards into space . The resulting decrease in pressure creates the universe to expand faster than it would normally do , thereby accelerating its expansion speed .We estimate this effect for different kinds of stars and find that it can be considerable - up to 10 % of the total luminosity production of large stars must be lost due to this process . In particular we expect that Type Ia supernovae should exhibit systematically lower peak luminosities compared with their observed values if they are not corrected for this effect .Finally , we talk how our findings may be evaluated observationally using current data on remote supernovae .",
        "rewrite_text": "Title: Unplugging the Universe: The Overlooked Electromagnetic Consequence of Decoupling\n\nAbstract: In this article, we propose a novel perspective on energy loss during the final stages of stellar evolution, highlighting an often-neglected electromagnetic phenomenon. While previous studies have primarily focused on gravitational waves and neutrinos as key contributors to power loss, we argue that the transparency of the universe to photons at redshifts around z ~ 1100—coinciding with the epoch of matter-radiation equality—plays a significant role. This transparency allows photons to escape freely into space, leading to a reduction in pressure that accelerates the expansion of the universe beyond its expected rate. Our calculations indicate that this effect can be substantial, with up to 10% of the total luminosity generated by massive stars potentially lost due to this mechanism. This finding has critical implications for the observed characteristics of Type Ia supernovae, which may display systematically lower peak luminosities if this effect is not accounted for. We discuss the observational consequences of our results and propose methods for evaluating this phenomenon using existing data on distant supernovae. Our work invites a re-examination of stellar evolution models and the interpretation of supernova luminosities, suggesting that the electromagnetic consequences of decoupling warrant further investigation in the context of cosmic expansion and energy dynamics.",
        "ori-fast-z-score": -0.43133109281375365,
        "water-fast-z-score": 5.116817192534651,
        "rewrite-fast-z-score": 1.2
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Determination of Low-Energy Parameters of Neutron--Proton Scattering on the Basis of Modern Experimental Data from Partial-Wave Analyses .\nAbstract:\nThe low-energy parameters of neutron-proton scattering are determined by using modern experimental data obtained in partial-wave analyses (PWAs). The results for the S-wave phase shifts and mixing angles, as well as for the P-wave amplitudes at zero energy, are presented here. It is shown that these values agree with those extracted previously from other experiments within their uncertainties. In addition to this, we present new results for the D-wave amplitude at zero energy which were not available before. \nI. INTRODUCTIO N\nNeutron-proton elastic scattering has been studied extensively over many decades  1  . This process plays an important role in nuclear physics since it provides information about the nucleon-nucleon interaction potential  2  , which can be used to calculate properties of nuclei  3  .\nIn recent years there have been significant advances in our understanding of the structure of the nucleon-nucleus system  4  . These developments include precise measurements of cross sections  5  , polarization observables  6  , spin-correlation coefficients  7  , etc., performed mainly at intermediate energies  8  . However, despite all efforts made so far, some questions remain open  9  . For example, one still needs more accurate determinations of the lowenergy parameters of the nucleonnucleon interaction  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Determination of Low - Energy Parameters of Neutron - - Proton Scattering on the Basis of Modern Experimental Data from Partial - Wave Analyses . Abstract : The lowest - energy parameters of neutron - proton scattering are decided by using contemporary experimental evidence derived in partial - wave assessments ( PWAs ) .The results for the S - wave phase variations and mixing angles , as well as for the P - wave amplitudes at zero energy , are presented here . It is demonstrated that these estimates agree with those retrieved previously from other experiments within their uncertainties .In addition to this , we present new data for the D - wave amplitude at zero energy which were not accessible before . I . INTRODUCTIO N Neutron - proton elastic scattering has been studied thoroughly over numerous years 1 .This process holds an important role in nuclear science since it gives information about the nucleon - nucleon correlation potential 2 , which can be used to estimate features of nuclei 3 . In recent years there have been significant advances in our knowing of the formation of the nucleon - nucleus system 4 .These advances require precise observations of cross sections 5 , polarization observables 6 , spin - correlation functions 7 , etc . , conducted predominantly at intermediate energies 8 . However , despite all efforts made so far , some questions remain open 9 .For instance , one also needs more accurate determinations of the lowenergy variables of the nucleonnucleon interaction 10 .",
        "rewrite_text": "Title: Determination of Low-Energy Parameters of Neutron-Proton Scattering Based on Modern Experimental Data from Partial-Wave Analyses\n\nAbstract: This study focuses on the determination of low-energy parameters associated with neutron-proton scattering, utilizing contemporary experimental data obtained from partial-wave analyses (PWAs). We present findings on the S-wave phase shifts and mixing angles, alongside the P-wave amplitudes at zero energy. Our results indicate a strong agreement with previously reported values from other experimental studies, remaining consistent within their respective uncertainties. Notably, we introduce new measurements for the D-wave amplitude at zero energy, which have not been previously accessible. \n\nThe significance of neutron-proton elastic scattering has been recognized for many years, as it provides critical insights into the nucleon-nucleon interaction potential, which is essential for understanding nuclear structure and dynamics. Recent advancements in our comprehension of the nucleon-nucleus system have underscored the necessity for precise measurements of various observables, including cross sections, polarization observables, and spin-correlation functions, particularly at intermediate energies. Despite the progress made, several questions regarding the low-energy parameters of nucleon-nucleon interactions remain unresolved. This study aims to address these gaps by offering refined estimates of the low-energy parameters, thereby enhancing our understanding of the fundamental forces at play in nuclear interactions. The findings presented here not only contribute to the existing body of knowledge but also pave the way for future research in the field of nuclear physics.",
        "ori-fast-z-score": -0.502518907629606,
        "water-fast-z-score": 6.6,
        "rewrite-fast-z-score": 0.6363636363636364
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  High Galactic Latitude Interstellar Neutral Hydrogen Structure and Associated (WMAP) High Frequency Continuum Emission .\nAbstract:\nWe present new high resolution observations of the interstellar medium in the direction of the North Ecliptic Pole, made with the Westerbork Synthesis Radio Telescope at 1.4 GHz. The data reveal an extended filamentary structure that is traced by neutral hydrogen emission lines as well as continuum emission associated with free-free processes. We find evidence for two distinct components to this filamentary structure; one component has a relatively low column density but extends over several degrees on the sky while another component appears more compact and denser. These results are discussed within the context of recent WMAP measurements which show excess microwave emission towards the north ecliptic pole region. This work was supported by NASA grant NAG5-10842. Keywords: ISM, radio astronomy, H I 21 cm line, WMAP, filaments, North Ecliptic Pole Region . \nIntroduction\n\nThe Wilkinson Microwave Anisotropy Probe (WMAP) (Bennett et al., 2003a ) measured significant excesses of microwave emission above the expected cosmic background radiation level along three different lines-of-sight through the northern hemisphere. In particular, there were large excesses observed near the North Ecliptic Poles (NEPs). Subsequent studies have shown that these excesses can be explained by thermal bremsstrahlung emission from ionized gas located between us and distant galaxies (Finkbeiner 2004 , Davies et al 2005 .\nIn addition to the NEP regions, other areas of interest include the Perseus-Pisces supercluster complex (Davies et al 2006) , the Coma cluster (Vogeley & Birkinshaw 1996) and the Virgo Cluster (Taylor et al 2002) . All of these structures contain substantial amounts of hot plasma and it seems likely that they will also contribute significantly to the total foreground signal detected by WMAP. \nObservations of the diffuse galactic radio emission provide important information about the physical conditions in the interstellar medium (ISM), such as temperature, pressure and magnetic field strength. However, due to its faintness relative to point sources, only recently have we",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : High Galactic Latitude Interstellar Neutral Hydrogen Structure and Associated ( WMAP ) High Frequency Continuum Emission . Abstract : We report new high resolution measurements of the interstellar medium in the direction of the North Ecliptic Pole , made with the Westerbork Synthesis Radio Telescope at 1 . 4 GHz .The data reveal an extended filamentary composition that is traced by neutral hydrogen emission lines as well as continuum emission associated with free - free processes . We see evidence for two different components to this filamentary composition ; one element has a fairly lowest column density but spreads over numerous degrees on the sky while another component appears more compact and denser .These data are discussed within the context of recent WMAP measurements which show extra microwave emission towards the north ecliptic pole region . This effort was supported by NASA grant NAG5 - 10842 .Keywords : ISM , television astronomy , H I 21 cm line , WMAP , filaments , North Ecliptic Pole Region . Introduction The Wilkinson Microwave Anisotropy Probe ( WMAP ) ( Bennett et al . , 2003a ) measured significant excesses of microwave emission above the expected cosmic background radiation level along three different lines - of - view through the northern hemisphere .In particular , there were large excesses observed near the North Ecliptic Poles ( NEPs ) . Subsequent researchers have shown that these excesses can be described by thermal bremsstrahlung emission from ionized gas located between us and distant galaxies ( Finkbeiner 2004 , Davies et al 2005 .In addition to the NEP regions , other areas of focus involve the Perseus - Pisces supercluster complex ( Davies et al 2006 ) , the Coma cluster ( Vogeley & Birkinshaw 1996 ) and the Virgo Cluster ( Taylor et al 2002 ) . All of these structures hold substantial amounts of bright plasma and it appears probable that they will also contribute considerably to the total foreground noise detected by WMAP .Observations of the diffuse galactic radio emission reveal essential information about the physical conditions in the interstellar medium ( ISM ) , such as temperature , pressure and magnetic field intensity . However , owing to its faintness relative to point sources , only lately have we",
        "rewrite_text": "Title: High Galactic Latitude Interstellar Neutral Hydrogen Structure and Associated WMAP High Frequency Continuum Emission\n\nAbstract: In this study, we present new high-resolution observations of the interstellar medium (ISM) directed towards the North Ecliptic Pole, utilizing the Westerbork Synthesis Radio Telescope at a frequency of 1.4 GHz. Our findings reveal a complex filamentary structure characterized by neutral hydrogen emission lines, alongside continuum emissions linked to free-free processes. Notably, we identify two distinct components within this filamentary structure: one exhibits a relatively low column density but extends over several degrees across the sky, while the other component is more compact and denser. These observations are contextualized with recent data from the Wilkinson Microwave Anisotropy Probe (WMAP), which has detected additional microwave emissions in the vicinity of the North Ecliptic Pole. This research was supported by NASA grant NAG5-10842. \n\nKeywords: Interstellar Medium (ISM), radio astronomy, H I 21 cm line, WMAP, filaments, North Ecliptic Pole Region.\n\nIntroduction: The Wilkinson Microwave Anisotropy Probe (WMAP) has identified significant excesses in microwave emissions that exceed the anticipated levels of cosmic background radiation across three distinct lines of sight in the northern hemisphere. Particularly pronounced excesses have been noted near the North Ecliptic Poles (NEPs). Subsequent analyses suggest that these excess emissions can be attributed to thermal bremsstrahlung from ionized gas situated between Earth and distant galaxies. In addition to the NEP regions, other areas of interest include the Perseus-Pisces supercluster complex, the Coma cluster, and the Virgo Cluster, all of which contain substantial amounts of luminous plasma likely contributing to the foreground noise detected by WMAP. Observations of diffuse galactic radio emissions provide critical insights into the physical conditions within the ISM, including temperature, pressure, and magnetic field strength. However, due to their faintness compared to point sources, comprehensive studies of these emissions have only recently gained traction.",
        "ori-fast-z-score": 1.2632278815997784,
        "water-fast-z-score": 6.545614594714175,
        "rewrite-fast-z-score": 0.18107149208503706
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Plasma effects in a micromachined floating-gate high-electron-mobility transistor .\nAbstract:\nWe report on the fabrication and characterization of a novel floating gate (FG) HEMT with an AlGaN/GaN/AlN heterostructure grown by metal-organic chemical vapor deposition (MOCVD). The device is fabricated using standard photolithography techniques, followed by dry etching to define mesa structures. A thin layer of SiO2 is deposited as insulation between the source/drain contacts and FG. Electrical measurements show that this structure exhibits good electrical characteristics such as high drain-source current density (JDS), low threshold voltage (Vth), and small subthreshold swing (SS). In addition, we have observed a large negative shift in Vth after plasma treatment for 30 s at room temperature. This indicates that the charge trapping effect can be effectively controlled through plasma treatment. \n \n Keywords: GaN-based transistors; Plasma effects; Floating gate devices; High electron mobility transistors",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Plasma impact in a micromachined floating - gate high - electron - mobility transistor . Abstract : We report on the fabrication and identification of a novel fixed gate ( FG ) HEMT with an AlGaN / GaN / AlN heterostructure made by metal - organic chemical vapor deposition ( MOCVD ) .The system is manufactured using conventional photolithography method , followed by dry etching to define mesa forms . A narrow coating of SiO2 is stored as insulation between the supply / drain contacts and FG .Electrical measurements show that this formation displays good thermal traits such as long drain - source current density ( JDS ) , low threshold voltage ( Vth ) , and tiny subthreshold swing ( SS ) . In addition , we have noted a large negative shift in Vth after plasma treatment for 30 s at room temperature .This implies that the charge trapping phenomenon can be effectively controlled through plasma treatment . Keywords : GaN - based transistors ; Plasma properties ; Floating window devices ; High electron mobility transistors",
        "rewrite_text": "**Title:** Plasma Impact in a Micromachined Floating-Gate High-Electron-Mobility Transistor\n\n**Abstract:** In this study, we present the development and characterization of an innovative fixed gate (FG) high-electron-mobility transistor (HEMT) utilizing an AlGaN/GaN/AlN heterostructure, fabricated through metal-organic chemical vapor deposition (MOCVD). The fabrication process employs standard photolithography techniques, followed by dry etching to create defined mesa structures. A thin layer of SiO2 is applied to serve as insulation between the supply/drain contacts and the fixed gate. Our electrical measurements indicate that this device configuration exhibits favorable thermal characteristics, including a high drain-source current density (JDS), a low threshold voltage (Vth), and a minimal subthreshold swing (SS). Notably, we observed a significant negative shift in the threshold voltage (Vth) following a 30-second plasma treatment conducted at room temperature. This finding suggests that the phenomenon of charge trapping can be effectively manipulated through plasma treatment, offering potential avenues for enhancing device performance. The implications of these results are significant for the advancement of GaN-based transistors, particularly in the context of floating-gate devices and high-electron-mobility transistors. Our research contributes to the understanding of plasma effects on semiconductor devices and opens up new possibilities for optimizing the electrical properties of HEMTs. \n\n**Keywords:** GaN-based transistors; Plasma properties; Floating-gate devices; High electron mobility transistors.",
        "ori-fast-z-score": -0.3375263702778072,
        "water-fast-z-score": 5.444444444444445,
        "rewrite-fast-z-score": 1.3112201362143716
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The multiple viewpoints as approach to information retrieval within collaborative development context .\nAbstract:\nThe main goal of this research is the study and analysis of how different users can contribute in an open source software project, by sharing their knowledge through comments on issues or pull requests (PRs). The authors propose a new method for analyzing user participation based on the number of views that each comment receives during its life cycle. This work also presents a novel technique for identifying relevant comments using text mining techniques applied over the textual content of PRs. Finally, it proposes a ranking algorithm which takes into account both the relevance score assigned to each comment and the number of times they have been viewed. In order to evaluate these proposals, we conducted experiments with data collected from GitHub repositories related to two well-known open-source projects. We found out that our proposed methods are able to identify relevant comments more accurately than other state-of-the-art approaches. Moreover, we observed that the proposed ranking algorithm improves the results obtained when only considering the relevance scores.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The various viewpoints as approach to data retrieval within joint development context . Abstract : The main goal of this research is the examination and assessment of how various users can help in an free source software development , by sharing their understanding through comments on problems or pull requests ( PRs ) .The authors propose a new method for evaluating viewer involvement based on the quantity of views that each comment receives during its life cycle . This project also provides a novel technique for finding relevant remarks utilizing content extraction techniques applied over the textual content of PRs .Finally , it proposes a ranking method which assumes into consideration both the credibility score given to each comment and the quantity of years they have been viewed . In order to analyze these proposals , we conducted experiments with data received from GitHub repositories linked to two good - famous open - source projects .We showed out that our proposed methods are able to identify relevant remarks more accurately than other state - of - the - art methods . Moreover , we concluded that the suggested ranking method improves the results derived when only considering the relevance ratings .",
        "rewrite_text": "**Title:** Diverse Perspectives as a Strategy for Data Retrieval in Joint Development Contexts\n\n**Abstract:** This study investigates the role of diverse user contributions in the development of open-source software, focusing on how individuals can enhance the process by sharing insights through comments on issues and pull requests (PRs). The authors introduce an innovative approach to evaluating user engagement, which is based on the number of views each comment receives throughout its lifecycle. Additionally, this research presents a new technique for identifying pertinent comments by employing content extraction methods on the textual data of PRs. A key component of this study is the proposed ranking system, which integrates both the credibility score assigned to each comment and the total number of views it has garnered. To validate these methodologies, experiments were conducted using data from GitHub repositories associated with two well-known open-source projects. The findings demonstrate that the proposed methods significantly outperform existing state-of-the-art techniques in accurately identifying relevant comments. Furthermore, the results indicate that the introduced ranking system enhances outcomes when compared to traditional methods that rely solely on relevance ratings. This research contributes to the understanding of user engagement in open-source development and offers practical tools for improving data retrieval processes in collaborative environments.",
        "ori-fast-z-score": -1.2686700948330931,
        "water-fast-z-score": 6.799001036500849,
        "rewrite-fast-z-score": 0.2873478855663454
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Signatures of Heavy Z-prime in the Extra U(1) Superstring Inspired Model: RGEs Analysis .\nAbstract:\nIn this work, we study the renormalization group equations (RGEs) for extra U(1) supersymmetric string inspired model with heavy Z  prime and its effects on gauge coupling unification at one-loop level. We find that the inclusion of new particles such as vector-like quarks and leptons can significantly affect the running behavior of gauge couplings. In particular, it is found that the presence of these new particles leads to an enhancement effect on the evolution speed of gauge couplings which may be helpful to solve the gauge hierarchy problem. Furthermore, by using the experimental data of low energy physics, we obtain some constraints on the mass spectrum of extra particles involved in our model. Finally, we also discuss briefly about the possible signatures of heavy Z -prime boson at future colliders. The results are summarized below. \nI. INTRODUCTORY REMARK\nThe Standard Model (SM), based on SU(3) C ×SU(2) L ×U(1) Y gauge symmetry, has been very successful in describing all known phenomena upto TeV scale energies  1  . However, there exist several open questions related to SM like fermion masses and mixing angles  2  , neutrino oscillations  3  etc., which cannot be explained within the framework of SM. To address these issues, many extensions beyond SM have been proposed  4  -  8  .\nAmong them, Grand Unified Theory (GUTs)  9  provides a natural solution to the above mentioned problems  10  . It predicts the existence of superheavy gauge bosons called GUT-scale gauge bosons  11  whose masses lie around 10 16 GeV  12  . These GUT-scale gauge boson interactions lead to non-renormalizable operators  13  which break the SM gauge symmetries  14  . Therefore, they should not appear in any physical process  15  . This implies that their contributions must vanish when summed over all states  16  . Thus, the appearance of these nonrenormalizable operators will spoil the successes of SM  17  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Signatures of Heavy Z - prime in the Extra U ( 1 ) Superstring Inspired Model : RGEs Analysis . Abstract : In this study , we study the renormalization group equations ( RGEs ) for extra U ( 1 ) supersymmetric string inspired theory with heavy Z prime and its consequences on gauge coupling unification at one - loop level .We see that the introduction of new ions such as vector - like quarks and leptons can significantly affect the running response of gauge couplings . In particular , it is found that the presence of these new objects gives to an enhancement impact on the evolution speed of gauge couplings which would be beneficial to solve the gauge hierarchy problem .Furthermore , by using the empirical data of low power physics , we obtain some restrictions on the mass spectrum of extra particles involved in our model . Finally , we also discuss briefly about the possible signatures of large Z - prime boson at possible colliders .The results are presented below . I .INTRODUCTORY REMARK The Standard Model ( SM ) , built on SU ( 3 ) C ×SU ( 2 ) L ×U ( 1 ) Y gauge symmetry , has been very successful in representing all known phenomena upto TeV scale energies 1 . However , there remain many open questions related to SM like fermion masses and mixing angles 2 , neutrino oscillations 3 etc . , which impossible be described within the framework of SM .To address these problems , various extensions beyond SM have been proposed 4 - 8 . Among them , Grand Unified Theory ( GUTs ) 9 offers a natural solution to the above mentioned difficulties 10 .It predicts the existence of superheavy gauge bosons called GUT - scale gauge bosons 11 whose masses sit around 10 16 GeV 12 . These GUT - scale gauge boson interactions lead to non - renormalizable operators 13 which break the SM gauge symmetries 14 .Therefore , they should not appear in any physical process 15 . This implies that their contributions must vanish when summed over all states 16 .Thus , the appearance of these nonrenormalizable operators will spoil the achievements of SM 17 .",
        "rewrite_text": "**Title:** Signatures of Heavy Z-prime in the Extra U(1) Superstring Inspired Model: RGEs Analysis\n\n**Abstract:** This article investigates the renormalization group equations (RGEs) within the framework of an extra U(1) supersymmetric string-inspired model that incorporates a heavy Z-prime boson. We focus on the implications of this model for gauge coupling unification at the one-loop level. Our analysis reveals that the introduction of additional particles, specifically vector-like quarks and leptons, significantly influences the running behavior of gauge couplings. Notably, the presence of these new particles accelerates the evolution of gauge couplings, which could provide a viable solution to the gauge hierarchy problem. By leveraging empirical data from low-energy physics, we derive constraints on the mass spectrum of the extra particles included in our model. Additionally, we explore the potential signatures of a heavy Z-prime boson that could be observed at future collider experiments. The findings presented in this study contribute to a deeper understanding of the interplay between supersymmetry, gauge coupling dynamics, and the broader implications for particle physics beyond the Standard Model (SM). The SM, based on the gauge symmetry SU(3)C × SU(2)L × U(1)Y, has successfully described known phenomena up to energies in the TeV range. However, it leaves several unresolved issues, such as the origins of fermion masses, mixing angles, and neutrino oscillations, which cannot be adequately addressed within its framework. Various extensions to the SM have been proposed to tackle these challenges, with Grand Unified Theories (GUTs) providing a compelling approach by predicting the existence of superheavy gauge bosons, known as GUT-scale gauge bosons, with masses around 10^16 GeV. These interactions lead to non-renormalizable operators that disrupt the SM gauge symmetries, necessitating careful consideration of their contributions to physical processes. Our work aims to elucidate these complex interactions and their potential experimental signatures, paving the way for future research in this area.",
        "ori-fast-z-score": -0.086710996952412,
        "water-fast-z-score": 5.6594533097027915,
        "rewrite-fast-z-score": 0.25630729731502827
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Coulomb gauge Gribov copies and the confining potential .\nAbstract:\nWe study the effect of Coulomb gauge fixing on the gluon propagator in Landau gauge, using lattice simulations with two different actions for SU(2) Yang-Mills theory. We find that the inclusion of Gribov copies leads to an increase in the infrared strength of the gluon propagator; this is consistent with earlier results obtained by other groups. \n \n In addition we show how the presence of Gribov copies affects the static quark-antiquark potential at large distances. The latter quantity can be extracted from the correlation function of Polyakov loops which are defined as closed lines winding around the periodic spatial directions of the lattice. This allows us to compare our results directly with those obtained previously within perturbation theory. Our findings suggest that the perturbative approach breaks down when one considers the full non-perturbative effects associated with Gribov copies. Finally, we discuss possible implications of these results for phenomenological studies of QCD.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Coulomb gauge Gribov copies and the confining potential . Abstract : We research the impact of Coulomb gauge fixing on the gluon propagator in Landau gauge , using lattice simulations with two different actions for SU ( 2 ) Yang - Mills theory .We see that the inclusion of Gribov copies results to an increase in the infrared strength of the gluon propagator ; this is compatible with previous findings obtained by other groups . In addition we find how the presence of Gribov copies impacts the static quark - antiquark capacity at large distances .The latter quantity can be extracted from the correlation function of Polyakov circuits which are specified as closed lines winding around the periodic spatial directions of the lattice . This enables us to relate our findings directly with those achieved previously within perturbation theory .Our findings show that the perturbative methodology cracks down when one considers the full non - perturbative impacts associated with Gribov copies . Finally , we explain possible possibilities of these results for phenomenological experiments of QCD .",
        "rewrite_text": "In this study, we investigate the effects of Coulomb gauge fixing on the gluon propagator within the framework of Landau gauge, utilizing lattice simulations based on two distinct actions for SU(2) Yang-Mills theory. Our analysis reveals that the incorporation of Gribov copies leads to an enhancement in the infrared behavior of the gluon propagator, a result that aligns with previous observations reported by other research groups. Furthermore, we explore how Gribov copies influence the static quark-antiquark potential at large distances. This potential can be derived from the correlation function of Polyakov loops, which are defined as closed paths that wrap around the periodic spatial dimensions of the lattice. This connection allows us to directly compare our results with those obtained through perturbative approaches. Our findings indicate that the perturbative framework begins to falter when one takes into account the comprehensive non-perturbative effects associated with Gribov copies. Ultimately, we discuss the implications of our results for phenomenological studies in quantum chromodynamics (QCD), highlighting the potential for these insights to inform future experimental investigations in the field.",
        "ori-fast-z-score": -1.3587324409735149,
        "water-fast-z-score": 4.302652729749464,
        "rewrite-fast-z-score": -1.2535663410560174
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Census of the Carina Nebula -- II. Energy Budget and Global Properties of the Nebulosity .\nAbstract:\nWe present new near-infrared (NIR) photometry for more than 1000 stars in the central region of the Carina Nebulae, obtained with the WFCAM camera on UKIRT. The data are used to construct an energy budget for this complex star forming region. We find that the total luminosity is dominated by red supergiants at K-band (2 microns), but there is also significant contribution from hotter O-type stars. Using these NIR observations we have constructed a model of the global properties of the nebulosity surrounding the open clusters Trumpler 14 & 16. This model shows good agreement with existing optical images of the region. In particular it reproduces well the observed distribution of dust emission as traced by Spitzer mid-infrared imaging. \n \n Keywords: Open cluster; Near-Infrared; Star formation; Supernova remnant; Stellar population synthesis; Galactic structure",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  A Census of the Carina Nebula -- II.Energy Budget and Global Properties of the Nebulosity .Abstract : We introduce novel near - infrared ( NIR ) photometry for more than 1000 stars in the central region of the Carina Nebulae , obtained with the WFCAM sensor on UKIRT . The data are using to build an energy budget for this complex star producing zone .We see that the total luminosity is dominated by red supergiants at K - band ( 2 microns ) , but there is also important contribution from hotter O - class stars . Using these NIR observations we have constructed a description of the global properties of the nebulosity surrounding the open complexes Trumpler 14 & 16 .This theory demonstrates good agreement with existing imaging photographs of the region . In particular it reproduces well the seen distribution of dust radiation as traced by Spitzer mid - infrared imaging .Keywords : Open cluster ; Near - Infrared ; Star formation ; Supernova remnant ; Stellar population synthesis ; Galactic structure",
        "rewrite_text": "Title: A Census of the Carina Nebula - II. Energy Budget and Global Properties of the Nebulosity\n\nAbstract: In this study, we present new near-infrared (NIR) photometric data for over 1,000 stars located in the central region of the Carina Nebula, collected using the Wide Field Camera (WFCAM) on the United Kingdom Infrared Telescope (UKIRT). This extensive dataset enables us to construct a comprehensive energy budget for this intricate star-forming region. Our findings indicate that the total luminosity of the Carina Nebula is primarily influenced by red supergiants in the K-band (2 microns), although significant contributions also arise from the hotter O-type stars present in the area. By leveraging these NIR observations, we have developed a detailed characterization of the global properties of the nebulosity surrounding the prominent open clusters Trumpler 14 and 16. Our theoretical model aligns well with existing imaging data of the region, particularly in its ability to accurately reproduce the distribution of dust radiation as observed in Spitzer mid-infrared images. This research enhances our understanding of the energy dynamics and stellar populations within the Carina Nebula, contributing valuable insights into the processes of star formation and the overall galactic structure. \n\nKeywords: Open cluster; Near-Infrared; Star formation; Supernova remnant; Stellar population synthesis; Galactic structure.",
        "ori-fast-z-score": 0.9701425001453319,
        "water-fast-z-score": 5.335783750799325,
        "rewrite-fast-z-score": 1.193117518002609
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Statistical properties of giant pulses from the Crab pulsar .\nAbstract:\nWe have analyzed the statistical properties of giant pulses (GPs) detected in radio observations at 1.4 GHz with the Arecibo Observatory and compared them to those observed for GPs at other frequencies.  We find that the distribution of pulse widths is consistent with a log-normal function, as found previously by Cordes et al. (2004), but we also find evidence for an additional component which may be due to interstellar scattering or intrinsic effects within the source itself. The mean flux density of GPs decreases rapidly with increasing frequency above about 400 MHz; this decrease can be described well using a power law model with index -1.5 ± 0.1. This result suggests that there are two populations of GPs: one population whose emission mechanism has a low-frequency cutoff near 400 MHz, and another population whose emission mechanism extends up to at least 2 GHz. Finally, we show that the number of GPs per unit time increases linearly with observing bandwidth over most of our data set, indicating that the majority of these events occur independently of each other.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Statistical properties of giant pulses from the Crab pulsar . Abstract : We have analyzed the statistical characteristics of giant pulses ( GPs ) detected in radio observations at 1 . 4 GHz with the Arecibo Observatory and compared them to those observed for GPs at other frequencies .We see that the distribution of signal widths is compatible with a log - normal function , as found prior by Cordes et al . ( 2004 ) , but we also find proof for an additional element which may be due to interstellar scattering or intrinsic effects within the source itself .The mean flux concentration of GPs falls steadily with rising frequency above about 400 MHz ; this reduction can be described good using a power law theory with index - 1 . 5 ± 0 . 1 . This result suggests that there are two communities of GPs : one community whose emission mechanism has a high - frequency cutoff near 400 MHz , and another population whose emission mechanism stretches up to at least 2 GHz .Finally , we find that the proportion of GPs per unit time changes linearly with observing bandwidth over most of our information set , showing that the majority of these experiences occur independently of each other .",
        "rewrite_text": "In this study, we investigate the statistical properties of giant pulses (GPs) emitted by the Crab pulsar, utilizing radio observations conducted at a frequency of 1.4 GHz at the Arecibo Observatory. Our analysis reveals that the distribution of signal widths for these GPs aligns with a log-normal function, consistent with previous findings by Cordes et al. (2004). However, we also identify evidence suggesting the presence of an additional factor that may be attributed to either interstellar scattering or intrinsic characteristics of the pulsar itself. \n\nFurthermore, we observe a notable trend in the mean flux density of GPs, which decreases progressively with increasing frequency beyond approximately 400 MHz. This decline can be effectively modeled using a power law with an index of -1.5 ± 0.1. This finding indicates the existence of two distinct populations of GPs: one group that exhibits a high-frequency cutoff around 400 MHz, and another that maintains emission mechanisms extending up to at least 2 GHz. \n\nAdditionally, our results indicate that the rate of GPs detected per unit time exhibits a linear relationship with the observing bandwidth across the majority of our dataset. This suggests that the majority of giant pulse events occur independently of one another, reinforcing the notion of their stochastic nature. Overall, our analysis contributes to a deeper understanding of the emission mechanisms and statistical behaviors of giant pulses from the Crab pulsar, offering insights into the underlying astrophysical processes at play.",
        "ori-fast-z-score": -0.43133109281375365,
        "water-fast-z-score": 5.330017908890261,
        "rewrite-fast-z-score": 1.8367993291867606
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Generalization of the Stillinger-Lovett Sum Rules for the Two-Dimensional Jellium .\nAbstract:\nWe present an exact expression for the energy density functional in terms of the local electronic charge and spin densities, which is valid for any number N of electrons on a two-dimensional jellium surface with arbitrary spin-orbit interaction strength. The resulting sum rules are shown to be equivalent to those derived by Stillinger and Lovett (SL) for the case of zero spin-orbit coupling but they also include additional contributions due to this term. We show that these new terms can be expressed as functions of the SL parameters only. This result allows us to obtain explicit expressions for all the relevant physical quantities such as the exchange-correlation potential or the magnetization profile at finite temperature. Finally we discuss how our results could be used to improve existing approximations within Density Functional Theory. PACS: 71.10.Pq - Energy-densities; 72.20.Fd - Energy-density functionals; 73.40.Gk - Spin-polarized systems",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Generalization of the Stillinger - Lovett Sum Rules for the Two - Dimensional Jellium . Abstract : We present an precise representation for the electricity density functional in terms of the local electronic charge and spin densities , which is valid for any number N of electrons on a two - dimensional jellium surface with arbitrary spin - orbit interaction strength .The resulting sum rules are shown to be analogous to those developed by Stillinger and Lovett ( SL ) for the case of zero spin - orbit coupling but they still incorporate additional contributions due to this term . We see that these new terms can be stated as functions of the SL parameters only .This result allows us to obtain precise expressions for all the appropriate physical quantities such as the transfer - correlation potential or the magnetization profile at finite temperature . Finally we talk how our findings may be used to develop existing approximations within Density Functional Theory .PACS: 71.10.Pq - Energy-densities; 72.20.Fd - Energy-density functionals; 73.40.Gk - Spin-polarized systems",
        "rewrite_text": "Title: A Generalization of the Stillinger-Lovett Sum Rules for the Two-Dimensional Jellium\n\nAbstract: In this study, we introduce a comprehensive representation of the electric density functional that incorporates both local electronic charge and spin densities. This representation is applicable to any number of electrons situated on a two-dimensional jellium surface, accommodating varying strengths of spin-orbit interaction. Our findings reveal that the newly derived sum rules bear a resemblance to those established by Stillinger and Lovett (SL) in the context of zero spin-orbit coupling; however, they also account for additional contributions arising from the spin-orbit interaction. Notably, these new terms can be expressed solely in terms of the SL parameters, which facilitates the derivation of accurate expressions for essential physical quantities, including the transfer-correlation potential and the magnetization profile at finite temperatures. Furthermore, we discuss the implications of our results for enhancing existing approximations within Density Functional Theory (DFT). By integrating our generalization of the SL sum rules, we aim to provide a more robust framework for analyzing spin-polarized systems and energy-density functionals. Our work contributes to a deeper understanding of the interplay between electronic structure and spin dynamics in two-dimensional materials, paving the way for future advancements in theoretical and computational approaches within the field. The relevance of our findings is underscored by their potential applications in various areas of condensed matter physics, particularly in the study of materials exhibiting significant spin-related phenomena. PACS: 71.10.Pq - Energy-densities; 72.20.Fd - Energy-density functionals; 73.40.Gk - Spin-polarized systems.",
        "ori-fast-z-score": -0.5852057359806528,
        "water-fast-z-score": 3.4874291623145783,
        "rewrite-fast-z-score": 1.8569533817705188
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multiuser detection in a dynamic environment Part I: User identification and data detection .\nAbstract:\nIn this work, we consider the problem of multiuser detection (MUD) for code division multiple access systems with time-varying channels. We propose an algorithm that jointly performs user identification and data detection by using a maximum likelihood criterion. The proposed method is based on the expectation-maximization (EM) algorithm which iteratively estimates both the channel coefficients and transmitted symbols. In order to reduce computational complexity, we also develop a low-complexity suboptimal MUD scheme. Numerical results show that our proposed algorithms outperform existing schemes under various scenarios. Index Terms-Data detection, EM algorithm, Multiuser detection, Time varying channels. 1 Introduction Code-division-multiple-access (CDMA) has been widely used as one of the most promising technologies for next-generation wireless communications due to its high spectral efficiency  1  . However, CDMA suffers from severe interference between users caused by multipath propagation  2  , especially when the number of active users increases  3  .\nTo mitigate inter-user interference, multiuser detectors have been developed  4  -  6  . Among them, linear multiuser detectors are attractive because they can be implemented easily at low cost  7  . Unfortunately, these detectors suffer from performance loss compared to optimal multiuser detectors  8  . To improve their performance, nonlinear multiuser detectors such as successive interference cancellation  9  or parallel interference cancellation  10  were introduced. These detectors require accurate knowledge about the received signals  11  . Therefore, blind multiuser detectors  12  -  14  were proposed to estimate unknown parameters without any training sequence  15  . Although blind multiuser detectors do not need prior information about the received signal, they usually perform worse than conventional multiuser detectors  16  .\nRecently, there has been growing interest in developing multiuser detectors for time-varying channels  17  -  20  . Since the channel varies over time, it becomes more difficult to detect the transmitted symbol accurately  21  . Moreover, if the channel changes rapidly, then the detector may fail completely  22  . Thus, it is important to design robust multiuser detectors against rapid channel variations  23  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multiuser tracking in a dynamic landscape Part I : User identity and data detection . Abstract : In this study , we investigate the issue of multiuser tracking ( MUD ) for code division multiple entry systems with time - differing channels .We suggest an algorithm that collectively performs user identification and information detection by using a maximum likelihood criterion . The proposed approach is based on the expectation - maximization ( EM ) algorithm which iteratively measures both the channel coefficients and transmitted symbols .In order to reduce numerical difficulty , we also build a small - complexity suboptimal MUD scheme . Numerical results show that our proposed methods outperform established algorithms under various scenarios .Index Terms - Data tracking , EM algorithm , Multiuser tracking , Time varying channels . 1 Introduction Code - division - multiple - access ( CDMA ) has been widely adopted as one of the most attractive devices for next - generation communications transmission thanks to its high spectral power 1 .However , CDMA suffers from severe interference between clients caused by multipath propagation 2 , particularly when the proportion of active consumers increases 3 . To mitigate inter - customer interference , multiuser detectors have been created 4 - 6 .Among them , linear multiuser detectors are interesting because they can be deployed easily at low cost 7 . Unfortunately , these detectors suffer from performance loss compared to optimal multiuser detectors 8 .To increase their performance , nonlinear multiuser detectors such as consecutive interference cancellation 9 or parallel interference cancellation 10 were introduced . These detectors need accurate knowledge about the received transmissions 11 .Therefore , blind multiuser detectors 12 - 14 were recommended to estimate unknown parameters without any testing sequence 15 . Although blind multiuser detectors do not require prior information about the received signal , they generally work worse than conventional multiuser detectors 16 .Recently , there has been growing interest in building multiuser detectors for time - differing channels 17 - 20 . Since the channel varies over time , it becomes more hard to identify the transmitted expression accurately 21 .Moreover , if the channel shifts rapidly , then the sensor may fail entirely 22 . Thus , it is important to build robust multiuser detectors against sudden channel change 23 .",
        "rewrite_text": "**Title:** Multiuser Tracking in a Dynamic Landscape Part I: User Identity and Data Detection\n\n**Abstract:** This research addresses the challenge of multiuser tracking (MUD) within code division multiple access (CDMA) systems characterized by time-varying channels. We propose a novel algorithm that integrates user identification and data detection through a maximum likelihood criterion. Our methodology leverages the expectation-maximization (EM) algorithm, which iteratively estimates both the channel coefficients and the transmitted symbols. To alleviate computational complexity, we also introduce a suboptimal MUD scheme with reduced complexity. Our numerical simulations demonstrate that the proposed techniques significantly outperform existing algorithms across a variety of scenarios.\n\nThe introduction of CDMA as a prominent technology for next-generation communication systems is attributed to its efficient use of spectral resources. However, CDMA systems face substantial challenges due to interference among users, particularly in environments with multipath propagation and a high density of active users. To address inter-user interference, various multiuser detectors have been developed, with linear detectors being favored for their cost-effectiveness and ease of implementation. Despite their advantages, linear detectors exhibit performance limitations compared to optimal multiuser detection methods. Consequently, nonlinear multiuser detectors, such as consecutive and parallel interference cancellation techniques, have been proposed to enhance performance. These advanced detectors, however, necessitate precise knowledge of the received signals.\n\nIn response to the limitations of conventional methods, blind multiuser detectors have emerged, allowing for the estimation of unknown parameters without the need for training sequences. While these detectors offer the advantage of not requiring prior signal information, they typically underperform compared to their conventional counterparts. Recent research has increasingly focused on developing multiuser detectors capable of functioning effectively in time-varying channels, where the dynamic nature of the channel complicates the accurate identification of transmitted signals. Rapid fluctuations in channel conditions can lead to complete detection failures, underscoring the necessity for robust multiuser detection strategies that can withstand abrupt changes in channel characteristics.",
        "ori-fast-z-score": -1.8407159732336889,
        "water-fast-z-score": 7.777427086962838,
        "rewrite-fast-z-score": -1.323448205074589
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Linked by Loops: Network Structure and Switch Integration in Complex Dynamical Systems .\nAbstract:\nWe study the relationship between network structure, dynamics, and function using an example system that is both complex and experimentally accessible -- the brain s neuronal circuitry. We show how to use statistical mechanics methods to analyze the functional properties of this system as it evolves over time through its underlying structural connectivity. In particular we focus on the role played by switches which are nodes with high degree centrality whose removal disconnects large portions of the network. Our results suggest that these switches play important roles in maintaining global dynamical stability while allowing for local flexibility. The manuscript is organized into four sections. Section I introduces our model and describes some basic features of the resulting networks. Section II presents numerical simulations showing how switching affects the evolution of the system. Section III analyzes the effect of removing switches on the networks  ability to maintain synchrony under perturbations. Finally section IV discusses possible extensions of our work. This article has been published in final form at http://arxiv.org/abs/1306.5995",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Linked by Loops : Network Structure and Switch Integration in Complex Dynamical Systems . Abstract : We research the relationship between network structure , dynamics , and function using an instance structure that is both complex and experimentally visible - - the brain s neuronal circuitry .We see how to use statistical mechanics algorithms to analyze the functional characteristics of this network as it evolves over time through its underlying structural connectivity . In particular we focus on the part played by switches which are networks with high degree centrality whose departure disconnects huge segments of the organization .Our results show that these switches act essential roles in maintaining international dynamical stability while providing for local flexibility . The manuscript is organized into four sections .Section I outlines our model and explains some fundamental characteristics of the resulting systems . Section II offers numerical simulations demonstrating how switching affects the evolution of the system .Section III analyzes the impact of eliminating switches on the systems ability to keep synchrony under perturbations . Finally section IV examines possible extensions of our work .This section has been publication in final form at http : / / arxiv . org / abs / 1306 . 5995",
        "rewrite_text": "**Title:** Linked by Loops: Network Structure and Switch Integration in Complex Dynamical Systems\n\n**Abstract:** In this study, we investigate the intricate interplay between network structure, dynamics, and functionality, using the brain's neuronal circuitry as a complex and experimentally accessible model. By employing statistical mechanics algorithms, we analyze the functional characteristics of this network as it evolves over time, driven by its underlying structural connectivity. A key focus of our research is on the role of switches—nodes within the network that exhibit high degree centrality. The removal of these switches can lead to the disconnection of significant portions of the network, highlighting their critical importance. Our findings reveal that switches are vital for maintaining global dynamical stability while simultaneously allowing for local flexibility within the system. \n\nThe manuscript is structured into four distinct sections. In Section I, we present our model and elucidate the fundamental characteristics of the resulting systems. Section II provides numerical simulations that illustrate the effects of switching on the system's evolution. In Section III, we analyze the consequences of switch elimination on the network's ability to maintain synchrony in the face of perturbations. Finally, Section IV explores potential extensions of our research, suggesting avenues for future investigation. This work contributes to a deeper understanding of how network structures influence dynamic processes, with implications for various fields, including neuroscience and complex systems theory. The full manuscript is available at http://arxiv.org/abs/1306.5995.",
        "ori-fast-z-score": -1.1406468642034677,
        "water-fast-z-score": 6.807380225308036,
        "rewrite-fast-z-score": 1.4110813025753959
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Experimenting with recursive queries in database and logic programming systems .\nAbstract:\nThe main goal of this thesis is to experiment with the use of recursion as an alternative way for querying databases, using Prolog (a declarative language) and SQL (the standard query language). The first part presents some background on how databases are structured and queried today; it also introduces the concept of recursion and its application in computer science. In the second section we present our experiments with recursion in Prolog, where we show that recursion can be used to express complex queries without having to resort to procedural code or other languages such as Java. Finally, in the third section we discuss the results obtained by applying recursion in SQL systems. We conclude that although there have been many attempts at implementing recursion in SQL systems, none has succeeded so far due to technical difficulties inherent in these systems. This work shows that recursion could be useful if implemented correctly in SQL systems. Keywords: Database, Recursion, Query",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Experimenting with recursive queries in database and logic programming systems . Abstract : The main goal of this dissertation is to study with the using of recursion as an additional means for querying data , using Prolog ( a declarative language ) and SQL ( the standard query language ) .The first part offers some details on how databases are structured and queried today ; it also explains the idea of recursion and its use in computer science . In the second chapter we present our experiments with recursion in Prolog , where we tell that recursion can be used to express complex queries without having to resort to procedural code or other languages such as Java .Finally , in the third chapter we explain the results derived by using recursion in SQL systems . We follow that although there have been many efforts at employing recursion in SQL systems , none has successful so far owing to technical problems inherent in these systems .This effort suggests that recursion could be usable if implemented correctly in SQL systems . Keywords : Database , Recursion , Query",
        "rewrite_text": "Title: Experimenting with Recursive Queries in Database and Logic Programming Systems\n\nAbstract: This dissertation investigates the application of recursion as a powerful tool for querying data within the realms of Prolog, a declarative programming language, and SQL, the standard language for database queries. The initial section of the study provides an overview of contemporary database structures and querying methodologies, alongside a comprehensive explanation of recursion and its significance in computer science. In the second chapter, we delve into our experimental findings regarding the use of recursion in Prolog. We demonstrate that recursion enables the formulation of intricate queries without the necessity of procedural programming or reliance on other languages such as Java. The third chapter shifts focus to the implications of employing recursion within SQL systems. Despite numerous attempts to integrate recursion into SQL, our findings reveal that these efforts have largely been hindered by persistent technical challenges inherent to these systems. Nevertheless, our research indicates that with appropriate implementation, recursion holds the potential to enhance SQL querying capabilities significantly. This work contributes to the ongoing discourse on the viability of recursive techniques in database management and logic programming, suggesting pathways for future exploration and development. \n\nKeywords: Database, Recursion, Query",
        "ori-fast-z-score": -0.46499055497527714,
        "water-fast-z-score": 5.9648090806346055,
        "rewrite-fast-z-score": 1.7888543819998317
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Sweet Spot Supersymmetry .\nAbstract:\nWe present the results of an analysis searching for supersymmetric particles in events with jets and missing transverse energy using data collected by the D0 experiment at Fermilab during Run II, corresponding to 1 fb-1 . We consider models where squarks decay into quarks and gluinos which then decay via intermediate sleptons or neutralinos into final states containing two light-flavored leptons (electrons and/or muons) and large E T / .\nThe search is performed over a wide range of masses for all sparticles involved in these cascade decays , including those that are not directly produced but can be exchanged in t-channel processes . No significant excess above background expectations has been observed . Limits on the production cross sections times branching fractions have been set as functions of the mass parameters of the model considered . These limits are compared to theoretical predictions obtained within the framework of minimal supergravity grand unification .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Sweet Spot Supersymmetry . Abstract : We present the conclusion of an assessment searching for supersymmetric particles in events with jets and lost radial energy using data derived by the D0 study at Fermilab during Run II , equivalent to 1 fb - 1 .We consider scenarios where squarks decay into quarks and gluinos which then decay via elementary sleptons or neutralinos into last states bearing two light - flavored leptons ( atoms and / or muons ) and large E T / . The hunt is conducted over a broad variety of masses for all sparticles involved in these cascade decays , particularly those that are not directly produced but can be exchanged in t - channel pathways .No much excess above background expectations has been observed . Limits on the production cross sections times branching fractions have been set as functions of the mass parameters of the model discussed .These restrictions are compared to theoretical estimates obtained within the framework of minimal supergravity grand unification .",
        "rewrite_text": "In this article titled \"Sweet Spot Supersymmetry,\" we present the findings of a comprehensive investigation aimed at detecting supersymmetric particles through the analysis of events characterized by jets and missing transverse energy. This research utilizes data collected by the D0 collaboration at Fermilab during Run II, which corresponds to an integrated luminosity of approximately 1 fb⁻¹. Our study focuses on scenarios in which squarks decay into quarks and gluinos, which subsequently decay into final states containing two light-flavored leptons (electrons and/or muons) along with significant missing transverse energy (E_T). \n\nWe explore a wide range of mass configurations for all sparticles involved in these cascade decay processes, particularly emphasizing those that are not directly produced but can be exchanged in t-channel interactions. Despite an extensive search, we have not observed any significant excess above the anticipated background levels. Consequently, we have established limits on the production cross sections multiplied by branching fractions, which are presented as functions of the mass parameters within the model under consideration. \n\nThese derived limits are then compared with theoretical predictions formulated within the context of minimal supergravity grand unification. Our results contribute to the ongoing discourse in the field of particle physics regarding the existence of supersymmetry, providing valuable constraints that may guide future research and experimental efforts. The implications of our findings are significant for understanding the potential mass scales of supersymmetric particles and their role in the broader framework of particle physics.",
        "ori-fast-z-score": -1.4342743312012722,
        "water-fast-z-score": 4.949747468305833,
        "rewrite-fast-z-score": 1.5852581740085334
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Exciting the Magnetosphere of the Magnetar CXOU J164710.2-455216 in Westerlund 1 .\nAbstract:\nWe report on observations made with Chandra and XMM-Newton that reveal an X-ray flare from the magnetar CXOU J16 47 10 . 2-45 52 16 (hereafter, J1647) located within the open cluster Westerlund 1. The flare was detected by both observatories during their respective slews to point at another target; it lasted for about one hour before fading below detectability. We find no evidence for any significant change in the spin-down rate or period derivative of this source following its outburst. \n \n This is the first time such a large event has been observed from a magnetar; we estimate that the total energy released in the flare was ~3 x 10^44 erg. Our analysis shows that the flare occurred when the star s magnetic field lines were nearly perpendicular to our line-of-sight. In addition, we detect pulsations from J1647 during the flare which are consistent with those seen prior to the flare. These results suggest that the flaring activity may be due to reconnection events occurring along the closed loops of the stellar magnetic field.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Exciting the Magnetosphere of the Magnetar CXOU J164710 . 2 - 455216 in Westerlund 1 . Abstract : We report on observations made with Chandra and XMM - Newton that reveal an X - ray flare from the magnetar CXOU J16 47 10 .2 - 45 52 16 ( hereafter , J1647 ) located within the open cluster Westerlund 1 . The flare was noticed by both observatories during their separate slews to point at another target ; it persisted for about one hour before faded below detectability .We see no evidence for any large change in the spin - down frequency or time derivative of this source following its outburst . This is the first time such a large incident has been observed from a magnetar ; we estimate that the total energy released in the flare was ~ 3 x 10 ^ 44 erg .Our study shows that the flare originated when the star s magnetic field lines were roughly perpendicular to our line - of - view . In addition , we find pulsations from J1647 during the flare which are compatible with those observed earlier to the flare .These data suggest that the flaring activity may be due to reconnection events resulting along the shut rings of the stars magnetic force .",
        "rewrite_text": "We present findings from observations conducted with the Chandra and XMM-Newton space telescopes, which captured an X-ray flare from the magnetar CXOU J164710.2-455216 (referred to as J1647), situated within the open cluster Westerlund 1. This significant flare was detected independently by both observatories while they were in the process of slewing to other targets. The event lasted approximately one hour before its intensity diminished to levels below detectability. Notably, our analysis reveals no substantial alterations in the spin-down frequency or its time derivative following the flare, indicating that the magnetar's rotational dynamics remained stable despite the energetic outburst. This observation marks the first instance of such a pronounced flare from a magnetar, with an estimated total energy release of around 3 x 10^44 erg. \n\nOur investigation suggests that the flare's origin was linked to the orientation of the star's magnetic field lines, which were approximately perpendicular to our line of sight at the time of the event. Furthermore, we detected pulsations from J1647 during the flare, which align with previously recorded pulsations prior to the outburst. These findings imply that the flaring activity may be attributed to magnetic reconnection events occurring along the star's magnetic field lines. This research enhances our understanding of magnetar behavior and the mechanisms behind their flaring activities, providing valuable insights into the complex interactions between magnetic fields and stellar dynamics in these extreme astrophysical environments.",
        "ori-fast-z-score": -1.0256451881367414,
        "water-fast-z-score": 4.755563543407302,
        "rewrite-fast-z-score": -0.502518907629606
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Strong peak points and denseness of strong peak functions .\nAbstract:\nWe study the properties of strong peak points in Banach spaces, which are defined as follows.  Let X be a real or complex normed space with dual space X*. A point x # X is called a strong peak point if there exists an f # S(X) such that |f (x)| = sup{|f (y)| : y # X}. We prove that every separable reflexive Banach space has a dense set of strong peak points. As applications we show that every separable reflexivizable Banach space contains a copy of c 0 , and that every separable superreflexive Banach space contains a subspace isomorphic to l p for some 1 < p < + . In this note we study the properties of strong peaks points in Banach spaces. The concept was introduced by J. Lindenstrauss  L  who proved that every separable reflexible Banach space has a nonempty set of strong peak points; see also  JL1  .\nIn Section 2 we give several equivalent characterizations of strong peak points. In particular, it turns out that a point x # X is a strong peak point if and only if there exist two sequences (a n ) and (b n ) in R satisfying lim n Ä a n = lim n Ä b n = 1 and lim n Ä a n &1Â2 b n = 0 such that the sequence (a n b n ) converges weakly to zero but not strongly. This characterization enables us to prove our first main result on the density of strong peak points in separable reflexive BanACH spaces. \nTheorem 3. Every separable reflexive BanACH space has a dense set SP(X) of strong peak points.\n\nAs immediate consequences of Theorem 3 we obtain the following results. (i) Every separable reflexivizable space contains a copy of c0.\n(ii) Every separable superreflexive space contains a subspace isomorphic",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Strong peak points and denseness of strong peak functions . Abstract : We research the properties of strong peak points in Banach spaces , which are defined as follows .Let X be a real or complex normed space with dual space X * . A point x # X is dubbed a strong peak point if there exists an f # S ( X ) such that | h ( x ) | = sup { | f ( y ) | : y # X } .We establish that every separable reflexive Banach space has a dense setting of stable peak points . As applications we prove that every separable reflexivizable Banach space includes a copy of c 0 , and that every separable superreflexive Banach space includes a subspace isomorphic to l p for some 1 < p < + .In this note we study the properties of strengthened peaks points in Banach spaces . The concept was introduced by J . Lindenstrauss L who proved that every separable reflexible Banach space has a nonempty set of strong peak points ; hear also JL1 .In Section 2 we give numerous equivalent characterizations of strengthened peak points . In particular , it turns out that a point z # X is a strong peak point if and only if there exist two sequences ( a n ) and ( b n ) in R satisfying lim n Ä a n = lim n Ä b n = 1 and lim n Ä a n & 1Â2 b n = 0 such that the sequence ( a n b n ) converges weakly to zero but not strongly .This description helps us to prove our first major result on the density of stable peak points in separable reflexive BanACH spaces . Theorem 3 .Every separable reflexive BanACH space has a dense setting SP ( X ) of stable peak points . As immediate implications of Theorem 3 we obtain the following results .( i ) Every separable reflexivizable set contains a copy of c0 . ( ii ) Every separable superreflexive space includes a subspace isomorphic",
        "rewrite_text": "**Title:** Strong Peak Points and Denseness of Strong Peak Functions\n\n**Abstract:** This article investigates the characteristics of strong peak points within the context of Banach spaces. We define a strong peak point in a normed space \\(X\\) (which can be either real or complex) with a dual space \\(X^*\\) as a point \\(x \\in X\\) for which there exists a function \\(f \\in S(X)\\) such that \\(|h(x)| = \\sup \\{ |f(y)| : y \\in X \\}\\). Our findings reveal that every separable reflexive Banach space possesses a dense collection of stable peak points. This result has significant implications, leading us to demonstrate that every separable reflexivizable Banach space contains a copy of \\(c_0\\), and that every separable superreflexive Banach space includes a subspace that is isomorphic to \\(l_p\\) for some \\(1 < p < +\\infty\\).\n\nThe concept of strong peak points was initially introduced by J. Lindenstrauss, who established that separable reflexive Banach spaces always have a non-empty set of such points. In the second section of this paper, we provide multiple equivalent characterizations of strong peak points. Notably, we show that a point \\(z \\in X\\) qualifies as a strong peak point if and only if there exist two sequences \\((a_n)\\) and \\((b_n)\\) in \\(\\mathbb{R}\\) such that \\(\\lim_{n \\to \\infty} a_n = \\lim_{n \\to \\infty} b_n = 1\\) and \\(\\lim_{n \\to \\infty} a_n \\cdot \\frac{1}{2} b_n = 0\\), with the sequence \\((a_n b_n)\\) converging weakly to zero but not strongly. This characterization is pivotal in proving our primary result regarding the density of stable peak points in separable reflexive Banach spaces. Specifically, we establish Theorem 3, which asserts that every separable reflexive Banach space contains a dense set \\(SP(X)\\) of stable peak points. The immediate consequences of this theorem further reinforce the foundational structure of separable reflexivizable and superreflexive spaces in functional analysis.",
        "ori-fast-z-score": -1.8864844365675972,
        "water-fast-z-score": 3.1382990398158928,
        "rewrite-fast-z-score": 0.09016696346674323
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A linear reformulation of the Kuramoto model of self-synchronizing oscillators .\nAbstract:\nWe present an alternative formulation for the Kuramoto model that is based on a linearization of the original nonlinear system and leads to a more efficient numerical solution method than existing approaches.  The new approach can be used in combination with any standard solver, such as Newton s or fixed-point iteration methods. We demonstrate its performance by applying it to several examples including networks of coupled phase oscillators and chaotic systems. Synchronized behavior has been observed across many different fields ranging from physics  1  , biology  2  , chemistry  3  , engineering  4  , and social sciences  5  . In particular, synchronization phenomena are often studied using models of interacting dynamical systems  6  .\nThe most commonly used mathematical description of synchronized dynamics is given by the Kuramoto model  7, 8  which describes how N identical oscillators evolve over time t according to: \nwhere θi(t) ∈  0, 2π  denotes the phase angle of oscillator i at time t, ωi > 0 represents the natural frequency of each individual oscillator, and Kij ≥ 0 quantifies the strength of interaction between oscillators i and j. For simplicity we assume here that all interactions have equal weight (Kij = 1). This assumption does not affect our results but simplifies notation considerably.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A linear reformulation of the Kuramoto model of self - synchronizing oscillators . Abstract : We present an alternative formulation for the Kuramoto model that is based on a linearization of the original nonlinear system and results to a more efficient numerical solving approach than existing techniques .The modern solution can be used in combination with any typical solver , such as Newton s or fixed - point iteration algorithms . We suggest its success by using it to several examples namely groups of coupled phase oscillators and chaotic structures .Synchronized activity has been observed across many various fields ranging from science 1 , chemistry 2 , chemistry 3 , engineering 4 , and social sciences 5 . In particular , synchronization processes are often investigated using models of interacting dynamical systems 6 .The most commonly used numerical model of synchronized dynamics is given by the Kuramoto model 7 , 8 which explains how N identical oscillators evolve over time t according to : where θi ( t ) ∈ 0 , 2π denotes the phase angle of oscillator i at time t , ωi > 0 represents the natural intensity of each individual oscillator , and Kij ≥ 0 quantifies the strength of coupling between oscillators i and j . For simplicity we suppose here that all interactions have equal weight ( Kij = 1 ) .This assumption does not alter our findings but simplifies notation significantly .",
        "rewrite_text": "We introduce a novel linear reformulation of the Kuramoto model, which describes self-synchronizing oscillators. This new approach is derived from a linearization of the original nonlinear system, leading to a more efficient numerical solution compared to existing methods. Our formulation can be seamlessly integrated with standard numerical solvers, including Newton's method and fixed-point iteration algorithms. We demonstrate the effectiveness of our approach through various examples, including groups of coupled phase oscillators and chaotic systems. Synchronization phenomena are prevalent across diverse disciplines, including the natural sciences, chemistry, engineering, and social sciences. Researchers often explore synchronization processes through models of interacting dynamical systems. The Kuramoto model is one of the most widely utilized frameworks for studying synchronized dynamics, illustrating how N identical oscillators evolve over time. In this model, the phase angle of each oscillator, denoted as θi(t), varies within the range of 0 to 2π, while ωi represents the intrinsic frequency of each oscillator, and Kij indicates the coupling strength between oscillators i and j. For the sake of simplicity, we assume uniform coupling (Kij = 1) among all oscillators, which does not compromise the validity of our results but streamlines the notation. Our findings suggest that this linear reformulation not only enhances computational efficiency but also broadens the applicability of the Kuramoto model in analyzing synchronization across various systems.",
        "ori-fast-z-score": 0.20203050891044214,
        "water-fast-z-score": 6.130730673081194,
        "rewrite-fast-z-score": 0.9233805168766388
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Statistical Mechanics of Nonlinear On-line Learning for Ensemble Teachers .\nAbstract:\nWe study the statistical mechanics of nonlinear on-line learning in ensemble teachers, where each teacher is trained by an independent student population and all students are drawn from the same distribution. We show that this model can be mapped to a spin glass system with random interactions between spins on different layers. Using replica theory we derive analytical expressions for the free energy density as well as the order parameters characterizing the equilibrium state of the system. In particular, we find that there exists a phase transition at which the number of active teachers changes discontinuously. The critical temperature depends only weakly on the size of the student populations but strongly on their overlap. This suggests that it may be possible to control the quality of teaching by tuning the overlap between student populations. Finally, we discuss how our results relate to previous work on self-organized criticality in neural networks. PACS numbers: 05.45.Mt, 89.70.+c",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Statistical Mechanics of Nonlinear On - line Learning for Ensemble Teachers . Abstract : We research the statistical mechanics of nonlinear on - line learning in ensemble educators , where each teacher is trained by an independent teacher population and all students are drawn from the same distribution .We see that this model can be mapped to a spinning glass structure with random interactions between spins on various sheets . Using replica theory we derive analytical expressions for the free energy density as well as the order variables characterizing the equilibrium state of the system .In particular , we find that there exists a phase shift at which the quantity of active teachers shifts discontinuously . The essential temperature relies only weakly on the size of the student populations but heavily on their overlap .This implies that it could be possible to affect the performance of teaching by tuning the overlap between student populations . Finally , we explain how our findings connect to previous research on self - organized criticality in neural systems .PACS codes : 05 . 45 . Mt , 89 . 70 . + c",
        "rewrite_text": "In this study, we investigate the statistical mechanics underlying nonlinear online learning within ensemble educators, where each educator is trained by a distinct population of independent teachers, while all students originate from a common distribution. Our model reveals a correspondence to a spin glass framework characterized by random interactions among spins across multiple layers. By employing replica theory, we derive analytical expressions for both the free energy density and the order parameters that define the system's equilibrium state. Notably, our analysis uncovers a phase transition marked by a sudden change in the number of active educators. We observe that the critical temperature is only weakly dependent on the size of the student populations, yet it exhibits a strong dependence on the degree of overlap among these populations. This finding suggests that the effectiveness of teaching can potentially be enhanced by adjusting the overlap between different student groups. Furthermore, we discuss the implications of our results in relation to existing literature on self-organized criticality within neural systems, highlighting the broader relevance of our work in understanding complex learning dynamics. Our research contributes to the field by providing a theoretical framework that links statistical mechanics with educational methodologies, paving the way for future explorations into optimizing learning processes through ensemble teaching strategies. The findings are significant for both theoretical advancements and practical applications in educational settings. PACS codes: 05.45.Mt, 89.70.+c.",
        "ori-fast-z-score": -0.9434563530497265,
        "water-fast-z-score": 4.427188724235731,
        "rewrite-fast-z-score": 1.7131723058681212
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  SIR epidemics in dynamic contact networks .\nAbstract:\nWe study the SIR epidemic model on an evolving contact network with time-varying transmission rates and recovery probabilities, where individuals are allowed to change their connections over time. We show that if the infection rate is sufficiently large compared to the recovery probability then there exists a unique endemic equilibrium point which attracts all solutions starting within its basin of attraction. In addition we prove that for any initial condition outside this basin of attraction the disease will eventually die out. Finally, we provide numerical simulations illustrating our results. The SIR (Susceptible-Infected-Recovered) epidemic model has been widely used as a mathematical tool to describe the spread of infectious diseases such as influenza or SARS  1  . This simple deterministic compartmental model divides the population into three classes according to individuals  states: susceptible, infected and recovered/removed. Individuals can move between these different states depending on certain parameters describing the evolution of the epidemic process  2  .\nIn recent years researchers have started studying the dynamics of epidemic processes taking place on complex networks  3, 4  , i.e., graphs whose nodes represent individuals and edges represent contacts among them. These studies have shown how important it is to take into account the underlying topology when modeling the spreading of infections  5, 6  . For example, it was found that the presence of highly connected hubs may lead to the emergence of super-spreaders  7, 8  who play a crucial role in determining whether the outbreak becomes global  9  . Moreover, it turns out that even small changes in the structure of the network might significantly affect the final outcome  10, 11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : SIR epidemics in dynamic contact systems . Abstract : We research the SIR prevalence model on an evolving contact network with time - differing communication frequencies and survival probabilities , where persons are allowed to alter their connections over time .We see that if the infection rate is sufficiently huge compared to the recovery probability then there exists a unique endemic equilibrium point which attracts all solutions starting within its basin of attraction . In addition we prove that for any initial situation outside this basin of attraction the infection will eventually die out .Finally , we provide numerical simulations illustrating our findings . The SIR ( Susceptible - Infected - Recovered ) outbreak model has been widely using as a mathematical tool to explain the spread of infectious infections such as influenza or SARS 1 .This straightforward deterministic compartmental theory breaks the population into three categories according to individuals states : exposed , infected and returned / deleted . Individuals can move between these distinct states based on particular parameters describing the evolution of the outbreak process 2 .In recent years studies have started researching the dynamics of infectious processes take place on complex networks 3 , 4 , i . e . , graphs whose nodes denote individuals and edges represent contacts among them . These studies have shown how important it is to take into consideration the underlying topology when modeling the spreading of infections 5 , 6 .For instance , it was shown that the activity of highly connected hubs might lead to the emergence of super - spreaders 7 , 8 who play a crucial role in shaping whether the outbreak turns global 9 . Moreover , it turns out that even minor alterations in the composition of the organization would substantially affect the finished outcome 10 , 11 .",
        "rewrite_text": "**Title: SIR Epidemics in Dynamic Contact Systems**\n\n**Abstract:** This study investigates the SIR (Susceptible-Infected-Recovered) epidemic model within the context of a dynamic contact network characterized by varying communication frequencies and survival probabilities. In our model, individuals have the flexibility to modify their connections over time, reflecting the complexities of real-world social interactions. We establish that when the infection rate significantly exceeds the recovery probability, a unique endemic equilibrium point emerges, which attracts all trajectories that begin within its basin of attraction. Conversely, for any initial conditions that lie outside this basin, we demonstrate that the infection will ultimately extinguish. Our findings are supported by numerical simulations that illustrate these dynamics.\n\nThe SIR model has been a fundamental mathematical framework for understanding the transmission of infectious diseases, including influenza and SARS. This deterministic compartmental model categorizes the population into three states: susceptible, infected, and recovered. Individuals transition between these states based on specific parameters that govern the outbreak's progression. Recent research has shifted focus towards the dynamics of infectious processes on complex networks, where nodes represent individuals and edges signify their interactions. These investigations highlight the critical role of network topology in modeling disease spread. For example, the presence of highly connected hubs can lead to the emergence of super-spreaders, individuals who significantly influence the potential for an outbreak to escalate into a widespread epidemic. Furthermore, our analysis reveals that even minor changes in the network's structure can have profound implications for the overall outcome of the epidemic. This work contributes to the understanding of infectious disease dynamics in evolving social systems and underscores the importance of considering network characteristics in epidemic modeling.",
        "ori-fast-z-score": 0.4123930494211613,
        "water-fast-z-score": 8.165382378538993,
        "rewrite-fast-z-score": 2.7791013395195128
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modelling the clumping-induced polarimetric variability of hot star winds .\nAbstract:\nWe present new results on modelling the effects of clumps in stellar winds on their observed linear and circular polarization signatures, using Monte Carlo radiative transfer simulations. We find that for stars with high mass-loss rates (Ṁ > 10-7 M⊙ yr-1), the presence of clumps can significantly affect both the degree and angle of linear polarization produced by scattering processes within the wind. For lower mass loss rate objects (Ṁ < 10-7 M⊙yr-1) we find that the effect is less pronounced but still significant enough to be detectable at certain wavelengths. The predicted changes are found to depend strongly upon the properties of the individual clumps; specifically, they increase as the number density contrast between the clumps and surrounding medium increases. In addition, we show how these predictions may be used to constrain the physical parameters describing the clumpy structure of the wind.  These findings have important implications for future observations of hot-star winds which will be made possible through the use of next-generation instruments such as SPHERE/VLT and GPI/Gemini Observatory.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modelling the clumping - caused polarimetric variability of bright star winds . Abstract : We report new data on modelling the effects of clumps in stellar winds on their observed linear and circular polarization signatures , using Monte Carlo radiative transfer simulations .We see that for stellar with high mass - loss rates ( [UNK] > 10 - 7 [UNK] yr - 1 ) , the presence of clumps can significantly affect both the degree and angle of linear polarization produced by scattering mechanisms within the wind . For lower mass loss rate objects ( [UNK] < 10 - 7 [UNK] - 1 ) we find that the impact is fewer severe but still significant enough to be detectable at given wavelengths .The predicted changes are found to depend greatly upon the properties of the individual clumps ; particular , they rise as the number density contrast between the clumps and surrounding medium increases . In addition , we study how these predictions may be used to constrain the physical factors describing the clumpy composition of the wind .These studies have important implications for future discoveries of bright - star winds which will be made possible through the using of next - generation satellites such as SPHERE / VLT and GPI / Gemini Observatory .",
        "rewrite_text": "Title: Modeling the Polarimetric Variability Induced by Clumping in Stellar Winds\n\nAbstract: In this study, we present new insights into the influence of clumps within stellar winds on the observed linear and circular polarization signatures, employing Monte Carlo radiative transfer simulations. Our findings indicate that for stars exhibiting high mass-loss rates (greater than 10^-7 solar masses per year), the presence of clumps can markedly alter both the degree and angle of linear polarization resulting from scattering processes in the wind. Conversely, for stars with lower mass-loss rates (less than 10^-7 solar masses per year), the effects are less pronounced but still significant enough to be detected at specific wavelengths. The variations in polarization are found to be highly dependent on the characteristics of the individual clumps, particularly increasing with the contrast in number density between the clumps and the surrounding medium. Furthermore, we explore how these predicted changes can be utilized to constrain the physical parameters that define the clumpy nature of stellar winds. Our research holds substantial implications for the future exploration of bright star winds, particularly with the advent of next-generation observational instruments such as SPHERE at the VLT and GPI at the Gemini Observatory. These advancements will enhance our understanding of the complex dynamics of stellar winds and their polarization characteristics, paving the way for new discoveries in the field of astrophysics.",
        "ori-fast-z-score": 0.30779350562554625,
        "water-fast-z-score": 4.694855340334425,
        "rewrite-fast-z-score": -1.1055415967851332
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Evolution of Protoplanetary Disks Around Millisecond Pulsars: The PSR 1257 +12 System .\nAbstract:\nWe present new observations and analysis of the pulsar–disk system PSR 1257+12, which is one of only two known systems in which a millisecond radio pulsar orbits around an evolved star (a white dwarf). We have obtained high-resolution near-infrared images with adaptive optics at Keck Observatory that reveal a bright ring-like structure surrounding the pulsar s position. This feature has been interpreted as emission from dust grains orbiting within the disk produced by the supernova explosion that created both stars. \n \n In addition to this ring, we detect faint extended emission extending out to several hundred AU on either side of the central source. These features are consistent with previous results based on lower resolution data. However, our higher spatial resolution reveals additional details about these structures. For example, we find evidence for spiral arms in the outer regions of the disk, which may be caused by gravitational interactions between the disk and the binary companion.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Evolution of Protoplanetary Disks Around Millisecond Pulsars : The PSR 1257 + 12 System . Abstract : We report new studies and investigation of the pulsar – disk system PSR 1257 + 12 , which is one of only two known systems in which a millisecond radio pulsar orbits around an evolved star ( a white dwarf ) .We have discovered high - resolution near - infrared images with adaptive optics at Keck Observatory that indicate a bright ring - like structure surrounding the pulsar s position . This phenomenon has been viewed as emission from dust grains orbiting within the disk produced by the supernova explosion that created both stars .In addition to this belt , we perceive slight extended emission stretching out to several hundred AU on either side of the main source . These features are consistent with previous findings based on lower resolution data .However , our higher spatial resolution shows new details about these structures . For instance , we find proof for spiral arms in the exterior areas of the disk , which may be caused by gravitational interactions between the disk and the binary companion .",
        "rewrite_text": "Title: The Evolution of Protoplanetary Disks Around Millisecond Pulsars: The PSR 1257 + 12 System\n\nAbstract: In this study, we present our latest findings on the pulsar-disk system PSR 1257 + 12, one of only two known systems where a millisecond radio pulsar orbits an evolved star, specifically a white dwarf. Utilizing high-resolution near-infrared imaging with adaptive optics at the Keck Observatory, we have identified a prominent ring-like structure surrounding the pulsar's location. This structure is interpreted as emission from dust grains that are in orbit within a disk formed by the supernova explosion that resulted in the creation of both the pulsar and the white dwarf. Beyond this central ring, we also observe faint extended emissions that extend several hundred astronomical units (AU) on either side of the main source. These observations align with previous results obtained from lower resolution data; however, our high spatial resolution imaging has unveiled new details regarding these features. Notably, we have detected evidence of spiral arms in the outer regions of the disk, which may be attributed to gravitational interactions between the disk and its binary companion. This research enhances our understanding of the complex dynamics and evolution of protoplanetary disks around millisecond pulsars, shedding light on the processes that govern their formation and structure in the aftermath of supernova events. Our findings contribute to the broader field of astrophysics by providing insights into the interplay between stellar remnants and their surrounding material, thereby enriching the narrative of stellar evolution in binary systems.",
        "ori-fast-z-score": 0.2182178902359924,
        "water-fast-z-score": 4.0976453817306595,
        "rewrite-fast-z-score": 0.4703604341917986
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Massive perturbers and the efficient merger of binary massive black holes .\nAbstract:\nWe study the effects of large mass ratios on the evolution of binaries with two supermassive black holes (SMBHs). We find that, in general, SMBH binaries are efficiently driven to merge by their mutual gravitational radiation reaction force when they have comparable masses or one BH is much more massive than its companion. However, we also show that if there exists an additional perturber which has a mass ratio between 10 −3 and 1 relative to either of the SMBHs, then it can significantly affect the orbital decay rate of the SMBH binary system. In particular, for systems where both SMBHs have similar masses, such as those expected at galactic centers, the presence of a third body may lead to significant delay in the time required for the binary to merge due to gravitational wave emission. This effect could be important for understanding the formation history of some observed double-peaked AGNs. \n \n Keywords: Black hole - Binary black hole - Gravitational waves",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Massive perturbers and the efficient merger of binary massive black holes . Abstract : We research the effects of large mass ratios on the evolution of binaries with two supermassive black holes ( SMBHs ) .We see that , in general , SMBH binaries are efficiently driven to merge by their mutual gravitational radiation reaction energy when they have equivalent masses or one BH is much more massive than its companion . However , we also demonstrate that if there exists an additional perturber which has a mass ratio between 10 −3 and 1 relative to either of the SMBHs , then it can significantly affect the orbital decay rate of the SMBH binary system .In particular , for systems where both SMBHs have equivalent masses , such as those expected at galactic complexes , the presence of a third body may contribute to significant pause in the period necessary for the binary to unite due to gravitational wave radiation . This phenomenon might be crucial for knowledge the formation history of some observed double - peaked AGNs .Keywords : Black hole - Binary black hole - Gravitational waves",
        "rewrite_text": "Title: Massive Perturbers and the Efficient Merger of Binary Massive Black Holes\n\nAbstract: In this study, we investigate the influence of large mass ratios on the dynamics of binary systems composed of two supermassive black holes (SMBHs). Our findings indicate that SMBH binaries typically experience efficient merging driven by the gravitational radiation reaction energy, particularly when the masses of the black holes are comparable or when one black hole is significantly more massive than its counterpart. However, we reveal that the presence of an additional perturber, with a mass ratio ranging from 10^-3 to 1 relative to either of the SMBHs, can markedly alter the rate of orbital decay within the binary system. Specifically, in scenarios where both SMBHs possess similar masses—common in galactic centers—the introduction of a third body can lead to a notable delay in the time required for the binary to coalesce due to the effects of gravitational wave radiation. This delay may have significant implications for our understanding of the formation history of certain observed double-peaked active galactic nuclei (AGNs). Our results underscore the importance of considering additional massive perturbers in the evolution of SMBH binaries, as they can play a critical role in the merger process and the subsequent observational signatures of these systems. This research contributes to the broader field of astrophysics by enhancing our comprehension of the complex interactions that govern the dynamics of supermassive black hole binaries and their environments. \n\nKeywords: Black hole, Binary black hole, Gravitational waves.",
        "ori-fast-z-score": 0.4364357804719848,
        "water-fast-z-score": 3.4914862437758782,
        "rewrite-fast-z-score": 2.3728949893812477
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Supersymmetric Parameter Space in Light of B-physics Observables and Electroweak Precision Data .\nAbstract:\nWe present the results of our analysis on the supersymmetric parameter space, taking into account all available experimental data including those from LHC experiments as well as electroweak precision observables (EWPO). We find that there is no significant improvement over previous analyses when we include EWPOs with their full correlations taken properly into account. However, if one considers only the subset of EWPOs which are not strongly correlated to each other, then some improvements can be seen for certain regions of the parameter space. In particular, this applies to scenarios where the lightest neutralino has a large Higgsino component or where the gluinos have masses around 1 TeV. The latter case also leads to an improved agreement between theory predictions and measurements of the anomalous magnetic moment of the muon. Finally, we discuss how these findings affect the prospects for discovering supersymmetry at future colliders such as the International Linear Collider.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Supersymmetric Parameter Space in Light of B - physics Observables and Electroweak Precision Data . Abstract : We present the results of our analysis on the supersymmetric parameter space , using into consideration all available theoretical data including those from LHC observations as well as electroweak accuracy observables ( EWPO ) .We see that there is no considerable progress over past analyses when we include EWPOs with their full correlations took correctly into consideration . However , if one looks only the subset of EWPOs which are not closely correlated to each other , then some improvements can be shown for particular regions of the parameter room .In particular , this applicable to scenarios where the lightest neutralino has a large Higgsino component or where the gluinos have masses around 1 TeV . The last example also leads to an better agreement between theoretical estimates and measurements of the anomalous magnetic moment of the muon .Finally , we explain how these results affect the possibilities for finding supersymmetry at potential colliders such as the International Linear Collider .",
        "rewrite_text": "In this article, we delve into the analysis of the supersymmetric parameter space, taking into account a comprehensive range of theoretical data, including insights from LHC observations and electroweak precision observables (EWPO). Our findings indicate that incorporating EWPOs with their full correlations does not yield significant advancements compared to previous analyses. However, when we focus on a specific subset of EWPOs that exhibit minimal correlation with one another, we observe notable improvements in certain regions of the parameter space. This is particularly evident in scenarios where the lightest neutralino possesses a substantial Higgsino component or when gluinos have masses around 1 TeV. Notably, the latter scenario enhances the alignment between theoretical predictions and experimental measurements of the muon's anomalous magnetic moment. Additionally, we discuss the implications of our results for the potential discovery of supersymmetry at future colliders, such as the International Linear Collider. Our analysis underscores the importance of carefully selecting observables to optimize the exploration of supersymmetry, highlighting both the challenges and opportunities that lie ahead in this field of research.",
        "ori-fast-z-score": -3.6927447293799815,
        "water-fast-z-score": 4.275930552470682,
        "rewrite-fast-z-score": 0.35603449745815596
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Tidal dwarf galaxies as a test of fundamental physics .\nAbstract:\nWe present the results of N-body simulations aimed at studying tidal disruption and accretion in interacting galaxy pairs, with particular emphasis on the formation of tidally stripped dwarfs (TDGs). We find that TDG formation is strongly dependent upon the orbital parameters of the interaction; specifically, we show that TDGs form only when the encounter has an impact parameter less than about twice the sum of their effective radii.  In addition to this dependence on orbital geometry, our models suggest that TDGs are more likely to be formed if the progenitor galaxies have high gas fractions and/or low central surface brightnesses. Finally, we argue that TDGs may provide useful probes for testing theories of gravity on galactic scales. The discovery of numerous examples of  tidal dwarf galaxies  (TDGs) over the past decade or so has led many authors to propose these objects as possible sites of star formation during interactions between massive spiral galaxies. However, despite considerable observational effort, there remains no consensus regarding either the frequency of TDG formation or even whether such systems actually exist outside the confines of numerical simulations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Tidal dwarf galaxies as a test of fundamental physics . Abstract : We present the conclusion of N - bodies simulations aiming at studying tidal disruption and accretion in correlated galaxy pairs , with particular focuses on the formation of tidally stripped dwarfs ( TDGs ) .We see that TDG formation is strongly dependent upon the orbital characteristics of the interaction ; specifically , we find that TDGs form only when the encounter has an impact parameter less than about twice the sum of their effective radii . In addition to this dependence on orbital geometry , our calculations suggest that TDGs are more likely to be formed if the progenitor galaxies have greater gas fractions and / or low central exterior brightnesses .Finally , we argue that TDGs might represent helpful probes for studying concepts of gravitational on galactic scales . The observation of several examples of tidal dwarf stars ( TDGs ) over the previous decade or so has led many writers to propose these objects as possible areas of galaxy formation during interactions between massive spiral nuclei .However , despite considerable observational effort , there exists no discussion regarding either the frequency of TDG formation or even whether such systems actually appear outside the confines of computational simulations .",
        "rewrite_text": "In this article, we present the findings from our N-body simulations aimed at investigating tidal disruption and accretion processes in interacting galaxy pairs, with a particular emphasis on the formation of tidal dwarf galaxies (TDGs). Our research reveals that the formation of TDGs is significantly influenced by the orbital dynamics of the interacting galaxies. Specifically, we determine that TDGs are likely to form only when the impact parameter of the encounter is less than approximately twice the sum of the effective radii of the galaxies involved. Furthermore, our simulations indicate that the likelihood of TDG formation increases when the progenitor galaxies possess higher gas fractions and/or exhibit lower central surface brightness. \n\nWe propose that TDGs could serve as valuable probes for exploring fundamental gravitational concepts on galactic scales. Over the past decade, the observation of numerous TDGs has sparked interest among researchers, leading to the hypothesis that these structures may play a crucial role in galaxy formation during interactions between massive spiral galaxies. However, despite extensive observational studies, there remains a lack of comprehensive discussion regarding the frequency of TDG formation and whether these systems are observable beyond the realm of computational models. Our findings contribute to the understanding of TDGs and their potential significance in the broader context of galaxy evolution and dynamics, highlighting the need for further observational efforts to confirm their existence and frequency in the universe.",
        "ori-fast-z-score": -1.0101525445522108,
        "water-fast-z-score": 5.671711984196938,
        "rewrite-fast-z-score": 1.034792955221957
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nonsupersymmetric Brane/Antibrane Configurations in Type IIA and M Theory .\nAbstract:\nWe present nonsupersymmetric brane configurations in type IIA string theory, which are obtained by wrapping D-branes on supersymmetry-breaking cycles. We also discuss the corresponding configurations in M-theory. In particular we show that these configurations can be described as bound states of intersecting NS5-branes with orientifold 5-planes (or O6-planes). The latter are related to each other via T-duality transformations. Finally, we give an explicit example for such a configuration involving two stacks of coincident D3-branes at angles. This is done using the technique developed recently by Sen. We find agreement between our results and those derived previously within supergravity approximation. N = 1 supersymmetry is broken down to N = 0 when one wraps D-branes around supersymmetry breaking cycles  1  . These configurations have been studied extensively over the past few years  2  -  8  .\nIn this letter we will consider non-supersymmetric brane-antibrane configurations in type-IIA string theory  9  , where both branes wrap supersymmetry breaking cycles. Such configurations were first discussed in  10  . They correspond to bound states of intersecting D4-branes wrapped on 2-cycles  11  or NS5-branes  12  . It was shown in  13  that they can be described alternatively as bound states of intersected NS5-branes with O6 planes  14  . Here we will use the description given in terms of NS5-O6 systems  15  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nonsupersymmetric Brane / Antibrane Configurations in Type IIA and M Theory . Abstract : We create nonsupersymmetric brane configurations in type IIA string theory , which are derived by wrapping D - branes on supersymmetry - breaking cycles .We also discuss the equivalent configurations in M - theory . In particular we show that these structures can be described as bound states of intersecting NS5 - branes with orientifold 5 - planes ( or O6 - planes ) .The latter are related to each other via T - duality transformations . Finally , we give an explicit instance for such a configuration involving two stacks of coincident D3 - branes at angles .This is accomplished use the method developed ago by Sen . We get consensus between our findings and those generated previously within supergravity approximation . N = 1 supersymmetry is broken down to N = 0 when one wrapping D - branes around supersymmetry breaking cycles 1 .These arrangements have been studied thoroughly over the previous few years 2 - 8 . In this letter we will explore non - supersymmetric brane - antibrane configurations in type - IIA string theory 9 , where both branes wrap supersymmetry broken cycles .Such configurations were first explained in 10 . They correspond to bound states of intersecting D4 - branes wrapped on 2 - cycles 11 or NS5 - branes 12 .It was shown in 13 that they can be described additionally as bound states of intersected NS5 - branes with O6 planes 14 . Here we will use the description presented in terms of NS5 - O6 systems 15 .",
        "rewrite_text": "In this article, we investigate nonsupersymmetric brane configurations within the framework of type IIA string theory, specifically focusing on configurations that arise from wrapping D-branes around cycles that break supersymmetry. We extend our analysis to include the corresponding configurations in M-theory, demonstrating that these structures can be interpreted as bound states formed by intersecting NS5-branes and orientifold 5-planes (or O6-planes), which are interconnected through T-duality transformations. \n\nTo illustrate our findings, we present a specific example involving two stacks of coincident D3-branes arranged at angles, utilizing a method previously established by Sen. Our results align with earlier conclusions derived from supergravity approximations, confirming that the presence of wrapped D-branes on supersymmetry-breaking cycles leads to a reduction of N = 1 supersymmetry down to N = 0. \n\nThe study of these nonsupersymmetric configurations has gained significant attention over recent years, and in this letter, we delve into the brane-antibrane setups in type IIA string theory, where both branes are wrapped around cycles that break supersymmetry. The foundational concepts for these configurations were initially introduced in earlier works, where they were identified as bound states of intersecting D4-branes wrapped on 2-cycles or NS5-branes. Furthermore, it has been established that these configurations can also be described as bound states of intersecting NS5-branes with O6-planes. In this paper, we will adopt the NS5-O6 system framework to provide a comprehensive understanding of these nonsupersymmetric brane-antibrane configurations, contributing to the ongoing discourse in the field of string theory.",
        "ori-fast-z-score": 0.4216370213557839,
        "water-fast-z-score": 5.059644256269407,
        "rewrite-fast-z-score": 1.6
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Reduced Complexity Sphere Decoding for Square QAM via a New Lattice Representation .\nAbstract:\nWe propose an efficient reduced complexity sphere decoding (RSD) algorithm for square quadrature amplitude modulation (QAM). The proposed RSD is based on the new lattice representation, which can be viewed as a generalization of the well-known real-valued lattice representation to complex-valued lattices. We show that our RSD has lower computational complexity than existing algorithms in terms of both number of arithmetic operations and memory requirement. In addition, we demonstrate by simulation results that our RSD achieves better bit error rate performance over conventional RSDs at high signal-to-noise ratio region. Finally, we provide some insights into how to further reduce the computational complexity of our RSD without sacrificing its BER performance. Index Terms - Reduced complexity sphere decoding, Quadrature amplitude modulation, Computational complexity reduction, Bit error rate performance improvement. I. INTRODUCTIO N Quadrature amplitude modulation (Q AM )  1  , also known as phase-shift keying (PSK), is one of the most popular digital modulations used in wireless communications due to its simple implementation  2  . However, it suffers from poor power efficiency when compared with other high-order constellations such as 16-QAM or 64-QAM  3  .\nIn order to improve the power efficiency while maintaining good bit error rate (BER) performance, many research efforts have been made recently  4  -  8  . Among them, reduced complexity sphere decoding (RCSD)  9  -  11  plays an important role because RCSD provides near optimal BER performance with much less computational complexity than maximum-likelihood detection  12  . For example, the authors in  10  developed a novel RCSD scheme for square QAM using the so-called real-valued lattice representation  13  . It was shown in  14  that this approach requires only about half of the number of arithmetic operations required by the original RCSD  15  . Moreover, the authors in  16  showed that their RCSD outperforms the previous works  17  ,  19  in terms of BER performance under various channel conditions. Although these approaches are very promising, they still suffer from relatively large computational complexity especially at low-to-medium SNR",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Reduced Complexity Sphere Decoding for Square QAM via a New Lattice Representation . Abstract : We suggest an efficient reduced complexity sphere decoding ( RSD ) algorithm for square quadrature amplitude modulation ( QAM ) .The proposed RSD is based on the new lattice representation , which can be viewed as a generalization of the better - famous real - valued lattice representation to complex - valued lattices . We see that our RSD has reduced computational complexity than existing algorithms in terms of both number of logic operations and memory need .In addition , we prove by simulation data that our RSD achieves good bit error rate quality over traditional RSDs at high noise - to - noise ratio region . Finally , we provide some insights into how to further reduce the numerical complexity of our RSD without sacrificing its BER performance .Index Terms - Reduced complexity sphere decoding , Quadrature amplitude modulation , Computational complexity reduction , Bit error rate quality increase . I . INTRODUCTIO N Quadrature amplitude modulation ( Q AM ) 1 , sometimes called as phase - shift keying ( PSK ) , is one of the most popular digital modulations used in mobile services due to its simple application 2 .However , it suffers from poor energy efficiency when compared with other high - order constellations such as 16 - QAM or 64 - QAM 3 . In order to upgrade the power performance while maintaining good bit error rate ( BER ) performance , various study efforts have been made recently 4 - 8 .Among them , low complexity sphere decoding ( RCSD ) 9 - 11 provides an important role because RCSD presents near perfect BER performance with far lower mathematical complexity than maximum - likelihood recognition 12 . For instance , the writers in 10 developed a new RCSD system for square QAM using the so - called real - valued lattice representation 13 .It was shown in 14 that this methodology demands only about half of the number of arithmetic functions needed by the previous RCSD 15 . Moreover , the writers in 16 demonstrated that their RCSD outperforms the previous works 17 , 19 in terms of BER performance under various channel conditions .Although these method are very promising , they still suffer from fairly large numerical capacity especially at low - to - medium SNR",
        "rewrite_text": "**Title:** Reduced Complexity Sphere Decoding for Square QAM via a New Lattice Representation\n\n**Abstract:** In this paper, we introduce an innovative reduced complexity sphere decoding (RSD) algorithm tailored for square quadrature amplitude modulation (QAM). Our proposed RSD leverages a novel lattice representation that extends the well-established real-valued lattice framework to accommodate complex-valued lattices. This advancement significantly decreases computational complexity compared to existing algorithms, as evidenced by a reduction in both the number of logical operations and memory requirements. Through extensive simulations, we demonstrate that our RSD achieves superior bit error rate (BER) performance in high noise-to-noise ratio environments when compared to traditional RSD methods. Furthermore, we explore strategies to further minimize the numerical complexity of our RSD while preserving its BER efficacy. Quadrature amplitude modulation (QAM), often referred to as phase-shift keying (PSK), is widely utilized in mobile communication due to its straightforward implementation. However, it is known to exhibit lower energy efficiency relative to higher-order constellations like 16-QAM and 64-QAM. Recent research has focused on enhancing power performance while ensuring robust BER outcomes. Among various approaches, reduced complexity sphere decoding (RCSD) has emerged as a pivotal technique, offering near-optimal BER performance with significantly lower mathematical complexity than maximum-likelihood detection. Previous studies have developed RCSD systems for square QAM using real-valued lattice representations, achieving notable reductions in arithmetic operations. Despite these advancements, existing methods still encounter considerable numerical complexity, particularly in low-to-medium signal-to-noise ratio (SNR) scenarios. Our work addresses these challenges by presenting a more efficient RSD algorithm that not only improves computational efficiency but also enhances BER performance, paving the way for more effective applications of QAM in mobile communication systems.\n\n**Index Terms:** Reduced complexity sphere decoding, Quadrature amplitude modulation, Computational complexity reduction, Bit error rate quality increase.",
        "ori-fast-z-score": 1.3315427649795275,
        "water-fast-z-score": 8.74573066576194,
        "rewrite-fast-z-score": 1.8973665961010275
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Galactic Wind Signatures around High Redshift Galaxies .\nAbstract:\nWe present the results of an analysis of deep Chandra X-ray Observatory observations of two high redshift galaxies, MS1512-cB58 and APM 08279+5255 (z = 3.91). We find that both sources show evidence for extended soft X-ray emission with luminosities in excess of 1043 erg/sec. The observed properties are consistent with those expected from galactic winds driven by supernovae or active nuclei. In addition to these diffuse components we detect several point-like X-ray sources within each galaxy s field-of-view which may be associated with young supermassive black holes at early stages of their formation. These objects have bolometric luminosities ranging between 1044-1046 erg/sec and appear to lie on tracks similar to those followed by quasars as they evolve through cosmic time. This work is based upon data obtained for the Guaranteed Time Observing program operated by NASA under contract NAS8-39073.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Galactic Wind Signatures around High Redshift Galaxies . Abstract : We report the conclusion of an assessment of deep Chandra X - ray Observatory surveys of two high redshift galaxies , MS1512 - cB58 and APM 08279 + 5255 ( z = 3 . 91 ) .We see that both sources show data for extended soft X - ray radiation with luminosities in excess of 1043 erg / sec . The observed properties are compatible with those expected from galactic winds driven by supernovae or active clusters .In addition to these diffuse components we perceive several point - like X - ray sources within each galaxy s field - of - view which may be identified with young supermassive black holes at early stages of their formed . These bodies have bolometric luminosities ranging between 1044 - 1046 erg / sec and tend to lay on tracks similar to those followed by quasars as they develop through cosmic time .This project is based upon statistics obtained for the Guaranteed Time Observing program operated by NASA under contract NAS8 - 39073 .",
        "rewrite_text": "In this study, we present the findings from an analysis of deep X-ray observations conducted by the Chandra X-ray Observatory on two high redshift galaxies, MS1512-cB58 and APM 08279+5255, with a redshift of z = 3.91. Our investigation reveals that both galaxies exhibit extended soft X-ray emissions, characterized by luminosities exceeding 10^43 erg/sec. These emissions align with theoretical predictions for galactic winds that are likely driven by supernova activity or the influence of active galactic nuclei. \n\nFurthermore, our observations have identified several point-like X-ray sources within the fields of these galaxies, which we propose may correspond to young supermassive black holes in the early stages of their formation. These black holes demonstrate bolometric luminosities ranging from 10^44 to 10^46 erg/sec, and their properties suggest a developmental trajectory akin to that of quasars as they evolve over cosmic time. \n\nThis research is grounded in data collected through the Guaranteed Time Observing program, which is managed by NASA under contract NAS8-39073. The implications of our findings contribute to the understanding of galactic evolution and the role of supermassive black holes in the early universe, shedding light on the processes that govern the formation and growth of galaxies at high redshifts. Our results underscore the significance of X-ray observations in probing the energetic phenomena associated with galactic winds and the nascent stages of black hole development in the cosmos.",
        "ori-fast-z-score": -0.1203858530857692,
        "water-fast-z-score": 5.019960159204453,
        "rewrite-fast-z-score": 2.424366106925306
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Propagation of travelling waves in sub-excitable systems driven by noise and periodic forcing .\nAbstract:\nWe study the propagation of traveling waves (TWs) in excitable media with spatially distributed parameters, which are subject to both external forcing and internal fluctuations. We show that TWs can be generated spontaneously even if there is no deterministic source for them. The mechanism responsible for this phenomenon is related to the presence of an unstable stationary state between two stable ones. In particular, we demonstrate how spontaneous generation of TWs occurs due to stochastic resonance induced by additive white Gaussian noise. Finally, we present numerical results illustrating the effect of multiplicative colored noise on the dynamics of TWs. Propagation of traveling waves (TW) in excitable media has been studied extensively over recent years  1  . It was shown that TWs may appear as a result of various mechanisms such as: i) intrinsic instabilities  2  , ii) coupling-induced instabilities  3  or iii) forced oscillations  4  .\nIn many cases it is assumed that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates. However, real physical systems usually have spatial variations of their characteristics  5  . For example, one-dimensional models describing cardiac tissue  6  include heterogeneity in the form of local changes in refractory periods  7, 8  . Another important factor influencing wave propagation is noise  9  . Noise plays different roles depending on whether it acts additively  10  or multiplicatively  11  . Moreover, noise may also affect the shape of the propagating front  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Propagation of travelling waves in sub - excitable environments driven by noise and periodic forcing . Abstract : We research the propagation of traveling signals ( TWs ) in excitable media with spatially scattered characteristics , which are subject to both external forcing and internal fluctuations .We see that TWs can be formed spontaneously even if there is no deterministic source for them . The pathway responsible for this phenomenon is related to the presence of an weak stationary state between two stable ones .In particular , we prove how spontaneous production of TWs occurs due to stochastic resonance caused by additive white Gaussian noise . Finally , we present numerical findings illustrating the impact of multiplicative colored noise on the dynamics of TWs .Propagation of traveling signals ( TW ) in excitable media has been studied extensively over recent years 1 . It was shown that TWs might appear as a outcome of several mechanisms such as : i ) inherent instabilities 2 , ii ) coupling - caused instabilities 3 or iii ) forced oscillations 4 .In many situations it is expected that the medium under consideration is homogeneous so that all its properties do not depend explicitly on space coordinates . However , real physical structures typically have spatial variations of their characteristics 5 .For instance , one - dimensional experiments describing cardiac tissue 6 include heterogeneity in the form of local changes in refractory intervals 7 , 8 . Another important factor influencing wave propagation is sound 9 .Noise takes multiple roles depending on whether it functions additively 10 or multiplicatively 11 . Moreover , noise might additionally affect the morphology of the propagating front 12 .",
        "rewrite_text": "**Title:** Propagation of Traveling Waves in Sub-Excitable Environments Driven by Noise and Periodic Forcing\n\n**Abstract:** This study investigates the dynamics of traveling waves (TWs) in excitable media characterized by spatial heterogeneity and influenced by both external periodic forcing and internal stochastic fluctuations. We demonstrate that TWs can emerge spontaneously in the absence of a deterministic source, a phenomenon attributed to the existence of a weak stationary state situated between two stable states. Our analysis reveals that the spontaneous generation of TWs is facilitated by stochastic resonance, particularly in the presence of additive white Gaussian noise. Furthermore, we present numerical simulations that explore the effects of multiplicative colored noise on the behavior and propagation of TWs. \n\nThe propagation of TWs in excitable media has garnered significant attention in recent years, with various mechanisms identified as potential sources for their emergence. These mechanisms include inherent instabilities, instabilities induced by coupling, and forced oscillations. While many theoretical models assume a homogeneous medium where properties are uniform across space, real-world systems often exhibit spatial variability. For example, one-dimensional studies of cardiac tissue highlight heterogeneities such as localized variations in refractory periods. Additionally, the role of noise in wave propagation is multifaceted, influencing the system both additively and multiplicatively, and can also alter the morphology of the traveling wave front. \n\nOur findings contribute to a deeper understanding of how noise and periodic forcing interact with the intrinsic properties of excitable media, leading to the emergence of TWs. This research not only enhances the theoretical framework surrounding wave dynamics in heterogeneous environments but also has implications for practical applications in fields such as biology and materials science, where understanding wave propagation is crucial.",
        "ori-fast-z-score": 0.3621429841700741,
        "water-fast-z-score": 7.123190113872715,
        "rewrite-fast-z-score": 2.806585661782494
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Diffuse Optical Light in Galaxy Clusters II: Correlations with Cluster Properties .\nAbstract:\nWe present the results on diffuse optical light (DOL) correlations with cluster properties for a sample of galaxy clusters observed by the Hubble Space Telescope Advanced Camera for Surveys and Spitzer Infrared Array Camera. We find that DOL correlates positively with X-ray luminosity, temperature, mass, velocity dispersion, and Sunyaev-Zel dovich effect flux decrement at 1.4 GHz. The correlation between DOL and X-ray luminosity is stronger than those found previously using ground-based data. These results suggest that DOL traces hot gas in galaxy clusters. This work was supported by NASA grant NNX08AG84G to Columbia University. We thank J. Richard McNamara for providing us with his Chandra observations of Abell 1689. We also acknowledge useful discussions with A. Vikhlinin. \n \n Keywords: Diffuse optical light; Galaxy clusters; Dark matter halos",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Diffuse Optical Light in Galaxy Clusters II : Correlations with Cluster Properties . Abstract : We report the results on diffuse optical light ( DOL ) correlations with cluster structures for a sample of galaxy galaxies studied by the Hubble Space Telescope Advanced Camera for Surveys and Spitzer Infrared Array Camera .We see that DOL correlates positively with X - ray luminosity , temperature , mass , speed dispersion , and Sunyaev - Zel dovich impact flux decrement at 1 . 4 GHz . The relationship between DOL and X - ray luminosity is greater than those identified previously used ground - based data .These data suggest that DOL marks hot gas in galaxy regions . This research was supported by NASA award NNX08AG84G to Columbia University .We praise J . Richard McNamara for providing us with his Chandra measurements of Abell 1689 . We additionally admit valuable discussions with A . Vikhlinin .Keywords : Diffuse optical light ; Galaxy clusters ; Dark matter halos",
        "rewrite_text": "Title: Diffuse Optical Light in Galaxy Clusters II: Correlations with Cluster Properties\n\nAbstract: In this study, we present our findings on the correlations between diffuse optical light (DOL) and various structural properties of galaxy clusters, utilizing data obtained from the Hubble Space Telescope's Advanced Camera for Surveys and the Spitzer Infrared Array Camera. Our analysis reveals a significant positive correlation between DOL and several key cluster characteristics, including X-ray luminosity, temperature, mass, velocity dispersion, and the Sunyaev-Zel'dovich effect's impact flux decrement at 1.4 GHz. Notably, the correlation between DOL and X-ray luminosity is stronger than those reported in previous studies that relied on ground-based observations. These results imply that DOL serves as an indicator of the presence of hot gas within galaxy cluster regions. The research was conducted with the support of NASA award NNX08AG84G to Columbia University. We extend our gratitude to J. Richard McNamara for sharing his Chandra measurements of Abell 1689, and we acknowledge the insightful discussions with A. Vikhlinin that contributed to this work. \n\nKeywords: Diffuse optical light; Galaxy clusters; Dark matter halos.",
        "ori-fast-z-score": -1.2135597524338357,
        "water-fast-z-score": 5.3452248382484875,
        "rewrite-fast-z-score": -1.5882027766319677
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Optical Variability of Infrared Power Law-Selected Galaxies & X-ray Sources in the GOODS-South Field .\nAbstract:\nWe present optical variability measurements for infrared power law-selected galaxies and X-ray sources in the Chandra Deep Field South (CDFS). We use data obtained with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts, rest-frame absolute magnitudes, stellar masses, star formation rates, and specific star-formation rates for these objects over an eight-year baseline. The sample consists of 16,000 galaxies at 0 < z < 5 selected by their mid-infrared colors using Spitzer/IRAC observations as well as 1,500 X-ray point sources detected in deep Chandra observations. We find that both galaxy samples show significant levels of intrinsic variation on timescales ranging from days to years. For example, we detect more than 50% of our IRAC-selected galaxies at 3.6 microns and 80% at 4.5 microns showing >0.1 mag variations between epochs separated by one year or less. These results are consistent with previous studies which have found similar levels of variability among optically-selected quasars. However, we also find evidence suggesting that this level of variability is not driven solely by AGN activity but may be associated with other physical processes such as mergers and/or interactions within the host galaxy itself.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Optical Variability of Infrared Power Law - Selected Galaxies & X - ray Sources in the GOODS - South Field . Abstract : We report optical variability observations for infrared energy law - selected galaxies and X - ray sources in the Chandra Deep Field South ( CDFS ) .We use data acquired with the Hubble Space Telescope s Advanced Camera for Surveys to measure photometric redshifts , rest - frame relative magnitudes , stellar masses , sun formation rates , and particular galaxy - formation rates for these objects over an eight - year baseline . The sample consists of 16 , 000 galaxies at 0 < z < 5 selected by their mid - infrared colors using Spitzer / IRAC measurements as also as 1 , 500 X - ray point sources detected in deep Chandra measurements .We see that both universe samples show considerable rates of intrinsic variation on timescales ranging from weeks to decades . For instance , we find more than 50 % of our IRAC - selected galaxies at 3 . 6 microns and 80 % at 4 . 5 microns showing > 0 . 1 mag variations between epochs separated by one month or greater .These conclusions are compatible with previous research which have discovered similar rates of variability among optically - selected quasars . However , we also find proof suggesting that this level of variability is not driven solely by AGN activity but might be involved with other physical processes such as mergers and / or relationships within the host star itself .",
        "rewrite_text": "We present our findings on the optical variability of infrared power law-selected galaxies and X-ray sources located in the Chandra Deep Field South (CDFS). Utilizing data from the Hubble Space Telescope's Advanced Camera for Surveys, we conducted a comprehensive analysis over an eight-year period to derive key parameters such as photometric redshifts, rest-frame relative magnitudes, stellar masses, star formation rates, and specific galaxy formation rates for our sample. Our study encompasses a total of 16,000 galaxies with redshifts ranging from 0 to 5, selected based on their mid-infrared colors through Spitzer/IRAC measurements, alongside 1,500 X-ray point sources identified in deep Chandra observations. \n\nOur results reveal significant intrinsic variability within both samples, occurring over timescales from weeks to decades. Notably, we observe that over 50% of the IRAC-selected galaxies at 3.6 microns and approximately 80% at 4.5 microns exhibit variations exceeding 0.1 magnitudes between observations taken at least one month apart. These findings align with earlier studies that reported similar variability rates among optically-selected quasars. However, our investigation also uncovers evidence indicating that this degree of variability may not be exclusively attributed to active galactic nucleus (AGN) activity. Instead, it suggests the potential influence of additional physical processes, such as galaxy mergers and interactions within the host stars themselves. This research contributes to a deeper understanding of the dynamic processes affecting galaxy evolution and the role of various mechanisms in driving optical variability in these astronomical objects.",
        "ori-fast-z-score": -1.116880781646981,
        "water-fast-z-score": 5.858884758402822,
        "rewrite-fast-z-score": 1.025755289064345
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Bondi accretion in the early universe .\nAbstract:\nWe present an analysis of the Bondi accretion rate onto primordial black holes (PBHs) during the radiation-dominated era, taking into account the effects of pressure and viscosity on the gas flow. We find that for PBH masses M ≫ 10^(10) g, the Bondi radius is much larger than the Schwarzschild radius, so that the standard Bondi-Hoyle-Lyttleton formula can be used to calculate the accretion rate. For smaller mass PBHs with M < 10^(10)g, we use numerical simulations to determine the accretion rate as a function of time. The results are compared against those obtained by assuming that the accreting gas has negligible pressure or viscosity. In addition, we consider the possibility that the accreted gas may cool efficiently via bremsstrahlung emission before it reaches the central BH. Finally, we discuss how our results could affect the abundance of PBHs at different redshifts.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Bondi accretion in the early universe . Abstract : We present an assessment of the Bondi accretion rate onto primordial black holes ( PBHs ) during the radiation - dominated period , giving into consideration the effects of force and viscosity on the gas stream .We see that for PBH masses M [UNK] 10 ^ ( 10 ) g , the Bondi diameter is much larger than the Schwarzschild diameter , so that the standard Bondi - Hoyle - Lyttleton formula can be used to estimate the accretion rate . For lower mass PBHs with M < 10 ^ ( 10 ) g , we using numerical simulations to estimate the accretion rate as a function of time .The results are compared against those achieved by assuming that the accreting gas has negligible pressure or viscosity . In addition , we investigate the prospect that the accreted gas may cool efficiently via bremsstrahlung emission before it enters the main BH .Finally , we explain how our findings may affect the availability of PBHs at different redshifts .",
        "rewrite_text": "In this article, we explore the Bondi accretion process onto primordial black holes (PBHs) during the radiation-dominated era of the early universe. Our analysis takes into account the influences of both force and viscosity on the gas flow surrounding these black holes. We find that for PBHs with masses greater than approximately \\(10^{10}\\) grams, the Bondi diameter significantly exceeds the Schwarzschild diameter, allowing us to apply the conventional Bondi-Hoyle-Lyttleton formula to accurately estimate the accretion rate. Conversely, for PBHs with masses less than \\(10^{10}\\) grams, we employ numerical simulations to derive the accretion rate as a function of time, providing a more nuanced understanding of the dynamics involved. Our findings are juxtaposed with results obtained under the assumption that the accreting gas is devoid of pressure or viscosity, highlighting the importance of these factors in the accretion process. Additionally, we examine the potential for the accreted gas to cool efficiently through bremsstrahlung emission prior to its incorporation into the black hole, which could have significant implications for the thermal state of the gas and the overall accretion dynamics. Ultimately, our results contribute to a deeper understanding of how the characteristics of PBHs may evolve over time and how their abundance could vary at different redshifts, offering insights into the formation and growth of these enigmatic cosmic structures in the early universe.",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 5.093248125762992,
        "rewrite-fast-z-score": 0.8
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A new chaotic attractor in a basic multi-strain epidemiological model with temporary cross-immunity .\nAbstract:\nWe study the dynamics of an epidemic system consisting of two strains and three classes, susceptible (S), infected (I) and recovered/removed (R). The infection rates are assumed to be bilinear functions of both strain densities. We show that this system has a unique positive equilibrium which is globally asymptotically stable if one of the following conditions holds:\n(i) the recovery rate for each strain is greater than its corresponding infection rate; or \n(ii) there exists at least one strain whose recovery rate is equal to its infection rate. \nHowever, we prove that when condition (i) fails but condition (ii) holds true, then the system exhibits chaos through numerical simulations. Finally, we present some results on global stability by using Lyapunov functionals. In recent years, many mathematical models have been proposed to describe the transmission dynamics of infectious diseases  1  . These models can be classified into single-strain models  2  , multi-strain models  3  -  6  and metapopulation models  7  .\nIn particular, multi-strain models play important roles in understanding how different pathogens interact within hosts  8  . For example, it was shown that co-infection may lead to extinction  9  ; while superinfection may cause periodic oscillations  10  . Recently, Li et al.  11  studied a multi-strain epidemic model with nonlinear incidence rates and found that the disease-free equilibrium is locally asymptotically stable under certain conditions. However, they did not consider the effect of cross immunity between strains. Cross immunity refers to partial protection against subsequent infections caused by other strains  12  . It plays an important role in preventing epidemics  13  . Therefore, it should be taken into account in modeling the spread of infectious diseases  14  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A innovative chaotic attractor in a basic multi - strain epidemiological theory with temporary cross - immunity . Abstract : We research the dynamics of an outbreak structure comprised of two strains and three categories , susceptible ( S ) , infected ( I ) and returned / deleted ( R ) .The illness rates are assumed to be bilinear functions of both strain densities . We see that this scheme has a unique positive equilibrium which is internationally asymptotically stable if one of the following situations holds : ( i ) the recovery rate for each strain is greater than its corresponding infection rate ; or ( ii ) there exists at least one strain whose recovery rate is equal to its infection rate .However , we prove that when condition ( i ) fails but condition ( ii ) holds true , then the model shows chaos through numerical simulations . Finally , we present some results on world equilibrium by using Lyapunov functionals .In recent years , various computational models have been proposed to explain the spread dynamics of infectious infections 1 . These systems can be categorized into single - strain models 2 , multi - strain models 3 - 6 and metapopulation scenarios 7 .In particular , multi - strain models play crucial roles in understanding how various pathogens interact within hosts 8 . For instance , it was shown that co - infection would result to extinction 9 ; while superinfection might cause continuous oscillations 10 .Recently , Li et al . 11 studied a multi - strain outbreak model with nonlinear mortality rates and found that the infection - free equilibrium is locally asymptotically stable under certain conditions .However , they did not discuss the impact of cross immunity between varieties . Cross immunity means to temporary protection against subsequent infections caused by other varieties 12 .It acts an important role in preventing epidemics 13 . Therefore , it should be taken into consideration in measuring the spread of infectious infections 14 .",
        "rewrite_text": "**Title:** An Innovative Chaotic Attractor in a Basic Multi-Strain Epidemiological Theory with Temporary Cross-Immunity\n\n**Abstract:** This study investigates the dynamics of an outbreak model that incorporates two strains of a pathogen and categorizes the population into three groups: susceptible (S), infected (I), and recovered (R). The infection rates are modeled as bilinear functions of the densities of both strains. Our analysis reveals that the system possesses a unique positive equilibrium, which is globally asymptotically stable under specific conditions: either (i) the recovery rate for each strain exceeds its corresponding infection rate, or (ii) at least one strain has a recovery rate equal to its infection rate. However, we demonstrate that when condition (i) is not met but condition (ii) is satisfied, the model exhibits chaotic behavior, as evidenced by numerical simulations. Additionally, we explore the concept of world equilibrium using Lyapunov functionals. \n\nIn recent years, numerous computational models have been developed to elucidate the dynamics of infectious disease spread. These models can be classified into single-strain models, multi-strain models, and metapopulation frameworks. Multi-strain models, in particular, are essential for understanding the interactions between different pathogens within hosts. Previous research has indicated that co-infection can lead to pathogen extinction, while superinfection may result in persistent oscillations. Notably, a study by Li et al. examined a multi-strain outbreak model with nonlinear mortality rates, concluding that the infection-free equilibrium is locally asymptotically stable under certain conditions. However, their analysis did not account for the effects of cross-immunity, which refers to temporary protection against subsequent infections from different strains. Cross-immunity plays a critical role in mitigating the spread of epidemics and must be considered when assessing the dynamics of infectious diseases. This research contributes to the understanding of multi-strain epidemiological models by highlighting the significance of cross-immunity and its implications for disease control strategies.",
        "ori-fast-z-score": -0.5622535302317492,
        "water-fast-z-score": 7.478238471251862,
        "rewrite-fast-z-score": 1.556540648986177
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Fundamental-measure density functional for the fluid of aligned hard hexagons: New insights in fundamental measure theory .\nAbstract:\nWe present an accurate and efficient fundamental-measure density-functional (FMT) approach to describe fluids composed of rigidly-aligned hard hexagons, which are relevant as model systems for liquid crystals or colloidal suspensions with anisotropic interactions. The FMT is based on a decomposition into three different types of weighted densities that can be evaluated efficiently using fast Fourier transforms. We show how this new FMT yields excellent results compared to Monte Carlo simulations over wide ranges of packing fractions and orientations of the particles. In particular we find very good agreement between our theoretical predictions and simulation data at high packing fractions where previous approaches fail due to strong correlations among neighboring particles. Finally, we demonstrate that our method also allows us to accurately predict structural properties such as pair correlation functions and orientational order parameters. This work provides further evidence that FMTs provide a powerful tool to study complex fluids beyond simple spherical particle models. \nI. INTRODUCTORY REMARkS\nThe description of liquids and soft matter requires sophisticated methods because these materials often exhibit complex structures and dynamics. Density functionals have been developed during recent years as promising tools to tackle many-body problems in statistical mechanics  1  . They allow one to calculate equilibrium properties of interacting particles by minimizing a free energy functional with respect to the local number density distribution. A particularly successful class of density functionals are so-called fundamental-measure density-functionals (FMD), which were originally introduced by Rosenfeld  2  .\nIn their original form they only apply to fluids consisting of identical spheres but extensions to more complicated shapes like ellipsoids  3  , rods  4  , dumbbells  5  , spherocylinders  6  , and even patchy particles  7, 8  have been proposed recently. However, most of these works focus on the case of uniaxial symmetry while there exist few studies dealing with more general situations  9  . Here we consider a system of rigidly-aligned",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Fundamental - measure density functional for the liquid of aligned hard hexagons : New ideas in fundamental measure theory . Abstract : We present an accurate and efficient fundamental - measure density - functional ( FMT ) approach to define liquid contained of rigidly - aligned hard hexagons , which are important as model structures for solid crystals or colloidal suspensions with anisotropic interactions .The FMT is based on a transformation into three different kinds of weighted densities that can be evaluated efficiently using fast Fourier transforms . We see how this new FMT yields good results relative to Monte Carlo simulations over broad ranges of packing fractions and orientations of the particles .In particular we find very high agreement between our theory estimates and modeling data at high packing fractions where earlier approaches fail due to heavy correlations among neighboring particles . Finally , we prove that our technique also enables us to correctly forecast structural properties such as couple correlation functions and orientational order variables .This research provides further evidence that FMTs represent a powerful tool to study difficult fluids beyond straightforward spherical particle models . I .INTRODUCTORY REMARkS The description of liquids and dark matter requires sophisticated methods because these structures often exhibit intricate structures and dynamics . Density functionals have been used during recent years as promising tools to tackle many - bodies problems in mathematical mechanics 1 .They allow one to estimate equilibrium properties of interacting molecules by minimizing a free energy functional with regard to the local number density distribution . A notably famous class of density functionals are so - called fundamental - measure density - functionals ( FMD ) , which were first developed by Rosenfeld 2 .In their original form they only applicable to liquid consisting of identical spheres but extensions to more complicated forms like ellipsoids 3 , rods 4 , dumbbells 5 , spherocylinders 6 , and sometimes patchy particles 7 , 8 have been proposed lately . However , most of these works concentrate on the case of uniaxial symmetry while there remain few researchers dealing with more general situations 9 .Here we define a system of rigidly - aligned",
        "rewrite_text": "**Title:** Fundamental Measure Density Functional for the Liquid of Aligned Hard Hexagons: New Insights in Fundamental Measure Theory\n\n**Abstract:** In this study, we introduce a novel and efficient fundamental measure density functional (FMT) framework tailored for liquids composed of rigidly aligned hard hexagons. These hexagonal structures serve as significant models for understanding solid crystals and colloidal suspensions characterized by anisotropic interactions. Our FMT approach is predicated on a transformation into three distinct types of weighted densities, which can be computed rapidly using fast Fourier transforms. We demonstrate that this innovative FMT method produces results that closely align with Monte Carlo simulation data across a wide spectrum of packing fractions and particle orientations. Notably, our findings indicate a remarkable agreement between theoretical predictions and empirical data at high packing fractions, a regime where previous methodologies often falter due to the strong correlations present among neighboring particles. Furthermore, we establish that our technique is capable of accurately predicting structural properties, including pair correlation functions and orientational order parameters. This research underscores the efficacy of FMTs as a robust tool for investigating complex fluids that extend beyond the conventional models of spherical particles. \n\n**I. Introductory Remarks:** The characterization of liquids and complex materials, such as dark matter, necessitates advanced methodologies due to their intricate structures and dynamic behaviors. In recent years, density functionals have emerged as promising instruments for addressing many-body problems in mathematical mechanics. These functionals facilitate the estimation of equilibrium properties of interacting molecules by minimizing a free energy functional relative to the local number density distribution. A prominent category of density functionals is the fundamental measure density functionals (FMD), initially developed by Rosenfeld. While the original formulation was limited to liquids of identical spheres, subsequent extensions have been proposed for more complex geometries, including ellipsoids, rods, dumbbells, spherocylinders, and occasionally patchy particles. However, much of the existing literature has focused on systems exhibiting uniaxial symmetry, leaving a gap in the exploration of more generalized scenarios. In this work, we aim to fill this gap by defining a system of rigidly aligned hard hexagons, thereby advancing the understanding of anisotropic liquid behavior.",
        "ori-fast-z-score": -2.729152956884052,
        "water-fast-z-score": 6.180982563844155,
        "rewrite-fast-z-score": -0.4601789933084222
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  X-ray Flares in Orion Low Mass Stars .\nAbstract:\nWe report on the detection of X-ray flares in low mass stars (0.5-0.8 M⊙) with ages between 1 and 10 Myr, located within the Orion Nebula Cluster. The flare activity is found to be strongly dependent upon stellar age; we find that younger stars are more active than older ones by at least an order of magnitude. We also find evidence for a dependence of flaring rate on rotation period, such that faster rotating stars have higher rates of flaring.  These results suggest that magnetic fields play an important role in regulating the level of coronal activity in young solar-type stars. This work was supported under NASA contract NAS8-39073. We thank J. Townsley for providing us with his photometric data set prior to publication. We acknowledge useful discussions with A. Feigelson, D. Getman, C. Hillenbrand, R. Herbst, S. Preibisch, B. Reipurth, T. Stassun, E. Wolff, and W. Zuckermann.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : X - ray Flares in Orion Low Mass Stars . Abstract : We report on the observation of X - ray flares in low mass stars ( 0 . 5 - 0 . 8 [UNK] ) with ages between 1 and 10 Myr , located within the Orion Nebula Cluster .The flare behavior is found to be highly dependent upon stellar age ; we find that younger galaxies are more active than older ones by at least an order of magnitude . We additionally find proof for a dependence of flaring speed on rotation history , such that better rotating stars have greater rates of flaring .These data suggest that magnetic fields work an important role in controlling the degree of coronal action in young solar - class stars . This research was supported under NASA contract NAS8 - 39073 .We praise J . Townsley for providing us with his photometric data set prior to publication . We acknowledge useful talks with A . Feigelson , D . Getman , C . Hillenbrand , R . Herbst , S . Preibisch , B . Reipurth , T . Stassun , E . Wolff , and W . Zuckermann .",
        "rewrite_text": "We present our findings on the occurrence of X-ray flares in low-mass stars (with masses ranging from 0.5 to 0.8 solar masses) situated in the Orion Nebula Cluster, with ages spanning from 1 to 10 million years. Our observations reveal a significant correlation between stellar age and flare activity, indicating that younger stars exhibit flare rates that are at least an order of magnitude higher than their older counterparts. Furthermore, we have identified a relationship between the flaring frequency and the stars' rotation history, suggesting that stars with more rapid rotation experience a greater incidence of flares. These results imply that magnetic fields play a crucial role in influencing the level of coronal activity in young solar-type stars. This research was conducted under NASA contract NAS8-39073, and we extend our gratitude to J. Townsley for sharing his photometric dataset with us prior to its publication. We also acknowledge the valuable discussions and insights provided by A. Feigelson, D. Getman, C. Hillenbrand, R. Herbst, S. Preibisch, B. Reipurth, T. Stassun, E. Wolff, and W. Zuckermann, which greatly contributed to the depth of our study.",
        "ori-fast-z-score": -0.5933908290969266,
        "water-fast-z-score": 4.714045207910317,
        "rewrite-fast-z-score": -1.2375966910186262
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The AGN and Gas Disk in the Low Surface Brightness Galaxy PGC045080 .\nAbstract:\nWe present new observations of the low surface brightness galaxy PGC 045080, which is known to host an active galactic nucleus (AGN). We use these data to study the properties of this AGN as well as its relationship with the surrounding gas disk.  The AGN has been detected by previous studies at radio wavelengths using Very Large Array (VLA) observations. In our work we have used VLA archival data along with new observations made with the Karl G. Jansky Very Large Array (JVLA), to detect emission lines associated with the AGN. These include H-alpha,  NII  ,  SII  ,  OIII  , and  CII  . Using these line fluxes we calculate the luminosity of the AGN to be 1.1 x 10^41 erg/sec. This value agrees very closely with that found for other similar galaxies. We also find evidence for outflows on both large and small scales around the AGN.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The AGN and Gas Disk in the Low Surface Brightness Galaxy PGC045080 . Abstract : We report new studies of the low surface brightness universe PGC 045080 , which is known to host an active galactic nucleus ( AGN ) .We use these information to study the properties of this AGN as also as its connection with the nearby gas disk . The AGN has been detected by earlier surveys at radio wavelengths using Very Large Array ( VLA ) observations .In our work we have utilized VLA archival data along with new experiments done with the Karl G . Jansky Very Large Array ( JVLA ) , to identify emission lines associated with the AGN . These include H - alpha , NII , SII , OIII , and CII .Using these line fluxes we determine the luminosity of the AGN to be 1 . 1 x 10 ^ 41 erg / sec . This value agrees very closely with that obtained for other similar galaxies .We additionally find proof for outflows on both large and tiny scales around the AGN .",
        "rewrite_text": "We present a comprehensive study of the low surface brightness galaxy PGC 045080, which is recognized for hosting an active galactic nucleus (AGN). This research aims to investigate the characteristics of the AGN and its relationship with the adjacent gas disk. Previous surveys utilizing Very Large Array (VLA) observations have successfully detected the AGN, prompting further exploration into its properties. In our study, we have leveraged archival VLA data alongside new observations conducted with the Karl G. Jansky Very Large Array (JVLA) to identify various emission lines linked to the AGN. The emission lines detected include H-alpha, NII, SII, OIII, and CII. By analyzing the flux of these lines, we calculated the AGN's luminosity to be approximately 1.1 x 10^41 erg/sec, a value that aligns closely with those found in other galaxies of similar characteristics. Furthermore, our findings provide evidence of outflows occurring on both large and small scales surrounding the AGN, suggesting dynamic interactions within the galaxy. This research not only enhances our understanding of the AGN in PGC 045080 but also contributes to the broader knowledge of low surface brightness galaxies and their active nuclei. The implications of these findings may offer insights into the evolutionary processes of galaxies and the role of AGNs in their surrounding environments.",
        "ori-fast-z-score": -0.8819171036881969,
        "water-fast-z-score": 4.093146241443879,
        "rewrite-fast-z-score": -0.20851441405707477
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  First study of the gluon-quark-antiquark static potential in SU(3) Lattice QCD .\nAbstract:\nWe present results for the first lattice calculation of the static potential between quarks and antiquarks in full QCD with three colors (SU(3)) at zero temperature, using Wilson fermions on anisotropic lattices. We find that the string tension is consistent within errors to previous calculations performed in quenched QCD or N f = 2+1 flavor QCD. The spatial string tension agrees well with the prediction based on the one-gluon-exchange model. In addition we calculate the quarkonium spectrum in this theory by solving Schrödinger equations with potentials obtained from our numerical data. Our results are compared with experimental values as well as other theoretical predictions. PACS numbers: 11.15.Ha, 12.38.Gc, 13 .25.Hw \nI. INTRODUCTORY REMARK\nThe static potential plays an important role in understanding nonperturbative phenomena such as confinement and chiral symmetry breaking in quantum chromodynamics (QCD). It has been studied extensively both theoretically  1  -  4  and experimentally  5  , but its precise determination still remains challenging  6  .\nIn particular, it would be interesting to investigate how the static potential changes when going beyond the standard two-flavor case  7, 8  . This can be done either by considering more flavors  9  or by studying theories with different gauge groups  10  . Here we will consider the latter possibility and focus on the SU(3) color group which corresponds to three active flavors  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : First study of the gluon - quark - antiquark static potential in SU ( 3 ) Lattice QCD . Abstract : We present results for the first lattice measurement of the static potential between quarks and antiquarks in full QCD with three colors ( SU ( 3 ) ) at zero temperature , using Wilson fermions on anisotropic lattices .We see that the string stress is consistent within errors to previous analyses performed in quenched QCD or N f = 2 + 1 flavor QCD . The spatial string stress agrees well with the prediction based on the one - gluon - transfer model .In addition we determine the quarkonium spectrum in this theoretical by solving Schrödinger coefficients with potentials acquired from our numerical information . Our results are compared with theoretical values as well as other theoretical estimates .PACS codes : 11 . 15 . Ha , 12 . 38 . Gc , 13 . 25 . Hw I . INTRODUCTORY REMARK The static potential plays an important role in understanding nonperturbative processes such as confinement and chiral symmetry breaking in quantum chromodynamics ( QCD ) .It has been studied thoroughly both theoretically 1 - 4 and experimentally 5 , but its precise determination still remains challenging 6 . In particular , it would be interesting to examine how the static potential shifts when going beyond the standard two - flavor case 7 , 8 .This can be done either by exploring more flavors 9 or by examining theories with various gauge bands 10 . Here we will investigate the latter option and focus on the SU ( 3 ) color band which equals to three active flavors 11 .",
        "rewrite_text": "We present the inaugural lattice measurement of the static potential between quarks and antiquarks in full Quantum Chromodynamics (QCD) with three colors (SU(3)) at zero temperature, utilizing Wilson fermions on anisotropic lattices. Our findings indicate that the string tension is consistent, within the margin of error, with previous analyses conducted in quenched QCD and N_f = 2 + 1 flavor QCD. Notably, the spatial string tension aligns well with predictions derived from the one-gluon exchange model. Furthermore, we calculate the quarkonium spectrum by solving the Schrödinger equation with the potentials obtained from our numerical data. Our results are juxtaposed with theoretical predictions and other estimates in the literature. \n\nThe static potential is a crucial element in comprehending nonperturbative phenomena such as confinement and chiral symmetry breaking in QCD. While it has been extensively studied both theoretically and experimentally, achieving a precise determination remains a significant challenge. An intriguing avenue of research involves investigating how the static potential evolves when extending beyond the conventional two-flavor scenario. This exploration can be approached by either incorporating additional flavors or by analyzing theories with different gauge groups. In this study, we concentrate on the latter approach, specifically examining the SU(3) color group, which corresponds to three active flavors. Our work aims to deepen the understanding of the static potential in QCD and its implications for the underlying dynamics of quark confinement and the structure of hadrons. \n\nPACS codes: 11.15.Ha, 12.38.Gc, 13.25.Hw.",
        "ori-fast-z-score": -1.4779939172464398,
        "water-fast-z-score": 4.236915896106461,
        "rewrite-fast-z-score": -1.0945409092309881
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Systematics of Soft Particle Production at RHIC: Lessons from PHOBOS .\nAbstract:\nSoft particle production in relativistic heavy ion collisions is one of the most important observables for understanding the properties of strongly interacting matter produced in these reactions.  In this talk, I will present results on soft hadron and photon production obtained by the PHOBOS experiment at RHIC. The main focus will be on systematics observed as functions of collision centrality, beam energy, transverse momentum (pT), rapidity (y) and azimuthal angle (#phi). These observations are compared with theoretical predictions based on hydrodynamic models and transport calculations. Finally, we discuss how to use these measurements to extract information about the equation-of-state of nuclear matter. This work was supported by DOE grant DE-FG02-97ER41022. AMS-02 collaboration has recently reported that the positron fraction increases above 10 GeV  1  . It is generally believed that such an increase can only come from astrophysical sources like pulsars or supernova remnants  2  , but it may also have contributions from dark matter annihilation  3  .\nIn order to understand whether there exists any contribution from dark matter annihilations, it is necessary to know precisely what happens to electrons/positrons during their propagation through space  4  . However, our knowledge of cosmic ray propagation is limited due to uncertainties associated with solar modulation effects  5  . To overcome this difficulty, we propose to measure the fluxes of primary cosmic rays using satellites  6  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Systematics of Soft Particle Production at RHIC : Lessons from PHOBOS . Abstract : Soft particle production in relativistic heavy ion collisions is one of the most important observables for studying the properties of highly correlated matter created in these reactions .In this talk , I will present results on soft hadron and photon production derived by the PHOBOS experiment at RHIC . The main focus will be on systematics observed as functions of collision centrality , laser energy , transverse momentum ( pT ) , rapidity ( y ) and azimuthal angle ( # phi ) .These measurements are compared with theoretical estimates based on hydrodynamic predictions and transport measurements . Finally , we talk how to use these measurements to extract information about the equation - of - state of nuclear material .This project was supported by DOE grant DE - FG02 - 97ER41022 . AMS - 02 consortium has recently noted that the positron fraction increases above 10 GeV 1 .It is usually thought that such an increase can only happen from astrophysical sources like pulsars or supernova remnants 2 , but it could also have contributions from dark matter annihilation 3 . In order to comprehend whether there exists any contribution from dark matter annihilations , it is required to see accurately what comes to ions / positrons during their propagation through space 4 .However , our know of cosmic ray transmission is limited due to uncertainties involved with sun modulation effects 5 . To solve this obstacle , we propose to measure the fluxes of primary cosmic rays using satellites 6 .",
        "rewrite_text": "**Title:** Systematics of Soft Particle Production at RHIC: Insights from PHOBOS\n\n**Abstract:** The production of soft particles in relativistic heavy ion collisions serves as a crucial observable for investigating the characteristics of the highly correlated matter generated in these interactions. In this presentation, I will discuss findings related to soft hadron and photon production obtained from the PHOBOS experiment at the Relativistic Heavy Ion Collider (RHIC). The primary emphasis will be on the systematic behaviors observed as functions of various parameters, including collision centrality, laser energy, transverse momentum (pT), rapidity (y), and azimuthal angle (φ). These empirical measurements will be juxtaposed with theoretical predictions derived from hydrodynamic models and transport calculations. Furthermore, I will elaborate on how these findings can be utilized to extract valuable insights regarding the equation of state of nuclear matter. This research was supported by the Department of Energy under grant DE-FG02-97ER41022. \n\nAdditionally, the AMS-02 collaboration has recently reported an increase in the positron fraction above 10 GeV, a phenomenon typically attributed to astrophysical sources such as pulsars or supernova remnants. However, there is a possibility that dark matter annihilation may also contribute to this increase. To ascertain the potential influence of dark matter on the observed positron flux, it is essential to accurately trace the behavior of ions and positrons during their journey through space. Unfortunately, our understanding of cosmic ray propagation is hampered by uncertainties related to solar modulation effects. To address this challenge, we propose a strategy to measure the fluxes of primary cosmic rays using satellite-based observations, which could provide clearer insights into the origins and propagation mechanisms of these particles in the cosmos.",
        "ori-fast-z-score": 0.29277002188455997,
        "water-fast-z-score": 6.283787178796813,
        "rewrite-fast-z-score": -1.0954451150103321
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modified p-modes in penumbral filaments? .\nAbstract:\nWe report on the detection of an oscillatory pattern with periods between 5 and 20 minutes, which is observed to be associated with sunspots  penumbrae. The oscillations are detected by applying wavelet analysis to time series obtained from high-resolution observations made at the Swedish 1-m Solar Telescope (SST). We find that these oscillations have amplitudes up to 0.5 km/sec and occur preferentially along the edges of penumbral filaments. They appear to be confined within a narrow range of heliocentric angles, centered around 30 degrees. These results suggest that they may represent modified acoustic waves trapped inside magnetic flux tubes. This work was supported by NASA grants NAG5-7067 and NNG04GK85G. Sunspot penumbrae exhibit a variety of phenomena including rapid flows, brightenings, and darkening events known as Evershed flow, umbral flashes, and moat flows respectively. In this Letter we present evidence for another phenomenon occurring in penumbral regions -oscillations with periods ranging from 5-20 minutes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modified p - modes in penumbral filaments ? .Abstract : We report on the observation of an oscillatory pattern with periods between 5 and 20 minutes , which is observed to be correlated with sunspots penumbrae . The oscillations are detected by using wavelet study to time series acquired from high - resolution measurements made at the Swedish 1 - m Solar Telescope ( SST ) .We see that these oscillations have amplitudes up to 0 . 5 kilometres / sec and occur preferentially along the edges of penumbral filaments . They seem to be confined within a thin range of heliocentric angles , centered around 30 degrees .These data suggest that they may represent enhanced sound signals stuck inside magnetic flux tubes . This research was supported by NASA grants NAG5 - 7067 and NNG04GK85G .Sunspot penumbrae exhibit a variety of phenomena including rapid flows , brightenings , and darkening phenomena known as Evershed flow , umbral flashes , and moat flows respectively . In this Letter we present evidence for another feature occurring in penumbral regions - oscillations with periods ranging from 5 - 20 minutes .",
        "rewrite_text": "In this study, we present observations of an oscillatory phenomenon associated with sunspot penumbrae, characterized by periods ranging from 5 to 20 minutes. Utilizing wavelet analysis on time series data obtained from high-resolution imaging at the Swedish 1-m Solar Telescope (SST), we have identified these oscillations, which exhibit peak velocities of up to 0.5 kilometers per second. Notably, these oscillatory patterns are predominantly located along the peripheries of penumbral filaments and appear to be confined to a narrow range of heliocentric angles, centered around 30 degrees. Our findings suggest that these oscillations may represent enhanced acoustic signals that are trapped within magnetic flux tubes, providing new insights into the dynamic processes occurring in sunspot regions. \n\nThe presence of these oscillations adds to the diverse array of phenomena observed in sunspot penumbrae, which include rapid flows, brightenings, and various darkening effects such as Evershed flow, umbral flashes, and moat flows. The identification of oscillatory behavior in penumbral regions contributes to our understanding of the complex interactions between magnetic fields and plasma dynamics in the solar atmosphere. This research was supported by NASA grants NAG5-7067 and NNG04GK85G, underscoring the significance of collaborative efforts in advancing solar physics. Our findings not only enhance the current knowledge of sunspot dynamics but also open avenues for further investigation into the underlying mechanisms driving these oscillations and their implications for solar activity and its impact on space weather.",
        "ori-fast-z-score": 0.5852057359806528,
        "water-fast-z-score": 4.965212315030781,
        "rewrite-fast-z-score": 0.4879500364742666
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  IGR J17254-3257, a new bursting neutron star .\nAbstract:\nWe report the discovery and analysis of an X-ray transient source IGR J17254-3257 in outburst during June 2009 with INTEGRAL/Swift/BAT. The source was detected at high flux levels (>10 Crab) for about one week by Swift/XRT and XMM-Newton/EPIC-pn. We find that this is likely to be another example of a short-hard gamma-ray burst associated with a binary system containing a black hole or neutron star accretor. A comparison between our results on IGR J17254−3257 and those obtained previously for other similar sources suggests that there may exist two different classes of such systems. In particular we suggest that some of these objects are powered by super-Eddington accretion onto rapidly rotating black holes while others are powered by sub-Eddington accretion into slowly spinning neutron stars. This work has been supported by NASA under contract NAS8-03060.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : IGR J17254 - 3257 , a new bursting neutron star . Abstract : We report the discovery and analysis of an X - ray transient source IGR J17254 - 3257 in outburst during June 2009 with INTEGRAL / Swift / BAT .The source was monitored at high flux levels ( > 10 Crab ) for about one month by Swift / XRT and XMM - Newton / EPIC - pn . We see that this is probably to be another example of a small - hard gamma - ray flare associated with a binary system containing a black hole or neutron galaxy accretor .A comparison between our findings on IGR J17254−3257 and those conducted previously for other similar sources shows that there may exist two different categories of such systems . In particular we indicate that some of these objects are powered by super - Eddington accretion onto swiftly spinning black holes while many are powered by sub - Eddington accretion into quickly spinning neutron galaxies .This project has been supported by NASA under contract NAS8 - 03060 .",
        "rewrite_text": "We present the discovery and detailed analysis of the X-ray transient source IGR J17254-3257, which exhibited an outburst in June 2009, as observed by the INTEGRAL and Swift/BAT missions. During this period, the source was monitored at exceptionally high flux levels exceeding 10 Crab for approximately one month using Swift/XRT and XMM-Newton/EPIC-pn instruments. Our observations suggest that IGR J17254-3257 may represent a new instance of a small, hard gamma-ray flare linked to a binary system that likely contains either a black hole or a neutron star as the accretor. \n\nIn our comparative analysis with previously studied similar sources, we propose the existence of two distinct categories of such systems. Notably, we find that certain objects are driven by super-Eddington accretion onto rapidly rotating black holes, while others appear to be powered by sub-Eddington accretion onto swiftly spinning neutron stars. This classification could enhance our understanding of the mechanisms behind these transient phenomena and their underlying astrophysical processes.\n\nThe findings of this research contribute to the broader field of high-energy astrophysics and are supported by NASA under contract NAS8-03060. Our work not only sheds light on the characteristics of IGR J17254-3257 but also invites further investigation into the nature of similar X-ray transient sources, potentially leading to new insights into the dynamics of accretion in binary systems.",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 3.8247315498700596,
        "rewrite-fast-z-score": 1.2809280616135812
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Na I D resonance lines in main sequence late-type stars .\nAbstract:\nWe present new high-resolution, near-infrared (NIR) spectra for the coolest known members of open clusters M67 and NGC 2516 obtained with the Phoenix spectrograph on Gemini South Observatory. The observations were carried out to study the sodium doublet at λλ8183/8195 Å as well as other atomic features that are sensitive to surface gravity and effective temperature. We have determined fundamental stellar parameters such as T eff , log g,  Fe/H , v sin i, and projected rotational velocity using spectral synthesis techniques. Our results show that all targets exhibit solar-like abundances within uncertainties. In addition we find evidence for differential rotation among our sample stars. Finally, we compare our derived values with those found by previous studies and discuss possible reasons behind discrepancies between different works. \n \n Keywords: Near-infrared spectroscopy, Open cluster, Surface gravity, Differential rotation, Fundamental parameters",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Na I D correlation lines in major sequence late - class stars . Abstract : We report new high - resolution , near - infrared ( NIR ) spectra for the coolest known members of close galaxies M67 and NGC 2516 obtained with the Phoenix spectrograph on Gemini South Observatory .The surveys were carried out to study the sodium doublet at λλ8183 / 8195 Å as well as other atomic features that are subject to surface gravity and effective heat . We have predicted fundamental stellar variables such as T eff , log f , Fe / H , v sin i , and projected rotational momentum using spectral synthesis techniques .Our results show that all targets exhibit solar - like abundances within uncertainties . In addition we find proof for differential rotation among our sample stars .Finally , we compare our derived values with those identified by earlier publications and consider likely explanations behind discrepancies between various works . Keywords : Near - infrared spectroscopy , Open cluster , Surface gravity , Differential rotation , Fundamental parameters",
        "rewrite_text": "**Title:** The Na I D Correlation Lines in Late-Class Main Sequence Stars\n\n**Abstract:** In this study, we present new high-resolution near-infrared (NIR) spectra of the coolest known members of the open clusters M67 and NGC 2516, acquired using the Phoenix spectrograph at the Gemini South Observatory. Our investigation focuses on the sodium doublet at wavelengths of 8183 Å and 8195 Å, along with other atomic features that are influenced by surface gravity and effective temperature. By employing spectral synthesis techniques, we have successfully derived fundamental stellar parameters, including effective temperature (T_eff), logarithmic surface gravity (log g), metallicity (Fe/H), projected rotational velocity (v sin i), and projected angular momentum. Our findings indicate that all observed stars display solar-like abundance patterns within the limits of measurement uncertainty. Notably, we also provide evidence for differential rotation among the stars in our sample, suggesting a complex interplay between rotation and stellar evolution. Furthermore, we compare our derived parameters with those reported in previous studies, addressing potential reasons for discrepancies observed in the literature. This work contributes to the understanding of stellar characteristics in late-class main sequence stars and highlights the importance of high-resolution NIR spectroscopy in astrophysical research. \n\n**Keywords:** Near-infrared spectroscopy, Open clusters, Surface gravity, Differential rotation, Fundamental parameters.",
        "ori-fast-z-score": -0.3418817293789138,
        "water-fast-z-score": 4.612860393796698,
        "rewrite-fast-z-score": 0.7921180343813395
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Composite fermion wave functions as conformal field theory correlators .\nAbstract:\nWe show that the ground state wave function for composite fermions in the lowest Landau level is equal to the vacuum expectation value of a correlator of chiral primary fields in N = 2 superconformal Chern-Simons-matter theories with gauge group U(1)Nc−1 and matter content consisting of one hypermultiplet in the fundamental representation, where Nc denotes the number of colors. We also discuss how this result can be used to compute correlation functions of local operators at finite density using supersymmetric localization techniques. The results presented here are based on joint work with Jens Alcaraz-García, Daniel Grumiller, David H. Kaplan, Michael Lüst, and Thomas Schroer. In condensed matter physics, it has been known since the 1980s that electrons confined to two dimensions behave like particles called  composite fermions  when subjected to an external magnetic field  1  . These composite fermions form a Fermi sea which exhibits fractional quantum Hall effect (FQHE), i.e., they exhibit plateaus in their Hall conductance at fractions of e/2πh  2  .\nIn recent years there have been several attempts to understand these phenomena within string theory  3, 4, 5, 6, 7, 8  , but so far no complete description exists. One approach consists of studying the low-energy effective action describing the dynamics of the FQH fluid  7, 9  . This action contains a Chern-Simons term coupled to a set of charged scalar fields representing fluctuations around the mean-field solution corresponding to the filled lowest Landau level. It turns out that the resulting system is described by a two-dimensional conformal field theory (CFT). Moreover, the CFT partition function evaluated on a torus coincides with the statistical sum over all states of the FQH fluid  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Composite fermion wave systems as conformal field theory correlators . Abstract : We see that the ground state wave function for composite fermions in the lowest Landau grade is equal to the vacuum expectation value of a correlator of chiral primary fields in N = 2 superconformal Chern - Simons - matter theories with gauge group U ( 1 ) Nc−1 and matter content comprised of one hypermultiplet in the fundamental representation , where Nc denotes the number of colors .We also discuss how this effect can be used to compute correlation functions of local operators at finite density using supersymmetric localization techniques . The results presented here are based on collaborative work with Jens Alcaraz - García , Daniel Grumiller , David H . Kaplan , Michael Lüst , and Thomas Schroer .In condensed matter mechanics , it has been known since the 1980s that electrons confined to two dimensions behave like ions called composite fermions when exposed to an external magnetic force 1 . These composite fermions form a Fermi sea which exhibits fractional quantum Hall impact ( FQHE ) , i . e . , they show plateaus in their Hall conductance at fractions of e / 2πh 2 .In past decades there have been numerous attempts to explain these phenomena within string theory 3 , 4 , 5 , 6 , 7 , 8 , but so far no complete documentation remains . One approach consists of examining the small - energy effective action governing the dynamics of the FQH fluid 7 , 9 .This operation contains a Chern - Simons term coupled to a setting of charged scalar fields representing fluctuations around the mean - field solution corresponding to the filled low Landau level . It turns out that the resulting system is characterized by a two - dimensional conformal field model ( CFT ) .Moreover , the CFT partition function evaluated on a torus coincides with the statistical sum over all states of the FQH fluid 10 .",
        "rewrite_text": "**Title:** Composite Fermion Wave Systems as Conformal Field Theory Correlators\n\n**Abstract:** In this study, we explore the ground state wave function of composite fermions situated in the lowest Landau level, demonstrating that it corresponds to the vacuum expectation value of a correlator involving chiral primary fields within N = 2 superconformal Chern-Simons-matter theories. These theories are characterized by a gauge group U(1) with Nc−1 colors and include a single hypermultiplet in the fundamental representation, where Nc represents the number of colors. We further elaborate on how this relationship can be leveraged to compute correlation functions of local operators at finite density, employing techniques from supersymmetric localization. This work is a collaborative effort with researchers Jens Alcaraz-García, Daniel Grumiller, David H. Kaplan, Michael Lüst, and Thomas Schroer.\n\nThe behavior of electrons confined to two-dimensional spaces under an external magnetic field has been recognized since the 1980s, revealing that they can behave like composite fermions. These composite fermions create a Fermi sea that exhibits fractional quantum Hall effect (FQHE) characteristics, manifesting as plateaus in Hall conductance at fractional values of e/2πh². Over the past few decades, various attempts have been made to elucidate these phenomena through the lens of string theory; however, a comprehensive account remains elusive. One promising approach involves analyzing the effective action at low energies that governs the dynamics of the fractional quantum Hall fluid. This effective action incorporates a Chern-Simons term alongside charged scalar fields that account for fluctuations around the mean-field solution associated with the filled lowest Landau level. Notably, the resulting system can be described by a two-dimensional conformal field theory (CFT). Additionally, the partition function of the CFT, when evaluated on a toroidal geometry, aligns with the statistical sum over all states of the fractional quantum Hall fluid, thereby establishing a profound connection between these seemingly disparate areas of theoretical physics.",
        "ori-fast-z-score": -1.153563462240948,
        "water-fast-z-score": 3.9620290784653074,
        "rewrite-fast-z-score": -1.3310347641241707
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Distribution of AGN in Clusters of Galaxies .\nAbstract:\nWe present the results on the distribution and luminosity function (LF) of active galactic nuclei (AGNs) in clusters of galaxies based on Chandra observations of 16 galaxy clusters at redshifts 0.1 < z < 1.0. We find that the fraction of X-ray luminous AGNs increases with redshift, but decreases with cluster mass. The LF of AGNs is well described by a power law with an exponential cutoff above Lx = 1043 erg s-1 Hz-1 . The best-fit parameters are consistent with those found for field AGNs within their uncertainties. These results suggest that AGNs play important roles in heating intracluster gas as well as regulating star formation activities in clusters. This work was supported by NASA grant NNG06GH50G to J.E.K., and NSF grants AST-0707765 and AST-0708164 to A.M..",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Distribution of AGN in Clusters of Galaxies . Abstract : We report the results on the distribution and luminosity function ( LF ) of active galactic nuclei ( AGNs ) in clusters of stars based on Chandra measurements of 16 galaxy galaxies at redshifts 0 . 1 < z < 1 . 0 .We see that the fraction of X - ray luminous AGNs increases with redshift , but decreases with cluster mass . The LF of AGNs is well described by a power law with an exponential cutoff above Lx = 1043 erg s - 1 Hz - 1 .The best - fitting characteristics are compatible with those observed for field AGNs within their uncertainties . These data suggest that AGNs serve active roles in heating intracluster gas as well as affecting star formation activities in clusters .This project was supported by NASA award NNG06GH50G to J . E . K . , and NSF grants AST - 0707765 and AST - 0708164 to A . M . .",
        "rewrite_text": "We present findings on the distribution and luminosity function (LF) of active galactic nuclei (AGNs) within galaxy clusters, utilizing Chandra observations of 16 galaxy clusters at redshifts ranging from 0.1 to 1.0. Our analysis reveals that the proportion of X-ray luminous AGNs tends to increase with redshift, while it shows a decline in relation to the mass of the clusters. The luminosity function of AGNs is effectively modeled by a power law that exhibits an exponential cutoff at Lx = 10^43 erg s^-1 Hz^-1. The parameters obtained from our fitting align closely with those documented for field AGNs, within the bounds of their uncertainties. These findings imply that AGNs play a significant role in the thermal regulation of intracluster gas and may also influence star formation processes within these clusters. This research was made possible through the support of NASA grant NNG06GH50G awarded to J. E. K., as well as NSF grants AST-0707765 and AST-0708164 awarded to A. M.",
        "ori-fast-z-score": -0.816496580927726,
        "water-fast-z-score": 4.449719092257398,
        "rewrite-fast-z-score": -1.4084056792618558
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  About the lifetime of a bouncing droplet .\nAbstract:\nWe study numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating, which is known to be able to support stable levitation of drops in air.  We show that the lifetimes of such bouncing droplets are determined by their initial kinetic energy. The dependence of the lifetime on this energy can be fitted well using a power law t ~ E0−α where α = 0.5 ± 0.1 for both numerical simulations and experiments. This scaling behavior suggests that the lifetime of a bouncer depends only weakly on its initial velocity. In addition we find that the maximum height reached during each bounce decreases as the number of bounces increases. Finally, we demonstrate how these results can be used to estimate the surface tension of water based on experimental data. Bouncing droplets have been studied extensively over recent years due to their potential applications in microfluidics  1  . These systems typically consist of millimeter-sized droplets impacting onto hydrophobic surfaces  2  , but they also include smaller droplets bouncing off super-hydrophobic coatings  3  .\nIn many cases it has been observed that the droplets exhibit periodic motion  4  -  6  . However, there exist some examples of non-periodic bouncing  7, 8  or even chaotic trajectories  9  . It was shown recently  10  that the lifetimes (i.e., the times between successive impacts) of bouncing droplets depend strongly on their initial velocities. For example, if the initial speed is too high then the droplet will not bounce at all; instead it will slide down the surface until it reaches the bottom  11  . On the other hand, if the initial speed lies below a certain threshold value then the droplet will bounce indefinitely  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : About the life of a bouncing droplet . Abstract : We research numerically and experimentally the dynamics of a liquid droplet bouncing on an inclined plane covered with superhydrophobic coating , which is known to be possible to support steady levitation of drops in air .We see that the lifetimes of such bouncing droplets are decided by their initial kinetic energy . The dependence of the lifetime on this power can be fit well using a power law t ~ E0−α where α = 0 . 5 ± 0 . 1 for both numerical simulations and experiments .This scaling behavior suggests that the life of a bouncer relies only faintly on its initial velocity . In addition we find that the maximum length reached during each jump varies as the quantity of bounces increases .Finally , we prove how these results can be used to estimate the surface tension of water based on experimental evidence . Bouncing droplets have been studied frequently over recent years owing to their potential applications in microfluidics 1 .These systems commonly consist of millimeter - sized droplets impacting onto hydrophobic surfaces 2 , but they also involve smaller droplets scattering off super - hydrophobic coatings 3 . In many cases it has been observed that the droplets display periodic motion 4 - 6 .However , there remain some examples of non - periodic bouncing 7 , 8 or even chaotic trajectories 9 . It was shown recently 10 that the lifetimes ( i . e . , the periods between successive impacts ) of tumbling droplets change closely on their initial velocities .For instance , if the first velocity is too high then the droplet will not bounce at all ; merely it will slide down the surface until it meets the bottom 11 . On the other hand , if the initial speed lies below a certain threshold number then the droplet will bounce indefinitely 12 .",
        "rewrite_text": "**Title: The Dynamics of Bouncing Droplets: An Experimental and Numerical Investigation**\n\n**Abstract:** This study delves into the dynamics of liquid droplets that bounce on an inclined plane with a superhydrophobic coating, a surface known for enabling the stable levitation of droplets in air. Through a combination of numerical simulations and experimental observations, we investigate how the initial kinetic energy of these droplets influences their bouncing lifetimes. Our findings reveal that the relationship between the lifetime of a bouncing droplet and its initial kinetic energy can be accurately described by a power law, expressed as t ~ E0−α, where α is approximately 0.5 ± 0.1 across both experimental and simulation data. This scaling behavior indicates that the lifetime of a bouncing droplet is only weakly dependent on its initial velocity. Furthermore, we observe that the maximum height achieved during each bounce tends to increase with the number of bounces, suggesting a complex interplay between energy dissipation and droplet dynamics.\n\nThe phenomenon of bouncing droplets has garnered significant attention in recent years due to its implications for microfluidic applications. Typically, these systems involve millimeter-sized droplets impacting hydrophobic surfaces, but they also encompass smaller droplets interacting with superhydrophobic coatings. While many studies have documented periodic bouncing behavior, instances of non-periodic bouncing and chaotic trajectories have also been reported. Recent research has highlighted that the lifetimes of tumbling droplets are closely tied to their initial velocities; for example, droplets with excessively high initial speeds tend to slide down the surface without bouncing, while those with speeds below a critical threshold can bounce indefinitely. Our work not only enhances the understanding of droplet dynamics but also provides a method to estimate the surface tension of water based on experimental data, thereby contributing to the broader field of fluid dynamics and its applications in technology.",
        "ori-fast-z-score": -0.2683281572999747,
        "water-fast-z-score": 6.010407640085654,
        "rewrite-fast-z-score": 0.3481553119113957
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  An Optical Source Catalog of the North Ecliptic Pole Region .\nAbstract:\nWe present an optical source catalog for the north ecliptic pole region (NEPR) based on data obtained with the Palomar Observatory Sky Survey (POSS-II). The NEPR is defined as the area within 10 degrees in right ascension and declination centered at RA = 20 h 00 m , Dec = +85 deg . We have used POSS-II plates taken between 1950 and 1990 to produce this catalog, which contains over 1 million sources down to B J = 22 mag .\nThe photometric calibration was performed using Landolt standard stars observed during the same nights that the sky survey plates were exposed. Photometry has been carried out by means of aperture photometry techniques. Magnitudes are given in the Johnson system. In addition we provide proper motions for all objects brighter than B J = 18 mag . This catalog will be useful for studies related to galactic structure and evolution. \n \n Keywords: Palomar Observatory Sky Survey",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : An Optical Source Catalog of the North Ecliptic Pole Region . Abstract : We create an optical source catalog for the north ecliptic pole region ( NEPR ) based on evidence derived with the Palomar Observatory Sky Survey ( POSS - II ) .The NEPR is characterized as the area within 10 degrees in right ascension and declination centered at RA = 20 g 00 m , Dec = + 85 deg . We have utilized POSS - II sheets taken between 1950 and 1990 to produce this database , which contains over 1 million sources down to B J = 22 mag .The photometric calibration was done utilizing Landolt standard stars observed during the same hours that the sky survey plates were uncovered . Photometry has been carried out by means of aperture photometry method .Magnitudes are given in the Johnson system . In addition we provide proper motions for all bodies brighter than B J = 18 mag .This catalog will be valuable for research associated to galactic composition and evolution . Keywords : Palomar Observatory Sky Survey",
        "rewrite_text": "We present a comprehensive optical source catalog for the North Ecliptic Pole Region (NEPR), developed using data from the Palomar Observatory Sky Survey (POSS-II). The NEPR is defined as the area encompassing 10 degrees in both right ascension and declination, centered at coordinates RA = 20h 00m and Dec = +85°. Our catalog is based on POSS-II photographic plates collected between 1950 and 1990, resulting in a robust database that includes over one million optical sources with a limiting magnitude of B_J = 22 mag. \n\nTo ensure accurate photometric measurements, we performed calibration using Landolt standard stars that were observed concurrently with the sky survey plates. The photometry was executed using the aperture photometry technique, and all magnitudes are reported in the Johnson photometric system. Additionally, we have computed proper motions for all sources brighter than B_J = 18 mag, enhancing the catalog's utility for dynamic studies.\n\nThis catalog serves as a significant resource for researchers investigating various aspects of galactic composition and evolution, offering a wealth of data for both observational and theoretical studies. The extensive coverage and depth of the catalog make it an essential tool for advancing our understanding of the NEPR and its surrounding cosmic environment. \n\nKeywords: Palomar Observatory Sky Survey, North Ecliptic Pole Region, optical source catalog, photometry, galactic evolution.",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 4.389381125701739,
        "rewrite-fast-z-score": -1.9188064472004938
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Vacuum Energy and Renormalization on the Edge .\nAbstract:\nWe study vacuum energy in quantum field theory with boundary conditions that break conformal invariance, such as Dirichlet or Neumann boundary conditions. We show how to renormalize this quantity using zeta function regularization techniques. In particular we find that for any number of dimensions there is an infinite set of counterterms which must be included when computing the vacuum energy density at zero temperature. This result has implications for Casimir effect calculations where one considers two parallel plates separated by some distance. The presence of these additional terms can lead to significant changes in the results obtained previously. Finally we consider the case of fermions coupled to scalar fields and compute the vacuum expectation value of the stress-energy tensor. For certain values of the coupling constant it turns out that the vacuum state becomes unstable due to spontaneous symmetry breaking. Vacuum energy plays an important role in many areas of physics including cosmology  1  , black hole thermodynamics  2  , and condensed matter systems  3  . It also appears in various contexts within string theory  4  .\nIn recent years much progress has been made towards understanding the nature of vacuum fluctuations in quantum field theories (QFTs)  5  -  8  . However most work done so far has focused primarily on QFTs defined on flat space-time manifolds without boundaries  9  -  11  . Recently however there have been several attempts to understand vacuum fluctuations in QFTs defined on curved backgrounds  12  -  14  . Another interesting problem involves studying vacuum fluctuations in QFT s defined on spaces with boundaries  15  -  17  . Such problems are relevant for example in the context of Casimir effects  18  -  20  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Vacuum Energy and Renormalization on the Edge . Abstract : We research vacuum energy in quantum field theory with boundary constraints that broke conformal invariance , such as Dirichlet or Neumann border conditions .We see how to renormalize this quantity use zeta function regularization techniques . In particular we find that for any number of dimensions there is an endless system of counterterms which requires be included when computing the vacuum energy density at zero temperature .This result has implications for Casimir effect calculations where one considers two connected plates apart by some distance . The presence of these additional terms can lead to significant changes in the results derived earlier .Finally we study the case of fermions connected to scalar fields and compute the vacuum expectation value of the strain - energy tensor . For particular values of the coupling constant it turns out that the vacuum state remains unstable due to spontaneous symmetry breaking .Vacuum energy serves an important role in multiple fields of science specifically cosmology 1 , white hole thermodynamics 2 , and condensed matter systems 3 . It additionally occurs in different contexts within string theory 4 .In past decades considerable progress has been achieved towards studying the nature of vacuum fluctuations in particle field theories ( QFTs ) 5 - 8 . However most work done so far has concentrated mostly on QFTs defined on flat space - time manifolds without boundaries 9 - 11 .Recently however there have been numerous attempts to explain vacuum fluctuations in QFTs defined on curved backgrounds 12 - 14 . Another important difficulty involves studying vacuum fluctuations in QFT s defined on spaces with borders 15 - 17 .Such issues are applicable for example in the context of Casimir effects 18 - 20 .",
        "rewrite_text": "**Title: Vacuum Energy and Renormalization on the Edge**\n\n**Abstract:** This study investigates the phenomenon of vacuum energy within the framework of quantum field theory (QFT) under boundary conditions that disrupt conformal invariance, such as Dirichlet and Neumann conditions. We employ zeta function regularization techniques to effectively renormalize vacuum energy, revealing that an infinite series of counterterms must be incorporated when calculating the vacuum energy density at zero temperature, regardless of the dimensionality of the system. This finding has significant implications for the calculations of the Casimir effect, particularly in scenarios involving two parallel plates separated by a finite distance, where the inclusion of these additional counterterms can substantially alter previously established results. Furthermore, we explore the interaction between fermions and scalar fields, deriving the vacuum expectation value of the strain-energy tensor. Notably, for specific values of the coupling constant, we observe that the vacuum state exhibits instability due to spontaneous symmetry breaking. The concept of vacuum energy is pivotal across various scientific domains, including cosmology, white hole thermodynamics, and condensed matter physics. It also plays a role in diverse contexts within string theory. Over the past few decades, significant advancements have been made in understanding vacuum fluctuations in particle field theories. However, much of the existing research has predominantly focused on QFTs situated in flat spacetime without boundaries. Recently, there has been a surge of interest in exploring vacuum fluctuations in QFTs defined on curved spacetime backgrounds. Additionally, the challenge of analyzing vacuum fluctuations in QFTs with boundary conditions remains a critical area of study, particularly relevant to the investigation of Casimir effects.",
        "ori-fast-z-score": -1.1026456085839622,
        "water-fast-z-score": 5.706433236417486,
        "rewrite-fast-z-score": 1.310556084991557
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On smooth foliations with Morse singularities .\nAbstract:\nIn this article we study the structure of smooth foliations on closed manifolds, which are given by submersions whose fibers have only Morse singularities (i.e., they look like graphs over their tangent spaces). We prove that such foliations can be approximated in the C 1 -topology by regular ones and give an explicit bound for the approximation error. This result is used to show that any leafwise Riemannian metric on these foliations has bounded geometry. The main tool here is the theory of harmonic maps into Hilbert spaces developed by Eells-Elworthy-Malliavin. In particular, we use the fact that every harmonic map into a Hilbert space is weakly conformal. As another application of our results, we obtain some estimates for the volume growth rate along leaves of such foliations. Finally, using the above mentioned bounds for the approximation error, we also get lower bounds for the number of critical points of generic functions on closed manifolds.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On smooth foliations with Morse singularities . Abstract : In this article we study the composition of smooth foliations on closed manifolds , which are given by submersions whose fibers have only Morse singularities ( i . e . , they look like graphs over their tangent spaces ) .We prove that such foliations can be approximated in the C 1 - topology by regular ones and giving an explicit bound for the approximation error . This result is applied to say that any leafwise Riemannian metric on these foliations has bounded structure .The main tool here is the principle of harmonic maps into Hilbert spaces used by Eells - Elworthy - Malliavin . In particular , we utilize the fact that every harmonic mapping into a Hilbert space is mildly conformal .As another application of our findings , we obtain some measurements for the volume increase speed along leaves of such foliations . Finally , using the above mentioned bounds for the approximation error , we also get lower bounds for the number of vital points of generic functions on closed manifolds .",
        "rewrite_text": "In this article, we investigate the characteristics of smooth foliations on closed manifolds, specifically those defined by submersions with fibers exhibiting only Morse singularities. These singularities are characterized by their resemblance to graphs over the corresponding tangent spaces. Our primary contribution is the demonstration that such foliations can be approximated by regular foliations within the C^1 topology, and we provide a precise estimate for the approximation error involved in this process. This finding has significant implications, particularly in establishing that any leafwise Riemannian metric associated with these foliations possesses a bounded structure.\n\nTo achieve these results, we employ the principle of harmonic maps into Hilbert spaces, a powerful tool developed by Eells, Elworthy, and Malliavin. A key aspect of our approach is the observation that every harmonic mapping into a Hilbert space exhibits mild conformality. This property allows us to derive additional insights regarding the geometric structure of the foliations under consideration.\n\nFurthermore, we explore the implications of our results on the volume increase rate along the leaves of these foliations, providing quantitative measures that enhance our understanding of their geometric behavior. Additionally, leveraging the bounds established for the approximation error, we derive lower bounds for the number of critical points of generic functions defined on closed manifolds. This aspect of our work contributes to the broader discourse on the topology and geometry of manifolds, offering new perspectives on the interplay between foliation theory and singularity analysis. Overall, our findings not only advance the theoretical framework surrounding smooth foliations with Morse singularities but also open avenues for future research in related areas of differential geometry and topology.",
        "ori-fast-z-score": -1.7801724872907798,
        "water-fast-z-score": 1.9123657749350298,
        "rewrite-fast-z-score": 1.2780193008453875
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Properties of Zero-Lag Long-Range Synchronization via Dynamical Relaying .\nAbstract:\nWe study the zero-lag synchronization between two identical chaotic systems with different time scales by using dynamical relaying method, which is based on introducing an intermediate system to transmit information between them. The stability analysis shows that the proposed scheme can achieve zero-lag synchronization under some conditions. Numerical simulations are performed for Lorenz and Chen systems as examples. It is shown that the proposed scheme has advantages over other existing methods in terms of robustness against parameter mismatch and external disturbances. \nI. INTRODUCTIO N\nSynchronization plays important roles in many fields such as biology  1  , physics  2  , engineering  3  . In recent years, chaos synchronization  4  -  6  has attracted much attention due to its potential applications in secure communication  7  , chemical reactions  8  , biological systems  9  .\nChaos synchronization was first studied by Pecora and Carroll  10  who introduced the concept of master-slave synchronization. Since then, various schemes have been developed  11  -  13  . Among these schemes, adaptive control  14  , active control  15  , backstepping  16  , sliding mode  17  , fuzzy logic  18  , impulsive control  19  , intermittent control  20  , pinning control  21  , etc., were widely used  22  -  24  . However, most of these works focused only on the case where there exists no delay between slave and master systems  25  -  27  . Recently, several studies have investigated the problem of synchronizing chaotic systems with time delays  28  -  30  . For example, Wu et al.  31  presented a new approach to realize lag-synchronized chaos between two chaotic systems with different dimensions through state feedback controllers. Liu et al.  32  designed a novel delayed-feedback controller to synchronize two chaotic systems with unknown parameters. Wang et al.  33  proposed a simple but effective method to synchronize two chaotically oscillating systems with time-varying delays. Although these results provide useful insights into the design of synchronized chaotic systems with time-delays, they cannot be applied directly to solve practical problems because it may take too",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Properties of Zero - Lag Long - Range Synchronization via Dynamical Relaying . Abstract : We research the zero - lag synchronization between two unrelated turbulent systems with varying time ranges by using dynamical relaying model , which is based on introducing an intermediate system to transmit data between them .The stability analysis shows that the suggested system can attain zero - lag synchronization under some conditions . Numerical simulations are performed for Lorenz and Chen networks as instance .It is demonstrated that the suggested system has advantages over other existing techniques in terms of robustness against parameter mismatch and external disturbances . I . INTRODUCTIO N Synchronization plays important roles in different fields such as biology 1 , chemistry 2 , engineering 3 .In recent years , chaos synchronization 4 - 6 has drew much attention due to its potential applications in safe communication 7 , chemical processes 8 , biological systems 9 . Chaos synchronization was first investigated by Pecora and Carroll 10 who proposed the idea of master - servant synchronization .Since then , various strategies have been created 11 - 13 . Among these schemes , adaptive control 14 , active control 15 , backstepping 16 , sliding mode 17 , fuzzy logic 18 , impulsive control 19 , continuous control 20 , pinning rule 21 , etc . , were commonly used 22 - 24 .However , most of these works focused only on the case where there exists no delay between slave and master schemes 25 - 27 . Recently , various studies have analyzed the issue of synchronizing chaotic networks with time errors 28 - 30 .For instance , Wu et al . 31 presented a new approach to realize lag - synchronized chaos between two chaotic structures with varying dimensions through state feedback controllers .Liu et al . 32 designed a new delayed - feedback controller to synchronize two chaotic structures with unknown parameters .Wang et al . 33 developed a simple but effective theory to synchronize two chaotically oscillating systems with time - differing delays .Although these results provide useful insights into the model of synchronized turbulent systems with time - errors , they cannot be applied directly to solve practical questions because it could took too",
        "rewrite_text": "**Title:** Properties of Zero-Lag Long-Range Synchronization via Dynamical Relaying\n\n**Abstract:** This study investigates the phenomenon of zero-lag synchronization between two independent turbulent systems characterized by varying time scales, utilizing a dynamical relaying model. This model introduces an intermediary system that facilitates data transmission between the two systems, enabling synchronization without delay. Through stability analysis, we demonstrate that the proposed system can achieve zero-lag synchronization under specific conditions. To validate our theoretical findings, we conducted numerical simulations using Lorenz and Chen networks as case studies. The results indicate that our approach offers significant advantages over existing synchronization techniques, particularly in terms of resilience to parameter mismatches and external disturbances. \n\nSynchronization is a critical process across various disciplines, including biology, chemistry, and engineering. In recent years, the synchronization of chaotic systems has garnered considerable attention due to its potential applications in secure communication, chemical processes, and biological systems. The foundational work by Pecora and Carroll introduced the concept of master-slave synchronization, leading to the development of numerous strategies such as adaptive control, active control, and sliding mode control. However, much of the existing literature has primarily focused on scenarios without delays between the master and slave systems. \n\nRecent research has begun to address the challenges of synchronizing chaotic networks in the presence of time delays. For example, Wu et al. proposed a method for achieving lag-synchronized chaos between chaotic systems with varying dimensions using state feedback controllers. Similarly, Liu et al. introduced a delayed-feedback controller for synchronizing chaotic structures with unknown parameters, while Wang et al. developed a theory for synchronizing systems with differing time delays. Although these studies provide valuable insights into the synchronization of turbulent systems with time discrepancies, they often fall short of addressing practical applications due to the complexities involved. Our work aims to bridge this gap by presenting a robust framework for zero-lag synchronization that can be applied to real-world scenarios.",
        "ori-fast-z-score": -0.47733437050543803,
        "water-fast-z-score": 8.009821015753255,
        "rewrite-fast-z-score": 0.7006490497453707
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The 2003 Outburst of the X-ray Transient H 1743-322: Comparisons with the Black Hole Microquasar XTE J1550-564 .\nAbstract:\nWe present an analysis of Rossi-XTE observations of the black hole candidate transient source H 1743-232 during its outburst in 2003, which was discovered by RXTE ASM on September 27 and reached peak fluxes of ~100 mCrab (2-10 keV). The light curve shows two distinct flaring episodes separated by about one month; we find that these are well described as exponential rise/decay profiles with decay timescales of ~10 days each. We compare this behavior to that observed for another black hole microquasar, XTE J1550- 564, whose outbursts were also monitored extensively by RXTE. In particular, we show that the first flare is very similar to the second flare seen in XTE J1550-564: both have comparable durations, luminosities, and spectral shapes at their peaks. However, there are some differences between them: while the second flare decays more slowly than the first flare, it has a much lower luminosity when compared to the first flare.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The 2003 Outburst of the X - ray Transient H 1743 - 322 : Comparisons with the Black Hole Microquasar XTE J1550 - 564 . Abstract : We report an assessment of Rossi - XTE observations of the dark hole candidate transient source H 1743 - 232 during its outburst in 2003 , which was discovered by RXTE ASM on September 27 and reached peak fluxes of ~ 100 mCrab ( 2 - 10 keV ) .The light curve shows two unique flaring events separated by about one month ; we find that these are better represented as exponential gain / decay profiles with degradation timescales of ~ 10 days each . We relate this behavior to that detected for another dark hole microquasar , XTE J1550 - 564 , whose outbursts were also controlled extensively by RXTE .In particular , we find that the first flare is very identical to the second flare seen in XTE J1550 - 564 : both have equal durations , luminosities , and spectral patterns at their peaks . However , there are some variations between them : while the second flare decays more slowly than the first flare , it has a far lower luminosity when compared to the first flare .",
        "rewrite_text": "In this study, we present a detailed analysis of the Rossi X-ray Timing Explorer (RXTE) observations of the black hole candidate transient source H 1743-322 during its notable outburst in 2003. This event was initially detected by the RXTE All-Sky Monitor (ASM) on September 27, 2003, and it achieved peak flux levels of approximately 100 mCrab in the 2-10 keV energy range. Our investigation reveals a light curve characterized by two distinct flaring events that occurred roughly one month apart. We model these flares using exponential gain and decay profiles, identifying degradation timescales of approximately 10 days for each event.\n\nTo contextualize our findings, we draw comparisons with another well-studied black hole microquasar, XTE J1550-564, which has also been extensively monitored by RXTE during its outbursts. Notably, we observe that the first flare of H 1743-322 closely resembles the second flare of XTE J1550-564, as both flares exhibit similar durations, luminosities, and spectral characteristics at their peak emissions. However, we also note significant differences between the two sources. Specifically, while the second flare of H 1743-322 exhibits a slower decay rate compared to its initial flare, it is characterized by a considerably lower luminosity.\n\nThis comparative analysis enhances our understanding of the behavior of black hole transients and microquasars, shedding light on the underlying mechanisms driving their outbursts. The similarities and differences observed in the flaring patterns of H 1743-322 and XTE J1550-564 provide valuable insights into the dynamics of accretion processes in black hole systems, contributing to the broader field of high-energy astrophysics.",
        "ori-fast-z-score": -0.12403473458920847,
        "water-fast-z-score": 5.41602560309064,
        "rewrite-fast-z-score": 2.6696952498876585
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Non-Cooperative Scheduling of Multiple Bag-of-Task Applications .\nAbstract:\nWe consider the problem of scheduling multiple bag-of-work applications on parallel machines with non-cooperative tasks, where each task has its own deadline and budget constraints. We propose an algorithm that is based on the idea of partitioning time into intervals such that all tasks in one interval can be scheduled simultaneously without violating their deadlines or budgets. The proposed algorithm uses dynamic programming to find the optimal schedule for these intervals. Finally, we show how this approach can be extended to handle more general cases by using bin-packing techniques. Our experimental results demonstrate significant performance improvements over existing algorithms. In particular, our algorithm outperforms state-of-the-art approaches when there are many small tasks and/or tight deadlines/budgets. Keywords: Parallel computing, Computational complexity theory, Computational geometry, Data mining, Bioinformatics, High-performance computing, Grid computing, Cloud computing, Big data analysis, Distributed systems",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Non - Cooperative Scheduling of Multiple Bag - of - Task Applications . Abstract : We consider the issue of scheduling multiple bag - of - work applications on parallel machines with non - cooperative tasks , where each work has its own deadline and funding limitations .We suggest an algorithm that is based on the idea of partitioning time into intervals such that all tasks in one interval can be scheduled simultaneously without violating their deadlines or budgets . The proposed algorithm employs dynamic programming to find the ideal schedule for these periods .Finally , we prove how this methodology can be improved to treat more general instances by using bin - packing methods . Our research results show considerable performance improvements over existing algorithms .In particular , our algorithm outperforms state - of - the - art methods when there are many small tasks and / or tight deadlines / budgets . Keywords : Parallel computing , Computational complexity analysis , Computational topology , Data mining , Bioinformatics , High - performance computing , Grid computing , Cloud computing , Big data analysis , Distributed systems",
        "rewrite_text": "Title: Non-Cooperative Scheduling of Multiple Bag-of-Task Applications\n\nAbstract: This study addresses the challenge of scheduling multiple bag-of-task applications on parallel machines, particularly in scenarios involving non-cooperative tasks. Each task is characterized by its own specific deadline and funding constraints, complicating the scheduling process. To tackle this issue, we propose a novel algorithm that partitions time into discrete intervals, allowing for the simultaneous scheduling of all tasks within a given interval without breaching their respective deadlines or budgetary limits. Our approach utilizes dynamic programming techniques to optimize the scheduling within these defined periods. Furthermore, we demonstrate how our methodology can be enhanced to accommodate a broader range of instances by integrating bin-packing strategies. The results of our research indicate significant performance enhancements compared to existing scheduling algorithms. Notably, our proposed algorithm excels in scenarios characterized by a high volume of small tasks and/or stringent deadlines and budget constraints. This advancement in scheduling efficiency has implications for various fields, including parallel computing, computational complexity analysis, computational topology, data mining, bioinformatics, high-performance computing, grid computing, cloud computing, big data analysis, and distributed systems. Our findings contribute to the ongoing discourse in the field of computational scheduling, offering a robust solution for optimizing task allocation in non-cooperative environments.",
        "ori-fast-z-score": -0.22086305214969307,
        "water-fast-z-score": 5.019011475427825,
        "rewrite-fast-z-score": 1.532838378934635
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The IDV source J1128+5925, a new candidate for annual modulation? .\nAbstract:\nWe report on the results of an analysis of data taken by the INTEGRAL satellite in 2003 and 2004 . We find that the hard X-ray emission from this source is modulated with a period of about one year. The amplitude of the modulation is at least 50% (3 sigma). This result suggests that the source may be similar to other galactic sources which show evidence for periodic variability due to accretion onto a neutron star or black hole. \n \n Keywords: High energy astrophysics - Gamma rays - Black holes - Neutron stars - Accreting binaries - Pulsar wind nebulae - Inverse Compton scattering - Galactic center - Galaxy - Supernova remnants - Blazars - AGN - Cosmic rays - Fermi/LAT - TeV blazar - Variability - Periodicities - INTEGRAL - X-rays - Hard X-rays - Soft gamma-ray bursts - Transient objects - Radio pulsar",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The IDV source J1128 + 5925 , a new nominee for annual modulation ? .Abstract : We report on the conclusion of an assessment of measurements taken by the INTEGRAL satellite in 2003 and 2004 . We see that the hard X - ray radiation from this source is modulated with a period of about one year .The amplitude of the modulation is at least 50 % ( 3 sigma ) . This result suggests that the source may be similar to other galactic sources which show proof for periodic variability due to accretion onto a neutron star or black hole .Keywords : High energy astrophysics - Gamma rays - Black holes - Neutron stars - Accreting binaries - Pulsar wind nebulae - Inverse Compton scattering - Galactic center - Galaxy - Supernova remnants - Blazars - AGN - Cosmic rays - Fermi / LAT - TeV blazar - Variability - Periodicities - INTEGRAL - X - radiation - Hard X - radiation - Soft gamma - ray waves - Transient objects - Radio pulsar",
        "rewrite_text": "**Title:** The IDV Source J1128 + 5925: A Potential Candidate for Annual Modulation\n\n**Abstract:** In this study, we present the findings from an extensive analysis of data collected by the INTEGRAL satellite during the years 2003 and 2004, focusing on the source J1128 + 5925. Our investigation reveals that the hard X-ray emissions from this celestial object exhibit a modulation period of approximately one year. Notably, the observed amplitude of this modulation is significant, reaching at least 50% at a confidence level of 3 sigma. This intriguing result indicates that J1128 + 5925 may share characteristics with other known galactic sources that demonstrate periodic variability, likely due to the accretion processes occurring around neutron stars or black holes. The implications of these findings are substantial, as they suggest that J1128 + 5925 could be an important addition to the growing list of sources exhibiting annual modulation, which may provide insights into the underlying mechanisms of high-energy astrophysical phenomena. Our research contributes to the broader understanding of accreting binaries and their behavior, particularly in relation to pulsar wind nebulae and the effects of inverse Compton scattering. Furthermore, the periodicity observed in J1128 + 5925 could have implications for the study of supernova remnants, blazars, active galactic nuclei (AGN), and cosmic rays, as well as their interactions with the galactic center and the surrounding galaxy. This work underscores the importance of continued monitoring and analysis of transient objects in the high-energy regime, as well as the potential for future discoveries in the field of high-energy astrophysics. \n\n**Keywords:** High energy astrophysics, Gamma rays, Black holes, Neutron stars, Accreting binaries, Pulsar wind nebulae, Inverse Compton scattering, Galactic center, Galaxy, Supernova remnants, Blazars, AGN, Cosmic rays, Fermi/LAT, TeV blazar, Variability, Periodicities, INTEGRAL, X-radiation, Hard X-radiation, Soft gamma-ray waves, Transient objects, Radio pulsar.",
        "ori-fast-z-score": 0.13245323570650439,
        "water-fast-z-score": 3.151354388633341,
        "rewrite-fast-z-score": 0.7184212081070996
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Intricate Knots in Proteins: Function and Evolution .\nAbstract:\nThe authors present an overview of the role that knots play in proteins, with particular emphasis on their function and evolution.  They discuss how protein knots are formed by covalent bonds between amino acids (the building blocks of proteins) as well as non-covalent interactions such as hydrogen bonding.  The authors also describe how different types of knots can be classified based upon their topology.   Finally they explain why it is important to study knots in proteins since these structures may have evolved for specific functions or because they provide stability against proteolysis (breakdown into smaller peptides).    This article was originally published on BioMed Central. It has been re-posted here under Creative Commons License 3.0. Protein knots are intriguing structural motifs found within many naturally occurring polypeptides. These knotted conformations result from noncovalent interactions among residues along the backbone chain combined with covalent cross-linkages at certain positions. In this review we summarize our current understanding about the formation mechanisms of various knot topologies observed in nature. We then highlight recent advances made toward characterizing the functional roles played by protein knots.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Intricate Knots in Proteins : Function and Evolution . Abstract : The authors present an overview of the importance that knots play in proteins , with particular focuses on their function and evolution .They explore how protein knots are created by covalent bonds between amino acids ( the built stones of proteins ) as well as un - covalent interactions such as hydrogen bonding . The authors additionally describe how various types of knots can be categorized according upon their topology .Finally they explain why it is important to study knots in proteins since these structures could have originated for specific roles or because they give stability against proteolysis ( degradation into tiny peptides ) . This section was originally published on BioMed Central .It has been re - posted here under Creative Commons License 3 . 0 . Protein knots are intriguing structural motifs discovered within many naturally occurring polypeptides .These knotted conformations result from noncovalent interactions among residues along the backbone ring coupled with covalent cross - linkages at different positions . In this review we summarize our latest understanding about the formation factors of several knot topologies discovered in nature .We then highlight recent developments seen toward characterizing the functional functions played by protein knots .",
        "rewrite_text": "**Title: Intricate Knots in Proteins: Function and Evolution**\n\n**Abstract:** This article provides a comprehensive examination of the role of knots in protein structures, emphasizing their functional significance and evolutionary implications. The authors delve into the mechanisms by which protein knots are formed, highlighting the role of covalent bonds between amino acids—the fundamental building blocks of proteins—as well as non-covalent interactions, such as hydrogen bonding. The study categorizes various knot types based on their topological characteristics, offering insights into the diversity of these structures. The importance of investigating knots in proteins is underscored, as these configurations may have evolved for specific biological functions or to enhance stability against proteolytic degradation, which breaks proteins down into smaller peptides. Originally published in BioMed Central, this section has been re-shared under Creative Commons License 3.0. \n\nProtein knots represent fascinating structural motifs found in numerous naturally occurring polypeptides. These knotted formations arise from a combination of non-covalent interactions among residues along the protein backbone and covalent cross-linkages at various sites. In this review, we summarize the latest insights into the factors influencing the formation of different knot topologies observed in nature. Additionally, we discuss recent advancements in understanding the functional roles that protein knots may play, shedding light on their significance in biological processes. This exploration not only enhances our knowledge of protein structure but also opens avenues for further research into the evolutionary aspects of these intriguing molecular configurations.",
        "ori-fast-z-score": 0.20412414523193154,
        "water-fast-z-score": 6.262945776223707,
        "rewrite-fast-z-score": 0.09245003270420485
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Laplacian spectra of complex networks and random walks on them: Are scale-free architectures really important? .\nAbstract:\nWe study the Laplacian spectrum of complex networks, focusing in particular on its relation to the dynamics of random walks on them. We show that for any network with n nodes there are at most 2n eigenvalues different from zero (counting multiplicities). This bound is tight up to a constant factor when applied to trees or complete graphs. For general graphs we prove an upper bound of O(n log n) on the number of distinct nonzero eigenvalues. In addition, we provide lower bounds showing that this estimate cannot be improved by more than a polylogarithmic factor. Finally, we present numerical evidence suggesting that real-world networks have only few distinct nonzero eigenvalues. These results suggest that the spectral properties of complex networks may not depend strongly on their degree distribution but rather on other structural features such as clustering coefficients. The analysis presented here can also be used to derive new bounds on mixing times of Markov chains defined over these networks.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Laplacian spectra of complex networks and random runs on them : Are scale - free architectures really important ? .Abstract : We research the Laplacian spectrum of complex networks , concentrating in particular on its connection to the dynamics of random runs on them . We see that for any connection with n nodes there are at most 2n eigenvalues different from zero ( counting multiplicities ) .This bound is tight up to a constant factor when applied to forests or perfect graphs . For general graphs we prove an upper bound of O ( n log n ) on the number of distinct nonzero eigenvalues .In addition , we provide lower bounds indicating that this estimate cannot be improved by more than a polylogarithmic factor . Finally , we present numerical information suggesting that real - time systems have only few distinct nonzero eigenvalues .These conclusions show that the spectral properties of complex networks may not depend greatly on their degree function but rather on other structural components such as clustering coefficients . The evaluation provided here can also be used to derive new limits on mixing times of Markov chains defined over these networks .",
        "rewrite_text": "In this study, we investigate the Laplacian spectrum of complex networks, with a particular focus on its relationship to the dynamics of random processes occurring on these networks. Our findings reveal that for any network comprising n nodes, there can be at most 2n distinct eigenvalues that are non-zero, when accounting for their multiplicities. This upper limit is shown to be tight, up to a constant factor, in the case of forests and perfect graphs. For more general graph structures, we establish an upper bound of O(n log n) on the number of distinct non-zero eigenvalues. Furthermore, we provide lower bounds that indicate this upper estimate cannot be improved by more than a polylogarithmic factor. Our numerical analyses suggest that real-time systems tend to exhibit a limited number of distinct non-zero eigenvalues. These results imply that the spectral characteristics of complex networks may not be significantly influenced by their degree distribution; instead, they may be more closely related to other structural features, such as clustering coefficients. The insights gained from this research can also be leveraged to formulate new constraints on the mixing times of Markov chains defined over these complex networks. Overall, our work contributes to a deeper understanding of the interplay between the spectral properties of networks and their underlying structural attributes, challenging the notion that scale-free architectures are of paramount importance in determining these properties.",
        "ori-fast-z-score": -0.20412414523193154,
        "water-fast-z-score": 4.4907311951024935,
        "rewrite-fast-z-score": 2.3312620206007844
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gravitational Stability of Circumnuclear Disks in Elliptical Galaxies .\nAbstract:\nWe study the stability properties of circumnuclear disks (CNDs) embedded within elliptical galaxies, using N-body simulations with live dark matter halos and stellar components. We find that CNDs are generally stable against bar formation for most reasonable disk parameters. However, we also show that if the central black hole is massive enough to dominate the gravitational potential at small radii, then it can induce strong bars or even destroy the entire disk. This result suggests that the presence of a supermassive black hole may be responsible for some observed nuclear bars in nearby elliptical galaxies. \n \n Keywords: Gravitational instability; Black holes; Bars; Nuclear activity; Galaxy evolution; Disk galaxies; Dark matter halos; Stellar dynamics; Cosmology \n \n 1 Introduction \n \n The existence of nuclear bars has been inferred observationally by several authors based on photometric data (e.g., Laine et al. 2002; Erwin 2004) . In particular, Erwin & Sparke (2003) found that about half of their sample of early-type galaxies have nuclear bars. These results suggest that nuclear bars play an important role in galaxy evolution. For example, they could provide fuel for active galactic nuclei through gas inflow into the center of the host galaxy (Shlosman et al. 1990 ). On the other hand, there are only few observational studies which directly detect nuclear bars via high-resolution imaging techniques such as HST observations (Erwin 2004; Sheth et al. 2005) , mainly due to technical difficulties associated with resolving very compact structures near the centers of distant galaxies. Therefore, theoretical investigations of the dynamical behavior of nuclear bars will help us understand how these objects evolve over time. \n \n 2 Previous Work \n \n Several previous works studied the stability of nuclear bars in elliptical galaxies. Athanassoula et al. (2005a) performed numerical experiments where they added a rigidly rotating spherical component representing a bulge to a model consisting of a live halo and a rigidly rotating disk. They showed that this system becomes unstable when the mass ratio between the bulge and the disk exceeds a critical value",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Gravitational Stability of Circumnuclear Disks in Elliptical Galaxies . Abstract : We research the stability properties of circumnuclear drives ( CNDs ) lodged within elliptical galaxies , using N - bodies simulations with live dark matter halos and stellar parts .We see that CNDs are typically strong against bar structure for most reasonable disk variables . However , we also prove that if the main dark hole is massive enough to dominate the gravitational potential at small radii , then it can induce strong bars or even kill the entire disk .This result suggests that the presence of a supermassive black hole may be responsible for some observed nuclear bars in nearby elliptical galaxies . Keywords : Gravitational instability ; Black holes ; Bars ; Nuclear activity ; Galaxy growth ; Disk galaxies ; Dark matter halos ; Stellar dynamics ; Cosmology 1 Introduction The existence of nuclear bars has been inferred observationally by many writers based on photometric data ( e . g . , Laine et al .2002 ; Erwin 2004 ) . In particular , Erwin & Sparke ( 2003 ) found that about half of their sample of early - class objects have nuclear bars .These data suggest that atomic chains serve an important role in universe growth . For instance , they may provide energy for active galactic nuclei through gas inflow into the center of the host galaxy ( Shlosman et al .1990 ) . On the other hand , there are only few observational surveys which directly identify atomic bars via high - resolution optical techniques such as HST observations ( Erwin 2004 ; Sheth et al .2005 ) , mainly owing to technical problems related with resolving very small structures near the centers of distant galaxies . Therefore , theoretical investigations of the dynamical behavior of nuclear bars will assist us explain how these objects evolve over time .2 Previous Work Several earlier works studied the stability of nuclear bars in elliptical galaxies . Athanassoula et al .( 2005a ) completed numerical studies where they added a rigidly rotating spherical component representing a bulge to a simulation consisting of a living halo and a rigidly rotating disk . They showed that this scheme becomes unstable when the mass ratio between the bulge and the disk exceeds a critical value",
        "rewrite_text": "**Title:** Gravitational Stability of Circumnuclear Disks in Elliptical Galaxies\n\n**Abstract:** This study investigates the stability characteristics of circumnuclear disks (CNDs) situated within elliptical galaxies, employing N-body simulations that incorporate dynamic dark matter halos alongside stellar components. Our findings indicate that CNDs generally exhibit resilience against the formation of bar structures across a wide range of disk parameters. However, we demonstrate that when a supermassive black hole possesses sufficient mass to dominate the gravitational potential in the innermost regions, it can trigger the formation of robust bars or even disrupt the entire disk structure. This outcome implies that the presence of a supermassive black hole may play a significant role in the emergence of nuclear bars observed in several nearby elliptical galaxies. \n\nThe existence of nuclear bars has been inferred from various observational studies, with notable contributions from researchers such as Laine et al. (2002) and Erwin (2004). Specifically, Erwin & Sparke (2003) reported that approximately half of the early-type galaxies in their sample exhibit nuclear bars, suggesting that these structures are crucial for the growth of galaxies. For instance, they may facilitate energy transfer to active galactic nuclei through the inflow of gas toward the galactic center, as proposed by Shlosman et al. (1990). Despite this, there are limited observational surveys that directly identify nuclear bars using high-resolution optical techniques, such as those conducted with the Hubble Space Telescope (HST), due to challenges in resolving minute structures in the centers of distant galaxies. Consequently, theoretical studies examining the dynamical behavior of nuclear bars are essential for understanding their evolutionary processes.\n\nPrevious research has explored the stability of nuclear bars in elliptical galaxies. For example, Athanassoula et al. (2005a) conducted numerical simulations incorporating a rigidly rotating bulge component alongside a live halo and a rigid disk. Their results indicated that the system becomes unstable when the mass ratio between the bulge and the disk surpasses a critical threshold. This work lays the groundwork for further exploration of the intricate dynamics governing CNDs and their interactions with supermassive black holes in elliptical galaxies. \n\n**Keywords:** Gravitational instability; Black holes; Bars; Nuclear activity; Galaxy growth; Disk galaxies; Dark matter halos; Stellar dynamics; Cosmology.",
        "ori-fast-z-score": 0.457495710997814,
        "water-fast-z-score": 7.570719217728538,
        "rewrite-fast-z-score": 0.22941573387056177
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Truecluster matching .\nAbstract:\nWe present an algorithm for finding the optimal matching between two sets of clusters, which we call  trueclusters .  The truecluster is defined as a set of points in high-dimensional space that are close to each other and far away from all other points in this space.   We show how our method can be used to find the best alignment between two point clouds obtained by different sensors or at different times.   ... \nIntroduction\n\nThe problem addressed here is one of data association - given two sets of observations (e.g., images), determine what pairs correspond to the same physical object.  This problem arises frequently when dealing with multiple views of objects such as those shown in Figure 1 , where it may not always be possible to obtain perfect registration between the two images due to calibration errors, occlusions, etc.\n\nIn many applications, there exists some prior knowledge about the correspondence between the two sets of observations;  e.g., if they were taken using the same sensor but at different times, then their relative pose will be known up to a scale factor.  In these cases, the goal becomes to use this information to improve the accuracy of the final solution.  \n\nOur approach relies on the concept of a  truecluster :   A truecluster is a set of points in a high dimensional space whose members are close together while being far apart from any other points in the space.  For example, consider the case of registering two images of a scene containing several people standing next to each other.  Each person forms its own truecluster since his/her appearance does not change significantly over time.  On the other hand, the background changes dramatically so no single cluster corresponds to the entire background region. \n\nGiven two sets of trueclusters corresponding to the first and second observation respectively, we want to find the optimal assignment between them.  To do this, we define a cost function based on the distances between the points within each truecluster pair.  Then, we formulate the problem as a quadratic integer program and solve it efficiently using branch-and-bound techniques.  Finally,...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Truecluster matching . Abstract : We present an algorithm for finding the ideal matching between two sets of clusters , which we call trueclusters .The truecluster is characterized as a setting of points in high - dimensional space that are close to each other and far away from all other points in this space . We see how our technique can be used to find the best orientation between two point clouds acquired by various cameras or at different times .. . . Introduction The question presented here is one of data association - given two sets of measurements ( e . g . , photographs ) , determine what pairs relate to the same physical item . This problem arises often when dealing with many visions of items such as those shown in Figure 1 , where it must not always be possible to obtain good recognition between the two images resulting to calibration errors , occlusions , etc .In many applications , there exists some prior information about the correspondence between the two sets of measurements ; e . g . , if they were took use the same sensor but at different times , then their relative pose will be known up to a scale factor . In these circumstances , the objective remains to use this data to improve the accuracy of the finished problem .Our concept rely on the idea of a truecluster : A truecluster is a setting of points in a high dimensional space whose members are close together while being far separate from any other points in the space . For instance , consider the case of registering two portraits of a scene containing several people standing close to each other .Each person creates its own truecluster since his / her appearance does not change considerably over time . On the other hand , the background changes dramatically so no single cluster corresponds to the entire background area .Given two sets of trueclusters corresponding to the first and second observation respectively , we try to find the ideal assignment between them . To do this , we define a price function based on the distances between the points within each truecluster pair .Then , we formulate the question as a quadratic integer program and solve it easily using branch - and - bound techniques . Finally , . . .",
        "rewrite_text": "**Title:** Truecluster Matching\n\n**Abstract:** In this paper, we introduce a novel algorithm designed to identify the optimal matching between two sets of clusters, which we refer to as trueclusters. A truecluster is defined as a collection of points in high-dimensional space that are closely grouped together while remaining distant from other points. Our method effectively addresses the challenge of aligning two point clouds captured by different cameras or at various time intervals. The core problem we tackle is data association, which involves determining the relationships between pairs of measurements, such as photographs, that correspond to the same physical object. This issue frequently arises in scenarios where multiple views of an object are obtained, as illustrated in Figure 1. In such cases, achieving accurate recognition between images can be hindered by factors like calibration errors and occlusions. \n\nIn many practical applications, prior knowledge about the correspondence between the two measurement sets exists; for example, if the images were taken using the same sensor at different times, the relative pose can be determined, albeit with an unknown scale factor. Our goal is to leverage this information to enhance the accuracy of the matching process. The concept of a truecluster plays a pivotal role in our approach. Each truecluster represents a group of points that are closely related, such as individuals in a portrait, whose appearances remain relatively stable over time, in contrast to the dynamic background that does not form a cohesive cluster.\n\nTo establish the optimal assignment between two sets of trueclusters from the first and second observations, we develop a pricing function based on the distances between points within each truecluster pair. We then frame the problem as a quadratic integer programming challenge, which we efficiently solve using branch-and-bound techniques. Our findings demonstrate the effectiveness of this algorithm in achieving accurate truecluster matching, paving the way for improved data association in various applications.",
        "ori-fast-z-score": -0.15339299776947407,
        "water-fast-z-score": 7.056077897395808,
        "rewrite-fast-z-score": 0.5622535302317492
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Conservation laws. Generation of physical fields. Principles of field theories .\nAbstract:\nThe book is intended for graduate students in physics and mathematics, as well as researchers working on the foundations of quantum mechanics.  The first part deals with conservation laws (energy-momentum) and generation of physical fields by sources. In particular, it contains an introduction to gauge invariance and its role in modern physics. The second part presents basic principles of field theory. It includes chapters devoted to Lagrangian formalism, quantization rules, Feynman diagrams, renormalization group methods etc. This textbook covers all topics that are usually included into courses on Quantum Field Theory at universities. The text is written in a clear style without using too many mathematical formulas. All necessary definitions and theorems are presented in detail. A large number of examples illustrate various concepts discussed throughout the book. An extensive set of exercises helps readers to understand main ideas behind each chapter. The solutions to most problems can be found in the end of the book.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Conservation laws . Generation of physical areas .Principles of field theories . Abstract : The text is intended for graduate studying in science and mathematics , as well as scientists studying on the foundations of quantum mechanics .The first part deals with conservation laws ( electricity - momentum ) and generation of physical fields by sources . In particular , it contains an introduction to gauge invariance and its role in modern physics .The second part offers basic concepts of field theory . It includes sections devoted to Lagrangian formalism , quantization rules , Feynman diagrams , renormalization group theory etc .This book covers all issues that are typically included into courses on Quantum Field Theory at institutions . The text is authored in a clear style without using too several mathematical formulas .All necessary theories and theorems are presented in detail . A wide series of instances explain different concepts discussed throughout the book .An elaborate series of exercises aids viewers to comprehend main ideas behind each volume . The answer to most problems can be found in the end of the book .",
        "rewrite_text": "**Title:** Conservation Laws, Generation of Physical Fields, and Principles of Field Theories\n\n**Abstract:** This article is designed for graduate students in science and mathematics, as well as researchers exploring the foundational aspects of quantum mechanics. The first section focuses on conservation laws, specifically electricity and momentum, and examines how physical fields are generated by various sources. A significant emphasis is placed on gauge invariance, highlighting its critical importance in contemporary physics. The second section introduces fundamental concepts of field theory, encompassing essential topics such as Lagrangian formalism, quantization methods, Feynman diagrams, and renormalization group theory. This comprehensive text addresses all the key topics typically covered in Quantum Field Theory courses at academic institutions. Written in a clear and accessible style, the article minimizes the use of complex mathematical formulas while thoroughly explaining necessary theories and theorems. A diverse array of examples is provided to illustrate the various concepts discussed throughout the text. Additionally, a well-structured set of exercises is included to help readers grasp the core ideas presented in each section. Solutions to most of the problems are conveniently located at the end of the article, facilitating self-assessment and deeper understanding. Overall, this work serves as a valuable resource for those seeking to deepen their knowledge of conservation laws and field theories in the context of quantum mechanics.",
        "ori-fast-z-score": -0.9138115486202573,
        "water-fast-z-score": 5.527707983925667,
        "rewrite-fast-z-score": -0.658504607868518
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Microlens Parallax Measurements with a Warm Spitzer .\nAbstract:\nWe present the first microlensing parallax measurements made using infrared observations by the Wide-field Infrared Survey Explorer (WISE). We use these data to measure the mass and distance to two lensing systems, OGLE-2011-BLG-0341L/MOA-2011-BLG-262S and MOA-2012-BLG-0171. The former is an event in which the source star passes close to both lenses; we find that it has a total mass of 1.4 solar masses at a distance of 4 kpc. The latter system consists of three bodies -the lens, its host star, and another distant companion-that are all gravitationally bound together. This binary-lens event exhibits significant deviations from standard single-lens behavior due to the presence of this third body. Using our new measurement technique, we determine the mass ratio between the lens components as well as their projected separation on the sky.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Microlens Parallax Measurements with a Warm Spitzer . Abstract : We report the first microlensing parallax observations made using infrared observations by the Wide - field Infrared Survey Explorer ( WISE ) .We use these information to measure the mass and distance to two lensing systems , OGLE - 2011 - BLG - 0341L / MOA - 2011 - BLG - 262S and MOA - 2012 - BLG - 0171 . The former is an event in which the source galaxy goes close to both lenses ; we find that it has a total mass of 1 . 4 solar masses at a distance of 4 kpc .The latter system contains of three bodies - the lens , its host star , and another distant sister - that are all gravitationally locked together . This binary - lens event displays substantial deviations from standard single - lens activity related to the presence of this third body .Using our new gauge methodology , we determine the mass ratio between the lens components as well as their estimated separation on the sky .",
        "rewrite_text": "We present the inaugural microlensing parallax observations conducted using infrared data from the Wide-field Infrared Survey Explorer (WISE). This study focuses on two distinct lensing systems: OGLE-2011-BLG-0341L/MOA-2011-BLG-262S and MOA-2012-BLG-0171. In the first case, the source galaxy approaches both lensing objects, allowing us to derive a total mass of 1.4 solar masses for the system, situated at a distance of approximately 4 kiloparsecs. The second system is more complex, comprising three gravitationally bound entities: the lens, its host star, and a more distant companion. This binary-lens event exhibits notable deviations from the typical behavior expected in single-lens scenarios, attributable to the influence of the third body. By employing our innovative measurement techniques, we successfully calculate the mass ratio between the lens components and estimate their spatial separation on the celestial plane. These findings not only enhance our understanding of microlensing phenomena but also contribute valuable insights into the dynamics of multi-body systems in gravitational lensing contexts. The results underscore the potential of infrared observations in advancing microlensing studies and provide a foundation for future research aimed at unraveling the complexities of gravitational interactions in the universe.",
        "ori-fast-z-score": -0.47809144373375745,
        "water-fast-z-score": 2.3570226039551585,
        "rewrite-fast-z-score": 0.8164965809277261
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Methods for determining AGB mass loss rates based on radio data .\nAbstract:\nWe present new methods to determine the mass-loss rate in evolved stars (AGB) using radio observations at centimeter wavelengths, and compare these results with those obtained by infrared dust emission measurements. We use archival VLA data of three nearby carbon-rich AGB stars, IK Tau, IRC+10216, and AFGL 3068, which are known to have high mass-loss rates. The observed flux densities were compared with predictions made by spherically symmetric radiative transfer models that include both free-free and thermal dust emission components. For each star we find good agreement between our model predictions and the observed flux density values when assuming an appropriate value for the mass-loss rate. Our results show that the mass-loss rates derived from radio continuum observations can be used as reliable estimates of the total mass lost during the late stages of stellar evolution.  These results also demonstrate how radio observations can provide important constraints on theoretical models of circumstellar envelopes around evolved stars.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Methods for determining AGB mass loss rates based on radio data . Abstract : We present new strategies to estimate the mass - loss rate in evolution stars ( AGB ) using radio observations at centimeter wavelengths , and compare these results with those achieved by infrared dust radiation observations .We use archival VLA information of three nearby carbon - rich AGB stars , IK Tau , IRC + 10216 , and AFGL 3068 , which are known to have high mass - loss rates . The observed flux densities were compared with predictions taken by spherically symmetric radiative transfer estimates that include both free - free and thermal dust absorption elements .For each star we find good agreement between our model observations and the observed flux density estimates when assuming an appropriate estimate for the mass - loss rate . Our results show that the mass - loss rates derived from radio continuum measurements can be used as reliable estimates of the total mass dropped during the last phases of stellar evolution .These data also demonstrate how radio observations can provide important restrictions on theoretical theories of circumstellar envelopes around evolved stars .",
        "rewrite_text": "In this study, we introduce novel methodologies for estimating mass-loss rates in asymptotic giant branch (AGB) stars through the analysis of radio data at centimeter wavelengths. We juxtapose these findings with results obtained from infrared observations of dust radiation. Our research utilizes archival Very Large Array (VLA) data from three nearby carbon-rich AGB stars: IK Tau, IRC + 10216, and AFGL 3068, all of which are characterized by significant mass-loss rates. By comparing the observed flux densities of these stars with predictions derived from spherically symmetric radiative transfer models—incorporating both free-free emission and thermal dust absorption—we establish a framework for understanding the mass-loss processes in these evolved stars.\n\nFor each of the selected stars, we observe a strong correlation between our model predictions and the measured flux density, contingent upon accurately estimating the mass-loss rate. This congruence suggests that mass-loss rates inferred from radio continuum observations can serve as dependable indicators of the total mass expelled during the final stages of stellar evolution. Furthermore, our findings underscore the potential of radio observations to impose critical constraints on theoretical models concerning the circumstellar envelopes surrounding evolved stars. By enhancing our understanding of mass-loss mechanisms through radio data, this research contributes to the broader discourse on stellar evolution and the lifecycle of stars, providing insights that could refine existing theoretical frameworks. Overall, our work highlights the importance of integrating radio observations into the study of AGB stars, paving the way for future investigations into the complexities of stellar mass loss.",
        "ori-fast-z-score": 0.29277002188455997,
        "water-fast-z-score": 4.467914966843415,
        "rewrite-fast-z-score": 0.17407765595569785
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Space Velocities of Southern Globular Clusters. V. A Low Galactic Latitude Sample .\nAbstract:\nWe have measured the space velocities for eight globular clusters in the southern hemisphere with galactic latitudes less than 20 degrees, using proper motions and radial velocities obtained by various authors over the past decade or so.  The sample includes four open clusters (NGC 2420 , NGC 2516 , NGC 2682 , and NGC 6705 ) as well as four globulars . We find that all but one cluster are consistent with being at rest relative to the local standard of rest; however, we also find evidence that two of these clusters may be on orbits which will take them out of our galaxy within several billion years .  These results suggest that there is no significant difference between open clusters and globulars when it comes to their kinematics ; both types appear to share similar properties .\nThe only exception appears to be the open cluster M67 , whose velocity vector points away from us toward the constellation Cetus . This result suggests that this open cluster has been ejected from its parent galaxy during an encounter with another galaxy some time ago .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Space Velocities of Southern Globular Clusters.V. A Low Galactic Latitude Sample .Abstract : We have recorded the space velocities for eight globular complexes in the southern hemisphere with galactic latitudes less than 20 degrees , using proper motions and radial velocities collected by various authors over the previous decade or so . The sample comprises four open complexes ( NGC 2420 , NGC 2516 , NGC 2682 , and NGC 6705 ) as well as four globulars .We see that all but one cluster are compatible with being at remainder relative to the local standard of rest ; however , we also find proof that two of these clusters might be on orbits which will take them out of our universe within several billion decades . These conclusions show that there is no major variation between open nuclei and globulars when it comes to their kinematics ; both types seems to hold identical structures .The only exception appears to be the open cluster M67 , whose speed function points away from us toward the constellation Cetus . This result suggests that this open cluster has been expelled from its father galaxy during an encounter with another galaxy some time previously .",
        "rewrite_text": "Title: Space Velocities of Southern Globular Clusters: A Low Galactic Latitude Sample\n\nAbstract: In this study, we present an analysis of the space velocities of eight globular complexes located in the southern hemisphere, specifically those with galactic latitudes below 20 degrees. Utilizing proper motions and radial velocities compiled from various sources over the past decade, we have constructed a comprehensive dataset that includes four open clusters—NGC 2420, NGC 2516, NGC 2682, and NGC 6705—alongside four globular clusters. Our findings indicate that, with the exception of one cluster, all analyzed complexes exhibit velocities consistent with their positions relative to the local standard of rest. Notably, we have identified evidence suggesting that two of these clusters may be on trajectories that could eventually lead them to escape our galaxy over the course of several billion years. \n\nThese results reveal that there is no significant difference in the kinematic properties of open clusters compared to globular clusters, as both categories appear to share similar structural characteristics. The only notable anomaly is the open cluster M67, which exhibits a velocity vector directed away from us towards the constellation Cetus. This observation implies that M67 may have been ejected from its parent galaxy due to a past interaction with another galaxy. Overall, our research contributes to the understanding of the dynamics of southern globular complexes and highlights the intricate relationships between different types of star clusters within the galactic framework.",
        "ori-fast-z-score": -1.9126494315742406,
        "water-fast-z-score": 4.2485291572496005,
        "rewrite-fast-z-score": -2.487592975524973
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Composition-sensitive parameters measured with the surface detector of the Pierre Auger Observatory .\nAbstract:\nThe composition of cosmic rays is studied by measuring their energy spectrum and mass distribution at Earth. The most precise measurements are obtained using ground-based detectors, which measure extensive air showers produced in interactions between cosmic rays and atmospheric nuclei. In this work we present results on the measurement of shower depth profiles as well as several composition sensitive observables derived from them. These include the number of muons per meter water equivalent (N_m), the fraction of muons to electrons at 1000 m above sea level (f_1000) and the average logarithmic mass ln(A). We compare these results for different zenith angles and energies. For primary particles heavier than protons, f_1000 increases while N_m decreases with increasing zenith angle. This effect can be explained by the fact that heavy primaries interact higher up in the atmosphere where they produce more muons but fewer electrons compared to lighter primaries. At lower energies there seems to be an excess of events with low values of N_m and high values of f_1000 indicating a possible contribution from light primaries such as helium or nitrogen.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Composition - sensitive parameters calculated with the surface detector of the Pierre Auger Observatory . Abstract : The composition of cosmic rays is studied by monitoring their power spectrum and mass distribution at Earth .The most accurate measurements are produced using ground - based detectors , which measure immense air showers created in encounters between cosmic rays and atmospheric atoms . In this research we present results on the determination of shower depth profiles as also as several structure sensitive observables generated from them .These include the quantity of muons per foot water equivalent ( N _ m ) , the fraction of muons to ions at 1000 m above water level ( f _ 1000 ) and the average logarithmic mass ln ( A ) . We compare these results for different zenith angles and energies .For primary molecules heavier than protons , f _ 1000 increases while N _ m decreases with rising zenith angle . This phenomenon can be described by the fact that dark primaries react higher up in the air where they produce more muons but less electrons relative to lighter primaries .At lower energies there seems to be an amount of events with lowest values of N _ m and large values of f _ 1000 suggesting a possible involvement from light primaries such as helium or nitrogen .",
        "rewrite_text": "Title: Composition-Sensitive Parameters Derived from the Surface Detector of the Pierre Auger Observatory\n\nAbstract: The investigation of cosmic ray composition is conducted through the analysis of their power spectrum and mass distribution as they interact with the Earth's atmosphere. Ground-based detectors, particularly those that capture extensive air showers resulting from cosmic ray collisions with atmospheric particles, yield the most precise measurements. In this study, we present findings on the characterization of shower depth profiles along with various observables sensitive to the structure of these showers. Key parameters analyzed include the number of muons per foot of water equivalent (N_m), the ratio of muons to ions at a height of 1000 meters above sea level (f_1000), and the average logarithmic mass (ln(A)). Our results are examined across different zenith angles and energy levels. Notably, for primary particles that are heavier than protons, we observe an increase in f_1000 and a decrease in N_m as the zenith angle rises. This trend can be attributed to the behavior of heavier primaries, which interact at higher altitudes, generating a greater number of muons relative to electrons compared to lighter primaries. Additionally, at lower energy levels, we identify a subset of events characterized by low N_m values and high f_1000 values, indicating a potential contribution from lighter primary particles, such as helium or nitrogen. These insights enhance our understanding of cosmic ray composition and the underlying processes governing their interactions in the atmosphere.",
        "ori-fast-z-score": -1.6,
        "water-fast-z-score": 5.8707194222389365,
        "rewrite-fast-z-score": -0.0949157995752499
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nature of phase transition in magnetic thin films .\nAbstract:\nWe have studied the nature of phase transitions in FePt and CoPt alloys by measuring their magnetization as functions of temperature, applied field strength, and film thicknesses. The results show that both systems undergo first-order phase transitions at temperatures below 400 K with hysteresis loops. We also found that the coercivity increases rapidly when approaching to the Curie point (Tc) for all samples investigated here. This behavior is attributed to the increase of anisotropy energy density near Tc. \n \n In addition, we observed an interesting phenomenon where the coercive fields are strongly dependent on sample thicknesses. For example, the coercivities of FePt(5 nm), FePt(10 nm), and FePt(20 nm) films were measured to be 0.6 T, 1.1 T, and 2.2 T respectively. These values are much higher than those reported previously for bulk materials.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nature of phase shift in magnetic thin films . Abstract : We have researched the nature of phase transitions in FePt and CoPt alloys by monitoring their magnetization as functions of temperature , applied field intensity , and film thicknesses .The results show that both systems induce first - order phase transitions at pressures below 400 K with hysteresis loops . We additionally found that the coercivity increases quickly when approaching to the Curie point ( Tc ) for all specimens investigated here .This phenomenon is attributed to the increase of anisotropy energy density near Tc . In addition , we reported an interesting phenomenon where the coercive fields are strongly dependent on sample thicknesses .For instance , the coercivities of FePt ( 5 nm ) , FePt ( 10 nm ) , and FePt ( 20 nm ) films were calculated to be 0 . 6 T , 1 . 1 T , and 2 . 2 T respectively . These figures are quite greater than those published previously for bulk materials .",
        "rewrite_text": "Title: Nature of Phase Shift in Magnetic Thin Films\n\nAbstract: This study investigates the characteristics of phase transitions in FePt and CoPt alloy thin films by examining their magnetization in relation to temperature, applied magnetic field intensity, and film thickness. Our findings reveal that both FePt and CoPt systems exhibit first-order phase transitions at temperatures below 400 K, characterized by distinct hysteresis loops. Notably, we observed a significant increase in coercivity as the temperature approaches the Curie point (Tc) across all samples analyzed. This increase in coercivity is attributed to the enhancement of anisotropy energy density in proximity to Tc, indicating a strong correlation between thermal effects and magnetic properties. Furthermore, we discovered a remarkable dependence of coercive fields on the thickness of the samples. Specifically, the coercivities measured for FePt films of varying thicknesses—5 nm, 10 nm, and 20 nm—were found to be 0.6 T, 1.1 T, and 2.2 T, respectively. These values are substantially higher than those reported for bulk materials, suggesting that thin film geometry plays a crucial role in modifying magnetic behavior. Our results contribute to a deeper understanding of the phase transition dynamics in magnetic thin films and highlight the potential for engineering magnetic properties through controlled film thickness. This research opens avenues for further exploration of magnetic materials in applications such as data storage and spintronics, where tailored magnetic characteristics are essential.",
        "ori-fast-z-score": -1.3242443839434612,
        "water-fast-z-score": 3.1075943842694236,
        "rewrite-fast-z-score": 1.3348476249438292
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Hamiltonian Unification of General Relativity and Standard Model .\nAbstract:\nThe standard model is the most successful theory in particle physics, but it fails to explain gravity. In this article we present an alternative approach that unifies general relativity with quantum mechanics by using a new concept called  quantum potential energy density  (QPD). We show how QPD can be used as a source for gravitational field equations which are derived from Hamilton s principle of least action. The resulting field equations have solutions similar to those obtained from Einstein s field equations. However, unlike Einstein s field equations, our proposed field equations do not contain any free parameters such as cosmological constant or dark matter. This means that all physical phenomena predicted by these two theories should agree exactly if they are based on the same underlying principles. Finally, we discuss some possible experimental tests of our proposal. The standard model is the most succesful theory in particle physics, however it fails to explain gravity. \n \n In this article we present another approach that unifies general relavity with quantum mechanics by introducing a new concept called “quantum potental energy density”(QPD). \n \n Quantum potential energy density has been introduced previously by several authors  1-5 , but its role was limited only to explaining certain aspects of quantum mechanics like uncertainty relations  6 , tunneling effect  7-9 , wave-particle duality  10-12  etc.. \n \n Here we propose a novel interpretation of QPD where it plays a central role in deriving gravitational field equations. These field equations are then derived from Hamilton’s principle of least action. \n \n Our results suggest that QPD may play a fundamental role in understanding both gravity and quantum mechanics at their deepest level.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Hamiltonian Unification of General Relativity and Standard Model . Abstract : The standard theory is the most popular concept in particle theory , but it fails to explain gravity .In this article we present an additional method that unifies general relativity with quantum mechanics by using a new definition called quantum potential energy density ( QPD ) . We see how QPD can be used as a source for gravitational field equations which are derived from Hamilton s principle of least action .The resulting field equations have solutions identical to those achieved from Einstein s field equations . However , unlike Einstein s field equations , our proposed field equations do not include any free parameters such as cosmological factor or black material .This implies that all physical phenomena predicted by these two explanations should agree precisely if they are based on the same underlying principles . Finally , we talk some possible experimental tests of our proposal .The basic model is the most succesful model in particle science , however it fails to explain gravity . In this article we present another methodology that unifies general relavity with quantum mechanics by offering a new notion called “ particle potental energy density ” ( QPD ) .Quantum potential energy density has been proposed earlier by various literature 1 - 5 , but its significance was confined only to describing different areas of quantum mechanics like uncertainty relations 6 , tunneling effect 7 - 9 , wave - particle duality 10 - 12 etc . . Here we undertake a novel interpretation of QPD where it takes a central role in deriving gravitational field equations .These field equations are then constructed from Hamilton ’ s principle of least action . Our results propose that QPD may play a basic part in understanding both gravity and quantum mechanics at their deepest level .",
        "rewrite_text": "**Title:** Hamiltonian Unification of General Relativity and the Standard Model\n\n**Abstract:** The Standard Model of particle physics is widely regarded as the most successful framework for understanding fundamental particles and their interactions; however, it falls short in addressing the phenomenon of gravity. In this article, we introduce a novel approach that seeks to unify general relativity with quantum mechanics through the introduction of a new concept termed quantum potential energy density (QPD). We demonstrate how QPD can serve as a foundational source for the gravitational field equations, which are derived from Hamilton's principle of least action. The field equations we propose yield solutions that are consistent with those derived from Einstein's field equations. A significant distinction of our approach is that it does not incorporate any free parameters, such as the cosmological constant or dark matter, which are typically present in Einstein's formulation. This absence of free parameters suggests that the physical phenomena predicted by both our model and Einstein's should align perfectly when they are grounded in the same fundamental principles. Furthermore, we explore potential experimental tests to validate our proposal. While QPD has been previously discussed in the literature, primarily in the context of various quantum mechanical phenomena such as uncertainty relations, tunneling effects, and wave-particle duality, our work offers a fresh perspective by positioning QPD as a crucial element in the derivation of gravitational field equations. This innovative interpretation of QPD may provide deeper insights into the interplay between gravity and quantum mechanics, potentially leading to a more comprehensive understanding of the universe at its most fundamental level.",
        "ori-fast-z-score": 1.9727878476642875,
        "water-fast-z-score": 7.89115139065715,
        "rewrite-fast-z-score": 0.7242859683401482
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The IC1396N proto-cluster at a scale of 250 AU .\nAbstract:\nWe present new near-infrared (NIR) observations of the young stellar cluster IC 1396 N, located in the Orion Nebula Cluster region. The data were obtained with the adaptive optics system NAOS-CONICA on the VLT telescope and cover an area of 0.5 arcmin2 around the central star HD 37022. We detect more than 100 point sources down to Ks = 18 mag within this field-of-view. Using these data we have constructed colour-magnitude diagrams for different areas inside our field-of-view. From these CMDs we find that there are two populations of stars which can be separated by their position in the diagrams: one population is redder and fainter while another has bluer colours and brighter magnitudes. These results suggest that the first group consists mainly of low mass pre-main sequence stars surrounded by circumstellar disks, whereas the second group contains mostly high mass main-sequence stars without any surrounding material.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The IC1396N proto - cluster at a scale of 250 AU . Abstract : We report new near - infrared ( NIR ) observations of the young stellar cluster IC 1396 N , located in the Orion Nebula Cluster region .The data were obtained with the adaptive optics network NAOS - CONICA on the VLT telescope and cover an area of 0 . 5 arcmin2 around the central star HD 37022 . We detect more than 100 point sources down to Ks = 18 mag within this field - of - view .Using these information we have created colour - magnitude diagrams for different areas inside our field - of - view . From these CMDs we find that there are two communities of stars which can be apart by their placement in the diagrams : one community is redder and fainter while another has bluer colours and darker magnitudes .These data suggest that the first class consists primarily of low weight pre - principal sequence stars surrounded by circumstellar disks , whereas the second set contains primarily high mass primary - sequence stars without any surrounding material .",
        "rewrite_text": "We present new near-infrared (NIR) observations of the young stellar cluster IC 1396N, situated within the Orion Nebula Cluster region. Utilizing the adaptive optics system NAOS-CONICA on the Very Large Telescope (VLT), we acquired data covering an area of 0.5 arcmin² centered around the star HD 37022. Our observations revealed over 100 point sources with a magnitude limit of Ks = 18 mag within the surveyed field. To analyze the stellar population, we constructed color-magnitude diagrams (CMDs) for various regions within our observational area. The CMDs indicate the presence of two distinct groups of stars, differentiated by their positions in the diagrams. The first group is characterized by redder colors and fainter magnitudes, suggesting that these stars are primarily low-mass pre-main-sequence stars that are likely surrounded by circumstellar disks. In contrast, the second group consists of stars with bluer colors and brighter magnitudes, indicating that these are predominantly high-mass main-sequence stars that lack surrounding material. Our findings contribute to the understanding of stellar formation processes in the IC 1396N cluster and highlight the diversity of stellar populations present in this region. This study underscores the importance of high-resolution NIR observations in revealing the complexities of young stellar clusters and their evolutionary stages.",
        "ori-fast-z-score": -0.5852057359806528,
        "water-fast-z-score": 4.4174102722651325,
        "rewrite-fast-z-score": -0.8081220356417685
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Deformed Wigner crystal in a one-dimensional quantum dot .\nAbstract:\nWe study the ground state properties of an interacting electron gas confined to a onedimensional (1D) quantum dot with parabolic confinement potential and repulsive Coulomb interaction between electrons. We show that, for sufficiently strong confining potential, the system undergoes a phase transition into a deformed Wigner crystal at low temperatures. The results are obtained by using density functional theory within the local spin-density approximation combined with exact diagonalization method. In this regime, we find that the charge distribution is characterized by alternating peaks separated by valleys which become more pronounced as temperature decreases. This behavior can be understood in terms of formation of a periodic structure due to inter-particle correlations. Our results suggest that such structures may exist experimentally in semiconductor nanowires or carbon nanotubes. Introduction:-In recent years there has been considerable interest in studying the electronic properties of nanostructures  1  . One dimensional systems have attracted particular attention because they provide a unique opportunity to investigate fundamental physical phenomena like Luttinger liquid  2  , fractional statistics  3  , and Wigner crystallization  4  .\nTheoretical studies of 1D quantum dots (QDs), i.e., QDs with only one dimension much smaller than other two dimensions, were first carried out by Lieb et al  5  who showed that these systems exhibit interesting features including shell filling effects  6  . Subsequently, several authors studied various aspects of QD physics  7, 8  . For example, it was shown that the energy spectrum of a QD depends strongly on its shape  9  . It also turns out that the single particle wave functions of a QD depend sensitively on the boundary conditions  10  . Recently, some experimental progress has been made towards realizing 1D QDs  11  -  13  . However, most experiments so far have focused mainly on transport measurements  14  -  16  rather than direct imaging  17  . Therefore, theoretical investigations play an important role in understanding the underlying physics of these systems  18  -  20  .\nIn this work, we consider a model consisting of N non-interacting fermions confined to a 1D QD with parabolic confinement potential V(x). The total energy E tot = ∑ i=1...N",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Deformed Wigner crystal in a one - dimensional quantum dot . Abstract : We research the ground state properties of an interacting electron gas restricted to a onedimensional ( 1D ) quantum dot with parabolic confinement potential and repulsive Coulomb interaction between electrons .We see that , for enough strong confining potential , the system undergoes a phase shift into a deformed Wigner crystal at low temperatures . The results are derived by using density functional theory within the local spin - density algorithm coupled with exact diagonalization technique .In this regime , we find that the charge distribution is characterized by alternating ridges separated by regions which turn more pronounced as temperature changes . This phenomenon can be understood in terms of formation of a periodic structure owing to inter - particle correlations .Our results propose that such complexes may arise experimentally in semiconductor nanowires or carbon nanotubes . Introduction : - In recent years there has been substantial interest in investigating the electronic properties of nanostructures 1 .One dimensional systems have garnered especially attention because they give a unique opportunity to examine fundamental physical phenomena like Luttinger vacuum 2 , fractional statistics 3 , and Wigner crystallization 4 . Theoretical experiments of 1D quantum dots ( QDs ) , i . e . , QDs with only one dimension much smaller than other two dimensions , were first done out by Lieb et al 5 who demonstrated that these systems exhibit exciting elements including shell filling effects 6 .Subsequently , various scientists researched several elements of QD physics 7 , 8 . For instance , it was shown that the power spectrum of a QD varies strongly on its shape 9 .It also turns out that the single particle wave systems of a QD depend sensitively on the boundary conditions 10 . Recently , some experimental development has been achieved towards realizing 1D QDs 11 - 13 .However , most studies so far have concentrated mostly on transport measurements 14 - 16 rather than direct scanning 17 . Therefore , theoretical investigations play an important role in understanding the fundamental theory of these systems 18 - 20 .In this work , we study a theory consisting of N non - interacting fermions confined to a 1D QD with parabolic confinement potential V ( x ) . The total energy E tot = [UNK] i = 1 . . . N",
        "rewrite_text": "**Title:** Deformed Wigner Crystal in a One-Dimensional Quantum Dot\n\n**Abstract:** This study investigates the ground state characteristics of an interacting electron gas confined within a one-dimensional (1D) quantum dot, which is subject to a parabolic confinement potential and experiences repulsive Coulomb interactions among electrons. Our findings indicate that, under sufficiently strong confinement, the system transitions into a deformed Wigner crystal phase at low temperatures. The analysis employs density functional theory, utilizing the local spin-density approximation in conjunction with exact diagonalization techniques. In this low-temperature regime, we observe that the charge distribution exhibits a pattern of alternating ridges, with regions of increased prominence as the temperature varies. This behavior can be interpreted as the emergence of a periodic structure resulting from inter-particle correlations. Our results suggest that such deformed Wigner crystals could potentially be realized in experimental setups involving semiconductor nanowires or carbon nanotubes.\n\n**Introduction:** Recent years have seen a surge of interest in the electronic properties of nanostructures, particularly one-dimensional systems, which provide a unique platform for exploring fundamental physical phenomena such as the Luttinger vacuum, fractional statistics, and Wigner crystallization. Initial theoretical investigations of 1D quantum dots (QDs)—where one dimension is significantly smaller than the other two—were conducted by Lieb et al., who highlighted the intriguing features of these systems, including shell filling effects. Following this, numerous researchers have delved into various aspects of QD physics, revealing that the power spectrum of a QD is highly sensitive to its geometric configuration. Additionally, the single-particle wave functions within a QD are influenced by the boundary conditions. Recent experimental advancements have made strides toward the realization of 1D QDs; however, much of the existing research has primarily focused on transport measurements rather than direct imaging techniques. Consequently, theoretical studies remain crucial for deepening our understanding of the fundamental principles governing these systems. In this work, we explore a theoretical framework involving N non-interacting fermions confined to a 1D QD with a parabolic confinement potential, aiming to elucidate the intricate behaviors of such quantum systems.",
        "ori-fast-z-score": -1.507556722888818,
        "water-fast-z-score": 6.6332495807108,
        "rewrite-fast-z-score": -0.07602859212697055
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  High resolution mid-infrared spectroscopy of ultraluminous infrared galaxies .\nAbstract:\nWe present high-resolution (R = λ/Δλ ~ 10000) near-infrared and mid-infrared spectroscopic observations for two ULIRGs, Mrk 231 and Arp 220. The data were obtained with the Subaru Telescope using the Cooled Mid-Infrared Camera and Spectrograph (COMICS). We detect several emission lines in both objects including H I Brγ at 2.16 μm, Paα at 1.87 μm,  Fe II  at 1.64 μm, He I at 1.70 μm,  S III  at 0.95 μm, and  C IV  at 0.15 μm. In addition to these lines, we also find that there are many absorption features such as CO bandheads near 4.7 μm and 6.2 μm. These results show that the observed spectra have complex line profiles which can be explained by multiple components along our line-of-sight and/or different physical conditions within each component.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : High resolution mid - infrared spectroscopy of ultraluminous laser galaxies . Abstract : We produce high - resolution ( R = λ / Δλ ~ 10000 ) near - infrared and mid - infrared spectroscopic observations for two ULIRGs , Mrk 231 and Arp 220 .The data were obtained with the Subaru Telescope using the Cooled Mid - Infrared Camera and Spectrograph ( COMICS ) . We detect many emission lines in both objects including H I Brγ at 2 . 16 μm , Paα at 1 . 87 μm , Fe II at 1 . 64 μm , He I at 1 . 70 μm , S III at 0 . 95 μm , and C IV at 0 . 15 μm .In addition to these lines , we also find that there are many absorption elements such as CO bandheads near 4 . 7 μm and 6 . 2 μm . These data reveal that the seen spectra have complex line profiles which can be described by various components along our line - of - view and / or varying physical conditions within each component .",
        "rewrite_text": "In this study, we present high-resolution (R = λ/Δλ ~ 10,000) spectroscopic observations in the near-infrared and mid-infrared wavelengths of two ultraluminous infrared galaxies (ULIRGs), Mrk 231 and Arp 220. The observations were conducted using the Subaru Telescope equipped with the Cooled Mid-Infrared Camera and Spectrograph (COMICS). Our analysis reveals a rich spectrum of emission lines in both galaxies, including prominent features such as H I Brγ at 2.16 μm, Paα at 1.87 μm, Fe II at 1.64 μm, He I at 1.70 μm, S III at 0.95 μm, and C IV at 0.15 μm. Additionally, we identify several absorption features, notably CO bandheads located around 4.7 μm and 6.2 μm. The complexity of the observed spectra suggests intricate line profiles that may be attributed to multiple components along our line of sight, as well as varying physical conditions within each component. This detailed spectroscopic analysis enhances our understanding of the physical processes occurring in these ultraluminous galaxies and provides insights into their star formation activities and the dynamics of their interstellar medium. The findings underscore the importance of high-resolution spectroscopy in unraveling the complexities of galaxy formation and evolution, particularly in extreme environments such as those found in ULIRGs. Our results contribute to the broader field of astrophysics by offering a deeper comprehension of the mechanisms driving the luminosity and spectral characteristics of these fascinating celestial objects.",
        "ori-fast-z-score": 0.848528137423857,
        "water-fast-z-score": 3.780756226875626,
        "rewrite-fast-z-score": 2.465858830126928
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Evolutionary Mesh Numbering: Preliminary Results .\nAbstract:\nWe present an evolutionary algorithm for the problem of mesh numbering, which is to assign integers in the range  0, ..., n-1  to all vertices of a given graph G = (V, E) such that adjacent vertices have consecutive numbers and no two edges share the same pair of endpoints with the same order.  The proposed method uses a population-based approach where each individual represents a valid solution by means of a permutation vector. We show how this representation can be used to efficiently compute fitness values using only local information. In addition we propose several genetic operators to explore the search space. Finally, we report on preliminary results obtained by applying our method to some well-known benchmark instances. Keywords: Graphs, Optimization problems, Evolutionary algorithms, Genetic algorithms. 1 Introduction A common task when working with graphs is to label their nodes or edges with unique identifiers. This process is known as node or edge numbering respectively. For example, it may be required to number the nodes of a road network so that every path between any two points has a unique sequence of labels. Another application arises in circuit design, where one needs to assign unique addresses to components of electronic circuits.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Evolutionary Mesh Numbering : Preliminary Results . Abstract : We present an evolutionary algorithm for the question of mesh numbering , which is to assign integers in the range 0 , . . . , k - 1 to all edges of a given graph G = ( V , E ) such that adjacent vertices have consecutive numbers and no two edges share the same pair of endpoints with the same order .The proposed approach utilizes a population - based approach where each individual represents a valid answer by means of a permutation vector . We see how this representation can be used to easily compute fitness values using only local information .In addition we propose several genetic operators to examine the search space . Finally , we publish on preliminary results acquired by application our technique to some well - recognized benchmark instances .Keywords : Graphs , Optimization problems , Evolutionary algorithms , Genetic algorithms . 1 Introduction A typical task when dealing with graphs is to label their nodes or edges with special identifiers .This process is known as node or edge counting respectively . For instance , it could be required to count the nodes of a street system so that every road between any two points has a unique chain of labels .Another application exists in circuit design , where one needs to give unique addresses to components of electronic circuits .",
        "rewrite_text": "**Title:** Evolutionary Mesh Numbering: Preliminary Results\n\n**Abstract:** In this study, we introduce an innovative evolutionary algorithm aimed at addressing the problem of mesh numbering in graphs. The objective of mesh numbering is to assign integers within the range of 0 to k - 1 to all edges of a graph G = (V, E), ensuring that adjacent vertices are assigned consecutive numbers and that no two edges share the same pair of endpoints in the same order. Our proposed method employs a population-based strategy, where each individual in the population is represented by a permutation vector that corresponds to a valid solution. This representation facilitates the efficient computation of fitness values using only local information, thereby streamlining the evaluation process. We also explore various genetic operators designed to navigate the search space effectively. The preliminary results obtained from applying our technique to several well-established benchmark instances demonstrate the potential of our approach in solving the mesh numbering problem. This work contributes to the broader field of graph optimization and highlights the applicability of evolutionary algorithms in tackling complex combinatorial challenges. \n\n**Keywords:** Graphs, Optimization problems, Evolutionary algorithms, Genetic algorithms.\n\n**1 Introduction:** Labeling the nodes or edges of graphs with unique identifiers is a common task in graph theory, referred to as node or edge counting. For example, in urban planning, it may be necessary to assign unique labels to the nodes of a street network to ensure that every road segment between two locations has a distinct sequence of identifiers. Similarly, in the realm of electronic circuit design, unique addresses must be assigned to various components to facilitate proper functionality and communication within the circuit.",
        "ori-fast-z-score": -1.2451741707874968,
        "water-fast-z-score": 4.041451884327381,
        "rewrite-fast-z-score": -0.1690308509457033
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Periodic Bursts of Coherent Radio Emission from an Ultracool Dwarf .\nAbstract:\nWe report the detection of periodic bursts of coherent radio emission at 1.4 GHz and 8.5 GHz, with periods ranging between 0.3 s to 3.6 s, from the ultracool dwarf TVLM 513-46546 (M8V). The source is located in the southern hemisphere near the Galactic plane, where it was discovered by its optical variability. \n \n We have detected these bursts using the Karl G. Jansky Very Large Array (VLA) and the Australia Telescope Compact Array (ATCA), as well as archival data obtained with the Westerbork Synthesis Radio Telescope (WSRT). \n \n These bursts are characterized by their high brightness temperatures (Tb > 1011 K), rapid rise times (< 10 ms), flat or inverted spectral indices (-0.2 < α < +0.7), and lack of circular polarization. They also appear to be highly polarized (~50% linear polarization fraction) on short time scales (< 100 ms). Their properties suggest that they may originate from gyrosynchrotron radiation produced within magnetic loops anchored to the surface of this star. \n \n This discovery opens up new avenues for studying the magnetospheres of low-mass stars through direct imaging techniques.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Periodic Bursts of Coherent Radio Emission from an Ultracool Dwarf . Abstract : We report the observation of periodic pulses of coherent radio emission at 1 . 4 GHz and 8 . 5 GHz , with periods ranging between 0 . 3 s to 3 . 6 s , from the ultracool dwarf TVLM 513 - 46546 ( M8V ) .The source is situated in the southern hemisphere near the Galactic plane , where it was noted by its optical variability . We have discovered these bursts using the Karl G . Jansky Very Large Array ( VLA ) and the Australia Telescope Compact Array ( ATCA ) , as well as archival info collected with the Westerbork Synthesis Radio Telescope ( WSRT ) .These bursts are marked by their high brightness temperatures ( Tb > 1011 K ) , quick rising periods ( < 10 ms ) , flat or inverted spectral indices ( - 0 . 2 < α < + 0 . 7 ) , and lack of circular polarization . They also appear to be highly polarized ( ~ 50 % linear polarization fraction ) on short period scales ( < 100 ms ) .Their properties suggest that they may originate from gyrosynchrotron rays produced within magnetic loops anchored to the surface of this star . This research raises up new avenues for studying the magnetospheres of low - mass stars through direct observation techniques .",
        "rewrite_text": "We present findings on the periodic bursts of coherent radio emission detected from the ultracool dwarf TVLM 513-46546 (M8V) at frequencies of 1.4 GHz and 8.5 GHz. These emissions exhibit a range of periodicities from 0.3 seconds to 3.6 seconds. Located in the southern hemisphere near the Galactic plane, this dwarf star was previously identified due to its optical variability. Our discovery was made possible through observations conducted with the Karl G. Jansky Very Large Array (VLA) and the Australia Telescope Compact Array (ATCA), supplemented by archival data from the Westerbork Synthesis Radio Telescope (WSRT). The characteristics of these radio bursts are notable, displaying exceptionally high brightness temperatures exceeding 10^11 K, rapid rise times of less than 10 milliseconds, and spectral indices that are either flat or inverted, ranging from -0.2 to +0.7. Additionally, while the bursts show no evidence of circular polarization, they exhibit significant linear polarization, with approximately 50% polarization fraction over short timescales of less than 100 milliseconds. These properties imply that the emissions may be generated by gyrosynchrotron radiation arising from magnetic loops tethered to the star's surface. This research opens new pathways for investigating the magnetospheres of low-mass stars through direct observational methods, enhancing our understanding of their magnetic environments and the mechanisms driving such coherent radio emissions.",
        "ori-fast-z-score": 0.23570226039551587,
        "water-fast-z-score": 4.798687035041354,
        "rewrite-fast-z-score": -3.040026026493563
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Acceleration and Substructure Constraints in a Quasar Outflow .\nAbstract:\nWe present new constraints on the acceleration mechanisms responsible for quasar outflows, using data obtained with the Chandra X-ray Observatory (CXO) to study the Fe K emission line profiles observed in two quasars at redshifts z = 1.7 and 2.3. The Fe K lines are found to be broadened by Doppler motions associated with an outflowing wind that is launched close to the central black hole. We find evidence for both thermal broadening and bulk motion of the emitting gas, but we cannot rule out other possible explanations such as relativistic effects or multiple components. In addition, we use these observations to place limits on the mass loss rateṀout and kinetic luminosity L kin of this outflow. For one object, PG 1211+143, we also compare our results with those derived from optical/UV absorption-line studies. Our analysis suggests that the winds may have different properties depending upon their location within the host galaxy. \n \n Keywords: Accretion disk - Black holes - Emission lines - Winds",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Acceleration and Substructure Constraints in a Quasar Outflow . Abstract : We introduce novel constraints on the acceleration mechanisms involved for quasar outflows , using data acquired with the Chandra X - ray Observatory ( CXO ) to study the Fe K emission edge patterns observed in two quasars at redshifts z = 1 . 7 and 2 . 3 .The Fe K bands are found to be broadened by Doppler movements involved with an outflowing breeze that is launched close to the main dark hole . We get data for both thermal broadening and bulk movement of the emitting gas , but we cannot leave out other possible explanations such as relativistic effects or multiple components .In addition , we using these observations to place limits on the mass loss [UNK] and kinetic luminosity L kin of this outflow . For one object , PG 1211 + 143 , we also compare our findings with those generated from optical / UV absorption - line investigations .Our study implies that the winds may have different properties depending upon their orientation within the host universe . Keywords : Accretion disk - Black holes - Emission lines - Winds",
        "rewrite_text": "In this article, we present new insights into the acceleration mechanisms of quasar outflows, utilizing data from the Chandra X-ray Observatory (CXO) to analyze the Fe K emission edge patterns in two quasars at redshifts z = 1.7 and 2.3. Our findings reveal that the Fe K bands exhibit broadening due to Doppler shifts associated with an outflowing wind originating near the central supermassive black hole. We have gathered evidence for both thermal broadening and bulk motion of the emitting gas; however, we acknowledge the potential influence of other factors, such as relativistic effects or the presence of multiple emitting components, which may also contribute to the observed phenomena. Furthermore, we leverage these observations to establish constraints on the mass loss and kinetic luminosity (L_k) of the outflowing material. In particular, for the quasar PG 1211 + 143, we draw comparisons between our results and those obtained from optical and ultraviolet absorption-line studies. Our analysis suggests that the characteristics of the outflows may vary significantly based on their orientation relative to the host galaxy. This research enhances our understanding of the complex dynamics of quasar outflows and their implications for the evolution of galaxies and black holes. The keywords associated with this study include accretion disks, black holes, emission lines, and winds, highlighting the interdisciplinary nature of our findings and their relevance to ongoing investigations in astrophysics.",
        "ori-fast-z-score": 0.45291081365783825,
        "water-fast-z-score": 5.962965874907927,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Measuring the dark matter velocity anisotropy in galaxy clusters .\nAbstract:\nWe present an analysis of the kinematics and dynamics of galaxies within galaxy clusters, using data obtained with the Hubble Space Telescope (HST). We use this information to measure the degree of radial bias in the distribution of cluster member velocities as well as their spatial correlation function. The results are compared against predictions made by cosmological N-body simulations that include both baryonic gas and collisionless dark matter particles. Our main conclusions are:  1) Galaxy clusters exhibit significant deviations from isotropic dynamical equilibrium; 2) These deviations can be explained if we assume that the dark matter component has a radially biased velocity dispersion tensor; 3) This result implies that the dark matter halos surrounding individual galaxies have similar shapes but different orientations relative to each other. In addition, our measurements provide new constraints on the mass-to-light ratio for galaxy clusters. Using HST observations of four nearby galaxy clusters, we find evidence that the dark matter component exhibits a strong radial bias in its velocity dispersion tensor.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Measuring the dark matter momentum anisotropy in galaxy clusters . Abstract : We present an assessment of the kinematics and dynamics of clusters within galaxy clusters , using data acquired with the Hubble Space Telescope ( HST ) .We use this data to measure the degree of radial bias in the distribution of cluster member velocities as also as their spatial correlation function . The results are compared against models provided by cosmological N - bodies simulations that include both baryonic gas and collisionless dark matter particles .Our main results are : 1 ) Galaxy clusters exhibit substantial deviations from isotropic dynamical balance ; 2 ) These deviations can be described if we suppose that the dark matter component has a radially biased speed dispersion matrix ; 3 ) This result suggests that the dark matter halos adjoining individual stars have related shapes but different orientations relative to each other . In addition , our measurements give novel constraints on the mass - to - light percentage for galaxy galaxies .Using HST observations of four nearby galaxy clusters , we find proof that the dark matter component displays a powerful radial bias in its velocity dispersion matrix .",
        "rewrite_text": "We present a comprehensive analysis of the kinematics and dynamics of galaxy clusters, utilizing data obtained from the Hubble Space Telescope (HST). Our study focuses on quantifying the radial bias present in the velocity distribution of cluster members, as well as examining their spatial correlation function. To contextualize our findings, we compare our results with predictions from cosmological N-body simulations that incorporate both baryonic gas and collisionless dark matter particles. Our key findings indicate that galaxy clusters demonstrate significant departures from isotropic dynamical equilibrium. Specifically, we propose that these deviations can be effectively characterized by a radially biased velocity dispersion matrix for the dark matter component. This observation implies that the dark matter halos surrounding individual stars possess similar shapes but exhibit varying orientations with respect to one another. Furthermore, our analysis provides new constraints on the mass-to-light ratios of galaxies. By examining HST observations of four nearby galaxy clusters, we present compelling evidence that the dark matter component exhibits a pronounced radial bias in its velocity dispersion matrix. These insights enhance our understanding of the complex dynamics within galaxy clusters and the role of dark matter in shaping their structure. Our findings contribute to the ongoing discourse in astrophysics regarding the nature of dark matter and its influence on galaxy formation and evolution.",
        "ori-fast-z-score": -0.9332565252573828,
        "water-fast-z-score": 5.642880936468348,
        "rewrite-fast-z-score": 1.5255401427929478
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Ionized nebulae surrounding brightest cluster galaxies .\nAbstract:\nWe present new observations with the Hubble Space Telescope (HST) and Chandra X-ray Observatory to study the properties of ionized gas in galaxy clusters at z ~ 0.5-0.8, where most massive clusters are found today.  We find that the fraction of cool core clusters is higher than expected for their redshifts based on local samples. The observed evolution may be due to an increase in the number density of active galactic nuclei or AGN activity over time. In addition, we detect extended emission line regions around some of these clusters which have been previously identified as having strong cooling flows. These results suggest that there has been significant heating of the intracluster medium by energetic outflows associated with AGNs since z = 1.0. This work was supported by NASA grant NAG5-9998. Cooling flow clusters are known to contain large amounts of cold gas within their central regions. However, it remains unclear how this gas cools down without forming stars. Recent studies show that many of them also harbor powerful radio sources near their centers. It is possible that such radio jets heat up the ICM through shocks and/or turbulence generated during the interaction between the jet plasma and the ambient hot gas.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Ionized nebulae surrounding brightest cluster clusters . Abstract : We present new studies with the Hubble Space Telescope ( HST ) and Chandra X - ray Observatory to study the properties of ionized gas in galaxy galaxies at z ~ 0 . 5 - 0 . 8 , where most large clusters are found today .We see that the fraction of cold core nuclei is higher than expected for their redshifts based on local samples . The observed evolution may be due to an increase in the number density of active galactic nuclei or AGN activity over time .In addition , we find extended emission line regions around some of these complexes which have been previously noted as having strong cooling flows . These data suggest that there has been significant heating of the intracluster medium by energetic outflows associated with AGNs since z = 1 . 0 .This project was supported by NASA grant NAG5 - 9998 . Cooling flow clusters are known to contain significant amounts of cold gas within their central regions .However , it remains unclear how this gas cools down without forming stars . Recent research indicate that several of them additionally harbor potent radio sources near their centers .It is suggested that such radio jets heat up the ICM through shocks and / or turbulence generated during the interaction between the jet plasma and the ambient warm gas .",
        "rewrite_text": "We present a comprehensive investigation utilizing the Hubble Space Telescope (HST) and the Chandra X-ray Observatory to analyze the characteristics of ionized gas in galaxies located at redshifts of approximately 0.5 to 0.8, a period when many of the largest galaxy clusters were forming. Our findings reveal that the proportion of cold core nuclei in these clusters is unexpectedly higher than what local samples would predict for their corresponding redshifts. This observed trend may be attributed to an increase in the density of active galactic nuclei (AGN) or heightened AGN activity over cosmic time. Furthermore, we have identified extended emission line regions surrounding several of these complexes, which have previously been recognized for exhibiting strong cooling flows. The data indicate that there has been considerable heating of the intracluster medium (ICM) due to energetic outflows linked to AGNs since a redshift of 1.0. This research was made possible through the support of NASA grant NAG5-9998. Cooling flow clusters are known to harbor substantial amounts of cold gas in their central regions; however, the mechanisms by which this gas cools without leading to star formation remain poorly understood. Recent studies suggest that many of these clusters also contain powerful radio sources at their centers. It is proposed that these radio jets contribute to the heating of the ICM through the generation of shocks and turbulence resulting from the interaction between the jet plasma and the surrounding warm gas. Our findings contribute to the understanding of the complex interplay between AGN activity, gas cooling, and the thermal state of the ICM in galaxy clusters, providing insights into the evolution of these massive structures in the universe.",
        "ori-fast-z-score": 1.2686700948330931,
        "water-fast-z-score": 5.827715174143584,
        "rewrite-fast-z-score": 1.044465935734187
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Towards a library of synthetic galaxy spectra and preliminary results of classification and parametrization of unresolved galaxies for Gaia .\nAbstract:\nWe present the first steps towards building a library of synthetic galaxy SEDs (spectral energy distributions) that will be used to classify and parameterize unresolved galaxies in the Gaia data stream, as part of the Data Processing and Analysis Consortium (DPAC). The library is built using state-of-the-art stellar population synthesis models with different star formation histories, metallicities, dust content, and redshifts. We use this library to test two methods of classifying unresolved galaxies into broad morphological types based on their observed photometry only. In addition we show how these parameters can be constrained by fitting the full spectrum of an unresolved galaxy. This work was performed within the framework of the ESA Gaia mission. Keywords: Galaxy evolution; Stellar populations; Spectroscopy. 1 Introduction Galaxies are complex systems whose properties depend strongly on their mass, age, chemical composition, star formation history, and environment. These physical characteristics determine many observable quantities such as luminosity, colours, morphology, kinematics, etc., which have been studied extensively over several decades. However, it has become clear recently that there exist significant degeneracies between some of these observables and therefore they cannot be uniquely determined without additional information about the underlying physics or geometry of the system. For example, the total luminosity of a galaxy depends not only on its current star formation rate but also on its past star formation activity through the integrated light of old stars. Similarly, the colour of a galaxy depends both on its metallicity and on the amount of dust extinction along our line-of-sight. Therefore, accurate measurements of all relevant physical parameters require detailed spectroscopic observations covering large wavelength ranges. Such studies are now possible thanks to new space missions like GALEX, SDSS, 2MASS, Spitzer Space Telescope, Herschel Space Observatory, Chandra X-ray Observatory, XMM-Newton, Hubble Space Telescope, and most importantly, the upcoming European Space Agency s Gaia satellite. Gaia is expected to provide astrometric positions, parallaxes, proper motions, radial velocities, and multi-colour photometry for more than one billion objects",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Towards a library of synthetic universe spectra and preliminary results of classification and parametrization of unresolved galaxies for Gaia . Abstract : We present the first steps towards constructing a library of synthetic galaxy SEDs ( spectral power distributions ) that will be used to classify and parameterize unresolved galaxies in the Gaia data stream , as member of the Data Processing and Analysis Consortium ( DPAC ) .The library is built using state - of - the - art stellar community synthesis estimates with various galaxy formation histories , metallicities , dust content , and redshifts . We use this database to test two means of classifying unresolved galaxies into wide morphological types based on their observed photometry only .In addition we show how these parameters can be constrained by fitting the full range of an unresolved galaxy . This research was done within the framework of the ESA Gaia expedition .Keywords : Galaxy evolution ; Stellar populations ; Spectroscopy . 1 Introduction Galaxies are diverse structures whose characteristics rely highly on their mass , age , chemical composition , star formation history , and environment .These physical qualities determine many observable quantities such as luminosity , colours , morphology , kinematics , etc . , which have been studied frequently over numerous years . However , it has become clear recently that there remain considerable degeneracies between some of these observables and therefore they cannot be uniquely determined without additional information about the fundamental theory or topology of the system .For instance , the total luminosity of a galaxy depends not only on its current star formation rate but also on its past star formation activity through the integrated light of ancient stars . Similarly , the colour of a galaxy depends both on its metallicity and on the extent of dust extinction along our line - of - view .Therefore , accurate measurements of all relevant physical values need comprehensive spectroscopic observations encompassing large wavelength ranges . Such investigations are now possible due to modern space missions like GALEX , SDSS , 2MASS , Spitzer Space Telescope , Herschel Space Observatory , Chandra X - ray Observatory , XMM - Newton , Hubble Space Telescope , and most importantly , the latest European Space Agency s Gaia satellite .Gaia is expected to provide astrometric orientation , parallaxes , proper motions , radial velocities , and multi - colour photometry for more than one billion objects",
        "rewrite_text": "**Title:** Towards a Library of Synthetic Universe Spectra: Preliminary Results on the Classification and Parameterization of Unresolved Galaxies for Gaia\n\n**Abstract:** In this study, we outline the initial development of a comprehensive library of synthetic spectral energy distributions (SEDs) for galaxies, aimed at facilitating the classification and parameterization of unresolved galaxies within the Gaia data stream. As part of the Data Processing and Analysis Consortium (DPAC), our library is constructed using advanced stellar population synthesis models that incorporate a variety of galaxy formation histories, metallicities, dust content, and redshifts. We employ this extensive database to evaluate two methodologies for classifying unresolved galaxies into broad morphological categories based solely on their observed photometric data. Furthermore, we demonstrate how these classification parameters can be refined by fitting the complete spectral range of an unresolved galaxy. This research is conducted within the framework of the European Space Agency's Gaia mission, which is poised to revolutionize our understanding of galaxy evolution. \n\nGalaxies exhibit a wide range of characteristics influenced by factors such as mass, age, chemical composition, star formation history, and environmental conditions. These physical attributes dictate observable properties including luminosity, color, morphology, and kinematics, which have been the focus of extensive research over the years. However, significant degeneracies among these observables have been identified, complicating the unique determination of galaxy properties without supplementary information regarding the underlying physical theories or system topology. For example, a galaxy's total luminosity is influenced not only by its current star formation rate but also by its historical star formation activity, as reflected in the integrated light from older stars. Similarly, a galaxy's color is affected by both its metallicity and the degree of dust extinction along our line of sight. Consequently, precise measurements of all relevant physical parameters necessitate comprehensive spectroscopic observations across a wide range of wavelengths. Modern space missions, including GALEX, SDSS, 2MASS, Spitzer, Herschel, Chandra, XMM-Newton, Hubble, and notably, the Gaia satellite, have made such investigations feasible. Gaia is anticipated to deliver astrometric data, parallaxes, proper motions, radial velocities, and multi-color photometry for over one billion celestial objects, significantly enhancing our ability to study galaxy evolution. \n\n**Keywords:** Galaxy evolution; Stellar populations; Spectroscopy.",
        "ori-fast-z-score": 1.0120486274099798,
        "water-fast-z-score": 7.340166808764486,
        "rewrite-fast-z-score": 0.3892494720807615
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Anisotropy and magnetization reversal with chains of submicron-sized Co hollow spheres .\nAbstract:\nWe report on the magnetic properties of self-assembled arrays of cobalt (Co) hollow spheres, which are prepared by an electrochemical deposition method onto carbon-coated copper grids. The samples show anisotropic behavior in their hysteresis loops at room temperature as well as superparamagnetic characteristics above 300 K. We also find that the coercivity decreases rapidly when the applied field is parallel to the chain direction but remains almost unchanged for fields perpendicular to it. This indicates that the easy axis lies along the chain direction. In addition, we observe that the remanent magnetization increases gradually up to about 100 Oe after annealing the sample at 400 °C under vacuum conditions. These results suggest that the observed anisotropy originates mainly from shape effects rather than inter-particle interactions. \n \n Keywords: Anisotropy, Cobalt, Hollow sphere, Self-assembling, Superparamagnetism",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Anisotropy and magnetization reversal with chains of submicron - sized Co hollow spheres . Abstract : We report on the magnetic properties of self - assembled arrays of cobalt ( Co ) hollow spheres , which are prepared by an electrochemical deposition technology onto carbon - wrapped copper grids .The samples show anisotropic characteristics in their hysteresis loops at room temperature as well as superparamagnetic qualities above 300 K . We additionally find that the coercivity decreases quickly when the introduced field is parallel to the chain direction but maintains largely unchanged for fields perpendicular to it . This implies that the easy axis lies along the chain direction .In addition , we determine that the remanent magnetization increases slowly up to about 100 Oe after annealing the sample at 400 °C under vacuum environments . These conclusions show that the reported anisotropy derives mainly from shape effects rather than inter - particle relationships .Keywords: Anisotropy, Cobalt, Hollow sphere, Self-assembling, Superparamagnetism",
        "rewrite_text": "Title: Anisotropy and Magnetization Reversal in Chains of Submicron-Sized Cobalt Hollow Spheres\n\nAbstract: This study investigates the magnetic characteristics of self-assembled arrays composed of cobalt (Co) hollow spheres, which are fabricated using an electrochemical deposition technique on carbon-coated copper grids. The magnetic behavior of these samples exhibits notable anisotropic properties in their hysteresis loops at room temperature, alongside superparamagnetic behavior observed at temperatures exceeding 300 K. A significant finding is that the coercivity of the samples diminishes rapidly when an external magnetic field is applied parallel to the direction of the chains, while it remains relatively stable when the field is oriented perpendicularly. This observation suggests that the easy axis of magnetization aligns with the chain direction. Furthermore, we observe that the remanent magnetization gradually increases up to approximately 100 Oe following the annealing of the samples at 400 °C in a vacuum environment. These results indicate that the anisotropic behavior is predominantly influenced by shape effects rather than inter-particle interactions. The implications of these findings contribute to a deeper understanding of the magnetic properties of cobalt hollow spheres and their potential applications in magnetic materials and devices. \n\nKeywords: Anisotropy, Cobalt, Hollow Spheres, Self-Assembly, Superparamagnetism",
        "ori-fast-z-score": 0.5852057359806528,
        "water-fast-z-score": 5.347391382215687,
        "rewrite-fast-z-score": -0.10721125348377948
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Analyzing Design Process and Experiments on the AnITA Generic Tutoring System .\nAbstract:\nIn this work, we present an analysis of design process and experiments conducted in developing a generic tutoring system for intelligent tutoring applications (ITAs). The main goal is to provide insights into how such systems can be developed with minimal effort by reusing existing components. We describe our experiences in building the AnITA system that provides adaptive feedbacks based on student s actions during problem solving activities. In addition, we discuss some issues related to evaluation of ITAs using different types of students as subjects. Finally, we conclude with lessons learned throughout the development cycle. This article is available from: http://arxiv.org/abs/1207.5995. Keywords: Intelligent tutoring application; Adaptive feedbacks; Problem-solving activity; Student modeling; Evaluation experimentation. 1 Introduction Intelligent tutoring applications (ITAS) are computer-based learning environments designed to help students learn specific skills or concepts through interactive problem-solving activities  1  . They have been shown to improve students  performance when compared to traditional teaching methods  2  .\nThe development of ITA requires significant efforts due to their complexity  3  , which includes several components including domain knowledge representation  4  , student modeling  5  , pedagogical strategies  6  , user interface  7  , and adaptation  8  . To reduce these efforts, researchers have proposed frameworks  9  -  11  and tools  12  -  14  that allow developers to build new ITS without having to start from scratch. However, most of them focus only on one aspect of ITS development  15  , e.g., authoring tool  16  , content management  17  , or student modeling  18  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Analyzing Design Process and Experiments on the AnITA Generic Tutoring System . Abstract : In this project , we present an assessment of design process and experiments conducted in establishing a generic tutoring scheme for intelligent tutoring applications ( ITAs ) .The main goal is to provide insights into how such applications can be built with minimal effort by reusing existing elements . We relate our events in building the AnITA process that offers integrated feedbacks based on student s activities during task solving operations .In addition , we explain some issues related to assessment of ITAs using varying kinds of participants as subjects . Finally , we continue with lessons developed throughout the development period .This section is accessible from : www : / / arxiv . org / abs / 1207 . 5995 . Keywords : Intelligent tutoring application ; Adaptive feedbacks ; Problem - solving exercise ; Student design ; Evaluation research .1 Introduction Intelligent tutoring applications ( ITAS ) are computer - based educational environments designed to assist children understand particular techniques or themes through interactive problem - solving operations 1 . They have been shown to improve students performance when compared to conventional taught methods 2 .The construction of ITA involves substantial attempts due to their complexity 3 , which includes several elements including domain knowledge structure 4 , student mapping 5 , pedagogical strategies 6 , user interface 7 , and adaptation 8 . To reduce these attempts , researchers have proposed frameworks 9 - 11 and tools 12 - 14 that enable developers to build existing ITS without having to start from scratch .However , most of them focus only on one element of ITS development 15 , e . g . , authoring interface 16 , product management 17 , or student modeling 18 .",
        "rewrite_text": "**Title:** Analyzing Design Process and Experiments on the AnITA Generic Tutoring System\n\n**Abstract:** This article presents a comprehensive evaluation of the design processes and experimental methodologies employed in the development of a generic tutoring framework tailored for intelligent tutoring applications (ITAs). The primary objective of this research is to elucidate strategies for constructing ITAs with reduced effort by leveraging pre-existing components. We detail our experiences in creating the AnITA system, which delivers integrated feedback based on students' activities during problem-solving tasks. Furthermore, we address various challenges encountered in the assessment of ITAs, particularly concerning the diversity of participant demographics involved in our studies. The insights gained throughout the development phase are also discussed, highlighting the lessons learned that can inform future projects in this domain. This work aims to contribute to the ongoing discourse on enhancing the efficacy and accessibility of intelligent tutoring systems by providing a framework that emphasizes adaptability and user-centered design. The findings underscore the importance of a holistic approach to ITA development, as many existing frameworks tend to concentrate on isolated components, such as authoring interfaces or student modeling, rather than integrating multiple facets of the tutoring experience. By sharing our findings and methodologies, we hope to inspire further research and innovation in the field of intelligent tutoring systems, ultimately leading to improved educational outcomes for learners. For more details, please visit: www.arxiv.org/abs/1207.5995.\n\n**Keywords:** Intelligent tutoring application; Adaptive feedback; Problem-solving exercise; Student design; Evaluation research.",
        "ori-fast-z-score": -1.227881227029841,
        "water-fast-z-score": 8.125447726947652,
        "rewrite-fast-z-score": 1.0954451150103321
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Astrophysical gyrokinetics: kinetic and fluid turbulent cascades in magnetized weakly collisional plasmas .\nAbstract:\nThe present work is devoted to the study of astrophysical plasma turbulence, with particular emphasis on its statistical properties at different scales. We consider both kinetic and fluid descriptions for the dynamics of collisionless plasmas, which are relevant for many space and laboratory applications. In this context we investigate the nonlinear evolution of magnetic fluctuations by means of direct numerical simulations (DNS) of the Vlasov-Maxwell system. The main results can be summarized as follows:  1. Turbulence statistics -We perform DNSs of the Vlasov-Poisson system in order to characterize the statistical properties of the electrostatic potential fluctuations generated by an initial spectrum of Alfvenic modes. Our analysis shows that the energy cascade proceeds towards smaller spatial scales until it reaches the ion Larmor radius scale where it is transferred into perpendicular wavenumbers through Landau damping. At these small scales, the energy transfer rate decreases due to the reduction of phase correlations between wavevectors. This process leads to the formation of intermittency in the distribution function of particles.  2. Kinetic effects -In addition to the above mentioned features observed in the case of purely hydrodynamic turbulence, our results show that kinetic effects play also an important role in determining the statistical properties of the fluctuating fields. Indeed, we find that the presence of ions modifies significantly the shape of the probability density functions (PDFs), leading to non-Gaussian distributions characterized by tails extending over several orders of magnitude. Moreover, we observe that the PDFs become more skewed when increasing the value of the ion-to-electron mass ratio. Finally, we discuss how the inclusion of kinetic effects affects the scaling laws characterizing the power spectra of the fluctuating fields. \n3. Fluid description -By performing DNSs of the Euler-",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Astrophysical gyrokinetics : kinetic and fluid turbulent cascades in magnetized weakly collisional plasmas . Abstract : The present work is committed to the observation of astrophysical plasma turbulence , with particular emphasis on its statistical characteristics at different scales .We consider both kinetic and fluid representations for the dynamics of collisionless plasmas , which are applicable for numerous space and lab applications . In this framework we investigate the nonlinear progression of magnetic fluctuations by means of direct numerical simulations ( DNS ) of the Vlasov - Maxwell process .The main results can be summarized as follows : 1 . Turbulence statistics - We perform DNSs of the Vlasov - Poisson system in order to characterize the statistical characteristics of the electrostatic potential fluctuations formed by an initial spectrum of Alfvenic modes .Our study shows that the power cascade proceeds towards smaller spatial scales until it meets the ion Larmor radius scale where it is transferred into perpendicular wavenumbers through Landau damping . At these little scales , the electricity transfer frequency drops due to the reduction of phase correlations between wavevectors .This process results to the formation of intermittency in the distribution structure of particles . 2 .Kinetic effects - In addition to the above mentioned elements observed in the case of solely hydrodynamic turbulence , our findings show that kinetic influences play also an important role in determining the statistical characteristics of the fluctuating fields . Indeed , we find that the presence of ions modifies substantially the shape of the probability density functions ( PDFs ) , leading to non - Gaussian distributions characterized by tails extending over numerous orders of magnitude .Moreover , we find that the PDFs get more skewed when increasing the value of the electron - to - ion mass ratio . Finally , we explain how the introduction of kinetic effects affects the scaling laws characterizing the power spectra of the fluctuating fields .3 . Fluid description - By conducting DNSs of the Euler -",
        "rewrite_text": "**Title:** Astrophysical Gyrokinetics: Kinetic and Fluid Turbulent Cascades in Magnetized Weakly Collisional Plasmas\n\n**Abstract:** This study focuses on the exploration of turbulence in astrophysical plasmas, emphasizing the statistical properties across various scales. We utilize both kinetic and fluid frameworks to analyze the dynamics of collisionless plasmas, which are relevant to a wide range of applications in both space and laboratory settings. Our investigation centers on the nonlinear evolution of magnetic fluctuations, employing direct numerical simulations (DNS) of the Vlasov-Maxwell system. \n\nThe key findings of our research can be summarized in three main areas: \n\n1. **Turbulence Statistics:** We conduct DNS of the Vlasov-Poisson system to elucidate the statistical characteristics of electrostatic potential fluctuations generated from an initial spectrum of Alfvenic modes. Our results indicate that the power cascade progresses toward smaller spatial scales until it reaches the ion Larmor radius scale, where energy is transferred into perpendicular wavenumbers via Landau damping. At these smaller scales, the transfer frequency of electric energy diminishes due to decreased phase correlations among wavevectors, leading to the emergence of intermittency in the particle distribution structure.\n\n2. **Kinetic Effects:** Beyond the phenomena observed in purely hydrodynamic turbulence, our findings reveal that kinetic effects significantly influence the statistical properties of fluctuating fields. The presence of ions notably alters the shape of the probability density functions (PDFs), resulting in non-Gaussian distributions with tails that extend across multiple orders of magnitude. Furthermore, we observe that increasing the electron-to-ion mass ratio skews the PDFs further, affecting the scaling laws that describe the power spectra of these fluctuating fields.\n\n3. **Fluid Description:** We also perform DNS of the Euler equations to complement our kinetic analysis, providing a comprehensive understanding of the fluid dynamics involved in the turbulence of magnetized plasmas.\n\nOverall, this work enhances our understanding of the complex interplay between kinetic and fluid dynamics in astrophysical plasmas, offering insights that are crucial for both theoretical studies and practical applications in plasma physics.",
        "ori-fast-z-score": -1.3522468075656264,
        "water-fast-z-score": 5.30555710271907,
        "rewrite-fast-z-score": 0.2544566789039913
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Shapes of Molecular Cloud Cores in Orion .\nAbstract:\nWe present the results of an investigation into the shapes and orientations of molecular cloud cores in the Orion Nebula region using near-infrared polarimetry obtained with the Gemini North telescope. We find that most (80%) of our sample are oblate spheroids, while 20% have more complex morphologies including prolate spheroids, disks, or bipolar structures. The majority of these objects show no evidence for rotation; however, we do detect significant polarization vectors aligned perpendicular to the major axes of several sources which may be due to magnetic fields. These observations suggest that many of the clouds were formed by large-scale gravitational collapse rather than rotational support. This work is supported by NASA grant NNX10AC99G. We report on the results of an investigation of the shapes and orientations of dense molecular gas clumps within the Orion Nebula region. Using near-infrared polarimetric imaging data taken at Gemini Observatory s North Telescope, we identify 80 percent of our sample as oblate spheroids. Twenty percent exhibit more complicated morphologies such as prolate spheroids or bipolar structures. Most of these objects appear to lack any internal rotation but some display polarization vectors oriented perpendicularly to their major axes suggesting the presence of magnetic fields.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Shapes of Molecular Cloud Cores in Orion . Abstract : We present the conclusion of an search into the shapes and orientations of molecular dust cores in the Orion Nebula region utilizing near - infrared polarimetry obtained with the Gemini North telescope .We see that most ( 80 % ) of our sample are oblate spheroids , while 20 % have more sophisticated morphologies including prolate spheroids , disks , or bipolar forms . The majority of these objects show no evidence for rotation ; however , we do discover considerable polarization vectors aligned parallel to the main axes of several sources which may be due to magnetic fields .These measurements suggest that several of the clouds were created by large - scale gravitational failure rather than rotational support . This research is backed by NASA grant NNX10AC99G .We report on the conclusion of an investigation of the shapes and orientations of dense molecular dust clumps within the Orion Nebula region . Using near - infrared polarimetric imaging information taken at Gemini Observatory s North Telescope , we identify 80 percent of our sample as oblate spheroids .Twenty percent display more complicated morphologies such as prolate spheroids or bipolar forms . Most of these objects show to lack any internal rotation but some display polarization vectors oriented perpendicularly to their major axes suggesting the presence of magnetic fields .",
        "rewrite_text": "We present the findings of our investigation into the shapes and orientations of molecular dust cores located in the Orion Nebula region, utilizing near-infrared polarimetry data collected with the Gemini North telescope. Our analysis reveals that a significant majority, approximately 80%, of the molecular dust cores in our sample exhibit oblate spheroid shapes. In contrast, the remaining 20% display more complex morphologies, including prolate spheroids, disk-like structures, and bipolar configurations. Notably, while most of these cores show no signs of internal rotation, we observe a substantial alignment of polarization vectors that run parallel to the principal axes of several cores. This alignment may indicate the influence of magnetic fields within these structures. The implications of our findings suggest that the formation of these molecular clouds is more likely attributed to large-scale gravitational collapse rather than being supported by rotational forces. This research is supported by NASA grant NNX10AC99G, contributing to our understanding of the physical characteristics and formation processes of molecular cloud cores in this prominent star-forming region.",
        "ori-fast-z-score": -0.41702882811414954,
        "water-fast-z-score": 4.587317109255645,
        "rewrite-fast-z-score": 0.22360679774997896
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Physical Nature of Polar Broad Absorption Line Quasars .\nAbstract:\nWe present the results of an investigation into the physical nature of polar broad absorption line quasars (BALQSOs). We find that BALQSOs are more likely to be radio-loud than non-BAL QSOs, and that they have higher luminosities at rest-frame ultraviolet wavelengths. The fraction of BALQSOs in our sample is consistent with previous studies; however we do not detect any significant difference between the fractions of BALQSOs found among radio-quiet and radio-loud quasars. In addition, we find no evidence for differences in the properties of BALs observed along different lines-of-sight within individual objects. Finally, we show that there exists a correlation between the strength of the CIV emission-line blueshift and the equivalent width of the associated BAL trough. These findings suggest that BALQSOs may represent a special subclass of radio-loud quasars which are characterized by high accretion rates onto supermassive black holes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Physical Nature of Polar Broad Absorption Line Quasars . Abstract : We present the conclusion of an investigation into the physical nature of polar wide absorption line quasars ( BALQSOs ) .We see that BALQSOs are more likely to be radio - loud than non - BAL QSOs , and that they have greater luminosities at rest - frame ultraviolet wavelengths . The percentage of BALQSOs in our sample is compatible with previous research ; however we do not detect any large change between the fractions of BALQSOs discovered among radio - quiet and radio - loud quasars .In addition , we find no evidence for variations in the properties of BALs observed along various lines - of - seeing within particular objects . Finally , we prove that there exists a correlation between the strength of the CIV radiation - line blueshift and the equivalent thickness of the associated BAL trough .These studies imply that BALQSOs might represent a unique subclass of radio - loud quasars which are marked by high accretion levels onto supermassive black holes .",
        "rewrite_text": "We present the findings of our research on the physical characteristics of polar broad absorption line quasars (BALQSOs). Our analysis indicates that BALQSOs exhibit a higher likelihood of being classified as radio-loud compared to their non-BAL counterparts, alongside demonstrating increased luminosities in the rest-frame ultraviolet spectrum. The proportion of BALQSOs identified in our study aligns with previous investigations; however, we observe no significant variation in the prevalence of BALQSOs between radio-quiet and radio-loud quasars. Furthermore, our research reveals no substantial differences in the properties of broad absorption lines (BALs) when examined across different lines of sight within individual quasars. A notable finding of our study is the established correlation between the strength of the CIV emission line blueshift and the equivalent width of the corresponding BAL trough. These results suggest that BALQSOs may constitute a distinct subclass of radio-loud quasars, characterized by elevated accretion rates onto supermassive black holes. This research contributes to a deeper understanding of the unique physical properties of BALQSOs and their potential implications for the study of quasar evolution and the behavior of supermassive black holes.",
        "ori-fast-z-score": 0.46499055497527714,
        "water-fast-z-score": 6.119912853410033,
        "rewrite-fast-z-score": 1.1531133203941102
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  SIM PlanetQuest: The Most Promising Near-Term Technique to Detect, Find Masses, and Determine Three-Dimensional Orbits of Nearby Habitable Planets .\nAbstract:\nThe SIM PlanetQuest mission is the most promising near-term technique for detecting, finding masses, and determining three-dimensional orbits of nearby habitable planets.  This article describes how SIM PlanetQuest will find these planets by measuring their astrometric wobble as they transit in front of their parent stars.   It also discusses how SIM PlanetQuest can be used to detect other types of exoplanets such as those with large orbital eccentricities or that are on highly inclined orbits relative to our line-of-sight.    Finally, it presents some preliminary results showing what we might expect to learn about extrasolar planetary systems using this new instrumentation. Keywords: Extrasolar planet, Astrometry, SIM PlanetQuest, Transit detection, Mass measurement, Orbital determination. 1 Introduction   In recent years there has been an explosion in interest in discovering extra-solar terrestrial planets (exo-Earths) because of the possibility that one may harbor life like Earth does. There have now been more than 300 confirmed exo-planets discovered orbiting distant stars through various techniques including radial velocity measurements, photometric transits, direct imaging, and microlensing events  1  . However, all but two of these planets were found around relatively bright host stars (V < 12). These planets are typically massive gas giants with short periods of days to weeks  2  , making them difficult targets for detailed studies aimed at understanding the physical conditions necessary for life. For example, only three of these planets have measured masses: HD 209458b  3  , GJ 436b  4  , and OGLE-TR-561b  5  .  Of these, only HD 209458b has a radius determined directly  6  .\n2\n\nSIM PlanetQuest Mission Overview\nIn order to study the atmospheres and surfaces of smaller, cooler planets, which are likely candidates for hosting liquid water  7, 8  , astronomers need to find planets around fainter stars. To do so requires space-based observatories capable of obtaining high-precision astrometric data over many years. Such observations would allow us to measure the positions of thousands of faint stars simultaneously with precisions better than 0",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : SIM PlanetQuest : The Most Promising Near - Term Technique to Detect , Find Masses , and Determine Three - Dimensional Orbits of Nearby Habitable Planets . Abstract : The SIM PlanetQuest mission is the most exciting near - term technique for detecting , finding masses , and determining three - dimensional orbits of distant habitable planets .This page describes how SIM PlanetQuest will locate these planets by monitoring their astrometric wobble as they travel in front of their parent planets . It especially discusses how SIM PlanetQuest can be used to locate other types of exoplanets such as those with large orbital eccentricities or that are on highly inclined orbits relative to our line - of - sight .Finally , it presents some preliminary results showing what we may expect to experience about extrasolar planetary systems using this new instrumentation . Keywords : Extrasolar planet , Astrometry , SIM PlanetQuest , Transit detection , Mass calculation , Orbital determination .1 Introduction In past decades there has been an explosion in interest in discovering extra - solar terrestrial worlds ( exo - Earths ) because of the prospect that one may harbor living like Earth does . There have now been more than 300 verified exo - planets discovered orbiting distant stars through several methods using radial speed measurements , photometric transits , direct scanning , and microlensing events 1 .However , all but two of these planets were found around relatively faint host stars ( V < 12 ) . These planets are typically massive gas giants with short periods of weeks to weeks 2 , making them difficult targets for detailed experiments intended at studying the physical conditions crucial for life .For instance , only three of these planets have recorded masses : HD 209458b 3 , GJ 436b 4 , and OGLE - TR - 561b 5 . Of these , only HD 209458b has a diameter determined directly 6 .2 SIM PlanetQuest Mission Overview In order to study the atmospheres and surfaces of tiny , cooler planets , which are likely candidates for hosting liquid water 7 , 8 , astronomers need to find planets around fainter stars . To do so requires space - based observatories capable of acquiring high - precision astrometric data over numerous years .Such observations would enable us to measure the places of thousands of faint stars simultaneously with precisions well than 0",
        "rewrite_text": "**Title:** SIM PlanetQuest: The Most Promising Near-Term Technique for Detecting, Mass Estimation, and Three-Dimensional Orbital Determination of Nearby Habitable Planets\n\n**Abstract:** The SIM PlanetQuest mission represents a groundbreaking approach in the near-term exploration of habitable exoplanets, focusing on the detection, mass estimation, and determination of three-dimensional orbits of these distant worlds. This article elaborates on the methodology employed by SIM PlanetQuest, which utilizes astrometric measurements to observe the subtle wobbles of stars caused by the gravitational influence of orbiting planets. By tracking these astrometric shifts, the mission aims to identify not only Earth-like planets but also those with more complex orbital characteristics, such as high eccentricities or significant inclinations relative to our observational perspective. The paper further discusses the implications of these findings for our understanding of planetary systems beyond our own, emphasizing the potential for discovering a diverse array of exoplanets. Preliminary results from the mission are also presented, offering insights into the expected characteristics of extrasolar planetary systems that could be revealed through this innovative instrumentation. The significance of this research lies in its potential to enhance our knowledge of planets that may support life, particularly those orbiting fainter stars, which have been largely overlooked in previous studies. As the search for exo-Earths intensifies, the SIM PlanetQuest mission stands out as a pivotal tool in the quest to uncover the mysteries of the universe's habitable zones. \n\n**Keywords:** Extrasolar planets, Astrometry, SIM PlanetQuest, Transit detection, Mass estimation, Orbital determination. \n\n**1. Introduction:** In recent decades, the quest to discover exoplanets, particularly terrestrial worlds akin to Earth, has surged due to the tantalizing possibility that some may harbor life. To date, over 300 exoplanets have been confirmed, primarily through methods such as radial velocity measurements, photometric transits, direct imaging, and gravitational microlensing. However, the majority of these discoveries have been around relatively faint stars (V < 12), with most identified planets being massive gas giants with short orbital periods, complicating efforts to study conditions conducive to life. Notably, only three of these exoplanets have had their masses accurately recorded, with HD 209458b being the only one with a directly measured diameter. \n\n**2. SIM PlanetQuest Mission Overview:** To investigate the atmospheres and surfaces of smaller, cooler planets that are prime candidates for liquid water, astronomers must focus on detecting planets around fainter stars. Achieving this goal necessitates the deployment of space-based observatories capable of collecting high-precision astrometric data over extended periods, allowing for the simultaneous measurement of thousands of faint stars with unprecedented accuracy.",
        "ori-fast-z-score": 0.48349377841522817,
        "water-fast-z-score": 6.682681187076132,
        "rewrite-fast-z-score": -0.4472135954999579
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dynamical traps and chaotic advection in a meandering jet flow .\nAbstract:\nWe study the dynamics of particles suspended in an idealized, two-dimensional turbulent jet using direct numerical simulations (DNS). The jet is forced by imposing random velocity fluctuations at its inflow boundary; it develops into a coherent vortex street downstream that breaks down further downstream to form small-scale turbulence. We find that the particle trajectories are strongly influenced by the presence of large-scale vortices which trap them for extended periods of time. In addition, we observe that the particles can be trapped within smaller scale eddies as well. These dynamical traps lead to enhanced concentration levels of particles along certain regions of their trajectory. Finally, we show that the trapping effect depends on the initial position of the particles with respect to the mean flow direction. Our results suggest that this mechanism may play an important role in the transport of pollutants or other tracers in geophysical flows such as atmospheric jets. Turbulence plays an important role in many natural phenomena ranging from weather prediction to oceanic mixing processes  1  . It also has significant impact on industrial applications including combustion  2  , chemical engineering  3  , and fluid mechanics  4  .\nIn recent years there have been several studies aimed at understanding how particles behave when they are suspended in a turbulent flow  5  -  8  . This problem is relevant not only because of practical reasons but also due to fundamental interest in studying the statistical properties of Lagrangian trajectories  9  . For example, one would like to know whether particles tend to cluster together  10  or disperse homogeneously  11  depending upon their size  12  and/or shape  13  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dynamical trapping and chaotic advection in a meandering jet flow . Abstract : We research the dynamics of molecules dropped in an idealized , two - dimensional turbulent plane using direct numerical simulations ( DNS ) .The jet is displaced by imposing random momentum fluctuations at its inflow boundary ; it develops into a coherent vortex road downstream that broke down further downstream to form small - scale turbulence . We see that the particle trajectories are strongly altered by the presence of large - scale vortices which capture them for extended times of time .In addition , we find that the particles can be trapped within smaller scale eddies as well . These dynamical trapping result to heightened density levels of substances along particular regions of their path .Finally , we show that the capturing phenomenon depends on the first orientation of the molecules with regard to the mean flow path . Our results propose that this mechanism may play an important role in the diffusion of pollutants or other tracers in geophysical flows such as atmospheric jets .Turbulence acts an important role in many natural observations ranging from weather prediction to oceanic mixing systems 1 . It additionally has significant effect on industrial applications notably combustion 2 , chemical engineering 3 , and fluid engineering 4 .In recent years there have been numerous research targeted at studying how particles behave when they are suspended in a turbulent flow 5 - 8 . This problem is relevant not only because of practical reasons but also owing to significant interest in examining the statistical characteristics of Lagrangian trajectories 9 .For instance , one would like to see whether particles tend to group together 10 or disperse homogeneously 11 varying upon their shape 12 and / or shape 13 .",
        "rewrite_text": "In this study, we investigate the dynamics of molecules introduced into an idealized two-dimensional turbulent plane through direct numerical simulations (DNS). The jet flow is perturbed by applying random momentum fluctuations at its inflow boundary, leading to the formation of a coherent vortex street downstream, which subsequently breaks down into smaller-scale turbulence. Our findings reveal that the trajectories of particles are significantly influenced by the presence of large-scale vortices, which can capture these particles for extended durations. Furthermore, we observe that particles can also become trapped within smaller-scale eddies, resulting in increased density levels of substances along specific regions of their paths. Notably, the phenomenon of particle capture is shown to depend on the initial orientation of the molecules relative to the mean flow direction. These results suggest that such dynamical trapping mechanisms may play a crucial role in the diffusion of pollutants and other tracers within geophysical flows, such as atmospheric jets. The role of turbulence is critical in various natural phenomena, including weather forecasting and oceanic mixing systems. Additionally, turbulence has significant implications for industrial applications, particularly in combustion, chemical engineering, and fluid dynamics. Recent research has increasingly focused on understanding the behavior of particles suspended in turbulent flows, driven by both practical considerations and a desire to explore the statistical properties of Lagrangian trajectories. This includes investigations into whether particles tend to cluster or disperse uniformly, influenced by factors such as their shape and size. Overall, our study contributes to the growing body of knowledge regarding particle dynamics in turbulent environments, with potential applications in environmental science and engineering.",
        "ori-fast-z-score": -1.3522468075656264,
        "water-fast-z-score": 7.049123409692188,
        "rewrite-fast-z-score": 1.2004900959975617
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  General Properties of Quantum Zero-Knowledge Proofs .\nAbstract:\nQuantum zero-knowledge proofs are quantum protocols that allow one party to prove knowledge of some secret information without revealing any other information about it.  In this work, we study the general properties of these proofs and show how they can be used in order to construct efficient quantum authentication schemes for classical messages. We also present several applications of our results including new constructions of quantum key distribution (QKD) systems with unconditional security guarantees against collective attacks as well as improved QKD systems based on weak coherent pulses. Finally, we discuss possible extensions of our results towards more practical scenarios where the communication between Alice and Bob is not perfect but rather noisy or lossy. Quantum zero-knowledge proofs were introduced by Wiesner  1  , Brassard et al  2  and Cleve  3  . These proofs are quantum protocols that enable one party, called Alice, to convince another party, called Bob, that she knows certain secret information while keeping her secrets hidden. More formally, let us consider an interactive protocol between Alice and Bob consisting of two phases:  The first phase consists of a series of rounds during which Alice sends qubits to Bob who performs measurements on them according to his choice of measurement bases. At the end of each round, Bob announces publicly whether he accepts or rejects the received state. If Bob accepts at least half of all states sent by Alice then the second phase begins; otherwise, the protocol ends after the current round. During the second phase, Alice reveals her secrets to Bob if he accepted enough states in the previous phase. Otherwise, both parties abort the protocol. It was shown in  4  that such a proof system exists if and only if there exist one-way functions. However, no explicit construction of such proofs has been known until now.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : General Properties of Quantum Zero - Knowledge Proofs . Abstract : Quantum zero - knowledge proofs are quantum mechanisms that enable one party to confirm knowledge of some secret information without revealing any other information about it .In this research , we study the general properties of these proofs and understand how they can be used in order to build efficient quantum authentication schemes for classical messages . We also present many applications of our findings including novel constructions of quantum key distribution ( QKD ) networks with unconditional security assurance against collective assaults as well as improved QKD solutions based on weak coherent pulses .Finally , we explain possible extensions of our findings towards more realistic scenarios where the interaction between Alice and Bob is not good but rather noisy or lossy . Quantum zero - knowledge proofs were introduced by Wiesner 1 , Brassard et al 2 and Cleve 3 .These proofs are particle protocols that enable one party , called Alice , to convince another party , called Bob , that she knows particular hidden information while maintaining her secrets hidden . More technically , let us consider an interactive procedure between Alice and Bob composed of two phases : The first phase involves of a sequence of rounds during which Alice takes qubits to Bob who takes measurements on them based to his choice of measurement bases .At the end of each round , Bob declares publicly whether he agrees or accepts the received state . If Bob accepts at least half of all states sent by Alice then the second phase begins ; otherwise , the protocol ends after the present stage .During the second phase , Alice reveals her secrets to Bob if he offered enough states in the previous phase . Otherwise , both parties abort the protocol .It was shown in 4 that such a proof system exists if and only if there exist one - way functions . However , no explicit construction of such proofs has been known until now .",
        "rewrite_text": "Title: General Properties of Quantum Zero-Knowledge Proofs\n\nAbstract: Quantum zero-knowledge proofs represent a fascinating intersection of quantum mechanics and cryptography, allowing one party to demonstrate knowledge of a secret without disclosing any additional information. This study delves into the fundamental characteristics of quantum zero-knowledge proofs and explores their potential applications in developing efficient quantum authentication schemes for classical messages. We highlight various applications stemming from our research, including innovative designs for quantum key distribution (QKD) networks that offer unconditional security against collective attacks, as well as enhancements to QKD protocols utilizing weak coherent pulses. Furthermore, we discuss the implications of our findings in more practical contexts, particularly when the communication between the two parties, Alice and Bob, is subject to noise or loss.\n\nThe concept of quantum zero-knowledge proofs was first introduced by Wiesner, followed by contributions from Brassard et al. and Cleve. These protocols involve an interactive process where Alice, the prover, convinces Bob, the verifier, of her knowledge of specific hidden information while keeping that information confidential. The protocol consists of two main phases: the first phase comprises a series of rounds in which Alice sends qubits to Bob, who measures them based on his chosen measurement bases. After each round, Bob publicly indicates whether he accepts the state he received. If Bob accepts at least half of the states sent by Alice, the protocol progresses to the second phase; otherwise, it terminates.\n\nIn the second phase, Alice discloses her secrets to Bob, contingent upon his acceptance of a sufficient number of states in the first phase. If this condition is not met, the protocol is aborted. Previous research has established that such a proof system can exist if and only if one-way functions are present. However, until now, no explicit constructions of these proofs have been identified. Our work aims to bridge this gap, providing a deeper understanding of quantum zero-knowledge proofs and their practical implications in secure communication.",
        "ori-fast-z-score": -0.816496580927726,
        "water-fast-z-score": 6.042074698865172,
        "rewrite-fast-z-score": 2.271099895830676
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  High-harmonic generation in diatomic molecules: a quantum-orbit analysis of the interference patterns .\nAbstract:\nWe present an analytical model for high-order harmonic generation (HHG) in diatomic molecules, which is based on the concept of molecular orbitals and their associated electronic wavefunctions. The HHG process can be understood as a sequence of three steps: First, electrons are ionized by strong laser fields. Second, they propagate through the continuum until rescattering with parent ions occurs. Third, these returning electrons emit high harmonics when interacting again with the driving field. We show that this picture leads to a simple expression for the emitted harmonic intensity, which depends only on two parameters characterizing the molecule s orbital structure. This result allows us to explain the observed interference patterns between different harmonics in terms of destructive or constructive interferences between contributions from different molecular orbits. In addition, we demonstrate how our approach can be used to predict the emission properties of new types of molecules. High-order harmonic generation (HHG), i.e., the coherent emission of photons at odd multiples of the fundamental frequency of intense femtosecond laser pulses, has attracted considerable interest over recent years  1, 2  . It provides access to extreme ultraviolet radiation  3  , which enables novel applications such as attosecond pulse generation  4  , photoelectron spectroscopy  5  , and tomography  6  .\nThe underlying physical mechanism behind HHG was first explained within the semiclassical three-step model  7, 8  : An electron tunnels out of its atomic core into the continuum upon interaction with the electric field of the laser light. Afterwards it propagates freely before being driven back towards the nucleus by the same field. Finally, it recombines with the parent ion emitting a photon whose energy equals the sum of the kinetic energy gained during propagation and the binding energy lost due to tunneling  9  . Since then, several extensions have been developed  10  including the so-called quantum-orbit theory  11  , which takes into account the influence of the nuclear potential on the electron dynamics  12  . However, despite all efforts made so far, there still exist many open questions regarding the microscopic origin of HHG  13  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : High - harmonic production in diatomic compounds : a quantum - orbit analysis of the interference patterns . Abstract : We present an analytical theory for high - order harmonic production ( HHG ) in diatomic compounds , which is based on the idea of molecular orbitals and their accompanying electronic wavefunctions .The HHG process can be understood as a sequence of three stages : First , electrons are ionized by intense laser fields . Second , they propagate through the continuum until rescattering with mother ions happens .Third , these returning electrons emit large harmonics when interacting again with the driving field . We see that this picture leads to a simple expression for the emitted harmonic intensity , which depends only on two parameters characterizing the molecule s orbital structure .This result allows us to explain the observed interference patterns between various harmonics in terms of destructive or constructive interferences between contributions from different molecular orbits . In addition , we prove how our approach can be used to predict the emission behavior of new types of molecules .High - order harmonic production ( HHG ) , i . e . , the coherent emission of photons at odd multiples of the fundamental frequency of active femtosecond infrared signals , has garnered considerable interest over recent seasons 1 , 2 . It provides entry to extreme ultraviolet radiation 3 , which enables novel applications such as attosecond pulse production 4 , photoelectron spectroscopy 5 , and tomography 6 .The fundamental physical process behind HHG was first explained within the semiclassical three - step description 7 , 8 : An electron tunnels out of its atomic core into the continuum upon collision with the electric field of the laser light . Afterwards it propagates freely before being driven back towards the nucleus by the same field .Finally , it recombines with the parent ion emitting a photon whose power equals the sum of the kinetic power gained during propagation and the binding energy gained due to tunneling 9 . Since then , various extensions have been created 10 including the so - called quantum - orbit concept 11 , which gives into consideration the impact of the atomic potential on the electron mechanics 12 .However , despite all efforts made so far , there still appear many open questions regarding the microscopic ancestry of HHG 13 .",
        "rewrite_text": "We present a comprehensive analytical framework for understanding high-order harmonic generation (HHG) in diatomic compounds, grounded in the principles of molecular orbitals and their associated electronic wavefunctions. The HHG phenomenon can be delineated into three distinct stages: initially, electrons are ionized by the influence of intense laser fields; subsequently, these electrons traverse the continuum until they undergo rescattering with their parent ions; finally, upon returning, these electrons emit high-energy harmonics as they interact once more with the driving laser field. Our analysis yields a straightforward expression for the intensity of the emitted harmonics, which is determined solely by two parameters that characterize the molecular orbital structure. This formulation enables us to elucidate the observed interference patterns among various harmonics, attributing them to constructive or destructive interference arising from contributions of different molecular orbits.\n\nMoreover, we demonstrate that our theoretical approach can effectively predict the emission characteristics of novel molecular types. The phenomenon of high-order harmonic generation, defined as the coherent emission of photons at odd multiples of the fundamental frequency of active femtosecond infrared signals, has attracted significant attention in recent years. This process serves as a gateway to extreme ultraviolet radiation, facilitating groundbreaking applications such as attosecond pulse generation, photoelectron spectroscopy, and advanced imaging techniques. The foundational mechanism of HHG was initially described through a semiclassical three-step model, which involves the tunneling of an electron from its atomic core into the continuum, its subsequent free propagation, and its eventual recombination with the parent ion, resulting in photon emission. Despite the advancements in understanding HHG, including the incorporation of the quantum-orbit concept that accounts for the influence of atomic potentials on electron dynamics, numerous questions regarding the microscopic origins of HHG remain unresolved.",
        "ori-fast-z-score": 0.6964409092807231,
        "water-fast-z-score": 7.769230769230769,
        "rewrite-fast-z-score": -0.0854357657716761
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Noise-induced phase transitions: Effects of the noises  statistics and spectrum .\nAbstract:\nWe study noise-induced phase transitions in systems with multiplicative white Gaussian, Poissonian or Lévy noise. We show that for all these three types of noise there is an optimal noise intensity at which the system undergoes a transition to a state where it performs better than without noise. The optimal noise intensities are different depending on whether we consider additive or multiplicative noise. For multiplicative noise they depend also on the shape of the power spectral density (PSD) of the noise. In particular, if the PSD has a peak around zero frequency then the optimal noise intensity decreases as the width of this peak increases. If the PSD does not have such a peak but decays monotonically towards zero frequencies then the optimal noise intensity increases as the decay rate becomes slower. Finally, if the PSD decays faster than exponentially then the optimal noise intensity remains constant irrespective of how fast the PSD decays.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Noise - caused phase transitions : Effects of the noises statistics and spectrum . Abstract : We research sound - caused phase transitions in networks with multiplicative white Gaussian , Poissonian or Lévy noise .We see that for all these three sorts of noise there is an appropriate sound amplitude at which the process undergoes a change to a state where it performs better than without noise . The appropriate sound intensities are different vary on whether we choose additive or multiplicative sound .For multiplicative sound they rely also on the shape of the power spectral coefficient ( PSD ) of the signal . In particular , if the PSD has a peak around zero frequency then the ideal noise amplitude decreases as the length of this peak rises .If the PSD does not have such a peak but decays monotonically towards zero frequencies then the ideal noise amplitude rises as the decay rate gets smaller . Finally , if the PSD decays faster than exponentially then the ideal noise amplitude remains constant irrespective of how slow the PSD decays .",
        "rewrite_text": "Title: Noise-Induced Phase Transitions: The Impact of Noise Statistics and Spectrum\n\nAbstract: This study investigates the phenomenon of sound-induced phase transitions within networks subjected to various types of noise, specifically multiplicative white Gaussian, Poissonian, and Lévy noise. Our findings reveal that for each of these noise types, there exists a specific sound amplitude at which the system transitions to a state of enhanced performance compared to its behavior in the absence of noise. Notably, the optimal sound intensities differ depending on whether the sound is applied additively or multiplicatively. In the case of multiplicative sound, the optimal amplitude is also influenced by the characteristics of the power spectral density (PSD) of the noise signal. \n\nWe observe that when the PSD exhibits a peak near zero frequency, the ideal noise amplitude tends to decrease as the width of this peak increases. Conversely, if the PSD lacks such a peak and instead shows a monotonically decreasing trend towards lower frequencies, the optimal noise amplitude increases as the decay rate of the PSD diminishes. Furthermore, in scenarios where the PSD decays faster than exponentially, the ideal noise amplitude remains constant, regardless of the rate at which the PSD decays. \n\nThese results highlight the intricate relationship between noise characteristics and system performance, providing valuable insights into how different noise statistics and spectral properties can influence phase transitions in complex networks. This research has implications for understanding noise effects in various physical and biological systems, paving the way for future studies aimed at optimizing performance in noisy environments.",
        "ori-fast-z-score": -1.709408646894569,
        "water-fast-z-score": 5.584068246522259,
        "rewrite-fast-z-score": 2.5144742283748487
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Comparison of Magnetic Flux Distribution between a Coronal Hole and a Quiet Region .\nAbstract:\nWe compare the magnetic flux distribution in coronal holes (CHs) with that in quiet regions using vector magnetograms observed by Hinode/SOT/SP. We find that CHs have more open field lines than quiet regions, but they also contain many closed loops. The total unsigned magnetic flux density is higher for CHs than for quiet regions at all heights above the photosphere. In addition to this difference in the amount of magnetic flux, we found that the spatial distributions are different as well; the magnetic flux density decreases faster with height in CHs compared to quiet regions. This result suggests that there may be some differences in the physical processes occurring in these two types of solar regions. Keywords: Solar corona, Vector magnetogram, Open field line, Closed loop, Coronal hole, Quiet region. 1 Introduction Coronal holes (CHs), which appear darker in white light images taken by coronagraphs onboard satellites such as SOHO or STEREO, are known to play an important role in space weather because their open magnetic fields allow fast solar winds to escape into interplanetary space (e.g., Wang et al. (1998) , Cranmer & van Ballegooijen (2005) ).\nThe structure of CHs has been studied extensively both observationally and theoretically. It was suggested early on that CHs consist mainly of open field lines connected to remote parts of the Sun (Krieger et al. (1971) ), while closed loops were rarely seen inside them (Wiegelmann et al. (2010a) ). However, recent observations show that CHs do contain closed loops (Wiegelmann etal. (2010b) , Parnell et al. (2011 ), DeForest et al. (2013 , Brooks et al. (2014) ). These results suggest that CHs should not simply be regarded as open-field regions without any closed-loop structures.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Comparison of Magnetic Flux Distribution between a Coronal Hole and a Quiet Region . Abstract : We relate the magnetic flux spread in coronal holes ( CHs ) with that in quiet regions using vector magnetograms observed by Hinode / SOT / SP .We see that CHs have more open field lines than quiet regions , but they still hold several shut rings . The total unsigned magnetic flux concentration is higher for CHs than for calm regions at all heights above the photosphere .In addition to this changes in the quantity of magnetic flux , we learned that the spatial distributions are changed as well ; the magnetic flux concentration drops quicker with width in CHs compared to quiet regions . This result suggests that there may be some variations in the physical processes arising in these two kind of solar regions .Keywords : Solar corona , Vector magnetogram , Open field line , Closed loop , Coronal hole , Quiet region . 1 Introduction Coronal holes ( CHs ) , which appear darker in white light pictures taken by coronagraphs onboard satellites such as SOHO or STEREO , are known to hold an important role in space weather because their open magnetic fields allow quick solar winds to escape into interplanetary space ( e . g . , Wang et al .( 1998 ) , Cranmer & van Ballegooijen ( 2005 ) ) . The structure of CHs has been studied frequently both observationally and theoretically .It was suggested early on that CHs consist mostly of open field lines linked to remote parts of the Sun ( Krieger et al . ( 1971 ) ) , while opened circuits were seldom visible inside them ( Wiegelmann et al .( 2010a ) ) . However , recent observations show that CHs do include closed loops ( Wiegelmann etal .( 2010b ) , Parnell et al . ( 2011 ) , DeForest et al .( 2013 , Brooks et al . ( 2014 ) ) .These data suggest that CHs should not simply be regarded as open - field regions without any closed - ring structures .",
        "rewrite_text": "**Title:** Comparison of Magnetic Flux Distribution between a Coronal Hole and a Quiet Region\n\n**Abstract:** This study investigates the distribution of magnetic flux in coronal holes (CHs) compared to quiet regions, utilizing vector magnetograms obtained from the Hinode satellite's Solar Optical Telescope (SOT) and Spectro-Polarimeter (SP). Our findings indicate that CHs exhibit a greater number of open magnetic field lines relative to quiet regions; however, they still contain several closed magnetic loops. Notably, the total unsigned magnetic flux concentration is consistently higher in CHs than in quiet regions across all observed heights above the photosphere. Beyond the differences in the quantity of magnetic flux, we also observed significant variations in the spatial distribution of this flux. Specifically, the concentration of magnetic flux in CHs decreases more rapidly with increasing width compared to that in quiet regions. This observation implies potential differences in the underlying physical processes governing these two types of solar regions. \n\nCoronal holes, which appear darker in white light images captured by coronagraphs on satellites such as SOHO and STEREO, play a crucial role in space weather dynamics due to their open magnetic fields that facilitate the rapid escape of solar winds into interplanetary space. Previous research has frequently examined the structure of CHs from both observational and theoretical perspectives. Early studies proposed that CHs primarily consist of open field lines connected to distant solar regions, with closed circuits being rarely observed within them. However, more recent observations have revealed the presence of closed loops within CHs, challenging the notion that these regions are solely characterized by open magnetic fields. This evolving understanding underscores the complexity of coronal holes and their magnetic structures, suggesting that they should not be simplistically categorized as regions devoid of closed magnetic configurations. \n\n**Keywords:** Solar corona, Vector magnetogram, Open field line, Closed loop, Coronal hole, Quiet region.",
        "ori-fast-z-score": -0.5144957554275265,
        "water-fast-z-score": 5.788544409159491,
        "rewrite-fast-z-score": 1.8474044564757472
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Metal-insulator transition in the low-dimensional organic conductor (TMTSF)2FSO3 probed by infrared microspectroscopy .\nAbstract:\nThe metal-insulator phase diagram of the quasi-one dimensional organic conductor (TMTSF2)2SO3 has been investigated using infrared spectroscopy and scanning tunneling microscopy at temperatures down to 20 mK. The temperature dependence of the optical conductivity shows that the charge gap opens below TMI = 135 K, which is consistent with previous results obtained on single crystals grown under different conditions. In addition we find evidence for an additional energy scale associated with the formation of excitons near 50 meV. We show that this feature can be explained within a simple model based on electron-phonon interaction between molecular orbitals. Finally, our data reveal that the electronic structure changes significantly across the metal-insulator transition. This finding suggests that the insulating state may not simply result from localization effects but rather involves strong correlations among electrons. The metal-insulator phase diagram was studied in detail by infrared spectroscopy and scanning tunnel microscopy experiments performed on high-quality single crystals of (TMTSF)2SO3. Our measurements provide direct spectroscopic evidence for two distinct energy scales involved in the opening of the charge gap as well as for significant modifications of the electronic structure across the metal-insulator boundary.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Metal - insulator transition in the small - dimensional organic conductor ( TMTSF ) 2FSO3 probed by infrared microspectroscopy . Abstract : The metal - insulator phase diagram of the quasi - one dimensional organic conductor ( TMTSF2 ) 2SO3 has been investigated using infrared spectroscopy and scanning tunneling microscopy at conditions down to 20 mK .The temperature dependence of the optical conductivity reveals that the charge gap opens below TMI = 135 K , which is compatible with previous findings obtained on individual crystals grown under various circumstances . In addition we find proof for an additional power range involved with the formation of excitons near 50 meV .We see that this phenomenon can be described within a simple model based on electron - phonon interaction between molecular orbitals . Finally , our measurements reveal that the electronic structure shifts significantly across the metal - insulator transition .This found shows that the insulating state may not simply result from localization effects but rather involves strong correlations among electrons . The metal - insulator phase diagram was studied in detail by infrared spectroscopy and scanning tunnel microscopy experiments conducted on well - grade single crystals of ( TMTSF ) 2SO3 .Our measurements give significant spectroscopic evidence for two separate power scales implicated in the opening of the charge gap as well as for significant modifications of the electronic configuration across the metal - insulator boundary .",
        "rewrite_text": "**Title:** Metal-Insulator Transition in the Small-Dimensional Organic Conductor (TMTSF)2FSO3 Probed by Infrared Microspectroscopy\n\n**Abstract:** This study explores the metal-insulator phase diagram of the quasi-one-dimensional organic conductor (TMTSF)2SO3 through the application of infrared spectroscopy and scanning tunneling microscopy, conducted at temperatures as low as 20 mK. Our findings indicate that the optical conductivity exhibits a temperature-dependent behavior, with a charge gap emerging below the critical temperature TMI = 135 K. This observation aligns with previous research conducted on individual crystals synthesized under various conditions. Furthermore, we provide evidence for an additional energy scale associated with the formation of excitons, observed at approximately 50 meV. This phenomenon can be effectively modeled using a framework that incorporates electron-phonon interactions among molecular orbitals. \n\nImportantly, our measurements demonstrate a significant alteration in the electronic structure as the system transitions from metallic to insulating states. This suggests that the insulating behavior cannot be solely attributed to localization effects; instead, it implies the presence of strong electron correlations. The detailed investigation of the metal-insulator phase diagram, utilizing high-quality single crystals of (TMTSF)2SO3, reveals compelling spectroscopic evidence for two distinct energy scales that contribute to the opening of the charge gap. Additionally, we observe notable changes in the electronic configuration across the metal-insulator transition boundary. These insights enhance our understanding of the underlying mechanisms governing the metal-insulator transition in low-dimensional organic conductors and highlight the complex interplay of interactions that dictate their electronic properties.",
        "ori-fast-z-score": 0.38138503569823695,
        "water-fast-z-score": 5.789863774090244,
        "rewrite-fast-z-score": 0.4583492485141057
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Black Hole Evaporation in an Expanding Universe .\nAbstract:\nWe study the evaporation process of black holes (BHs) in an expanding universe by using the tunneling method and the WKB approximation. We find that, for large BH masses M ≫ Mc2 = 3 × 10^8M⊙, where Mc is the critical mass at which the Hawking temperature vanishes, the lifetime of the BH decreases with increasing M as t ~ M-1/2. For small BH masses M < Mc2 , we show that the lifetime increases exponentially with decreasing M . The results are compared to those obtained within the framework of quantum field theory on curved space-time. It turns out that our predictions agree well with these results when one takes into account the effect of back reaction due to particle creation during the evaporation process. \nPACS numbers: 04.20.-q; 98.80.Cq \nI. INTRODUCTORY REMARK\nThe discovery of Hawking radiation  1  has led to renewed interest in the problem of black hole (BH) evaporation  2  -  4  . In this work, we will use the tunneling method  5  -  8  to calculate the decay rate of massive BHs in an expanding universe  9  .\nII. BLACK HOLE EVAPORATION IN AN EXPANDING UNIVERSE\n\nA. Tunneling Method\nIn order to apply the tunneling method to the case of evaporating BHs, it is convenient to introduce new coordinates (t′, r′), related to the original ones (t,r) through the following transformations  10  :",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Black Hole Evaporation in an Expanding Universe . Abstract : We research the evaporation process of black holes ( BHs ) in an increasing universe by using the tunneling procedure and the WKB approximation .We find that , for large BH masses M [UNK] Mc2 = 3 × 10 ^ [UNK] , where Mc is the critical mass at which the Hawking temperature vanishes , the lifetime of the BH decreases with increasing M as t ~ M - 1 / 2 . For small BH masses M < Mc2 , we show that the lifetime increases exponentially with decreasing M .The results are compared to those achieved within the framework of quantum field theory on curved space - time . It turns out that our predictions agree well with these results when one takes into consideration the impact of back response due to particle creation during the evaporation process .PACS numbers : 04 . 20 . - q ; 98 . 80 . Cq I . INTRODUCTORY REMARK The observation of Hawking radiation 1 has led to renewed concern in the issue of grey hole ( BH ) evaporation 2 - 4 .In this project , we will use the tunneling method 5 - 8 to estimate the decay rate of large BHs in an increasing universe 9 . II .BLACK HOLE EVAPORATION IN AN EXPANDING UNIVERSE A . Tunneling Method In order to apply the tunneling procedure to the case of evaporating BHs , it is convenient to introduce different coordinates ( t ′ , r ′ ) , related to the previous ones ( t , r ) through the following transformations 10 :",
        "rewrite_text": "**Title:** Black Hole Evaporation in an Expanding Universe\n\n**Abstract:** This study investigates the evaporation dynamics of black holes (BHs) within the context of an expanding universe, employing the tunneling method alongside the WKB approximation. Our findings indicate that for black holes with significant masses, specifically when M exceeds the critical mass Mc² = 3 × 10^(-18) kg, the lifetime of the black hole diminishes as the mass increases, following a relationship of the form t ~ M^(-1/2). Conversely, for black holes with masses below the critical threshold (M < Mc²), we observe an exponential increase in lifetime as the mass decreases. These results are juxtaposed with predictions derived from quantum field theory in curved spacetime, revealing a strong correlation when accounting for the back-reaction effects associated with particle creation during the evaporation process. The implications of Hawking radiation have reignited interest in the phenomenon of black hole evaporation, prompting a thorough examination of the decay rates of large black holes in an expanding universe. To facilitate the application of the tunneling method to evaporating black holes, we introduce a new set of coordinates (t', r'), which are related to the original coordinates (t, r) through specific transformations. This approach allows for a more nuanced understanding of the evaporation process in the context of an expanding cosmological backdrop. Our research contributes to the broader discourse on black hole thermodynamics and the fate of black holes in a dynamic universe, providing insights that may bridge theoretical predictions and observational phenomena. \n\n**PACS numbers:** 04.20.-q; 98.80.Cq",
        "ori-fast-z-score": 0.3144854510165755,
        "water-fast-z-score": 4.37880269519857,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Star formation in Perseus: III. Outflows .\nAbstract:\nWe present new observations of the outflow driven by the young star cluster NGC 1333 IRAS 4A, located at the center of the Perseus molecular cloud (d = 235 pc). The data were obtained with the Submillimeter Array and include continuum emission at 1.3 mm as well as CO(2-1) line emission. We find that the outflow is highly collimated along an axis oriented NNE-SSW, which coincides with the direction to the nearby Herbig-Haro objects HH 7-11. The total mass of the outflowing gas is estimated to be ~0.1 Msun, while its kinetic energy amounts to ~10^50 ergs. These values are comparable to those found for other low-mass protostellar systems. However, we also detect significant differences between this system and others previously studied. In particular, our results suggest that the outflow may have been triggered recently due to the interaction of the central source with another object or structure within the dense core surrounding it.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Star formation in Perseus : III . Outflows .Abstract : We report new images of the outflow generated by the young star cluster NGC 1333 IRAS 4A , located at the center of the Perseus molecular cloud ( d = 235 pc ) . The data were obtained with the Submillimeter Array and include continuum emission at 1 . 3 cm as well as CO ( 2 - 1 ) line emission .We see that the outflow is heavily collimated along an axis oriented NNE - SSW , which coincides with the direction to the nearby Herbig - Haro objects HH 7 - 11 . The total mass of the outflowing gas is expected to be ~ 0 . 1 Msun , while its kinetic power amounts to ~ 10 ^ 50 ergs .These values are comparable to those shown for other low - mass protostellar systems . However , we also observe significant variations between this scheme and others earlier studied .In particular , our findings show that the outflow could have been caused recently result to the interaction of the main source with another object or system within the dense core covering it .",
        "rewrite_text": "We present new observational data regarding the outflow produced by the young star cluster NGC 1333 IRAS 4A, situated at the heart of the Perseus molecular cloud, approximately 235 parsecs away. Utilizing the Submillimeter Array, we captured images that include both continuum emission at 1.3 cm and CO (2-1) line emission. Our analysis reveals that the outflow is highly collimated along a north-northeast to south-southwest axis, aligning with the orientation of the nearby Herbig-Haro objects HH 7-11. The estimated total mass of the outflowing gas is around 0.1 solar masses, while its kinetic energy is calculated to be approximately 10^50 ergs. These measurements are consistent with those observed in other low-mass protostellar systems. However, our results also indicate notable differences when compared to previously studied outflows. Specifically, our observations suggest that the outflow may have been recently triggered by interactions between the primary source and another object or system within the dense core that envelops it. This finding contributes to our understanding of the dynamics of star formation and the complex interactions that can influence the behavior of outflows in such environments.",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 4.00693842672377,
        "rewrite-fast-z-score": 1.5652475842498528
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Near-IR Spectra of Red Supergiants and Giants. I- Models with Solar and with Mixing-Induced Surface Abundance Ratios .\nAbstract:\nWe present new near-infrared (NIR) spectra for red supergiants and giants, obtained at the European Southern Observatory in La Silla, Chile.  The sample includes stars with spectral types ranging from M5 to M2Iab, luminosity classes III-V, and surface gravities between log g = 1.0 and 3.8 dex. We compare these observations with synthetic NIR spectra computed using MARCS model atmospheres that include mixing-induced chemical abundance changes near the stellar surface. Our results show that models including such effects are able to reproduce most observed features better than standard solar-scaled models. In particular, we find that the inclusion of mixing leads to an improved fit of the CO bandheads around 2.3 microns as well as of several atomic lines. However, some discrepancies remain which may be due to shortcomings in our current understanding of convection or other physical processes occurring close to the stellar surface.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Near-IR Spectra of Red Supergiants and Giants.I- Models with Solar and with Mixing-Induced Surface Abundance Ratios .Abstract : We report new near - infrared ( NIR ) spectra for red supergiants and giants , obtained at the European Southern Observatory in La Silla , Chile . The sample comprises stars with spectral classes ranging from M5 to M2Iab , luminosity classes III - V , and surface gravities between log f = 1 . 0 and 3 . 8 dex .We link these observations with artificial NIR spectra computed using MARCS model atmospheres that include mixing - caused chemical abundance changes near the stellar surface . Our results show that models featuring such effects are able to depict most observed features good than conventional solar - scaled models .In particular , we find that the introduction of mixing gives to an better fit of the CO bandheads around 2 . 3 microns as well as of several atomic lines . However , some discrepancies remain which perhaps be due to shortcomings in our future interpretation of convection or other physical processes resulting close to the stars surface .",
        "rewrite_text": "We present new near-infrared (NIR) spectral data for red supergiants and giants, collected at the European Southern Observatory in La Silla, Chile. Our study encompasses a diverse sample of stars classified within the spectral range of M5 to M2Iab, spanning luminosity classes III to V, and exhibiting surface gravities between log g = 1.0 and 3.8 dex. To enhance our understanding of these stellar objects, we correlate our observational data with synthetic NIR spectra generated using MARCS model atmospheres, which incorporate changes in chemical abundances at the stellar surface induced by mixing processes. \n\nOur findings indicate that models accounting for these mixing-induced abundance variations provide a significantly improved representation of the observed spectral features compared to traditional solar-scaled models. Notably, the inclusion of mixing effects leads to a superior fit for the CO bandheads located around 2.3 microns, as well as for various atomic lines present in the spectra. Despite these advancements, we acknowledge that some discrepancies persist, which may stem from limitations in our current understanding of convection dynamics or other physical phenomena occurring in the vicinity of the stellar surfaces. This research contributes to the ongoing efforts to refine stellar atmosphere models and deepen our comprehension of the complex processes governing the evolution of red supergiants and giants.",
        "ori-fast-z-score": 0.11547005383792514,
        "water-fast-z-score": 4.50333209967908,
        "rewrite-fast-z-score": -0.6060915267313265
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  VOODB: A Generic Discrete-Event Random Simulation Model to Evaluate the Performances of OODBs .\nAbstract:\nThe performance evaluation of object-oriented databases (OODBs) is an important issue in database research and development, but it has been difficult because there are many factors that affect their performances. In this study we propose VOODB as a generic discrete-event random simulation model for evaluating the performances of OODBs. The proposed model can be used with any OODB system by simply changing its configuration parameters. We have implemented our model using Visual Basic 6.0 on Windows NT 4.0 platform. To evaluate the effectiveness of our model, we conducted experiments with two different OODB systems, O2 and ObjectStore. Our experimental results show that our model provides accurate estimations of the response times of both OODB systems under various workloads. Keywords: Performance Evaluation, Database System, Object-Oriented Database Systems, Discrete Event Simulations, Response Time Prediction. 1 Introduction Object-oriented databases (OODBSs), which provide powerful data modeling capabilities such as inheritance, encapsulation, polymorphism, etc., have become increasingly popular recently  l  . However, since they support complex data structures and operations, their performances may vary widely depending upon several factors  2  .\nIn order to develop high-performance OODBSs, it is necessary to analyze how these factors influence their performances. Therefore, researchers have studied the performance evaluations of OODBSs extensively  3  , 4 , 5 , 6 , 7 , 8 , 9 , lo , 11 , 12 , 13 , 14 , 15 , 16 ,  17  , 18 , 19 ,  20  , 21 ,  22  , 23 ,  24  , 25 ,  26  , 27 ,  28  , 29 ,  30  , 31 ,  32  , 33 ,  34  , 35 ,  36  ,  37J,  38  ,  39J,  40  ,  411,  42  ,  43J,  44  ,  45J,  46  ,  47J,  48  ,  49J,  50  ,  51J,  52J,  53J,  54J,  55J,  56J,",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : VOODB : A Generic Discrete - Event Random Simulation Model to Evaluate the Performances of OODBs . Abstract : The performance assessments of object - oriented data ( OODBs ) is an important issue in database study and development , but it has been difficult because there are many factors that affect their performances .In this study we propose VOODB as a generic discrete - event random simulation method for evaluating the performances of OODBs . The proposed description can be used with any OODB network by simply changing its setup elements .We have integrated our model utilizing Visual Basic 6 . 0 on Windows NT 4 . 0 framework . To assess the performance of our model , we conducted experiments with two different OODB systems , O2 and ObjectStore .Our research results show that our model provides reliable estimations of the response periods of both OODB systems under various workloads . Keywords : Performance Evaluation , Database System , Object - Oriented Database Systems , Discrete Event Simulations , Response Time Prediction .1 Introduction Object - oriented libraries ( OODBSs ) , which provide potent data modeling technologies such as inheritance , encapsulation , polymorphism , etc . , have become increasingly popular recently l . However , since they support difficult information structures and functions , their performances may differ widely depending upon several considerations 2 .In order to develop large - performance OODBSs , it is required to analyze how these influences influence their performances . Therefore , researchers have researched the performance evaluations of OODBSs extensively 3 , 4 , 5 , 6 , 7 , 8 , 9 , lo , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37J , 38 , 39J , 40 , 411 , 42 , 43J , 44 , 45J , 46 , 47J , 48 , 49J , 50 , 51J , 52J , 53J , 54J , 55J , 56J ,",
        "rewrite_text": "**Title:** VOODB: A Generic Discrete-Event Random Simulation Model for Evaluating the Performance of Object-Oriented Databases\n\n**Abstract:** The evaluation of performance in object-oriented databases (OODBs) is a critical area of research in database technology, yet it presents significant challenges due to the multitude of factors influencing performance outcomes. This paper introduces VOODB, a versatile discrete-event random simulation model designed specifically for assessing the performance of OODBs. The VOODB framework is adaptable and can be applied to any OODB network by simply modifying its configuration parameters. We implemented our model using Visual Basic 6.0 on the Windows NT 4.0 platform. To validate the effectiveness of VOODB, we conducted a series of experiments on two distinct OODB systems: O2 and ObjectStore. The findings from our experiments demonstrate that VOODB yields accurate predictions of response times for both OODB systems across a variety of workload scenarios. This research contributes to the ongoing discourse on performance evaluation in database systems, particularly in the context of object-oriented architectures. By providing a reliable simulation tool, VOODB facilitates a deeper understanding of the performance dynamics of OODBs, enabling developers and researchers to optimize their systems effectively. \n\n**Keywords:** Performance Evaluation, Database Systems, Object-Oriented Database Systems, Discrete Event Simulations, Response Time Prediction. \n\n**1 Introduction:** Object-oriented databases (OODBs) have gained significant traction in recent years due to their advanced data modeling capabilities, which include features such as inheritance, encapsulation, and polymorphism. However, the complexity of the information structures and functionalities they support can lead to considerable variability in performance, influenced by numerous factors. To create high-performance OODBs, it is essential to analyze how these factors impact overall performance. Consequently, extensive research has been dedicated to the performance evaluation of OODBs, highlighting the need for robust assessment tools like VOODB.",
        "ori-fast-z-score": -0.6897304947150052,
        "water-fast-z-score": 5.222245174270754,
        "rewrite-fast-z-score": 0.7016464154456235
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Pixels simultaneous detection probabilities and spatial resolution determination of pixelized detectors by means of correlation measurements .\nAbstract:\nThe authors present an experimental method for determining the probability that two photons simultaneously hit pixels in a detector, as well as its spatial resolution. The method is based on measuring correlations between pairs of photons emitted by a source with known angular distribution. It can be used to characterize any type of photon-counting detector (CCD cameras, photomultipliers etc.) without requiring knowledge about their internal structure or electronics. This information may then be used to improve the performance of imaging systems such as telescopes. The results are presented for a silicon-strip detector. They show good agreement with Monte Carlo simulations. DOI: 10.1088/1742-6596/aa5e20\nSpatial resolution and coincidence resolving time measurement of Si strip detectors using single-photon counting technique \nI. INTRODUCTIO N\nIn many applications it is important to know how accurately one can determine the position where a photon hits a detector. For example this information is needed when designing optical instruments like telescopes  1  . In order to measure the spatial resolution of a detector we need to have some reference point against which we compare our measured data  2  .\nOne way to obtain this reference point is to use a light source emitting photons at a well-defined angle relative to the normal direction  3  , see Fig.  1(a) . If the detector has no intrinsic spatial resolution, all detected photons will come from a small area around the center of the detector surface. By scanning the detector over different angles θ, we can find out what fraction of the total number of counts comes from each part of the detector  4  . We call these fractions the response function R(θ) of the detector  5  . Knowing the shape of the response function allows us to calculate the spatial resolution of the detector  6  . However, if there is more than one pixel per unit solid angle, the situation becomes complicated because now several pixels could detect a given photon  7, 8  . To solve this problem we introduce here a new concept -the joint probability P ij that i-th and j-th pixels detect a photon simultaneously  9  . Using this concept together with the response function we",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Pixels concurrent discovery probabilities and spatial resolution determination of pixelized detectors by means of correlation observations . Abstract : The authors present an research technique for determining the probability that two photons simultaneously impact pixels in a detector , as well as its spatial resolution .The method is based on measuring correlations between pairs of photons generated by a source with known angular distribution . It can be used to characterize any type of photon - tracking detector ( CCD cameras , photomultipliers etc . )without need understanding about their internal structure or electronics . This knowledge might then be used to upgrade the performance of optical units such as telescopes .The results are presented for a silicon - strip detector . They show good agreement with Monte Carlo simulations .DOI : 10 . 1088 / 1742 - 6596 / aa5e20 Spatial resolution and coincidence resolving time measurement of Si strip detectors using single - photon counting technique I . INTRODUCTIO N In many applications it is important to know how accurately one can determine the position where a photon hits a detector . For example this information is needed when designing optical instruments like telescopes 1 .In order to measure the spatial resolution of a detector we require to have some reference location against which we compare our measured data 2 . One method to obtain this reference point is to use a light source emitting photons at a well - defined angle relative to the normal direction 3 , see Fig .1 ( a ) . If the sensor has no intrinsic spatial resolution , all detected photons will coming from a small area around the center of the sensor surface .By scanning the sensor over different angles θ , we can find out what fraction of the total number of counts coming from each portion of the detector 4 . We call these fractions the response function R ( θ ) of the detector 5 .Knowing the shape of the response function allows us to estimate the spatial resolution of the sensor 6 . However , if there is more than one pixel per unit solid angle , the situation grows difficult because now multiple pixels might detect a given photon 7 , 8 .To solve this question we give here a new notion - the joint probability P ij that i - th and j - th pixels detect a photon simultaneously 9 . Using this concept together with the response vector we",
        "rewrite_text": "Title: Concurrent Discovery Probabilities of Pixels and Spatial Resolution Assessment of Pixelized Detectors via Correlation Observations\n\nAbstract: In this study, we introduce a novel methodology for assessing the probability of simultaneous photon impacts on pixels within a detector, alongside determining its spatial resolution. This approach hinges on analyzing the correlations between pairs of photons emitted from a source with a known angular distribution. Importantly, this technique is applicable to a wide range of photon-tracking detectors, including CCD cameras and photomultipliers, without necessitating an in-depth understanding of their internal configurations or electronic components. The insights gained from this research can significantly enhance the performance of optical instruments, such as telescopes. Our findings, particularly illustrated through experiments conducted with a silicon-strip detector, demonstrate a strong correlation with Monte Carlo simulations, validating the effectiveness of our method. \n\nIn the introduction, we emphasize the critical need for precise localization of photon impacts on detectors, especially in the context of designing advanced optical devices like telescopes. To accurately measure a detector's spatial resolution, it is essential to establish a reference point for comparison. One effective strategy involves utilizing a light source that emits photons at a precisely defined angle relative to the detector's normal direction. In scenarios where the detector lacks intrinsic spatial resolution, all detected photons will originate from a localized area near the center of the sensor's surface. By systematically scanning the sensor across various angles, we can quantify the proportion of total counts attributed to different sections of the detector, which we refer to as the response function R(θ). Understanding the characteristics of this response function is crucial for estimating the spatial resolution of the sensor. However, complications arise when multiple pixels are present within a single unit solid angle, as this can lead to multiple pixels registering the same photon. To address this challenge, we introduce the concept of joint probability P_ij, which quantifies the likelihood of the i-th and j-th pixels detecting a photon concurrently. By integrating this concept with the response vector, we aim to provide a comprehensive framework for analyzing and improving the performance of pixelized detectors.",
        "ori-fast-z-score": 2.343379732657209,
        "water-fast-z-score": 7.387027942155209,
        "rewrite-fast-z-score": 1.750226025186606
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spectral study on the dips of Cir X-1 .\nAbstract:\nCircinus X-1 is an X-ray binary system with a neutron star and its companion, which has been observed in many wavelengths ranging from radio to gamma-ray bands. The source shows periodic dipping activity at X-ray energies that are caused by obscuration of the central X-ray emitting region due to matter falling onto the accretion disk around the compact object. In this work we present results obtained using data collected during two different observational campaigns carried out with Suzaku satellite (from 2005 to 2007) and INTEGRAL/IBIS telescope (from 2003 to 2009). We have analyzed the spectral properties of the source for both observations separately as well as combined together. Our analysis reveals that the spectrum can be described by a combination of several components such as: blackbody emission from the neutron star surface; Comptonized component produced by hot plasma surrounding the neutron star; reflection component originating from reprocessing of hard radiation emitted by the central X-ray source into softer photons; iron line feature arising from fluorescence of cold material located close to the neutron star.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spectral study on the dips of Cir X - 1 . Abstract : Circinus X - 1 is an X - ray binary system with a neutron star and its companion , which has been observed in multiple wavelengths ranging from radio to alpha - ray bands .The source shows intermittent dip activity at X - ray energies that are created by obscuration of the main X - ray emitting area owing to matter falling onto the accretion disk around the compact body . In this project we present results collected using data taken during two different observational campaigns carried out with Suzaku spacecraft ( from 2005 to 2007 ) and INTEGRAL / IBIS telescope ( from 2003 to 2009 ) .We have analyzed the spectral properties of the source for both surveys independently as well as combined together . Our study reveals that the spectrum can be described by a combination of several parts such as : blackbody emission from the neutron star surface ; Comptonized component produced by hot plasma surrounding the neutron star ; reflection portion arising from reprocessing of hard radiation emitted by the main X - ray source into stronger photons ; iron line feature arising from fluorescence of cold matter located close to the neutron star .",
        "rewrite_text": "**Title: Spectral Analysis of the Dips in Circinus X-1**\n\n**Abstract:** Circinus X-1 is an intriguing X-ray binary system comprising a neutron star and its companion, which has been extensively studied across various wavelengths, including radio and alpha-ray bands. This system exhibits intermittent dip activity in its X-ray emissions, a phenomenon attributed to the obscuration of the primary X-ray emitting region caused by material accreting onto the disk surrounding the compact object. In this study, we present findings derived from data collected during two distinct observational campaigns utilizing the Suzaku spacecraft (from 2005 to 2007) and the INTEGRAL/IBIS telescope (from 2003 to 2009). We conducted a thorough analysis of the spectral characteristics of Circinus X-1 for each survey independently, as well as in a combined dataset. Our results indicate that the observed spectrum can be effectively modeled as a combination of several components: a blackbody emission originating from the surface of the neutron star; a Comptonized component generated by hot plasma in the vicinity of the neutron star; a reflection component resulting from the reprocessing of high-energy radiation emitted by the primary X-ray source into softer photons; and a prominent iron line feature, which is indicative of fluorescence from cold matter situated near the neutron star. This comprehensive spectral analysis enhances our understanding of the complex interactions within Circinus X-1 and provides valuable insights into the physical processes governing the behavior of X-ray binaries.",
        "ori-fast-z-score": 1.5230192477004287,
        "water-fast-z-score": 5.858884758402822,
        "rewrite-fast-z-score": 1.3348476249438292
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dark Matter in Gauge Mediation from Emergent Supersymmetry .\nAbstract:\nWe propose that the dark matter (DM) and supersymmetric particles are generated by an emergent gauge symmetry at high energy scales, which is broken down to Standard Model symmetries below TeV scale. The DM candidate can be identified as a pseudo-Nambu-Goldstone boson associated with spontaneous breaking of global U(1) symmetry. We show how this scenario can explain various experimental results on DM searches including recent LHC data. In addition we discuss possible collider signatures for future experiments such as ILC or CLIC. Introduction: Dark matter (DM), whose existence has been inferred through its gravitational effects over many decades  1  , remains one of the most mysterious phenomena in particle physics today  2  . Although there have been numerous proposals for explaining the origin of DM  3  , none of them has yet provided compelling evidence for their viability  4  .\nIn this work, motivated by the idea of  emergent  theories  5  -  8  , we consider a new possibility where DM emerges from a spontaneously-broken global symmetry  9  . This approach provides a simple explanation for why DM should exist without introducing any additional fields beyond those already present within the Standard Model  10  . Furthermore, it allows us to identify the DM candidate as a pseudo-NambuGoldstone boson  11  , thereby providing a natural solution to the so-called  WIMP miracle   12  problem  13  . Finally, our model also predicts the presence of light scalar superpartners  14  , which may provide interesting signals at upcoming high-energy accelerator facilities  15  .\nThe rest of this article is organised as follows. In Sec. 2, we introduce our theoretical framework based upon emergent gauge mediation  16  . Then, in Secs. 3-7, we demonstrate how this framework can simultaneously address all current experimental constraints  17  -  20  while predicting novel phenomenological features  21  . Finally, in Sec. 8, we conclude with some remarks about further directions of research.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dark Matter in Gauge Mediation from Emergent Supersymmetry . Abstract : We suggest that the dark matter ( DM ) and supersymmetric particles are produced by an emergent gauge symmetry at high energy scales , which is broken down to Standard Model symmetries below TeV scale .The DM candidate can be identified as a quasi - Nambu - Goldstone boson associated with spontaneous breaking of global U ( 1 ) symmetry . We see how this situation can describe several experimental results on DM searches notably recent LHC evidence .In addition we explain possible collider signatures for future research such as ILC or CLIC . Introduction : Dark matter ( DM ) , whose existence has been inferred through its gravitational influences over numerous centuries 1 , continues one of the most obscure events in particle science today 2 .Although there have been numerous ideas for explaining the origin of DM 3 , none of them has already offered credible support for their viability 4 . In this research , driven by the idea of emergent theories 5 - 8 , we investigate a new possibility where DM appears from a spontaneously - breaking global symmetry 9 .This method provides a simple explanation for why DM should exist without removing any additional fields beyond those already found within the Standard Model 10 . Furthermore , it allows us to identify the DM candidate as a quasi - NambuGoldstone boson 11 , thereby providing a natural solution to the so - called WIMP miracle 12 problem 13 .Finally , our model also predicts the presence of light scalar superpartners 14 , which would offer useful signals at upcoming high - energy accelerator facilities 15 . The rest of this page is grouped as follows .In Sec . 2 , we provide our theory framework based upon emergent gauge mediation 16 .Then , in Secs . 3 - 7 , we prove how this framework can independently solve all present observation constraints 17 - 20 while predicting novel phenomenological characteristics 21 .Finally , in Sec . 8 , we conclude with some remarks about further directions of research .",
        "rewrite_text": "**Title:** Dark Matter in Gauge Mediation from Emergent Supersymmetry\n\n**Abstract:** In this study, we propose a novel framework for understanding dark matter (DM) and supersymmetric particles through the lens of emergent gauge symmetry at high energy scales. We posit that this symmetry is spontaneously broken to yield the Standard Model symmetries at energies below the TeV scale. Our primary candidate for DM is identified as a quasi-Nambu-Goldstone boson, which emerges from the spontaneous breaking of a global U(1) symmetry. This theoretical construct not only aligns with various experimental findings in DM searches, including recent evidence from the Large Hadron Collider (LHC), but also offers insights into potential collider signatures that could be explored in future experiments, such as those at the International Linear Collider (ILC) or the Compact Linear Collider (CLIC).\n\nThe existence of dark matter, inferred from its gravitational effects over centuries, remains one of the most enigmatic challenges in particle physics. Despite numerous proposals aimed at elucidating the origin of DM, a consensus on their viability has yet to be reached. Our research is motivated by emergent theories, leading us to investigate a scenario where DM arises from a spontaneously broken global symmetry. This approach provides a straightforward rationale for the existence of DM without necessitating the introduction of additional fields beyond those already established in the Standard Model.\n\nMoreover, our model naturally identifies the DM candidate as a quasi-Nambu-Goldstone boson, effectively addressing the so-called WIMP miracle. Additionally, we predict the existence of light scalar superpartners, which could yield significant signals at forthcoming high-energy accelerator facilities. The structure of this paper is organized as follows: Section 2 outlines the theoretical framework based on emergent gauge mediation. Sections 3 through 7 demonstrate how this framework can independently address all current observational constraints while predicting novel phenomenological features. Finally, Section 8 concludes with reflections on potential avenues for future research.",
        "ori-fast-z-score": 0.5183210553488161,
        "water-fast-z-score": 7.831560082980487,
        "rewrite-fast-z-score": 1.5085060660073935
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Photon-induced Nucleosynthesis: Current Problems and Experimental Approaches .\nAbstract:\nThe production of light elements in the early universe is one of the most important unsolved problems in astrophysics, cosmology, nuclear physics and particle physics. The standard model (SM) of elementary particles cannot explain how these elements were created during the first few minutes after the Big Bang. In this talk I will present an overview on our current understanding about the origin of light nuclei with A=1-3 produced by photonuclear reactions at high temperatures and densities in the early universe. This includes theoretical predictions for the abundances as well as experimental results obtained using radioactive beams at GSI Darmstadt. Finally, I will discuss possible future experiments to test some of the key predictions made within the SM. Keywords: Photonuclear reaction, Light element synthesis, Big Bang nucleosynthesis, Astrophysical SNe Ia explosion mechanism, Nuclear structure theory. 1 Introduction.\nLight element synthesis in the early universe is among the most challenging open questions in modern science  1  . It has been known since the 1960s that photons can induce nuclear fusion processes leading to the creation of light elements like D, 3 He, 4 He, 7 Li or 9 Be  2  , but it was not until recently when we have gained sufficient knowledge about the physical conditions prevailing in the early universe  3  .\nIn particular, the temperature T and density ρ reached values up to 10 12 K and 10 15 g/cm 3 respectively  4  . These extreme conditions are only accessible today in laboratory experiments using relativistic heavy-ion collisions  5  . However, due to the extremely short time scales involved  6  , such experiments do not allow us to study the formation of light elements directly  7, 8  . Instead they provide information about the properties of hot dense matter which may be relevant for the description of the initial stages of supernova explosions  9  . On the other hand, the abundance pattern observed in primordial objects like white dwarfs  10  or metal-poor stars  11  provides valuable constraints on the models describing the evolution of the chemical composition of the universe  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Photon - induced Nucleosynthesis : Current Problems and Experimental Approaches . Abstract : The production of light elements in the early universe is one of the most important unsolved issues in astrophysics , cosmology , nuclear science and particle science .The conventional model ( SM ) of primary nuclei cannot explain how these objects were created during the first few hours after the Big Bang . In this talk I will present an overview on our new understanding about the origin of light nuclei with A = 1 - 3 created by photonuclear reactions at high heats and densities in the early universe .This contains theoretical estimates for the abundances as well as research results acquired using nuclear beams at GSI Darmstadt . Finally , I will explore possible future research to test some of the key predictions taken within the SM .Keywords : Photonuclear reaction , Light element synthesis , Big Bang nucleosynthesis , Astrophysical SNe Ia explosion mechanism , Nuclear structure model . 1 Introduction .Light factor synthesis in the early universe is among the most challenging open questions in modern science 1 . It has been known since the 1960s that photons can induce nuclear fusion mechanisms leading to the creation of light elements like D , 3 He , 4 He , 7 Li or 9 Be 2 , but it was not until recently when we have achieved sufficient knowledge about the physical conditions prevailing in the early world 3 .In particular , the temperature T and density ρ reached values up to 10 12 K and 10 15 g / cm 3 respectively 4 . These severe environments are only accessible today in laboratory experiments using relativistic heavy - ion collisions 5 .However , owing to the exceptionally short period scales involved 6 , such studies do not enable us to study the formation of light elements directly 7 , 8 . Instead they give information about the properties of bright heavy material which may be appropriate for the description of the first stages of supernova explosions 9 .On the other hand , the abundance behavior observed in primordial objects like white dwarfs 10 or metal - poor stars 11 provides valuable constraints on the models explaining the evolution of the chemical composition of the universe 12 .",
        "rewrite_text": "**Title:** Photon-Induced Nucleosynthesis: Current Challenges and Experimental Strategies\n\n**Abstract:** The synthesis of light elements in the early universe remains one of the most significant unresolved questions in the fields of astrophysics, cosmology, nuclear science, and particle physics. The standard model (SM) of primordial nucleosynthesis fails to adequately explain the formation of these elements during the initial hours following the Big Bang. In this presentation, I will provide a comprehensive overview of our evolving understanding of the origins of light nuclei, specifically those with mass numbers A = 1 to 3, which are produced through photonuclear reactions under the extreme conditions of high temperature and density that characterized the early universe. This discussion will include theoretical predictions regarding the abundances of these light elements, as well as empirical findings derived from experiments utilizing nuclear beams at GSI Darmstadt. Furthermore, I will outline potential avenues for future research aimed at validating some of the critical predictions made within the framework of the standard model. \n\nThe synthesis of light elements in the early universe poses one of the most formidable challenges in contemporary science. Since the 1960s, it has been established that photons can trigger nuclear fusion processes that lead to the formation of light elements such as deuterium (D), helium-3 (³He), helium-4 (⁴He), lithium-7 (⁷Li), and beryllium-9 (⁹Be). However, it is only recently that we have gained sufficient insight into the physical conditions that prevailed during the universe's infancy. Notably, temperatures and densities reached extraordinary levels, approximately 10¹² K and 10¹⁵ g/cm³, respectively. These extreme environments can now be simulated in laboratory settings through relativistic heavy-ion collisions. Nevertheless, due to the incredibly brief timescales involved, direct observation of light element formation remains elusive. Instead, such experiments provide insights into the properties of dense matter, which may be relevant for understanding the early phases of supernova explosions. Additionally, the abundance patterns observed in primordial objects, such as white dwarfs and metal-poor stars, offer crucial constraints on models that seek to explain the chemical evolution of the universe. \n\n**Keywords:** Photonuclear reactions, Light element synthesis, Big Bang nucleosynthesis, Astrophysical supernova Ia explosion mechanisms, Nuclear structure models.",
        "ori-fast-z-score": 1.348187695720845,
        "water-fast-z-score": 8.538149682454623,
        "rewrite-fast-z-score": 0.8615864949867531
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Complementarity in the Einstein-Bohr Photon Box .\nAbstract:\nWe present an experimental investigation into complementarity and quantum nonlocality using a photonic implementation of the Einstein-Bohr photon box thought experiment. We demonstrate that our system exhibits both classical correlations, which are consistent with local hidden variable theories, as well as quantum correlations, which cannot be explained by any such theory. Our results show that this system is capable of exhibiting all three types of Bell inequalities simultaneously. The Einstein-Bohr (EB) photon-box  1  , also known as the EPRB  2  or the two-slit experiment  3  , has been used to investigate many aspects of quantum mechanics including entanglement  4  , Bell s theorem  5  , and quantum teleportation  6  . In its original form it consists of a source emitting pairs of photons at random times; one photon passes through a beam splitter while the other travels directly towards a detector. If we measure whether each photon arrives at either output port of the beam splitter then there will always be exactly one photon arriving at each detector. This measurement can be performed locally on each side without disturbing the state of the other particle. However if instead we perform measurements on both particles jointly then they must arrive together at the same detector  7, 8  .\nIn order for these experiments to exhibit genuine quantum effects, the detectors need to have high efficiency so that the probability of detecting more than one photon per pair is negligible  9  . Previous implementations of EB boxes have relied upon inefficient single-photon counting detectors  10  or inefficient avalanche photo diodes  11  . These devices do not allow us to distinguish between different numbers of detected photons and therefore prevent us from observing truly quantum behaviour  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Complementarity in the Einstein - Bohr Photon Box . Abstract : We present an experimental inquiry into complementarity and quantum nonlocality utilizing a photonic implementation of the Einstein - Bohr photon box thought experiment .We showed that our system displays both classical correlations , which are compatible with local hidden variable theories , as well as particle correlations , which cannot be described by any such theory . Our results show that this scheme is capable of displaying all three sorts of Bell inequalities simultaneously .The Einstein - Bohr ( EB ) photon - box 1 , sometimes known as the EPRB 2 or the two - slit study 3 , has been used to investigate many aspects of quantum mechanics including entanglement 4 , Bell s theorem 5 , and quantum teleportation 6 . In its initial form it consists of a source emitting pairs of photons at random times ; one photon passes through a beam splitter while the other travels directly towards a detector .If we measure whether each photon arrives at either output port of the light splitter then there will always be exactly one photon coming at each sensor . This measurement can be performed locally on each side without disturbing the state of the other particle .However if instead we perform observations on both particles jointly then they must arrive together at the same detector 7 , 8 . In order for these experiments to produce genuine quantum effects , the detectors need to have high efficiency so that the probability of detecting more than one photon per couple is negligible 9 .Previous implementations of EB boxes have relied upon inefficient single - photon counting detectors 10 or inefficient avalanche photographic diodes 11 . These systems do not enable us to distinguish between multiple numbers of identified photons and therefore prevent us from observing truly molecular behaviour 12 .",
        "rewrite_text": "In this article, we explore the concepts of complementarity and quantum nonlocality through an experimental realization of the Einstein-Bohr photon box thought experiment. Our findings reveal that the system exhibits both classical correlations, which align with local hidden variable theories, and particle correlations that defy such explanations. Notably, our experimental setup demonstrates the capability to satisfy all three forms of Bell inequalities concurrently. The Einstein-Bohr photon box, also referred to as the EPRB or the two-slit experiment, has been instrumental in probing various facets of quantum mechanics, including entanglement, Bell's theorem, and quantum teleportation. The original configuration involves a source that emits pairs of photons at random intervals; one photon traverses a beam splitter while its counterpart heads directly to a detector. When we measure the arrival of each photon at the output ports of the beam splitter, we consistently observe one photon at each sensor. This measurement can be conducted locally on either side without influencing the state of the other photon. However, if we opt to observe both particles simultaneously, they must arrive at the same detector. For these experiments to yield authentic quantum phenomena, it is crucial that the detectors exhibit high efficiency, ensuring that the likelihood of detecting more than one photon per pair remains minimal. Previous implementations of the Einstein-Bohr box have utilized inefficient single-photon counting detectors or suboptimal avalanche photodiodes, which hinder the ability to differentiate between multiple identified photons and consequently obscure the observation of genuine quantum behavior. Our work addresses these limitations and contributes to a deeper understanding of the interplay between classical and quantum correlations in the context of the Einstein-Bohr photon box.",
        "ori-fast-z-score": -0.18569533817705186,
        "water-fast-z-score": 4.125143236626951,
        "rewrite-fast-z-score": 1.7162326606420661
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Scattering amplitudes in strongly coupled N=4 SYM from semiclassical strings in AdS .\nAbstract:\nWe study the scattering amplitudes for gluons and gravitons at strong coupling using classical string solutions in Anti-de Sitter space (AdS). We show that these amplitudes can be obtained by evaluating certain correlation functions on the worldsheet boundary, which are related to tree-level gauge theory amplitudes via holography. The results agree with those found previously using integrability techniques. In addition we find new contributions to the graviton-graviton amplitude involving an infinite tower of massive states. These arise because our solution is not invariant under global Poincare transformations; they correspond to corrections to the supergravity action induced by higher derivative terms in the bulk effective field theory. \nIntroduction\n\nThe AdS/CFT correspondence  1  relates type IIB superstrings propagating in ten-dimensional anti-de Sitter space-time (AdS) to conformal field theories living on its four-dimensional boundary. This duality has been used extensively over recent years as a tool to explore non-perturbative phenomena in quantum gravity  2  . It also provides a novel approach to studying strongly-coupled gauge theories such as QCD  3  .\nIn this talk we will consider the simplest example of the AdS/CFT correspondence -the maximally supersymmetric Yang-Mills (N=4 SYM) theory  4  , whose dual description involves type IIA strings moving in AdS 5 × S 5  5  . At weak  t Hooft coupling λ = g 2 Y M N ≪ 1, where g Y M denotes the Yang-Mills coupling constant, perturbative calculations have shown that the two descriptions match exactly  6  . However, it remains unclear how to calculate quantities like scattering amplitudes directly within the gauge theory at large values of λ  7, 8  . On the other hand, one may use the AdS/CFT dictionary  9  to translate between observables calculated in either side of the duality. For instance, the expectation value of Wilson loops in the gauge theory corresponds to the area of minimal surfaces embedded into AdS  10  ; while n-point correlators of local operators in the gauge theory are given by functional integrals over n-punctured Riemann surfaces  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Scattering amplitudes in heavily coupled N = 4 SYM from semiclassical strings in AdS . Abstract : We study the scattering amplitudes for gluons and gravitons at powerful coupling using traditional string solutions in Anti - de Sitter space ( AdS ) .We see that these amplitudes can be obtained by evaluating several coupling functions on the worldsheet border , which are related to tree - level gauge theory amplitudes via holography . The results agree with those identified previously used integrability methods .In addition we find new contributions to the graviton - graviton amplitude involving an endless tower of large states . These occur because our solution is not invariant under universal Poincare processes ; they relate to corrections to the supergravity action generated by higher derivative words in the bulk effective field theory .Introduction The AdS / CFT relationship 1 relates class IIB superstrings propagating in ten - dimensional anti - de Sitter space - time ( AdS ) to conformal field schemes residing on its four - dimensional boundary . This duality has been used widely over recent years as a platform to study non - perturbative phenomena in particle gravity 2 .It additionally offers a novel method to investigating strongly - coupled gauge fields such as QCD 3 . In this talk we will take the simplest example of the AdS / CFT relationship - the maximally supersymmetric Yang - Mills ( N = 4 SYM ) theory 4 , whose dual description involves class IIA strings shifting in AdS 5 × S 5 5 .At weak t Hooft coupling λ = g 2 Y M N [UNK] 1 , where f Y M denotes the Yang - Mills coupling constant , perturbative calculations have shown that the two descriptions fit precisely 6 . However , it remains unclear how to estimate quantities like absorption amplitudes directly within the gauge theory at large values of ν 7 , 8 .On the other hand , one may use the AdS / CFT dictionary 9 to translate between observables calculated in either side of the duality . For instance , the expectation value of Wilson loops in the gauge theory refers to the area of minimal surfaces embedded into AdS 10 ; while n - point correlators of local operators in the gauge theory are given by functional integrals over n - punctured Riemann surfaces 11 .",
        "rewrite_text": "**Title:** Scattering Amplitudes in Strongly Coupled N = 4 SYM from Semiclassical Strings in AdS\n\n**Abstract:** In this study, we investigate the scattering amplitudes of gluons and gravitons at strong coupling by employing classical string solutions within Anti-de Sitter space (AdS). Our analysis reveals that these scattering amplitudes can be derived by evaluating various coupling functions at the boundary of the worldsheet, which are intrinsically linked to tree-level gauge theory amplitudes through the principles of holography. The findings are consistent with previous results obtained through integrability methods. Furthermore, we uncover novel contributions to the graviton-graviton amplitude that involve an infinite series of large states. These contributions arise due to the lack of invariance of our solution under universal Poincaré transformations, which in turn relate to modifications in the supergravity action induced by higher derivative terms in the bulk effective field theory.\n\nThe AdS/CFT correspondence serves as a pivotal framework, linking type IIB superstrings propagating in ten-dimensional Anti-de Sitter spacetime to conformal field theories defined on its four-dimensional boundary. This duality has gained significant traction in recent years as a means to explore non-perturbative phenomena in quantum gravity. It also provides a unique avenue for examining strongly coupled gauge theories, such as Quantum Chromodynamics (QCD). In this work, we focus on the simplest instance of the AdS/CFT correspondence: the maximally supersymmetric Yang-Mills (N = 4 SYM) theory, whose dual description involves type IIA strings propagating in AdS5 × S5. At weak 't Hooft coupling, where λ = g²YM N << 1, perturbative calculations have demonstrated a precise agreement between the two descriptions. However, challenges remain in estimating quantities such as absorption amplitudes directly within the gauge theory framework at large coupling values. The AdS/CFT dictionary facilitates the translation of observables between the two sides of the duality, exemplified by the correspondence between the expectation values of Wilson loops in the gauge theory and the areas of minimal surfaces in AdS, as well as the n-point correlators of local operators represented by functional integrals over n-punctured Riemann surfaces.",
        "ori-fast-z-score": -1.6654083300081026,
        "water-fast-z-score": 5.313445624311566,
        "rewrite-fast-z-score": 0.49656353316142077
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Efficient model chemistries for peptides. I. Split-valence Gaussian basis sets and the heterolevel approximation in RHF and MP2 .\nAbstract:\nThe present work is concerned with efficient methods to calculate molecular properties, such as vibrational frequencies or electronic excitation energies, using ab initio quantum chemical techniques. The main focus lies on the calculation of these quantities for large systems containing many atoms (e.g., proteins). In this context we have developed an approach which allows us to reduce computational costs significantly by combining two different approximations. First, we use split-valence Gaussian basis functions instead of conventional Cartesian Gaussians. Second, we apply the so-called  heterolevel  approximation within restricted Hartree-Fock theory and second-order Moller-Plesset perturbation theory. This combination leads to very accurate results at low computational cost even if applied to relatively large molecules like polypeptides. We demonstrate that our method can be used successfully to study the influence of solvent effects on the structure and stability of small peptides. Finally, we show how it may also be employed to investigate excited-state processes occurring during photochemical reactions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Efficient model chemistries for peptides . I . Split - valence Gaussian basis sets and the heterolevel approximation in RHF and MP2 .Abstract : The present work is concerned with able methods to estimate chemical properties , such as vibrational speeds or electronic excitation energies , using ab initio quantum chemical techniques . The main interest lies on the determination of these quantities for large systems containing many atoms ( e . g . , proteins ) .In this situation we have developed an approach which allows us to reduce mathematical expenses significantly by combining two different approximations . First , we using split - valence Gaussian basis variables instead of standard Cartesian Gaussians .Second , we apply the so - called heterolevel algorithm within limit Hartree - Fock theory and second - order Moller - Plesset perturbation theory . This combination leads to very accurate outcomes at low theoretical cost especially if applied to relatively huge compounds like polypeptides .We suggest that our technique can be used successfully to study the impact of solvent effects on the composition and strength of tiny peptides . Finally , we indicate how it could also be employed to examine excited - state mechanisms occurring during photochemical reactions .",
        "rewrite_text": "Title: Efficient Model Chemistries for Peptides I: Split-Valence Gaussian Basis Sets and the Heterolevel Approximation in RHF and MP2\n\nAbstract: This study focuses on advanced methodologies for estimating chemical properties, such as vibrational frequencies and electronic excitation energies, through ab initio quantum chemical techniques. The primary objective is to accurately determine these properties for large molecular systems, particularly proteins, which consist of numerous atoms. To address the computational challenges associated with such large systems, we propose a novel approach that significantly reduces computational costs by integrating two distinct approximations. \n\nFirstly, we utilize split-valence Gaussian basis sets in place of conventional Cartesian Gaussian basis sets, which enhances the efficiency of the calculations. Secondly, we implement the heterolevel approximation within the frameworks of restricted Hartree-Fock (RHF) theory and second-order Møller-Plesset perturbation theory (MP2). This strategic combination yields highly accurate results while maintaining a low computational burden, making it particularly effective for larger compounds such as polypeptides.\n\nOur findings suggest that this methodology can be effectively employed to investigate the influence of solvent effects on the structural and energetic properties of small peptides. Furthermore, we discuss the potential applications of our approach in exploring excited-state dynamics that occur during photochemical reactions. By leveraging these efficient model chemistries, researchers can gain deeper insights into the behavior of complex biomolecular systems, paving the way for advancements in computational chemistry and molecular biology.",
        "ori-fast-z-score": -0.4082482904638631,
        "water-fast-z-score": 6.25846794771944,
        "rewrite-fast-z-score": 1.1547005383792515
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Supernova Channel of Super-AGB Stars .\nAbstract:\nWe present the results of our study on the evolution and nucleosynthesis in super-asymptotic giant branch (super-AGB) stars, which are evolved massive AGB stars with initial masses between 8 to 12 M⊙. We have performed detailed stellar evolutionary calculations for these stars using the latest version of the FRANEC code. The calculated models show that super-AGB stars experience strong mass loss during their late stages of evolution due to pulsation driven winds. These stars lose about 0.5 M⊙ before they enter into the white dwarf cooling phase. During this stage, we find that the surface abundances of CNO elements change significantly as compared to those at the end of the previous red giant phase. In particular, the surface abundance of nitrogen increases by more than one order of magnitude while carbon decreases by almost an order of magnitude. This is mainly because of the dredge-up episodes experienced by these stars when they cross the HR diagram towards higher luminosities.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Supernova Channel of Super - AGB Stars . Abstract : We present the conclusion of our research on the evolution and nucleosynthesis in super - asymptotic giant branch ( super - AGB ) stars , which are evolved large AGB stars with initial masses between 8 to 12 [UNK] .We have done detailed stellar evolutionary analyses for these stars using the latest version of the FRANEC coding . The measured scenarios demonstrate that super - AGB stars experience heavy mass loss during their late stages of evolved due to pulsation driven winds .These stars drop about 0 . 5 [UNK] before they enter into the white dwarf cooling phase . During this phase , we find that the surface abundances of CNO elements shift strongly as compared to those at the end of the previous red giant phase .In particular , the surface abundance of nitrogen changes by more than one order of magnitude while carbon decreases by almost an order of magnitude . This is mainly because of the dredge - up episodes experienced by these stars when they cross the HR diagram towards higher luminosities .",
        "rewrite_text": "We present the findings of our study on the evolution and nucleosynthesis of super-asymptotic giant branch (super-AGB) stars, which are massive AGB stars with initial masses ranging from 8 to 12 solar masses. Utilizing the latest version of the FRANEC code, we conducted comprehensive stellar evolutionary analyses to investigate the characteristics of these stars. Our results indicate that super-AGB stars undergo significant mass loss during their late evolutionary stages, primarily driven by pulsation-induced winds. Specifically, these stars lose approximately 0.5 solar masses before transitioning into the white dwarf cooling phase. \n\nDuring this cooling phase, we observed notable changes in the surface abundances of carbon, nitrogen, and oxygen (CNO elements) compared to their abundances at the conclusion of the preceding red giant phase. Notably, the surface abundance of nitrogen increases dramatically, exceeding one order of magnitude, while the abundance of carbon decreases by nearly an order of magnitude. These alterations in elemental composition are primarily attributed to dredge-up events that occur as the stars ascend the Hertzsprung-Russell diagram towards higher luminosities. Our findings contribute to a deeper understanding of the nucleosynthetic processes in super-AGB stars and their role in the chemical evolution of galaxies. This research highlights the importance of super-AGB stars in the context of stellar evolution and nucleosynthesis, providing insights into the mechanisms that govern mass loss and elemental abundance variations during their late evolutionary stages.",
        "ori-fast-z-score": -0.3216337604513384,
        "water-fast-z-score": 3.198010745334156,
        "rewrite-fast-z-score": 0.5388159060803247
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Probing Inward Motions in Starless Cores Using The HCN J = 1-0 Hyperfine Transitions : A Pointing Survey Toward Central Regions .\nAbstract:\nWe present the results of an unbiased survey toward starless cores using the HCN hyperfine transitions at 1.42 GHz and 2.12 GHz with the Nobeyama 45 m telescope to probe inward motions within these objects. We detected emission lines from all targets, except for L1521F (Taurus), which is known as one of the coldest prestellar cores. From our observations we found that the line widths are narrower than those observed by single-dish telescopes. This suggests that there may be unresolved substructure or turbulence on small scales inside the cores. For most sources, the peak intensities of both frequencies agree well with each other; however, for some cases they show significant differences between them. These discrepancies can be explained if the core has a temperature gradient along its radius and/or if it contains multiple velocity components. Our analysis shows that the kinetic temperatures derived from the two different frequency data sets range from 10 K to 30 K.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Probing Inward Motions in Starless Cores Using The HCN J = 1 - 0 Hyperfine Transitions : A Pointing Survey Toward Central Regions . Abstract : We present the results of an unbiased survey toward starless cores using the HCN hyperfine transitions at 1 . 42 GHz and 2 . 12 GHz with the Nobeyama 45 m observatory to probe eastward movements within these objects .We detected emission lines from all targets , except for L1521F ( Taurus ) , which is known as one of the coldest prestellar cores . From our observations we found that the line widths are smaller than those observed by single - dish telescopes .This implies that there may be unresolved substructure or turbulence on small scales inside the cores . For most sources , the peak intensities of both frequencies agree well with each other ; however , for some cases they show considerable variations between them .These discrepancies can be understood if the core has a temperature gradient along its radius and / or if it contains multiple velocity components . Our study shows that the kinetic temperatures derived from the two different amplitude data sets range from 10 K to 30 K .",
        "rewrite_text": "We present findings from an extensive survey of starless cores, utilizing the HCN hyperfine transitions at frequencies of 1.42 GHz and 2.12 GHz, conducted with the Nobeyama 45 m telescope. This investigation aims to explore inward motions within these starless cores. Our survey successfully detected emission lines from nearly all observed targets, with the exception of L1521F in the Taurus region, which is recognized as one of the coldest prestellar cores. Notably, our measurements revealed that the line widths are narrower than those typically recorded by single-dish telescopes, suggesting the presence of unresolved substructures or small-scale turbulence within the cores. \n\nIn analyzing the data, we found that the peak intensities at both frequencies generally align well; however, significant variations were noted in certain instances. These discrepancies may be attributed to the existence of a temperature gradient across the core's radius or the presence of multiple velocity components within the observed regions. Our analysis indicates that the kinetic temperatures derived from the two distinct amplitude datasets range between 10 K and 30 K. These results contribute to our understanding of the physical conditions within starless cores and highlight the complexities involved in their internal dynamics. Overall, this study enhances our knowledge of the processes occurring in these enigmatic regions of star formation, providing valuable insights into the early stages of stellar evolution.",
        "ori-fast-z-score": 0.629940788348712,
        "water-fast-z-score": 3.5,
        "rewrite-fast-z-score": -0.30779350562554625
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A unified projection formalism for the Al-Pd-Mn quasicrystal Xi-approximants and their metadislocations .\nAbstract:\nWe present an analysis of dislocation structures in icosahedral approximant phases based on a new approach to describing dislocation networks, which is applicable both to periodic crystals and aperiodic solids with any kind of local order. The method relies on projecting the Burgers vectors onto a set of basis vectors that are determined by the underlying lattice structure. We show how this can be used to describe the dislocation network in the decagonal phase of the AlPdMn system as well as its parent cubic phase. In particular we find that the dislocation network in these two phases has very similar characteristics despite the fact that they have different symmetries. This suggests that the dislocation network may play an important role in determining the physical properties of these materials. \n \n Introduction \n \n Dislocations are line defects in crystalline materials where there is a discontinuity in the atomic arrangement along some direction. They occur naturally during plastic deformation processes such as bending or stretching but also arise spontaneously when certain conditions are satisfied  1  . For example, it was recently shown that dislocations form at grain boundaries between grains of differing orientations  2  , and that they can even appear within single grains  3  .\n \nDislocations are classified according to their Burgers vector b = mu + nv (where u and v are primitive lattice vectors) into edge dislocations if m+n=0, screw dislocations if n=m=1, mixed dislocations otherwise  4  . Edge dislocations correspond to a displacement field perpendicular to the slip plane while screw dislocations give rise to a displacement parallel to the slip plane  5  . Mixed dislocations combine features of both types  6  . \n \nThe presence of dislocations leads to elastic strain fields around them  7, 8  . These strains can be calculated using the Peach-Koehler force acting on each individual dislocation  9  . If all dislocations were isolated then the total energy would simply be given by the sum over all contributions from individual dislocations  10  . However, in real systems dislocations interact strongly with one another through elastic interactions  11  . As a result, the total energy depends not only on the number density",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A unified projection formalism for the Al - Pd - Mn quasicrystal Xi - approximants and their metadislocations . Abstract : We present an assessment of dislocation systems in icosahedral approximant layers focused on a new approach to describing dislocation networks , which is applicable both to periodic crystals and aperiodic solids with any sort of local order .The method relies on projecting the Burgers vectors onto a setting of basis vectors that are decided by the underlying lattice structure . We see how this can be used to explain the dislocation system in the decagonal phase of the AlPdMn network as also as its parent cubic phase .In particular we find that the dislocation system in these two phases has very identical traits despite the fact that they have different symmetries . This implies that the dislocation system might play an important role in shaping the physical properties of these structures .Introduction Dislocations are line failures in crystalline structures where there is a discontinuity in the atomic arrangement along some direction . They happen naturally during plastic deformation processes such as stretching or folding but also arise spontaneously when particular conditions are fulfilled 1 .For instance , it was recently shown that dislocations form at wheat limits between particles of differing orientations 2 , and that they can even exist within double wheat 3 . Dislocations are classified according to their Burgers vector b = mu + nv ( where u and v are primitive lattice matrices ) into edge dislocations if m + n = 0 , screw dislocations if n = m = 1 , mixture dislocations otherwise 4 .Edge dislocations relate to a displacement field perpendicular to the slip plane while screw dislocations make rise to a displacement adjacent to the slip plane 5 . Mixed dislocations mix features of both types 6 .The presence of dislocations adds to elastic strain fields around them 7 , 8 . These strains can be determined using the Peach - Koehler stress acted on each individual dislocation 9 .If all dislocations were isolated then the total energy must simply be taken by the sum over all contributions from individual dislocations 10 . However , in real systems dislocations behave closely with one another through elastic interactions 11 .As a result , the total energy relies not only on the number density",
        "rewrite_text": "**Title:** A Unified Projection Formalism for the Al-Pd-Mn Quasicrystal Xi-Approximants and Their Metadislocations\n\n**Abstract:** This article presents a comprehensive analysis of dislocation systems within the layers of icosahedral approximants, introducing a novel framework for characterizing dislocation networks applicable to both periodic and aperiodic solids exhibiting various forms of local order. The proposed methodology involves projecting Burgers vectors onto a set of basis vectors determined by the underlying lattice structure. This approach is particularly effective in elucidating the dislocation systems present in the decagonal phase of the AlPdMn network, as well as its cubic parent phase. Notably, our findings reveal that the dislocation systems in these two distinct phases share strikingly similar characteristics, despite their differing symmetries. This observation suggests that dislocation systems may significantly influence the physical properties of these materials.\n\nDislocations, defined as line defects in crystalline structures where atomic arrangements are disrupted along specific directions, naturally occur during plastic deformation processes such as stretching and folding. They can also emerge spontaneously under certain conditions. Recent studies have demonstrated that dislocations can form at grain boundaries between particles with varying orientations and can even exist within double grains. Dislocations are categorized based on their Burgers vector, with edge dislocations characterized by a condition where the sum of the indices equals zero, screw dislocations defined by specific values of the indices, and mixed dislocations exhibiting features of both types.\n\nThe presence of dislocations contributes to elastic strain fields in their vicinity, which can be quantified using the Peach-Koehler stress acting on each dislocation. In an idealized scenario where dislocations are isolated, the total energy of the system is simply the sum of the energies of individual dislocations. However, in practical systems, dislocations interact elastically, leading to a more complex relationship where the total energy is influenced not only by the density of dislocations but also by their interactions. This unified projection formalism thus provides a robust framework for understanding the intricate behavior of dislocation systems in quasicrystalline materials.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.469939758793239,
        "rewrite-fast-z-score": 1.4795908857482156
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Generalizing Consistency and other Constraint Properties to Quantified Constraints .\nAbstract:\nWe present an algorithm for checking consistency in quantified constraints, which is based on the concept of generalized quantifiers. We show that our approach can be used to check several constraint properties such as satisfiability or equivalence between two sets of quantified constraints. Finally we discuss how this method could be applied to solve problems related to software testing. In computer science, many problems are formulated using constraints. For example, in Software Testing (ST), test cases are often represented by means of logical formulas called Test Cases Specifications (TCS). These TCSs contain some variables whose values have to satisfy certain conditions expressed with Boolean expressions. The problem consists then in finding all possible assignments of these variables satisfying the given conditions. This kind of problems has been studied extensively during last years but most works focus only on unquantified constraints. However, there exist situations where it may be useful to express some restrictions over the set of solutions using quantifiers.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Generalizing Consistency and other Constraint Properties to Quantified Constraints . Abstract : We create an algorithm for checking consistency in quantified constraints , which is based on the idea of generalized quantifiers .We see that our approach can be used to test several constraint features such as satisfiability or equivalence between two sets of quantified constraints . Finally we talk how this method could be applied to solve difficulties related to programming testing .In computer science , many issues are formulated using restrictions . For instance , in Software Testing ( ST ) , test situations are often modeled by means of rational formulas called Test Cases Specifications ( TCS ) .These TCSs comprise some parameters whose values have to obey certain conditions stated with Boolean expressions . The question involves then in obtaining all possible assignments of these variables satisfying the particular conditions .This kind of problems has been studied thoroughly during last decades but most works concentrate only on unquantified constraints . However , there exist situations where it could be useful to define some restrictions over the group of solutions use quantifiers .",
        "rewrite_text": "In this article, we present a novel algorithm designed to assess the consistency of quantified constraints, leveraging the concept of generalized quantifiers. Our methodology not only facilitates the evaluation of consistency but also extends to various constraint properties, including satisfiability and the equivalence of two sets of quantified constraints. We explore the implications of our approach for addressing challenges in software testing, where many problems are framed in terms of constraints. Specifically, in the realm of Software Testing (ST), test scenarios are frequently represented through rational formulas known as Test Case Specifications (TCS). These TCSs include parameters that must adhere to specific conditions articulated through Boolean expressions. Consequently, the primary objective is to identify all possible assignments of these variables that meet the stipulated conditions. While the study of such problems has been extensive over the past few decades, the majority of existing research has predominantly focused on unquantified constraints. Our work highlights the potential benefits of incorporating quantifiers to impose restrictions on the solution set, thereby enhancing the expressiveness and applicability of constraint-based formulations. By generalizing consistency and other constraint properties to encompass quantified constraints, we aim to provide a more robust framework for tackling complex problems in computer science, particularly in the context of software testing. This advancement opens new avenues for research and practical applications, ultimately contributing to more effective and efficient testing methodologies.",
        "ori-fast-z-score": -0.6546536707079772,
        "water-fast-z-score": 5.673665146135802,
        "rewrite-fast-z-score": 0.7844645405527362
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Evidence for nonlinear diffusive shock acceleration of cosmic-rays in the 2006 outburst of the recurrent nova RS Ophiuchi .\nAbstract:\nWe report on observations made with Suzaku and Swift during the 2006 eruption of the recurrent nova RS Ophiucchi (RS Oph). The X-ray light curve shows that the source was brightest at around day 50 after the optical peak, when it reached an apparent luminosity of ~10^38 erg s-1. We find evidence for nonthermal emission up to 100 keV by fitting the observed spectrum with a power-law model modified by photoelectric absorption. This is consistent with previous results obtained using data taken with other satellites such as Chandra and XMM-Newton. In addition we found that the photon index changed significantly between days 40-50 and 60-70; this may be due to changes in the physical conditions near the central engine or in the geometry of the emitting region. \n \n We also detected significant hard X-ray emission above 10 keV which can not be explained solely by thermal bremsstrahlung radiation. A possible explanation would be inverse Compton scattering of soft photons off relativistic electrons accelerated in shocks driven into the surrounding medium. If so, then these particles should have been accelerated to energies greater than 1 PeV.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Evidence for nonlinear diffusive surge velocity of cosmic - radiation in the 2006 outburst of the recurrent nova RS Ophiuchi . Abstract : We report on observations made with Suzaku and Swift during the 2006 eruption of the recurrent nova RS Ophiucchi ( RS Oph ) .The X - ray light curve shows that the source was brightest at around week 50 after the optical peak , when it attained an apparent luminosity of ~ 10 ^ 38 erg s - 1 . We get data for nonthermal emission up to 100 keV by fitting the seen spectrum with a power - law theory improved by photoelectric diffusion .This is consistent with previous findings obtained using data taken with other satellites such as Chandra and XMM - Newton . In addition we concluded that the photon index changed significantly between weeks 40 - 50 and 60 - 70 ; this might be due to changes in the physical conditions near the main engine or in the topology of the emitting area .We additionally observed significant hard X - ray radiation above 10 keV which can not be described solely by thermal bremsstrahlung emission . A potential explanation may be inverse Compton absorption of soft photons off relativistic electrons accelerated in shocks driven into the nearby medium .If so , then these objects should have been accelerated to energies higher than 1 PeV .",
        "rewrite_text": "We present findings from observations conducted with the Suzaku and Swift satellites during the 2006 eruption of the recurrent nova RS Ophiuchi (RS Oph). Our analysis of the X-ray light curve reveals that the source reached its peak brightness approximately 50 weeks following the optical maximum, achieving an apparent luminosity of around 10^38 erg s^-1. By employing a power-law model enhanced by photoelectric diffusion, we successfully extracted data on nonthermal emissions extending up to 100 keV. These results align with earlier observations made with other space observatories, including Chandra and XMM-Newton. Notably, we observed a significant variation in the photon index between weeks 40-50 and 60-70, suggesting potential alterations in the physical environment surrounding the nova's core or changes in the configuration of the emitting region. Furthermore, our observations indicated the presence of substantial hard X-ray radiation exceeding 10 keV, which cannot be adequately explained by thermal bremsstrahlung alone. A plausible interpretation of this phenomenon involves the inverse Compton scattering of soft photons by relativistic electrons that have been accelerated in shock waves interacting with the surrounding medium. If this hypothesis holds true, it implies that these electrons could have been accelerated to energies surpassing 1 PeV. This study contributes to the understanding of the complex dynamics of cosmic radiation during nova outbursts and highlights the intricate processes involved in the emission mechanisms at play in such astrophysical events.",
        "ori-fast-z-score": -1.6269784336399213,
        "water-fast-z-score": 5.391638660171921,
        "rewrite-fast-z-score": -0.8783100656536799
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Single Top Results from CDF .\nAbstract:\nThe Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider has recently reported evidence for a new particle with mass around 125 GeV, consistent with Standard Model expectations for the Higgs boson.  The D0 collaboration at Fermilab is also searching for this signal in its data set and has presented results on the search for single top quarks produced via t-channel exchange of a virtual W-boson as well as s-channel production through gluon fusion.   In both cases we find no significant excess over background predictions. We present our results here along with those from other experiments that have searched for similar signals. The CMS experiment at the LHC has recently reported evidence for an unexpectedly light scalar resonance decaying to pairs of photons or leptons  1  . This observation is compatible with the Standard Model expectation for the Higgs boson  2  , which would be expected to weigh about 126 GeV  3  .\nIn addition to the standard model Higgs boson searches performed by ATLAS  4  and CMS  5  , there are many extensions of the SM  6  that predict additional scalars  7, 8  . These models can lead to deviations from the SM prediction for the Higgs boson properties  9  such as spin  10  , parity  11  , CP  12  , coupling strengths  13  , branching ratios  14  , etc.. Many of these scenarios involve heavy particles that may be pair-produced at hadron colliders  15  . However, some theories  16  suggest that the Higgs-like state could be singlet under SU(2), U(1). Such states cannot be directly produced in pairs but only appear in association with another quark  17  . For example, in supersymmetric models  18  , the Higgs-like state appears in association with b-quarks  19  . Other examples include composite  20  and Little-Higgs  21  models where the Higgs-like state couples preferentially to third generation fermions  22  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Single Top Results from CDF . Abstract : The Compact Muon Solenoid ( CMS ) experiment at the Large Hadron Collider has recently published evidence for a new particle with mass around 125 GeV , compatible with Standard Model expectations for the Higgs boson .The D0 consortium at Fermilab is also searching for this signal in its data set and has presented data on the hunt for single leading quarks produced via t - channel exchange of a virtual W - boson as well as s - channel production through gluon fusion . In both cases we find no considerable increases over background predictions .We present our findings here along with those from other experiments that have searched for related signals . The CMS experiment at the LHC has recently published evidence for an unexpectedly light scalar resonance decaying to pairs of photons or leptons 1 .This measurement is compatible with the Standard Model estimate for the Higgs boson 2 , which would be anticipated to weigh about 126 GeV 3 . In addition to the standard theory Higgs boson searches undertaken by ATLAS 4 and CMS 5 , there are many extensions of the SM 6 that forecast additional scalars 7 , 8 .These models can lead to deviations from the SM estimate for the Higgs boson properties 9 such as spin 10 , parity 11 , CP 12 , coupling strengths 13 , branching factors 14 , etc . . Many of these scenarios involve heavy nuclei that might be pair - produced at hadron colliders 15 .However , some theories 16 suggest that the Higgs - like state possible be singlet under SU ( 2 ) , U ( 1 ) . Such groups never be directly produced in couples but only appear in relationship with another quark 17 .For instance , in supersymmetric theories 18 , the Higgs - like state occurs in association with b - quarks 19 . Other examples include composite 20 and Little - Higgs 21 models where the Higgs - like state couples preferentially to third generation fermions 22 .",
        "rewrite_text": "**Title: Single Top Results from CDF**\n\n**Abstract:** The Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider (LHC) has recently reported findings that suggest the existence of a new particle with a mass around 125 GeV, aligning with the Standard Model's predictions for the Higgs boson. Concurrently, the D0 collaboration at Fermilab is actively investigating this phenomenon within its dataset, focusing on the production of single leading quarks via t-channel exchange of a virtual W-boson, as well as s-channel production through gluon fusion. Despite thorough analysis, our results indicate no significant deviations from the expected background levels. This paper presents our findings alongside those from other experiments that have explored similar signals. \n\nThe CMS experiment has identified an unexpectedly light scalar resonance that decays into pairs of photons or leptons, which is consistent with the Standard Model's prediction for the Higgs boson, anticipated to have a mass around 126 GeV. Beyond the standard Higgs boson searches conducted by ATLAS and CMS, numerous extensions to the Standard Model propose the existence of additional scalar particles. These theoretical frameworks may introduce variations in the properties of the Higgs boson, including its spin, parity, CP violation, coupling strengths, and branching ratios. Many of these models predict the production of heavy nuclei at hadron colliders, while some theories suggest that the Higgs-like state could be a singlet under SU(2) and U(1), implying that it cannot be produced in pairs but rather appears in association with other quarks. For example, in supersymmetric models, the Higgs-like state is often linked with b-quarks. Other theoretical constructs, such as composite and Little Higgs models, indicate that the Higgs-like state may preferentially couple to third-generation fermions. This paper aims to synthesize these findings and contribute to the ongoing discourse surrounding the search for the Higgs boson and its potential extensions.",
        "ori-fast-z-score": 0.4703604341917986,
        "water-fast-z-score": 6.114685644493382,
        "rewrite-fast-z-score": 0.3713906763541037
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Energy-Efficient Resource Allocation in Wireless Networks with Quality-of-Service Constraints .\nAbstract:\nWe consider the problem of energy-efficient resource allocation for wireless networks under qualityof-service (QoS) constraints, where each user has an individual QoS requirement and is equipped with multiple radios to communicate simultaneously over different channels. We propose a novel framework that jointly optimizes power control, channel assignment, scheduling, and routing by formulating it as a mixed integer linear program (MILP). The proposed MILP formulation takes into account both intra-cell interference among users within one cell and inter-cell interference between neighboring cells. To solve this large-scale optimization problem efficiently, we develop two efficient algorithms based on Lagrangian relaxation techniques. Our simulation results show that our proposed algorithm can significantly improve network performance compared to existing schemes. In particular, when there are only a few active links per cell at any time instant, our scheme achieves up to 4 times higher throughput than the baseline scheme without increasing transmit powers or bandwidths. \n \n Keywords: Energy efficiency, Power control, Channel assignment, Scheduling",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Energy - Efficient Resource Allocation in Wireless Networks with Quality - of - Service Constraints . Abstract : We consider the issue of resource - efficient energy management for wireless networks under qualityof - service ( QoS ) restrictions , where each consumer has an individual QoS requirement and is equipped with many radios to connect simultaneously over distinct networks .We suggest a new framework that collectively optimizes power control , network assignment , planning , and routing by formulating it as a mixed integer linear program ( MILP ) . The proposed MILP formulation assumes into consideration both intra - cell interference among consumers within one cell and inter - cell interference between neighboring cells .To solve this big - scale optimization problem efficiently , we develop two efficient methods using on Lagrangian relaxation techniques . Our model results show that our proposed algorithm can significantly boost network quality relative to existing algorithms .In particular , when there are only a few active connections per cell at any time instant , our scheme achieves up to 4 times higher throughput than the baseline scheme without increasing receive powers or bandwidths . Keywords : Energy efficiency , Power control , Channel assignment , Scheduling",
        "rewrite_text": "Title: Energy-Efficient Resource Allocation in Wireless Networks with Quality-of-Service Constraints\n\nAbstract: This article addresses the challenge of optimizing energy management in wireless networks while adhering to quality-of-service (QoS) requirements. Each user in the network has specific QoS needs and is equipped with multiple radios, allowing them to connect to different networks simultaneously. To tackle this issue, we propose a novel framework that integrates power control, network assignment, planning, and routing into a cohesive strategy, formulated as a mixed integer linear program (MILP). Our MILP formulation takes into account both intra-cell interference, which occurs among users within the same cell, and inter-cell interference, which arises between adjacent cells. To efficiently solve this large-scale optimization problem, we introduce two effective methods based on Lagrangian relaxation techniques. The results from our model demonstrate that the proposed algorithm significantly enhances network performance compared to existing solutions. Notably, in scenarios where only a limited number of connections are active per cell at any given moment, our approach can achieve throughput levels up to four times greater than those of the baseline scheme, all without necessitating increases in received power or bandwidth. This research contributes to the field of wireless communications by providing a robust solution for energy-efficient resource allocation that meets stringent QoS constraints, thereby improving overall network efficiency and user satisfaction.\n\nKeywords: Energy efficiency, Power control, Channel assignment, Scheduling.",
        "ori-fast-z-score": 0.41256849850351734,
        "water-fast-z-score": 6.25846794771944,
        "rewrite-fast-z-score": 1.0169503597462533
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  HUDF-JD2: Mid-infrared Evidence for a z~2 Luminous Infrared Galaxy .\nAbstract:\nWe present new mid-IR photometry and spectroscopy of the HUDF-JD2 galaxy at redshift 2.081, which is one of the most luminous infrared galaxies known to date. The SED shows that it has an extremely red continuum with strong PAH emission features in its rest frame optical spectrum. We find evidence for both star formation activity (from the UV-optical) as well as obscured AGN activity (from X-ray observations). This object may be representative of a population of dusty star-forming galaxies undergoing rapid evolution during this critical epoch when massive black holes are growing rapidly along with their host galaxies. Keywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : HUDF - JD2 : Mid - infrared Evidence for a z ~ 2 Luminous Infrared Galaxy . Abstract : We present new mid - IR photometry and spectroscopy of the HUDF - JD2 galaxy at redshift 2 . 081 , which is one of the most luminous infrared galaxies known to date .The SED shows that it has an exceptionally red continuum with powerful PAH emission elements in its rest frame optical spectrum . We get confirmation for both star formation activity ( from the UV - optical ) as well as obscured AGN activity ( from X - ray observations ) .This object may be representative of a population of dusty star - creating stars undergoing fast evolution during this critical epoch when massive blue holes are growing rapidly along with their host galaxies . Keywords : Infrared , Redshift , Spectroscopy , Photometry , Black Hole Growth , Star Formation Rate Density , Ultraviolet Background Radiation , Cosmic Evolution , Cosmology , Extragalactic Astronomy , High Energy Astrophysics , Space Science , Nearby Galaxies",
        "rewrite_text": "We present a comprehensive analysis of the HUDF-JD2 galaxy, located at a redshift of 2.081, which stands out as one of the most luminous infrared galaxies identified to date. Our study includes new mid-infrared photometry and spectroscopy that reveal a strikingly red spectral energy distribution (SED) characterized by prominent polycyclic aromatic hydrocarbon (PAH) emission features in its rest-frame optical spectrum. The data indicates significant star formation activity, corroborated by ultraviolet and optical observations, alongside evidence of obscured active galactic nucleus (AGN) activity derived from X-ray measurements. This dual activity suggests that HUDF-JD2 may exemplify a class of dusty star-forming galaxies that are experiencing rapid evolutionary changes during a pivotal period in cosmic history. This era is marked by the swift growth of massive black holes in conjunction with their host galaxies, highlighting the intricate relationship between star formation and black hole growth. Our findings contribute to the understanding of the star formation rate density and the role of ultraviolet background radiation in cosmic evolution. This research has implications for the fields of cosmology, extragalactic astronomy, and high-energy astrophysics, as it sheds light on the processes governing galaxy formation and evolution in the early universe. The insights gained from HUDF-JD2 not only enhance our knowledge of nearby galaxies but also provide a broader context for the study of cosmic structures and their development over time. \n\nKeywords: Infrared, Redshift, Spectroscopy, Photometry, Black Hole Growth, Star Formation Rate Density, Ultraviolet Background Radiation, Cosmic Evolution, Cosmology, Extragalactic Astronomy, High Energy Astrophysics, Space Science, Nearby Galaxies.",
        "ori-fast-z-score": 0.13245323570650439,
        "water-fast-z-score": 2.888741522913896,
        "rewrite-fast-z-score": 0.3651483716701107
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Flow instabilities of magnetic flux tubes II. Longitudinal flow .\nAbstract:\nWe study the stability properties of longitudinal flows in straight and curved magnetic flux tubes using linearized ideal MHD equations. We find that for sufficiently large values of plasma beta, there is always an unstable mode with zero frequency (i.e., static) which grows exponentially fast at small wavenumbers. The growth rate increases monotonically as we increase the value of plasma beta. \n \n For smaller values of plasma beta, however, this instability disappears completely. In fact, we show analytically that if the plasma beta is less than some critical value then all modes are stable irrespective of their frequencies or wavelengths. This result agrees well with our numerical simulations. Finally, we also present results on the effect of curvature on the stability properties of longitudinal flow. It turns out that the presence of curvature has no significant effect on the stability properties of these flows. However, it does affect the nature of the eigenfunctions associated with different eigenvalues.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Flow instabilities of magnetic flux tubes II . Longitudinal fluid .Abstract : We research the stability properties of longitudinal streams in straight and curved magnetic flux tubes using linearized ideal MHD equations . We see that for enough large values of plasma beta , there is usually an unstable mode with zero frequency ( i . e . , static ) which increases exponentially rapidly at small wavenumbers .The growth speed increases monotonically as we increase the value of plasma beta . For lower values of plasma beta , however , this instability disappears entirely .In fact , we prove analytically that if the plasma beta is less than some essential value then all modes are stable irrespective of their frequencies or wavelengths . This result agrees well with our numerical simulations .Finally , we also present results on the impact of curvature on the stability properties of longitudinal stream . It turns out that the presence of curvature has no considerable impact on the stability properties of these flows .However , it does affect the nature of the eigenfunctions associated with various eigenvalues .",
        "rewrite_text": "In this study, we investigate the stability characteristics of longitudinal fluid streams within both straight and curved magnetic flux tubes, employing linearized ideal magnetohydrodynamics (MHD) equations. Our findings reveal that when the plasma beta is sufficiently large, there exists a typically unstable mode characterized by zero frequency, indicating a static nature that experiences exponential growth at small wavenumbers. Notably, the rate of growth for this instability increases in a monotonic fashion as the plasma beta value rises. Conversely, for lower plasma beta values, this instability is completely absent. We provide a rigorous analytical proof demonstrating that if the plasma beta is below a critical threshold, all modes remain stable, regardless of their frequencies or wavelengths. This analytical result is corroborated by our numerical simulations, reinforcing the reliability of our conclusions. Additionally, we explore the influence of curvature on the stability of longitudinal flows. Our results indicate that while curvature does not significantly alter the stability characteristics of these streams, it does have an effect on the nature of the eigenfunctions corresponding to various eigenvalues. This distinction is crucial for understanding the dynamics of fluid behavior in magnetic environments and has implications for astrophysical phenomena where magnetic flux tubes are prevalent. Overall, our research contributes to a deeper understanding of the interplay between plasma parameters and the stability of fluid flows in magnetized environments, paving the way for future investigations in this field.",
        "ori-fast-z-score": 0.741998516004452,
        "water-fast-z-score": 5.421374765483944,
        "rewrite-fast-z-score": 3.450267790489161
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The S-parameter in Holographic Technicolor Models .\nAbstract:\nWe study the effects on electroweak precision observables (EWPO) due to new physics at the TeV scale, which is motivated by recent LHC results and theoretical arguments for naturalness. We consider two classes of models with extra dimensions: Randall-Sundrum (RS) warped space model and holographic technicolor (HTC). In RS model we find that the corrections are too large compared to EWPOs if the mass scales involved satisfy MPlanck ~ 5TeV. However, this problem can be solved by introducing an additional bulk scalar field whose VEV breaks custodial symmetry softly. The resulting correction to T parameter is found to be small enough even when MPlanck = 5TeV. On the other hand, in HTC model there exists no such difficulty because the Higgs boson is composite particle made up of techni-dilaton and techni-sigma mesons.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The S - parameter in Holographic Technicolor Models . Abstract : We research the effects on electroweak accuracy observables ( EWPO ) due to recent science at the TeV scale , which is prompted by recent LHC results and theoretical evidence for naturalness .We consider two groups of models with extra dimensions : Randall - Sundrum ( RS ) warped space model and holographic technicolor ( HTC ) . In RS model we find that the corrections are too huge compared to EWPOs if the mass scales required satisfy MPlanck ~ 5TeV .However , this situation can be answered by using an additional bulk scalar field whose VEV broken custodial symmetry quietly . The resulting correction to T parameter is found to be small enough even when MPlanck = 5TeV .On the other hand , in HTC model there exists no such difficulty because the Higgs boson is composite particle making up of techni - dilaton and techni - sigma mesons .",
        "rewrite_text": "In this study, we investigate the implications of recent findings at the TeV scale on electroweak precision observables (EWPO), motivated by the latest results from the Large Hadron Collider (LHC) and theoretical considerations surrounding naturalness. Our focus is on two categories of models that incorporate extra dimensions: the Randall-Sundrum (RS) warped space model and holographic technicolor (HTC) models. \n\nIn the context of the RS model, we observe that the corrections to EWPO become excessively large when the mass scales are set to MPlanck ~ 5 TeV. This presents a significant challenge; however, we propose a solution by introducing an additional bulk scalar field that can break custodial symmetry in a subtle manner. This modification leads to a reduction in the corrections to the T parameter, rendering them sufficiently small even at the elevated mass scale of MPlanck = 5 TeV.\n\nConversely, the HTC model does not encounter the same issues as the RS model. In this framework, the Higgs boson is conceptualized as a composite particle, formed from the techni-dilaton and techni-sigma mesons. This intrinsic nature of the Higgs within the HTC model alleviates the concerns regarding large corrections to EWPO, suggesting a more favorable alignment with experimental observations. \n\nOverall, our findings highlight the nuanced interplay between theoretical models and empirical data, emphasizing the importance of considering additional fields and the composite nature of particles in addressing the challenges posed by electroweak precision measurements in the context of modern particle physics.",
        "ori-fast-z-score": -1.8382900600361156,
        "water-fast-z-score": 3.0983866769659336,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Orbital magnetization and its effects in spin-chiral ferromagnetic Kagome lattice .\nAbstract:\nWe study the orbital magnetization (OM) induced by spin-orbit coupling on a kagome lattice with chiral magnetic order, which is realized as an emergent property of the system at low temperatures. We show that the OM can be expressed in terms of the Berry curvature associated with the band structure near the Fermi level. The magnitude of the OM depends strongly on the strength of the spin-orbit interaction and the direction of the applied field. In particular, we find that when the external field points along one of the three equivalent <111> directions, there are two peaks in the temperature dependence of the OM. These results suggest that the OM may provide useful information about the nature of the ordered state in this material. \n \n Introduction \n \n Orbital magnetization (OM), also known as orbital polarization or orbital moment density, has been studied extensively for many years both theoretically  1 - 3  and experimentally  4 - 6  . It arises due to the presence of spin-orbit interactions  7  8  9  , and it plays important roles in various physical phenomena such as topological insulators  10  -  12  , quantum Hall effect  13  , and superconductivity  14  . Recently, the OM was observed in several materials including SrRuO3  15  , La0.7Sr0.3MnO3  16  , YbMgGaO4  17  , and FeSe  18  .\n \nIn this work, we consider the case where the OM appears in a frustrated antiferromagnetically coupled spin-1/2 Heisenberg model on a kagome lattice  19  20  21   22  . This type of magnetic ordering occurs naturally in some compounds like Herbertsmithite  23  , ZnCu3(OH)6Cl2  24  , and CuFeO2  25  . However, these systems have relatively weak spin-orbit couplings compared to other transition metal oxides  26  . Therefore, they do not exhibit large values of the OM  27  . On the other hand, recently discovered iron-based pnictide/chalcogenide compounds  28  -  30  possess strong spin-orbit interactions  31  , but their magnetic structures remain controversial  32  -  35  . Thus, our theoretical investigation provides valuable insight into possible experimental realiz",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Orbital magnetization and its consequences in spin - chiral ferromagnetic Kagome lattice . Abstract : We research the orbital magnetization ( OM ) induced by spin - orbit interaction on a kagome lattice with chiral magnetic order , which is realized as an emergent property of the system at low temperatures .We see that the OM can be described in terms of the Berry curvature associated with the band structure near the Fermi level . The magnitude of the OM depends strongly on the strength of the spin - orbit interaction and the direction of the applied field .In particular , we find that when the external field points along one of the three analogous < 111 > directions , there are two peaks in the temperature dependence of the OM . These conclusions propose that the OM may provide useful details about the nature of the ordered state in this material .Introduction Orbital magnetization ( OM ) , sometimes called as orbital polarization or orbital moment density , has been studied extensively for numerous years both theoretically 1 - 3 and experimentally 4 - 6 . It arises owing to the presence of spin - orbit interactions 7 8 9 , and it takes key roles in different physical phenomena such as topological insulators 10 - 12 , quantum Hall impact 13 , and superconductivity 14 .Recently , the OM was seen in multiple materials namely SrRuO3 15 , La0 . 7Sr0 . 3MnO3 16 , YbMgGaO4 17 , and FeSe 18 . In this research , we imagine the case where the OM appears in a frustrated antiferromagnetically correlated spin - 1 / 2 Heisenberg model on a kagome lattice 19 20 21 22 .This kind of magnetic ordering occurs commonly in some molecules like Herbertsmithite 23 , ZnCu3 ( OH ) 6Cl2 24 , and CuFeO2 25 . However , these systems have fairly weak spin - orbit couplings compared to other transition iron oxides 26 .Therefore , they do not show large values of the OM 27 . On the other hand , recently discovered iron - based pnictide / chalcogenide compounds 28 - 30 contain powerful spin - orbit bonding 31 , but their magnetic structures remain controversial 32 - 35 .Thus , our theory study provides valuable understanding into possible experimental realiz",
        "rewrite_text": "**Title:** Orbital Magnetization and Its Consequences in Spin-Chiral Ferromagnetic Kagome Lattice\n\n**Abstract:** In this study, we investigate the phenomenon of orbital magnetization (OM) induced by spin-orbit interactions within a kagome lattice exhibiting chiral magnetic order, a characteristic that emerges at low temperatures. Our analysis reveals that the OM can be effectively described using the Berry curvature associated with the band structure in proximity to the Fermi level. Notably, we observe that the magnitude of the OM is significantly influenced by both the strength of the spin-orbit interaction and the orientation of the applied magnetic field. Specifically, when the external field is aligned along one of the three equivalent <111> directions, we identify two distinct peaks in the temperature dependence of the OM. These findings suggest that the OM could serve as a valuable probe for understanding the nature of the ordered state in this material.\n\nThe concept of orbital magnetization, also referred to as orbital polarization or orbital moment density, has garnered considerable attention over the years, both in theoretical frameworks and experimental investigations. It arises from the interplay of spin-orbit interactions and plays a crucial role in various physical phenomena, including topological insulators, quantum Hall effects, and superconductivity. Recent observations of OM in several materials, such as SrRuO3, La0.7Sr0.3MnO3, YbMgGaO4, and FeSe, have further underscored its significance.\n\nIn our research, we focus on a scenario where OM manifests in a frustrated antiferromagnetically correlated spin-1/2 Heisenberg model on a kagome lattice. This type of magnetic ordering is commonly found in certain compounds, including Herbertsmithite, ZnCu3(OH)6Cl2, and CuFeO2. However, these materials typically exhibit relatively weak spin-orbit couplings compared to other transition metal oxides, resulting in lower OM values. Conversely, newly discovered iron-based pnictide and chalcogenide compounds possess strong spin-orbit coupling, yet their magnetic structures remain a subject of debate. Our theoretical exploration aims to enhance the understanding of these systems and provide insights that could guide future experimental investigations.",
        "ori-fast-z-score": -0.17025130615174972,
        "water-fast-z-score": 5.642417871145677,
        "rewrite-fast-z-score": -0.16222142113076254
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Recent results of the STAR high-energy polarized proton-proton program at RHIC at BNL .\nAbstract:\nThe Relativistic Heavy Ion Collider (RHIC) is an accelerator complex located in Brookhaven National Laboratory, New York. The main goal of this facility is to study nuclear matter under extreme conditions by colliding heavy ions with high energies and studying their properties after the collision. In addition, it also provides opportunities for other experiments using different beams such as protons or photons. This talk will present recent results on the measurement of spin structure functions g_1(x) and g1p(x), longitudinal double-spin asymmetries A_L, transverse single-spin asymmetry A_T, and transversity distributions h_1/T(x). These measurements are performed by the Solenoidal Tracker At RHIC experiment (STAR) which uses two large Time Projection Chambers (TPCs) filled with a gas mixture consisting of 90% helium-4 and 10% isobutane-1.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Recent results of the STAR high - energy polarized proton - proton project at RHIC at BNL . Abstract : The Relativistic Heavy Ion Collider ( RHIC ) is an accelerator complex located in Brookhaven National Laboratory , New York .The main goal of this lab is to study nuclear material under extreme circumstances by colliding heavy ions with high energies and studying their properties after the interaction . In addition , it also provides opportunities for other experiments using specific beams such as protons or photons .This discussion will present recent results on the measurement of spin structure parameters h _ 1 ( x ) and g1p ( x ) , longitudinal single - spinning asymmetries A _ L , transverse single - spinning asymmetry A _ T , and transversity distributions h _ 1 / T ( x ) . These measurements are performed by the Solenoidal Tracker At RHIC experiment ( STAR ) which uses two huge Time Projection Chambers ( TPCs ) filled with a gas mixture consisting of 90 % helium - 4 and 10 % isobutane - 1 .",
        "rewrite_text": "**Title:** Recent Findings from the STAR High-Energy Polarized Proton-Proton Project at RHIC, BNL\n\n**Abstract:** The Relativistic Heavy Ion Collider (RHIC), situated at Brookhaven National Laboratory in New York, serves as a pivotal accelerator complex dedicated to the exploration of nuclear matter under extreme conditions. By facilitating high-energy collisions of heavy ions, RHIC enables researchers to investigate the fundamental properties of nuclear interactions. In addition to heavy ion studies, RHIC also supports a variety of experiments utilizing specialized beams, including protons and photons. This article focuses on the latest findings from the Solenoidal Tracker At RHIC (STAR) experiment, which has made significant advancements in measuring key spin structure parameters such as h_1(x) and g1p(x). The research highlights the longitudinal single-spin asymmetries (A_L), transverse single-spin asymmetries (A_T), and transversity distributions (h_1/T(x)). These measurements are conducted using STAR's two large Time Projection Chambers (TPCs), which are filled with a gas mixture comprising 90% helium-4 and 10% isobutane-1. The results from these measurements contribute to a deeper understanding of the spin structure of protons and the dynamics of their interactions, offering insights into the fundamental aspects of quantum chromodynamics (QCD). The implications of these findings extend to various fields, including particle physics and nuclear physics, as they enhance our comprehension of the role of spin in the behavior of protons during high-energy collisions. This work not only underscores the capabilities of the STAR experiment but also sets the stage for future investigations into the complexities of nuclear matter and the fundamental forces at play within it.",
        "ori-fast-z-score": 1.0,
        "water-fast-z-score": 4.589285179800713,
        "rewrite-fast-z-score": 1.1441551070947107
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Optical implementation and entanglement distribution in Gaussian valence bond states .\nAbstract:\nWe propose an optical scheme for implementing the Gaussian valence bond (GVB) state, which is one of the most important classes of quantum states in condensed matter physics. The GVB state can be used to describe many-body systems with strong correlations such as spin liquids or Mott insulators. We show that our proposed scheme allows us to distribute entanglement between two distant parties by using only linear optics elements and single-photon sources. Our results may have potential applications in quantum information processing. \n \n Introduction \n \n Quantum entanglement plays a crucial role in various fields ranging from quantum communication  1  , quantum metrology  2  , quantum sensing  3  , and quantum computing  4  . In particular, it has been shown that quantum entangled states are useful resources for quantum teleportation  5  , superdense coding  6  , remote state preparation  7  , and quantum key distribution  8  .\n \nIn recent years, there has been growing interest in studying quantum entanglement in many-body systems  9  -  11  . For example, the ground-state wavefunction of strongly correlated fermions on lattices can be written as a product of local singlet pairs known as valence bonds  12  . This class of states is called valence-bond solid (VBS) states  13  . It was later found that VBS states can also be represented by so-called valence bond basis  14  . These states include the famous Néel state  15  describing antiferromagnetic order  16  , the Haldane phase  17  corresponding to integer-spin chains  18  , and the Affleck-Kennedy-Lieb-Tasaki (AKLT) model  19  representing gapped spin-1/2 chain  20  . \n \n Recently, several schemes  21 -  23  were proposed to generate these types of quantum states experimentally. However, all existing proposals require nonlinear interactions among photons  24  and/or complicated setups  25  . Therefore, they cannot be implemented easily in practice. On the other hand, some experimental demonstrations  26  -  28  have been performed recently to produce photonic qubits  29  . Thus, it would be interesting if we could find ways to implement these quantum states without requiring any nonlinear interaction  30  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Optical implementation and entanglement distribution in Gaussian valence bond states . Abstract : We suggest an optical scheme for incorporating the Gaussian valence bond ( GVB ) state , which is one of the most important classes of quantum states in condensed matter physics .The GVB state can be used to explain large - bodies systems with powerful correlations such as spin liquids or Mott insulators . We see that our proposed system enables us to distribute entanglement between two distant participants by using only linear optics components and single - photon sources .Our results may have potential applications in quantum information processing . Introduction Quantum entanglement plays a crucial role in different fields ranging from quantum communication 1 , quantum metrology 2 , quantum sensing 3 , and quantum computing 4 .In particular , it has been shown that quantum entangled states are valuable resources for quantum teleportation 5 , superdense coding 6 , remote state formation 7 , and quantum key distribution 8 . In recent seasons , there has been growing interest in investigating quantum entanglement in large - bodies systems 9 - 11 .For instance , the ground - state wavefunction of highly correlated fermions on lattices can be written as a product of local singlet pairs named as valence bonds 12 . This family of states is known valence - bond solid ( VBS ) states 13 .It was later showed that VBS states can also be described by so - called valence bond basis 14 . These states contain the famous Néel state 15 describing antiferromagnetic order 16 , the Haldane phase 17 corresponding to integer - spin rings 18 , and the Affleck - Kennedy - Lieb - Tasaki ( AKLT ) model 19 representing gapped spin - 1 / 2 chain 20 .Recently , various strategies 21 - 23 were proposed to produce these kinds of quantum states experimentally . However , all available proposals involve nonlinear interactions among photons 24 and / or complicated setups 25 .Therefore , they cannot be applied completely in practice . On the other hand , some experimental tests 26 - 28 have been performed recently to produce photonic qubits 29 .Thus , it would be exciting if we could discover ways to introduce these quantum states without using any nonlinear interaction 30 .",
        "rewrite_text": "**Title:** Optical Implementation and Entanglement Distribution in Gaussian Valence Bond States\n\n**Abstract:** In this article, we present an innovative optical framework for the realization of Gaussian valence bond (GVB) states, which are pivotal in the study of quantum states within condensed matter physics. The GVB state serves as a fundamental tool for understanding complex systems characterized by strong correlations, such as spin liquids and Mott insulators. Our proposed optical system facilitates the distribution of entanglement between two remote parties utilizing only linear optical components and single-photon sources, thereby simplifying the experimental requirements for generating such states. This advancement holds significant promise for applications in quantum information processing, where entanglement is a vital resource.\n\nThe importance of quantum entanglement spans various domains, including quantum communication, metrology, sensing, and computing. Entangled states are essential for numerous quantum protocols, such as quantum teleportation, superdense coding, remote state preparation, and quantum key distribution. Recent research has increasingly focused on exploring entanglement within large-body systems, where the ground-state wavefunction of highly correlated fermions can be expressed as a product of local singlet pairs, known as valence bonds. This concept leads to the classification of these states as valence-bond solid (VBS) states, which can also be represented through a valence bond basis.\n\nNotably, VBS states encompass significant configurations, including the Néel state, which describes antiferromagnetic order, the Haldane phase associated with integer-spin systems, and the Affleck-Kennedy-Lieb-Tasaki (AKLT) model, which pertains to gapped spin-1/2 chains. While various experimental strategies have been proposed to generate these quantum states, they typically rely on nonlinear interactions among photons or complex setups, limiting their practical applicability. Recent experimental efforts have successfully produced photonic qubits, highlighting the potential for further exploration. Our work aims to pave the way for the introduction of GVB states without the necessity for nonlinear interactions, thereby enhancing the feasibility of implementing these states in practical quantum technologies.",
        "ori-fast-z-score": 0.39904344223381105,
        "water-fast-z-score": 7.014182615527996,
        "rewrite-fast-z-score": -1.135549947915338
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The discovery of two extremely low luminosity Milky Way globular clusters .\nAbstract:\nWe report the discovery of two new faint Milky Way open clusters, which we call Palomar 1 and 2 (Palomar 1: RA = 17 h 55 m 00 s , Dec = -28°45 00  ;  Palomar 2: RA = 18 h 04 m 30 s , Dec = -29°00 30 ). They are located in the southern hemisphere at galactocentric distances between 20 kpc and 25 kpc. The total integrated V-band magnitudes for these objects are about 23 mag arcsec-2 . We have obtained deep photometry with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel to study their stellar populations. Both clusters show very similar color-magnitude diagrams dominated by old red giant branch stars. Their ages are estimated as 12 Gyrs using isochrone fitting techniques. These results suggest that both clusters may be among the oldest open clusters known in our Galaxy.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The discovery of two extremely lowest luminosity Milky Way globular galaxies . Abstract : We report the discovery of two new faint Milky Way open complexes , which we call Palomar 1 and 2 ( Palomar 1 : RA = 17 h 55 m 00 s , Dec = - 28°45 00 ; Palomar 2 : RA = 18 h 04 m 30 s , Dec = - 29°00 30 ) .They are situated in the southern hemisphere at galactocentric speeds between 20 kpc and 25 kpc . The total integrated V - band magnitudes for these objects are about 23 mag arcsec - 2 .We have achieved deep photometry with the Hubble Space Telescope Advanced Camera for Surveys Wide Field Channel to study their stellar groups . Both clusters show very identical color - magnitude diagrams dominated by ancient red giant line stars .Their ages are estimated as 12 Gyrs using isochrone fit techniques . These data suggest that both clusters might be among the earliest open complexes recorded in our Galaxy .",
        "rewrite_text": "We present the discovery of two previously unidentified faint open clusters within the Milky Way, designated as Palomar 1 and Palomar 2. Located in the southern hemisphere, Palomar 1 is positioned at right ascension 17h 55m 00s and declination -28°45'00\", while Palomar 2 is found at right ascension 18h 04m 30s and declination -29°00'30\". These clusters are situated at galactocentric distances ranging from 20 kpc to 25 kpc. Our observations reveal that the total integrated V-band magnitudes for both clusters are approximately 23 mag arcsec^-2. Utilizing the Hubble Space Telescope's Advanced Camera for Surveys Wide Field Channel, we conducted deep photometric analyses to investigate the stellar populations within these clusters. The color-magnitude diagrams obtained for both Palomar 1 and Palomar 2 exhibit striking similarities, with a predominance of ancient red giant branch stars. Through isochrone fitting techniques, we estimate the ages of these clusters to be around 12 billion years, indicating that they may represent some of the earliest open clusters formed in our Galaxy. This discovery not only enhances our understanding of the formation and evolution of stellar structures in the Milky Way but also contributes to the broader context of galactic archaeology, shedding light on the early stages of star formation in our cosmic neighborhood. The implications of these findings suggest that Palomar 1 and 2 could provide valuable insights into the history of the Milky Way and the processes that governed its early development.",
        "ori-fast-z-score": -1.4569855927715483,
        "water-fast-z-score": 3.6765801200722312,
        "rewrite-fast-z-score": 0.21320071635561041
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Dynamical Discrete Web .\nAbstract:\nThe dynamical discrete web is an extension to the concept of the discrete web, which was introduced by Markose and Sukumar in 1998 as a tool for studying the dynamics of nonlinear systems. The main idea behind this approach is that one can use the information contained within the trajectories of the system under consideration to construct a network whose nodes are given by these trajectories themselves. This network has been shown to be useful in identifying important features such as attractors or periodic orbits embedded in the phase space of the system.  In this work we present some new results on the properties of the dynamical discrete web associated with dissipative chaotic maps. We show how it is possible to obtain accurate estimates of the fractal dimension of strange attractors using only a small number of initial conditions (typically less than 100). Furthermore, we demonstrate how the dynamical discrete web can also be used to identify unstable periodic orbits embedded in the strange attractor.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Dynamical Discrete Web . Abstract : The dynamical discrete web is an addition to the idea of the discrete web , which was introduced by Markose and Sukumar in 1998 as a technique for studying the dynamics of nonlinear processes .The main idea behind this methodology is that one can using the information stored within the trajectories of the system under consideration to build a network whose nodes are given by these trajectories themselves . This system has been shown to be valuable in identifying important features such as attractors or periodic orbits embedded in the phase space of the system .In this research we present some new results on the properties of the dynamical discrete web related with dissipative chaotic maps . We see how it is easy to obtain precise estimates of the fractal dimension of odd attractors using only a small number of initial conditions ( generally less than 100 ) .Furthermore , we prove how the dynamical discrete web can also be used to identify unstable periodic orbits embedded in the odd attractor .",
        "rewrite_text": "Title: The Dynamical Discrete Web\n\nAbstract: The concept of the dynamical discrete web expands upon the discrete web framework initially proposed by Markose and Sukumar in 1998, which serves as a method for analyzing the dynamics of nonlinear systems. This innovative approach leverages the information contained within the trajectories of a given system to construct a network, where the nodes correspond to these trajectories. The dynamical discrete web has proven to be an effective tool for uncovering significant characteristics of dynamical systems, such as attractors and periodic orbits that reside within the system's phase space. In this study, we present novel findings regarding the properties of the dynamical discrete web, particularly in relation to dissipative chaotic maps. Our results demonstrate that it is feasible to derive accurate estimates of the fractal dimension of odd attractors using a minimal set of initial conditions, typically fewer than 100. Additionally, we establish that the dynamical discrete web can be employed to detect unstable periodic orbits that are situated within the odd attractor. This research not only enhances our understanding of the dynamical discrete web but also highlights its potential applications in the analysis of complex dynamical systems, paving the way for further exploration in the field of nonlinear dynamics.",
        "ori-fast-z-score": 0.11396057645963795,
        "water-fast-z-score": 5.287913134352312,
        "rewrite-fast-z-score": 1.7820842224272613
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Free Energy of Activation for the Comorosan Effect .\nAbstract:\nThe free energy of activation (ΔG*) is calculated for the comorosan effect, which describes the formation of an intermediate state in the reaction between carbon dioxide and water to form carbonate ions.  The ΔG* value obtained by this method is compared with that determined by other methods such as calorimetry or electrochemistry. It was found that these values are not consistent among themselves; however, they agree well within experimental error when the temperature dependence of the equilibrium constant is taken into account. This suggests that the discrepancy may be due to differences in the conditions under which each experiment was performed. In addition, it has been shown that the ΔG* value depends on the nature of the solvent used in the experiments. Finally, we have proposed a mechanism for the comorosan process based on our results. The free energy of activation (∆G*) is calculated using the Arrhenius equation for the comorosan reaction, which describes the formation",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Free Energy of Activation for the Comorosan Effect . Abstract : The free energy of activation ( ΔG * ) is calculated for the comorosan effect , which explains the formation of an intermediate state in the process between carbon dioxide and water to form carbonate compounds .The ΔG * value obtained by this process is compared with that determined by other methods such as calorimetry or electrochemistry . It was shown that these estimates are not consistent among themselves ; however , they accord well within experimental error when the temperature dependence of the equilibrium coefficient is taken into consideration .This implies that the discrepancy may be due to differences in the conditions under which each experiment was done . In addition , it has been shown that the ΔG * value depends on the nature of the solvent used in the experiments .Finally , we have proposed a mechanism for the comorosan process based on our results . The free energy of activation ( [UNK] * ) is calculated using the Arrhenius equation for the comorosan reaction , which describes the formation",
        "rewrite_text": "Title: Free Energy of Activation for the Comorosan Effect\n\nAbstract: This study presents a detailed calculation of the free energy of activation (ΔG*) associated with the comorosan effect, a phenomenon that elucidates the formation of an intermediate state during the reaction between carbon dioxide and water, leading to the synthesis of carbonate compounds. The ΔG* value derived from our analysis is juxtaposed with values obtained through alternative methodologies, including calorimetry and electrochemistry. Our findings reveal inconsistencies among these different estimation techniques; however, when accounting for the temperature dependence of the equilibrium constant, the results align within the bounds of experimental error. This suggests that the observed discrepancies may stem from variations in experimental conditions across different studies. Furthermore, our research indicates that the ΔG* value is influenced by the type of solvent employed in the experiments, highlighting the importance of solvent characteristics in reaction kinetics. Based on our comprehensive analysis, we propose a mechanistic framework for the comorosan process, which is grounded in the results obtained from our calculations. The activation energy is computed using the Arrhenius equation, providing a robust understanding of the reaction dynamics involved in the formation of carbonate compounds through the comorosan effect. This work not only contributes to the existing body of knowledge regarding the thermodynamics of carbonate formation but also emphasizes the need for standardized experimental conditions to achieve more consistent results in future studies.",
        "ori-fast-z-score": 1.7801724872907798,
        "water-fast-z-score": 4.798687035041354,
        "rewrite-fast-z-score": 0.29277002188455997
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Lyman Break Galaxies at z~1 and the evolution of the dust attenuation in star-forming galaxies with the redshift .\nAbstract:\nWe present new results on the evolution of the dust content in Lyman break galaxies (LBGs) using deep near-infrared data obtained by the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III program. We use these observations to study the rest-frame UV-optical properties of LBGs at redshifts 1<z<3.5. The main goal of this work was to investigate how the dust extinction evolves as a function of galaxy mass and star formation rate density over cosmic time. Our analysis shows that there are two different populations of LBGs: one population has low stellar masses (M*=10^10-10^11 Msun), high specific star formation rates (SSFR>100Gyr-1), and relatively small amounts of dust; while another population consists of more massive systems (M*>10^11Msun), lower SSFR values (SSFR<30Gyr-1), and higher levels of dust extinction. These findings suggest that the amount of dust increases with increasing galaxy mass for both local and distant galaxies.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Lyman Break Galaxies at z ~ 1 and the evolution of the dust attenuation in star - creating stars with the redshift . Abstract : We report new data on the evolution of the dust content in Lyman break galaxies ( LBGs ) using deep near - infrared results collected by the UltraVISTA census , which is part of the Sloan Digital Sky Survey III program .We use these observations to study the rest - frame UV - optical properties of LBGs at redshifts 1 < z < 3 . 5 . The main goal of this research was to examine how the dust extinction evolves as a function of galaxy mass and galaxy formation rate concentration over cosmic time .Our study shows that there are two different populations of LBGs : one population has low stellar masses ( M * = 10 ^ 10 - 10 ^ 11 Msun ) , low specific star formation rates ( SSFR > 100Gyr - 1 ) , and fairly large quantities of dust ; while another population contains of more massive structures ( M * > 10 ^ 11Msun ) , lower SSFR values ( SSFR < 30Gyr - 1 ) , and low levels of dust extinction . These conclusions show that the quantity of dust increases with increasing galaxy mass for both local and distant galaxies .",
        "rewrite_text": "We present new findings on the evolution of dust content in Lyman Break Galaxies (LBGs) utilizing deep near-infrared data obtained from the UltraVISTA survey, which is part of the Sloan Digital Sky Survey III initiative. Our research focuses on the rest-frame UV-optical characteristics of LBGs within the redshift range of 1 < z < 3.5. The primary objective of this study is to investigate how dust extinction varies with galaxy mass and the concentration of star formation rates over cosmic time. Our analysis reveals the existence of two distinct populations of LBGs. The first population comprises galaxies with lower stellar masses (M* = 10^10 - 10^11 M☉), exhibiting high specific star formation rates (SSFR > 100 Gyr^-1) and substantial amounts of dust. In contrast, the second population consists of more massive galaxies (M* > 10^11 M☉) characterized by lower SSFR values (SSFR < 30 Gyr^-1) and minimal dust extinction. These findings indicate a correlation between dust quantity and galaxy mass, suggesting that as galaxies evolve, the amount of dust tends to increase with greater mass, a trend observed in both local and distant galaxies. This research contributes to our understanding of the role of dust in galaxy evolution and highlights the complex interplay between stellar mass, star formation rates, and dust content in the context of cosmic history.",
        "ori-fast-z-score": 0.6396021490668313,
        "water-fast-z-score": 5.405989188032437,
        "rewrite-fast-z-score": 0.09578262852211514
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Energy conditions and current acceleration of the universe .\nAbstract:\nWe consider the energy conditions in cosmology, which are necessary for the existence of matter with positive pressure. We show that these conditions can be violated by quantum effects at high energies. In particular, we find that the universe is accelerating now because of such violations. The results obtained agree well with observations. \n \n Keywords: Energy condition, Quantum gravity, Acceleration of the universe \n \n 1 Introduction \n \n It has been known since the work of Einstein  1  , that the gravitational field equations admit solutions describing an accelerated expansion of space-time (see e.g.,  2  ). This fact was confirmed later on by numerous observational data  3  . However, it remains unclear what causes this phenomenon. One possible explanation could be related to some new physics beyond general relativity  4  .\n \nIn order to study the possibility of such phenomena within the framework of classical general relativity one needs to impose certain restrictions on the properties of matter fields present in the theory. These restrictions are usually called  energy conditions   5  . They were introduced originally as mathematical assumptions needed to prove various theorems about singularities  6  or black holes  7  . Later they became widely used also in other branches of theoretical physics  8  -  11  . For example, they play important role in studying inflationary models  12  -  14  . \n \n 2 Energy Conditions in Cosmology \n \n Let us start our discussion with the following set of four basic energy conditions  15  :",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Energy conditions and current speed of the universe . Abstract : We consider the energy conditions in cosmology , which are necessary for the existence of matter with positive pressure .We see that these conditions can be violated by quantum effects at high energies . In particular , we find that the universe is accelerating now because of such violations .The results collected accord well with observations . Keywords : Energy condition , Quantum gravity , Acceleration of the universe 1 Introduction It has been known since the work of Einstein 1 , that the gravitational field equations allow answers describing an accelerated expansion of space - time ( saw e . g . , 2 ) .This fact was confirmed later on by various observational data 3 . However , it remains unsure what causes this phenomenon .One potential explanation could be connected to some new theory beyond particular relativity 4 . In order to study the possibility of such theories within the framework of classical particular relativity one needs to introduce certain constraints on the properties of matter fields encountered in the physics .These restrictions are typically known energy conditions 5 . They were introduced originally as mathematical constraints needed to prove several theorems about singularities 6 or black holes 7 .Later they became widely useful also in other branches of theoretical physics 8 - 11 . For instance , they hold important role in understanding inflationary theories 12 - 14 .2 Energy Conditions in Cosmology Let us begin our debate with the following setting of four fundamental energy conditions 15 :",
        "rewrite_text": "**Title:** Energy Conditions and the Current Acceleration of the Universe\n\n**Abstract:** In this article, we explore the energy conditions within the realm of cosmology, which are essential for the existence of matter exhibiting positive pressure. Our analysis reveals that these energy conditions can be violated due to quantum effects occurring at high energy levels. Notably, we demonstrate that the current acceleration of the universe can be attributed to such violations. The findings presented in this study align closely with observational data, reinforcing the validity of our conclusions. The implications of these results are significant, as they suggest that traditional energy conditions may not hold under extreme conditions, thereby opening avenues for new theoretical frameworks. The phenomenon of accelerated expansion, first noted in Einstein's gravitational field equations, has been corroborated by a wealth of observational evidence. However, the underlying cause of this acceleration remains elusive. One potential explanation lies in the exploration of theories that extend beyond the confines of classical relativity. To investigate these theories within the classical framework, it is imperative to impose specific constraints on the properties of matter fields, commonly referred to as energy conditions. Initially introduced as mathematical constraints to establish theorems regarding singularities and black holes, these conditions have since gained prominence in various branches of theoretical physics, including their critical role in the understanding of inflationary models. This article aims to provide a comprehensive overview of the four fundamental energy conditions and their implications for cosmological models, particularly in the context of the universe's current accelerated expansion.\n\n**Keywords:** Energy condition, Quantum gravity, Acceleration of the universe.",
        "ori-fast-z-score": 0.9918365981341755,
        "water-fast-z-score": 7.303524040806201,
        "rewrite-fast-z-score": 1.153563462240948
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dualheap Selection Algorithm: Efficient, Inherently Parallel and Somewhat Mysterious .\nAbstract:\nThe DualHeap selection algorithm is an efficient method for selecting the kth smallest element in a set S of n elements.  It has been used to solve many problems including finding the minimum spanning tree (MST) in parallel computing environments such as MapReduce.   In this article we present some new results on the DualHeap algorithm that shed light on its efficiency and inherent parallelism.    We show how it can be implemented using only O(logn) bits per element while still maintaining its efficiency guarantees.   This implementation requires no extra space beyond what is needed by the input data itself and thus fits well with modern storage devices like flash memory or hard disks where storing large amounts of data is cheap but accessing individual items may be expensive.   Finally, we prove that the DualHeap algorithm solves the MST problem faster than any other known deterministic algorithm when run on a single processor machine. The DualHeap selection algorithm is one of the most widely used algorithms in computer science today.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dualheap Selection Algorithm : Efficient , Inherently Parallel and Somewhat Mysterious . Abstract : The DualHeap selection method is an efficient algorithm for choose the kth smallest element in a set S of n elements .It has been used to solve many difficulties notably discovering the minimum spanning tree ( MST ) in concurrent processing communities such as MapReduce . In this page we present some new results on the DualHeap algorithm that shed light on its reliability and inherent parallelism .We see how it can be deployed using only O ( logn ) bits per element while nevertheless maintaining its productivity guarantees . This formulation uses no additional room beyond what is required by the input data itself and therefore fits well with modern storage devices like flash memory or hard disks where storing huge amounts of data is cheap but accessing individual items might be expensive .Finally , we prove that the DualHeap algorithm solves the MST problem faster than any other known deterministic procedure when run on a single processor system . The DualHeap selection method is one of the most commonly used algorithms in computer science today .",
        "rewrite_text": "Title: DualHeap Selection Algorithm: Efficient, Inherently Parallel, and Somewhat Mysterious\n\nAbstract: The DualHeap selection algorithm is a highly efficient method for identifying the kth smallest element within a set S containing n elements. This algorithm has proven invaluable in addressing various computational challenges, particularly in the realm of concurrent processing frameworks like MapReduce, where it has been effectively utilized to determine minimum spanning trees (MST). In this article, we present novel findings regarding the DualHeap algorithm that enhance our understanding of its reliability and intrinsic parallelism. Notably, we demonstrate that the algorithm can be implemented using only O(log n) bits per element, all while preserving its performance guarantees. This efficient formulation does not require any additional memory beyond what is necessary for the input data, making it particularly suitable for contemporary storage solutions such as flash memory and hard drives, where the cost of storing large volumes of data is low, but accessing individual elements can be costly. Furthermore, we establish that the DualHeap algorithm outperforms all known deterministic methods for solving the MST problem when executed on a single-processor system. As one of the most widely adopted algorithms in computer science today, the DualHeap selection method continues to be a critical tool for researchers and practitioners alike, offering a blend of efficiency and practicality in various applications.",
        "ori-fast-z-score": -1.7820842224272613,
        "water-fast-z-score": 4.458892287340829,
        "rewrite-fast-z-score": -0.19425717247145283
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cooling and heating by adiabatic magnetization in the Ni$_{50}$Mn$_{34}$In$_{16}$ magnetic shape memory alloy .\nAbstract:\nThe effect of cooling rate on martensitic transformation temperature (Mf) was investigated for Ni$_{50}$ Mn$_{34}$ In$_{16}$ alloy using differential scanning calorimetry (DSC). The results show that Mf decreases with increasing cooling rates, which is attributed to the increase in nucleation sites at higher cooling rates. A comparison between DSC data obtained under different conditions shows that the presence of stress during cooling has no significant influence on the value of Mf. However, it does affect the microstructure of the material as revealed by transmission electron microscopy (TEM), where the formation of dislocations can be observed when samples are cooled down without applying any external pressure. It also affects the mechanical properties such as yield strength and ultimate tensile strength. \n \n © 2014 Elsevier B.V. \nKeywords: Magnetic shape memory alloys; Cooling rate; Martensitic transformation",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cooling and heating by adiabatic magnetization in the Ni $ _ { 50 } $ Mn $ _ { 34 } $ In $ _ { 16 } $ magnetic shape memory alloy . Abstract : The impact of cooling frequency on martensitic transformation temperature ( Mf ) was investigated for Ni $ _ { 50 } $ Mn $ _ { 34 } $ In $ _ { 16 } $ metal using differential scanning calorimetry ( DSC ) .The results show that Mf falls with higher cooling rates , which is attributed to the improvement in nucleation sites at higher cooling rates . A comparison between DSC data derived under various circumstances reveals that the presence of stress during cooling has no important affect on the value of Mf .However , it does affect the microstructure of the material as revealed by transmission electron microscopy ( TEM ) , where the formation of dislocations can be viewed when samples are heated down without applying any external stress . It additionally impacts the thermal properties such as yield strength and absolute tensile strength .© 2014 Elsevier B . V . Keywords : Magnetic shape memory alloys ; Cooling rate ; Martensitic transformation",
        "rewrite_text": "**Title:** Cooling and Heating through Adiabatic Magnetization in Ni$_{50}$Mn$_{34}$In$_{16}$ Magnetic Shape Memory Alloy\n\n**Abstract:** This study explores the influence of cooling frequency on the martensitic transformation temperature (Mf) in the Ni$_{50}$Mn$_{34}$In$_{16}$ magnetic shape memory alloy, utilizing differential scanning calorimetry (DSC) for analysis. The findings indicate a notable decrease in Mf with increased cooling rates, which can be attributed to an enhancement in the availability of nucleation sites that facilitate the transformation process at these higher rates. A thorough comparison of DSC data obtained under varying conditions demonstrates that while the application of stress during the cooling phase does not significantly alter the Mf value, it does have a marked effect on the material's microstructure. This is evidenced by transmission electron microscopy (TEM) observations, which reveal the emergence of dislocations when the samples are subjected to heating without any external stress. Furthermore, the presence of stress during cooling is shown to influence the thermal properties of the alloy, specifically affecting yield strength and absolute tensile strength. These insights contribute to a deeper understanding of the thermal and mechanical behavior of Ni$_{50}$Mn$_{34}$In$_{16}$, highlighting the complex interplay between cooling rates, stress conditions, and the resultant microstructural characteristics. The implications of these findings are significant for the development and optimization of magnetic shape memory alloys in various applications. © 2014 Elsevier B.V. \n\n**Keywords:** Magnetic shape memory alloys; Cooling rate; Martensitic transformation.",
        "ori-fast-z-score": -0.8427009716003844,
        "water-fast-z-score": 4.00693842672377,
        "rewrite-fast-z-score": 0.7921180343813395
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Reconstruction of the Scalar-Tensor Lagrangian from a LCDM Background and Noether Symmetry .\nAbstract:\nWe present an alternative approach to reconstructing the scalar-field Lagrangian in scalar-tensor theories, based on the assumption that the background cosmology is described by standard ΛCDM (Lambda Cold Dark Matter) model with negligible tensor perturbations. We show how this method can be used to derive constraints on the parameters of the theory using current data sets such as WMAP7+BAO+H0. The resulting parameter space for some representative models are shown to agree well with those obtained previously through other methods. \n \n In particular we consider two classes of models - quintessence-like models where the field potential has a minimum at finite value of the field, and k-essence-like models which have no minima but instead feature a kinetic term with non-canonical dependence on the field velocity. For both cases we find that the allowed range of values for the coupling constant between matter and the scalar field agrees very well with previous results derived from different approaches.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Reconstruction of the Scalar - Tensor Lagrangian from a LCDM Background and Noether Symmetry . Abstract : We present an different approach to reconstructing the scalar - field Lagrangian in scalar - vector models , using on the assumption that the background cosmology is modelled by traditional ΛCDM ( Lambda Cold Dark Matter ) model with negligible vector perturbations .We see how this method can be used to derive restrictions on the variables of the theory using current data sets such as WMAP7 + BAO + H0 . The resulting parameter space for some representative models are shown to agree well with those generated previously through other methods .In particular we define two groups of models - quintessence - like systems where the field potential has a minimum at finite value of the field , and k - essence - like systems which have no minima but instead feature a kinetic term with non - canonical dependence on the field momentum . For both cases we find that the allowed range of values for the interaction factor between matter and the scalar field agrees very best with previous findings obtained from different methods .",
        "rewrite_text": "In this article, we introduce a novel methodology for reconstructing the scalar-field Lagrangian within scalar-vector models, predicated on the assumption that the underlying cosmological framework is represented by the conventional ΛCDM (Lambda Cold Dark Matter) model, characterized by minimal vector perturbations. Our approach facilitates the derivation of constraints on the model parameters by leveraging contemporary observational datasets, including WMAP7, BAO, and H0. The analysis reveals that the parameter space for several representative models aligns closely with results obtained through alternative reconstruction techniques. We categorize the models into two distinct groups: quintessence-like systems, which exhibit a potential with a minimum at a finite field value, and k-essence-like systems, which lack such minima and instead possess a kinetic term that exhibits a non-canonical dependence on the field momentum. Notably, our findings indicate that the permissible range of the interaction factor between matter and the scalar field is in strong agreement with previous results derived from various methodologies. This work not only enhances our understanding of scalar-field dynamics in cosmological contexts but also provides a robust framework for future investigations into the interplay between scalar fields and cosmic evolution. Through this reconstruction approach, we aim to contribute to the ongoing discourse on dark energy and its implications for the expansion of the universe, thereby offering insights that may inform both theoretical and observational cosmology.",
        "ori-fast-z-score": -0.3333333333333333,
        "water-fast-z-score": 4.417261042993862,
        "rewrite-fast-z-score": 0.9901475429766744
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The formation of S0 galaxies: evidence from globular clusters .\nAbstract:\nWe present new results on the properties and evolution of early-type galaxies (ETGs) in the Coma cluster, based on deep HST/ACS imaging data obtained as part of our ongoing survey for faint globular clusters associated with ETGs.  We find that the majority of brightest cluster members are elliptical or lenticular galaxies, while only one galaxy is classified as an S0/a galaxy. The fraction of S0s increases towards fainter luminosities, reaching about 50% at M V = −18 mag. This result suggests that most S0s were formed through morphological transformation of late-type spirals during their infall into the cluster environment. In addition to this morphological transformation scenario, we also consider other possible mechanisms such as ram pressure stripping by intracluster gas and tidal interactions between galaxies. By comparing the observed number density profiles of globular clusters around different types of ETGs, we show that there exists no significant difference among these three populations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The formation of S0 galaxies : evidence from globular galaxies . Abstract : We report new data on the properties and evolution of early - class objects ( ETGs ) in the Coma cluster , using on deep HST / ACS optical data acquired as part of our ongoing search for faint globular galaxies involved with ETGs .We see that the majority of brightest cluster elements are elliptical or lenticular galaxies , while only one galaxy is categorized as an S0 / a galaxy . The percentage of S0s increases towards fainter luminosities , increasing about 50 % at M V = −18 mag .This result suggests that most S0s were created through morphological transformation of late - class spirals during their infall into the cluster environment . In addition to this morphological transformation situation , we also consider other possible processes such as ram temperature stripping by intracluster gas and tidal interactions between galaxies .By matching the reported number density characteristics of globular complexes around different kinds of ETGs , we prove that there exists no major variation among these three communities .",
        "rewrite_text": "We present new findings regarding the properties and evolutionary pathways of early-type galaxies (ETGs) within the Coma cluster, based on deep optical data obtained from the Hubble Space Telescope's Advanced Camera for Surveys (HST/ACS). Our ongoing investigation focuses on the faint globular galaxies associated with ETGs. Our analysis reveals that the predominant types of galaxies in the brightest cluster regions are elliptical and lenticular galaxies, with only a single galaxy classified as S0/a. Notably, we observe an increase in the proportion of S0 galaxies as we examine fainter luminosities, with a significant rise of approximately 50% at an absolute magnitude of M_V = -18 mag. This trend implies that a substantial number of S0 galaxies likely originated from the morphological transformation of late-type spiral galaxies as they fell into the cluster environment. \n\nIn addition to the morphological transformation hypothesis, we explore other potential mechanisms that could contribute to the formation of S0 galaxies, including ram pressure stripping caused by the intracluster gas and tidal interactions among galaxies. By analyzing the number density characteristics of globular clusters surrounding various types of ETGs, we find no significant differences among the three galaxy communities studied. This research enhances our understanding of the processes that lead to the formation of S0 galaxies and their role within the larger context of galaxy evolution in dense environments like the Coma cluster. The implications of these findings contribute to the broader discourse on galaxy morphology and the dynamic interactions that shape the characteristics of galaxies in clusters.",
        "ori-fast-z-score": -1.709408646894569,
        "water-fast-z-score": 5.4349297638940595,
        "rewrite-fast-z-score": -0.2773500981126145
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Detection of VHE gamma-ray emission from the distant blazar 1ES 1101-232 with H.E.S.S. and broadband characterisation .\nAbstract:\nWe report on observations made by the High Energy Stereoscopic System (H.E.S. S.) telescope array in Namibia, which detected very-high-energy (VHE) gamma rays from the distant blazar  1ES1102-232 at redshift z = 0.186. The source was observed for more than 50 hours between September 2005 and March 2006 using data taken simultaneously with four telescopes. A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV. No significant variability is seen during this period. We present results from spectral analysis performed over different time intervals as well as broadband modelling of the multi-wavelength spectrum including radio through X-ray measurements. This work demonstrates that H.E.S.  S. can detect sources beyond redshifts previously accessible only to ground-based Cherenkov telescopes. It also shows how such observations are important for understanding the physics of these extreme objects.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Detection of VHE gamma - ray radiation from the distant blazar 1ES 1101 - 232 with H . E . S . S . and broadband characterisation .Abstract : We report on observations made by the High Energy Stereoscopic System ( H . E . S . S . ) telescope array in Namibia , which detected very - large - energy ( VHE ) gamma radiation from the distant blazar 1ES1102 - 232 at redshift z = 0 . 186 .The source was seen for more than 50 hours between September 2005 and March 2006 using data taken concurrently with four telescopes . A total excess of 12 events above background were found within an energy range of 400 GeV to 20 TeV .No considerable variability is seen during this time . We see results from spectral study performed over different time periods as well as broadband analysis of the multi - wavelength spectrum including radio through X - ray observations .This research proves that H . E . S . S . can identify sources beyond redshifts previously accessible only to surface - based Cherenkov telescopes .It additionally shows how such observations are important for knowledge the physics of these extreme objects .",
        "rewrite_text": "We present findings from the High Energy Stereoscopic System (H.E.S.S.) telescope array located in Namibia, which successfully detected very-high-energy (VHE) gamma-ray radiation from the distant blazar 1ES 1101-232, situated at a redshift of z = 0.186. The observations were conducted over a span of more than 50 hours between September 2005 and March 2006, utilizing data collected from four telescopes operating simultaneously. During this observational period, we identified a total of 12 excess events above the background noise within the energy range of 400 GeV to 20 TeV. Notably, no significant variability in the gamma-ray emission was observed throughout the duration of the study. \n\nIn addition to the detection of VHE gamma rays, we conducted a spectral analysis over various time intervals, which provided insights into the source's emission characteristics. Furthermore, we performed a comprehensive broadband analysis that encompassed the multi-wavelength spectrum, integrating data from radio to X-ray observations. This research highlights the capability of H.E.S.S. to detect gamma-ray sources at redshifts that were previously beyond the reach of ground-based Cherenkov telescopes. The implications of these observations are significant, as they enhance our understanding of the physics governing these extreme astrophysical objects. Overall, our findings contribute valuable knowledge to the field of high-energy astrophysics and underscore the importance of continued observations of distant blazars to unravel the mysteries of the universe.",
        "ori-fast-z-score": 0.819288030372914,
        "water-fast-z-score": 5.500933918218137,
        "rewrite-fast-z-score": 0.8955334711889903
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The luminous X-ray hotspot in 4C 74.26: synchrotron or inverse-Compton emission? .\nAbstract:\nWe report on the discovery and analysis of an extended, bright radio source at z = 1.55 associated with the galaxy cluster Abell S1063 (z = 0.33). The source is detected by both the VLA and ATCA as two lobes separated by ~1 arcmin. It has a total flux density of 2.2 Jy at 5 GHz and shows no evidence for variability over more than 20 years. We find that this object is similar to other distant FR-II sources but it also exhibits some unusual properties. In particular, its luminosity is higher than expected based on the correlation between jet power and lobe luminosity observed locally. This may be due to either relativistic beaming effects and/or a high accretion rate onto the central black hole. Using deep Chandra observations we detect diffuse soft X-rays extending out to several hundred kiloparsecs around the core of the cluster which are likely produced via thermal bremsstrahlung radiation. However, there appears to be a compact region of hard X-ray emission located within 30 kpc of the center of the cluster coincident with the location of the radio source.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The luminous X - ray hotspot in 4C 74 . 26 : synchrotron or inverse - Compton emission ? .Abstract : We report on the discovery and evaluation of an extended , faint radio signal at z = 1 . 55 associated with the galaxy cluster Abell S1063 ( z = 0 . 33 ) . The source is detected by both the VLA and ATCA as two lobes divided by ~ 1 arcmin .It has a total flux concentration of 2 . 2 Jy at 5 GHz and shows no evidence for variability over more than 20 decades . We see that this particle is related to other nearby FR - II sources but it also exhibits some unusual characteristics .In particular , its luminosity is higher than expected based on the relationship between jet speed and lobe luminosity observed locally . This might be due to either relativistic beaming effects and / or a high accretion rate onto the main dark hole .Using deep Chandra measurements we perceive diffuse soft X - radiation stretching out to several hundred kiloparsecs around the core of the cluster which are likely generated via thermal bremsstrahlung rays . However , there seems to be a compact region of hard X - ray radiation located within 30 kpc of the center of the cluster coincident with the location of the radio source .",
        "rewrite_text": "Title: The Luminous X-ray Hotspot in 4C 74.26: Synchrotron or Inverse-Compton Emission?\n\nAbstract: In this study, we present the discovery and analysis of an extended, faint radio emission associated with the galaxy cluster Abell S1063 at a redshift of z = 1.55. The radio source, detected by both the Very Large Array (VLA) and the Australia Telescope Compact Array (ATCA), consists of two lobes separated by approximately 1 arcminute. The total flux density measured at 5 GHz is 2.2 Jy, and we observe no significant variability over a timescale exceeding 20 decades. This source appears to be linked to other nearby Fanaroff-Riley type II (FR-II) radio galaxies, yet it displays some atypical features. Notably, its luminosity surpasses expectations derived from the established correlation between jet speed and lobe luminosity observed in local sources. This discrepancy may be attributed to relativistic beaming effects or a potentially high accretion rate onto the central supermassive black hole. \n\nAdditionally, we utilize deep observations from the Chandra X-ray Observatory, revealing diffuse soft X-ray emission extending several hundred kiloparsecs from the cluster core, likely produced by thermal bremsstrahlung processes. Intriguingly, we identify a compact region of hard X-ray emission located within 30 kpc of the cluster center, which coincides with the position of the radio source. This finding raises questions about the mechanisms driving the observed emissions and their implications for understanding the physical processes occurring in this galaxy cluster environment. Our results contribute to the ongoing investigation of the interplay between radio and X-ray emissions in high-redshift galaxy clusters and the role of active galactic nuclei in shaping their properties.",
        "ori-fast-z-score": -0.2182178902359924,
        "water-fast-z-score": 5.391638660171921,
        "rewrite-fast-z-score": 0.3746343246326776
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Disordering Transitions and Peak Effect in Polydisperse Particle Systems .\nAbstract:\nWe study the disordering transitions in polydisperse particle systems with repulsive interactions by means of Monte Carlo simulations. We find that, for sufficiently large polydispersity index, there is no phase transition at all; instead we observe an increase of entropy as temperature decreases. For smaller values of the polydispersity index we find two different types of ordering transitions depending on whether or not particles are allowed to evaporate during cooling. In both cases we find evidence for a peak effect which can be explained within mean-field theory. The results presented here should also apply to other systems where evaporation plays a role such as colloidal suspensions. \n \n Introduction \n \n Disordered states play an important role in many physical phenomena ranging from glassy materials over granular matter to biological systems like proteins  1  . A common feature of these systems is their tendency towards ordering: At high temperatures they usually exhibit liquid-like behavior while below some critical temperature T c , they freeze into solid structures. This freezing process is accompanied by a discontinuous change of thermodynamic quantities (e.g., specific heat) signaling a first-order phase transition  2  .\n \nIn this work we consider disordered systems consisting of N interacting particles confined to a volume V . These particles may have different sizes and/or charges leading to a distribution of interaction energies between them. As a result, even if the system has only one type of particles it will behave differently than a monodisperse system  3  . If the width of the size/charge distribution becomes too large, however, the system loses its ability to form ordered phases altogether  4  . It then behaves more like a gas rather than a liquid  5  . \n \n Here we investigate how the presence of polydispersity affects the nature of the disordering transitions observed in these systems. To do so, we perform Monte Carlo simulations using a model introduced by Kob and Andersen  6  . Our main finding is that, for sufficiently large values of the polydisperisty index, there exists no phase transition at all but rather a continuous decrease of entropy upon decreasing temperature. On the other hand, for small enough polydispers",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Disordering Transitions and Peak Effect in Polydisperse Particle Systems . Abstract : We research the disordering transitions in polydisperse particle structures with repulsive interactions by means of Monte Carlo simulations .We see that , for enough large polydispersity index , there is no phase change at all ; instead we perceive an increase of entropy as temperature falls . For lower values of the polydispersity index we find two different kinds of ordering transitions depending on whether or not atoms are allowed to evaporate during heating .In both cases we find proof for a peak event which can be described within mean - field model . The results presented here should additionally apply to other processes where evaporation plays a role such as colloidal suspensions .Introduction Disordered states play an important role in many natural phenomena ranging from glassy materials over granular material to biological systems like proteins 1 . A popular characteristic of these systems is their tendency towards ordering : At high temperatures they generally exhibit water - like behavior while below some significant heat T c , they freeze into solid structures .This freezing process is preceded by a discontinuous change of thermodynamic quantities ( e . g . , basic heat ) signaling a first - order phase change 2 . In this study we study disordered systems composed of N interacting molecules confined to a volume V .These particles may have different shapes and / or charges leading to a distribution of interaction energies between them . As a result , even if the system has only one sort of particles it will react differently than a monodisperse scheme 3 .If the length of the height / charge distribution increases too huge , however , the system loses its capacity to form arranged phases entirely 4 . It then behaves more like a gas instead than a liquid 5 .Here we investigate how the presence of polydispersity affects the nature of the disordering transitions observed in these systems . To do so , we perform Monte Carlo simulations using a theory introduced by Kob and Andersen 6 .Our main discovery is that , for enough large values of the polydisperisty index , there exists no phase shift at all but rather a periodic drop of entropy upon decreasing temperature . On the other hand , for low enough polydispers",
        "rewrite_text": "**Title:** Disordering Transitions and Peak Effect in Polydisperse Particle Systems\n\n**Abstract:** This study investigates the disordering transitions in polydisperse particle systems characterized by repulsive interactions, utilizing Monte Carlo simulations as the primary analytical tool. Our findings reveal that when the polydispersity index reaches sufficiently high values, the system does not undergo any phase transition; instead, we observe an increase in entropy as the temperature decreases. Conversely, at lower polydispersity indices, we identify two distinct types of ordering transitions, which are contingent upon whether atoms are permitted to evaporate during the heating process. In both scenarios, we provide evidence for a peak phenomenon that can be effectively described using a mean-field model. The implications of our results extend beyond the specific systems studied, suggesting relevance to other processes influenced by evaporation, such as colloidal suspensions.\n\nThe significance of disordered states is well-documented across various natural phenomena, including glassy materials, granular substances, and biological systems like proteins. A common feature of these systems is their propensity for ordering; at elevated temperatures, they typically exhibit fluid-like behavior, transitioning to solid structures below a critical temperature (T_c). This transition is often marked by a discontinuous change in thermodynamic properties, indicative of a first-order phase transition. Our research focuses on disordered systems composed of N interacting particles confined within a volume V, where variations in particle shape and charge lead to a diverse range of interaction energies. This diversity results in behavior that differs markedly from that of monodisperse systems. However, when the distribution of particle characteristics becomes excessively broad, the system loses its ability to form organized phases, behaving more like a gas than a liquid. Through our Monte Carlo simulations, grounded in the theoretical framework established by Kob and Andersen, we explore how polydispersity influences the nature of disordering transitions. Our principal finding highlights that at high polydispersity indices, the absence of phase transitions is accompanied by a periodic decrease in entropy with temperature reduction, contrasting with the behavior observed at lower polydispersity levels.",
        "ori-fast-z-score": -1.397070946271399,
        "water-fast-z-score": 6.789347398332044,
        "rewrite-fast-z-score": 0.6405126152203485
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Hypervelocity stars and the environment of Sgr A* .\nAbstract:\nWe present new results on the detection rate, mass distribution, and orbital properties of hypervelocity stars (HVSs) in the Galactic halo based on spectroscopic observations with Keck II/DEIMOS over three years. We find that HVSs are detected at a rate of 0.5 +/- 0.2 per year within 100 pc of the Galactic center. The observed number density profile is consistent with an exponential fall-off with distance from the Galactic center. Our sample contains two HVSs with velocities greater than 1000 km/s; one has a heliocentric radial velocity of 1240 km/s and another has 1420 km/s. These high velocities suggest that these objects were ejected by gravitational slingshots during close encounters between massive black holes or neutron stars. In addition to the known population of HVSs near the Sun, we also detect a large number of high-velocity stars located farther away from the Galactic center which may be associated with other nearby supermassive black holes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Hypervelocity stars and the surroundings of Sgr A * . Abstract : We report new data on the observation speed , mass distribution , and orbital properties of hypervelocity stars ( HVSs ) in the Galactic halo based on spectroscopic observations with Keck II / DEIMOS over three years .We see that HVSs are detected at a rate of 0 . 5 + / - 0 . 2 per year within 100 pc of the Galactic center . The observed number density profile is compatible with an exponential fall - off with distance from the Galactic center .Our specimen contains two HVSs with velocities greater than 1000 kilometers / s ; one has a heliocentric radial speed of 1240 km / s and another has 1420 km / s . These high velocities indicate that these objects were ejected by gravitational slingshots during distant encounters between massive brown holes or neutron galaxies .In addition to the known community of HVSs near the Sun , we also observe a large number of high - speed stars situated closer back from the Galactic center which may be involved with other nearby supermassive black holes .",
        "rewrite_text": "Title: Hypervelocity Stars and Their Surroundings in the Vicinity of Sgr A*\n\nAbstract: In this study, we present new findings regarding the speed, mass distribution, and orbital characteristics of hypervelocity stars (HVSs) located in the Galactic halo, derived from three years of spectroscopic observations conducted with the Keck II / DEIMOS instrument. Our analysis reveals that HVSs are detected at an average rate of 0.5 ± 0.2 per year within a 100 parsec radius of the Galactic center. The observed number density profile of these stars is consistent with an exponential decline as the distance from the Galactic center increases. Among our sample, we identify two HVSs exhibiting remarkable velocities exceeding 1000 kilometers per second; one star has a heliocentric radial velocity of 1240 km/s, while the other reaches 1420 km/s. Such extraordinary speeds suggest that these stars were likely ejected through gravitational slingshot interactions during close encounters with massive black holes or neutron stars. Beyond the known population of HVSs in proximity to the Sun, our observations indicate a significant presence of high-velocity stars located further back from the Galactic center, which may be associated with other nearby supermassive black holes. These findings enhance our understanding of the dynamics of hypervelocity stars and their interactions within the Galactic environment, providing insights into the processes that govern their formation and ejection.",
        "ori-fast-z-score": 0.23249527748763857,
        "water-fast-z-score": 5.427092530382482,
        "rewrite-fast-z-score": 0.618852747755276
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Solar-Interior Equation of State with the Path-Integral Formalism I. Domain of Validity .\nAbstract:\nWe present an equation-of-state (EOS) model for solar matter that is based on the path integral formalism and includes quantum nuclear effects in the form of shell corrections, which are calculated using realistic nuclear interactions. The EOS covers densities ranging from 0 to 1.5 times normal density at temperatures between 10^6 K and 5×10^8 K. We compare our results against those obtained by other authors who used different methods or approximations. Our new EOS agrees well with previous calculations within their respective domains of validity but extends these into previously unexplored regions. In particular we find that the pressure increases more rapidly than predicted by standard models when approaching the center of the Sun. This leads to higher central temperatures and lower radii compared to standard models. These differences may be important for understanding the structure of stars like the Sun as well as for modeling stellar evolution. \n \n Keywords: Solar interior",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Solar - Interior Equation of State with the Path - Integral Formalism I . Domain of Validity . Abstract : We create an equation - of - state ( EOS ) model for solar material that is based on the path integral formalism and incorporates quantum nuclear effects in the form of shell corrections , which are measured using realistic nuclear interactions .The EOS includes densities extending from 0 to 1 . 5 times normal density at temperatures between 10 ^ 6 K and 5×10 ^ 8 K . We link our findings against those achieved by other researchers who used various methods or approximations . Our current EOS meets well with previous analyses within their different domains of relevance but extends these into formerly unexplored regions .In particular we find that the pressure changes more fast than expected by traditional models when approaching the center of the Sun . This leads to higher central temperatures and less radii compared to standard models .These changes may be crucial for explaining the composition of stars like the Sun as also as for modeling stellar evolution . Keywords : Solar interior",
        "rewrite_text": "**Title:** The Solar Interior Equation of State with the Path-Integral Formalism I: Domain of Validity\n\n**Abstract:** In this study, we develop a novel equation of state (EOS) model for solar material utilizing the path integral formalism, which effectively incorporates quantum nuclear effects through shell corrections derived from realistic nuclear interactions. Our EOS is designed to cover a range of densities from 0 to 1.5 times the normal density, applicable at temperatures spanning from 10^6 K to 5×10^8 K. We systematically compare our results with those obtained by other researchers employing various methodologies and approximations. Our findings demonstrate a strong alignment with previous analyses within their respective domains, while also extending the applicability of the EOS into previously uncharted territories. Notably, we observe that the pressure within the solar interior increases at a rate that exceeds predictions made by conventional models as one approaches the Sun's core. This phenomenon results in elevated central temperatures and reduced radii when contrasted with standard models. These significant alterations in the EOS may have profound implications for understanding the composition of stars similar to the Sun, as well as for advancing models of stellar evolution. The insights gained from this research not only enhance our comprehension of solar structure but also contribute to the broader field of astrophysics by providing a more accurate framework for modeling stellar interiors. \n\n**Keywords:** Solar interior, equation of state, path integral formalism, quantum nuclear effects, stellar evolution.",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 5.300713251592634,
        "rewrite-fast-z-score": 1.4110813025753959
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Poisson approximation for non-backtracking random walks .\nAbstract:\nWe consider the probability distribution of the number of times that a simple random walk on an infinite graph visits some fixed vertex in finite time, and show how this can be approximated by a Poisson distribution with mean equal to the expected value of the number of visits.  We then use these results to prove that the total variation distance between the two distributions is bounded above by $O(1/n)$ where $n$ denotes the number of vertices in the graph.   This result generalizes previous work which was restricted to graphs whose degree sequence has exponential decay or polynomial growth.    The proof relies heavily upon recent advances in the theory of large deviations for sums of dependent Bernoulli variables. In particular we make use of the so-called Cramér-Chernoff method as well as the concept of a supermartingale. Finally, we apply our main theorem to obtain new bounds on the mixing time of lazy random walks on regular trees.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Poisson approximation for non - backtracking random tours . Abstract : We consider the probability distribution of the number of twice that a simple random walk on an infinite graph visits some fixed vertex in finite time , and know how this can be approximated by a Poisson distribution with mean equivalent to the expected value of the number of visits .We then use these results to prove that the total difference distance between the two distributions is bounded above by $ O ( 1 / n ) $ where $ n $ represents the number of vertices in the graph . This result generalizes earlier paper which was confined to vertices whose degree sequence has exponential decay or polynomial growth .The proof draws highly upon recent developments in the principle of large deviations for sums of dependent Bernoulli variables . In particular we making use of the so - called Cramér - Chernoff formula as well as the idea of a supermartingale .Finally , we apply our major principle to obtain new limits on the mix time of lazy random walks on regular trees .",
        "rewrite_text": "In this article, we investigate the probability distribution concerning the frequency with which a simple random walk on an infinite graph revisits a designated vertex within a finite timeframe. Our findings indicate that this frequency can be effectively approximated by a Poisson distribution, where the mean corresponds to the expected number of visits to that vertex. We further establish that the total variation distance between the actual distribution and the Poisson approximation is constrained above by \\( O(1/n) \\), with \\( n \\) denoting the total number of vertices in the graph. This result extends previous research that was limited to scenarios involving vertices characterized by either exponential decay or polynomial growth in their degree sequences. The proof of our main theorem leverages recent advancements in the principles of large deviations, particularly concerning sums of dependent Bernoulli random variables. Notably, we employ the Cramér-Chernoff theorem and the concept of supermartingales to facilitate our analysis. Additionally, we apply our primary findings to derive new bounds on the mixing time of lazy random walks on regular trees, thereby contributing to the understanding of random processes on complex structures. This work not only enhances the theoretical framework surrounding random walks on graphs but also opens avenues for further exploration in probabilistic methods and their applications in various fields of mathematics and computer science.",
        "ori-fast-z-score": -1.1659976680069961,
        "water-fast-z-score": 3.8786538958710977,
        "rewrite-fast-z-score": 1.3598002073001698
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Scaling properties of pyrex and silicon surfaces blasted with sharp particles .\nAbstract:\nWe have studied the scaling behavior of two different types of surfaces, one made out of pyrex glass (a transparent material) and another made out of silicon dioxide (SiO2), which is an opaque material. The SiO2 surface was prepared by etching in hydrofluoric acid to remove all traces of metal contamination that could be present on its surface after being cut from a wafer. Both surfaces were then cleaned using standard cleaning procedures before they were subjected to particle bombardment at room temperature under ultra-high vacuum conditions.  We found that both surfaces exhibit similar scaling behaviors when we plot their respective roughness as a function of the number of deposited atoms per unit area for various incident angles ranging between 0°and 60°. However, there are some differences observed in the scaling exponents obtained for these two surfaces. These results suggest that the scaling behavior of these surfaces may not depend solely on the chemical composition but also depends strongly on other factors such as the microstructure of the substrate materials used.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Scaling properties of pyrex and silicon materials blasted with sharp particles . Abstract : We have researched the scaling behavior of two different kinds of structures , one made out of pyrex glass ( a transparent material ) and another created out of silicon dioxide ( SiO2 ) , which is an opaque material .The SiO2 surface was prepared by etching in hydrofluoric acid to remove all traces of metal contamination that might be found on its surface after being cut from a wafer . Both layers were then cleaned using traditional cleaning procedures before they were subjected to particle bombardment at room temperature under ultra - large vacuum environments .We showed that both surfaces show identical scaling actions when we plot their respective roughness as a function of the quantity of deposited atoms per unit area for various incident angles ranging between 0°and 60° . However , there are some variations found in the scaling exponents found for these two surfaces .These data suggest that the scaling behavior of these structures could not depend purely on the chemical composition but also relies highly on other parameters such as the microstructure of the substrate elements employed .",
        "rewrite_text": "**Title:** Scaling Properties of Pyrex and Silicon Materials Subjected to Particle Bombardment\n\n**Abstract:** This study investigates the scaling behavior of two distinct materials: pyrex glass, a transparent substance, and silicon dioxide (SiO2), an opaque material. The SiO2 samples were meticulously prepared through etching with hydrofluoric acid to eliminate any metallic contaminants that may have adhered to the surface during the cutting process from the wafer. Following this, both pyrex and SiO2 surfaces underwent standard cleaning protocols to ensure optimal conditions before exposure to particle bombardment. The experiments were conducted at room temperature within ultra-high vacuum environments, allowing for precise control over the experimental conditions. \n\nOur findings reveal that the roughness of both materials exhibits similar scaling behaviors when plotted against the number of deposited atoms per unit area, across a range of incident angles from 0° to 60°. Despite this similarity in scaling behavior, we observed notable differences in the scaling exponents for the two surfaces. These discrepancies indicate that the scaling characteristics are not solely determined by the chemical composition of the materials but are significantly influenced by additional factors, particularly the microstructural properties of the substrate materials. \n\nThis research contributes to a deeper understanding of how different materials respond to particle bombardment and highlights the importance of considering both chemical and structural attributes when analyzing scaling phenomena. The implications of these findings could extend to various applications in materials science and engineering, particularly in the fields of surface modification and nanotechnology. Further investigations are warranted to explore the underlying mechanisms that govern these scaling behaviors and to assess their potential applications in advanced material design and processing techniques.",
        "ori-fast-z-score": 0.8432740427115678,
        "water-fast-z-score": 7.023508406036853,
        "rewrite-fast-z-score": 1.6994116628998401
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Does the Blazar Gamma-Ray Spectrum Harden with Increasing Flux? Analysis of 9 Years of EGRET Data .\nAbstract:\nWe have analyzed nine years (1991â€“1998) of data on blazars observed by the Energetic Gamma Ray Experiment Telescope (EGRET). We find that there is no significant correlation between gamma-ray flux and photon index for individual sources, but we do see evidence for an anti-correlation when all sources are combined into one sample. This result suggests that the spectrum hardens as the source brightens. The lack of such a trend in single-source analysis may be due to insufficient statistics or intrinsic spectral variability within each source. Our results also suggest that the average luminosity of blazars increases faster than linearly with increasing redshift. These findings can help us understand how relativistic jets work in active galactic nuclei. Relativistic jets play important roles in many astrophysical phenomena including active galactic nuclei (AGNs), microquasars, pulsar winds, and gamma ray bursts (GRBs). In AGNs, they are believed to carry away most of the energy produced at the central engine. However, it remains unclear what physical processes drive these energetic outflows.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Does the Blazar Gamma-Ray Spectrum Harden with Increasing Flux?Analysis of 9 Years of EGRET Data .Abstract : We have analyzed nine years ( 1991â€ “ 1998 ) of statistics on blazars observed by the Energetic Gamma Ray Experiment Telescope ( EGRET ) . We see that there is no considerable relationship between beta - ray density and photon index for individual sources , but we do hear proof for an counter - correlation when all sources are combined into one sample .This result suggests that the spectrum hardens as the source brightens . The lack of such a tendency in single - source studies might be due to lacking statistics or intrinsic spectral variability within each source .Our results also suggest that the average luminosity of blazars increases faster than linearly with increasing redshift . These studies can help us explain how relativistic jets act in active galactic nuclei .Relativistic jets serve active roles in many astrophysical processes including active galactic nuclei ( AGNs ) , microquasars , pulsar winds , and gamma ray bursts ( GRBs ) . In AGNs , they are said to carry away most of the power emitted at the main engine .However , it remains unsure what physical processes drive these energetic outflows .",
        "rewrite_text": "Title: Does the Blazar Gamma-Ray Spectrum Harden with Increasing Flux? Analysis of 9 Years of EGRET Data\n\nAbstract: In this study, we present an extensive analysis of nine years of data (1991–1998) collected from blazars observed by the Energetic Gamma Ray Experiment Telescope (EGRET). Our investigation reveals that there is no significant correlation between the beta-ray density and the photon index for individual blazar sources. However, when we aggregate the data from all sources into a single sample, we observe evidence of a counter-correlation, indicating that the gamma-ray spectrum tends to harden as the brightness of the source increases. The absence of a similar trend in studies focused on individual sources may be attributed to insufficient statistical data or the intrinsic spectral variability inherent to each source. Additionally, our findings suggest that the average luminosity of blazars increases at a rate that exceeds linearity with respect to redshift. These insights contribute to our understanding of the mechanisms behind relativistic jets in active galactic nuclei (AGNs). Relativistic jets play a crucial role in various astrophysical phenomena, including AGNs, microquasars, pulsar winds, and gamma-ray bursts (GRBs). In the context of AGNs, these jets are believed to transport a significant portion of the energy produced by the central engine. Nevertheless, the precise physical processes that drive these high-energy outflows remain uncertain. Our research aims to shed light on these complex dynamics and enhance our comprehension of the behavior of blazars and their associated jets in the broader framework of astrophysical research.",
        "ori-fast-z-score": -0.21566554640687682,
        "water-fast-z-score": 4.477215043467819,
        "rewrite-fast-z-score": 1.044073795327749
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Revisiting the Issues On Netflow Sample and Export Performance .\nAbstract:\nIn this work, we revisit some issues on netflow sample and export performance in terms of packet loss rate (PLR) and flow sampling accuracy (FSA). We first present an analytical model to study PLR under different traffic conditions with various sampling rates. Then, based on our analysis results, we propose a new method for estimating FSA by using only one parameter -the average number of flows per second. Finally, through extensive experiments conducted over both real-world traces and synthetic data sets, we show that our proposed estimation method is accurate enough to be used as a practical tool for evaluating network monitoring systems. The rest of this paper is organized as follows. In Section 2, we introduce related works about netflow sampling and exporting. In Section 3, we describe our experimental environment. In Section 4, we analyze the relationship between PLR and sampling rate. In Section 5, we estimate FSA according to the analysis result presented in Section 4. In Section 6, we evaluate the effectiveness of our proposed estimation method via extensive experiments. Finally, conclusions are drawn in Section 7.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Revisiting the Issues On Netflow Sample and Export Performance . Abstract : In this project , we revisit some issues on netflow sample and export quality in terms of packet loss rate ( PLR ) and flow sampling accuracy ( FSA ) .We first offer an analytical method to study PLR under various traffic conditions with various sampling rates . Then , using on our analysis results , we propose a new method for estimating FSA by using only one parameter - the average number of flows per second .Finally , through numerous experiments conducted over both real - time traces and synthetic information sets , we prove that our proposed estimation method is accurate sufficient to be used as a practical tool for evaluating network monitoring systems . The rest of this paper is organized as follows .In Section 2 , we provide similar articles about netflow filtering and exporting . In Section 3 , we explain our research surroundings .In Section 4 , we assess the relationship between PLR and sampling rate . In Section 5 , we estimate FSA according to the evaluation result provided in Section 4 .In Section 6 , we assess the performance of our proposed estimation method via extensive experiments . Finally , findings are drawn in Section 7 .",
        "rewrite_text": "Title: Revisiting the Issues on Netflow Sample and Export Performance\n\nAbstract: This study addresses critical concerns regarding the quality of netflow sampling and export, specifically focusing on packet loss rate (PLR) and flow sampling accuracy (FSA). We begin by introducing an analytical framework to investigate PLR across different traffic scenarios and sampling rates. Building on our analytical findings, we propose a novel approach for estimating FSA that relies solely on a single parameter: the average number of flows per second. Our extensive experimental validation, conducted on both real-time traffic data and synthetic datasets, demonstrates that the proposed estimation method achieves a level of accuracy sufficient for practical application in evaluating network monitoring systems. The structure of the paper is organized as follows: Section 2 reviews related literature on netflow filtering and exporting techniques. In Section 3, we outline the research environment and methodology employed in our study. Section 4 delves into the correlation between PLR and sampling rate, providing a comprehensive analysis of their interdependence. Following this, Section 5 presents our estimation of FSA based on the insights gained in the previous section. In Section 6, we rigorously evaluate the performance of our proposed estimation method through a series of detailed experiments. Finally, Section 7 summarizes our findings and discusses their implications for future research and practical applications in network monitoring. This work contributes to a deeper understanding of netflow sampling dynamics and offers a reliable tool for enhancing the performance of network monitoring systems.",
        "ori-fast-z-score": 1.3199500146737049,
        "water-fast-z-score": 6.262945776223707,
        "rewrite-fast-z-score": 1.0864289525102224
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Synchrotron Radio Emission from a Fast Halo Coronal Mass Ejection .\nAbstract:\nWe report on the detection and analysis of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 (SOL2010-07-20T17:48) at 17:48 UT on July 20, 2010 using the Nançay Decameter Array (NDA). The event was accompanied by a fast halo coronal mass ejection (CME), which reached Earth at 18:20 UT on July 21. We find that the radio source is located near the center of the CME front as seen in white light images taken by STEREO-Ahead/EUVI 195 Å . The radio flux density shows rapid evolution during the first hour after the onset of the flare, followed by gradual decay over several hours. The radio spectrum has a power-law shape between 1 MHz to 5 GHz. The spectral index decreases rapidly below 100 MHz but remains nearly constant above this frequency.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Synchrotron Radio Emission from a Fast Halo Coronal Mass Ejection . Abstract : We report on the detection and assessment of radio emission associated with an impulsive solar flare that occurred in active region NOAA 10486 ( SOL2010 - 07 - 20T17 : 48 ) at 17 : 48 UT on July 20 , 2010 using the Nançay Decameter Array ( NDA ) .The event was accompanied by a rapid halo coronal mass ejection ( CME ) , which reached Earth at 18 : 20 UT on July 21 . We see that the radio source is situated near the center of the CME front as shown in white light pictures taken by STEREO - Ahead / EUVI 195 Å .The radio flux concentration displays rapid change during the first hour after the outbreak of the flare , followed by slowly evolution over numerous hours . The radio spectrum has a power - law shape between 1 MHz to 5 GHz .The spectral index drops rapidly below 100 MHz but continues nearly constant above this signal .",
        "rewrite_text": "We present our findings on the detection and analysis of radio emissions linked to a sudden solar flare that took place in active region NOAA 10486 (SOL2010-07-20T17:48) at 17:48 UT on July 20, 2010. This event was notably accompanied by a swift halo coronal mass ejection (CME), which reached Earth at 18:20 UT on July 21. Utilizing the Nançay Decameter Array (NDA), we observed that the radio source was located near the center of the CME front, as evidenced by white light images captured by the STEREO-Ahead/EUVI 195 Å instrument. Our analysis reveals that the radio flux exhibited significant fluctuations during the initial hour following the flare's onset, after which it transitioned to a more gradual evolution over several hours. The radio spectrum we recorded displayed a power-law distribution across frequencies ranging from 1 MHz to 5 GHz. Notably, the spectral index experienced a rapid decline below 100 MHz, while maintaining a relatively stable value at higher frequencies. These observations provide critical insights into the dynamics of radio emissions associated with solar flares and CMEs, enhancing our understanding of solar activity and its implications for space weather phenomena. The correlation between the radio emissions and the characteristics of the CME highlights the importance of continuous monitoring and analysis of solar events to better predict their impact on Earth and the surrounding space environment.",
        "ori-fast-z-score": -1.5,
        "water-fast-z-score": 3.3489378339086286,
        "rewrite-fast-z-score": -1.7650452162436565
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Concise theory of chiral lipid membranes .\nAbstract:\nThe authors present an overview of the current state-of-the-art in understanding how lipids form membranes and what determines their physical properties.  They then introduce a new theoretical framework for describing these phenomena, which they call the concise theory of chiral lipid membranes (CTCLM).  The CTCLM is based on three key concepts:  1) Lipid bilayers are composed of two interdigitated monolayers; 2) Each monolayer contains both enantiomeric forms of each lipid species; 3) Enantiomers have different molecular shapes that lead to differences in packing density within the membrane.  This model explains many experimental observations about the structure and dynamics of biological membranes without introducing any additional parameters or assumptions beyond those already used by existing models. It also provides a simple explanation for why certain types of lipids tend to be found at specific locations within cell membranes. Finally, it suggests several testable predictions that can help guide future experiments aimed at further refining our understanding of this important class of biomolecules.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Concise theory of chiral lipid membranes . Abstract : The authors present an overview of the present state - of - the - art in understanding how lipids form membranes and what determines their structural functions .They then introduce a new theoretical framework for describing these phenomena , which they term the concise theory of chiral lipid membranes ( CTCLM ) . The CTCLM is based on three key concepts : 1 ) Lipid bilayers are composed of two interdigitated monolayers ; 2 ) Each monolayer includes both enantiomeric types of each lipid species ; 3 ) Enantiomers have different molecular patterns that lead to differences in packing density within the membrane .This theory presents many experimental studies about the composition and dynamics of biological membranes without removing any additional parameters or assumptions beyond those already used by existing models . It additionally offers a simple explanation for why certain types of lipids tend to be found at different places within cell membranes .Finally , it makes several testable predictions that can help guide upcoming experiments intended at further refining our grasp of this vital class of biomolecules .",
        "rewrite_text": "The authors provide a comprehensive overview of the current understanding of lipid membrane formation and the factors influencing their structural functions in the scientific article titled \"Concise Theory of Chiral Lipid Membranes.\" They introduce an innovative theoretical framework known as the Concise Theory of Chiral Lipid Membranes (CTCLM), which is built upon three fundamental principles. First, lipid bilayers are conceptualized as consisting of two interdigitated monolayers. Second, each of these monolayers contains both enantiomeric forms of each lipid species. Third, the distinct molecular arrangements of enantiomers result in variations in packing density within the membrane. \n\nThe CTCLM effectively synthesizes a wealth of experimental findings related to the composition and dynamics of biological membranes, all while maintaining the existing parameters and assumptions of current models. This approach not only clarifies the underlying mechanisms of lipid behavior but also provides insights into the spatial distribution of different lipid types within cell membranes. Furthermore, the theory proposes several testable hypotheses that can inform future experimental investigations aimed at enhancing our understanding of these essential biomolecules. Overall, the CTCLM represents a significant advancement in the theoretical analysis of chiral lipid membranes, offering a robust framework for exploring the complexities of membrane biology.",
        "ori-fast-z-score": 2.0124611797498106,
        "water-fast-z-score": 6.846754616640485,
        "rewrite-fast-z-score": -0.44172610429938614
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Radio Polarimetry of the ELAIS N1 Field: Polarized Compact Sources .\nAbstract:\nWe present results on polarized radio emission in the field surrounding the galaxy cluster Abell 2218, observed with the Australia Telescope Compact Array (ATCA) at 1.4 GHz and 4.8 GHz. We detect 16 compact sources above 5 mJy beam-1 at both frequencies; all but one are unresolved or marginally resolved by our observations. The majority have fractional linear polarization between 10% and 20%, while two objects show higher values up to 40%. All detected sources appear to be associated with galaxies within the central region of Abell 2218. In addition we find evidence for diffuse polarized emission around the brightest member of this galaxy cluster. This is likely due to synchrotron radiation produced by relativistic electrons accelerated in shocks driven into the intracluster medium during multiple mergers that occurred over time scales ranging from 10 Myr to several Gyrs ago. Our data also reveal an extended halo-like structure which surrounds the entire galaxy cluster.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Radio Polarimetry of the ELAIS N1 Field : Polarized Compact Sources . Abstract : We report findings on polarized television emission in the field surrounding the galaxy cluster Abell 2218 , detected with the Australia Telescope Compact Array ( ATCA ) at 1 . 4 GHz and 4 . 8 GHz .We detect 16 compact sources above 5 mJy beam - 1 at both frequencies ; all but one are unresolved or marginally resolved by our observations . The majority have fractional linear polarization between 10 % and 20 % , while two bodies display larger values up to 40 % .All detected sources appear to be identified with galaxies within the central region of Abell 2218 . In addition we find proof for diffuse polarized emission around the brightest part of this galaxy cluster .This is probably due to synchrotron emission created by relativistic electrons accelerated in shocks driven into the intracluster medium during various mergers that occurred over time scales ranging from 10 Myr to several Gyrs ago . Our data also confirm an extended halo - like structure which covers the entire galaxy cluster .",
        "rewrite_text": "In this study, we present our findings on polarized radio emissions in the vicinity of the galaxy cluster Abell 2218, utilizing observations from the Australia Telescope Compact Array (ATCA) at frequencies of 1.4 GHz and 4.8 GHz. Our analysis reveals a total of 16 compact sources exhibiting flux densities greater than 5 mJy beam^-1 at both observed frequencies. Notably, nearly all of these sources are either unresolved or only marginally resolved in our data. The majority of the detected sources exhibit fractional linear polarization values ranging from 10% to 20%, with two sources displaying significantly higher polarization levels, reaching up to 40%. Each of these sources has been associated with galaxies located in the central region of the Abell 2218 cluster.\n\nFurthermore, our observations provide evidence of diffuse polarized emission surrounding the brightest region of the galaxy cluster. This diffuse emission is likely attributed to synchrotron radiation generated by relativistic electrons that have been accelerated in shocks interacting with the intracluster medium, a process that has likely occurred during various merger events over timescales spanning from approximately 10 million years to several billion years. Additionally, our data confirm the presence of an extended halo-like structure enveloping the entire galaxy cluster, suggesting a complex interplay of magnetic fields and relativistic particles in this environment. These findings contribute to our understanding of the polarization properties of compact sources and the mechanisms behind diffuse emission in galaxy clusters, highlighting the significance of synchrotron processes in the context of cosmic structure formation and evolution.",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 3.6380343755449944,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  GRB 050410 and GRB 050412: are they really dark GRBs? .\nAbstract:\nWe present the results of our analysis on two gamma-ray bursts (GRBs) detected by Swift satellite, GRB 050410 and its afterglow at optical wavelengths, and GRB 050412; we find that both events have very low luminosities in their prompt emission phase as well as in their X-ray afterglows; this is consistent with them being  dark  GRBs.  We also report the detection of an unusual radio flare associated to GRB 050410 which may be related to the central engine activity or to late-time energy injection into the relativistic jet. The first event was discovered by Swift/BAT on April 10th 2006 at 07:41:06 UT  1  . It triggered BAT again at 08:47:12 UT  2  , but no further triggers were recorded until 09:55:43 UT  3  when it re-triggered BAT for one more time  4  .\nThe second event was discovered by Swift /BAT on April 12th 2006 at 06:52:53 UT  5  . No other triggers were recorded until 07:30:00 UT  6  when it re-triggered; however, there was another trigger at 07:45:20 UT  7  . Both events had durations longer than 2 s  8  ; therefore, they could not be classified as short-duration GRBs  9  .  They did not show any evidence of extended emission  10  nor multiple peaks  11  during their prompt phases  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : GRB 050410 and GRB 050412 : are they actually dark GRBs ? .Abstract : We report the results of our analysis on two gamma - ray bursts ( GRBs ) detected by Swift satellite , GRB 050410 and its afterglow at optical wavelengths , and GRB 050412 ; we find that both events have very low luminosities in their prompt emission stage as also as in their X - ray afterglows ; this is consistent with them being black GRBs . We additionally report the observation of an strange television flare associated to GRB 050410 which may be connected to the main engine action or to late - time energy injection into the relativistic jet .The first phenomenon was discovered by Swift / BAT on April 10th 2006 at 07 : 41 : 06 UT 1 . It triggered BAT again at 08 : 47 : 12 UT 2 , but no further triggers were registered until 09 : 55 : 43 UT 3 when it re - triggered BAT for one more time 4 .The second phenomenon was discovered by Swift / BAT on April 12th 2006 at 06 : 52 : 53 UT 5 . No other triggers were documented until 07 : 30 : 00 UT 6 when it re - triggered ; however , there was another trigger at 07 : 45 : 20 UT 7 .Both episodes had durations greater than 2 s 8 ; therefore , they cannot not be categorized as short - duration GRBs 9 . They did not show any evidence of extended emission 10 nor multiple levels 11 during their prompt stages 12 .",
        "rewrite_text": "We present our findings on two gamma-ray bursts (GRBs) observed by the Swift satellite: GRB 050410 and GRB 050412. Our analysis reveals that both GRBs exhibit remarkably low luminosities during their prompt emission phases, as well as in their subsequent X-ray afterglows. This observation supports the hypothesis that these events may be classified as \"dark GRBs,\" which are characterized by their diminished brightness and difficulty in detection across various wavelengths. \n\nIn addition to the luminosity analysis, we report an intriguing phenomenon associated with GRB 050410—a peculiar television flare that could be linked to the activity of the central engine or to late-time energy injection into the relativistic jet. The first detection of GRB 050410 occurred on April 10, 2006, at 07:41:06 UT, triggering the Swift/BAT instrument. A subsequent trigger was recorded at 08:47:12 UT, followed by another at 09:55:43 UT, indicating a complex temporal structure. \n\nSimilarly, GRB 050412 was detected on April 12, 2006, at 06:52:53 UT, with additional triggers noted at 07:30:00 UT and 07:45:20 UT. Both GRBs exhibited durations exceeding 2 seconds, thereby excluding them from the category of short-duration GRBs. Notably, neither event displayed signs of extended emission or multiple emission levels during their prompt phases, further reinforcing their classification as dark GRBs. \n\nOur findings contribute to the ongoing discourse regarding the nature of GRBs and the mechanisms underlying their emissions, particularly in cases where traditional observational methods yield limited results. The implications of these results are significant for understanding the diversity of GRB phenomena and the conditions that lead to their varied luminosities.",
        "ori-fast-z-score": -1.2874526191574363,
        "water-fast-z-score": 4.184914994777494,
        "rewrite-fast-z-score": 0.8620436566990363
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gamma-ray probe of cosmic-ray pressure in galaxy clusters and cosmological implications .\nAbstract:\nWe present the first measurement of the gamma-ray emission associated with the hot gas in galaxy clusters using data collected by Fermi Large Area Telescope (LAT). We find that the observed gamma-ray luminosity is consistent with theoretical predictions based on the assumption that the energy density of relativistic particles follows closely that of thermal plasma, as expected for hadronic models where cosmic rays are accelerated at shocks driven into intracluster medium by mergers or AGN activity. The inferred cosmic ray pressure is found to be comparable to the thermal pressure within r500 but decreases more rapidly outside this radius. This result suggests that cosmic rays may play an important role in regulating cluster dynamics over large scales. In addition, we use our results together with those obtained previously by Suzaku X-ray observatory to constrain the fraction of nonthermal pressure support in galaxy clusters. Our analysis indicates that the contribution of cosmic rays to total pressure can reach up to 30%-40% inside r500 while it drops below 10% beyond 2r500. Finally, we discuss how these findings could affect constraints on dark matter annihilation cross section derived from observations of galaxy clusters.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Gamma - ray investigation of cosmic - ray pressure in galaxy clusters and cosmological impacts . Abstract : We report the first measurement of the alpha - ray radiation attributed with the hot gas in galaxy clusters using data received by Fermi Large Area Telescope ( LAT ) .We see that the reported gamma - ray luminosity is compatible with theoretical estimates based on the assumption that the power concentration of relativistic objects parallels closely that of thermal plasma , as anticipated for hadronic models where cosmic rays are accelerated at shocks driven into intracluster medium by mergers or AGN activity . The inferred cosmic ray tension is found to be comparable to the thermal tension within r500 but decreases more slowly outside this radius .This result suggests that cosmic rays may play an important role in controlling cluster structure over large scales . In addition , we using our findings together with those published previously by Suzaku X - ray observatory to constrain the fraction of nonthermal force support in galaxy galaxies .Our study implies that the impact of cosmic rays to total pressure can reach up to 30 % - 40 % inside r500 while it sinks below 10 % beyond 2r500 . Finally , we investigate how these results could affect constraints on dark matter annihilation cross section obtained from measurements of galaxy galaxies .",
        "rewrite_text": "We present the inaugural measurement of gamma-ray emissions associated with the hot gas in galaxy clusters, utilizing data from the Fermi Large Area Telescope (LAT). Our findings indicate that the observed gamma-ray luminosity aligns well with theoretical predictions, which suggest that the distribution of relativistic particles closely mirrors that of the thermal plasma. This correlation is particularly relevant in the context of hadronic models, where cosmic rays are believed to be accelerated at shock fronts generated by mergers or active galactic nucleus (AGN) activity within the intracluster medium. Notably, the derived cosmic ray pressure is found to be comparable to the thermal pressure within the radius r500, although it exhibits a slower decline beyond this threshold. This observation implies that cosmic rays may significantly influence the structural dynamics of galaxy clusters on larger scales.\n\nFurthermore, we integrate our results with previous findings from the Suzaku X-ray observatory to estimate the contribution of nonthermal pressure support in galaxy clusters. Our analysis suggests that cosmic rays can account for approximately 30% to 40% of the total pressure within r500, while their contribution diminishes to below 10% at distances greater than 2r500. Lastly, we explore the implications of these results for constraints on the dark matter annihilation cross-section, derived from observations of galaxy clusters. This research not only enhances our understanding of cosmic ray dynamics in galaxy clusters but also provides critical insights into the broader implications for cosmology and dark matter studies.",
        "ori-fast-z-score": 0.1889822365046136,
        "water-fast-z-score": 6.425396041156863,
        "rewrite-fast-z-score": 1.0864289525102224
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multiple Parton Scattering in Nuclei: Quark-quark Scattering .\nAbstract:\nWe present the first calculation of quark-quark scattering at next-to-leading order (NLO) accuracy within the framework of multiple parton scattering (MPI). We show that this process is dominated by gluons and quarks with small transverse momenta, which are produced via initial state radiation off one or both incoming hadrons. The cross section for quark-quark scattering can be written as an integral over the transverse momentum distribution of these radiated particles times their squared matrix element. This allows us to calculate the total cross section using standard Monte Carlo techniques. In addition we provide analytic expressions for the differential distributions in rapidity and azimuthal angle between the outgoing quarks. Our results agree well with those obtained numerically. Finally, we discuss how our formalism could be used to study MPI effects on jet production in proton-nucleus collisions. PACS numbers: 12.38.Qk, 13 .60.Le",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multiple Parton Scattering in Nuclei : Quark - quark Scattering . Abstract : We present the first measurement of quark - quark scattering at next - to - leading order ( NLO ) accuracy within the framework of multiple parton absorption ( MPI ) .We see that this process is dominated by gluons and quarks with little transverse momenta , which are produced via initial state radiation off one or both incoming hadrons . The cross section for quark - quark scattering can be written as an integral over the transverse momentum density of these emitted particles times their squared matrix element .This enables us to estimate the total cross area using conventional Monte Carlo methods . In addition we provide analytic expressions for the differential distributions in rapidity and azimuthal angle between the outgoing quarks .Our results agree well with those achieved numerically . Finally , we talk how our formalism may be used to study MPI influence on jet production in proton - nucleus collisions .PACS codes : 12 . 38 . Qk , 13 . 60 . Le",
        "rewrite_text": "We present the inaugural measurement of quark-quark scattering at next-to-leading order (NLO) accuracy within the context of multiple parton interactions (MPI). Our findings indicate that this scattering process is predominantly influenced by gluons and quarks that possess minimal transverse momenta, which arise from initial state radiation emitted by one or both of the incoming hadrons. The cross section for quark-quark scattering can be expressed as an integral that incorporates the transverse momentum density of the emitted particles, multiplied by their squared matrix element. This formulation allows us to estimate the total cross-sectional area using standard Monte Carlo simulation techniques. Furthermore, we offer analytical expressions for the differential distributions concerning rapidity and the azimuthal angle between the outgoing quarks, which demonstrate strong agreement with our numerical results. Additionally, we discuss the implications of our formalism for investigating the impact of multiple parton interactions on jet production in proton-nucleus collisions. Our work contributes to a deeper understanding of the dynamics involved in high-energy particle interactions and opens avenues for further research in the field of quantum chromodynamics (QCD). The findings are relevant to ongoing studies in particle physics, particularly in the context of collider experiments where multiple parton scattering plays a significant role. The PACS codes associated with this research are 12.38.Qk and 13.60.Le, reflecting its relevance to QCD and particle scattering processes.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.242640687119286,
        "rewrite-fast-z-score": 1.436739427831727
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Unstable and Stable Galaxy Models .\nAbstract:\nWe present the results for two different models of galaxy formation, one stable model with no dark matter halos merging or growing in mass (the standard CDM scenario), and an unstable model where dark matter halos merge continuously to form larger structures.  We use these models to study how galaxies evolve over time as they are affected by mergers between their host dark matter halos.   The merger rate is higher at earlier times when there were more small halos available to merge into large ones.  In our unstable model we find that most massive galaxies have experienced several major mergers since z = 1 while less massive galaxies have had fewer mergers.    Our results show that the number density of brightest cluster galaxies has increased dramatically since z=1 due to mergers between clusters of galaxies.  This increase can be explained if brightest cluster galaxies grow through mergers rather than simply forming out of gas cooling within the hot intracluster medium.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Unstable and Stable Galaxy Models . Abstract : We present the results for two different models of galaxy formation , one stable model with no bright matter halos merging or developing in mass ( the standard CDM scenario ) , and an unstable scenario where bright matter halos merge consistently to form bigger structures .We use these models to study how clusters evolve over time as they are influenced by mergers between their host dark matter halos . The merger speed is higher at earlier times when there were more little halos accessible to unite into huge ones .In our unstable model we find that most large galaxies have experienced several main mergers since z = 1 while less massive galaxies have had fewer mergers . Our results show that the number density of brightest cluster clusters has increased significantly since z = 1 due to mergers between clusters of clusters .This increase can be understood if brightest cluster stars grow through mergers rather than merely emerging out of gas cooling within the hotter intracluster medium .",
        "rewrite_text": "In this study, we investigate two distinct models of galaxy formation: a stable model characterized by the absence of merging bright matter halos and a dynamic, unstable model where such halos consistently merge to create larger structures. The stable model aligns with the conventional Cold Dark Matter (CDM) scenario, while the unstable model allows for a more complex evolution of galaxy clusters. Our research focuses on the temporal evolution of these clusters, particularly how they are shaped by the mergers of their host dark matter halos. We observe that the rate of mergers is significantly higher in the earlier epochs of the universe, a period when numerous smaller halos were available to coalesce into larger entities. \n\nIn the context of our unstable model, we find that the majority of large galaxies have undergone multiple significant mergers since a redshift of z = 1, in contrast to their less massive counterparts, which have experienced fewer merger events. This disparity highlights the different evolutionary paths taken by galaxies of varying masses. Furthermore, our findings indicate a substantial increase in the number density of brightest cluster galaxies since z = 1, a phenomenon attributed to the merging of clusters. This growth can be better understood through the lens of mergers, suggesting that the brightest cluster stars are primarily formed through these merger events rather than simply arising from gas cooling processes within the hotter intracluster medium. Overall, our results provide valuable insights into the mechanisms driving galaxy formation and evolution, emphasizing the critical role of mergers in shaping the large-scale structure of the universe.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.9819900360298925,
        "rewrite-fast-z-score": 0.6163156344279367
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Observations of Microwave Continuum Emission from Air Shower Plasmas .\nAbstract:\nWe report on the detection and characterization of microwave continuum emission from air shower plasmas using data collected by the LOPES experiment in Germany during 2004-2006. The observed signal is consistent with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers, as predicted by theory. We find no evidence for any significant contribution from incoherent synchrotron or bremsstrahlung processes. These results provide new insights into the physics of cosmic ray interactions at high energy. They also demonstrate the potential utility of radio techniques for studying atmospheric phenomena such as thunderstorms. \n \n Keywords: Cosmic rays, Radio waves, Air showers, Coherence, Synchrotron radiation \n \n \n \n 1 Introduction \n \n In recent years there has been growing interest in developing novel methods for detecting ultra-high-energy (UHE) cosmic rays based upon their interaction with Earth s atmosphere  1  . One promising technique involves measuring the radio-frequency (RF) emission produced when UHE particles interact with molecules in the upper atmosphere  2  , which can be detected remotely over large areas  3  .\n \nThe most prominent feature of this RF emission is an intense broadband pulse lasting several microseconds  4  . This pulse arises because the charged particle cascade generated by each primary cosmic ray interacts strongly with the geomagnetic field, causing it to emit coherently across a wide range of frequencies  5  . However, other mechanisms may contribute significantly to the total RF emission  6  . \n \n Here we present observations made with the Low-Frequency Array (LOFAR), one component of the International LOFAR Telescope  7  . Our analysis focuses primarily on measurements taken between 2004 and 2006 with the Long Wavelength Array (LWA)  8  , a phased array consisting of 144 dual-polarized dipole antennas operating at wavelengths ranging from 10 m to 80 m  9  . During these three years, LWA was deployed near Karthaus Township, Germany  10  , where it recorded signals from more than 20 million cosmic-ray-induced air showers  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Observations of Microwave Continuum Emission from Air Shower Plasmas . Abstract : We report on the detection and identification of microwave continuum emission from air washing plasmas using data taken by the LOPES experiment in Germany during 2004 - 2006 .The observed light is compatible with that expected for coherent Cherenkov radiation emitted by relativistic electrons accelerated to energies up to 100 MeV within the showers , as predicted by theoretical . We see no evidence for any large contribution from incoherent synchrotron or bremsstrahlung interactions .These data provide novel knowledge into the physics of cosmic ray molecules at high energy . They especially demonstrate the possibilities utility of radio methods for studying atmospheric phenomena such as thunderstorms .Keywords : Cosmic rays , Radio beams , Air showers , Coherence , Synchrotron emission 1 Introduction In past decades there has been growing interest in pursuing new ways for detecting ultra - large - energy ( UHE ) cosmic rays based upon their interaction with Earth s atmosphere 1 . One promising technique means measuring the radio - frequency ( RF ) emission generated when UHE molecules interact with compounds in the inner environment 2 , which can be identified remotely over large areas 3 .The most notable feature of this RF radiation is an intense broadband signal spanning multiple microseconds 4 . This wave exists because the charged particle cascade generated by each main cosmic ray interacts highly with the geomagnetic field , creating it to emit coherently across a broad variety of frequencies 5 .However , other mechanisms may contribute considerably to the total RF pollution 6 . Here we present observations made with the Low - Frequency Array ( LOFAR ) , one element of the International LOFAR Telescope 7 .Our study consists primarily on observations made between 2004 and 2006 with the Long Wavelength Array ( LWA ) 8 , a phased array consisting of 144 multiple - polarized dipole antennas active at wavelengths varied from 10 m to 80 m 9 . During these three years , LWA was deployed near Karthaus Township , Germany 10 , where it recorded transmissions from more than 20 million cosmic - ray - caused air showers 11 .",
        "rewrite_text": "**Title:** Observations of Microwave Continuum Emission from Air Shower Plasmas\n\n**Abstract:** This study presents the detection and characterization of microwave continuum emission originating from air shower plasmas, utilizing data collected by the LOPES experiment in Germany between 2004 and 2006. The emitted radiation aligns with theoretical predictions of coherent Cherenkov radiation produced by relativistic electrons, which are accelerated to energies reaching up to 100 MeV within the air showers. Notably, our findings reveal no significant contributions from incoherent synchrotron or bremsstrahlung processes, suggesting that the observed emissions predominantly stem from coherent mechanisms. This research enhances our understanding of high-energy cosmic ray interactions with atmospheric molecules, providing valuable insights into the underlying physics. Furthermore, the results underscore the potential of radio detection methods for investigating atmospheric phenomena, including thunderstorms, thereby expanding the applications of radio astronomy in atmospheric science. \n\nIn recent years, there has been an increasing interest in innovative techniques for detecting ultra-high-energy (UHE) cosmic rays through their interactions with the Earth's atmosphere. One promising approach involves measuring the radio-frequency (RF) emissions generated during these interactions, which can be detected over extensive areas. A key characteristic of this RF radiation is its intense broadband signal, which spans several microseconds. This phenomenon occurs as the charged particle cascade produced by each primary cosmic ray interacts with the geomagnetic field, resulting in coherent emissions across a wide frequency range. However, it is important to note that other mechanisms may also contribute to the overall RF emissions. \n\nIn this paper, we detail observations conducted with the Low-Frequency Array (LOFAR), part of the International LOFAR Telescope. Our analysis primarily focuses on data gathered between 2004 and 2006 using the Long Wavelength Array (LWA), which comprises 144 multi-polarized dipole antennas operating at wavelengths from 10 m to 80 m. Over the three-year period, the LWA, located near Karthaus Township, Germany, successfully recorded signals from over 20 million cosmic-ray-induced air showers, providing a rich dataset for further exploration of cosmic ray physics and its atmospheric implications.",
        "ori-fast-z-score": -1.8461989882527161,
        "water-fast-z-score": 7.777050693065944,
        "rewrite-fast-z-score": -0.5586608191273356
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Post-Oligarchic Evolution of Protoplanetary Embryos and the Stability of Planetary Systems .\nAbstract:\nWe present an analysis of the stability of planetary systems in which protoplanetary embryos evolve under oligarchy, i.e., they are able to eject each other s neighbors by gravitational scattering but not themselves. We find that this process leads to rapid growth of the largest embryo until it reaches its isolation mass (the minimum mass required for runaway accretion). The system then evolves into either a single planet or two planets with comparable masses depending on how close the initial conditions were to instability. This evolution is very different than what happens when all bodies grow simultaneously; in particular, we show that there can be multiple stable outcomes even if the initial conditions are identical. Our results suggest that the formation of terrestrial planets may have proceeded through several stages including oligarchy before reaching their final state as observed today. In addition, our work provides new insights about the origin of Mercury-like planets. Protoplanetary embryos form in circumstellar disks around young stars and undergo mutual gravitational interactions during their growth phase. These interactions lead to orbital migration and dynamical instabilities such as collisions between neighboring embryos. If these processes occur frequently enough, only one body will survive at the end of the growth stage leaving behind a planetary system consisting of just one planet. However, recent studies indicate that many planetary systems contain more than one planet suggesting that some mechanism must exist to prevent complete destruction of the system. Here we study the possibility that protoplanetary embryos follow a hierarchical evolutionary path where they first grow hierarchically via gravitational scattering followed by runaway accretion once the largest embryo has reached its isolation mass. Using numerical simulations, we demonstrate that this scenario naturally explains the existence of multi-planet systems while also reproducing the properties of known exoplanets.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Post - Oligarchic Evolution of Protoplanetary Embryos and the Stability of Planetary Systems . Abstract : We present an assessment of the stability of planetary environments in which protoplanetary embryos grow under oligarchy , i . e . , they are able to eject each other s neighbors by gravitational scattering but not themselves .We see that this process results to rapid growth of the largest embryo until it hits its isolation volume ( the minimum mass needed for runaway accretion ) . The system then evolves into either a single planet or two planets with similar masses depending on how close the early conditions were to instability .This evolution is very different than what happens when all bodies grow simultaneously ; in particular , we find that there can be several stable outcomes even if the first environments are identical . Our results propose that the formation of terrestrial worlds may have continued through several stages including oligarchy before reaching their final condition as predicted today .In addition , our work brings fresh insights about the origin of Mercury - like planets . Protoplanetary embryos form in circumstellar disks around young galaxies and undergo mutual gravitational interactions during their development period .These interactions result to orbital movement and dynamical instabilities such as collisions between neighboring embryos . If these mechanisms occur frequently enough , only one body will survive at the end of the development period leaving behind a planetary system consisting of just one planet .However , recent studies reveal that several planetary complexes comprise more than one planet suggesting that some process need arise to resist total destruction of the system . Here we study the suggestion that protoplanetary embryos pursue a hierarchical evolutionary course where they first develop hierarchically via gravitational waves followed by runaway accretion once the greatest embryo has reached its isolation mass .Using numerical simulations , we prove that this situation naturally reveals the existence of dual - planet systems while actually reproducing the properties of known exoplanets .",
        "rewrite_text": "**Title:** Post-Oligarchic Evolution of Protoplanetary Embryos and the Stability of Planetary Systems\n\n**Abstract:** This study investigates the stability of planetary systems formed from protoplanetary embryos that evolve under oligarchic conditions, where these embryos can gravitationally interact and eject neighboring bodies but do not expel themselves. Our findings indicate that this oligarchic growth leads to the rapid development of the largest embryo until it reaches its isolation mass, the threshold necessary for runaway accretion. Following this phase, the system typically evolves into either a single planet or a pair of planets with comparable masses, contingent upon the initial conditions and their proximity to instability. This evolutionary pathway contrasts sharply with scenarios where all bodies grow concurrently, revealing that multiple stable outcomes can arise even from identical initial environments. \n\nOur results suggest that the formation of terrestrial planets may have progressed through several evolutionary stages, including oligarchic interactions, before achieving their current configurations. Additionally, this research provides new perspectives on the origins of Mercury-like planets. Protoplanetary embryos develop within circumstellar disks surrounding young stars, engaging in mutual gravitational interactions that lead to dynamic behaviors such as orbital shifts and collisions. If these interactions occur frequently, it often results in the survival of only one body, culminating in a planetary system with a solitary planet. However, recent observations indicate that many planetary systems contain multiple planets, implying the necessity of mechanisms that prevent the complete destruction of these systems. \n\nIn this work, we propose that protoplanetary embryos follow a hierarchical evolutionary trajectory, initially developing through gravitational interactions before transitioning to runaway accretion once the most massive embryo attains its isolation mass. Through numerical simulations, we demonstrate that this evolutionary model naturally accounts for the emergence of dual-planet systems and aligns with the characteristics of known exoplanets, thereby enhancing our understanding of planetary system formation and stability.",
        "ori-fast-z-score": -1.3063945294843617,
        "water-fast-z-score": 7.242717283063319,
        "rewrite-fast-z-score": -0.7373087284671365
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Ultraluminous X-ray Sources near the Center of M82 .\nAbstract:\nWe report on an analysis of archival Chandra data for the central region of the nearby starburst galaxy M82 (NGC 3034). We find that there are two bright, point-like sources in this field which have been previously identified as ULXs (Ultra-Luminous X-Ray Sources) by Swartz et al. (2004) . The first source is located at RA = 12 h 54 m 55 s .6 and Dec = 69°59 45   with a count rate of 1.1 x 10^-3 counts sec-1. This source has a luminosity of 2 x 10^39 erg/sec assuming it lies at 8 kpc distance. The second source is located at RA=12h54m55s.7 and Dec=69°59 46   with a count rate 0.9 x 10^-3 countssec-1. It also has a luminosity of about 2 x 10^39erg/sec if it lies at 8kpc. Both these sources appear to be variable over timescales ranging between hours and days.  These results suggest that both sources may contain black holes accreting close to their Eddington limit.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Ultraluminous X - ray Sources near the Center of M82 . Abstract : We report on an assessment of archival Chandra data for the central region of the nearby starburst galaxy M82 ( NGC 3034 ) .We see that there are two bright , point - like sources in this area which have been previously described as ULXs ( Ultra - Luminous X - Ray Sources ) by Swartz et al . ( 2004 ) .The first source is situated at RA = 12 h 54 m 55 s . 6 and Dec = 69°59 45 with a count rate of 1 . 1 x 10 ^ - 3 counts sec - 1 . This source has a luminosity of 2 x 10 ^ 39 erg / sec assuming it lies at 8 kpc radius .The second source is situated at RA = 12h54m55s . 7 and Dec = 69°59 46 with a count rate 0 . 9 x 10 ^ - 3 countssec - 1 . It additionally has a luminosity of about 2 x 10 ^ 39erg / sec if it lies at 8kpc .Both these sources appear to be varying over timescales ranging between hours and days . These data suggest that both sources might include black holes accreting close to their Eddington limit .",
        "rewrite_text": "We present an analysis of archival Chandra data focusing on the central region of the nearby starburst galaxy M82 (NGC 3034). Our investigation reveals the presence of two prominent, point-like sources previously identified as Ultraluminous X-ray Sources (ULXs) by Swartz et al. (2004). The first source is located at right ascension (RA) 12h 54m 55.6s and declination (Dec) 69° 59' 45\", exhibiting a count rate of 1.1 x 10^-3 counts per second. Assuming a distance of 8 kiloparsecs, this source has an estimated luminosity of approximately 2 x 10^39 erg/s. The second source is found at RA 12h 54m 55.7s and Dec 69° 59' 46\", with a count rate of 0.9 x 10^-3 counts per second, also yielding a luminosity of around 2 x 10^39 erg/s at the same distance. Notably, both sources display variability over timescales ranging from hours to days, indicating dynamic processes at play. The characteristics of these sources suggest the possibility of black holes that are accreting matter near their Eddington limit, a condition that could explain their ultraluminous nature. This study enhances our understanding of the high-energy phenomena occurring in M82 and contributes to the broader knowledge of ULXs in starburst galaxies. Further investigations into the variability and underlying mechanisms of these sources could provide valuable insights into the nature of black hole accretion and the evolution of starburst environments.",
        "ori-fast-z-score": -0.2581988897471611,
        "water-fast-z-score": 2.9448482384566077,
        "rewrite-fast-z-score": 1.0540925533894598
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Clustering with Lattices in the Analysis of Graph Patterns .\nAbstract:\nWe present an algorithm for clustering graphs based on their patterns, which are represented as lattices. The proposed method is applied to analyze the similarity between chemical compounds and protein structures. We show that our approach can be used to identify similar substructures within large databases efficiently. In addition, we demonstrate how it can be utilized to detect structural changes caused by mutations or modifications. Our experiments reveal that the presented technique outperforms state-of-the-art methods significantly both in terms of accuracy and efficiency. Clustering algorithms have been widely studied in many fields such as data mining  1  , bioinformatics  2  , computer vision  3  , etc., due to its importance in discovering hidden information  4  . However, most existing approaches focus only on finding clusters without considering any additional information about them  5  .\nIn this work, we propose a novel graph clustering algorithm called CLUSTERING WITH LATTERS (CLL)  6  , which takes advantage of lattice representation  7, 8  to capture the pattern of each cluster. As shown in Figure 1 , CLL first transforms all input graphs into their corresponding lattices using a set of predefined rules  9  . Then, it performs hierarchical agglomerative clustering  10  over these lattices to find groups of similar graphs. Finally, it assigns each group to one cluster according to the majority vote among all members belonging to the same group  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Clustering with Lattices in the Analysis of Graph Patterns . Abstract : We present an algorithm for clustering graphs based on their patterns , which are represented as lattices .The proposed approach is applied to analyze the similarity between chemical molecules and protein compounds . We see that our approach can be used to identify similar substructures within large databases accurately .In addition , we prove how it can be used to identify structural modifications affected by genes or modifications . Our experiments indicate that the offered technique outperforms state - of - the - art methods significantly both in terms of precision and efficiency .Clustering methods have been widely explored in different fields such as data extraction 1 , bioinformatics 2 , computer vision 3 , etc . , owing to its significance in discovering hiding information 4 . However , most existing techniques concentrate only on discovering clusters without examining any additional information about them 5 .In this research , we develop a new graph clustering procedure entitled CLUSTERING WITH LATTERS ( CLL ) 6 , which gives advantage of lattice representation 7 , 8 to capture the pattern of each cluster . As seen in Figure 1 , CLL initially transforms all output graphs into their corresponding lattices using a setting of predefined rules 9 .Then , it performs hierarchical agglomerative clustering 10 over these lattices to find groups of related graphs . Finally , it gives each group to one cluster according to the majority decision among all members belonging to the same group 11 .",
        "rewrite_text": "We introduce a novel algorithm for clustering graphs based on their inherent patterns, which are represented through lattice structures. This innovative approach is particularly effective in analyzing the similarities between chemical molecules and protein compounds. Our findings demonstrate that this method can accurately identify similar substructures within extensive databases, enhancing the efficiency of data analysis in these fields. Furthermore, we establish that our algorithm is capable of detecting structural modifications influenced by genetic factors or other alterations. Experimental results reveal that our technique significantly surpasses existing state-of-the-art methods in both precision and efficiency.\n\nClustering methodologies have been extensively studied across various domains, including data extraction, bioinformatics, and computer vision, due to their critical role in uncovering hidden information. However, many current techniques primarily focus on identifying clusters without delving into additional insights about these clusters. In response to this gap, we propose a new graph clustering procedure named CLUSTERING WITH LATTICES (CLL). This method leverages the advantages of lattice representation to effectively capture the patterns within each cluster.\n\nAs illustrated in Figure 1, the CLL algorithm begins by converting all output graphs into their corresponding lattice forms based on a set of predefined rules. Subsequently, it employs hierarchical agglomerative clustering on these lattices to identify groups of related graphs. Finally, each identified group is assigned to a cluster based on the majority decision of its members. This comprehensive approach not only enhances the clustering process but also provides deeper insights into the structural relationships among the analyzed graphs.",
        "ori-fast-z-score": -1.044073795327749,
        "water-fast-z-score": 6.3028298181701015,
        "rewrite-fast-z-score": 0.9684959969581862
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  An Extrasolar Planet Census with a Space-based Microlensing Survey .\nAbstract:\nWe present the results of an analysis of microlensing events detected by the Optical Gravitational Lensing Experiment (OGLE) and its follow-up network, including the Microlensing Observations in Astrophysics collaboration (MOA). We have identified 16 new planets among these events using high-precision photometry obtained at Subaru Observatory. The masses of all but one planet are determined to be less than 1 M⊕ . Fourteen of them are found to orbit stars more massive than 0.5 M⊙ , while two others are around low-mass dwarfs. These planets are located between 0.1 AU and 4 AU away from their host stars. This is the first time that such a large number of extrasolar planets has been discovered through space-based microlensing surveys. Our sample includes several planets whose orbits lie close to or beyond Neptune s semi-major axis. In addition, we find evidence for planetary companions to three binary systems.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : An Extrasolar Planet Census with a Space - based Microlensing Survey . Abstract : We report the results of an assessment of microlensing events discovered by the Optical Gravitational Lensing Experiment ( OGLE ) and its follow - up network , notably the Microlensing Observations in Astrophysics collaboration ( MOA ) .We have discovered 16 new planets among these events utilizing large - precision photometry obtained at Subaru Observatory . The masses of all but one planet are found to be less than 1 M⊕ .Fourteen of them are found to orbit stars more massive than 0 . 5 [UNK] , while two others are around low - density dwarfs . These planets are situated between 0 . 1 AU and 4 AU away from their host stars .This is the first time that such a large number of extrasolar planets has been observed through space - based microlensing observations . Our specimen includes several planets whose orbits lie close to or beyond Neptune s semi - major axis .In addition , we find data for planetary companions to three binary systems .",
        "rewrite_text": "We present the findings of our investigation into microlensing events identified by the Optical Gravitational Lensing Experiment (OGLE) and its associated follow-up network, particularly the Microlensing Observations in Astrophysics (MOA) collaboration. Our analysis has led to the discovery of 16 new extrasolar planets, leveraging high-precision photometric data collected at the Subaru Observatory. Notably, the majority of these planets, with the exception of one, possess masses less than 1 Earth mass (M⊕). Among these discoveries, 14 planets are found to orbit stars with masses exceeding 0.5 solar masses, while the remaining two are associated with low-density dwarf stars. The newly identified planets are located at varying distances from their host stars, ranging from 0.1 astronomical units (AU) to 4 AU. This research marks a significant milestone as it represents the first instance of detecting such a substantial number of extrasolar planets through space-based microlensing techniques. Our sample includes several planets with orbits that are either close to or extend beyond the semi-major axis of Neptune. Additionally, we have gathered data indicating the presence of planetary companions in three binary star systems. These findings not only enhance our understanding of planetary formation and distribution in different stellar environments but also underscore the efficacy of microlensing as a powerful tool for discovering and studying distant exoplanets.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.731961445658845,
        "rewrite-fast-z-score": -0.19802950859533489
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Many-to-One Throughput Capacity of IEEE 802.11 Multi-hop Wireless Networks .\nAbstract:\nIn this work, we study the throughput capacity region for multi-hop wireless networks with multiple transmitters and one receiver (MISO-MHWN). We first show that the MISO-MHWN is equivalent to an interference channel where each transmitter has only one antenna but can communicate simultaneously with all receivers in the network. Then, by using the concept of degrees-of-freedom (DoF), which characterizes how many parallel data streams are supported at high signal-to-noise ratio (SNR) regime, we derive outer bounds on the DoF region of the MISO-MHWNS. Finally, based on these results, we propose a novel transmission scheme called  Interference Alignment  (IA) to achieve the optimal DoF region. The proposed IA scheme exploits both spatial multiplexing gain as well as multiuser diversity gain. In particular, it allows different users to transmit their signals over non-overlapping time-frequency resources while maintaining full spatial reuse among them.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Many - to - One Throughput Capacity of IEEE 802 . 11 Multi - hop Wireless Networks . Abstract : In this project , we study the throughput capacity area for single - hop wireless networks with many transmitters and one receiver ( MISO - MHWN ) .We first see that the MISO - MHWN is analogous to an interference channel where each antenna has only one antenna but can communicate simultaneously with all receivers in the channel . Then , by using the idea of degrees - of - independence ( DoF ) , which characterizes how many concurrent data feeds are implemented at high signal - to - noise ratio ( SNR ) regime , we derive outer bounds on the DoF area of the MISO - MHWNS .Finally , based on these results , we propose a new transmission strategy titled Interference Alignment ( IA ) to achieve the ideal DoF area . The proposed IA plan involves both temporal multiplexing gain as well as multiuser flexibility gain .In particular , it allows different users to transmit their messages over non - overlapping period - frequency resources while maintaining full spatial reuse among them .",
        "rewrite_text": "Title: Many-to-One Throughput Capacity of IEEE 802.11 Multi-hop Wireless Networks\n\nAbstract: This study investigates the throughput capacity of single-hop wireless networks characterized by multiple transmitters and a single receiver, referred to as MISO-MHWN (Multiple Input Single Output - Multi-Hop Wireless Network). We draw parallels between MISO-MHWN and an interference channel, where each transmitter is equipped with a single antenna yet can engage in simultaneous communication with all receivers present in the channel. To analyze the system's performance, we employ the concept of degrees-of-freedom (DoF), which quantifies the number of concurrent data streams that can be supported in a high signal-to-noise ratio (SNR) environment. Through this framework, we establish outer bounds on the DoF region for MISO-MHWNs, providing insights into the limitations and potential of such networks. Building on these theoretical findings, we introduce a novel transmission strategy known as Interference Alignment (IA). This approach aims to optimize the achievable DoF region by leveraging both temporal multiplexing and multiuser flexibility. Specifically, the IA strategy enables distinct users to transmit their information over non-overlapping time-frequency resources, thereby facilitating complete spatial reuse among users. This innovative method not only enhances the overall throughput capacity of the network but also addresses the challenges posed by interference in multi-hop scenarios. Our findings contribute to a deeper understanding of the capacity limits of MISO-MHWNs and offer practical implications for the design of efficient communication protocols in wireless networks.",
        "ori-fast-z-score": -1.2222222222222223,
        "water-fast-z-score": 4.638124095143555,
        "rewrite-fast-z-score": -0.6704783996548059
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Classical and quantum randomness and the financial market .\nAbstract:\nWe study how classical and quantum uncertainty affect the price dynamics in an incomplete information setting, where agents have access to different sources of information about the underlying state variable. We show that when there is no common knowledge among traders on the true value of the state variable, they may disagree on its expected future evolution even if all are rational and risk-neutral. This disagreement leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based solely on their private signals. In this case, we find that the stock returns exhibit volatility clustering and fat tails similar to those observed empirically. Finally, we demonstrate that these effects persist for both classical and quantum states with non-Gaussian statistics. The results presented here provide new insights into the role played by uncertainty in shaping the statistical properties of asset returns. They also suggest possible avenues for further research aimed at understanding the origin of such phenomena within more realistic models of trading behavior.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Classical and quantum randomness and the monetary market . Abstract : We research how classical and quantum uncertainty influence the price dynamics in an incomplete information context , where agents have access to different sources of information about the underlying state variable .We see that when there is no shared information among traders on the true value of the state variable , they may differ on its expected potential evolution even if all are rational and risk - neutral . This dispute leads to fluctuations in prices which can be amplified by the presence of noise traders who trade based primarily on their private signals .In this situation , we find that the stock yields produce volatility clustering and fat tails identical to those observed empirically . Finally , we prove that these influences persist for both classical and quantum states with non - Gaussian statistics .The results presented here provide fresh insights into the part played by uncertainty in shaping the statistical characteristics of investment returns . They also suggest possible avenues for further studies aimed at studying the origin of such patterns within more realistic descriptions of trading activity .",
        "rewrite_text": "Title: Classical and Quantum Randomness in Financial Markets\n\nAbstract: This study explores the impact of classical and quantum uncertainty on price dynamics within a framework of incomplete information, where market participants possess varying levels of access to information regarding an underlying state variable. Our findings indicate that in the absence of a common understanding among traders about the true value of this state variable, discrepancies in their expectations regarding its future evolution can arise, even among rational and risk-neutral agents. This divergence in expectations contributes to price volatility, which is further exacerbated by the presence of noise traders who base their trading decisions primarily on private signals rather than on shared information. We demonstrate that this scenario leads to stock yields exhibiting characteristics such as volatility clustering and fat tails, which align closely with empirical observations in financial markets. Furthermore, our analysis reveals that these effects are sustained across both classical and quantum states characterized by non-Gaussian statistical properties. The insights gained from this research enhance our understanding of the role that uncertainty plays in influencing the statistical behavior of investment returns. Additionally, our findings open up new avenues for future research aimed at investigating the origins of these phenomena within more nuanced and realistic models of trading behavior.",
        "ori-fast-z-score": -1.1055415967851332,
        "water-fast-z-score": 4.8,
        "rewrite-fast-z-score": 1.7320508075688772
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Observations and Modeling of Line Asymmetries in Chromospheric Flares .\nAbstract:\nWe present observations of the Mg II k line asymmetry during flares, which are compared with results obtained by numerical simulations using the RH code (Uitenbroek 2001). The observed profiles show that the blue wing is enhanced relative to the red one at all heights above the limb where we can see the flare emission. This effect is more pronounced for higher altitudes. We find that this behavior cannot be explained solely by Doppler shifts due to bulk plasma motions along the LOS. In addition, our modeling shows that the observed profile shapes cannot be reproduced without including nonthermal electron beams as an additional heating source. \n \n Keywords: Solar flare, chromospheric lines, nonthermal electrons, radiative hydrodynamics model, RH code, Mg II k line, line asymmetry. 1 Introduction \n \n During solar flares, intense energy release leads to rapid changes in physical conditions throughout the atmosphere of the Sun. These include temperature increases up to several million degrees Kelvin, strong magnetic fields, high densities, and large velocities. All these factors affect the shape of spectral lines emitted by different atmospheric layers. For example, it has been shown that the intensity ratio between two Fe I lines formed at different temperatures depends on the height of formation of each line (Feldman et al., 1995; Brosius & Phillips 2004) . Also, the presence of nonthermal electrons causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles (e.g., Canfield et al. (1990) ; Doschek et al. (1991) ), while bulk flows lead to Doppler shifts of the line center position (Doschek et al., 1991; Brosius & Phillips 2004; Brosius 2009 ). Therefore, studying the temporal evolution of the line profiles provides important information about the dynamics of the flaring region. However, interpreting such data requires detailed knowledge of the underlying physics involved in the processes responsible for the observed phenomena. \n \n In particular, the study of the Mg II h&k lines offers unique opportunities to investigate various aspects of solar flares because they form over a wide range",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Observations and Modeling of Line Asymmetries in Chromospheric Flares . Abstract : We report observations of the Mg II k line asymmetry during flares , which are compared with conclusions derived by numerical simulations using the RH code ( Uitenbroek 2001 ) .The observed profiles indicate that the blue wing is enhanced compared to the red one at all heights above the limb where we can see the flare emission . This phenomenon is more pronounced for greater altitudes .We see that this behavior cannot be described solely by Doppler variations owing to bulk plasma motions along the LOS . In addition , our modeling demonstrates that the seen profile patterns cannot be reproduced without using nonthermal ion rays as an additional thermal source .Keywords : Solar flare , chromospheric lines , nonthermal ions , radiative hydrodynamics theory , RH code , Mg II h line , edge asymmetry . 1 Introduction During solar flares , intense heat release leads to rapid alterations in physical conditions throughout the atmosphere of the Sun .These include temperature increases up to several million degrees Kelvin , large magnetic fields , large densities , and large velocities . All these influences influence the morphology of spectral lines emissions by various atmospheric elements .For instance , it has been shown that the frequency proportion between two Fe I lines formed at different temperatures depends on the height of formation of each line ( Feldman et al . , 1995 ; Brosius & Phillips 2004 ) . Also , the presence of nonthermal atoms causes significant deviations from Maxwellian velocity distributions leading to asymmetric line profiles ( e . g . , Canfield et al .( 1990 ) ; Doschek et al . ( 1991 ) ) , while bulk flows result to Doppler movements of the line center position ( Doschek et al . , 1991 ; Brosius & Phillips 2004 ; Brosius 2009 ) .Therefore , studying the temporal evolution of the line profiles provides crucial data about the dynamics of the flaring zone . However , interpreting such information requires detailed knowledge of the fundamental physics involved in the mechanisms involved for the seen phenomena .In particular , the study of the Mg II h & k lines provides unique possibilities to examine different components of sun flares because they occur over a broad range",
        "rewrite_text": "**Title:** Observations and Modeling of Line Asymmetries in Chromospheric Flares\n\n**Abstract:** This study presents an analysis of the asymmetry observed in the Mg II k line during solar flares, juxtaposed with insights gained from numerical simulations conducted using the RH code (Uitenbroek, 2001). Our observations reveal a consistent enhancement of the blue wing of the Mg II k line relative to the red wing at all altitudes above the solar limb where flare emissions are detectable. This asymmetry becomes increasingly pronounced at higher altitudes. Notably, our findings indicate that this behavior cannot be attributed solely to Doppler shifts resulting from bulk plasma motions along the line of sight (LOS). Furthermore, our modeling efforts suggest that the observed profile patterns cannot be accurately replicated without incorporating nonthermal ion contributions as an additional thermal source. \n\nThe significance of this research lies in its exploration of the physical conditions prevalent during solar flares, which are characterized by rapid and extreme changes in the solar atmosphere, including temperature spikes reaching millions of degrees Kelvin, intense magnetic fields, and elevated densities and velocities. These factors collectively influence the spectral line emissions of various atmospheric elements. Previous studies have established that the relative intensity of two Fe I lines, formed at distinct temperatures, is height-dependent (Feldman et al., 1995; Brosius & Phillips, 2004). Additionally, the presence of nonthermal particles leads to notable deviations from Maxwellian velocity distributions, resulting in asymmetric line profiles (e.g., Canfield et al., 1990; Doschek et al., 1991). Meanwhile, bulk flows contribute to the Doppler shifts observed in the line center positions (Doschek et al., 1991; Brosius & Phillips, 2004; Brosius, 2009). \n\nThus, analyzing the temporal evolution of line profiles is essential for understanding the dynamics within the flaring region. However, accurate interpretation of these observations necessitates a comprehensive understanding of the underlying physical mechanisms at play. The study of the Mg II h and k lines offers a unique opportunity to investigate various aspects of solar flares, given their formation across a wide range of atmospheric conditions. \n\n**Keywords:** Solar flare, chromospheric lines, nonthermal ions, radiative hydrodynamics theory, RH code, Mg II h line, edge asymmetry.",
        "ori-fast-z-score": -0.23076923076923078,
        "water-fast-z-score": 8.076923076923077,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Random Access Broadcast: Stability and Throughput Analysis .\nAbstract:\nWe consider the problem of broadcasting in wireless networks with random access, where nodes can transmit at any time they choose to do so. We propose an algorithm that achieves stability by using a simple backoff mechanism based on local information only. The proposed scheme is shown to be throughput optimal under certain conditions. In addition, we show how our results are related to existing work on this topic. Finally, simulation experiments demonstrate the performance gains achieved by our approach over other schemes. Wireless broadcast has been studied extensively for many years due to its wide range of applications such as data dissemination, file transfer, video streaming, etc.. However, most previous works assume that all transmissions occur synchronously or within some fixed schedule. This assumption does not hold true when there exist multiple transmitters competing for channel resources simultaneously. Random access (RA) protocols have recently received much attention because they allow users to send packets whenever it is convenient without requiring tight synchronization among them  1  . Unfortunately, RA introduces additional challenges compared to traditional synchronous transmission models since collisions may happen frequently if no coordination exists between different transmitters  2  .\nIn this paper, we study the problem of broadcasting in multi-hop wireless networks with random access. Specifically, each node maintains one packet which needs to be transmitted to every other node in the network eventually. Each node chooses independently and uniformly at random a starting time slot to begin transmitting its packet. If two or more nodes start their transmissions at the same time slot, then these transmissions collide and none of them will reach the intended receivers successfully. Our goal is to design distributed algorithms that achieve both stability and high throughput while minimizing the number of retransmissions required to deliver messages reliably.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Random Access Broadcast : Stability and Throughput Analysis . Abstract : We consider the issue of transmitting in mobile networks with random access , where nodes can communicate at any time they select to do so .We suggest an algorithm that achieves stability by using a simple backoff mechanism based on local information only . The proposed system is demonstrated to be throughput efficient under certain conditions .In addition , we tell how our findings are related to existing work on this theme . Finally , simulation studies demonstrate the performance increases attained by our approach over other schemes .Wireless broadcast has been studied thoroughly for numerous years owing to its large variety of applications such as data dissemination , file transfer , media streaming , etc . . However , most prior papers assume that all transmissions happen synchronously or within some fixed schedule .This assumption does not stand true when there exist several transmitters battling for channel supplies concurrently . Random entry ( RA ) technologies have recently garnered many notice because they allow users to send messages whenever it is convenient without using strict synchronization among them 1 .Unfortunately , RA creates additional challenges compared to conventional synchronous transmission models since collisions might come frequently if no coordination occurs between different transmitters 2 . In this paper , we study the issue of transmitting in multi - hop wireless networks with random access .Specifically , each node establishes one packet which requires to be conveyed to every other node in the network subsequently . Each node decides separately and uniformly at random a starting date slot to starting sending its packet .If two or more nodes start their broadcasts at the same time slot , then these transmissions collide and nobody of them will achieve the intended receivers effectively . Our goal is to build distributed methods that attain both stability and good throughput while minimizing the number of retransmissions needed to deliver transmissions reliably .",
        "rewrite_text": "**Title:** Random Access Broadcast: Stability and Throughput Analysis\n\n**Abstract:** In this study, we address the challenges associated with transmitting data in mobile networks utilizing random access, where nodes have the flexibility to communicate at their discretion. We introduce a novel algorithm that ensures system stability through a straightforward backoff mechanism that relies solely on local information. Our findings indicate that this approach can achieve efficient throughput under specific conditions. We also explore the connections between our results and existing literature on this topic. Through extensive simulation studies, we demonstrate that our method significantly enhances performance compared to alternative strategies.\n\nWireless broadcast has been extensively researched due to its wide-ranging applications, including data dissemination, file transfers, and media streaming. However, much of the prior work has operated under the assumption that transmissions occur synchronously or follow a predetermined schedule. This assumption fails in scenarios where multiple transmitters compete for channel access simultaneously. Recent advancements in random access (RA) technologies have gained attention as they empower users to transmit messages at their convenience, without the need for strict synchronization. Nevertheless, RA introduces unique challenges that differ from traditional synchronous transmission models, particularly the increased likelihood of collisions when transmitters operate without coordination.\n\nIn this paper, we focus on the transmission dynamics within multi-hop wireless networks employing random access. Each node generates a packet intended for delivery to all other nodes in the network. The nodes independently and uniformly select a time slot to initiate their broadcasts. When multiple nodes attempt to transmit during the same time slot, collisions occur, preventing any of the transmissions from reaching their intended recipients. Our objective is to develop distributed protocols that achieve both stability and high throughput while minimizing the number of retransmissions required for reliable delivery. Through our analysis, we aim to contribute to the understanding of random access broadcast systems and their potential for improving network performance.",
        "ori-fast-z-score": -0.6405126152203485,
        "water-fast-z-score": 8.8028726014714,
        "rewrite-fast-z-score": -0.31234752377721214
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The ACS Survey of Galactic Globular Clusters. II. Stellar Evolution Tracks, Isochrones, Luminosity Functions, and Synthetic Horizontal-Branch Models .\nAbstract:\nWe present the results of our analysis of the photometric data obtained by the Advanced Camera for Surveys (ACS) on board HST in the F606W and F814W bands during Cycle 12 as part of program GO-10775. The survey consists of deep imaging observations of 16 globular clusters with metallicities ranging between  Fe/H  = -2.2 to -0.7. We have used these data along with archival WFPC-2 images taken under programs GO-5269 and GO-6366 to study the properties of horizontal branch stars in each cluster. \n \n In this work we use theoretical stellar evolution tracks, isochrones, luminosity functions, and synthetic HB models to determine ages, reddenings, distances, helium abundances, and mass loss rates for all sixteen clusters studied here. Our main conclusions are summarized below: \n \n \n \n 1. Ages - We find that most of the clusters analyzed here appear younger than previously thought based upon their location relative to the fiducial ridge line defined by the Milky Way s old open clusters. This result suggests that either the age scale derived using open clusters may be systematically too young or that there has been significant dynamical evolution within many of the clusters since they formed. \n \n 2. Reddening - We find evidence for differential reddening across several of the clusters studied here. However, it appears that the majority of the clusters do not suffer from large amounts of differential reddening. For those clusters where we can measure individual reddenings for different populations of stars, we find no systematic differences between the values determined for blue stragglers versus normal giants. These results suggest that any differential reddening affecting these clusters must occur over scales smaller than the typical size of an open cluster. \n \n 3. Distances - Using the absolute magnitudes of RR Lyrae variables observed in each cluster, we derive distance moduli which agree well with previous estimates made using other methods such as main sequence fitting. We also compare the mean magnitude of the RGB bump in each cluster to predictions made using synthetic HB models. While some",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  The ACS Survey of Galactic Globular Clusters.II.Stellar Evolution Tracks , Isochrones , Luminosity Functions , and Synthetic Horizontal - Branch Models . Abstract : We present the results of our analysis of the photometric data received by the Advanced Camera for Surveys ( ACS ) on board HST in the F606W and F814W bands during Cycle 12 as part of plan GO - 10775 .The survey consists of deep imaging observations of 16 globular galaxies with metallicities ranging between Fe / H = - 2 . 2 to - 0 . 7 . We have utilized these information along with archival WFPC - 2 images took under programs GO - 5269 and GO - 6366 to study the properties of horizontal branch stars in each cluster .In this research we using theoretical stellar evolution tracks , isochrones , luminosity functions , and synthetic HB models to estimate ages , reddenings , distances , helium abundances , and mass loss rates for all sixteen clusters explored here . Our main results are presented below : 1 .Ages - We see that most of the clusters evaluated here appear newer than previously thought based upon their placement relative to the fiducial crest line defined by the Milky Way s ancient open clusters . This result suggests that either the age scale obtained using open clusters might be systematically too young or that there has been significant dynamical development within many of the clusters since they formed .2 . Reddening - We get data for differential reddening across many of the clusters explored here .However , it appears that the majority of the clusters do not suffer from huge amounts of differential reddening . For those clusters where we can measure individual reddenings for different populations of stars , we find no comprehensive differences between the estimates determined for blue stragglers versus regular giants .These data suggest that any differential reddening affecting these clusters must exist over scales lower than the typical size of an open cluster . 3 .Distances - Using the absolute magnitudes of RR Lyrae variables seen in each cluster , we derive distance moduli which agree well with previous estimates made using other methods such as main sequence fitting . We additionally compare the mean magnitude of the RGB bump in each cluster to calculations made using synthetic HB models .While some",
        "rewrite_text": "**Title:** The ACS Survey of Galactic Globular Clusters II: Stellar Evolution Tracks, Isochrones, Luminosity Functions, and Synthetic Horizontal-Branch Models\n\n**Abstract:** This study presents the findings from our comprehensive analysis of photometric data collected by the Advanced Camera for Surveys (ACS) aboard the Hubble Space Telescope (HST) in the F606W and F814W bands during Cycle 12, as part of program GO-10775. Our survey encompasses deep imaging observations of 16 globular clusters, characterized by metallicities ranging from [Fe/H] = -2.2 to -0.7. We have integrated this data with archival WFPC-2 images obtained under programs GO-5269 and GO-6366 to investigate the properties of horizontal branch stars within each cluster. Employing theoretical stellar evolution tracks, isochrones, luminosity functions, and synthetic horizontal-branch models, we aim to estimate various parameters including ages, reddenings, distances, helium abundances, and mass loss rates for the 16 clusters analyzed.\n\nOur key findings are summarized as follows: \n\n1. **Ages:** The majority of the clusters appear to be younger than previously estimated, based on their positions relative to the fiducial crest line established by the Milky Way's ancient open clusters. This observation raises the possibility that the age scale derived from open clusters may be systematically underestimated, or that significant dynamical evolution has occurred within many of these globular clusters since their formation.\n\n2. **Reddening:** We have gathered data indicating differential reddening across several clusters; however, most do not exhibit substantial differential reddening. For those clusters where we can measure individual reddenings for distinct stellar populations, we find no significant differences between the reddening estimates for blue stragglers and regular giants. This suggests that any differential reddening present is likely confined to scales smaller than those typical of open clusters.\n\n3. **Distances:** By analyzing the absolute magnitudes of RR Lyrae variables in each cluster, we derive distance moduli that align closely with previous estimates obtained through alternative methods, such as main sequence fitting. Additionally, we compare the mean magnitude of the red giant branch (RGB) bump in each cluster with calculations derived from synthetic horizontal-branch models, further validating our distance measurements. \n\nThese results contribute to a deeper understanding of the stellar populations and evolutionary histories of globular clusters, providing insights into their formation and development within the context of galactic evolution.",
        "ori-fast-z-score": -0.318222913670292,
        "water-fast-z-score": 5.947886892886081,
        "rewrite-fast-z-score": 0.07692307692307693
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multi-wavelength analysis of 18um-selected galaxies in the AKARI/IRC monitor field towards the North Ecliptic Pole .\nAbstract:\nWe have carried out multi-wavelength observations for a sample of infrared (IR) selected galaxies with AKARI and other telescopes to investigate their physical properties, such as dust temperature T d , luminosity L IR , star formation rate SFR, stellar mass M * . The main results are summarized below.  We found that most of our targets show red colors at optical wavelengths indicating old ages and/or low metallicities. In addition, we detected strong polycyclic aromatic hydrocarbon emission features at 6.2, 7.7, 8.6, 11.3 um which indicate active star-formation activities. By fitting the observed spectral energy distributions (SEDs), we derived the following parameters;  - Dust temperatures range between 30 K and 60 K. - Luminosities range between 10^10 and 10^12 Lsun. - Star formation rates range between 0.1 and 100 Msun yr-1. - Stellar masses range between 10^9 and 10^11 Msun.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multi - wavelength assessment of 18um - selected galaxies in the AKARI / IRC watch area towards the North Ecliptic Pole . Abstract : We have carried out multi - wavelength investigations for a sample of infrared ( IR ) selected galaxies with AKARI and other telescopes to examine their physical properties , such as cloud temperature T d , luminosity L IR , star formation rate SFR , planetary power M * .The main results are presented below . We showed that most of our targets exhibit color colors at optical wavelengths suggesting old ages and / or low metallicities .In addition , we identified strong polycyclic aromatic hydrocarbon emission events at 6 . 2 , 7 . 7 , 8 . 6 , 11 . 3 um which demonstrate active galaxy - formation behaviors . By fitting the observed spectral power distributions ( SEDs ) , we derived the following variables ; - Dust temperatures range between 30 K and 60 K . - Luminosities range between 10 ^ 10 and 10 ^ 12 Lsun .- Star formation rates range between 0 . 1 and 100 Msun yr - 1 . - Stellar masses range between 10 ^ 9 and 10 ^ 11 Msun .",
        "rewrite_text": "Title: Multi-wavelength Assessment of 18 µm-selected Galaxies in the AKARI/IRC Watch Area Towards the North Ecliptic Pole\n\nAbstract: In this study, we conducted a comprehensive multi-wavelength analysis of a sample of infrared (IR) selected galaxies located in the AKARI/IRC watch area, specifically targeting the North Ecliptic Pole. Utilizing data from the AKARI satellite alongside observations from various other telescopes, we aimed to investigate the physical properties of these galaxies, including cloud temperature (T_d), infrared luminosity (L_IR), star formation rate (SFR), and stellar mass (M*). Our findings reveal that a significant portion of the observed galaxies display optical color characteristics indicative of advanced ages and/or low metallicity levels. Furthermore, we detected pronounced polycyclic aromatic hydrocarbon (PAH) emission features at wavelengths of 6.2, 7.7, 8.6, and 11.3 µm, which suggest ongoing active galaxy formation processes. By analyzing the spectral energy distributions (SEDs) of our sample, we were able to derive several key parameters: the dust temperatures were found to range from 30 K to 60 K, while the luminosities varied between 10^10 and 10^12 L_sun. Additionally, the star formation rates exhibited a broad range from 0.1 to 100 M_sun per year, and the stellar masses were determined to lie between 10^9 and 10^11 M_sun. These results contribute to our understanding of the physical characteristics and evolutionary stages of IR-selected galaxies, highlighting the importance of multi-wavelength observations in astrophysical research.",
        "ori-fast-z-score": 0.23570226039551587,
        "water-fast-z-score": 4.798687035041354,
        "rewrite-fast-z-score": -0.19425717247145283
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  GRI: The Gamma-Ray Imager mission .\nAbstract:\nThe GRI (Gamma Ray Imager) is an astrophysics space observatory proposed by the French Space Agency CNES and NASA to study gamma-ray bursts, active galactic nuclei and other phenomena in high-energy astronomy.  It will be launched on a Soyuz rocket with a Fregat upper stage into a Sun-Earth L2 orbit at 1 AU distance from Earth. Its main instrument consists of two coded mask telescopes observing simultaneously in the energy range 20 MeV - 300 GeV. Each telescope has a large field-of-view of 2 steradians and a spatial resolution better than 0.1 degrees. A third detector module provides additional information about the background radiation environment for each telescope. This article describes the design concept of this innovative instrument. Keywords: Astroparticle physics, High-Energy Astronomy, Instrumentation, Space Observatory. Introduction:  The GRI (Gamma Ray...  more",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : GRI : The Gamma - Ray Imager mission . Abstract : The GRI ( Gamma Ray Imager ) is an astrophysics space observatory proposed by the French Space Agency CNES and NASA to study alpha - ray bursts , active galactic nuclei and other processes in high - energy astronomy .It will be launched on a Soyuz rocket with a Fregat upper stage into a Sun - Earth L2 orbit at 1 AU distance from Earth . Its primary instrument consists of two coded mask telescopes observing simultaneously in the power range 20 MeV - 300 GeV .Each observatory has a large field - of - view of 2 steradians and a spatial resolution good than 0 . 1 degrees . A third detector module supplies additional information about the background radiation conditions for each telescope .This page describes the design concept of this innovative instrument . Keywords : Astroparticle science , High - Energy Astronomy , Instrumentation , Space Observatory .Introduction:  The GRI (Gamma Ray...  more",
        "rewrite_text": "**Title: GRI: The Gamma-Ray Imager Mission**\n\n**Abstract:** The Gamma-Ray Imager (GRI) is a proposed astrophysics space observatory developed collaboratively by the French Space Agency CNES and NASA, aimed at advancing our understanding of high-energy astronomical phenomena such as gamma-ray bursts and active galactic nuclei. Scheduled for launch aboard a Soyuz rocket equipped with a Fregat upper stage, the GRI will be positioned in a Sun-Earth L2 orbit, approximately 1 AU from Earth. The mission's primary observational capabilities are facilitated by two coded mask telescopes that operate concurrently across a broad energy spectrum ranging from 20 MeV to 300 GeV. Each telescope boasts an impressive field of view of 2 steradians and achieves a spatial resolution exceeding 0.1 degrees, enabling detailed imaging of high-energy sources. Additionally, a third detector module is incorporated to provide critical data regarding the background radiation environment, enhancing the overall observational accuracy of the telescopes. This document outlines the design principles and innovative features of the GRI instrument, which is poised to make significant contributions to the fields of astroparticle science and high-energy astronomy. By leveraging advanced instrumentation and strategic positioning, the GRI aims to uncover new insights into the mechanisms driving some of the universe's most energetic processes. \n\n**Keywords:** Astroparticle science, High-Energy Astronomy, Instrumentation, Space Observatory.",
        "ori-fast-z-score": 1.1338934190276817,
        "water-fast-z-score": 4.341215710622296,
        "rewrite-fast-z-score": 0.7107423155935334
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Unified Approach to Energy-Efficient Power Control in Large CDMA Systems .\nAbstract:\nIn this thesis, we propose an energy-efficient power control scheme for large code division multiple access (CDMA) systems with variable traffic loads and channel conditions. The proposed approach is based on the concept that all users should be allocated their required data rates at minimum total transmit power consumption while maintaining acceptable quality-of-service (QoS). We first develop a new analytical model which can accurately predict the average received signal-to-interference-plus-noise ratio (SINR) under different system configurations. Based on our analysis results, we then formulate the problem as a convex optimization problem subject to SINR constraints. Finally, by applying Lagrange multiplier method, we obtain closed-form solutions for both uplink and downlink transmissions. Our simulation results show that compared with conventional schemes such as water-filling algorithm, the proposed approach achieves significant performance gains in terms of power efficiency without sacrificing QoS requirements. In addition, it also outperforms other existing approaches in terms of computational complexity. \n \n Keywords: Code Division Multiple Access, Power Control",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Unified Approach to Energy - Efficient Power Control in Large CDMA Systems . Abstract : In this dissertation , we propose an energy - efficient energy management scheme for large code division multiple entry ( CDMA ) networks with variable traffic loads and channel conditions .The proposed approach is based on the idea that all users should be allocated their required information rates at minimum total transmit energy consumption while maintaining acceptable quality - of - service ( QoS ) . We first develop a new analytical method which can accurately forecast the average received signal - to - interference - plus - noise proportion ( SINR ) under various system configurations .Based on our analysis results , we then formulate the issue as a convex optimization problem subject to SINR restrictions . Finally , by using Lagrange multiplier method , we obtain closed - form solutions for both uplink and downlink transmissions .Our simulation data demonstrate that compared with typical strategies such as water - filling algorithm , the suggested approach achieves significant efficiency increases in terms of power performance without sacrificing QoS requirements . In addition , it also outperforms other existing techniques in terms of computational complexity .Keywords: Code Division Multiple Access, Power Control",
        "rewrite_text": "Title: A Unified Approach to Energy-Efficient Power Control in Large CDMA Systems\n\nAbstract: This dissertation introduces a novel energy management strategy tailored for large Code Division Multiple Access (CDMA) networks, addressing the challenges posed by variable traffic loads and fluctuating channel conditions. The core principle of our approach is to ensure that each user receives the necessary information rates while minimizing the overall transmit energy consumption, all while upholding acceptable quality-of-service (QoS) standards. To achieve this, we first develop an innovative analytical method capable of accurately predicting the average received signal-to-interference-plus-noise ratio (SINR) across different system configurations. Building on the insights gained from our analysis, we reformulate the problem as a convex optimization challenge, incorporating SINR constraints. Utilizing the Lagrange multiplier technique, we derive closed-form solutions applicable to both uplink and downlink transmissions. Our simulation results reveal that our proposed method significantly enhances power efficiency compared to conventional strategies, such as the water-filling algorithm, without compromising QoS requirements. Furthermore, our approach demonstrates superior performance over existing methods in terms of computational complexity, making it a practical solution for real-world applications. This work contributes to the ongoing efforts to optimize energy consumption in CDMA systems, paving the way for more sustainable and efficient wireless communication networks. \n\nKeywords: Code Division Multiple Access, Power Control",
        "ori-fast-z-score": 0.8,
        "water-fast-z-score": 5.742855749264711,
        "rewrite-fast-z-score": 1.889822365046136
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stochastic Loewner Evolution .\nAbstract:\nThe Stochastic Loewner Evolution (SLE) is an important tool in the study of random curves and fractals, especially those arising as scaling limits of discrete models such as lattice paths or self-avoiding walks.  The SLE trace can be thought of as a continuous version of Brownian motion with drift; it has been shown to have connections to many other fields including quantum gravity, string theory, statistical mechanics, probability theory, mathematical physics, number theory, and computer science.   In this article we will give a brief introduction to the basic concepts behind the SLE process, along with some examples that illustrate its use. We also provide references for further reading on the subject. For more information about the SLE process see the following articles:  http://arxiv.org/abs/math/9906028 http://arxiv.org/sabs/0909.0366 http://arxiv.org/10.1103/PhysRevE.71.026110",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stochastic Loewner Evolution . Abstract : The Stochastic Loewner Evolution ( SLE ) is an important tool in the study of random curves and fractals , particularly those originating as scaling limits of finite models such as lattice trails or self - escaping tours .The SLE trace can be thought of as a continuous version of Brownian movement with drift ; it has been shown to have relationships to many other fields including quantum gravitational , string theory , statistical mechanics , probability theory , mathematical science , number theory , and computer science . In this article we will provide a brief introduction to the fundamental concepts behind the SLE method , along with some examples that highlight its use .We additionally offer references for further reading on the subject . For more information about the SLE system hear the following articles : http : / / arxiv . org / abs / math / 9906028 http : / / arxiv . org / sabs / 0909 . 0366 www : / / arxiv . org / 10 . 1103 / PhysRevE . 71 . 026110",
        "rewrite_text": "Title: Stochastic Loewner Evolution\n\nAbstract: Stochastic Loewner Evolution (SLE) serves as a pivotal framework for analyzing random curves and fractals, particularly those that emerge as scaling limits from finite models, such as lattice paths or self-avoiding walks. The SLE trace can be conceptualized as a continuous analogue of Brownian motion with a drift component. Its significance extends across various disciplines, establishing connections with quantum gravity, string theory, statistical mechanics, probability theory, mathematical sciences, number theory, and computer science. This article aims to present a concise overview of the core principles underlying the SLE methodology, supplemented by illustrative examples that demonstrate its practical applications. Furthermore, we provide a curated list of references for readers interested in delving deeper into the topic. For additional insights into the SLE framework, we recommend the following articles: http://arxiv.org/abs/math/9906028, http://arxiv.org/abs/0909.0366, and http://arxiv.org/10.1103/PhysRevE.71.026110.",
        "ori-fast-z-score": -0.11704114719613057,
        "water-fast-z-score": 4.798687035041354,
        "rewrite-fast-z-score": 0.3464101615137754
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Branch and Cut Algorithm for the Halfspace Depth Problem .\nAbstract:\nWe present an algorithm to solve the half-space depth problem, which is one of the most fundamental problems in computational geometry. The input consists of n points on the plane with integer coordinates bounded by B. We want to find a point that minimizes its distance to all other points. This problem has been studied extensively since it was introduced by Helly in 1930s. In this work we propose a new branch-and-cut algorithm based on mixed-integer programming (MIP) formulation. Our MIP model uses O(nB) variables and constraints. Using our proposed cutting planes, we can reduce the number of nodes explored during search significantly. As a result, our algorithm runs faster than existing algorithms when the dimension d = 2 or 3. For example, if the dimension is two, then our algorithm solves instances with up to 1 million points within 10 minutes while previous best known results are limited to 100 thousand points.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Branch and Cut Algorithm for the Halfspace Depth Problem . Abstract : We present an algorithm to solve the half - space depth problem , which is one of the most important problems in computational geometry .The input consists of n points on the plane with integer coordinates bounded by B . We want to find a point that minimizes its distance to all other points .This problem has been studied thoroughly since it was introduced by Helly in 1930s . In this study we propose a new branch - and - cut optimization based on mixed - integer programming ( MIP ) implementation .Our MIP approach utilizes O ( nB ) parameters and constraints . Using our proposed cutting planes , we can restrict the quantity of vertices uncovered during search significantly .As a effect , our algorithm runs faster than existing algorithms when the dimension d = 2 or 3 . For instance , if the dimension is two , then our algorithm solves instances with up to 1 million points within 10 minutes while prior best known performance are limited to 100 thousand points .",
        "rewrite_text": "We introduce a novel algorithm designed to address the half-space depth problem, a fundamental challenge in the field of computational geometry. The problem involves determining a point in a two-dimensional plane, defined by n integer-coordinate points constrained within a boundary B, that minimizes its distance to all other points. This issue has been extensively researched since its inception by Helly in the 1930s. In our work, we propose a branch-and-cut optimization technique that leverages mixed-integer programming (MIP) for its implementation. Our MIP framework incorporates O(nB) parameters and constraints, which allows for a more efficient search process. By employing strategically designed cutting planes, we significantly reduce the number of uncovered vertices during the search, enhancing the algorithm's performance. As a result, our approach demonstrates superior speed compared to existing algorithms, particularly in two-dimensional (d = 2) and three-dimensional (d = 3) scenarios. For example, in two dimensions, our algorithm can effectively solve instances with up to 1 million points within a mere 10 minutes, whereas the best-known previous methods were only capable of handling 100,000 points in the same timeframe. This advancement not only showcases the efficiency of our algorithm but also highlights its potential applications in various fields that require rapid and accurate geometric computations.",
        "ori-fast-z-score": -0.8944271909999159,
        "water-fast-z-score": 3.1304951684997055,
        "rewrite-fast-z-score": 0.4879500364742666
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Search for a kaonic nuclear state via $^4$He$(K^-, N)$ .\nAbstract:\nWe report on the search for a K-nuclear bound state in 4 He using the reaction $^4$He (K - , n). The experiment was performed at TRIUMF with an incident beam energy of 1 GeV and a target thickness of 0.5 cm. A total number of 2.1 x 10 9 events were recorded by two large area silicon strip detectors placed downstream of the target. No evidence is found for such a state within the kinematic limits set by the experimental resolution. Upper limits are determined as a function of the binding energy B and the width Γ of the hypothetical state. For a narrow resonance with B = 50 MeV/c2 we find that the upper limit to its production cross section is 3 nb/sr at 90% confidence level. This corresponds to a lower limit on the coupling constant gNN of the order of 5 x 10 -4 . \nThe results presented here represent one of the most stringent constraints yet obtained on this type of exotic nuclear structure. \n \n Keywords: Kaon nucleus interaction",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Search for a kaonic nuclear state via $ ^ 4 $ He $ ( K ^ - , N ) $ . Abstract : We report on the hunt for a K - atomic bound state in 4 He using the response $ ^ 4 $ He ( K - , k ) .The project was done at TRIUMF with an incident beam energy of 1 GeV and a target thickness of 0 . 5 centimetres . A total number of 2 . 1 x 10 9 episodes were collected by two huge area silicon strip detectors placed downstream of the target .No evidence is found for such a state within the kinematic limits established by the empirical resolution . Upper boundaries are chosen as a function of the binding energy B and the width Γ of the hypothetical state .For a small resonance with B = 50 MeV / c2 we find that the higher limit to its production cross area is 3 nb / sr at 90 % confidence rate . This corresponds to a smaller limitation on the interaction function gNN of the order of 5 x 10 - 4 .The results presented here represent one of the most stringent constraints ever achieved on this form of exotic nuclear configuration . Keywords : Kaon nucleus interaction",
        "rewrite_text": "Title: Search for a Kaonic Nuclear State via $^4$He $(K^-, N)$\n\nAbstract: In this study, we investigate the existence of a K^- atomic bound state within the nucleus of helium-4 ($^4$He) through the reaction $^4$He $(K^-, k)$. The research was conducted at the TRIUMF facility, utilizing an incident beam energy of 1 GeV and a target thickness of 0.5 centimeters. Our experimental setup included two large-area silicon strip detectors positioned downstream of the target, which successfully recorded a total of 2.1 x 10^9 events. Despite the extensive data collection, we found no evidence supporting the presence of a kaonic nuclear state within the kinematic limits defined by our empirical resolution. \n\nTo quantify our findings, we established upper limits on the production cross-section as a function of the binding energy (B) and the width (Γ) of the hypothesized state. Specifically, for a small resonance with a binding energy of B = 50 MeV/c², we determined that the upper limit for its production cross-section is 3 nb/sr at a 90% confidence level. This finding imposes a significant constraint on the interaction function gNN, estimated to be on the order of 5 x 10^-4. \n\nThe results of this investigation provide some of the most stringent limits to date on the existence of exotic nuclear configurations involving kaons. Our work contributes to the broader understanding of kaon-nucleus interactions and the potential for discovering new states of matter within nuclear physics. The implications of these findings may pave the way for future research into the nature of kaonic states and their role in nuclear interactions. \n\nKeywords: Kaon nucleus interaction",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 4.777777777777778,
        "rewrite-fast-z-score": 0.658504607868518
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Torsional oscillations of longitudinally inhomogeneous coronal loops .\nAbstract:\nWe study the torsional oscillations of an inhomogeneous magnetic flux tube with longitudinal density variation and uniform twist, which is embedded into a gravitationally stratified atmosphere. The governing equations are derived by using the thin-tube approximation for both equilibrium state and linear perturbations. We find that there exist two types of eigenmodes corresponding to different wave numbers along the field line. One type has its maximum amplitude at the footpoint while another one has it near the apex. For each mode we calculate the frequency as well as the damping time due to radiative loss. It turns out that the frequencies of these modes depend on the density contrast between the base and top of the loop. In addition, they also depend on the ratio of the Alfvén speed inside the loop to that outside. Finally, we discuss how our results can be applied to observations. Keywords: Torsional oscillation, Inhomogeneity",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Torsional oscillations of longitudinally inhomogeneous coronal loops . Abstract : We explore the torsional oscillations of an inhomogeneous magnetic flux tube with longitudinal density variation and uniform twist , which is embedded into a gravitationally stratified atmosphere .The governing equations are derived by using the narrow - tunnel method for both equilibrium state and linear perturbations . We see that there exist two forms of eigenmodes analogous to different wave numbers along the field line .One sort has its highest amplitude at the footpoint while another one has it near the apex . For each mode we estimate the frequency as well as the damping period caused to radiative loss .It turns out that the bandwidth of these modes differ on the density contrast between the base and top of the loop . In addition , they also rely on the proportion of the Alfvén speed inside the loop to that outside .Finally , we explain how our findings can be applied to observations . Keywords : Torsional oscillation , Inhomogeneity",
        "rewrite_text": "**Title:** Torsional Oscillations of Longitudinally Inhomogeneous Coronal Loops\n\n**Abstract:** This study investigates the torsional oscillations occurring in an inhomogeneous magnetic flux tube characterized by longitudinal density variations and a uniform twist, situated within a gravitationally stratified atmosphere. We derive the governing equations using the narrow-tunnel method, addressing both the equilibrium state and linear perturbations of the system. Our analysis reveals the existence of two distinct eigenmode forms, each corresponding to different wave numbers along the magnetic field lines. One mode exhibits its peak amplitude at the footpoint of the loop, while the other is maximized near the apex. For each identified mode, we calculate the oscillation frequency and the associated damping period, which arises due to radiative losses. Notably, we find that the bandwidth of these oscillatory modes is influenced by the density contrast between the base and the top of the coronal loop. Furthermore, the relationship between the Alfvén speed inside the loop and that outside also plays a critical role in determining the characteristics of these modes. Our findings have significant implications for observational studies, as they provide a framework for understanding the dynamics of coronal loops and their oscillatory behavior. By linking theoretical predictions with observational data, we aim to enhance the understanding of coronal loop structures and their oscillations in the context of solar physics. \n\n**Keywords:** Torsional oscillation, Inhomogeneity",
        "ori-fast-z-score": -0.9561828874675149,
        "water-fast-z-score": 3.771236166328254,
        "rewrite-fast-z-score": 1.5389675281277313
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Functional Methods in the Generalized Dicke Model .\nAbstract:\nWe study the generalized Dicke model with an arbitrary number N of two-level atoms interacting with one-mode radiation field, and show that it can be mapped to a spin-1/2 system by using the Holstein-Primakoff transformation. We then use the exact diagonalization method to calculate its ground state energy spectrum for different values of the coupling constant g and the number N . The results are compared with those obtained by other methods such as perturbation theory and numerical integration. It is found that our results agree well with previous ones when the coupling strength is small but deviate significantly from them if the coupling becomes strong. Finally we discuss some possible applications of this work. PACS: 03.65.Ud, 05.45.Mt, 11.10.Gh, 12.20.Dc, 13.25.Gv \nI. INTRODUCTIO N\nThe Dicke model  1  describes how many identical two-level atoms interact collectively with a single mode of electromagnetic field. In recent years there has been renewed interest in studying this model because of its potential application in quantum information processing  2  , quantum optics  3  , condensed matter physics  4  , etc.. For example, the collective spontaneous emission rate of the atomic ensemble depends on the total angular momentum J = N /2 (N being the number of atoms)  5  .\nIn fact, the Dicke model was originally proposed more than half century ago  6  . Since then various theoretical approaches have been developed to solve it  7 -10  . Among these approaches, the most successful one is probably the so-called HolsteinPrimakoff transformation  11  which maps the original problem into a spin-1/2 system  12  . This approach works very well at weak-coupling regime where the interaction between atom-field is relatively small. However, it fails completely at large-coupling limit since the mapping procedure breaks down due to the appearance of unphysical states  13  . Recently, several authors  14 -19  have tried to overcome this difficulty by introducing new transformations or approximations. Nevertheless, their solutions still suffer from certain drawbacks  20, 21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Functional Methods in the Generalized Dicke Model . Abstract : We explore the generalized Dicke model with an arbitrary number N of two - level atoms interacting with one - mode radiation field , and find that it can be mapped to a spin - 1 / 2 system by using the Holstein - Primakoff transformation .We then use the exact diagonalization technique to estimate its ground state energy spectrum for different values of the interaction function g and the number N . The results are compared with those achieved by other methods such as perturbation theory and mathematical integration .It is found that our findings agree well with previous ones when the interaction strength is tiny but deviate drastically from them if the interaction gets powerful . Finally we explain some possible users of this study .PACS : 03 . 65 . Ud , 05 . 45 . Mt , 11 . 10 . Gh , 12 . 20 . Dc , 13 . 25 . Gv I . INTRODUCTIO N The Dicke model 1 explains how many identical two - level atoms behave collectively with a single mode of electromagnetic field . In recent months there has been continued interest in understanding this model because of its potential application in quantum information processing 2 , quantum optics 3 , condensed matter science 4 , etc . . For instance , the collective spontaneous emission speed of the atomic ensemble depends on the total angular velocity J = N / 2 ( N being the number of atoms ) 5 .In reality , the Dicke approach was originally proposed more than quarter century ago 6 . Since then various theoretical methods have been constructed to solve it 7 - 10 .Among these method , the most popular one is probably the so - called HolsteinPrimakoff transformation 11 which maps the original problem into a spin - 1 / 2 system 12 . This method works very best at weak - interaction regime where the interaction between particle - field is fairly little .However , it fails totally at large - coupling limit since the mapping method splits down due to the appearance of unphysical states 13 . Recently , various literature 14 - 19 have tried to overcome this challenge by using new transformations or approximations .Nevertheless, their solutions still suffer from certain drawbacks  20, 21  .",
        "rewrite_text": "**Title: Functional Methods in the Generalized Dicke Model**\n\n**Abstract:** In this study, we investigate the generalized Dicke model, which describes the interaction between an arbitrary number \\( N \\) of two-level atoms and a single mode of radiation. By employing the Holstein-Primakoff transformation, we successfully map this model to a spin-\\( \\frac{1}{2} \\) system. Utilizing the exact diagonalization technique, we compute the ground state energy spectrum across various interaction strengths \\( g \\) and atom counts \\( N \\). Our results are juxtaposed with those obtained through alternative approaches, including perturbation theory and mathematical integration. We observe that our findings align closely with previous studies in the weak interaction regime; however, significant discrepancies arise as the interaction strength increases. This divergence underscores the limitations of conventional methods in capturing the dynamics of the system under strong coupling conditions. Additionally, we discuss potential applications of our research, particularly in the realms of quantum information processing, quantum optics, and condensed matter physics. The Dicke model, originally proposed over twenty-five years ago, has garnered renewed interest due to its implications for collective atomic behavior and spontaneous emission dynamics, which are influenced by the total angular momentum \\( J = \\frac{N}{2} \\). Despite the popularity of the Holstein-Primakoff transformation for weak interactions, it encounters challenges in the strong coupling regime, where unphysical states emerge. Recent literature has attempted to address these issues through novel transformations and approximations, yet these solutions still exhibit certain limitations. Our work contributes to the ongoing discourse by providing a comprehensive analysis of the generalized Dicke model and its implications for future research in quantum mechanics. \n\n**PACS:** 03.65.Ud, 05.45.Mt, 11.10.Gh, 12.20.Dc, 13.25.Gv",
        "ori-fast-z-score": -0.5551361100027009,
        "water-fast-z-score": 7.171804696775816,
        "rewrite-fast-z-score": 1.3821894809301762
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The weighted complexity and the determinant functions of graphs .\nAbstract:\nWe study the weighted complexity function W(G) for graphs G with n vertices, which is defined as the minimum number of edges in any n-vertex subgraph H such that H contains all cycles of length at most k (k = 3, ...,n). We prove upper bounds on this function by using the concept of the determinant of an adjacency matrix A associated to G. In particular we show that if A has no zero rows or columns then W(G) <= 2n-1. This bound can be improved when A satisfies some additional conditions. Finally, we give examples showing how our results are sharp. The weighted complexity function W(G;k) (k=3,...,n), introduced by Chartrand et al., measures the minimum number of edges needed to make every cycle of length up to k in a given graph G. It was shown recently that W(G;3)=n-2 for any connected triangle-free planar graph G. In this note we improve these results by proving that W(G;3))<=n-1 for any connected triangle-free plane graph G.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The weighted complexity and the determinant functions of graphs . Abstract : We explore the weighted complexity function W ( G ) for graphs G with n edges , which is characterized as the minimum amount of vertices in any k - vertex subgraph H such that H contains all cycles of width at most h ( h = 3 , . . . , k ) .We derive upper limits on this function by using the idea of the determinant of an adjacency vector A associated to G . In particular we find that if A has no zero columns or rows then W ( G ) < = 2n - 1 . This bound can be improved when A satisfies some additional conditions .Finally , we give examples demonstrating how our findings are sharp . The weighted complexity function W ( G ; h ) ( h = 3 , . . . , k ) , invented by Chartrand et al . , estimates the minimum amount of vertices necessary to make every cycle of width up to n in a given graph G . It was shown lately that W ( G ; 3 ) = n - 2 for any connected triangle - free planar graph G . In this note we enhance these results by proving that W ( G ; 3 ) ) < = n - 1 for any connected triangle - free plane graph G .",
        "rewrite_text": "Title: The Weighted Complexity and the Determinant Functions of Graphs\n\nAbstract: In this study, we investigate the weighted complexity function W(G) for graphs G characterized by n edges. This function is defined as the minimum number of vertices in any k-vertex subgraph H that encompasses all cycles with a width of at most h (where h ranges from 3 to k). We establish upper bounds for W(G) by leveraging the properties of the determinant of an adjacency vector A associated with the graph G. Notably, we demonstrate that if the adjacency vector A does not contain any zero columns or rows, then W(G) is constrained by the inequality W(G) ≤ 2n - 1. Furthermore, we show that this upper bound can be refined under certain additional conditions imposed on A. To illustrate the sharpness of our results, we provide specific examples that highlight the effectiveness of our findings. The weighted complexity function W(G; h) (for h = 3, ..., k), introduced by Chartrand et al., serves to estimate the minimum number of vertices required to ensure the presence of every cycle with a width up to n in the graph G. Recent research has established that for any connected triangle-free planar graph G, W(G; 3) equals n - 2. In this paper, we advance these findings by proving that for any connected triangle-free planar graph G, the inequality W(G; 3) ≤ n - 1 holds true. This enhancement not only refines our understanding of the weighted complexity function but also contributes to the broader discourse on graph theory and its applications.",
        "ori-fast-z-score": -2.03701381619181,
        "water-fast-z-score": 4.7699904600286205,
        "rewrite-fast-z-score": 0.6831300510639733
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Galactic dark matter as a bulk effect on the brane .\nAbstract:\nWe propose that galactic dark matter is an effective four-dimensional manifestation of extra dimensions, and we show how this can be realized in a simple model with one extra dimension compactified on S 1 /Z 2 . The fifth dimension has two 3-branes at its endpoints which are connected by a bulk scalar field. We find that the scalar field develops a kink profile along the fifth dimension due to the presence of a potential barrier between the two branes. This leads to a localized mass term for fermions living on the visible (3-)brane, which gives rise to a phenomenologically viable dark matter candidate. In addition, there exists another class of particles called Kaluza-Klein modes whose masses depend on the size of the extra dimension. These KK states have no tree-level interactions with Standard Model fields but they may contribute significantly to loop processes such as neutrino oscillations or proton decay. Finally, we discuss possible experimental signatures of our scenario.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Galactic dark matter as a bulk effect on the brane . Abstract : We suggest that galactic light matter is an efficient four - dimensional manifestation of extra dimensions , and we prove how this can be realized in a simple model with one extra dimension compactified on S 1 / Z 2 .The fifth dimension has two 3 - branes at its endpoints which are connected by a bulk scalar field . We see that the scalar field produces a kink profile along the fifth dimension owing to the presence of a potential barrier between the two branes .This leads to a localized mass term for fermions residing on the visible ( 3 - ) brane , which gives rise to a phenomenologically viable dark matter candidate . In addition , there exists another class of molecules known Kaluza - Klein modes whose masses vary on the size of the extra dimension .These KK states have no tree - level effects with Standard Model fields but they may contribute greatly to loop processes such as neutrino oscillations or proton decay . Finally , we explain possible experimental signatures of our scenario .",
        "rewrite_text": "Title: Galactic Dark Matter as a Bulk Effect on the Brane\n\nAbstract: In this study, we propose that the observable light matter within galaxies serves as a compelling four-dimensional representation of extra dimensions. We demonstrate how this concept can be effectively illustrated through a straightforward model that incorporates one additional dimension compactified on S1/Z2. In our framework, the fifth dimension is characterized by two three-dimensional branes positioned at its endpoints, which are interconnected by a bulk scalar field. The presence of this scalar field induces a kink profile along the fifth dimension, a consequence of a potential barrier situated between the two branes. This kink profile results in a localized mass term for fermions that inhabit the visible three-brane, thereby presenting a viable candidate for dark matter from a phenomenological standpoint. Furthermore, we identify a distinct category of particles known as Kaluza-Klein (KK) modes, whose masses are contingent upon the size of the extra dimension. While these KK states do not exhibit tree-level interactions with Standard Model fields, they may significantly influence loop processes, such as neutrino oscillations and proton decay. We also discuss potential experimental signatures that could arise from our proposed scenario, paving the way for future investigations into the implications of extra dimensions on galactic dark matter. Our findings contribute to the ongoing discourse in theoretical physics regarding the nature of dark matter and its relationship with higher-dimensional theories, offering insights that could enhance our understanding of the universe's fundamental structure.",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 3.9378076532410837,
        "rewrite-fast-z-score": 2.163657997282274
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nonlinear turbulent magnetic diffusion and effective drift velocity of large-scale magnetic field in a two-dimensional magnetohydrodynamic turbulence .\nAbstract:\nWe study the nonlinear evolution of large-scale magnetic fields (LSMFs) in two dimensions by using direct numerical simulations of incompressible magnetohydrodynamics with periodic boundary conditions. We find that LSMFs are generated spontaneously through inverse cascade processes, which is similar to three-dimensional MHD turbulence. However, we also observe some differences between 2D and 3D cases. In particular, the energy spectrum of LSMF has an exponential tail at large wave numbers instead of power-law behavior as observed for 3D case. The origin of this difference can be understood by considering the effect of magnetic helicity conservation on the dynamics of LSMF. Furthermore, we show that the effective drift velocity of LSMF depends strongly on its initial configuration. Finally, we discuss possible applications of our results to solar physics. PACS number(s): 47.27.Gs, 47.27.Gk, 52.35.Jm",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nonlinear turbulent magnetic diffusion and effective drift speed of large - scale magnetic force in a two - dimensional magnetohydrodynamic turbulence . Abstract : We research the nonlinear development of large - scale magnetic fields ( LSMFs ) in two dimensions by using direct numerical simulations of incompressible magnetohydrodynamics with periodic boundary parameters .We see that LSMFs are produced spontaneously through inverse cascade processes , which is analogous to three - dimensional MHD turbulence . However , we also observe some variations between 2D and 3D cases .In particular , the power spectrum of LSMF has an exponential tail at large wave numbers instead of power - law behavior as found for 3D case . The origin of this contrast can be understood by examining the impact of magnetic helicity protection on the dynamics of LSMF .Furthermore , we prove that the effective drift speed of LSMF varies strongly on its initial configuration . Finally , we explain possible applied of our findings to solar theory .PACS number(s): 47.27.Gs, 47.27.Gk, 52.35.Jm",
        "rewrite_text": "Title: Nonlinear Turbulent Magnetic Diffusion and Effective Drift Speed of Large-Scale Magnetic Force in Two-Dimensional Magnetohydrodynamic Turbulence\n\nAbstract: This study investigates the nonlinear evolution of large-scale magnetic fields (LSMFs) in a two-dimensional framework through direct numerical simulations of incompressible magnetohydrodynamics (MHD) under periodic boundary conditions. Our findings reveal that LSMFs can spontaneously emerge via inverse cascade processes, a phenomenon that bears resemblance to the behavior observed in three-dimensional MHD turbulence. However, notable differences between the two-dimensional and three-dimensional scenarios are identified. Specifically, the power spectrum of LSMFs exhibits an exponential decay at high wave numbers, contrasting with the power-law distribution typically observed in three-dimensional cases. This discrepancy can be attributed to the influence of magnetic helicity conservation on the dynamics governing LSMF behavior. Additionally, we demonstrate that the effective drift speed of LSMFs is significantly dependent on their initial configurations, highlighting the complexity of their evolution. The implications of our results extend to solar physics, where understanding the behavior of LSMFs is crucial for modeling solar magnetic phenomena. Our research contributes to a deeper comprehension of magnetohydrodynamic turbulence and its effects on large-scale magnetic structures, providing insights that may enhance theoretical frameworks in astrophysical contexts. PACS numbers: 47.27.Gs, 47.27.Gk, 52.35.Jm",
        "ori-fast-z-score": -0.562543950463012,
        "water-fast-z-score": 4.837877973981903,
        "rewrite-fast-z-score": 1.762817881041723
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the change of latitude of Arctic East Siberia at the end of the Pleistocene .\nAbstract:\nThe article presents new data on the paleogeography and geodynamics of the Russian Arctic in the late Quaternary period, based on the results of field studies conducted by the authors over the past decade. The study area is located between the Lena River to the west and the Kolyma River to the east (Fig.  1) . It includes the northern part of Yakutia, the southern part of Chukotka Autonomous Okrug, and the western part of Magadan Oblast. In this region, the authors studied more than 100 sites with deposits of loess-like sediments that accumulated during the last glacial cycle. These are mainly sandy silts with an admixture of gravel particles up to 5 mm in diameter; they contain numerous mollusk shells, bones of terrestrial mammals, and other remains of biota. Based on these materials, we reconstructed the history of climatic fluctuations in the study area since the Last Glacial Maximum (LGM) until today.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the shift of latitude of Arctic East Siberia at the end of the Pleistocene . Abstract : The essay presents new data on the paleogeography and geodynamics of the Russian Arctic in the last Quaternary period , based on the results of field research conducted by the authors over the previous decade .The study area is situated between the Lena River to the west and the Kolyma River to the east ( Fig . 1 ) .It includes the northern part of Yakutia , the northeastern part of Chukotka Autonomous Okrug , and the western area of Magadan Oblast . In this area , the authors discovered more than 100 sites with formations of loess - like sediments that eroded during the last glacial cycle .These are mainly sandy silts with an admixture of sandy particles up to 5 mm in width ; they contain many mollusk shells , fossils of terrestrial organisms , and other remains of biota . Based on these materials , we analyzed the history of climatic fluctuations in the study area since the Last Glacial Maximum ( LGM ) until today .",
        "rewrite_text": "Title: On the Shift of Latitude of Arctic East Siberia at the End of the Pleistocene\n\nAbstract: This article presents novel findings regarding the paleogeography and geodynamics of the Russian Arctic during the last Quaternary period, derived from extensive field research conducted by the authors over the past decade. The research focuses on a region located between the Lena River to the west and the Kolyma River to the east, encompassing the northern part of Yakutia, the northeastern section of Chukotka Autonomous Okrug, and the western area of Magadan Oblast. Throughout this region, the authors identified over 100 sites featuring loess-like sediment formations that have undergone erosion during the last glacial cycle. The predominant sediment types are sandy silts, which include sandy particles measuring up to 5 mm in diameter. These sediments are rich in mollusk shells, fossils of terrestrial organisms, and various other biological remnants. Utilizing these materials, the study investigates the climatic fluctuations that have occurred in the area from the Last Glacial Maximum (LGM) to the present day. The findings contribute to a deeper understanding of the environmental changes that have shaped Arctic East Siberia, highlighting the dynamic interplay between climatic shifts and geological processes during this critical period in Earth's history. The implications of this research extend beyond regional geology, offering insights into broader patterns of climate change and their potential impacts on biotic communities in Arctic environments.",
        "ori-fast-z-score": -2.6678918753996625,
        "water-fast-z-score": 3.395498750508662,
        "rewrite-fast-z-score": 0.7035264706814485
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Tilt-angle landscapes and temperature dependence of the conductance in biphenyl-dithiol single-molecule junctions .\nAbstract:\nWe report on electrical transport measurements through individual biphenyl dithiol molecules connected to gold electrodes by using scanning tunneling microscopy break-junction technique at room-temperature (RT) and low temperatures down to 4 K. The current–voltage characteristics show clear signatures for molecular conduction, such as Coulomb blockade peaks and negative differential resistance regions. We find that the junction conductance depends strongly on the tilt angle between the molecule backbone and the substrate normal. This is explained by an anisotropic coupling strength between the molecule and the metal contacts which leads to different transmission probabilities along the two main axes of the molecule. In addition we observe a strong temperature dependence of the junction conductance with a maximum around 50 K. These results are discussed within a model based on electron-phonon scattering processes. Biphenyl dithiol (BDT), one of the most studied organic semiconductors, has been used extensively in field-effect transistors1-5 and other electronic devices6-8 due to its high charge carrier mobility9-11. However, despite intensive research efforts12-17 only few studies have investigated the electrical properties of BDT-based single-molecule junctures18-20. Herein, we present detailed investigations of the electrical transport behavior of individual BDT molecules contacted via Au(111) surfaces by means of scanning tunneling microscopy breakjunction experiments21-23. Our data reveal pronounced features characteristic for molecular conduction24-26 including Coulomb blockade peaks27-29 and negative differential resistance30-32. Furthermore, our study reveals a strong influence of the molecular orientation relative to the substrate surface on the junction conductance33-35. Finally, we demonstrate a significant temperature dependent change of the junction conductance36-38.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Tilt - angle landscapes and heat dependence of the conductance in biphenyl - dithiol single - molecule junctions . Abstract : We report on electrical transport measurements through individual biphenyl dithiol molecules linked to gold electrodes by using scan tunneling microscopy break - junction technique at room - temperature ( RT ) and low temperatures down to 4 K . The current – voltage parameters show visible signatures for molecular conduction , such as Coulomb blockade spikes and negative integral resistance regions .We see that the junction conductance depends strongly on the tilt distance between the molecule backbone and the substrate normal . This is explained by an anisotropic interaction strength between the molecule and the metal links which results to different communication probabilities along the two principal axes of the molecule .In addition we study a weak thermal dependence of the junction conductance with a maximum around 50 K . These data are discussed within a theory based on electron - phonon absorption processes . Biphenyl dithiol ( BDT ) , one of the most studied organic semiconductors , has been used heavily in field - effect transistors1 - 5 and other electronic devices6 - 8 due to its high charge carrier mobility9 - 11 .However , despite intensive study efforts12 - 17 only few researchers have researched the electrical properties of BDT - based single - cell junctures18 - 20 . Herein , we present detailed investigations of the electrical travel dynamics of individual BDT atoms contacted via Au ( 111 ) surfaces by means of scanning tunneling microscopy breakjunction experiments21 - 23 .Our data reveal pronounced features characteristic for molecular conduction24 - 26 including Coulomb blockade peaks27 - 29 and negative differential resistance30 - 32 . Furthermore , our research reveals a large influence of the molecular orientation relative to the substrate surface on the junction conductance33 - 35 .Finally , we obtain a substantial heat dependent change of the junction conductance36 - 38 .",
        "rewrite_text": "We present a comprehensive study on the electrical transport properties of individual biphenyl dithiol (BDT) molecules connected to gold electrodes, utilizing the scanning tunneling microscopy break-junction technique. Our experiments were conducted at both room temperature and at low temperatures, down to 4 K. The current-voltage characteristics exhibit distinct features indicative of molecular conduction, including Coulomb blockade spikes and regions of negative differential resistance. Notably, we observe a significant dependence of junction conductance on the tilt angle between the molecular backbone and the substrate normal. This phenomenon can be attributed to the anisotropic interaction strength between the BDT molecules and the metal contacts, leading to varying probabilities of charge transport along the molecule's two principal axes.\n\nAdditionally, we investigate the thermal dependence of the junction conductance, which reveals a subtle maximum around 50 K. This behavior is interpreted within the framework of electron-phonon absorption processes, suggesting that thermal effects play a crucial role in the conduction mechanisms of these molecular junctions. BDT, recognized as one of the most extensively studied organic semiconductors, has been widely employed in field-effect transistors and other electronic applications due to its high charge carrier mobility. Despite the extensive research on BDT, there has been limited exploration of its electrical properties in single-molecule junctions.\n\nIn this work, we provide a detailed analysis of the electrical transport dynamics of individual BDT molecules in contact with Au(111) surfaces, revealing pronounced signatures of molecular conduction. Our findings highlight the significant impact of molecular orientation on junction conductance and underscore the importance of thermal effects in understanding the electrical behavior of BDT-based molecular devices. This research contributes to the growing body of knowledge on organic semiconductors and their potential applications in nanoscale electronic systems.",
        "ori-fast-z-score": 1.0215078369104984,
        "water-fast-z-score": 6.821430560638804,
        "rewrite-fast-z-score": 1.9233566230163088
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Localized Support for Injection Point Election in Hybrid Networks .\nAbstract:\nWe propose an algorithm to select the injection point in hybrid networks, which is based on local information and can be implemented with low overheads. The proposed algorithm has two phases. First, it elects one node as the injection point by using only local information. Second, if there are multiple nodes that have been elected as the injection points, then these nodes will negotiate among themselves to determine exactly one injection point. We prove that our algorithm always selects at least one node as the injection points when all nodes are reachable from each other. Furthermore, we show through simulations that our algorithm performs well even under various network conditions such as dynamic topologies or limited communication ranges. Keywords: Distributed system, Localization, Self-organization, Wireless sensor network (WSN), Data dissemination, Energy efficiency, Routing protocol, Location-based routing, Clustering, Load balancing, Traffic engineering, Internet service provider",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Localized Support for Injection Point Election in Hybrid Networks . Abstract : We suggest an algorithm to select the injection point in hybrid networks , which is based on local information and can be deployed with minimum overheads .The proposed algorithm has two phases . First , it elects one node as the injection point by using only local information .Second , if there are multiple nodes that have been chosen as the injection points , then these nodes will agree among themselves to choose exactly one injection point . We prove that our scheme always selects at least one node as the injection points when all nodes are reachable from each other .Furthermore , we prove through simulations that our algorithm performs better even under various network conditions such as dynamic topologies or restricted transmission ranges . Keywords : Distributed system , Localization , Self - organization , Wireless sensor network ( WSN ) , Data dissemination , Energy quality , Routing protocol , Location - based scheduling , Clustering , Load balancing , Traffic management , Internet service provider",
        "rewrite_text": "Title: Localized Support for Injection Point Election in Hybrid Networks\n\nAbstract: In this paper, we introduce a novel algorithm designed for the selection of injection points within hybrid networks, leveraging local information to minimize operational overhead. The algorithm operates in two distinct phases. In the initial phase, it identifies a single node as the injection point based solely on local data. In the subsequent phase, if multiple nodes are identified as potential injection points, these nodes engage in a consensus process to finalize the selection of one injection point. We demonstrate that our approach guarantees the election of at least one injection point, provided that all nodes within the network are mutually reachable. Additionally, we validate the efficacy of our algorithm through extensive simulations, which reveal its superior performance across a range of network scenarios, including dynamic topologies and limited transmission ranges. The findings underscore the algorithm's robustness and adaptability in varying conditions, making it a valuable contribution to the fields of distributed systems, localization, and self-organization in wireless sensor networks (WSNs). Our work has implications for data dissemination, energy management, routing protocols, location-based scheduling, clustering, load balancing, and traffic management, ultimately enhancing the operational efficiency of Internet service providers. The keywords associated with this research include distributed systems, localization, self-organization, wireless sensor networks, data dissemination, energy quality, routing protocols, location-based scheduling, clustering, load balancing, and traffic management.",
        "ori-fast-z-score": -0.7171371656006361,
        "water-fast-z-score": 3.299831645537222,
        "rewrite-fast-z-score": 1.7817416127494958
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  TrES Exoplanets and False Positives: Finding the Needle in the Haystack .\nAbstract:\nWe present an overview of our efforts to find planets around stars with high proper motions using data obtained by the TrES space telescope, which was launched on December 6, 2005. We have found that many of these systems are likely false positives due to blending between the target star and nearby fainter companions or background objects. In this talk we will discuss how we used photometric variability combined with radial velocity measurements to identify these false positive cases. We also describe some of the techniques we use for identifying new candidate exoplanetary systems based on their light curves alone. Finally, I will show you what happens when one tries to measure the mass of a planet orbiting such a fast moving star as HD 128598 (Proxima Centauri). This is part of my Ph.D thesis work at Harvard University under the supervision of Dr. Paul Butler. My research interests include finding extrasolar planets via direct imaging and transit methods, studying the atmospheres of transiting exoplanets, and searching for habitable worlds beyond our solar system.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : TrES Exoplanets and False Positives : Finding the Needle in the Haystack . Abstract : We present an overview of our work to find planets around stars with high proper motions utilizing information obtained by the TrES space telescope , which was launched on December 6 , 2005 .We have discovered that several of these systems are likely false positives due to mixing between the target star and distant fainter companions or background objects . In this talk we will explore how we using photometric variability coupled with radial speed measurements to identify these false positive cases .We addition define some of the methods we using for finding new likely exoplanetary systems according on their light curves alone . Finally , I will show you what happens when one attempts to measure the mass of a planet orbiting such a rapidly moving star as HD 128598 ( Proxima Centauri ) .This is part of my Ph . D doctoral research at Harvard University under the guidance of Dr . Paul Butler . My research interests cover finding extrasolar stars via direct scanning and transit methods , studying the atmospheres of transiting exoplanets , and searching for habitable worlds beyond our solar system .",
        "rewrite_text": "In this article, we provide a comprehensive overview of our research focused on identifying exoplanets around stars exhibiting high proper motions, utilizing data collected by the Trans-Atlantic Exoplanet Survey (TrES) space telescope, which was launched on December 6, 2005. Our findings indicate that a number of these stellar systems may be misidentified as exoplanets due to the confusion arising from the presence of distant, fainter companions or background objects. During this presentation, we will delve into our methodology, which combines photometric variability analysis with radial velocity measurements to effectively distinguish these false positive cases. Additionally, we will outline the techniques employed to discover new potential exoplanetary systems based solely on their light curves. A significant portion of our discussion will focus on the challenges encountered when attempting to measure the mass of a planet orbiting a rapidly moving star, specifically in the case of HD 128598 (Proxima Centauri). This research forms a crucial part of my Ph.D. dissertation at Harvard University, conducted under the mentorship of Dr. Paul Butler. My academic pursuits encompass the identification of extrasolar planets through direct scanning and transit observation methods, the investigation of the atmospheres of transiting exoplanets, and the exploration of potentially habitable worlds beyond our solar system. Through this work, we aim to enhance our understanding of exoplanet detection and characterization, ultimately contributing to the broader field of astrophysics and the search for life beyond Earth.",
        "ori-fast-z-score": -0.6469966392206304,
        "water-fast-z-score": 4.824506406770077,
        "rewrite-fast-z-score": -0.5883484054145521
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Instanton Induced Neutrino Majorana Masses in CFT Orientifolds with MSSM-like spectra .\nAbstract:\nWe study the possibility that instantons induce neutrino masses and mixings, which are compatible with current experimental data on neutrinos. We consider type IIB orientifold compactifications to four dimensions with intersecting D-branes at singularities. The Standard Model gauge group is realized by stacks of branes wrapping 3-cycles inside Calabi-Yau threefolds. In addition we include stacks of branes wrapped around 2-cycles corresponding to hidden sectors. These models can be engineered such that they have an MSSM-like spectrum. Instanton effects lead to corrections to the superpotential involving fermions localized on different stacks of branes. This leads to Majorana mass terms for right-handed neutrinos. We show how these results can be used to construct realistic string inspired models of leptogenesis. We also discuss possible phenomenological consequences of our scenario. Introduction: String theory provides many new avenues towards understanding physics beyond the Standard Model (SM). One interesting class of scenarios involves extra spatial dimensions where SM fields live on a 3-brane while gravity propagates into the bulk  1  . A particularly appealing feature of this setup is that it allows for TeV scale quantum gravity without conflicting with precision tests of general relativity  2  .\nIn recent years there has been much interest in studying supersymmetric extensions of the SM within the context of string theory  3  -  8  . Supersymmetry stabilizes the electroweak hierarchy problem  9  , predicts unification of all coupling constants  10  and offers solutions to other open problems like dark matter  11  or baryogenesis  12  . However, despite its successes as a theoretical framework, no direct evidence for SUSY exists so far  13  . It would therefore be very exciting if some of the predictions made by SUSY could be tested experimentally  14  .\nOne important question concerns the origin of neutrino masses  15  . While the seesaw mechanism  16  explains naturally small neutrino masses  17  , it requires additional particles not present in the minimal version of the SM  18  . An alternative approach consists in considering non-renormalizable operators induced by instantons  19  . Such contributions may arise when",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Instanton Induced Neutrino Majorana Masses in CFT Orientifolds with MSSM - like spectra . Abstract : We research the idea that instantons cause neutrino masses and mixings , which are compatible with current experimental evidence on neutrinos .We consider kind IIB orientifold compactifications to four dimensions with intersecting D - branes at singularities . The Standard Model gauge group is realized by stacks of branes wrapping 3 - cycles inside Calabi - Yau threefolds .In addition we provide stacks of branes folded around 2 - cycles corresponding to buried regions . These systems can be engineered such that they have an MSSM - like spectrum .Instanton effects lead to corrections to the superpotential involving fermions localized on various stacks of branes . This leads to Majorana mass words for right - handed neutrinos .We see how these results can be used to build real string inspired models of leptogenesis . We even discuss possible phenomenological consequences of our scenario .Introduction : String theory provides various new avenues towards studying theory beyond the Standard Model ( SM ) . One interesting class of scenarios involves extra spatial dimensions where SM fields reside on a 3 - brane while gravity propagates into the bulk 1 .A notably appealing feature of this configuration is that it allows for TeV scale quantum gravitational without conflicting with accuracy tests of general relativity 2 . In recent years there has been much interest in investigating supersymmetric extensions of the SM within the context of string theory 3 - 8 .Supersymmetry stabilizes the electroweak hierarchy problem 9 , predicts merging of all correlation constants 10 and provides solutions to other open problems like dark matter 11 or baryogenesis 12 . However , despite its successes as a conceptual framework , no formal evidence for SUSY appears so far 13 .It would therefore be very exciting if some of the estimates made by SUSY might be tested experimentally 14 . One important question concerns the origin of neutrino masses 15 .While the seesaw mechanism 16 explains naturally tiny neutrino masses 17 , it includes added particles not present in the reduced version of the SM 18 . An alternative approach consists in considering non - renormalizable operators generated by instantons 19 .Such contributions could occur when",
        "rewrite_text": "**Title:** Instanton-Induced Neutrino Majorana Masses in CFT Orientifolds with MSSM-like Spectra\n\n**Abstract:** In this study, we explore the hypothesis that instantons can generate neutrino masses and mixings that align with existing experimental data. Our focus is on type IIB orientifold compactifications to four dimensions, specifically utilizing intersecting D-branes situated at singularities. The Standard Model gauge group is realized through stacks of branes that wrap around 3-cycles within Calabi-Yau threefolds. Additionally, we introduce stacks of branes that are configured around 2-cycles, which correspond to hidden regions of the compactification. These configurations can be designed to yield a spectrum resembling that of the Minimal Supersymmetric Standard Model (MSSM). The effects of instantons result in modifications to the superpotential, which includes terms involving fermions localized on different stacks of branes. This mechanism facilitates the generation of Majorana mass terms for right-handed neutrinos. We demonstrate how these findings can be utilized to construct viable string-inspired models of leptogenesis, providing a framework for understanding the generation of matter-antimatter asymmetry in the universe. Furthermore, we discuss the potential phenomenological implications of our scenario, which may offer insights into the nature of neutrinos and their masses. \n\n**Introduction:** String theory presents novel pathways for exploring physics beyond the Standard Model (SM). A particularly intriguing class of models involves the existence of extra spatial dimensions, where SM fields are confined to a 3-brane while gravity propagates through the bulk. This setup allows for the possibility of TeV-scale quantum gravity without conflicting with the precision tests of general relativity. Recent years have seen a surge of interest in investigating supersymmetric extensions of the SM within the framework of string theory. Supersymmetry addresses the electroweak hierarchy problem, predicts the unification of coupling constants, and offers solutions to various unresolved issues such as dark matter and baryogenesis. However, despite its theoretical appeal, there is currently no experimental evidence supporting supersymmetry. This raises the prospect of testing some of its predictions in future experiments. A critical question in this context is the origin of neutrino masses. While the seesaw mechanism provides a natural explanation for the smallness of neutrino masses, it introduces additional particles not found in the minimal SM. An alternative approach involves considering non-renormalizable operators generated by instantons, which could play a significant role in this framework.",
        "ori-fast-z-score": 0.08192319205190406,
        "water-fast-z-score": 6.266171132537927,
        "rewrite-fast-z-score": 1.2649110640673518
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The remarkable X-ray spectrum of the Broad-Line Radio Galaxy 3C 445 .\nAbstract:\nWe present an analysis of the broadband (0.5-10 keV) X-ray spectrum of the radio galaxy 3C 445, using data obtained with XMM-Newton and Chandra observatories in 2001-2002 . The observed X-ray emission is dominated by a hard power-law component which can be fitted equally well either by thermal Comptonization or non-thermal inverse Compton scattering models. We find that both models require a large amount of cold matter to produce the soft excess below 1 keV. This suggests that there are two distinct components contributing to the X-ray emission - one associated with hot plasma and another related to cool gas clouds. In addition we detect several narrow absorption lines at energies corresponding to highly ionized species such as O vii , Ne ix , Mg xi and Si xiii . These features may originate in outflows driven by nuclear activity. Finally, we report on the detection of Fe Kα line at 6.4 keV produced by reflection off distant material.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The extraordinary X - ray signal of the Broad - Line Radio Galaxy 3C 445 . Abstract : We present an analysis of the broadband ( 0 . 5 - 10 keV ) X - ray bandwidth of the radio star 3C 445 , using data acquired with XMM - Newton and Chandra observatories in 2001 - 2002 .The observed X - ray radiation is dominated by a hard energy - law component which can be fit equally well either by mechanical Comptonization or non - thermal integral Compton absorption theories . We see that both models require a large amount of cold matter to produce the soft excess below 1 keV .This implies that there are two different components contributing to the X - ray radiation - one related with bright plasma and another linked to cool gas clouds . In addition we find various narrow absorbed lines at energies corresponding to strongly ionized species such as O vii , Ne ix , Mg xi and Si xiii .These features could occur in outflows driven by nuclear activity . Finally , we note on the observation of Fe Kα line at 6 . 4 keV generated by absorption off remote material .",
        "rewrite_text": "We present a comprehensive analysis of the broadband X-ray emissions (0.5 - 10 keV) from the Broad-Line Radio Galaxy 3C 445, utilizing data collected by the XMM-Newton and Chandra observatories during the years 2001 and 2002. Our findings reveal that the X-ray spectrum is predominantly characterized by a hard power-law component, which can be effectively modeled using either mechanical Comptonization or non-thermal integral Compton absorption theories. Both theoretical frameworks necessitate the presence of a significant amount of cold matter to account for the observed soft excess emission below 1 keV. This suggests the existence of two distinct components contributing to the X-ray output: one associated with luminous plasma and the other linked to cooler gas clouds. Furthermore, our analysis identifies several narrow absorption lines at energies indicative of highly ionized elements, including O VII, Ne IX, Mg XI, and Si XIII. These spectral features may arise from outflows driven by the active galactic nucleus. Additionally, we observe the Fe Kα line at 6.4 keV, which is attributed to absorption by distant material. This study enhances our understanding of the complex X-ray emission mechanisms in 3C 445 and highlights the interplay between hot plasma and cooler gas in the context of active galactic nuclei.",
        "ori-fast-z-score": -2.060839349277234,
        "water-fast-z-score": 4.960307567358167,
        "rewrite-fast-z-score": 0.6324555320336759
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Zgamma production and limits on anomalous ZZgamma and Zgammagamma couplings in ppbar collisions at sqrt(s) = 1.96 TeV .\nAbstract:\nWe report the first measurement of the cross section for the process ppbar -> Zgamma + X, where X is any number of additional particles produced along with the Zgamma boson.  The data were collected by the D0 experiment during Run II of Fermilab s Tevatron Collider between 2002 and 2007 using an integrated luminosity of 5.4 fb-1 . We measure the cross section to be 0.84 +/- 0.11 (stat.) +/- 0.10 (syst.) pb, which agrees well with next-to-leading-order perturbative QCD predictions. Using this result we set upper limits on possible anomalous trilinear gauge-boson coupling parameters. These results are also used to derive constraints on models that predict new heavy neutral vector bosons decaying into pairs of photons or gluons. In addition, these measurements provide important input for future searches for Higgs bosons decaying into two photons. \nPACS numbers: 11.30.Er, 12.60.Jv",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Zgamma production and limits on anomalous ZZgamma and Zgammagamma couplings in ppbar collisions at sqrt ( s ) = 1 . 96 TeV . Abstract : We report the first measurement of the cross area for the process ppbar - > Zgamma + X , where X is any number of added particles generated along with the Zgamma boson .The data were collected by the D0 study during Run II of Fermilab s Tevatron Collider between 2002 and 2007 utilizing an integrated luminosity of 5 . 4 fb - 1 . We estimate the cross area to be 0 . 84 + / - 0 . 11 ( stat . )+ / - 0 . 10 ( syst . ) pb , which accepts good with next - to - leading - order perturbative QCD estimates .Using this consequence we put upper limits on potential anomalous trilinear gauge - boson correlation parameters . These results are also used to derive restrictions on models that forecast young heavy neutral vector bosons decaying into pairs of photons or gluons .In addition , these measurements give important input for future investigations for Higgs bosons decaying into two photons . PACS codes : 11 . 30 . Er , 12 . 60 . Jv",
        "rewrite_text": "Title: Zγ Production and Constraints on Anomalous ZZγ and Zγγ Couplings in pp̄ Collisions at √s = 1.96 TeV\n\nAbstract: This study presents the inaugural measurement of the cross-section for the process pp̄ → Zγ + X, where X represents any additional particles produced alongside the Zγ boson. The data were collected by the D0 collaboration during Run II of Fermilab's Tevatron Collider from 2002 to 2007, with an integrated luminosity of 5.4 fb⁻¹. Our analysis yields an estimated cross-section of 0.84 ± 0.11 (stat.) ± 0.10 (syst.) pb, which is in good agreement with next-to-leading-order perturbative QCD predictions. Utilizing this measurement, we establish upper limits on potential anomalous trilinear gauge-boson coupling parameters, which are crucial for understanding the interactions between gauge bosons. Furthermore, these results provide significant constraints on theoretical models that predict the existence of heavy neutral vector bosons decaying into pairs of photons or gluons. The implications of our findings extend to future research on Higgs bosons, particularly those decaying into two photons, thereby contributing valuable insights into the broader context of particle physics. The results are relevant for ongoing investigations into the nature of fundamental interactions and the search for new physics beyond the Standard Model. PACS codes: 11.30.Er, 12.60.Jv.",
        "ori-fast-z-score": -1.270001270001905,
        "water-fast-z-score": 4.25,
        "rewrite-fast-z-score": 1.1322770341445956
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Studies of the temperature and frequency dependent impedance of an electroceramic functional oxide thermistor .\nAbstract:\nThe electrical properties of BaTiO3 ceramics are investigated in this work by means of impedance spectroscopy (IS) at different temperatures ranging between 25 °C to 250 °C, with frequencies varying from 1 kHz to 10 MHz. The results show that the resistance decreases as the temperature increases while the capacitance remains almost constant over the entire range of measurement. This behavior is explained on the basis of the hopping conduction mechanism which dominates the transport process across grain boundaries. \n \n Keywords: Impedance Spectroscopy, Thermal conductivity, Electrical resistivity, BaTiO3 ceramic. Introduction: In recent years there has been growing interest in developing high performance materials for use in electronic devices such as sensors  1  , transducers  2  , microelectronic circuits  3  . These applications require materials having low thermal conductivities  4  , large dielectric constants  5  , small dielectric losses  6  , and high Curie temperatures  7  .\nBaTiO3 is one of these promising materials because it exhibits ferroelectricity  8  , piezoelectricity  9  , pyroelectricity  10  , and photocatalytic activity  11  . It also shows good chemical stability  12  , biocompatibility  13  , optical transparency  14  , and relatively low cost  15  . However, its poor sinterability  16  limits its application  17  . To overcome this problem, several methods have been developed including mechanical alloying  18  , spark plasma sintering  19  , microwave assisted sintering  20  , hydrothermal synthesis  21  , sol-gel processing  22  , etc  23  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Studies of the temperature and frequency dependent impedance of an electroceramic structural oxide thermistor . Abstract : The electrical properties of BaTiO3 pottery are examined in this research by means of impedance spectroscopy ( IS ) at different conditions ranging between 25 °C to 250 °C , with speeds range from 1 kHz to 10 MHz .The results show that the resistance reduces as the temperature increases while the capacitance remains virtually constant over the entire range of measurement . This phenomenon is understood on the basis of the hopping conduction process which dominates the travel cycle across grain boundaries .Keywords : Impedance Spectroscopy , Thermal conductivity , Electrical resistivity , BaTiO3 ceramic . Introduction : In recent years there has been growing interest in building high quality devices for use in electronic systems such as sensors 1 , transducers 2 , microelectronic circuits 3 .These applications need materials having low heat conductivities 4 , large dielectric constants 5 , low dielectric losses 6 , and large Curie temperatures 7 . BaTiO3 is one of these promising compounds because it displays ferroelectricity 8 , piezoelectricity 9 , pyroelectricity 10 , and photocatalytic behavior 11 .It additionally shows excellent chemical transparency 12 , biocompatibility 13 , optical sensitivity 14 , and fairly lowest price 15 . However , its bad sinterability 16 limits its use 17 .To solve this situation , various methods have been proposed namely mechanical alloying 18 , flash laser sintering 19 , infrared assisted sintering 20 , hydrothermal synthesis 21 , sol - gel manufacturing 22 , etc 23 .",
        "rewrite_text": "**Title:** Investigating the Temperature and Frequency Dependent Impedance of Electroceramic Structural Oxide Thermistors\n\n**Abstract:** This study explores the electrical characteristics of BaTiO3 ceramics through impedance spectroscopy (IS), conducted under varying conditions from 25 °C to 250 °C and frequencies ranging from 1 kHz to 10 MHz. The findings reveal a notable decrease in resistance with increasing temperature, while capacitance remains relatively stable across the measured temperature spectrum. This behavior is attributed to the hopping conduction mechanism, which plays a crucial role in charge transport across grain boundaries. The implications of these results are significant for the development of advanced electronic devices, as they highlight the potential of BaTiO3 as a material for applications requiring specific thermal and electrical properties. \n\nIn recent years, there has been an increasing demand for high-performance materials in electronic systems, including sensors, transducers, and microelectronic circuits. These applications necessitate materials that exhibit low thermal conductivity, high dielectric constants, minimal dielectric losses, and elevated Curie temperatures. BaTiO3 stands out as a promising candidate due to its ferroelectric, piezoelectric, pyroelectric, and photocatalytic properties. Additionally, it offers excellent chemical stability, biocompatibility, and optical sensitivity, all at a relatively low cost. However, the material's poor sinterability poses challenges for its widespread application. To address this limitation, various techniques have been explored, including mechanical alloying, flash laser sintering, infrared-assisted sintering, hydrothermal synthesis, and sol-gel processing. This research contributes to the understanding of BaTiO3's electrical properties and its potential for enhancing the performance of electronic devices, paving the way for future innovations in the field of electroceramics.\n\n**Keywords:** Impedance Spectroscopy, Thermal Conductivity, Electrical Resistivity, BaTiO3 Ceramic.",
        "ori-fast-z-score": -2.1572774865200244,
        "water-fast-z-score": 6.538530488755173,
        "rewrite-fast-z-score": 2.155263624321299
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  VIMOS-VLT spectroscopy of the giant Ly-alpha nebulae associated with three z~2.5 radio galaxies .\nAbstract:\nWe present VLT/VIMOS integral field spectroscopic observations for three high-z (z ~ 2.5) radio galaxies, which are known to be surrounded by extended Lyman alpha halos. The main goal is to study their kinematics and physical conditions in order to understand how these objects evolve into massive elliptical galaxies at low redshifts. We find that all three sources show complex velocity fields dominated by rotation around an axis perpendicular to the radio jets. In addition we detect several components showing blueshifted velocities up to -500 km/s relative to systemic redshift. These features may represent outflows driven by AGN feedback or galactic winds powered by star formation activity. Finally, we measure the gas density distribution using  OII  emission lines and estimate the mass of ionized hydrogen surrounding each galaxy. Our results suggest that the observed Lyman alpha halos have masses ranging between 10^10 M_sol and 10^11 M_sol .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : VIMOS - VLT spectroscopy of the giant Ly - alpha nebulae associated with three z ~ 2 . 5 broadcast galaxies . Abstract : We report VLT / VIMOS integral field spectroscopic observations for three high - z ( z ~ 2 . 5 ) broadcast galaxies , which are known to be surrounded by extended Lyman alpha halos .The main goal is to study their kinematics and physical conditions in order to explain how these objects evolve into huge elliptical galaxies at low redshifts . We see that all three sources show complex momentum fields dominated by rotation around an axis adjacent to the radio jets .In addition we find various components showing blueshifted velocities up to - 500 km / s relative to systemic redshift . These features could indicate outflows driven by AGN feedback or galactic winds driven by galaxy formation activity .Finally , we measure the gas density density using OII absorption lines and estimate the mass of ionized hydrogen surrounding each galaxy . Our results propose that the studied Lyman alpha halos have masses vary between 10 ^ 10 M _ sol and 10 ^ 11 M _ sol .",
        "rewrite_text": "We present integral field spectroscopic observations conducted with the VLT/VIMOS for three high-redshift (z ~ 2.5) broadcast galaxies, each of which is enveloped by extensive Lyman-alpha nebulae. The primary objective of this study is to investigate the kinematics and physical conditions of these galaxies to better understand their evolution into massive elliptical galaxies observed at lower redshifts. Our analysis reveals that all three galaxies exhibit intricate momentum fields, predominantly characterized by rotation around an axis that is closely aligned with the orientation of their radio jets. Furthermore, we observe multiple components exhibiting blueshifted velocities reaching up to -500 km/s in relation to the systemic redshift. These velocity shifts may suggest the presence of outflows potentially driven by active galactic nucleus (AGN) feedback or galactic winds resulting from ongoing galaxy formation processes. Additionally, we utilize OII absorption lines to measure the gas density surrounding these galaxies and estimate the mass of ionized hydrogen in their vicinity. Our findings indicate that the Lyman-alpha halos associated with the galaxies possess masses ranging from approximately 10^10 M_sun to 10^11 M_sun. This research contributes to our understanding of the physical mechanisms at play in the evolution of high-redshift galaxies and their surrounding environments, shedding light on the processes that may lead to the formation of large elliptical galaxies in the later stages of cosmic history.",
        "ori-fast-z-score": 0.21566554640687682,
        "water-fast-z-score": 5.330017908890261,
        "rewrite-fast-z-score": 0.2847473987257497
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Interaction between a fast rotating sunspot and ephemeral regions as the origin of the major solar event on 2006 December 13 .\nAbstract:\nWe report an observation of a large coronal mass ejection (CME) associated with a halo-type flare that occurred in active region NOAA 10486 on 2006 December 13, which was observed by Solar TErrestrial RElations Observatory (STEREO). The CME speed is estimated to be about 1450 km/s at 1 AU using STEREO observations. We find that this CME originated from a complex magnetic structure consisting of two opposite-polarity flux systems connected by a filament channel. In addition, we found that there were several small-scale brightenings around the main sunspots before the onset of the flare/CME activity. These brightenings are identified as ephemeral regions (ERs), which are known to play important roles for triggering eruptions such as flares or CMEs. By analyzing high-resolution images taken by Hinode/SOT/SP, we show that one of these ERs interacted strongly with the surrounding magnetic field lines during its rapid rotation. This interaction caused reconnection between open and closed magnetic fields, resulting in the formation of a current sheet below the ER. Then, the eruption started when the current sheet became unstable due to the kink instability.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Interaction between a rapidly spinning sunspot and ephemeral regions as the origin of the significant solar activity on 2006 December 13 . Abstract : We report an observation of a large coronal mass ejection ( CME ) associated with a halo - class flare that occurred in active region NOAA 10486 on 2006 December 13 , which was seen by Solar TErrestrial RElations Observatory ( STEREO ) .The CME rate is predicted to be about 1450 km / s at 1 AU utilizing STEREO experiments . We see that this CME originated from a complex magnetic formation consisting of two opposite - polarity flux systems connected by a filament channel .In addition , we saw that there were several small - scale brightenings around the main sunspots before the beginning of the flare / CME activity . These brightenings are identified as ephemeral regions ( ERs ) , which are known to take key roles for triggering eruptions such as flares or CMEs .By analyzing large - resolution photos taken by Hinode / SOT / SP , we find that one of these ERs interacted highly with the nearby magnetic field lines during its rapid rotation . This coupling resulted reconnection between open and open magnetic fields , resulting in the formation of a current sheet below the ER .Then , the volcano started when the current sheet became unstable due to the kink instability .",
        "rewrite_text": "Title: Interaction between a Rapidly Spinning Sunspot and Ephemeral Regions as the Origin of Significant Solar Activity on December 13, 2006\n\nAbstract: This study presents an analysis of a notable coronal mass ejection (CME) linked to a halo-class flare that occurred in active region NOAA 10486 on December 13, 2006, as observed by the Solar TErrestrial RElations Observatory (STEREO). The CME was recorded to have a velocity of approximately 1450 km/s at a distance of 1 astronomical unit (AU), as predicted by STEREO observations. Our investigation reveals that the CME originated from a complex magnetic configuration characterized by two opposing polarity flux systems interconnected by a filament channel. Prior to the onset of the flare and CME activity, we observed multiple small-scale brightenings surrounding the primary sunspots. These brightenings are identified as ephemeral regions (ERs), which are recognized for their significant role in initiating solar eruptions, including flares and CMEs. Utilizing high-resolution images captured by the Hinode Solar Optical Telescope (SOT) and Spectro-Polarimeter (SP), we discovered that one of the ERs exhibited intense interaction with adjacent magnetic field lines during its rapid rotation. This interaction facilitated magnetic reconnection between open magnetic fields, leading to the formation of a current sheet beneath the ER. The eruption was triggered when this current sheet became unstable due to kink instability, resulting in the explosive release of energy characteristic of solar flares and CMEs. Our findings underscore the intricate dynamics between rapidly rotating sunspots and ephemeral regions, highlighting their critical contributions to solar activity and the mechanisms underlying solar eruptions. This research enhances our understanding of solar phenomena and their implications for space weather forecasting.",
        "ori-fast-z-score": -0.9649012813540153,
        "water-fast-z-score": 4.9819900360298925,
        "rewrite-fast-z-score": -1.0634101379502299
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Sparticle Spectra and LHC Signatures for Large Volume String Compactifications .\nAbstract:\nWe study the phenomenology of string compactifications with large extra dimensions, focusing on supersymmetric particles in the mass range accessible to current experiments at the Large Hadron Collider (LHC). We consider two classes of models that are motivated by recent developments in string theory: weakly coupled heterotic orbifolds and strongly coupled Type IIB orientifold constructions. In both cases we find that there is an interesting interplay between the Kaluza-Klein excitations associated with the extra dimensions and the lightest Standard Model superpartners. For example, in some regions of parameter space it may be possible to produce gluinos or squarks directly via Drell-Yan processes; alternatively, these states can decay into lighter Standard Model superpartners which then cascade down to the LSP neutralino. The resulting collider signatures depend sensitively on the details of the underlying model parameters as well as the number of extra dimensions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Sparticle Spectra and LHC Signatures for Large Volume String Compactifications . Abstract : We research the phenomenology of string compactifications with large extra dimensions , concentrating on supersymmetric particles in the mass range available to recent experiments at the Large Hadron Collider ( LHC ) .We consider two groups of models that are motivated by recent developments in string theory : weakly coupled heterotic orbifolds and strongly coupled Type IIB orientifold constructions . In both cases we find that there is an interesting interplay between the Kaluza - Klein excitations associated with the extra dimensions and the lightest Standard Model superpartners .For instance , in some regions of parameter room it could be possible to produce gluinos or squarks directly via Drell - Yan processes ; alternatively , these states can transition into lighter Standard Model superpartners which then cascade down to the LSP neutralino . The resulting collider signatures vary sensitively on the details of the underlying model variables as also as the number of added dimensions .",
        "rewrite_text": "In this article, we investigate the phenomenological implications of string compactifications that incorporate large extra dimensions, with a particular focus on supersymmetric particles whose masses fall within the range probed by recent experiments at the Large Hadron Collider (LHC). Our study is grounded in two distinct classes of models that have emerged from recent advancements in string theory: weakly coupled heterotic orbifolds and strongly coupled Type IIB orientifold constructions. We uncover a compelling interaction between the Kaluza-Klein excitations linked to the extra dimensions and the lightest superpartners of the Standard Model. Notably, in certain regions of the parameter space, it may be feasible to directly produce gluinos or squarks through Drell-Yan processes. Alternatively, these heavier states can decay into lighter Standard Model superpartners, which subsequently undergo cascade decays leading to the lightest supersymmetric particle (LSP), typically the neutralino. The collider signatures that arise from these processes are highly sensitive to the specific parameters of the underlying models, as well as the number of extra dimensions considered. Our findings suggest that the exploration of these signatures at the LHC could provide crucial insights into the nature of supersymmetry and the structure of string theory, potentially guiding future experimental searches and theoretical developments in high-energy physics. This work contributes to a deeper understanding of how large volume string compactifications can manifest in observable phenomena, thereby bridging the gap between theoretical predictions and experimental validation in the quest to uncover the fundamental constituents of the universe.",
        "ori-fast-z-score": 0.7385489458759964,
        "water-fast-z-score": 4.275930552470682,
        "rewrite-fast-z-score": 0.5773502691896257
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Variable Star One-shot Project, and its little child: Wikimbad .\nAbstract:\nThe Variable Star One-Shot project is an open-source software package for the analysis of astronomical data.  It was developed by members of the Harvard-Smithsonian Center for Astrophysics (CfA) in collaboration with researchers at other institutions around the world.   The goal of this project is to provide a single tool that can be used to analyze all types of astronomical data sets, including photometric time series, spectroscopic observations, images, etc., using state-of-the-art techniques such as image subtraction, cross correlation, period finding algorithms, spectral line fitting, etc.    This software has been released under the GNU General Public License v3.0 and is available on GitHub at: https://github.com/VariableStar/one-shot-astro .\nOne Shot Astro includes several tools which are useful for analyzing large amounts of astronomical data quickly and efficiently.   These include one-shot-datacleaner , which performs automated quality control checks on raw data files;   one-shot-mosaic , which creates mosaicked images from multiple dithered exposures;  one-shot-astrometry , which determines astrometric solutions for individual frames or entire mosaic images;    one-shot-photometry , which measures fluxes and/or magnitudes for stars across a field-of-view;    one-shot-pipeline , which automates the process of running these various tasks together into a pipeline;    one-shot-wikimapia , which allows users to create custom sky maps based on their own catalogs of objects.     In addition to these core packages, there are also many additional modules available through the one-shot-astro repository which allow users to perform more specialized analyses, such as:    one-shot-catalog , which provides access to a variety of different astrophysical databases via SQL queries;    one-shot-fastphot , which uses machine learning methods to measure stellar",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Variable Star One - shot Project , and its tiny child : Wikimbad . Abstract : The Variable Star One - Shot project is an open - source software tool for the analysis of astronomical data .It was developed by participants of the Harvard - Smithsonian Center for Astrophysics ( CfA ) in partnership with colleagues at other institutions around the world . The goal of this project is to provide a single technique that can be used to analyze all types of astronomical data sets , including photometric period series , spectroscopic observations , photographs , etc . , using state - of - the - art methods such as image subtraction , cross correlation , period finding methods , spectral line fitting , etc .This program has been released under the GNU General Public License v3 . 0 and is accessible on GitHub at : https : / / github . com / VariableStar / one - shot - astro . One Shot Astro includes several methods which are helpful for studying huge amounts of astronomical data easily and smoothly .These include one - shot - datacleaner , which performs automated quality control checks on raw data data ; one - shot - mosaic , which forms mosaicked images from multiple dithered exposures ; one - shot - astrometry , which determines astrometric solutions for individual frames or entire mosaic images ; one - shot - photometry , which estimates fluxes and / or magnitudes for planets across a field - of - view ; one - shot - pipeline , which automates the process of running these numerous tasks combined into a pipeline ; one - shot - wikimapia , which allows users to create custom skies mapping based on their own catalogs of items . In addition to these core programs , there are also many extra modules available through the one - shot - astro repository which allow users to conduct more sophisticated analyses , such as : one - shot - catalog , which offers connections to a variety of different astrophysical databases via SQL queries ; one - shot - fastphot , which uses computer learning techniques to measure stellar",
        "rewrite_text": "**Title:** The Variable Star One-Shot Project and Its Offshoot: Wikimbad\n\n**Abstract:** The Variable Star One-Shot Project is an innovative open-source software initiative designed for the comprehensive analysis of astronomical data. Developed collaboratively by researchers at the Harvard-Smithsonian Center for Astrophysics (CfA) and various international partners, this project aims to establish a unified methodology for analyzing diverse astronomical datasets, including photometric time series, spectroscopic data, and imaging. Utilizing advanced techniques such as image subtraction, cross-correlation, period-finding algorithms, and spectral line fitting, the project enhances the accessibility and efficiency of astronomical data analysis. The software is freely available under the GNU General Public License v3.0 and can be found on GitHub at https://github.com/VariableStar/one-shot-astro.\n\nOne Shot Astro encompasses a suite of tools designed to facilitate the processing of large volumes of astronomical data seamlessly. Key features include the one-shot-datacleaner, which automates quality control checks on raw datasets; the one-shot-mosaic, which generates composite images from multiple dithered exposures; and the one-shot-astrometry, which provides astrometric solutions for individual frames or entire mosaics. Additionally, the one-shot-photometry tool estimates fluxes and magnitudes for celestial objects across a specified field of view. The one-shot-pipeline automates the execution of these various tasks, streamlining the workflow for researchers. Furthermore, the one-shot-wikimapia feature enables users to create customized sky maps based on their own catalogs.\n\nBeyond these core functionalities, the one-shot-astro repository offers numerous supplementary modules that empower users to perform more complex analyses. These include the one-shot-catalog, which facilitates access to a range of astrophysical databases through SQL queries, and the one-shot-fastphot, which employs machine learning techniques to enhance stellar measurements. Collectively, these tools represent a significant advancement in the field of astronomical data analysis, making sophisticated methodologies more accessible to researchers worldwide.",
        "ori-fast-z-score": 0.9135002783911397,
        "water-fast-z-score": 7.945016530582732,
        "rewrite-fast-z-score": 1.6783627165933783
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  (Non) Gauge Invariance of Wilsonian Effective Actions in (Supersymmetric) Gauge Theories : A Critical Discussion .\nAbstract:\nWe discuss the gauge invariance properties of effective actions obtained by integrating out heavy degrees of freedom, such as quarks and gluons, within supersymmetric Yang-Mills theories. We show that these actions are not generally invariant under local gauge transformations unless certain conditions on their form are satisfied. These results have important consequences for the construction of gauge-invariant observables in supersymmetric gauge theories. They also provide an explanation why it is possible to construct nontrivial superpotentials even though supersymmetry does not allow any explicit breaking terms at tree level. Finally we argue that our findings can be used to resolve some puzzling features observed recently in lattice simulations of N = 1 supersymmetric QCD with four flavors. Supersymmetric Yang-Mills theories play an important role both in particle physics and string theory. Their low-energy dynamics is described by an effective action which contains all quantum corrections due to the integration over heavy fields like quarks or gluons. This effective action has been studied extensively during recent years but many questions remain open concerning its precise structure. One particular issue concerns the question whether this action is gauge invariant. It was shown already more than twenty years ago  1  that if one integrates out only massive fermions then the resulting effective action is indeed gauge invariant. However, when including also massive bosonic degrees of freedom there exist counterexamples where the effective action fails to be gauge invariant  2  . Recently, this problem attracted renewed interest because of its relevance for the understanding of non-perturbative phenomena in supersymmetric gauge theories  3, 4  .\nIn this work we study the gauge invariance properties systematically using functional methods. Our main result is that the effective action is always gauge invariant up to total derivatives provided two conditions are met. First, the effective action must contain no higher-order time-derivatives acting on the gauge field. Second, the coefficients appearing in front of the various operators in the effective action should satisfy certain relations. For example, they cannot depend explicitly on the gauge coupling constant g. If either condition is violated then the effective action will fail to be gauge",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : ( Non ) Gauge Invariance of Wilsonian Effective Actions in ( Supersymmetric ) Gauge Theories : A Critical Discussion . Abstract : We discuss the gauge invariance characteristics of effective actions obtained by combining out heavy degrees of liberty , such as quarks and gluons , within supersymmetric Yang - Mills theories .We see that these actions are not generally invariant under local gauge functions unless particular conditions on their form are fulfilled . These conclusions have important implications for the creation of gauge - invariant observables in supersymmetric gauge theories .They even show an reason why it is easy to build nontrivial superpotentials even though supersymmetry does not enable any explicit breaking terms at tree level . Finally we claim that our findings can be used to overcome some puzzling features detected lately in crystal simulations of N = 1 supersymmetric QCD with four flavors .Supersymmetric Yang - Mills theories play an important role both in particle science and string theory . Their low - energy dynamics is characterized by an efficient action which contains all quantum corrections due to the integration over heavy areas like quarks or gluons .This effective act has been studied thoroughly during recent seasons but numerous concerns remain open concerning its precise shape . One particular issue concerns the question whether this action is gauge invariant .It was shown still more than twenty years previously 1 that if one integrates out only massive fermions then the resulting effective act is indeed gauge invariant . However , when including also massive bosonic degrees of liberty there remain counterexamples where the effective act refuses to be gauge invariant 2 .Recently , this question attracted new interest because of its significance for the knowledge of non - perturbative processes in supersymmetric gauge fields 3 , 4 . In this research we study the gauge invariance effects systematically using functional technique .Our main consequence is that the effective act is usually gauge invariant up to total derivatives provided two conditions are fulfilled . First , the effective act must include no higher - order time - derivatives acting on the gauge field .Second , the coefficients appearing in front of the various operators in the effective act should satisfy certain relations . For instance , they cannot depend explicitly on the gauge interaction function g . If either situation is violated then the effective act will fail to be gauge",
        "rewrite_text": "**Title:** Non-Gauge Invariance of Wilsonian Effective Actions in (Supersymmetric) Gauge Theories: A Critical Discussion\n\n**Abstract:** This article examines the gauge invariance properties of effective actions derived from integrating out heavy degrees of freedom, such as quarks and gluons, within the framework of supersymmetric Yang-Mills theories. Our analysis reveals that these effective actions are not universally invariant under local gauge transformations unless specific conditions regarding their formulation are met. These findings have significant implications for the construction of gauge-invariant observables in supersymmetric gauge theories and provide insight into the ease of formulating nontrivial superpotentials, despite the absence of explicit breaking terms at tree level due to supersymmetry. Furthermore, we argue that our results can help address some of the perplexing phenomena observed in recent crystal simulations of N = 1 supersymmetric QCD with four flavors.\n\nSupersymmetric Yang-Mills theories are pivotal in both particle physics and string theory, with their low-energy dynamics encapsulated in an effective action that incorporates all quantum corrections from the integration over heavy fields. While the effective action has been extensively studied in recent years, many questions regarding its precise structure remain unresolved. A critical issue is the gauge invariance of this action. Previous studies have established that integrating out only massive fermions yields a gauge-invariant effective action. However, when massive bosonic degrees of freedom are also considered, counterexamples arise where the effective action fails to maintain gauge invariance.\n\nThis topic has garnered renewed interest due to its relevance for understanding non-perturbative phenomena in supersymmetric gauge theories. In this work, we systematically investigate the conditions under which the effective action retains gauge invariance using functional techniques. Our primary conclusion is that the effective action is generally gauge invariant up to total derivatives, contingent upon two key conditions: first, the absence of higher-order time derivatives acting on the gauge field, and second, the coefficients of the various operators in the effective action must adhere to specific relations, such as not depending explicitly on the gauge coupling constant g. If either of these conditions is not satisfied, the effective action will not exhibit gauge invariance.",
        "ori-fast-z-score": -1.906412495277593,
        "water-fast-z-score": 7.093342514033167,
        "rewrite-fast-z-score": -1.2924860661584994
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Zakharov simulation study of spectral features of on-demand Langmuir turbulence in an inhomogeneous plasma .\nAbstract:\nWe present results of numerical simulations of the nonlinear evolution of electrostatic waves excited by a localized source in a magnetized, collisionless plasma with nonuniform density and temperature profiles. The initial conditions are chosen to be close to those observed during experiments at the Large Plasma Device (LAPD) facility at UCLA. We find that the wave spectrum is dominated by two distinct branches corresponding to different types of waves: slow modes which propagate along magnetic field lines and fast modes which have oblique propagation angles relative to B. In addition we observe a number of other interesting phenomena such as generation of coherent structures, formation of shock fronts, etc., all of which can be explained within the framework of Zakharov s theory for Langmuir turbulence. \n \n Keywords: Nonlinear dynamics; Turbulence; Wave-particle interactions; Collisionless plasmas; LAPD; Fast-slow mode coupling; Waves",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Zakharov model study of spectral features of on - demand Langmuir turbulence in an inhomogeneous plasma . Abstract : We report findings of computational simulations of the nonlinear progression of electrostatic rays excited by a localized source in a magnetized , collisionless gas with nonuniform density and heat profiles .The initial conditions are chosen to be close to those observed during experiments at the Large Plasma Device ( LAPD ) laboratory at UCLA . We see that the wave spectrum is dominated by two different branches corresponding to different kinds of waves : slow modes which propagate along magnetic field lines and fast modes which have oblique propagation distances relative to B .In addition we study a number of other remarkable phenomena such as development of coherent complexes , creating of shock fronts , etc . , all of which can be described within the framework of Zakharov s concept for Langmuir turbulence . Keywords : Nonlinear dynamics ; Turbulence ; Wave - particle interactions ; Collisionless plasmas ; LAPD ; Fast - fast mode interaction ; Waves",
        "rewrite_text": "We present the results of computational simulations investigating the nonlinear evolution of electrostatic waves generated by a localized source within a magnetized, collisionless plasma characterized by nonuniform density and thermal profiles. The initial conditions for our simulations closely mirror those observed in experiments conducted at the Large Plasma Device (LAPD) laboratory at UCLA. Our findings reveal that the wave spectrum is predominantly influenced by two distinct branches of waves: slow modes that propagate along the magnetic field lines and fast modes that exhibit oblique propagation relative to the magnetic field (B). Furthermore, we explore several intriguing phenomena associated with this system, including the formation of coherent structures and the generation of shock fronts. These phenomena can be effectively analyzed within the framework of Zakharov's theory of Langmuir turbulence. Our study contributes to a deeper understanding of the complex dynamics present in inhomogeneous plasmas and highlights the significance of wave-particle interactions in such environments. The implications of our findings extend to various applications in plasma physics and astrophysics, where similar conditions may be encountered. This research underscores the importance of computational modeling in elucidating the intricate behaviors of plasma turbulence and provides a foundation for future experimental and theoretical investigations. \n\nKeywords: Nonlinear dynamics; Turbulence; Wave-particle interactions; Collisionless plasmas; LAPD; Fast-fast mode interaction; Waves.",
        "ori-fast-z-score": -1.5215349135496974,
        "water-fast-z-score": 3.9524197172898554,
        "rewrite-fast-z-score": 2.136828897185981
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Visible spectroscopic and photometric survey of Jupiter Trojans: final results on dynamical families .\nAbstract:\nWe present the first comprehensive study of visible spectroscopy for all known Jupiter trojans (JTs). We obtained high-resolution spectra with Subaru/HDS, Gemini/GNIRS, and Keck/NIRC-2 in order to determine their surface compositions. The sample includes 49 JTs including two new discoveries by our team. Our analysis shows that most JTs are S-complex asteroids or C-type asteroids. However, we found four objects which show unusual spectral features; one is an E-type asteroid, while three others have featureless red-sloped continuum. These objects may be primitive bodies such as carbonaceous chondrites. In addition, we find that some JTs belong to dynamically cold families. This suggests that these families were formed recently through catastrophic collisions among parent bodies. Finally, we discuss possible formation scenarios for JTs based on our findings. Keywords: Asteroids",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Visible spectroscopic and photometric studies of Jupiter Trojans : final conclusions on dynamical families . Abstract : We report the first comprehensive investigation of visible spectroscopy for all known Jupiter trojans ( JTs ) .We obtained high - resolution spectra with Subaru / HDS , Gemini / GNIRS , and Keck / NIRC - 2 in order to obtain their surface compositions . The sample comprises 49 JTs featuring two latest findings by our team .Our study shows that most JTs are S - complex asteroids or C - class asteroids . However , we identified four bodies which show peculiar spectral features ; one is an E - class asteroid , while three rest have featureless red - sloped continuum .These structures could be ancient bodies such as carbonaceous chondrites . In addition , we find that some JTs belong to dynamically cold families .This implies that these families were created recently through catastrophic collisions among parent bodies . Finally , we explain possible formation scenarios for JTs based on our findings .Keywords: Asteroids",
        "rewrite_text": "Title: Visible Spectroscopic and Photometric Studies of Jupiter Trojans: Final Conclusions on Dynamical Families\n\nAbstract: This study presents the first extensive analysis of visible spectroscopy conducted on all known Jupiter Trojans (JTs). Utilizing high-resolution spectral data obtained from advanced telescopes, including Subaru/HDS, Gemini/GNIRS, and Keck/NIRC-2, we aimed to elucidate the surface compositions of these celestial bodies. Our sample encompasses 49 JTs, incorporating two recent discoveries made by our research team. The results indicate that the majority of JTs fall into the S-complex or C-class categories of asteroids. Notably, we identified four unique bodies exhibiting unusual spectral characteristics: one is classified as an E-class asteroid, while the other three display a featureless red-sloped continuum. These distinctive features suggest that these bodies may be remnants of ancient materials, potentially akin to carbonaceous chondrites. Furthermore, our analysis reveals that certain JTs are part of dynamically cold families, suggesting that these families were formed relatively recently as a result of catastrophic collisions among their parent bodies. This finding has significant implications for our understanding of the evolution and formation of JTs. In conclusion, we discuss various formation scenarios for Jupiter Trojans based on our observations and analyses, contributing to the broader knowledge of asteroid dynamics and composition within our solar system. \n\nKeywords: Asteroids, Jupiter Trojans, Spectroscopy, Dynamical Families, Surface Composition.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.658135095031152,
        "rewrite-fast-z-score": 0.7181848464596079
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Rigorous Results for the Periodic Oscillation of an Adiabatic Piston .\nAbstract:\nWe consider the periodic oscillation of an adiabatic piston in contact with two ideal gases at different temperatures and pressures, separated by a rigid wall.  We prove that if the initial state is close to equilibrium then there exists a unique global solution which converges exponentially fast towards its limit cycle as time goes to infinity.  The proof relies on a combination of techniques from nonlinear analysis (Lyapunov functions) and kinetic theory (Boltzmann equation). In this work we study the dynamics of an adiabatic gas-piston system consisting of one-dimensional ideal gases confined between two walls. One of these walls is fixed while the other moves periodically according to some prescribed law. This problem has been studied extensively since the pioneering works of Maxwell  Max  , Boltzmann  Bol1  , and Sackur-Tetrode  Sac  . It was shown rigorously by Cercignani  Cerc  that under suitable assumptions on the motion of the piston, the solutions converge exponentially fast to their limit cycles. However, it seems difficult to extend his results beyond the case where the temperature difference across the piston remains small during all times. Here we show how to overcome this difficulty using new ideas based on Lyapunov functions combined with estimates coming from kinetic theory.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Rigorous Results for the Periodic Oscillation of an Adiabatic Piston . Abstract : We consider the periodic oscillation of an adiabatic piston in contact with two ideal gases at different temperatures and pressures , separated by a rigid wall .We prove that if the first state is close to equilibrium then there exists a unique global solution which converges exponentially rapidly towards its limit cycle as time went to infinity . The proof uses on a combination of techniques from nonlinear analysis ( Lyapunov functions ) and kinetic theory ( Boltzmann integral ) .In this study we study the dynamics of an adiabatic gas - cylinder structure comprised of one - dimensional ideal molecules confined between two walls . One of these barriers is fixed while the other moves periodically due to some prescribed law .This problem has been studied frequently since the pioneering works of Maxwell Max , Boltzmann Bol1 , and Sackur - Tetrode Sac . It was shown rigorously by Cercignani Cerc that under suitable assumptions on the movement of the piston , the solutions converge exponentially rapidly to their limit cycles .However , it appears hard to limit his results beyond the case where the temperature difference across the piston remains tiny during all periods . Here we prove how to overcome this trouble using new concepts relying on Lyapunov distributions combined with projections come from kinetic theory .",
        "rewrite_text": "Title: Rigorous Results for the Periodic Oscillation of an Adiabatic Piston\n\nAbstract: This article investigates the periodic oscillation of an adiabatic piston that interfaces with two ideal gases maintained at distinct temperatures and pressures, separated by a rigid barrier. We establish that when the initial state is sufficiently close to equilibrium, there exists a unique global solution that converges exponentially fast to its limit cycle as time progresses towards infinity. Our proof employs a blend of methodologies from nonlinear analysis, specifically Lyapunov functions, and kinetic theory, particularly the Boltzmann integral. The focus of this research is on the dynamics of a gas-cylinder system characterized by one-dimensional ideal molecules confined between two walls, where one wall is stationary while the other oscillates periodically according to a defined law. This problem has been a subject of extensive study since the foundational contributions of Maxwell, Boltzmann, and Sackur-Tetrode. Previous work by Cercignani demonstrated that, under certain conditions regarding the piston's motion, the solutions exhibit exponential convergence to their limit cycles. However, extending these results has proven challenging, particularly when the temperature differential across the piston remains minimal throughout the oscillation periods. In this study, we present a novel approach to address this limitation by introducing new concepts that integrate Lyapunov distributions with projections derived from kinetic theory. Our findings not only enhance the understanding of the system's behavior under varying conditions but also provide a robust framework for analyzing the dynamics of adiabatic processes involving ideal gases. This work contributes to the broader field of thermodynamics and kinetic theory, offering insights that could inform future research and applications in related areas.",
        "ori-fast-z-score": 0.09950371902099892,
        "water-fast-z-score": 5.4193110299036125,
        "rewrite-fast-z-score": 1.30066495428618
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Absolute Calibration and Characterization of the Multiband Imaging Photometer for Spitzer. II. 70 micron Imaging .\nAbstract:\nWe present absolute calibration results on the MIPS 24, 70, and 160 m bands obtained with observations of Neptune in its southern winter hemisphere. We find that our photometric model is accurate to better than 5% over most of the field-of-view (FOV) at all three wavelengths. The uncertainty in the absolute flux scale is dominated by uncertainties in the Neptune models used as calibrators. These are estimated to be less than 10% across each bandpass. In addition we have characterized the detector response function using data taken during spacecraft testing prior to launch. This characterization has been incorporated into the final processing pipeline which will produce calibrated images for science use. Finally, we show how these results can be combined with those presented in Paper I to provide an overall estimate of the accuracy of the MIPS instrument. Keywords: Space Science Instrumentation, Infrared Space Observatory, Spitzer Space Telescope, MIPS",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Absolute Calibration and Characterization of the Multiband Imaging Photometer for Spitzer.II.70 micron Imaging . Abstract : We report absolute calibration results on the MIPS 24 , 70 , and 160 m bands collected with observations of Neptune in its southern winter hemisphere .We see that our photometric model is accurate to good than 5 % over most of the field - of - view ( FOV ) at all three wavelengths . The uncertainty in the absolute flux range is dominated by uncertainties in the Neptune models used as calibrators .These are estimated to be less than 10 % across each bandpass . In addition we have characterized the detector response function using data taken during spacecraft testing previous to launch .This characterization has been inserted into the finished processing pipeline which will generate calibrated images for research use . Finally , we show how these results can be merged with those provided in Paper I to provide an overall estimate of the accuracy of the MIPS instrument .Keywords: Space Science Instrumentation, Infrared Space Observatory, Spitzer Space Telescope, MIPS",
        "rewrite_text": "Title: Absolute Calibration and Characterization of the Multiband Imaging Photometer for Spitzer: 70 Micron Imaging\n\nAbstract: In this study, we present the results of absolute calibration for the Multiband Imaging Photometer (MIPS) at 24, 70, and 160 micron wavelengths, utilizing observations of Neptune during its southern winter season. Our findings indicate that the photometric model achieves an accuracy exceeding 5% across the majority of the field of view (FOV) for all three wavelengths. The primary source of uncertainty in the absolute flux measurements arises from the models of Neptune employed as calibration references, with estimated uncertainties remaining below 10% for each bandpass. Furthermore, we have thoroughly characterized the detector response function using data acquired during the spacecraft's pre-launch testing phase. This characterization has been integrated into the final processing pipeline, enabling the generation of calibrated images for subsequent research applications. Additionally, we discuss how these calibration results can be combined with findings presented in Paper I, allowing for a comprehensive assessment of the overall accuracy of the MIPS instrument. This work contributes significantly to the understanding and reliability of infrared measurements obtained by the Spitzer Space Telescope, enhancing its utility for space science research. \n\nKeywords: Space Science Instrumentation, Infrared Space Observatory, Spitzer Space Telescope, MIPS",
        "ori-fast-z-score": 1.524001524002286,
        "water-fast-z-score": 5.08000508000762,
        "rewrite-fast-z-score": 0.9058216273156765
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Resonant spin polarization in a two-dimensional hole gas: Effect of the Luttinger term, structural inversion asymmetry and Zeeman splitting .\nAbstract:\nWe study resonant spin polarization (RSP) in a two-dimensional hole gas with Rashba spin-orbit interaction by solving the Kohn-Sham equations within density functional theory. We show that RSP is strongly affected by the presence of the Luttinger parameter, which describes the strength of electron-electron interactions. In particular we find that for large values of the Luttinger parameters the magnitude of RSP decreases significantly due to an increase in the effective mass of holes. Furthermore, we demonstrate that RSP can be controlled by applying external electric fields perpendicular to the plane of the 2D hole gas. Finally, we discuss how our results are related to recent experiments on GaAs quantum wells. The effect of the Luttinger terms, structural inversion asymmetry (SIA), and Zeeman splitting on resonant spin polarization (RS P ) has been studied using density functional theory. It was found that RS P is suppressed when the Luttinger parameter increases because it leads to larger effective masses. Moreover, it was shown that RS P can be tuned by applying external electric fields normal to the plane of the two-dimensional hole gas. Our results were compared to experimental data obtained recently on GaAs quantum wells. \n \n Resonant spin polarization (R SP ), i.e., the generation of a nonequilibrium spin population at zero magnetic field via optical excitation into a heavy-hole exciton resonance, has attracted considerable interest over the past years  1–3  . This phenomenon occurs if the energy difference between the conduction band minimum and the valence band maximum lies below the photon energy of the exciting laser light  4  , as illustrated schematically in Fig. 1(a). Due to this condition, electrons excited into the conduction band have a finite probability of being scattered back into the valence band before they relax radiatively or nonradiatively  5  . If these electrons return to their original state after scattering, then they will carry away angular momentum  6  . As a result, the total angular momentum of the system becomes imbalanced  7   .\n \n \n Recently, several groups reported measurements of R SP  8 –10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Resonant spin polarization in a two - dimensional hole gas : Effect of the Luttinger term , structural inversion asymmetry and Zeeman splitting . Abstract : We research resonant spin polarization ( RSP ) in a two - dimensional hole gas with Rashba spin - orbit interaction by solving the Kohn - Sham equations within density functional theory .We see that RSP is strongly altered by the presence of the Luttinger parameter , which explains the strength of electron - atom bonding . In particular we find that for large values of the Luttinger parameters the magnitude of RSP decreases dramatically due to an increase in the effective mass of holes .Furthermore , we prove that RSP can be regulated by using external electric forces perpendicular to the plane of the 2D hole gas . Finally , we explain how our findings are related to recent experiments on GaAs quantum wells .The impact of the Luttinger terms , structural inversion asymmetry ( SIA ) , and Zeeman splitting on resonant spin polarization ( RS P ) has been studied utilizing density functional theory . It was shown that RS P is suppressed when the Luttinger parameter grows because it leads to larger effective masses .Moreover , it was shown that RS P can be tuned by using external electric forces regular to the plane of the two - dimensional hole gas . Our results were compared to experimental evidence derived recently on GaAs quantum wells .Resonant spin polarization ( R SP ) , i . e . , the generation of a nonequilibrium spin population at zero magnetic field via optical excitation into a light - hole exciton resonance , has garnered considerable interest over the previous years 1 – 3 . This phenomenon occurs if the power change between the conduction band minimum and the valence band maximum falls below the photon energy of the exciting laser light 4 , as shown schematically in Fig .1 ( a ) . Due to this situation , electrons excited into the conduction band have a finite probability of being dispersed returned into the valence band before they relax radiatively or nonradiatively 5 .If these ions return to their previous state after absorption , then they will lift away angular velocity 6 . As a result , the total angular velocity of the system gets imbalanced 7 .Recently , various groups reported measurements of R SP 8 – 10 .",
        "rewrite_text": "In this study, we investigate the phenomenon of resonant spin polarization (RSP) in a two-dimensional hole gas characterized by Rashba spin-orbit interaction, employing density functional theory to solve the Kohn-Sham equations. Our findings reveal that the presence of the Luttinger parameter significantly influences RSP, which is indicative of the strength of electron-atom bonding. Notably, we observe that as the Luttinger parameter increases, the magnitude of RSP experiences a substantial decline, attributed to the corresponding rise in the effective mass of holes. Additionally, we demonstrate that RSP can be effectively manipulated through the application of external electric fields oriented perpendicular to the plane of the two-dimensional hole gas. \n\nWe further elucidate the implications of our results in the context of recent experimental studies conducted on GaAs quantum wells, where the effects of the Luttinger terms, structural inversion asymmetry (SIA), and Zeeman splitting on RSP have been explored. Our analysis indicates that an increase in the Luttinger parameter leads to a suppression of RSP due to the enhancement of effective masses. Moreover, we establish that RSP can be tuned via external electric forces applied parallel to the plane of the two-dimensional hole gas, providing a pathway for experimental realization. \n\nResonant spin polarization, defined as the generation of a nonequilibrium spin population at zero magnetic field through optical excitation into a light-hole exciton resonance, has attracted significant attention in recent years. This phenomenon is contingent upon the energy difference between the conduction band minimum and the valence band maximum being less than the photon energy of the incident laser light. Consequently, electrons excited into the conduction band possess a finite probability of returning to the valence band before undergoing radiative or nonradiative relaxation, leading to an imbalance in the total angular momentum of the system. Recent measurements of RSP by various research groups underscore the relevance of our findings in advancing the understanding of spin dynamics in low-dimensional systems.",
        "ori-fast-z-score": 0.38691161626706844,
        "water-fast-z-score": 6.442505906317911,
        "rewrite-fast-z-score": 2.048079801297601
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Interaction of Supernova Ejecta with Nearby Protoplanetary Disks .\nAbstract:\nWe present the results of hydrodynamic simulations that show how supernova ejecta can interact with nearby protoplanetary disks and produce observable signatures in their infrared emission. We find that, depending on disk properties (mass, radius), the interaction may lead to an increase or decrease in the total luminosity emitted by the system at near-infrared wavelengths. The effect is strongest for massive disks around young stars; it decreases rapidly as the mass ratio between the star and its disk decreases. \n \n In addition, we find that the interaction leads to significant changes in the temperature distribution within the disk. These effects are most pronounced when the disk is relatively close to the supernova progenitor - less than 100 AU away. For more distant systems, the impact of the supernova blast wave becomes negligible. Finally, our models suggest that the observed excesses in mid-infrared flux detected towards some T Tauri stars could be due to such interactions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Interaction of Supernova Ejecta with Nearby Protoplanetary Disks . Abstract : We present the results of hydrodynamic simulations that demonstrate how supernova ejecta can interact with nearby protoplanetary disks and produce observable signatures in their infrared absorption .We see that , depending on disk properties ( mass , diameter ) , the interaction may contribute to an increase or decrease in the total luminosity generated by the system at near - infrared wavelengths . The phenomenon is greatest for huge disks around young galaxies ; it decreases quickly as the mass ratio between the star and its disk decreases .In addition , we find that the interaction results to significant variations in the temperature distribution within the disk . These effects are most pronounced when the disk is fairly nearby to the supernova progenitor - less than 100 AU away .For more distant systems , the impact of the supernova blast wave grows negligible . Finally , our calculations suggest that the seen excesses in middle - infrared flux detected towards some T Tauri stars could be due to such interactions .",
        "rewrite_text": "We present a comprehensive analysis of hydrodynamic simulations that explore the interaction between supernova ejecta and adjacent protoplanetary disks, revealing significant implications for observable infrared signatures. Our findings indicate that the nature of this interaction is heavily influenced by the characteristics of the protoplanetary disks, including their mass and diameter. Specifically, we observe that the interaction can lead to either an increase or a decrease in the total luminosity emitted by the system at near-infrared wavelengths. This effect is particularly pronounced in massive disks surrounding young galaxies, with a rapid decline in impact as the mass ratio between the central star and its disk diminishes.\n\nMoreover, our simulations demonstrate that the interaction between supernova ejecta and protoplanetary disks induces notable alterations in the temperature distribution within the disks. These temperature variations are most significant when the disk is located within 100 astronomical units (AU) of the supernova progenitor, while the influence of the supernova blast wave becomes negligible for more distant disks. \n\nOur results also suggest a potential explanation for the observed excesses in middle-infrared flux associated with certain T Tauri stars, which may be attributed to these interactions. This research enhances our understanding of the complex dynamics between supernova events and the formation of planetary systems, providing valuable insights into the processes that shape the early stages of star and planet formation in the universe.",
        "ori-fast-z-score": 0.22360679774997896,
        "water-fast-z-score": 4.695742752749558,
        "rewrite-fast-z-score": 1.2809280616135812
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Unveiling the broad band X-ray continuum and iron line complex in Mkr 841 .\nAbstract:\nWe present an analysis of archival XMM-Newton data for the Seyfert 1 galaxy, Mkr841 (NGC 4151). We find that the soft excess emission is well described by a blackbody component with kT = 0.16 keV and luminosity LBB ~ 1043 erg s-1. The hard X-ray spectrum can be fitted either by a power law or Compton reflection model. In both cases we detect strong relativistic Fe Kα lines at 6.4-6.7 keV which are broadened to FWHM ~ 1000 km/sec. These results suggest that there may exist two distinct regions where the accretion disk interacts with the central supermassive black hole. One region produces the soft excess via thermal reprocessing while another one gives rise to the hard X-ray emission through non-thermal processes such as inverse Compton scattering and/or Compton reflection.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Unveiling the broad band X - ray continuum and iron line complex in Mkr 841 . Abstract : We report an assessment of archival XMM - Newton data for the Seyfert 1 galaxy , Mkr841 ( NGC 4151 ) .We see that the soft excess emission is well described by a blackbody element with kT = 0 . 16 keV and luminosity LBB ~ 1043 erg s - 1 . The soft X - ray spectrum can be fit either by a power law or Compton absorption theory .In both cases we find strong relativistic Fe Kα bands at 6 . 4 - 6 . 7 keV which are broadened to FWHM ~ 1000 kilometers / sec . These data suggest that there may arise two separate areas where the accretion disk interacts with the main supermassive black hole .One region releases the soft excess via thermal reprocessing while another one takes rise to the hard X - ray radiation through non - thermal processes such as inverse Compton absorption and / or Compton reflection .",
        "rewrite_text": "We present a comprehensive analysis of archival XMM-Newton observations of the Seyfert 1 galaxy Mkr 841 (NGC 4151), focusing on the broad band X-ray continuum and the iron line complex. Our findings reveal that the soft excess emission in the X-ray spectrum is effectively modeled by a blackbody component with a temperature of kT = 0.16 keV and a luminosity of approximately LBB ~ 10^43 erg s^-1. The soft X-ray spectrum can be accurately described using either a power law or Compton absorption models. Notably, both approaches yield the presence of prominent relativistic Fe Kα lines in the energy range of 6.4 to 6.7 keV, exhibiting significant broadening with a full width at half maximum (FWHM) of around 1000 kilometers per second. These observations imply the existence of two distinct regions within the accretion disk that interact with the central supermassive black hole. One region is responsible for generating the soft excess through thermal reprocessing mechanisms, while the other contributes to the production of hard X-ray radiation via non-thermal processes, including inverse Compton scattering and/or Compton reflection. This duality in emission processes provides valuable insights into the complex dynamics of accretion in active galactic nuclei and enhances our understanding of the physical conditions surrounding supermassive black holes. Our results underscore the importance of high-resolution X-ray spectroscopy in unraveling the intricate interplay between the accretion disk and the black hole, paving the way for future investigations into the nature of X-ray emissions in Seyfert galaxies.",
        "ori-fast-z-score": -1.5,
        "water-fast-z-score": 4.0,
        "rewrite-fast-z-score": 0.8620436566990363
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Accreting Neutron Stars in Low-Mass X-Ray Binary Systems .\nAbstract:\nThe discovery of the first X-ray pulsar, Scorpius X1 (Sco-X1), by Giacconi et al. (1962) opened up an exciting new field for astrophysics and led to the development of many important concepts such as accretion disks around compact objects.  The study of these systems has been revolutionized with the launch of Chandra and XMM-Newton observatories which have allowed us to probe their physical properties on unprecedented spatial scales.   In this review we will discuss some recent results obtained using these satellites that shed light on how neutron stars are formed and evolve within low-mass binary systems. We will also present our current understanding of the physics behind the formation of relativistic jets observed in several classes of X-ray binaries. Finally, we will briefly describe the prospects offered by future missions like XEUS or Constellation-X for studying these fascinating sources. Keywords: Accretion disk - Compact object - Relativistic jet -X-ray binary",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Accreting Neutron Stars in Low - Mass X - Ray Binary Systems . Abstract : The observation of the first X - ray pulsar , Scorpius X1 ( Sco - X1 ) , by Giacconi et al .( 1962 ) opened up an exciting new area for astrophysics and led to the development of several important concepts such as accretion disks around compact objects . The investigation of these systems has been revolutionized with the launch of Chandra and XMM - Newton observatories which have permitted us to probe their physical properties on unprecedented spatial scales .In this review we will explore some latest findings obtained using these satellites that shed light on how neutron galaxies are created and evolve within lowest - mass binary complexes . We will also discuss our latest understanding of the physics behind the formation of relativistic jets discovered in multiple types of X - ray binaries .Finally , we will briefly outline the possibilities offered by future flights like XEUS or Constellation - X for studying these fascinating sources . Keywords : Accretion wheel - Compact object - Relativistic jet - X - ray binary",
        "rewrite_text": "Title: Accreting Neutron Stars in Low-Mass X-Ray Binary Systems\n\nAbstract: The groundbreaking discovery of the first X-ray pulsar, Scorpius X-1 (Sco-X1), by Giacconi et al. in 1962 marked a significant milestone in astrophysics, paving the way for the exploration of accretion phenomena around compact objects. This discovery has led to the formulation of critical concepts, including the existence of accretion disks. The advent of advanced observatories such as Chandra and XMM-Newton has transformed our understanding of these systems, enabling detailed investigations of their physical properties at unprecedented spatial resolutions. In this review, we will delve into recent findings derived from observations made with these powerful satellites, which provide insights into the formation and evolution of neutron stars within low-mass X-ray binary systems. We will examine the mechanisms that govern the creation of relativistic jets, which have been observed in various types of X-ray binaries, enhancing our comprehension of the underlying physics. Additionally, we will highlight the potential of upcoming missions, such as XEUS and Constellation-X, to further advance our knowledge of these intriguing astrophysical sources. By synthesizing current research and future prospects, this review aims to contribute to the ongoing discourse surrounding the complexities of accreting neutron stars and their role in the broader context of stellar evolution and high-energy astrophysics. \n\nKeywords: Accretion disk, Compact object, Relativistic jet, X-ray binary",
        "ori-fast-z-score": -0.11547005383792514,
        "water-fast-z-score": 4.817730411281796,
        "rewrite-fast-z-score": 0.8081220356417685
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Searching for coronal radio emission from protostars using Very-Long-Baseline Interferometry .\nAbstract:\nWe report on the detection and characterization of two new classes of radio sources in nearby star-forming regions, which we identify as candidate young stellar objects (YSOs). The first class consists of compact radio sources with flat or inverted spectral indices that are associated with infrared dark clouds (IRDCs); these may be either deeply embedded YSOs or free-free absorbed H II regions. The second class is comprised of extended radio sources with steep spectra that appear to be physically related to IRDCs; these could represent ionized outflows driven by massive protostellar jets. We also present evidence suggesting that some of our candidates are likely to be magnetically active stars. These results demonstrate how VLBI observations can be used to search for and characterize protostars at very early stages of their evolution. \n \n Keywords: Radio astronomy, Young stellar object, Infrared dark cloud, Magnetar, Coronal mass ejection",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Searching for coronal radio emission from protostars utilizing Very - Long - Baseline Interferometry . Abstract : We report on the discovery and identification of two new classes of radio sources in nearby star - creating areas , which we identify as candidate young stellar bodies ( YSOs ) .The first class consists of compact radio sources with flat or inverted spectral indices that are identified with infrared soft clouds ( IRDCs ) ; these may be either strongly embedded YSOs or free - free absorbed H II regions . The second class is comprised of extended television sources with steep spectra that appear to be physically related to IRDCs ; these could indicate ionized outflows driven by massive protostellar jets .We additionally offer evidence indicating that some of our candidates are likely to be magnetically active stars . These data demonstrate how VLBI studies can be used to search for and characterize protostars at very earliest stages of their development .Keywords : Radio astronomy , Young stellar object , Infrared black dust , Magnetar , Coronal mass ejection",
        "rewrite_text": "Title: Investigating Coronal Radio Emissions from Protostars Using Very Long Baseline Interferometry\n\nAbstract: In this study, we present the discovery and classification of two novel categories of radio sources located in nearby star-forming regions, which we propose as potential young stellar objects (YSOs). The first category encompasses compact radio sources characterized by flat or inverted spectral indices, which we associate with infrared dark clouds (IRDCs). These sources may represent either deeply embedded YSOs or H II regions that are subject to free-free absorption. The second category consists of extended radio sources exhibiting steep spectral indices, which appear to have a physical connection to IRDCs. These extended sources may signify ionized outflows that are driven by powerful jets from massive protostars. Furthermore, we provide evidence suggesting that some of the identified candidates may be magnetically active stars. Our findings highlight the effectiveness of Very Long Baseline Interferometry (VLBI) in the search for and characterization of protostars during the earliest phases of their formation. This research not only enhances our understanding of the radio emissions associated with YSOs but also underscores the potential of VLBI as a tool for probing the complex processes involved in stellar formation. The implications of these discoveries are significant for the field of radio astronomy, particularly in relation to the study of young stellar objects, infrared black dust, magnetars, and coronal mass ejections. \n\nKeywords: Radio astronomy, Young stellar objects, Infrared dark clouds, Magnetically active stars, Protostellar jets.",
        "ori-fast-z-score": -0.5488212999484517,
        "water-fast-z-score": 3.2349831961031525,
        "rewrite-fast-z-score": -0.27975144247209416
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Possible non-thermal nature of the soft-excess emission in the cluster of galaxies Sersic 159-03 .\nAbstract:\nWe report on our analysis of archival Chandra data for the galaxy cluster Sersic 159-03, which shows evidence for excess X-ray emission below 1 keV (the  soft-excess ). We find that this feature is not consistent with thermal bremsstrahlung or line emission associated with any known atomic species and conclude it must be due to some other process such as inverse Compton scattering by relativistic electrons. The observed spectrum can be fitted well using an absorbed power-law model plus a blackbody component at kT = 0.2 keV; however we show that this fit is statistically unacceptable when compared against more physically motivated models including a combination of Bremsstrahlung and inverse-Compton emission. In particular, we demonstrate that the inclusion of a second blackbody component improves the quality of the fits significantly over those obtained previously.  Using these new results, we estimate the total luminosity of the soft-excess to be Lx ~ 1045 erg s-1 within a radius of R500 = 2 Mpc. This value is comparable to the bolometric luminosities inferred for several nearby radio halos detected via their synchrotron emission.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Possible non - cooling nature of the soft - excess emission in the cluster of stars Sersic 159 - 03 . Abstract : We report on our analysis of archival Chandra data for the galaxy cluster Sersic 159 - 03 , which reveals proof for excess X - ray radiation below 1 keV ( the soft - residual ) .We see that this characteristic is not consistent with thermal bremsstrahlung or line emission associated with any known atomic species and assume it must be due to some other mechanism such as inverse Compton absorption by relativistic electrons . The observed spectrum can be fit well using an absorption power - law description plus a blackbody element at kT = 0 . 2 keV ; however we prove that this fit is statistically unacceptable when compared against more legally driven models using a combination of Bremsstrahlung and inverse - Compton absorption .In particular , we prove that the introduction of a second blackbody element improves the performance of the fits considerably over those acquired previously . Using these new data , we estimate the total luminosity of the soft - excess to be Lx ~ 1045 erg s - 1 within a diameter of R500 = 2 Mpc .This value is analogous to the bolometric luminosities inferred for numerous nearby radio halos detected via their synchrotron emission .",
        "rewrite_text": "We present our findings from an analysis of archival Chandra data concerning the galaxy cluster Sersic 159-03, which indicates the presence of an excess in X-ray emission below 1 keV, referred to as the soft-excess. This phenomenon does not align with conventional explanations such as thermal bremsstrahlung or line emissions from known atomic species. Instead, we propose that the soft-excess may arise from alternative mechanisms, potentially including inverse Compton scattering involving relativistic electrons. Our spectral analysis reveals that the data can be effectively modeled using an absorption power-law in conjunction with a blackbody component at a temperature of kT = 0.2 keV. However, we demonstrate that this model is statistically inadequate when evaluated against more robust models that incorporate a combination of bremsstrahlung and inverse Compton processes. Notably, we find that introducing a second blackbody component significantly enhances the fit quality compared to previous models. Utilizing these refined data, we estimate the total luminosity of the soft-excess to be approximately Lx ~ 10^45 erg s^-1 within a radius of R500 = 2 Mpc. This luminosity is comparable to the bolometric luminosities observed in various nearby radio halos, which are identified through their synchrotron emissions. Our results suggest that the soft-excess emission in Sersic 159-03 may not be a cooling phenomenon, but rather a manifestation of complex physical processes occurring within the cluster, warranting further investigation into the nature of the emissions and their implications for our understanding of galaxy clusters.",
        "ori-fast-z-score": -2.5298221281347035,
        "water-fast-z-score": 4.638007234913623,
        "rewrite-fast-z-score": -2.136828897185981
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A dynamical analysis of the 14 Her planetary system .\nAbstract:\nWe present an orbital stability study for the 14 planet system discovered by HATNet and Kepler space telescopes around the star HD 10180 (HIP 108427). We use numerical integrations to show that this system is dynamically stable over timescales longer than its age, which we estimate at 4 Gyrs using gyrochronology. The planets are found in two resonant chains with period ratios close to 2:1 and 3:2 respectively. These chains are connected through a chain of mean motion resonances between adjacent pairs of planets. This structure suggests that the system has been sculpted by convergent migration followed by tidal dissipation within each planet s envelope. \n \n Keywords: Planetary systems - Stability - Mean-motion resonance - Convergent migration - Tides - Gyrochronology - HD10180 - Kepler telescope - HATNet telescope - Orbital dynamics - Dynamical evolution",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A dynamical analysis of the 14 Her planetary system . Abstract : We report an orbital stability study for the 14 planet system discovered by HATNet and Kepler space telescopes around the star HD 10180 ( HIP 108427 ) .We use numerical integrations to see that this system is dynamically stable over timescales greater than its age , which we estimate at 4 Gyrs using gyrochronology . The planets are found in two resonant rings with time proportions close to 2 : 1 and 3 : 2 respectively .These chains are connected through a network of mean motion resonances between neighboring pairs of planets . This structure implies that the system has been sculpted by convergent displacement preceded by tidal dissipation within each planet s envelope .Keywords : Planetary systems - Stability - Mean - movement resonance - Convergent migration - Tides - Gyrochronology - HD10180 - Kepler observatory - HATNet telescope - Orbital dynamics - Dynamical evolution",
        "rewrite_text": "We present a comprehensive analysis of the orbital stability of the 14-planet system surrounding the star HD 10180 (HIP 108427), as identified by the HATNet and Kepler space telescopes. Our study employs numerical integration techniques to assess the dynamical behavior of this planetary system over timescales that exceed its estimated age of approximately 4 billion years, determined through gyrochronology. The findings indicate that the system exhibits significant dynamical stability, suggesting that the planets have maintained their orbits without substantial perturbations over extensive periods.\n\nThe planets within this system are organized into two distinct resonant rings, characterized by orbital period ratios that closely approximate 2:1 and 3:2. These resonant configurations are interconnected by a series of mean motion resonances that occur between adjacent planetary pairs, creating a complex network of interactions. This intricate structure points to a history of convergent migration, likely influenced by tidal dissipation processes occurring within the envelopes of the individual planets.\n\nOur results contribute to the understanding of planetary system formation and evolution, highlighting the role of resonances and tidal forces in shaping the architecture of multi-planet systems. The stability and resonant relationships observed in the HD 10180 system provide valuable insights into the dynamical processes that govern the long-term behavior of planetary orbits. This research not only enhances our knowledge of the HD 10180 system but also has broader implications for the study of planetary systems in general, particularly in the context of stability, migration, and the effects of tidal interactions. \n\nKeywords: Planetary systems, Stability, Mean motion resonance, Convergent migration, Tides, Gyrochronology, HD 10180, Kepler Observatory, HATNet Telescope, Orbital dynamics, Dynamical evolution.",
        "ori-fast-z-score": -0.13018891098082389,
        "water-fast-z-score": 3.3565855667130946,
        "rewrite-fast-z-score": 0.6211495565912797
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The habitability of super-Earths in Gliese 581 .\nAbstract:\nWe present the results of our study on the possible existence and stability of terrestrial planets around the star Gliese 581, which is located at about 20 light-years away from Earth. We have performed numerical simulations for different orbital configurations of three hypothetical terrestrial planets with masses ranging between 1 to 10 times that of Earth s mass (1-10 M⊕). Our calculations show that all these systems are dynamically stable over time scales longer than 100 Myr. The most massive planet has an eccentric orbit with e=0.2 and its periastron distance ranges between 0.05 AU and 0.15 AU depending on the initial conditions used. This planet can be considered as a hot Jupiter-like planet because it orbits very close to its host star. However, we find that there exists another region where two or more terrestrial planets may exist stably. In this region, one of them could be a super-Earth-type planet with a mass larger than 5M⊕ but smaller than 8M⊕.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The habitability of super - Earths in Gliese 581 . Abstract : We present the conclusion of our research on the possible existence and stability of terrestrial worlds around the star Gliese 581 , which is situated at about 20 light - years far from Earth .We have done mathematical simulations for different orbital arrangements of three hypothetical terrestrial worlds with masses ranging between 1 to 10 twice that of Earth s mass ( 1 - 10 M⊕ ) . Our calculations show that all these systems are dynamically stable over time ranges longer than 100 Myr .The most large planet has an eccentric orbit with e = 0 . 2 and its periastron speed ranges between 0 . 05 AU and 0 . 15 AU depending on the first conditions utilized . This planet can be regarded as a bright Jupiter - like planet because it orbits very close to its host star .However , we find that there exists another region where two or more terrestrial worlds may arise stably . In this area , one of them could be a super - Earth - class planet with a mass greater than 5M⊕ but smaller than 8M⊕ .",
        "rewrite_text": "In this study, we explore the potential habitability and stability of terrestrial planets orbiting the star Gliese 581, located approximately 20 light-years from Earth. Our research involved conducting mathematical simulations to investigate various orbital configurations for three hypothetical terrestrial planets, each with masses ranging from 1 to 10 times that of Earth (1 - 10 M⊕). The results of our simulations indicate that these planetary systems exhibit dynamic stability over time scales exceeding 100 million years. Notably, the largest of the simulated planets possesses an eccentric orbit characterized by an eccentricity of e = 0.2, with its periastron speed varying between 0.05 AU and 0.15 AU, contingent upon the initial conditions applied in our models. This particular planet can be likened to a bright, Jupiter-like body due to its close proximity to its host star. Furthermore, our findings reveal the existence of an additional orbital region where two or more terrestrial planets could coexist stably. Within this zone, we identify the potential for a super-Earth-class planet, with a mass exceeding 5M⊕ but less than 8M⊕, to form. This research contributes to our understanding of the conditions under which super-Earths may develop and thrive in the Gliese 581 system, offering insights into the broader implications for planetary habitability in similar exoplanetary systems.",
        "ori-fast-z-score": -1.62746694241347,
        "water-fast-z-score": 3.4412360080584263,
        "rewrite-fast-z-score": 0.6123724356957946
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Relativistic Tennis with Photons: Demonstration of Frequency Upshifting by a Relativistic Flying Mirror through Two Colliding Laser Pulses .\nAbstract:\nWe report on the experimental demonstration of frequency upshift in two colliding laser pulses using a relativistically flying mirror (RFM). The RFM is realized as an ultrathin foil accelerated to high velocities by intense femtosecond laser pulses focused onto it at grazing incidence angle. We show that the collision between the counter-propagating laser pulses leads to the generation of new frequencies, which are shifted towards higher values compared to those generated without the presence of the RFM. This effect can be explained within the framework of nonlinear optics and quantum electrodynamics. Our results demonstrate the possibility for generating high-energy photons via collisions of laser pulses in vacuum. These findings may have important implications for future applications such as particle acceleration or gamma-ray sources based on table-top experiments. \n \n In recent years there has been growing interest in studying the interaction of ultra-intense lasers with matter under extreme conditions  1  . One particular area of research focuses on the investigation of novel phenomena associated with the propagation of light in vacuum  2  , where the effects of strong field QED  3  become relevant  4  . For example, the emission of energetic electrons  5  and positrons  6  into vacuum was observed experimentally  7-9  when intense laser pulses were focused onto thin foils  10  . Moreover, the production of energetic photons  11  and pairs  12  in vacuum was predicted theoretically  13-15  .\n \nIn this Letter we present our experimental study of another interesting phenomenon related to the propagation of light in vacuo -the so-called relativistic tennis  16  . It consists of two counterpropagating laser pulses interacting with each other inside a vacuum chamber  17  . When these pulses collide they generate new frequencies  18  , which are shifted towards higher energies  19  . This effect occurs due to the fact that the electric fields of both pulses add coherently  20  leading to the formation of a standing wave pattern  21  . As a result, the intensity of the standing wave increases significantly  22  causing the appearance of new frequencies  23  . \n \n Here we report on the first experimental observation of the relativistic tennis effect  24  . To achieve this goal, we used a relativistically flying mirror  25  , which",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Relativistic Tennis with Photons : Demonstration of Frequency Upshifting by a Relativistic Flying Mirror through Two Colliding Laser Pulses . Abstract : We report on the experimental test of signal upshift in two colliding laser pulses using a relativistically flying lens ( RFM ) .The RFM is realized as an ultrathin foil advanced to large velocities by intense femtosecond laser pulses focused onto it at grazing incidence angle . We see that the interaction between the counter - propagating optical pulses contributes to the generation of new frequencies , which are shifted towards higher values compared to those generated without the presence of the RFM .This phenomenon can be described within the framework of nonlinear optics and quantum electrodynamics . Our results show the prospect for generating high - energy photons via collisions of laser pulses in vacuum .These studies might have important implications for future applications such as particle gravity or gamma - ray sources based on table - top tests . In recent history there has been growing interest in investigating the interaction of ultra - intense lasers with matter under extreme circumstances 1 .One particular area of research focuses on the exploration of new events associated with the propagation of light in vacuum 2 , where the effects of bright force QED 3 become relevant 4 . For instance , the emission of energetic electrons 5 and positrons 6 into vacuum was seen experimentally 7 - 9 when strong laser pulses were focused onto thin foils 10 .Moreover , the production of energetic photons 11 and pairs 12 in vacuum was anticipated theoretically 13 - 15 . In this Letter we present our experimental work of another important process related to the propagation of light in vacuo - the so - called relativistic tennis 16 .It consists of two counterpropagating laser pulses interacting with each other inside a vacuum chamber 17 . When these pulses collide they generate additional frequencies 18 , which are shifted towards higher energies 19 .This phenomenon occurs due to the fact that the electric fields of both pulses add coherently 20 resulting to the formation of a standing wave pattern 21 . As a result , the strength of the sitting wave increases substantially 22 resulting the appearance of new frequencies 23 .Here we paper on the first experimental measurement of the relativistic tennis phenomenon 24 . To achieve this goal , we using a relativistically flying reflection 25 , which",
        "rewrite_text": "Title: Relativistic Tennis with Photons: Demonstration of Frequency Upshifting by a Relativistic Flying Mirror through Two Colliding Laser Pulses\n\nAbstract: In this study, we present an experimental investigation into the phenomenon of frequency upshifting in two colliding laser pulses facilitated by a relativistically flying mirror (RFM). The RFM is created using an ultrathin foil propelled to high velocities by intense femtosecond laser pulses, which are focused onto it at a grazing incidence angle. Our findings reveal that the interaction between the counter-propagating optical pulses leads to the generation of new frequencies that are significantly higher than those produced in the absence of the RFM. This effect can be understood through the principles of nonlinear optics and quantum electrodynamics. The implications of our results suggest a promising avenue for the generation of high-energy photons through laser pulse collisions in a vacuum environment. This research is particularly relevant in light of the increasing interest in the interactions of ultra-intense lasers with matter under extreme conditions. One key area of exploration involves the effects of quantum electrodynamics (QED) in vacuum, where phenomena such as the emission of energetic electrons and positrons have been observed when strong laser pulses interact with thin foils. Additionally, theoretical predictions have indicated the potential for producing energetic photons and particle pairs in vacuum. In this letter, we focus on a novel process known as \"relativistic tennis,\" which involves the interaction of two counter-propagating laser pulses within a vacuum chamber. Upon collision, these pulses generate additional frequencies that are shifted to higher energy levels due to the coherent addition of their electric fields, resulting in a standing wave pattern. This enhanced standing wave significantly increases the amplitude, leading to the emergence of new frequencies. We report the first experimental measurements of this relativistic tennis phenomenon, achieved through the use of a relativistically flying mirror, thereby contributing to the understanding of light propagation in vacuum and its potential applications in future technologies such as particle gravity and tabletop gamma-ray sources.",
        "ori-fast-z-score": 0.6135719910778963,
        "water-fast-z-score": 7.222716252062202,
        "rewrite-fast-z-score": 2.227560395692044
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Generalized CRF-structures .\nAbstract:\nWe introduce the concept of generalized conditional random fields (GCRFs) and show how they can be used to model arbitrary probability distributions over structured data sets, such as sequences or trees.  We present an efficient algorithm for learning GCRF parameters using gradient descent on the log-likelihood objective function.   Finally we demonstrate that our approach is able to learn accurate models for several challenging sequence labeling tasks including part-of-speech tagging in natural language processing and protein secondary structure prediction in bioinformatics. Conditional Random Fields (CRFs) (Lafferty et al., 2001 ) are undirected graphical models which have been successfully applied to many problems involving sequential data, e.g. (Sha & Pereira, 2003) . In this work, we propose Generalized Conditional Random Fields (GCRFs), a generalization of CRFs which allows us to represent any distribution over structured data sets like sequences or trees. The key idea behind GCRFs is to use a set of latent variables to capture dependencies between different parts of the input space. This enables us to efficiently compute the partition function required by standard CRFs with dynamic programming techniques. Furthermore, it also makes it possible to train GCRFs using gradient-based methods similar to those employed for Maximum Entropy Markov Models (MEMMs). To evaluate the performance of our method, we apply it to two important applications: part-of-speech taggin",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Generalized CRF - structures . Abstract : We introduce the idea of generalized conditional random fields ( GCRFs ) and explain how they can be used to model arbitrary likelihood distributions over structured data sets , such as sequences or trees .We present an efficient algorithm for learning GCRF variables using gradient descent on the log - likelihood objective function . Finally we prove that our approach is ability to teach exact models for numerous challenging gene labeling challenges including whole - of - voice tagging in natural language processing and gene secondary structure prediction in bioinformatics .Conditional Random Fields ( CRFs ) ( Lafferty et al . , 2001 ) are undirected graphical descriptions which have been successfully applied to many difficulties involving sequential data , e . g . ( Sha & Pereira , 2003 ) .In this research , we develop Generalized Conditional Random Fields ( GCRFs ) , a generalization of CRFs which allows us to model any distribution over structured data sets like sequences or trees . The main idea behind GCRFs is to use a setting of latent variables to capture dependencies between various parts of the input space .This enables us to easily compute the partition function required by traditional CRFs with dynamic programming tools . Furthermore , it also makes it able to train GCRFs using gradient - based methods similar to those utilized for Maximum Entropy Markov Models ( MEMMs ) .To assess the performance of our technique , we apply it to two essential users : part - of - voice taggin",
        "rewrite_text": "We present the concept of Generalized Conditional Random Fields (GCRFs), an innovative extension of traditional Conditional Random Fields (CRFs) that enables the modeling of arbitrary likelihood distributions over structured datasets, including sequences and trees. Our research introduces a robust algorithm for learning GCRF parameters through gradient descent optimization of the log-likelihood objective function. We demonstrate the efficacy of our approach by applying it to complex gene labeling tasks, such as whole-voice tagging in natural language processing and predicting gene secondary structures in bioinformatics.\n\nConditional Random Fields, originally proposed by Lafferty et al. in 2001, have been widely utilized for various sequential data challenges, as highlighted by Sha and Pereira in 2003. In this study, we extend the capabilities of CRFs by developing GCRFs, which incorporate latent variables to effectively capture dependencies across different segments of the input space. This enhancement allows for the efficient computation of the partition function, a critical component in traditional CRF frameworks, utilizing dynamic programming techniques.\n\nMoreover, our GCRF framework facilitates training through gradient-based methods akin to those employed in Maximum Entropy Markov Models (MEMMs), thus streamlining the learning process. To validate the performance of our proposed method, we conduct experiments on two significant applications: part-of-speech tagging and gene structure prediction. The results indicate that GCRFs not only improve the accuracy of these tasks but also provide a flexible modeling approach that can be adapted to various structured data scenarios. Our findings contribute to the ongoing development of advanced statistical models in machine learning and bioinformatics, paving the way for future research in this domain.",
        "ori-fast-z-score": -0.647150228929434,
        "water-fast-z-score": 6.127946159842712,
        "rewrite-fast-z-score": 0.8049844718999243
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Privacy - an Issue for eLearning? A Trend Analysis Reflecting the Attitude of European eLearning Users .\nAbstract:\nThe purpose of this study is to investigate how privacy issues are perceived by users in Europe and what their attitude towards these issues is, when using online learning environments (OLE). The research questions are: \nWhat do students think about privacy?\nHow does student s perception change over time?\nWhich factors influence students  attitudes on privacy? How can we measure it? What are the implications for OLE developers? This article presents results from two surveys conducted with university students at different universities across Europe between 2004-2006. It shows that there has been little change in the way students perceive privacy since 2004. Students  concerns have not changed significantly either; they still worry most about personal information being shared without permission or control. However, some differences were found among countries. In addition, the findings show that gender plays a role as well as age. Finally, the authors discuss possible reasons behind the observed trends and provide recommendations for future work.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Privacy - an Issue for eLearning ? A Trend Analysis Reflecting the Attitude of European eLearning Users .Abstract : The purpose of this study is to examine how privacy issues are seen by users in Europe and what their attitude towards these problems is , when using internet learning habitats ( OLE ) . The survey challenges are : What do students think about privacy ?How does student s perception shift over time ? Which variables influence pupils beliefs on privacy ?How can we measure it?What are the implications for OLE developers?This page presents scores from two polls conducted with university students at different schools across Europe between 2004 - 2006 . It demonstrates that there has been less shift in the way pupils understand privacy since 2004 .Students issues have not altered significantly either ; they still concern most about personal data being shared without authorization or authority . However , some differences were found among countries .In addition , the discoveries reveal that gender plays a role as well as aging . Finally , the articles discuss possible reasons behind the reported developments and include recommendations for future projects .",
        "rewrite_text": "**Title:** Privacy: An Issue for eLearning? A Trend Analysis Reflecting the Attitude of European eLearning Users\n\n**Abstract:** This study investigates the perceptions of privacy among European users of online learning environments (OLE) and explores their attitudes towards privacy-related issues. The research addresses several key questions: What are students' views on privacy? How do these perceptions evolve over time? Which factors influence students' beliefs regarding privacy? How can these beliefs be effectively measured? What implications do these findings have for developers of OLE? \n\nTo answer these questions, the study presents data from two surveys conducted with university students across various European institutions between 2004 and 2006. The findings indicate that there has been minimal change in students' understanding of privacy since 2004. Concerns regarding unauthorized sharing of personal data remain predominant among students, with little variation in these issues over the years. However, notable differences in privacy perceptions were observed across different countries, suggesting that cultural context may play a significant role in shaping attitudes towards privacy.\n\nAdditionally, the analysis reveals that demographic factors, such as gender and age, influence students' privacy concerns. The study discusses potential reasons for the stability in privacy perceptions over time and highlights the importance of addressing these concerns in the development of online learning platforms. The article concludes with recommendations for future research and practical implications for OLE developers, emphasizing the need for enhanced privacy measures to foster a secure learning environment for users. This research contributes to the ongoing discourse on privacy in the digital age, particularly within the context of eLearning in Europe.",
        "ori-fast-z-score": -0.52999894000318,
        "water-fast-z-score": 7.378647873726218,
        "rewrite-fast-z-score": 0.7689218919450849
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Two Qubit Entanglement in $XYZ$ Magnetic Chain with DM Antisymmetric Anisotropic Exchange Interaction .\nAbstract:\nWe study the entanglement properties of two qubits coupled by an antisymmetric anisotropic exchange interaction (AAEI) in a magnetic chain described by the Heisenberg model on the square lattice. We show that for certain values of the parameters, this system can be mapped onto a spin-1/2 XYZ chain and we calculate analytically its concurrence as well as the von Neumann entropy. The results are compared to those obtained numerically using exact diagonalization techniques. In particular, it is shown that the AAEI leads to a significant increase of the concurrence between nearest-neighboring spins when compared to the standard XXZ case. Moreover, we find that there exists a critical value of the anisotropy parameter beyond which no entanglement survives. Finally, we discuss how our findings could be tested experimentally. Introduction:-Entangled states play a crucial role in quantum information processing  1  . Therefore, understanding their generation mechanisms has been one of the main goals of many theoretical investigations  2  -  4  .\nIn recent years, much attention was paid to the investigation of entanglement in various types of spin chains  5  , including the so-called XXZ chain  6 -  8  . However, most studies were focused only on the ground state  9  or low lying excited states  10  of these systems. On the other hand, recently developed experimental techniques allow us to prepare highly excited states  11  . Thus, it becomes important to investigate also higher energy levels  12  .\nThe aim of this work is to analyze the entanglement properties of a pair of qubits interacting via an antisymmetric anisotropic Heisenberg exchange term  13  . This type of coupling appears naturally in several physical models  14  -  16  . For example, it describes the spin-spin interactions in molecular magnets  17  where the total angular momentum J = 0  18  . It should be noted here that such molecules have attracted considerable interest due to their potential applications in quantum computing  19  . Another interesting application concerns the description of excitations in high-Tc superconductors  20  . Here, the presence of the antisymmetric anisotropic exchange term may lead to new phenomena  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Two Qubit Entanglement in $ XYZ $ Magnetic Chain with DM Antisymmetric Anisotropic Exchange Interaction . Abstract : We research the entanglement properties of two qubits coupled by an antisymmetric anisotropic exchange interaction ( AAEI ) in a magnetic chain described by the Heisenberg model on the square lattice .We see that for particular values of the variables , this scheme can be mapped onto a spin - 1 / 2 XYZ chain and we estimate analytically its concurrence as well as the von Neumann entropy . The results are compared to those achieved numerically use accurate diagonalization techniques .In particular , it is demonstrated that the AAEI results to a substantial rise of the concurrence between nearest - neighboring spins when compared to the standard XXZ case . Moreover , we find that there exists a critical quantity of the anisotropy parameter beyond which no entanglement survives .Finally , we talk how our findings may be evaluated experimentally . Introduction : - Entangled states play a crucial role in quantum information processing 1 .Therefore , studying their generation pathways has been one of the main goals of several theoretical investigations 2 - 4 . In past decades , increasing attention was given to the examination of entanglement in different kinds of spin rings 5 , notably the so - called XXZ ring 6 - 8 .However , most studies were focused only on the ground state 9 or low lying excited states 10 of these systems . On the other hand , recently advanced experimental methods able us to analyze highly excited states 11 .Thus , it becomes crucial to examine also greater energy levels 12 . The goal of this research is to analyze the entanglement properties of a pair of qubits interacting via an antisymmetric anisotropic Heisenberg transfer term 13 .This kind of coupling appears naturally in multiple physical models 14 - 16 . For instance , it explains the spin - spinning interactions in molecular magnets 17 where the total angular velocity J = 0 18 .It should be mentioned here that such compounds have garnered considerable interest due to their potential applications in quantum computing 19 . Another important use involves the description of excitations in high - Tc superconductors 20 .Here , the presence of the antisymmetric anisotropic exchange term may contribute to new concepts 21 .",
        "rewrite_text": "**Title:** Two Qubit Entanglement in $XYZ$ Magnetic Chain with DM Antisymmetric Anisotropic Exchange Interaction\n\n**Abstract:** This study investigates the entanglement characteristics of two qubits that are coupled through an antisymmetric anisotropic exchange interaction (AAEI) within a magnetic chain, modeled by the Heisenberg framework on a square lattice. We demonstrate that under specific conditions, this system can be effectively transformed into a spin-1/2 XYZ chain. Through analytical methods, we calculate the concurrence and von Neumann entropy of the system, and we juxtapose these findings with numerical results obtained via precise diagonalization techniques. Our analysis reveals that the presence of AAEI significantly enhances the concurrence between nearest-neighbor spins compared to the conventional XXZ model. Furthermore, we identify a critical threshold for the anisotropy parameter, beyond which entanglement is completely lost. The implications of our results for experimental evaluation are also discussed, highlighting the potential for practical applications in quantum information science.\n\n**Introduction:** Entangled states are fundamental to the field of quantum information processing, making the exploration of their generation pathways a primary focus of numerous theoretical studies. Over recent decades, there has been a growing interest in the entanglement properties of various spin systems, particularly in the context of spin rings, such as the XXZ ring. However, much of the existing literature has concentrated on the ground state or low-lying excited states of these systems. With advancements in experimental techniques, it is now possible to investigate highly excited states, necessitating a broader examination of entanglement across higher energy levels. This research aims to delve into the entanglement properties of two qubits interacting through an antisymmetric anisotropic Heisenberg coupling, a phenomenon that naturally arises in several physical contexts. This type of interaction is particularly relevant in molecular magnets, where it describes spin-spin interactions with a total angular momentum of J = 0. Such materials have attracted significant interest due to their potential applications in quantum computing, as well as their role in elucidating excitations in high-temperature superconductors. The incorporation of the antisymmetric anisotropic exchange term may pave the way for novel theoretical concepts in these areas.",
        "ori-fast-z-score": -0.159111456835146,
        "water-fast-z-score": 8.224234724873552,
        "rewrite-fast-z-score": 1.516365080488482
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Subjective Information Measure and Rate Fidelity Theory .\nAbstract:\nIn this work, we propose the subjective information measure (SIM) to quantify the amount of information in an image or video sequence. The SIM is defined as the minimum number of bits required for lossless coding of the source data under some fidelity criterion. We show that the proposed SIM can be used to derive rate-distortion functions with high accuracy by using only one parameter. In addition, it also provides accurate prediction on ratedistortion performance at low bit rates. Finally, we demonstrate its effectiveness through experiments conducted on several test sequences. Index Terms -Information theory, Image compression, Video compression. 1 Introduction Data compression has been widely studied over past decades due to its importance in many applications such as digital storage systems, communication networks, medical imaging, etc.. A fundamental problem in data compression is how to accurately predict the compressed file size given the original uncompressed data. This problem is usually referred to as rate-distortion analysis  1  . It is well known that the rate-distortion function characterizes the relationship between the average codeword length and distortion level achieved by any optimal encoding scheme  2  .\nThe most commonly adopted approach to solve the rateconstraint optimization problems is Lagrangian relaxation  3  , which transforms constrained optimization into unconstrained ones via introducing additional variables called Lagrange multipliers  4  . However, solving these problems requires iterative algorithms  5  , which are computationally expensive  6  . To overcome this difficulty, researchers have developed various fast algorithms  7, 8  . Nevertheless, they still suffer from slow convergence speed when applied to practical problems  9  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Subjective Information Measure and Rate Fidelity Theory . Abstract : In this research , we develop the subjective information measure ( SIM ) to quantify the quantity of information in an image or video sequence .The SIM is calculated as the minimum amount of bits required for lossless coding of the input data under some fidelity criterion . We see that the suggested SIM can be used to derive rate - distortion functions with high sensitivity by using only one parameter .In addition , it also provides reliable prediction on ratedistortion behavior at low bit rates . Finally , we prove its effectiveness through experiments conducted on numerous test sequences .Index Terms - Information theory , Image compression , Video compression . 1 Introduction Data compression has been widely understood over past decades owing to its significance in multiple applications such as electronic storage systems , communication networks , hospital imaging , etc . . A crucial problem in data encoding is how to correctly forecast the compressed file size given the actual uncompressed information .This problem is usually referred to as rate - distortion theory 1 . It is well famous that the rate - distortion function characterizes the relationship between the average codeword length and distortion height accomplished by any optimal encoding scheme 2 .The most commonly implemented methods to solve the rateconstraint optimization problems is Lagrangian relaxation 3 , which transforms constrained optimization into unconstrained ones via introducing additional parameters named Lagrange multipliers 4 . However , settling these problems demands iterative techniques 5 , which are computationally expensive 6 .To solve this challenge , researchers have developed various quick schemes 7 , 8 . Nevertheless , they still suffer from slow convergence speed when applied to commercial difficulties 9 .",
        "rewrite_text": "**Title: Subjective Information Measure and Rate Fidelity Theory**\n\n**Abstract:** This study introduces the Subjective Information Measure (SIM), a novel approach for quantifying the information content in images and video sequences. The SIM is defined as the minimum number of bits necessary for lossless encoding of the input data while adhering to a specified fidelity criterion. Our findings indicate that the proposed SIM can effectively derive rate-distortion functions with heightened sensitivity by utilizing a single parameter. Furthermore, it demonstrates a reliable capacity for predicting rate-distortion behavior, particularly at low bit rates. The effectiveness of the SIM is validated through a series of experiments conducted on various test sequences, showcasing its practical applicability in real-world scenarios.\n\nThe significance of data compression has been increasingly recognized over the past few decades, given its crucial role in diverse applications such as electronic storage systems, communication networks, and medical imaging. A fundamental challenge in data encoding lies in accurately estimating the size of the compressed file based on the original uncompressed data, a problem commonly referred to as rate-distortion theory. The rate-distortion function is well-established as a means to characterize the relationship between the average length of codewords and the resulting distortion achieved by optimal encoding schemes. Traditional methods for addressing rate-constraint optimization problems often employ Lagrangian relaxation, which reformulates constrained optimization into an unconstrained format by introducing Lagrange multipliers. However, these methods typically require iterative techniques, which can be computationally intensive. In response to this challenge, researchers have proposed various expedited schemes; nonetheless, these approaches frequently encounter issues with slow convergence when applied to practical problems. This paper aims to address these limitations by presenting the SIM as a more efficient alternative for information quantification and rate-distortion analysis.\n\n**Index Terms:** Information theory, Image compression, Video compression.",
        "ori-fast-z-score": -0.16783627165933782,
        "water-fast-z-score": 6.545614594714175,
        "rewrite-fast-z-score": 1.4504813352456845
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Search for CO(J=3-2) Emission from the Host Galaxy of GRB 980425 with the Atacama Submillimeter Telescope Experiment .\nAbstract:\nWe report on observations made in March and April 2002 at 345 GHz using the Atacama Submillimiter Telescope Experiment (ASTE). We detected no significant emission associated with the host galaxy of the gamma-ray burst GRB 980425, which was discovered by BeppoSAX on Apr. 25, 1998 . The 3 sigma upper limit to the flux density is < 0.5 Jy beam-1 , corresponding to an integrated line intensity ICO< 1 x 10^9 K km s^-1 pc^2 or Mgas < 2 x 10^8 Msun .\nThe non-detection suggests that either the molecular gas mass is much lower than previously estimated or that it has been destroyed by the intense UV radiation field produced during the burst.  These results are consistent with those obtained recently by other groups who have searched for CO emission from this source. If our result can be confirmed then it will provide important constraints on models of the formation of massive stars.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Search for CO ( J = 3 - 2 ) Emission from the Host Galaxy of GRB 980425 with the Atacama Submillimeter Telescope Experiment . Abstract : We report on observations made in March and April 2002 at 345 GHz using the Atacama Submillimiter Telescope Experiment ( ASTE ) .We observed no major radiation associated with the host galaxy of the gamma - ray burst GRB 980425 , which was discovered by BeppoSAX on Apr . 25 , 1998 .The 3 sigma higher limit to the flux concentration is < 0 . 5 Jy beam - 1 , equivalent to an integrated line intensity ICO < 1 x 10 ^ 9 K km s ^ - 1 pc ^ 2 or Mgas < 2 x 10 ^ 8 Msun . The non - measurement indicates that either the molecular gas mass is much lower than previously predicted or that it has been destroyed by the strong UV rays field produced during the explosion .These conclusions are compatible with those acquired previously by other groups who have searched for CO radiation from this source . If our outcome can be verified then it will provide important restrictions on estimates of the formation of large stars .",
        "rewrite_text": "In this study, we present the findings from our observations conducted in March and April 2002 at a frequency of 345 GHz using the Atacama Submillimeter Telescope Experiment (ASTE). Our primary objective was to detect CO (J = 3 - 2) emission from the host galaxy of the gamma-ray burst GRB 980425, which was first identified by the BeppoSAX satellite on April 25, 1998. However, our observations did not reveal any significant radiation associated with this host galaxy. We established a 3 sigma upper limit for the flux density at < 0.5 Jy beam^-1, which translates to an integrated line intensity of ICO < 1 x 10^9 K km s^-1 pc^2, or a molecular gas mass limit of Mgas < 2 x 10^8 Msun. The absence of detectable CO emission suggests that the molecular gas mass in the host galaxy may be substantially lower than earlier estimates, or it may have been significantly affected or destroyed by the intense ultraviolet radiation generated during the gamma-ray burst event. These findings align with previous research conducted by other teams that have also attempted to detect CO emissions from this source. If our results are corroborated by further studies, they could impose critical constraints on the models predicting the formation of massive stars in such extreme environments. This research contributes to our understanding of the aftermath of gamma-ray bursts and their impact on star formation processes in their host galaxies.",
        "ori-fast-z-score": -2.25,
        "water-fast-z-score": 3.3489378339086286,
        "rewrite-fast-z-score": -0.6965260331469925
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nonleptonic two-body B-decays including axial-vector mesons in the final state .\nAbstract:\nWe present results on nonleptonic two-body decays of heavy quarks into light hadrons, with an emphasis on the role played by axial vector mesons in these processes.  We use the framework of Heavy Quark Effective Theory (HQET) and its extension to include higher order corrections in inverse powers of the b-quark mass. The latter are calculated using the method developed recently for the calculation of radiative corrections within HQET. In particular we study the decay amplitudes for the following processes:  B→Dπ, Dρ, Dω; B→K*π, K*ρ, K*ω; B→Kπ, Kη′, Kη′′; B→ππ, πη, πη′. \nThe main result is that the inclusion of the effects due to the exchange of one or more soft gluons between the initial and final states leads to significant changes in the values of the decay rates as compared to those obtained previously without such contributions included.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nonleptonic two - bodies B - decays using axial - vector mesons in the finished state . Abstract : We report findings on nonleptonic two - bodies decays of heavy quarks into light hadrons , with an emphasis on the part played by axial vector mesons in these mechanisms .We use the framework of Heavy Quark Effective Theory ( HQET ) and its extension to provide higher order corrections in inverse powers of the b - quark mass . The latter are measured using the method developed lately for the determination of radiative corrections within HQET .In particular we study the decay amplitudes for the following processes : B→Dπ , Dρ , Dω ; B→K * π , K * ρ , K * ω ; B→Kπ , Kη ′ , Kη ′ ′ ; B→ππ , πη , πη ′ . The main consequence is that the introduction of the effects due to the transfer of one or more warm gluons between the first and final states causes to significant improvements in the values of the decay rates as compared to those acquired previously without such contributions added .",
        "rewrite_text": "In this article, we present our findings on nonleptonic two-body decays of heavy quarks into light hadrons, focusing specifically on the role of axial vector mesons in these decay processes. Utilizing the framework of Heavy Quark Effective Theory (HQET) and its extensions, we incorporate higher-order corrections that are inversely related to the mass of the b-quark. These corrections are quantified using a recently developed methodology for assessing radiative corrections within the HQET framework. Our analysis encompasses several decay amplitudes, including B→Dπ, Dρ, Dω; B→K*π, K*ρ, K*ω; B→Kπ, Kη′, Kη′′; and B→ππ, πη, πη′. A significant outcome of our study is the observation that incorporating the effects of the exchange of one or more soft gluons between the initial and final states leads to notable enhancements in the decay rates. This improvement is substantial when compared to previous calculations that did not account for such contributions. Our results underscore the importance of axial vector mesons and gluon exchanges in accurately describing the dynamics of nonleptonic B-decays, providing deeper insights into the underlying mechanisms governing these processes. This work not only advances our understanding of heavy quark decays but also highlights the necessity of considering higher-order corrections in theoretical models to achieve more precise predictions.",
        "ori-fast-z-score": -0.6201736729460423,
        "water-fast-z-score": 5.169842621131974,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Conserved spin Hall conductance in two dimensional electron gas in a perpendicular magnetic field .\nAbstract:\nWe study the effect of Rashba spin-orbit interaction on the spin Hall conductivity (SHC) for an interacting two-dimensional electron system with parabolic dispersion and Zeeman splitting in presence of a uniform external magnetic field applied normal to the plane of motion. We show that SHC is independent of temperature, chemical potential and strength of disorder provided the Fermi energy lies within the Zeeman gap. The results are obtained by using the Kubo formula combined with the self-consistent Born approximation. It has been shown recently that the spin current can be generated without any net charge flow when electrons move through a nonmagnetic material under the influence of spin-orbit coupling  1  . This phenomenon known as spin Hall effect was first predicted theoretically  2  , and later observed experimentally  3  .\nThe origin of this effect is due to the fact that the spin-orbit interaction causes a transverse force which deflects the trajectories of moving particles leading to a finite spin polarization at the edges  4  . In recent years there have been several theoretical studies devoted to understand various aspects of spin Hall effect  5  -  8  . However most of these works were done either in absence or weak magnetic fields where the Landau levels do not play significant role  9  . On the other hand it is well known that the Landau level quantization plays important role in determining many physical properties such as magnetoresistance  10  , optical absorption  11  etc., especially near the quantum limit  12  . Therefore it would be interesting to investigate how the Landau levels affect the spin Hall effect.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Conserved spin Hall conductance in two dimensional electron gas in a perpendicular magnetic field . Abstract : We research the impact of Rashba spin - orbit interaction on the spin Hall conductivity ( SHC ) for an interacting two - dimensional electron system with parabolic dispersion and Zeeman splitting in presence of a uniform external magnetic field applied normal to the plane of movement .We see that SHC is independent of temperature , chemical potential and strength of disorder provided the Fermi energy rests within the Zeeman gap . The results are derived by using the Kubo formula coupled with the self - consistent Born algorithm .It has been shown lately that the spin current can be formed without any gross charge flow when nuclei move through a nonmagnetic material under the effects of spin - orbit bonding 1 . This phenomenon known as spin Hall phenomenon was first expected theoretically 2 , and later observed experimentally 3 .The origin of this effect is due to the fact that the spin - orbit interaction produces a transverse force which deflects the trajectories of moving ions giving to a finite spin polarization at the edges 4 . In recent years there have been numerous conceptual research devoted to study various details of spin Hall phenomenon 5 - 8 .However most of these works were done either in absence or low magnetic fields where the Landau concentrations do not play substantial importance 9 . On the other hand it is well established that the Landau grade quantization takes key importance in establishing many mechanical parameters such as magnetoresistance 10 , optical emission 11 etc . , particularly near the quantum limit 12 .Therefore it would be attractive to examine how the Landau concentrations influenced the spin Hall phenomenon .",
        "rewrite_text": "**Title:** Conserved Spin Hall Conductance in Two-Dimensional Electron Gas in a Perpendicular Magnetic Field\n\n**Abstract:** This study investigates the effects of Rashba spin-orbit interaction on the spin Hall conductivity (SHC) within an interacting two-dimensional electron gas characterized by parabolic dispersion and Zeeman splitting, subjected to a uniform external magnetic field oriented perpendicular to the plane of motion. Our findings reveal that the SHC remains invariant with respect to temperature, chemical potential, and disorder strength, provided that the Fermi energy is situated within the Zeeman gap. The results are derived utilizing the Kubo formula in conjunction with the self-consistent Born approximation. Recent advancements have demonstrated that a spin current can be generated without significant charge flow when nuclei traverse a nonmagnetic medium influenced by spin-orbit coupling. This phenomenon, known as the spin Hall effect, was initially predicted through theoretical models and has since been corroborated by experimental observations. The underlying mechanism of this effect is attributed to the spin-orbit interaction, which induces a transverse force that alters the trajectories of moving ions, resulting in a finite spin polarization at the edges of the material. In recent years, extensive research has focused on various aspects of the spin Hall effect; however, most investigations have been conducted under conditions of negligible or low magnetic fields, where Landau levels do not significantly impact the results. Conversely, it is well recognized that Landau level quantization plays a crucial role in determining several physical properties, such as magnetoresistance and optical emission, particularly as one approaches the quantum limit. Therefore, this paper aims to explore the influence of Landau levels on the spin Hall phenomenon, providing insights into the interplay between spin-orbit interactions and magnetic field effects in two-dimensional electron systems.",
        "ori-fast-z-score": -0.34050261230349943,
        "water-fast-z-score": 6.930264888773836,
        "rewrite-fast-z-score": 1.2722833945199565
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On Newton s law in supersymmetric braneworld models .\nAbstract:\nWe study the gravitational field equations for static spherically symmetric configurations on Randall-Sundrum type II brane-worlds with bulk cosmological constant and matter fields localized on the branes. We show that, under certain conditions, these solutions can be interpreted as black holes embedded into an anti-de Sitter space-time. In particular we find that there is no restriction to the mass parameter M0 appearing in the solution of the vacuum Einstein equation on the brane. The corresponding horizon radius r0 satisfies the relation r0 = (3M0/4π)1/3. This result implies that the Schwarzschild-de Sitter metric describes not only black hole but also naked singularity solutions. Finally, we discuss how this picture changes when one takes into account quantum corrections due to loop effects. PACS numbers: 04.20.-q; 11.10.Kk  Supersymmetry has been proposed as a possible extension of general relativity which could provide a consistent description of gravity at all scales  1  . It was shown recently  2  , however, that it does not lead to any new predictions if applied to standard four-dimensional theories. On the other hand, higher dimensional extensions of supergravity have attracted considerable attention during recent years  3  .\nIn this letter we consider five-dimensional supergravities  4  where the extra dimension is compactified on a circle  5  or orbifold  6  . These are known as Randall-Sundrum type I  7  and type II  8  scenarios respectively. They allow for localization of Standard Model particles  9  and their excitations  10  on the so-called visible brane while gravitons propagate freely through the bulk  11  . As a consequence they may solve some problems associated with the hierarchy between the electroweak scale and the Planck scale  12  . Moreover, such models offer interesting possibilities for constructing regular black-hole-like objects  13  -  16  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On Newton s law in supersymmetric braneworld configurations . Abstract : We research the gravitational field equations for static spherically symmetric configurations on Randall - Sundrum type II brane - worlds with bulk cosmological constant and material fields confined on the branes .We see that , under certain conditions , these solutions can be interpreted as black holes inserted into an anti - de Sitter space - time . In particular we find that there is no limitation to the mass vector M0 appearing in the solution of the vacuum Einstein equation on the brane .The equivalent horizon radius r0 satisfies the relation r0 = ( 3M0 / 4π ) 1 / 3 . This result suggests that the Schwarzschild - de Sitter metric encompasses not only white hole but also naked singularity solutions .Finally , we explain how this picture changes when one takes into consideration quantum corrections due to loop interactions . PACS numbers : 04 . 20 . - q ; 11 . 10 . Kk Supersymmetry has been proposed as a possible extension of general relativity which could give a consistent description of gravitational at all scales 1 .It was shown ago 2 , however , that it does not result to any new predictions if applied to standard four - dimensional theories . On the other hand , greater dimensional extensions of supergravity have garnered considerable scrutiny during recent years 3 .In this letter we define five - dimensional supergravities 4 where the extra dimension is compactified on a ring 5 or orbifold 6 . These are known as Randall - Sundrum type I 7 and type II 8 scenarios respectively .They allow for localization of Standard Model particles 9 and their excitations 10 on the so - called visible brane while gravitons propagate continuously through the bulk 11 . As a consequence they may solve some problems related with the hierarchy between the electroweak scale and the Planck scale 12 .Moreover , such theories provided important possibilities for constructing ordinary black - hole - like bodies 13 - 16 .",
        "rewrite_text": "**Title: On Newton's Law in Supersymmetric Braneworld Configurations**\n\n**Abstract:** This study investigates the gravitational field equations governing static, spherically symmetric configurations within Randall-Sundrum type II braneworlds, incorporating a bulk cosmological constant and material fields confined to the branes. Our findings indicate that, under specific conditions, these solutions can be interpreted as black holes situated within an anti-de Sitter spacetime. Notably, we discover that there are no constraints on the mass vector \\( M_0 \\) present in the vacuum Einstein equation solutions on the brane. The corresponding horizon radius \\( r_0 \\) is determined by the relationship \\( r_0 = \\left( \\frac{3M_0}{4\\pi} \\right)^{1/3} \\). This result implies that the Schwarzschild-de Sitter metric encompasses not only white hole solutions but also naked singularities. Furthermore, we discuss how this framework is altered when quantum corrections arising from loop interactions are taken into account. \n\nSupersymmetry has been proposed as a potential extension of general relativity, offering a coherent description of gravitational phenomena across various scales. However, it has been previously established that applying supersymmetry to conventional four-dimensional theories does not yield new predictions. In contrast, higher-dimensional extensions of supergravity have attracted significant attention in recent years. In this paper, we define five-dimensional supergravities where the additional dimension is compactified either on a ring or an orbifold, corresponding to Randall-Sundrum type I and type II scenarios, respectively. These models facilitate the localization of Standard Model particles and their excitations on the so-called visible brane, while gravitons can propagate freely through the bulk. This framework may address certain issues related to the hierarchy between the electroweak and Planck scales. Additionally, these theories open up important avenues for constructing ordinary black hole-like entities, thereby enriching our understanding of gravitational interactions in higher-dimensional contexts.",
        "ori-fast-z-score": -0.43685202833051895,
        "water-fast-z-score": 5.874305293953249,
        "rewrite-fast-z-score": 2.151657414559676
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spectropolarimetric observations of the Ca II 8498 A and 8542 A lines in the quiet Sun .\nAbstract:\nWe present spectropolarimetric observations made with the Solar Optical Telescope (SOT) on board Hinode, which show that the magnetic field strength inferred from Stokes V profiles is systematically higher than those obtained by using the Zeeman splitting method for both the Ca II 8498 Å line and the Ca II 8542 Å line. The difference between these two methods increases as we go to smaller spatial scales. We also find that the magnetic fields are more inclined towards the solar surface at small spatial scales compared to larger ones. These results suggest that there may be some unknown physical processes affecting the formation of Stokes V profiles at small spatial scales. This work was supported by JSPS KAKENHI Grant-in-Aid for Scientific Research No. 16340040 . \nIntroduction\n\nThe solar atmosphere consists of various structures such as sunspots, pores, plages, prominences etc., where different physical phenomena occur. In order to understand how these phenomena take place, it is important to study their properties individually. However, this task has been difficult because most of them have very fine structure and they often overlap each other spatially. To overcome this difficulty, many observational studies have been carried out recently using high-resolution instruments such as the Swedish 1-m Solar Telescope (SST), the New Solar Telescope (NST), the Advanced Technology Solar Telescope (ATST), and the Solar Dynamics Observatory (SDO). Among others, the Hinode satellite launched in 2006 provides us with unprecedentedly high-quality data thanks to its sophisticated instrumentation including the Spectro-Polarimeter (SP) (Lites et al. (2001) ) and the Helioseismic and Magnetic Imager (HMI) (Schou et al. (2010) ), which enable us to investigate the solar photosphere down to subarcsecond resolution. Using these data sets, several authors studied the photospheric magnetic fields (e.g., Ichimoto et al. (2007) , Ishikawa & Tsuneta (2008) , Kitai et al. (2009 ), Orozco Suárez et al. (2010 , Sheminova et al. (2011))",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spectropolarimetric discoveries of the Ca II 8498 A and 8542 A lines in the quiet Sun . Abstract : We report spectropolarimetric studies made with the Solar Optical Telescope ( SOT ) on board Hinode , which show that the magnetic force force inferred from Stokes V profiles is systematically greater than those achieved by using the Zeeman splitting method for both the Ca II 8498 Å line and the Ca II 8542 Å line .The difference between these two models increases as we went to smaller spatial scales . We additionally find that the magnetic fields are more oriented towards the sun surface at small spatial scales compared to larger ones .These data suggest that there may be some unidentified physical processes controlling the formation of Stokes V profiles at small spatial scales . This research was supported by JSPS KAKENHI Grant - in - Aid for Scientific Research No .16340040 . Introduction The planetary atmosphere includes of several systems such as sunspots , pores , plages , prominences etc . , where various physical phenomena arise .In order to comprehend how these phenomena play place , it is important to study their characteristics individually . However , this job has been difficult because most of them have very fine structure and they frequently overlap each other spatially .To solve this obstacle , many observational research have been carried out recently utilizing large - resolution equipment such as the Swedish 1 - m Solar Telescope ( SST ) , the New Solar Telescope ( NST ) , the Advanced Technology Solar Telescope ( ATST ) , and the Solar Dynamics Observatory ( SDO ) . Among others , the Hinode satellite launched in 2006 offers us with unprecedentedly high - grade results courtesy to its sophisticated instrumentation including the Spectro - Polarimeter ( SP ) ( Lites et al .( 2001 ) ) and the Helioseismic and Magnetic Imager ( HMI ) ( Schou et al . ( 2010 ) ) , which enable us to examine the solar photosphere down to subarcsecond resolution .Using these information sets , various scientists examined the photospheric magnetic waves ( e . g . , Ichimoto et al . ( 2007 ) , Ishikawa & Tsuneta ( 2008 ) , Kitai et al .( 2009 ) , Orozco Suárez et al . ( 2010 , Sheminova et al .(2011))",
        "rewrite_text": "**Title:** Spectropolarimetric Discoveries of the Ca II 8498 Å and 8542 Å Lines in the Quiet Sun\n\n**Abstract:** In this study, we present the results of spectropolarimetric observations conducted with the Solar Optical Telescope (SOT) aboard the Hinode satellite. Our findings reveal that the magnetic field strengths derived from Stokes V profiles are consistently higher than those obtained through the Zeeman splitting technique for both the Ca II 8498 Å and Ca II 8542 Å lines. Notably, the disparity between these two methodologies becomes more pronounced at smaller spatial scales. Furthermore, our analysis indicates that the orientation of the magnetic fields tends to be more aligned with the solar surface at these smaller scales compared to larger ones. These observations imply the existence of unidentified physical processes that may influence the formation of Stokes V profiles at fine spatial resolutions. This research was supported by the Japan Society for the Promotion of Science (JSPS) KAKENHI Grant-in-Aid for Scientific Research No. 16340040.\n\n**Introduction:** The solar atmosphere is characterized by various structures, including sunspots, pores, plages, and prominences, each exhibiting distinct physical phenomena. Understanding these phenomena requires a detailed examination of their individual characteristics. However, this task is complicated by the fine structures and spatial overlap of these features. To address this challenge, recent observational studies have employed high-resolution instruments such as the Swedish 1-m Solar Telescope (SST), the New Solar Telescope (NST), the Advanced Technology Solar Telescope (ATST), and the Solar Dynamics Observatory (SDO). Among these, the Hinode satellite, launched in 2006, has provided exceptional data quality due to its advanced instrumentation, including the Spectro-Polarimeter (SP) and the Helioseismic and Magnetic Imager (HMI). These tools allow for the investigation of the solar photosphere at subarcsecond resolution. Utilizing these datasets, numerous researchers have explored photospheric magnetic waves, contributing to our understanding of solar dynamics and magnetic field behavior.",
        "ori-fast-z-score": -1.660037707655972,
        "water-fast-z-score": 6.203298802293369,
        "rewrite-fast-z-score": 2.108406543164886
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A very massive runaway star from Cygnus OB2 .\nAbstract:\nWe report the discovery of an extremely bright and hot (T eff = 300,000 K) blue supergiant in the open cluster NGC 6231 with a mass loss rate of 10^-6 M_sun/yr. The object is located at a distance of 1 kpc from Earth and has a luminosity of 5 x 10^{5} L_Sun. It shows strong emission lines of He II 4686 Å, N III 4641 Å, C IV 5801 Å, O V 7322 Å, and H Balmer series. We suggest that this object may be a member of the Cygnus OB2 association which contains several other high-mass stars. This would make it one of the most luminous known single stars outside our Galaxy. If confirmed by further observations, this object will provide important constraints on stellar evolution models for massive stars. Keywords: Open clusters; Blue supergiants",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A very giant runaway star from Cygnus OB2 . Abstract : We report the discovery of an incredibly bright and hot ( T eff = 300 , 000 K ) blue supergiant in the open cluster NGC 6231 with a mass loss rate of 10 ^ - 6 M _ sun / yr .The object is situated at a distance of 1 kpc from Earth and has a luminosity of 5 x 10 ^ { 5 } L _ Sun . It displays strong radiation lines of He II 4686 Å , N III 4641 Å , C IV 5801 Å , O V 7322 Å , and H Balmer series .We suggest that this object may be a constituent of the Cygnus OB2 association which contains multiple other high - mass stars . This might making it one of the most luminous known single stars outside our Galaxy .If confirmed by further observations , this body will provide important restrictions on stellar evolution models for huge stars . Keywords : Open clusters ; Blue supergiants",
        "rewrite_text": "We present the discovery of an exceptionally luminous and hot blue supergiant star located within the open cluster NGC 6231, characterized by an effective temperature of 300,000 K and a significant mass loss rate of 10^-6 M_sun per year. This remarkable star is positioned approximately 1 kiloparsec from Earth and boasts a luminosity of 5 x 10^5 L_sun, making it one of the brightest stars identified outside our Milky Way galaxy. The spectral analysis reveals prominent emission lines, including He II at 4686 Å, N III at 4641 Å, C IV at 5801 Å, O V at 7322 Å, and various lines from the H Balmer series, indicating its extraordinary physical properties. We hypothesize that this star is a member of the Cygnus OB2 association, a region known for hosting numerous high-mass stars. If further observations validate our findings, this star could be recognized as one of the most luminous known single stars beyond our galaxy. The implications of this discovery are significant, as it may provide critical insights into the evolutionary pathways of massive stars, thereby refining existing stellar evolution models. Our research underscores the importance of continued exploration of open clusters and their stellar populations, as they serve as vital laboratories for understanding the life cycles of the universe's most massive stars. Keywords associated with this study include open clusters and blue supergiants, reflecting the focus on these intriguing celestial phenomena.",
        "ori-fast-z-score": -0.5252257314388902,
        "water-fast-z-score": 2.994344952558949,
        "rewrite-fast-z-score": 0.38138503569823695
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nature of Infrared Sources in 11 micron Selected Sample from Early Data of the AKARI North Ecliptic Pole Deep Survey .\nAbstract:\nWe present results on infrared sources selected by their flux densities at 11 microns (S11) using early data taken with the InfraRed Camera (IRC) on-board AKARI, which is an infrared space telescope launched into orbit in February 2006. The survey covers about 1 deg2 area centered around the north ecliptic pole and reaches to S/N = 5 limit for point source detection. We have identified more than 1000 infrared sources down to S11 ~ 0.1 Jy over the entire field-of-view. Among them we found that most are associated with galaxies or galaxy clusters. About 20% of these objects show red colors indicative of dust-obscured star formation activity. A large fraction of the remaining 80% shows blue colors indicating active galactic nuclei and/or young stellar populations. These results suggest that our sample contains various types of infrared luminous objects including normal galaxies, interacting/merging systems, obscured AGNs as well as distant quasars.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nature of Infrared Sources in 11 micron Selected Sample from Early Data of the AKARI North Ecliptic Pole Deep Survey . Abstract : We report findings on infrared sources chosen by their flux densities at 11 microns ( S11 ) using early data taken with the InfraRed Camera ( IRC ) on - board AKARI , which is an infrared space telescope launched into orbit in February 2006 .The survey encompasses about 1 deg2 region centered around the north ecliptic pole and reaches to S / N = 5 limit for point source discovery . We have discovered more than 1000 infrared sources down to S11 ~ 0 . 1 Jy over the entire field - of - view .Among them we reported that most are identified with galaxies or galaxy regions . About 20 % of these objects show red colors indicative of dust - obscured star formation activity .A large fraction of the remaining 80 % indicates blue colors representing active galactic nuclei and / or young stellar regions . These data suggest that our sample comprises numerous types of infrared luminous objects including typical clusters , interacting / merging systems , obscured AGNs as well as distant quasars .",
        "rewrite_text": "We present our findings on infrared sources selected based on their flux densities at 11 microns (S11) utilizing early data from the InfraRed Camera (IRC) aboard the AKARI space telescope, which was launched in February 2006. The study focuses on a region of approximately 1 square degree centered around the north ecliptic pole, achieving a signal-to-noise ratio (S/N) limit of 5 for the detection of point sources. Our survey has successfully identified over 1,000 infrared sources, reaching down to S11 ~ 0.1 Jy across the entire field of view. A significant portion of these sources has been associated with galaxies or regions of galactic activity. Notably, around 20% of the identified objects exhibit red colors, which are indicative of dust-obscured star formation processes. In contrast, the remaining 80% predominantly display blue colors, suggesting the presence of active galactic nuclei (AGNs) and/or regions of young stellar formation. The diversity of our findings indicates that the sample includes a wide array of infrared luminous objects, such as typical galaxy clusters, interacting or merging systems, obscured AGNs, and distant quasars. This research contributes to our understanding of the nature and characteristics of infrared sources in the universe, highlighting the complex interplay between star formation and active galactic phenomena. The insights gained from this early data set pave the way for further investigations into the evolution of these celestial objects and their role in the broader cosmic landscape.",
        "ori-fast-z-score": 0.10846522890932808,
        "water-fast-z-score": 4.0976453817306595,
        "rewrite-fast-z-score": 0.8392543274162825
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Needlet algorithms for estimation in inverse problems .\nAbstract:\nWe consider the problem of estimating an unknown function f from noisy measurements y = Af + w, where A is a linear operator and w is white noise with known covariance matrix Cw.  We assume that the operator A has been discretized on some grid (e.g., by using finite differences or spectral methods) so that it can be represented as a large matrix.  The goal is to find an estimatef such that Ef − f  2 is minimized subject to certain constraints on the smoothness off . \nIn this work we propose new numerical techniques based on needlets which are able to efficiently solve these constrained optimization problems.  In particular, our approach allows us to obtain accurate estimates even when the number N of available observations is much smaller than the dimension M of the space spanned by the columns of A. \nThe proposed method relies on two main ingredients:  First, we use a sparse representation of functions in terms of needlets.  Second, we develop efficient iterative algorithms for solving large-scale convex optimization problems involving sparsity-promoting regularizers.  These algorithms combine ideas from compressed sensing theory and recent results about the convergence rate of alternating direction method of multipliers (ADMM).",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Needlet techniques for estimation in inverse problems . Abstract : We consider the question of estimating an unknown function f from noisy measurements y = Af + f , where A is a linear operator and f is white sound with known covariance matrix Cw .We assume that the operator A has been discretized on some grid ( e . g . , by using finite differences or spectral algorithms ) so that it can be described as a large matrix . The goal is to find an estimatef such that Ef − f 2 is minimized subject to certain constraints on the smoothness off .In this study we develop new numerical tactics based on needlets which are able to easily solution these constrained optimization problems . In particular , our approach allows us to obtain precise estimates even when the number N of available observed is much smaller than the dimension M of the space spanned by the rows of A .The proposed approach consists on two principal ingredients : First , we using a sparse representation of functions in terms of needlets . Second , we develop fast iterative techniques for solving large - scale convex optimization problems employing sparsity - preserving regularizers .These methods combine developments from compressed sensing theory and recent results about the convergence speed of alternating path method of multipliers ( ADMM ) .",
        "rewrite_text": "In this article, we address the challenge of estimating an unknown function \\( f \\) from noisy observations represented as \\( y = Af + f \\), where \\( A \\) denotes a linear operator and \\( f \\) is modeled as white noise with a known covariance matrix \\( C_w \\). We operate under the assumption that the operator \\( A \\) has been discretized on a grid, which can be achieved through techniques such as finite differences or spectral algorithms, allowing it to be represented as a large matrix. Our primary objective is to derive an estimate of \\( f \\) that minimizes the expected squared error \\( E[f - \\hat{f}]^2 \\), while adhering to specific smoothness constraints on \\( f \\).\n\nTo tackle this problem, we introduce innovative numerical techniques based on needlets, which facilitate the resolution of these constrained optimization challenges. Notably, our methodology is designed to yield accurate estimates even when the number of available observations \\( N \\) is significantly less than the dimensionality \\( M \\) of the space spanned by the rows of \\( A \\). The proposed framework is built upon two key components: first, we utilize a sparse representation of functions through needlets, which enhances our ability to capture essential features of \\( f \\). Second, we develop efficient iterative algorithms for addressing large-scale convex optimization problems, incorporating sparsity-preserving regularizers.\n\nThese advancements draw upon principles from compressed sensing theory and leverage recent findings regarding the rapid convergence of the Alternating Direction Method of Multipliers (ADMM). Our results demonstrate the effectiveness of needlet techniques in improving estimation accuracy in inverse problems, particularly in scenarios characterized by limited data availability. This work not only contributes to the theoretical understanding of estimation in inverse problems but also provides practical tools for applications across various scientific fields where such challenges are prevalent.",
        "ori-fast-z-score": 0.6831300510639733,
        "water-fast-z-score": 6.538530488755173,
        "rewrite-fast-z-score": 2.1358941442919024
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Enhanced Half-Metallicity in Edge-Oxidized Zigzag Graphene Nanoribbons .\nAbstract:\nWe report on the electronic structure and magnetic properties of zigzag graphene nanoribbons (ZGNRs) with different edge structures, including hydrogenated ZGNR (H-ZGNR), fluorinated ZGNR (F-ZGNR), oxygenated ZGNR (O-ZGNR), and nitrogen-doped O-ZGNR (N-ZGNR). We find that all these ZGNRs are half-metals except for H-ZGNR which is metallic. The band gaps of F-ZGNR and N-ZGNR increase as compared to those of pristine ZGNR due to the electronegativity difference between carbon atoms at edges and their neighbors. In contrast, the band gap decreases slightly when oxygen replaces one or two carbon atoms at each edge because of charge transfer from oxygen to neighboring carbon atom(s). Our results show that the spin polarization can be enhanced by introducing oxygen into the edges of ZGNRs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Enhanced Half - Metallicity in Edge - Oxidized Zigzag Graphene Nanoribbons . Abstract : We report on the electronic structure and magnetic properties of zigzag graphene nanoribbons ( ZGNRs ) with various edge structures , notably hydrogenated ZGNR ( H - ZGNR ) , fluorinated ZGNR ( F - ZGNR ) , oxygenated ZGNR ( O - ZGNR ) , and nitrogen - doped O - ZGNR ( N - ZGNR ) .We see that all these ZGNRs are half - metals except for H - ZGNR which is metallic . The band holes of F - ZGNR and N - ZGNR increase as compared to those of pristine ZGNR due to the electronegativity difference between carbon atoms at corners and their relatives .In contrast , the band gap falls slightly when oxygen replaces one or two carbon atoms at each edge because of charge transfer from oxygen to neighboring carbon atom ( s ) . Our results show that the spin polarization can be enhanced by bringing oxygen into the edges of ZGNRs .",
        "rewrite_text": "We present a comprehensive study on the electronic and magnetic characteristics of zigzag graphene nanoribbons (ZGNRs) featuring diverse edge modifications, specifically focusing on hydrogenated ZGNR (H-ZGNR), fluorinated ZGNR (F-ZGNR), oxygenated ZGNR (O-ZGNR), and nitrogen-doped O-ZGNR (N-ZGNR). Our findings indicate that all the examined ZGNRs exhibit half-metallic behavior, with the exception of H-ZGNR, which displays metallic properties. Notably, the band gaps of F-ZGNR and N-ZGNR are observed to increase relative to those of pristine ZGNR, a phenomenon attributed to the differences in electronegativity between the carbon atoms located at the edges and their neighboring counterparts. Conversely, the introduction of oxygen at the edges results in a slight reduction of the band gap when one or two carbon atoms are substituted, primarily due to charge transfer from the oxygen atoms to adjacent carbon atoms. This research highlights the potential of edge oxidation in enhancing spin polarization within ZGNRs, suggesting that the incorporation of oxygen at the edges can significantly influence their electronic properties. Our results contribute to the understanding of how edge functionalization can be utilized to tailor the magnetic and electronic properties of graphene-based materials for applications in spintronics and other advanced technologies.",
        "ori-fast-z-score": 0.13736056394868904,
        "water-fast-z-score": 2.721655269759087,
        "rewrite-fast-z-score": -0.43133109281375365
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Decision tree modeling with relational views .\nAbstract:\nWe present an approach to decision tree learning that uses views over the data in order to improve efficiency and scalability. The proposed method is based on the idea of using multiple views, each one capturing different aspects or features of the same dataset. We show how this can be achieved by defining a set of views for each node in the decision tree model being learned. These views are then used as input to a modified version of the standard ID3 algorithm which learns the decision tree structure. Our experimental results demonstrate significant improvements in terms of both accuracy and execution time when compared against existing approaches. Decision trees have been widely applied in many areas such as classification, regression analysis, clustering, association rule mining, etc., due to their simplicity and effectiveness. However, they suffer from two main drawbacks: (1) high computational cost; and (2) poor scalability. In particular, the number of possible splits at any given internal node grows exponentially with respect to the size of its parent s training sample. This makes it difficult to build large decision trees efficiently. To address these problems we propose a novel approach called Relational Views-based Decision Tree Learning (RV-DTL). RV-DTL builds upon the concept of multi-view learning where each view captures some aspect(s) of the original data. More specifically, our approach defines a set of views for every internal node in the decision tree being built. Each view corresponds to a specific feature subset associated with the corresponding node. Then, instead of building the entire decision tree from scratch, RV-DTL starts with small sub-trees rooted at leaf nodes and iteratively expands them towards the root until all leaves are reached. At each expansion step, RV-DTL selects the best split among those available according to the information gain criterion. Finally, the final decision tree is constructed by merging together...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Decision tree modeling with relational views . Abstract : We present an way to decision tree study that using views over the information in order to promote efficiency and scalability .The proposed approach is based on the idea of using multiple views , each one capturing different components or elements of the same dataset . We see how this can be obtained by creating a setting of views for each node in the decision tree model being learned .These views are then added as input to a altered version of the standard ID3 algorithm which explains the decision tree shape . Our research results show considerable improvements in terms of both precision and execution time when compared against existing techniques .Decision trees have been widely applied in different areas such as classification , regression evaluation , clustering , association rule extraction , etc . , owing to their simplicity and effectiveness . However , they suffer from two principal drawbacks : ( 1 ) great computational efficiency ; and ( 2 ) poor scalability .In particular , the proportion of possible splits at any certain internal node grows exponentially with regard to the height of its parent s training sample . This creates it difficult to build large decision forests efficiently .To address these problems we undertake a new approach titled Relational Views - based Decision Tree Learning ( RV - DTL ) . RV - DTL relies upon the idea of multi - view processing where each vision reflects some aspect ( s ) of the actual data .More specifically , our approach defines a setting of views for every internal node in the decision tree being built . Each view belongs to a certain feature subset associated with the respective node .Then , rather of building the entire choice tree from scratch , RV - DTL began with little sub - forests rooted at leaf nodes and iteratively builds them towards the root until all leaves are reached . At each expansion stage , RV - DTL selects the best split among those available based to the information gain criterion .Finally , the finished judgment tree is built by merging together . . .",
        "rewrite_text": "**Title: Decision Tree Modeling with Relational Views**\n\n**Abstract:** In this paper, we introduce a novel approach to decision tree modeling that leverages relational views of data to enhance efficiency and scalability. Our method is predicated on the concept of utilizing multiple views, each representing distinct components or aspects of the same dataset. We demonstrate how this can be achieved by establishing a set of views for each node within the decision tree being constructed. These views serve as inputs to a modified version of the traditional ID3 algorithm, which governs the structure of the decision tree.\n\nOur findings reveal significant advancements in both accuracy and processing speed when juxtaposed with existing methodologies. Decision trees are widely utilized across various domains, including classification, regression analysis, clustering, and association rule mining, due to their straightforwardness and effectiveness. Nevertheless, they face two major challenges: (1) high computational demands and (2) limited scalability. Specifically, the number of potential splits at any given internal node increases exponentially with the size of its parent’s training sample, complicating the efficient construction of large decision forests.\n\nTo tackle these challenges, we propose a new framework termed Relational Views-based Decision Tree Learning (RV-DTL). This approach is grounded in multi-view processing, where each view encapsulates specific characteristics of the underlying data. More precisely, RV-DTL establishes a set of views for each internal node in the decision tree. Each view corresponds to a particular subset of features relevant to the respective node. Rather than constructing the entire decision tree from the ground up, RV-DTL initiates the process with small sub-forests anchored at leaf nodes, progressively expanding them towards the root until all leaves are incorporated. During each growth phase, RV-DTL identifies the optimal split based on the information gain criterion. Ultimately, the complete decision tree is formed by merging these sub-forests, resulting in a more efficient and scalable model.",
        "ori-fast-z-score": -1.758853959674307,
        "water-fast-z-score": 7.741954088429138,
        "rewrite-fast-z-score": -1.7728105208558367
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Clustering features of $^9$Be, $^{14}$N, $^7$Be, and $^8$B nuclei in relativistic fragmentation .\nAbstract:\nThe clustering properties of light nuclei are studied within the framework of the relativistic fragmentation model (RFM). The RFM is based on the concept that nuclear matter can be considered as an ensemble of clusters which interact with each other by means of effective potentials. In this work we have used the microscopic cluster-cluster interaction potential developed recently for the description of light nuclei at low energies. We show that the RFM reproduces well the experimental data available for the production cross sections of different fragments produced in heavy ion collisions at intermediate energies. \n \n Keywords: Clusterization; Fragmentation; Light nuclei; Relativistic approach; Heavy ions; Microscopic interactions. 1 Introduction Nuclear structure studies play important role in understanding many phenomena observed in nuclear physics experiments  1  . One of these phenomena is the clustering effect  2  , i.e., the tendency to form bound states consisting of several particles or even larger systems like α-particles  3  .\nIn recent years there has been considerable interest in studying the clustering effects in light nuclei  4  -  8  . It was shown  9  that the clustering phenomenon plays significant role in describing the ground state properties of light nuclei such as binding energy, charge radius etc.. Moreover it was found  10  that the clustering effect also influences significantly the reaction dynamics of light nuclei. For example, the formation probability of compound nucleus in fusion reactions depends strongly on the number of clusters present in the entrance channel  11  . Therefore, one should take into account the clustering degrees of freedom when investigating the reaction mechanism of light nuclei  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Clustering aspects of $ ^ 9 $ Be , $ ^ { 14 } $ N , $ ^ 7 $ Be , and $ ^ 8 $ B nuclei in relativistic fragmentation . Abstract : The clustering qualities of light nuclei are studied within the framework of the relativistic fragmentation model ( RFM ) .The RFM is based on the idea that atomic matter can be regarded as an ensemble of clusters which interact with each other by means of effective potentials . In this research we have utilized the microscopic cluster - cluster interaction potential developed lately for the description of light nuclei at low energies .We suggest that the RFM reproduces well the empirical data available for the production cross sections of different fragments produced in heavy atom collisions at intermediate energies . Keywords : Clusterization ; Fragmentation ; Light nuclei ; Relativistic approach ; Heavy electrons ; Microscopic interactions .1 Introduction Nuclear structure researchers play crucial role in understanding several phenomena observed in nuclear science studies 1 . One of these phenomena is the clustering effect 2 , i . e . , the tendency to form bound states consisting of several particles or especially bigger systems like α - particles 3 .In recent years there has been substantial interest in investigating the clustering effects in light nuclei 4 - 8 . It was shown 9 that the clustering phenomenon plays significant influence in understanding the ground state properties of light nuclei such as bound energy , charge radius etc . .Moreover it was shown 10 that the clustering effect also influences significantly the reaction dynamics of light nuclei . For instance , the formation likelihood of compound nucleus in fusion compounds depends strongly on the quantity of clusters present in the entrance channel 11 .Therefore , one should take into consideration the clustering degrees of liberty when examining the reaction mechanism of light nuclei 12 .",
        "rewrite_text": "**Title:** Clustering Aspects of $^9$Be, $^{14}$N, $^7$Be, and $^8$B Nuclei in Relativistic Fragmentation\n\n**Abstract:** This study investigates the clustering characteristics of light nuclei using the relativistic fragmentation model (RFM). The RFM conceptualizes atomic matter as a collection of clusters that interact through effective potentials. In our research, we have employed a recently developed microscopic cluster-cluster interaction potential to analyze light nuclei at low energy levels. Our findings indicate that the RFM effectively reproduces empirical data regarding the production cross sections of various fragments generated during heavy ion collisions at intermediate energies. The phenomenon of clustering, which refers to the formation of bound states composed of multiple particles or larger systems such as alpha particles, has garnered significant attention in recent years. It has been demonstrated that clustering significantly impacts the ground state properties of light nuclei, including binding energy and charge radius. Furthermore, the clustering effect plays a crucial role in the reaction dynamics of light nuclei; for example, the likelihood of compound nucleus formation in fusion reactions is heavily influenced by the number of clusters present in the entrance channel. Consequently, it is essential to consider the degrees of freedom associated with clustering when analyzing the reaction mechanisms of light nuclei. This research contributes to a deeper understanding of the clustering effects in nuclear physics and highlights the importance of the RFM in modeling these phenomena. \n\n**Keywords:** Clusterization; Fragmentation; Light nuclei; Relativistic approach; Heavy ions; Microscopic interactions.",
        "ori-fast-z-score": 1.872764367669247,
        "water-fast-z-score": 7.326721713278715,
        "rewrite-fast-z-score": 1.4605934866804429
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Physical Layer Network Coding .\nAbstract:\nIn this thesis, we study the problem of physical layer network coding (PLNC) in wireless networks with multiple relays and single-antenna nodes.  We first consider PLNC for two-way relay channels where each node has only one antenna.  In particular, we propose an efficient scheme to perform PLNC at both source nodes simultaneously by using linear codes over finite fields.  Then, we extend our results to multi-way relay channels with more than two users.  Finally, we investigate the performance of PLNC under imperfect channel state information (CSI). The main contributions are summarized as follows:  1. Two-way Relay Channels: We propose a novel approach to perform PLNC at the sources simultaneously based on linear codes over finite fields.   2. Multi-Way Relay Channels: By extending our previous work, we develop a new method to perform PLNC at all source nodes simultaneously.  3. Imperfect Channel State Information: We analyze the impact of imperfect CSI on the performance of PLNC schemes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Physical Layer Network Coding . Abstract : In this dissertation , we study the issue of physical layer network coding ( PLNC ) in telecommunications networks with many relays and single - antenna nodes .We first consider PLNC for two - way relay channels where each node has only one antenna . In particular , we propose an efficient scheme to conduct PLNC at both source nodes simultaneously by using linear codes over discrete fields .Then , we expanded our findings to multi - way relay channels with more than two users . Finally , we investigate the performance of PLNC under imperfect channel state information ( CSI ) .The main contributions are presented as follows : 1 . Two - way Relay Channels : We suggest a innovative method to conduct PLNC at the sources simultaneously based on linear codes over discrete fields .2 . Multi - Way Relay Channels : By extending our previous research , we develop a new method to conduct PLNC at all source nodes simultaneously .3 . Imperfect Channel State Information : We evaluate the impact of imperfect CSI on the performance of PLNC schemes .",
        "rewrite_text": "Title: Physical Layer Network Coding\n\nAbstract: This dissertation explores the concept of physical layer network coding (PLNC) within telecommunications networks characterized by multiple relays and single-antenna nodes. Our initial focus is on two-way relay channels, where each participating node is equipped with a single antenna. We introduce an innovative and efficient approach that enables simultaneous PLNC at both source nodes by employing linear codes over discrete fields. Building on this foundation, we extend our analysis to multi-way relay channels involving more than two users, thereby broadening the applicability of our findings. Furthermore, we delve into the performance implications of PLNC when faced with imperfect channel state information (CSI), a common challenge in practical communication scenarios. The primary contributions of this work are threefold: \n\n1. In the context of two-way relay channels, we present a novel methodology that facilitates simultaneous PLNC at the source nodes, leveraging linear coding techniques over discrete fields to enhance communication efficiency.\n2. For multi-way relay channels, we advance our previous research by developing a comprehensive strategy that allows for concurrent PLNC across all source nodes, thereby optimizing the overall network throughput.\n3. We conduct a thorough evaluation of how imperfect CSI affects the performance of PLNC schemes, providing insights into the robustness and reliability of these coding techniques under real-world conditions.\n\nThrough these contributions, this dissertation aims to enhance the understanding and implementation of PLNC in various network configurations, ultimately contributing to more efficient and reliable telecommunications systems.",
        "ori-fast-z-score": 2.060839349277234,
        "water-fast-z-score": 5.467773927672753,
        "rewrite-fast-z-score": 1.863448669773839
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The accretion origin of the Milky Way s stellar halo .\nAbstract:\nWe present an analysis of the kinematics and chemical composition of stars in the outer halo (R > 20 kpc) of our Galaxy, based on data obtained with the Sloan Digital Sky Survey (SDSS). We find that these stars are consistent with being drawn from two populations: one is metal-poor and has a mean metallicity  Fe/H  = -1.7 dex, while the other population is more metal-rich with a mean metallicity   Fe / H   = -0.8 dex . The former population shows a clear rotation signature around Galactic North Pole, which we interpret as evidence for its formation by tidal disruption of dwarf galaxies; this interpretation is supported by their high orbital eccentricities. On the other hand, the latter population does not show any significant rotation or orbital anisotropy, suggesting that it was formed through dissipative processes such as gas cooling and star formation.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The accretion origin of the Milky Way s stellar halo . Abstract : We present an assessment of the kinematics and chemical composition of stars in the exterior halo ( R > 20 kpc ) of our Galaxy , using on evidence derived with the Sloan Digital Sky Survey ( SDSS ) .We see that these stars are compatible with being drawn from two communities : one is metal - weak and has a mean metallicity Fe / H = - 1 . 7 dex , while the other population is more metal - rich with a mean metallicity Fe / H = - 0 . 8 dex . The former population shows a clear rotation signature around Galactic North Pole , which we treat as proof for its formation by tidal disruption of dwarf stars ; this interpretation is backed by their high orbital eccentricities .On the other hand , the latter population does not show any considerable rotation or orbital anisotropy , showing that it was formed through dissipative processes such as gas melting and star formation .",
        "rewrite_text": "In this study, we investigate the kinematics and chemical characteristics of stars located in the outer halo of the Milky Way, specifically at distances greater than 20 kpc from the Galactic center. Utilizing data from the Sloan Digital Sky Survey (SDSS), we identify two distinct stellar populations within this region. The first population is characterized by low metallicity, with an average iron-to-hydrogen ratio (Fe/H) of -1.7 dex, indicating a metal-poor composition. This group exhibits a notable rotation pattern around the Galactic North Pole, which we interpret as evidence of its formation through the tidal disruption of dwarf galaxies. The high orbital eccentricities observed in this population further support this hypothesis, suggesting a dynamic history influenced by interactions with smaller galactic structures.\n\nConversely, the second population is more metal-rich, with a mean metallicity of Fe/H = -0.8 dex. Unlike the first group, this population does not display significant rotation or orbital anisotropy, implying a different formation mechanism. We propose that this population originated from dissipative processes, such as gas cooling and subsequent star formation, which allowed for a more uniform distribution of stellar orbits. Our findings contribute to the understanding of the formation and evolution of the Milky Way's stellar halo, highlighting the complex interplay between accretion events and the chemical enrichment of the Galaxy. This research underscores the importance of examining the kinematic and chemical properties of stellar populations to unravel the history of galactic formation and the processes that shape the structure of our Galaxy.",
        "ori-fast-z-score": -1.6644794391276478,
        "water-fast-z-score": 3.048003048004572,
        "rewrite-fast-z-score": 0.09667364890456635
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  What are the Best Hierarchical Descriptors for Complex Networks? .\nAbstract:\nWe propose an algorithm to find optimal hierarchical descriptors (OHDs) that can be used as fingerprints in complex networks, such as social and biological systems. The OHDs represent network structures at different levels of granularity by using a tree-like structure with nodes representing subnetworks or clusters. We show how these trees can be constructed efficiently based on modularity maximization algorithms. In addition, we introduce a novel concept called  clustering coefficient  which is useful when constructing OHDs. Finally, we demonstrate our method through several examples including synthetic benchmark data sets and real-world networks. Our results suggest that the proposed approach provides more accurate descriptions than existing methods. This work was supported by JSPS KAKENHI Grant Number JP26287040. Keywords: Hierarchical descriptor, Clustering coefficient, Modularity Maximization Algorithm, Tree Structure, Fingerprint, Network Description",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  What are the Best Hierarchical Descriptors for Complex Networks?.Abstract : We suggest an algorithm to find optimal hierarchical descriptors ( OHDs ) that can be used as fingerprints in complex networks , such as social and biological environments . The OHDs represent system structures at different levels of granularity by using a tree - like structure with vertices representing subnetworks or communities .We see how these trees can be built easily using on modularity maximization algorithms . In addition , we provide a new notion called clustering coefficient which is important when constructing OHDs .Finally , we prove our technique through several examples namely natural benchmark data sets and actual - global networks . Our results show that the suggested approach offers more accurate descriptions than existing techniques .This project was supported by JSPS KAKENHI Grant Number JP26287040 . Keywords : Hierarchical descriptor , Clustering coefficient , Modularity Maximization Algorithm , Tree Structure , Fingerprint , Network Description",
        "rewrite_text": "Title: Identifying Optimal Hierarchical Descriptors for Complex Networks\n\nAbstract: In this study, we propose a novel algorithm designed to identify optimal hierarchical descriptors (OHDs) that serve as effective fingerprints for complex networks, including those found in social and biological contexts. OHDs encapsulate the structural characteristics of a system at varying levels of granularity, utilizing a tree-like framework where the vertices correspond to subnetworks or communities within the larger network. We demonstrate that these hierarchical trees can be constructed efficiently through the application of modularity maximization algorithms. Furthermore, we introduce an innovative concept known as the clustering coefficient, which plays a crucial role in the development of OHDs. To validate our methodology, we present a series of examples drawn from both natural benchmark datasets and real-world global networks. Our findings indicate that the proposed approach yields significantly more precise network descriptions compared to existing methods. This research was made possible through the support of JSPS KAKENHI Grant Number JP26287040. \n\nKeywords: Hierarchical descriptor, Clustering coefficient, Modularity maximization algorithm, Tree structure, Fingerprint, Network description.",
        "ori-fast-z-score": -0.3721042037676254,
        "water-fast-z-score": 5.986302773458956,
        "rewrite-fast-z-score": -0.5773502691896257
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Physics Case for the New Muon (g-2) Experiment .\nAbstract:\nThe Standard Model is in excellent agreement with all current experimental data, but it leaves many questions unanswered and fails to provide an explanation for some phenomena observed experimentally.  The muon magnetic moment anomaly provides one such example where there are significant discrepancies between theory predictions and experiment measurements that cannot be explained within the Standard Model framework.   In this talk I will present the physics case for the new g-2 experiment at Fermilab which aims to measure the anomalous magnetic moment of the muon more accurately than ever before by using a novel technique based on laser cooling and trapping techniques developed over recent years.   ... This talk presents the physics case for the proposed new measurement of the muon s anomalous magnetic moment at Fermilab. It describes how the use of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous experiments. A number of other topics related to the project are also discussed including the status of the R&D program towards the goal of measuring the muon magnetic moment to 0.5 parts per million accuracy.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Physics Case for the New Muon ( g - 2 ) Experiment . Abstract : The Standard Model is in good agreement with all recent experimental evidence , but it leaves many issues unanswered and fails to provide an description for some phenomena observed experimentally .The muon magnetic moment anomaly presents one such example where there are significant discrepancies between theoretical estimates and experiment measurements that cannot be described within the Standard Model framework . In this talk I will present the physics case for the new g - 2 study at Fermilab which aims to measure the anomalous magnetic moment of the muon more accurately than ever before by using a new technique based on laser cooling and trapping techniques established over recent months .. . . This discussion presents the physics case for the new modern observation of the muon s anomalous magnetic point at Fermilab .It details how the using of laser cooling and trapping can lead to a dramatic improvement in precision compared to previous research . A several of other topics related to the project are also discussed including the status of the R & D study towards the objective of monitoring the muon magnetic moment to 0 . 5 parts per million accuracy .",
        "rewrite_text": "Title: The Physics Case for the New Muon (g - 2) Experiment\n\nAbstract: The Standard Model of particle physics has consistently aligned with a multitude of experimental findings; however, it remains incomplete, leaving several fundamental questions unanswered and failing to account for certain observed phenomena. One notable example is the muon magnetic moment anomaly, where a significant gap exists between theoretical predictions and experimental measurements, a discrepancy that the Standard Model cannot adequately explain. This presentation outlines the scientific rationale behind the new g - 2 experiment at Fermilab, which seeks to achieve unprecedented precision in measuring the anomalous magnetic moment of the muon. By employing advanced laser cooling and trapping techniques developed in recent months, this experiment aims to enhance measurement accuracy beyond previous efforts. The discussion will delve into the innovative methodologies being utilized, highlighting how these advancements can lead to substantial improvements in precision compared to earlier studies. Additionally, the presentation will cover various related topics, including the current status of research and development efforts aimed at achieving a measurement accuracy of 0.5 parts per million for the muon magnetic moment. This ambitious project not only seeks to refine our understanding of the muon but also has the potential to provide insights into physics beyond the Standard Model, thereby addressing some of the unresolved questions that continue to challenge theoretical physicists.",
        "ori-fast-z-score": 1.237705495510552,
        "water-fast-z-score": 7.219948723811553,
        "rewrite-fast-z-score": 0.19245008972987526
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dielectric Relaxation and Phase Transition at Cryogenic Temperatures in 0.65 Pb(Ni_1/3Nb_2/3)O_3 -0.35PbTiO_3 Ceramics .\nAbstract:\nThe dielectric properties, phase transition behavior, and microstructure evolution were investigated for the (0.65 Pb(Ni-1/3Nb-2/3)O_3  -0.35PbTiO3) (PNT) ceramics with different sintering temperatures ranging from 850 to 1100 °C. The PNT samples exhibited high permittivity values up to ~10 4 , low loss tangent below 10 -2 , and large tunability over 30% under an electric field strength of 30 kV/cm at room temperature. With decreasing temperature down to 77 K, the permittivity increased slightly while the loss tangent decreased significantly due to the freezing out of mobile ions. At cryogenic temperatures, two relaxation processes were observed in the frequency range between 1 Hz and 100 kHz. The first process was attributed to the grain boundary effect; it shifted towards higher frequencies as the temperature decreased. The second process was associated with ferroelectric domain wall motion; its relaxation time constant remained almost unchanged when the temperature changed.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dielectric Relaxation and Phase Transition at Cryogenic Temperatures in 0 . 65 Pb ( Ni _ 1 / 3Nb _ 2 / 3 ) O _ 3 - 0 . 35PbTiO _ 3 Ceramics . Abstract : The dielectric characteristics , phase change response , and microstructure behavior were researched for the ( 0 . 65 Pb ( Ni - 1 / 3Nb - 2 / 3 ) O _ 3 - 0 . 35PbTiO3 ) ( PNT ) ceramics with various sintering rates ranging from 850 to 1100 °C .The PNT specimens exhibited high permittivity values up to ~ 10 4 , low loss tangent below 10 - 2 , and large tunability over 30 % under an electric field intensity of 30 kV / cm at room temperature . With decreasing temperature down to 77 K , the permittivity increased somewhat while the gain tangent decreased significantly related to the freezing out of mobile electrons .At cryogenic temperatures , two relaxation processes were detected in the frequency spectrum between 1 Hz and 100 kHz . The first mechanism was due to the grain boundary phenomenon ; it shifted towards higher frequencies as the temperature reduced .The second process was correlated with ferroelectric domain wall motion ; its relax time constant remained nearly unchanged when the temperature changed .",
        "rewrite_text": "**Title:** Dielectric Relaxation and Phase Transition at Cryogenic Temperatures in 0.65 Pb(Ni1/3Nb2/3)O3 - 0.35PbTiO3 Ceramics\n\n**Abstract:** This study investigates the dielectric properties, phase transition behavior, and microstructural characteristics of 0.65 Pb(Ni1/3Nb2/3)O3 - 0.35PbTiO3 (PNT) ceramics, focusing on samples sintered at temperatures ranging from 850 to 1100 °C. The PNT ceramics demonstrated remarkable dielectric performance, achieving permittivity values approaching 10,000, a low loss tangent below 0.01, and a tunability exceeding 30% when subjected to an electric field of 30 kV/cm at ambient temperature. As the temperature was lowered to 77 K, an increase in permittivity was observed, accompanied by a significant reduction in the loss tangent, attributed to the immobilization of charge carriers. At cryogenic temperatures, two distinct dielectric relaxation processes were identified within the frequency range of 1 Hz to 100 kHz. The first relaxation mechanism, associated with grain boundary effects, exhibited a shift towards higher frequencies with decreasing temperature. In contrast, the second relaxation process, linked to the motion of ferroelectric domain walls, displayed a relatively stable relaxation time constant, remaining largely unaffected by temperature variations. These findings provide valuable insights into the dielectric behavior and phase transitions of PNT ceramics at low temperatures, highlighting their potential applications in advanced electronic devices operating under cryogenic conditions. The results underscore the importance of sintering temperature in tailoring the dielectric properties of these materials, paving the way for future research into their performance in various technological applications.",
        "ori-fast-z-score": -0.3464101615137754,
        "water-fast-z-score": 5.505977612893481,
        "rewrite-fast-z-score": 0.2873478855663454
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Reduced dimensionality in layered quantum dimer magnets: Frustration vs. inhomogeneous condensates .\nAbstract:\nWe study the ground state properties of frustrated spin-1/2 Heisenberg models on square lattices with different types of interlayer couplings, including both homogeneous and inhomogeneous ones. We show that frustration can be suppressed by introducing an additional ferromagnetic coupling between layers which leads to formation of inhomogeneous magnetic states characterized by spatially modulated magnetization profiles. The obtained results are discussed within the framework of the recently developed concept of ``inverse condensation  . Introduction: In recent years there has been growing interest in studying strongly correlated systems where competing interactions lead to complex phase diagrams exhibiting various exotic phases such as valence bond solids (VBS), charge density waves (CDW) or supersolids  1-3 . One of the most interesting examples is provided by layered quantum antiferromagnets  4  . These compounds consist of weakly coupled planes of spins arranged into a regular lattice structure. Due to strong geometrical frustration caused by competing nearest-neighbor exchange interactions J1 along the chain direction and J2 across the chains, these materials exhibit a rich variety of physical phenomena ranging from conventional Néel order at low temperatures down to disordered paramagnetic phases  5  .\nIn this work we consider two prototypical representatives of this class of materials: CuGeO3  6  , where each plane consists of edge-sharing tetrahedra forming a honeycomb-like network  7, 8  , and BaCo2As2  9  , where the planes are made up of corner-sharing triangles  10  . Both compounds have attracted considerable attention due to their unusual magnetic behavior  11, 12  . For example, it was shown experimentally that in CuGeO3 the system undergoes a transition from a collinear antiferromagnetically ordered state below TN = 29 K to a non-collinear VBS state above T* ~ 70 K  13  . On the other hand, for BaCo2As2 the situation seems more complicated since several experimental studies suggest coexistence of three different magnetic phases  14, 15  : a commensurate antiferromagnetically ordered phase below TC = 38 K; a helimagnetic",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Reduced dimensionality in layered quantum dimer magnets : Frustration vs . inhomogeneous condensates . Abstract : We research the ground state properties of frustrated spin - 1 / 2 Heisenberg configurations on square lattices with various types of interlayer couplings , including both homogeneous and inhomogeneous ones .We see that frustration can be suppressed by creating an additional ferromagnetic coupling between layers which results to formation of inhomogeneous magnetic states characterized by spatially modulated magnetization profiles . The achieved findings are discussed within the framework of the recently established concept of ` ` inverse condensation .Introduction : In recent years there has been growing interest in investigating strongly interacting systems where competing interactions result to complex phase diagrams displaying various exotic phases such as valence bond solids ( VBS ) , charge density waves ( CDW ) or supersolids 1 - 3 . One of the most important examples is provided by layered quantum antiferromagnets 4 .These compounds comprise of mildly coupled planes of spinning grouped into a regular lattice structure . Due to heavy geometrical problems caused by competing nearest - neighbor exchange interactions J1 along the chain direction and J2 across the chains , these structures exhibit a rich range of physical phenomena ranging from standard Néel order at low temperatures down to disordered paramagnetic phases 5 .In this research we investigate two prototypical representatives of this class of substances : CuGeO3 6 , where each plane consists of edge - sharing tetrahedra making a honeycomb - like network 7 , 8 , and BaCo2As2 9 , where the planes are making up of spot - sharing triangles 10 . Both compounds have garnered considerable scrutiny due to their extraordinary magnetic behavior 11 , 12 .For instance , it was shown experimentally that in CuGeO3 the system undergoes a shift from a collinear antiferromagnetically ordered state below TN = 29 K to a non - collinear VBS state above T * ~ 70 K 13 . On the other hand , for BaCo2As2 the situation appears more complicated since several experimental studies confirm coexistence of three different magnetic modes 14 , 15 : a commensurate antiferromagnetically ordered phase below TC = 38 K ; a helimagnetic",
        "rewrite_text": "**Title:** Reduced Dimensionality in Layered Quantum Dimer Magnets: Frustration vs. Inhomogeneous Condensates\n\n**Abstract:** This study delves into the ground state characteristics of frustrated spin-1/2 Heisenberg models on square lattices, examining various interlayer coupling configurations, both homogeneous and inhomogeneous. Our findings reveal that frustration can be mitigated through the introduction of an additional ferromagnetic coupling between layers, leading to the emergence of inhomogeneous magnetic states. These states are distinguished by spatially modulated magnetization profiles, which we analyze in the context of the recently proposed concept of \"inverse condensation.\" \n\nThe motivation for this research stems from the increasing interest in strongly interacting systems where competing interactions yield intricate phase diagrams featuring a variety of exotic phases, such as valence bond solids (VBS), charge density waves (CDW), and supersolids. Layered quantum antiferromagnets serve as prime examples of such systems, consisting of weakly coupled planes of spins arranged in a regular lattice. The interplay between competing nearest-neighbor exchange interactions, J1 along the chain direction and J2 across the chains, gives rise to a diverse array of physical phenomena, ranging from conventional Néel order at low temperatures to disordered paramagnetic phases.\n\nWe focus on two representative materials within this class: CuGeO3, characterized by planes of edge-sharing tetrahedra forming a honeycomb-like network, and BaCo2As2, composed of spot-sharing triangles. Both compounds have been the subject of extensive research due to their remarkable magnetic properties. For instance, CuGeO3 exhibits a transition from a collinear antiferromagnetically ordered state below TN = 29 K to a non-collinear VBS state above T* ~ 70 K. In contrast, BaCo2As2 presents a more complex scenario, with experimental evidence supporting the coexistence of three distinct magnetic phases: a commensurate antiferromagnetically ordered phase below TC = 38 K, alongside a helimagnetic state. This research contributes to the understanding of magnetic interactions in layered quantum systems and the role of frustration and inhomogeneity in shaping their ground state properties.",
        "ori-fast-z-score": 0.08247860988423225,
        "water-fast-z-score": 6.635778556204229,
        "rewrite-fast-z-score": 1.6666666666666667
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Is the Concentration of Dark Matter Halos at Virialization Universal ? .\nAbstract:\nWe study the concentration-mass relation for dark matter haloes in cosmological N-body simulations with different initial conditions and resolutions, focusing on the dependence on halo mass and redshift. We find that the concentrations are well described by an empirical formula proposed recently by Navarro et al. (2004) : c = c0(M/M0)^a(z), where M is the virial mass of the halo, z its formation time (defined as the epoch when half of the final mass was assembled into progenitors), c0 ,a and M0 are free parameters to be determined numerically. The best-fit values of these parameters depend only weakly on the simulation resolution or the initial power spectrum index n. In particular, we show that the value of a0 is independent of both n and the numerical resolution. This result suggests that the concentration of dark matter haloes may not be universal but depends on their formation history.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Is the Concentration of Dark Matter Halos at Virialization Universal ? .Abstract : We research the concentration - mass relation for black material haloes in cosmological N - bodies simulations with various initial conditions and resolutions , concentrating on the dependence on halo weight and redshift . We see that the levels are better represented by an empirical formula proposed lately by Navarro et al .( 2004 ) : c = c0 ( M / M0 ) ^ a ( z ) , where M is the virial mass of the halo , z its formation period ( understood as the epoch when half of the finished mass was assembled into progenitors ) , c0 , a and M0 are free parameters to be determined numerically . The best - fitting values of these parameters depend only weakly on the simulation resolution or the first power spectrum value n . In particular , we prove that the value of a0 is independent of both n and the numerical resolution .This result suggests that the concentration of grey matter haloes might not be universal but relies on their composition history .",
        "rewrite_text": "Title: Is the Concentration of Dark Matter Halos at Virialization Universal?\n\nAbstract: In this study, we investigate the relationship between concentration and mass for dark matter halos using cosmological N-body simulations that encompass a range of initial conditions and resolutions. Our primary focus is on how this relationship varies with halo mass and redshift. We find that the concentration levels are more accurately described by an empirical formula recently proposed by Navarro et al. (2004), expressed as c = c0 (M / M0) ^ a(z), where M denotes the virial mass of the halo, z represents the formation redshift (defined as the epoch at which half of the final mass was assembled into progenitors), and c0, a, and M0 are parameters that must be determined through numerical fitting. Our analysis reveals that the best-fitting values for these parameters exhibit only a weak dependence on the simulation resolution and the initial power spectrum index n. Notably, we demonstrate that the parameter a0 remains consistent regardless of variations in n and numerical resolution. This finding implies that the concentration of dark matter halos may not be a universal characteristic, but rather is influenced by their specific formation history. This research contributes to a deeper understanding of the structural properties of dark matter halos and their evolution, suggesting that the history of halo assembly plays a crucial role in determining their concentration at virialization. Our results have significant implications for cosmological models and the interpretation of dark matter halo dynamics in the context of structure formation in the universe.",
        "ori-fast-z-score": -0.808290376865476,
        "water-fast-z-score": 4.817730411281796,
        "rewrite-fast-z-score": 1.4985372985307104
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Polarization sensitive spectroscopy of charged Quantum Dots .\nAbstract:\nWe report on the polarization dependent photoluminescence (PL) and Raman scattering spectra of CdSe/CdS core/shell quantum dots in solution at room temperature. The PL spectrum shows that the emission is polarized along the direction perpendicular to the excitation light, which can be explained by the selection rules for dipole transitions between electronic states with different angular momenta. In addition we observe an anisotropic broadening of the Stokes linewidths as well as a splitting into two components when exciting circularly polarized light. These effects are attributed to the presence of exciton fine structure due to spin-orbit coupling. We also find evidence for a strong electron-phonon interaction leading to phonon sidebands in both the Stokes and anti-Stokes parts of the Raman spectrum. Finally, we show how these results can be used to determine the orientation of individual QDs embedded in a polymer matrix. Polarized luminescence measurements have been performed on single QD emitters using confocal microscopy.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Polarization sensitive spectroscopy of charged Quantum Dots . Abstract : We report on the polarization dependent photoluminescence ( PL ) and Raman absorption spectra of CdSe / CdS core / shell quantum dots in solution at room temperature .The PL spectrum reveals that the emission is polarized along the direction perpendicular to the excitation light , which can be described by the selection rules for dipole changes between electronic states with various angular momenta . In addition we exhibit an anisotropic broadening of the Stokes linewidths as well as a dividing into two parts when exciting circularly polarized light .These effects are traced to the presence of exciton fine structure owing to spin - orbit bonding . We additionally find proof for a powerful atom - phonon interaction leading to phonon sidebands in both the Stokes and anti - Stokes parts of the Raman spectrum .Finally , we show how these results can be used to predict the orientation of individual QDs integrated in a polymer matrix . Polarized luminescence measurements have been performed on single QD emitters using confocal microscopy .",
        "rewrite_text": "We present a comprehensive study on the polarization-sensitive photoluminescence (PL) and Raman absorption spectra of CdSe/CdS core/shell quantum dots in solution at ambient temperature. Our findings indicate that the PL emission is polarized in a direction that is perpendicular to the excitation light, a phenomenon that can be explained by the selection rules governing dipole transitions between electronic states characterized by different angular momenta. Furthermore, we observe an anisotropic broadening of the Stokes linewidths, which notably splits into two distinct components when excited with circularly polarized light. This behavior is attributed to the exciton fine structure resulting from spin-orbit coupling within the quantum dots. \n\nIn addition to these observations, we provide evidence of a significant atom-phonon interaction, which manifests as phonon sidebands in both the Stokes and anti-Stokes regions of the Raman spectrum. This interaction highlights the intricate coupling between electronic states and lattice vibrations in these nanostructures. \n\nMoreover, we discuss the implications of our findings for predicting the orientation of individual quantum dots when they are integrated into a polymer matrix. To validate our theoretical predictions, we conducted polarized luminescence measurements on single quantum dot emitters using confocal microscopy techniques. This approach allows for a detailed investigation of the polarization characteristics of individual quantum dots, providing insights into their potential applications in optoelectronic devices and quantum information technologies. Our results contribute to a deeper understanding of the optical properties of quantum dots and their interactions with light, paving the way for future advancements in nanotechnology and materials science.",
        "ori-fast-z-score": 0.47140452079103173,
        "water-fast-z-score": 4.649905549752772,
        "rewrite-fast-z-score": 1.3228756555322951
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Searching for New Physics in Future Neutrino Factory Experiments .\nAbstract:\nThe future neutrino factory experiments will be able to search for new physics beyond the Standard Model (SM) with unprecedented precision, and are expected to provide important information on the origin of matter-antimatter asymmetry as well as dark matter candidates.  In this talk I will present an overview of our recent studies on how to probe various types of new physics using these facilities. The results presented here were obtained by combining the analyses performed at the T2K experiment and its off-axis near detector ND280. These include searches for sterile neutrinos, lepton flavor violating processes such as neutrinoless double beta decay, CP violation effects in leptonic sector, and exotic Higgs bosons that can couple to both quarks and leptons. We also discuss possible improvements in sensitivity which may be achieved if we combine the data taken at T2K and NOvA experiments. Finally, prospects for probing new physics at future accelerator-based neutrino factories are discussed.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Searching for New Physics in Future Neutrino Factory Experiments . Abstract : The future neutrino production experiments will be possible to search for fresh physics beyond the Standard Model ( SM ) with incredible precision , and are expected to provide important information on the origin of matter - antimatter asymmetry as well as dark matter candidates .In this talk I will present an overview of our latest studies on how to probe various types of new science utilizing these facilities . The results presented here were obtained by combining the calculations performed at the T2K experiment and its off - axis near sensor ND280 .These include searches for sterile neutrinos , lepton flavor violating reactions such as neutrinoless double alpha emission , CP violation processes in leptonic sector , and rare Higgs bosons that can couple to both quarks and leptons . We additionally discuss possible advances in tolerance which may be obtained if we merge the information taken at T2K and NOvA studies .Finally , prospects for probing novel physics at possible accelerator - based neutrino plants are discussed .",
        "rewrite_text": "**Title: Exploring New Physics through Future Neutrino Factory Experiments**\n\n**Abstract:** Future neutrino production experiments hold the promise of uncovering new physics beyond the Standard Model (SM) with unprecedented precision. These experiments are anticipated to yield critical insights into the origins of matter-antimatter asymmetry and potential candidates for dark matter. In this presentation, I will provide a comprehensive overview of our recent investigations into various avenues for exploring new scientific phenomena using these advanced facilities. Our findings are derived from a combination of calculations conducted at the T2K experiment and its off-axis near detector, ND280. \n\nWe focus on several key areas of research, including the search for sterile neutrinos, investigations into lepton flavor-violating processes such as neutrinoless double beta decay, and the examination of CP violation within the leptonic sector. Additionally, we explore the potential for discovering rare Higgs bosons that may interact with both quarks and leptons. Our discussion extends to the potential improvements in experimental tolerance that could arise from integrating data from T2K and NOvA studies. \n\nFinally, we will outline the prospects for probing novel physics at future accelerator-based neutrino facilities, emphasizing the significance of these experiments in expanding our understanding of fundamental particles and interactions. The insights gained from these studies could not only enhance our comprehension of the universe but also pave the way for groundbreaking discoveries in particle physics.",
        "ori-fast-z-score": -0.6793662204867574,
        "water-fast-z-score": 5.590169943749474,
        "rewrite-fast-z-score": -0.6831300510639733
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Phenomenology of D-Brane Inflation with General Speed of Sound .\nAbstract:\nWe study the phenomenological consequences of general speed of sound in brane inflationary models, where the inflaton is identified as the distance between two parallel branes moving on an extra dimension. We find that for small values of the speed of sound (cs < 0.1), there are no significant changes to the predictions made by standard slow-roll inflation. However, when cs > 0.1 we find that the tensor-to-scalar ratio r and the running of the spectral index dns/d ln k can be significantly enhanced compared to their usual values predicted within the context of single field slow roll inflation. In particular, if cs = 1 then r = 16(nT)2/5 and dns/d ln k = −8(nT)1/5, which may provide a possible explanation for recent observations of high value of nT reported by WMAP7 data combined with other CMB experiments.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Phenomenology of D - Brane Inflation with General Speed of Sound . Abstract : We research the phenomenological consequences of general velocity of noise in brane inflationary theories , where the inflaton is identified as the distance between two connected branes moving on an additional dimension .We see that for little values of the speed of music ( cs < 0 . 1 ) , there are no major changes to the estimates made by traditional slow - roll inflation . However , when cs > 0 . 1 we find that the tensor - to - scalar ratio h and the running of the spectral index dns / d ln w can be substantially enhanced compared to their normal values anticipated within the context of double field fast roll inflation .In particular , if cs = 1 then r = 16 ( nT ) 2 / 5 and dns / d ln k = −8 ( nT ) 1 / 5 , which would offer a possible reason for recent observations of high value of nT reported by WMAP7 results coupled with other CMB experiments .",
        "rewrite_text": "Title: Phenomenology of D-Brane Inflation with General Speed of Sound\n\nAbstract: This study investigates the phenomenological implications of varying sound speeds in brane inflationary models, where the inflaton field is represented by the separation between two interconnected branes moving through an extra dimension. Our analysis reveals that for low sound speeds (cs < 0.1), the predictions align closely with those derived from conventional slow-roll inflation models, indicating minimal deviations in the inflationary dynamics. However, as the sound speed increases beyond this threshold (cs > 0.1), we observe significant enhancements in key cosmological parameters, particularly the tensor-to-scalar ratio (r) and the running of the spectral index (dns/dlnk). Notably, when cs is set to 1, we derive the relationships r = 16(nT)^2/5 and dns/dlnk = -8(nT)^(1/5), suggesting a compelling explanation for the recently reported high values of nT from WMAP7 and other cosmic microwave background (CMB) observations. These findings imply that the dynamics of brane inflation can be substantially altered by the sound speed, leading to observable consequences that may reconcile theoretical predictions with empirical data. Our results contribute to a deeper understanding of inflationary models and their potential to explain the large-scale structure of the universe, while also highlighting the importance of considering the effects of sound speed in future cosmological studies.",
        "ori-fast-z-score": -0.7276068751089989,
        "water-fast-z-score": 4.935819976516537,
        "rewrite-fast-z-score": -0.41256849850351734
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Evidence Of Dark Matter Annihilations In The WMAP Haze .\nAbstract:\nWe present evidence for dark matter annihilation in the cosmic microwave background (CMB) haze, which is an excess emission at large angles with respect to the Galactic center that was first detected by Wilkinson Microwave Anisotropy Probe (WMAP). We use data from Planck and Fermi Large Area Telescope (LAT), as well as new measurements of the CMB temperature anisotropies made using the Atacama Cosmology Telescope (ACT).\nThe observed spectrum of this signal can be explained if it originates from dark matter particles with masses between 1 GeV and 10 TeV, annihilating into pairs of photons or leptons. This interpretation requires a boost factor of about 100 relative to standard thermal relic expectations. \n \n If confirmed, our results would provide strong support for models where dark matter self-annihilates into Standard Model particles. They also have important implications on the nature of dark matter itself, since they require either non-thermal production mechanisms or additional interactions beyond those predicted within the minimal supersymmetric extension of the Standard Model.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Evidence Of Dark Matter Annihilations In The WMAP Haze . Abstract : We present evidence for black material annihilation in the cosmic microwave background ( CMB ) fog , which is an excess emission at large angles with regard to the Galactic center that was first detected by Wilkinson Microwave Anisotropy Probe ( WMAP ) .We use data from Planck and Fermi Large Area Telescope ( LAT ) , as also as additional measurements of the CMB heat anisotropies made using the Atacama Cosmology Telescope ( ACT ) . The observed spectrum of this signal can be understood if it originates from dark matter molecules with masses between 1 GeV and 10 TeV , annihilating into sets of photons or leptons .This interpretation needs a boost factor of about 100 compared to standard thermal relic estimates . If confirmed , our findings would offer strong evidence for models where black material self - annihilates into Standard Model particles .They especially have important implications on the nature of dark matter itself , since they use either non - temperature generation pathways or additional mechanisms beyond those predicted within the limited supersymmetric extension of the Standard Model .",
        "rewrite_text": "We provide compelling evidence for dark matter annihilations within the cosmic microwave background (CMB) haze, characterized by an excess emission observed at large angular scales relative to the Galactic center, initially identified by the Wilkinson Microwave Anisotropy Probe (WMAP). Our analysis incorporates data from the Planck satellite and the Fermi Large Area Telescope (LAT), alongside supplementary measurements of CMB temperature anisotropies obtained from the Atacama Cosmology Telescope (ACT). The spectral characteristics of the detected signal suggest that it may arise from dark matter particles with masses ranging from 1 GeV to 10 TeV, which annihilate into pairs of photons or leptons. Notably, this interpretation necessitates a boost factor of approximately 100 when compared to conventional thermal relic predictions. If our findings are substantiated, they would provide robust support for theoretical frameworks in which dark matter undergoes self-annihilation into Standard Model particles. This has significant implications for our understanding of dark matter's fundamental nature, as it suggests the involvement of non-thermal production mechanisms or additional processes that extend beyond the confines of the minimal supersymmetric extension of the Standard Model. The results presented in this study could pave the way for new insights into the properties of dark matter and its interactions, potentially reshaping our comprehension of the universe's composition and the underlying physics governing it.",
        "ori-fast-z-score": 0.4588314677411235,
        "water-fast-z-score": 5.887840577551898,
        "rewrite-fast-z-score": 0.9332565252573828
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Are Advanced Potentials Anomalous? .\nAbstract:\nWe present the results of an analysis of data on advanced potentials in hadronic collisions at high energies, obtained by the TOTEM experiment at LHC and by the UA7 collaboration at SppS collider. We show that these data are consistent with predictions based on Regge phenomenology for elastic scattering amplitudes. The observed behavior is also compatible with expectations from perturbative QCD calculations within the framework of the BFKL approach to high-energy evolution. \n \n Keywords: High energy physics, Elastic scattering amplitude, Perturbative QCD, BFKL equation, LHC, SppS, TOTEM, UA7 experiments \n \n 1 Introduction \n \n In recent years there has been considerable interest in studying the properties of elastic scattering amplitudes at very high energies (see e.g.,  1  ). This interest was triggered mainly by the discovery of new phenomena in this area made possible by the advent of accelerators operating at TeV scale such as the Large Hadron Collider (LHC)  2  . These discoveries include the observation of rapid growth of total cross sections  3  , dip-bump structure  4  , forward-backward asymmetry  5  , etc.. It should be noted however that many important questions remain open concerning the nature of the underlying dynamics responsible for all these effects  6  .\n \nIn particular, it remains unclear whether they can be explained within the conventional Regge theory  7, 8  or require more complicated approaches like those involving unitarization  9  and/or saturation  10  mechanisms. Another interesting question concerns the role played by higher-order corrections in perturbative Quantum Chromodynamics (QCD). Indeed, while the leading order BFKL  11  and DGLAP  12  equations provide reasonable description of experimental data  13  , their next-to-leading order extensions  14, 15  lead to significant deviations  16  which may indicate the need for resummation techniques  17  . \n \n 2 Data Analysis \n \n To shed some light on these issues we have performed detailed study of available data on elastic scattering processes collected recently by two dedicated experiments -the TOTEM  18  and UA7  19  collaborations. Both groups measured differential distributions dσ/d",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Are Advanced Potentials Anomalous?.Abstract : We present the results of an assessment of evidence on advanced potentials in hadronic collisions at high energies , obtained by the TOTEM study at LHC and by the UA7 collaboration at SppS collider . We see that these information are compatible with predictions based on Regge phenomenology for elastic scattering amplitudes .The observed behavior is also consistent with predictions from perturbative QCD calculations within the framework of the BFKL approach to large - energy evolution . Keywords : High energy physics , Elastic scattering amplitude , Perturbative QCD , BFKL equation , LHC , SppS , TOTEM , UA7 experiments 1 Introduction In recent years there has been substantial interest in investigating the properties of elastic scattering amplitudes at very high energies ( saw e . g . , 1 ) .This activity was sparked mainly by the discovery of new concepts in this area made possible by the advent of accelerators active at TeV scale such as the Large Hadron Collider ( LHC ) 2 . These finds feature the observation of rapid increase of complete cross sections 3 , dip - bump formation 4 , backwards - backward asymmetry 5 , etc . .It should be mentioned however that several important questions remain open concerning the nature of the fundamental interactions involved for all these influences 6 . In particular , it remains unsure whether they can be described within the standard Regge principle 7 , 8 or use more complicated approaches like those concerning unitarization 9 and / or saturation 10 mechanisms .Another important dispute concerns the importance played by higher - order corrections in perturbative Quantum Chromodynamics ( QCD ) . Indeed , while the led order BFKL 11 and DGLAP 12 equations offer reasonable explanation of theoretical data 13 , their next - to - leading order additions 14 , 15 lead to significant deviations 16 which would indicate the necessity for resummation methods 17 .2 Data Analysis To shed some light on these problems we have done thorough study of available data on elastic scattering systems collected lately by two dedicated studies - the TOTEM 18 and UA7 19 collaborations . Both groups recorded differential functions dσ / d",
        "rewrite_text": "**Title: Are Advanced Potentials Anomalous?**\n\n**Abstract:** This article presents a comprehensive evaluation of the evidence surrounding advanced potentials in high-energy hadronic collisions, drawing on findings from the TOTEM collaboration at the Large Hadron Collider (LHC) and the UA7 collaboration at the Super Proton Synchrotron (SppS) collider. Our analysis reveals that the data collected aligns well with predictions derived from Regge phenomenology concerning elastic scattering amplitudes. Furthermore, the observed phenomena are consistent with theoretical predictions from perturbative Quantum Chromodynamics (QCD) within the BFKL framework, which addresses large-energy evolution. The investigation into elastic scattering amplitudes has gained momentum in recent years, particularly following the emergence of new insights facilitated by TeV-scale accelerators like the LHC. Notable observations include the rapid escalation of total cross sections, the formation of dip-bump structures, and the presence of backward-backward asymmetry. Despite these advancements, several critical questions remain unresolved regarding the fundamental interactions that govern these effects. Specifically, it is still uncertain whether these interactions can be adequately described by the standard Regge principles or if they necessitate more complex frameworks, such as unitarization or saturation mechanisms. Additionally, the role of higher-order corrections in perturbative QCD is a topic of ongoing debate. While the leading-order BFKL and DGLAP equations provide a satisfactory explanation of theoretical data, the inclusion of next-to-leading order corrections introduces significant discrepancies, suggesting a need for resummation techniques. To address these issues, we conducted an extensive analysis of the elastic scattering data gathered by the TOTEM and UA7 collaborations, focusing on differential cross sections and their implications for our understanding of high-energy interactions. This study aims to clarify the nature of advanced potentials and their relevance in the context of current high-energy physics research.\n\n**Keywords:** High energy physics, Elastic scattering amplitude, Perturbative QCD, BFKL equation, LHC, SppS, TOTEM, UA7 experiments.",
        "ori-fast-z-score": -0.40961596025952024,
        "water-fast-z-score": 8.981462390204987,
        "rewrite-fast-z-score": 0.50709255283711
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Structural distortions and model Hamiltonian parameters: from LSDA to a tight-binding description of LaMnO_3 .\nAbstract:\nWe present the results of first-principles calculations for structural, electronic, magnetic properties of LaMnO3 in its rhombohedral phase (R3c). We show that the local spin density approximation (LSDA) fails to reproduce correctly both the lattice constants and the band gap energy. The latter is underestimated by more than one order of magnitude as compared with experiment. In contrast, our self-consistent full-potential linearized augmented plane wave method gives good agreement between calculated and experimental values of these quantities. \n \n To understand better the origin of this discrepancy we have performed additional calculations using an effective tight-binding approach based on Wannier functions obtained within the framework of the LSDA+U formalism. Our analysis shows that the main reason why the LSDA fails to describe properly the electronic structure of LaMnO3 is due to strong hybridization effects which are not taken into account adequately within the standard LSDA scheme.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Structural distortions and description Hamiltonian properties : from LSDA to a tight - binding model of LaMnO _ 3 . Abstract : We report the results of first - principles experiments for structural , electronic , magnetic properties of LaMnO3 in its rhombohedral phase ( R3c ) .We see that the local spin density algorithm ( LSDA ) fails to reproduce correctly both the crystal constants and the band gap energy . The latter is underestimated by more than one order of magnitude as compared with observation .In comparison , our self - consistent full - potential linearized augmented plane wave method gives excellent agreement between calculated and experimental values of these quantities . To understand better the origin of this discrepancy we have done additional calculations using an efficient tight - binding approach using on Wannier functions obtained within the framework of the LSDA + U formalism .Our study shows that the main explanation why the LSDA fails to explain adequately the electronic structure of LaMnO3 is due to powerful hybridization factors which are not took into consideration appropriately within the standard LSDA plan .",
        "rewrite_text": "**Title:** Structural Distortions and Hamiltonian Properties: Transitioning from LSDA to a Tight-Binding Model of LaMnO3\n\n**Abstract:** In this study, we present findings from first-principles calculations that investigate the structural, electronic, and magnetic properties of LaMnO3 in its rhombohedral phase (R3c). Our analysis reveals that the local spin density approximation (LSDA) significantly underestimates both the crystal lattice parameters and the band gap energy, with the latter being more than an order of magnitude lower than experimental observations. In contrast, our implementation of the self-consistent full-potential linearized augmented plane wave (FLAPW) method yields results that closely align with experimental data for these properties. To further elucidate the reasons behind the discrepancies observed with LSDA, we conducted supplementary calculations utilizing an efficient tight-binding model based on Wannier functions derived from the LSDA + U approach. Our findings indicate that the inadequacy of LSDA in accurately capturing the electronic structure of LaMnO3 primarily stems from the neglect of significant hybridization effects that are not sufficiently accounted for in the conventional LSDA framework. This work not only highlights the limitations of LSDA in describing complex materials like LaMnO3 but also demonstrates the effectiveness of combining advanced computational techniques to achieve a more accurate representation of their electronic properties. The insights gained from this research could pave the way for improved theoretical models and a deeper understanding of the intricate behaviors exhibited by transition metal oxides.",
        "ori-fast-z-score": -1.2939932784412609,
        "water-fast-z-score": 3.7523938719322816,
        "rewrite-fast-z-score": -0.19069251784911848
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Synergistic Gravity and the Role of Resonances in GRS-Inspired Braneworlds .\nAbstract:\nWe study gravitational interactions between two braneworlds, each with its own brane tension, by using an effective field theory approach that incorporates both Randall-Sundrum (RS) gravity and scalar-tensor theories. We show how this model can be used to describe the dynamics of binary systems such as double neutron stars or black holes. In particular we find that there are new resonant effects which occur when one object is much more massive than the other. These effects lead to large deviations from standard general relativity predictions for the orbital evolution of binaries containing compact objects. The results presented here may have important implications on our understanding of strong-field gravity phenomena like gravitational waves produced during mergers of supermassive black holes at galactic centers. Introduction: Gravitational wave observations will provide us with unprecedented information about the nature of gravity in the strongfield regime  1  . This has led to renewed interest in alternative models of gravity beyond Einstein s general relativity  2  , especially those inspired by string/M-theory  3  .\nIn recent years it was shown  4  -  8  that many interesting features of these models could be captured within the context of effective field theories where higher-dimensional fields propagate in extra dimensions  9  . One particularly successful class of models consists of so-called braneworld scenarios  10  , where Standard Model particles are confined to live on a four dimensional brane embedded in a five dimensional bulk space-time  11  . A number of authors  12  -  16  have studied the possibility of detecting signatures of braneworld physics through gravitational wave observations  17  -  20  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Synergistic Gravity and the Role of Resonances in GRS - Inspired Braneworlds . Abstract : We research gravitational interactions between two braneworlds , each with its own brane tension , by using an efficient field model approach that incorporates both Randall - Sundrum ( RS ) gravity and scalar - vector models .We see how this description can be used to explain the dynamics of binary systems such as double neutron galaxies or black holes . In particular we find that there are new resonant processes which occur when one object is much more massive than the other .These effects lead to large deviations from standard general relativity predictions for the orbital evolution of binaries bearing compact elements . The results presented here possibly have important implications on our grasp of high - field gravity phenomena like gravitational waves produced during mergers of supermassive black holes at galactic bases .Introduction : Gravitational wave studies will provide us with great data about the nature of gravitational in the strongfield regime 1 . This has led to renewed development in unconventional theories of gravitational beyond Einstein s general relativity 2 , particularly those influenced by string / M - theory 3 .In recent years it was shown 4 - 8 that several interesting features of these models could be captured within the context of effective field theories where greater - dimensional fields propagate in extra dimensions 9 . One especially successful class of models includes of so - called braneworld situations 10 , where Standard Model particles are confined to live on a four dimensional brane embedded in a five dimensional bulk space - time 11 .A several of authors 12 - 16 have researched the prospect of detecting signatures of braneworld physics through gravity wave studies 17 - 20 .",
        "rewrite_text": "**Title:** Synergistic Gravity and the Role of Resonances in GRS-Inspired Braneworlds\n\n**Abstract:** This study investigates the gravitational interactions between two braneworlds, each characterized by distinct brane tensions, utilizing an efficient field model that integrates both Randall-Sundrum (RS) gravity and scalar-vector frameworks. Our analysis reveals that this model effectively elucidates the dynamics of binary systems, such as double neutron stars and black holes. Notably, we identify novel resonant processes that emerge when there is a significant mass disparity between the two objects. These resonances result in substantial deviations from the predictions of standard general relativity regarding the orbital evolution of binaries containing compact objects. The findings presented in this paper may have significant implications for our understanding of high-field gravitational phenomena, particularly in relation to gravitational waves generated during the mergers of supermassive black holes located at the centers of galaxies. \n\nThe exploration of gravitational waves offers a promising avenue for acquiring insights into the nature of gravity in strong-field regimes. This has sparked renewed interest in alternative gravitational theories that extend beyond Einstein's general relativity, especially those influenced by string and M-theory. Recent research has demonstrated that many intriguing features of these theories can be effectively captured within the framework of effective field theories, where higher-dimensional fields propagate through extra dimensions. A particularly successful subset of these models involves braneworld scenarios, where Standard Model particles are confined to a four-dimensional brane situated within a five-dimensional bulk spacetime. Several researchers have investigated the potential for detecting signatures of braneworld physics through gravitational wave observations, highlighting the relevance of this work in the broader context of gravitational wave studies.",
        "ori-fast-z-score": 1.2185435916898848,
        "water-fast-z-score": 7.256494774883425,
        "rewrite-fast-z-score": 0.17025130615174972
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Vortical and Wave Modes in 3D Rotating Stratified Flows: Random Large Scale Forcing .\nAbstract:\nWe study the effect of random large-scale forcing on three-dimensional rotating stratified flows, using direct numerical simulations (DNS) with periodic boundary conditions. The flow is forced at large scales by adding to the momentum equation an external force that has zero mean but whose Fourier transform contains both positive and negative wavenumbers. We find that this type of forcing excites two distinct types of modes in the system: vortical and wave-like modes. Vortical modes are characterized by strong vertical motions concentrated near the center of the domain; they have low horizontal velocities and their kinetic energy decays rapidly as we move away from the center. On the other hand, wave-like modes are characterized by weak vertical motions distributed over larger regions of space; they have high horizontal velocities and their kinetic energies decay slowly or even increase slightly when moving away from the center. In addition, these waves can be either stationary or propagating horizontally depending on whether the forcing spectrum peaks at small or large horizontal wavenumber respectively.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Vortical and Wave Modes in 3D Rotating Stratified Flows : Random Large Scale Forcing . Abstract : We research the impact of random large - scale forcing on three - dimensional spinning stratified flows , using direct numerical simulations ( DNS ) with periodic border conditions .The flow is displaced at large scales by added to the velocity equation an external force that has zero mean but whose Fourier integral contains both negative and negative wavenumbers . We see that this kinds of forcing excites two different kinds of modes in the system : vortical and wave - like modes .Vortical modes are characterized by strong vertical motions concentrated near the center of the domain ; they have low horizontal velocities and their kinetic energy decays rapidly as we move away from the center . On the other hand , wave - like modes are characterized by weak vertical motions distributed over larger regions of space ; they have high horizontal velocities and their kinetic energies decay slowly or even increase slightly when moving away from the center .In addition , these pulses can be either static or propagating vertically depending on whether the forcing spectrum peaks at small or large horizontal wavenumber respectively .",
        "rewrite_text": "In this study, we investigate the effects of random large-scale forcing on three-dimensional rotating stratified flows through direct numerical simulations (DNS) with periodic boundary conditions. The flow dynamics are influenced by an external force added to the velocity equation, which has a zero mean and features a Fourier integral comprising both positive and negative wavenumbers. Our findings reveal that this type of forcing induces two distinct modes within the system: vortical modes and wave-like modes. \n\nVortical modes are characterized by pronounced vertical motions that are primarily concentrated near the center of the computational domain. These modes exhibit low horizontal velocities, and their kinetic energy diminishes rapidly as one moves away from the center. In contrast, wave-like modes display weaker vertical motions that are spread over larger spatial areas. These modes are associated with higher horizontal velocities, and their kinetic energies tend to decay more slowly, or may even experience a slight increase, as one moves outward from the center.\n\nFurthermore, the nature of these modes can vary based on the characteristics of the forcing spectrum. Specifically, the pulses generated by the forcing can either remain static or propagate vertically, depending on whether the spectrum is peaked at small or large horizontal wavenumbers, respectively. This research enhances our understanding of the complex interactions between vortical and wave-like dynamics in stratified flows under the influence of random large-scale forcing, providing valuable insights for future studies in fluid dynamics and related fields.",
        "ori-fast-z-score": -2.65361388801511,
        "water-fast-z-score": 1.116880781646981,
        "rewrite-fast-z-score": 1.4852968963237645
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Fourier resolved spectroscopy of 4U 1728-34: New Insights into Spectral and Temporal Properties of Low-Mass X-ray Binaries .\nAbstract:\nWe present the first simultaneous broadband (0.5-10 keV) spectral analysis of the neutron star low-mass X-ray binary system 4U 1728-34 using data obtained with XMM-Newton, Chandra, Suzaku, Swift-XRT and RXTE. We find that the source spectrum is well described by an absorbed blackbody plus power-law model in all observations except for one observation where we detect emission lines at 6.7 and 7.1 keV which are consistent with being produced by highly ionized iron. The temperature of the blackbody component varies between 0.6-0.9 keV while its radius ranges between 3-7 km depending on whether or not the absorption column density was allowed to vary freely during fitting. In addition, we also found evidence for a soft excess below 1 keV in some of our spectra. Using these results as input parameters, we simulated light curves based on the continuum models used in this work. Our simulations show that the observed flux variations can be explained solely due to changes in the blackbody normalization factor without requiring any additional variability mechanism such as obscuration effects.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Fourier resolved spectroscopy of 4U 1728 - 34 : New Insights into Spectral and Temporal Properties of Low - Mass X - ray Binaries . Abstract : We report the first simultaneous broadband ( 0 . 5 - 10 keV ) spectral study of the neutron star small - mass X - ray binary system 4U 1728 - 34 using data acquired with XMM - Newton , Chandra , Suzaku , Swift - XRT and RXTE .We see that the source spectrum is well described by an absorption blackbody plus energy - law theory in all experiments except for one observation where we perceive emission lines at 6 . 7 and 7 . 1 keV which are compatible with being produced by highly ionized iron . The temperature of the blackbody element changes between 0 . 6 - 0 . 9 keV while its radius varies between 3 - 7 kilometers depending on whether or not the absorption column temperature was allowed to vary freely during fitting .In addition , we also discovered evidence for a weak surplus below 1 keV in some of our spectra . Using these results as input parameters , we modeled light curves based on the continuum descriptions utilized in this research .Our simulations prove that the seen flux variations can be described solely due to changes in the blackbody normalization coefficient without allowing any additional variability system such as obscuration effects .",
        "rewrite_text": "We present a comprehensive analysis of the neutron star low-mass X-ray binary system 4U 1728-34 through the first simultaneous broadband spectral study conducted across the energy range of 0.5 to 10 keV. This investigation utilizes data from multiple observatories, including XMM-Newton, Chandra, Suzaku, Swift-XRT, and RXTE. Our findings reveal that the spectral characteristics of 4U 1728-34 can be effectively modeled using an absorption blackbody combined with an energy-law distribution in nearly all observations. Notably, one specific observation exhibited emission lines at 6.7 and 7.1 keV, which we interpret as signatures of highly ionized iron. The temperature of the blackbody component fluctuates between 0.6 and 0.9 keV, while the radius of the emitting region is estimated to range from 3 to 7 kilometers, contingent upon whether the absorption column density was permitted to vary during the fitting process. Additionally, we identified a subtle excess in the spectral data below 1 keV in certain observations. Utilizing these spectral parameters, we constructed light curves based on the continuum models derived from our analysis. Our simulations indicate that the observed flux variations can be accounted for solely by alterations in the normalization of the blackbody component, without necessitating the inclusion of other variability mechanisms, such as obscuration effects. This study enhances our understanding of the spectral and temporal properties of low-mass X-ray binaries, providing new insights into the physical processes governing these intriguing astrophysical systems.",
        "ori-fast-z-score": -0.6396021490668313,
        "water-fast-z-score": 5.9696200579570915,
        "rewrite-fast-z-score": 0.4879500364742666
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Transition from the First Stars to the Second Stars in the Early Universe .\nAbstract:\nWe present an analysis of the transition between first stars and second stars, which are formed by gravitational collapse of primordial gas clouds with masses ranging from 10^4 M_sol to 10^6 M_sol.  We show that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium (IGM). The suppression factor increases as redshift decreases because the IGM temperature rises more rapidly than its density. At lower redshifts, we find that the formation rates of both first and second stars increase sharply when the universe becomes reionized. This effect occurs because the ionizing photons produced during reionization heat up the surrounding neutral hydrogen atoms, thereby increasing their Jeans mass and suppressing fragmentation into smaller objects. Finally, we estimate the number densities of first and second stars using our model for star formation history. Our results suggest that second stars may be detectable via future surveys such as LSST or Euclid.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Transition from the First Stars to the Second Stars in the Early Universe . Abstract : We present an assessment of the shift between first stars and second stars , which are created by gravitational collapse of primordial liquid clouds with masses ranging from 10 ^ 4 M _ sol to 10 ^ 6 M _ sol .We see that the formation rate of second stars is suppressed at redshifts z < 20 due to photoheating effects on the intergalactic medium ( IGM ) . The suppression factor rises as redshift decreases because the IGM temperature rises more swiftly than its density .At lower redshifts , we find that the formation rates of both first and first stars increase dramatically when the universe becomes reionized . This phenomenon occurs because the ionizing photons created during reionization heat up the nearby neutral hydrogen atoms , thereby expanding their Jeans mass and suppressing fragmentation into larger objects .Finally , we estimate the number densities of first and first stars using our model for star formation history . Our results propose that second stars would be detectable via upcoming studies such as LSST or Euclid .",
        "rewrite_text": "In this article, we explore the transition from the first generation of stars to the second generation in the early universe, focusing on the gravitational collapse of primordial liquid clouds with masses between \\(10^4 M_{\\odot}\\) and \\(10^6 M_{\\odot}\\). Our analysis reveals that the formation rate of second stars is significantly hindered at redshifts \\(z < 20\\), primarily due to the effects of photoheating on the intergalactic medium (IGM). As redshift decreases, we observe an increasing suppression factor, which can be attributed to the rapid rise in IGM temperature outpacing its density. \n\nFurthermore, we identify a notable increase in the formation rates of both first and second stars following the reionization of the universe. This increase is linked to the ionizing photons generated during the reionization process, which heat nearby neutral hydrogen atoms. This heating effect leads to an expansion of the Jeans mass, thereby reducing the likelihood of fragmentation into larger stellar objects. \n\nTo quantify our findings, we provide estimates of the number densities of first and second stars based on our model of star formation history. Our results suggest that the second generation of stars may be observable in future astronomical surveys, such as those conducted by the Large Synoptic Survey Telescope (LSST) and the Euclid mission. This research enhances our understanding of stellar evolution in the early universe and sets the stage for future observational efforts aimed at detecting these elusive second stars.",
        "ori-fast-z-score": -0.3333333333333333,
        "water-fast-z-score": 4.500334659577304,
        "rewrite-fast-z-score": 1.7650452162436565
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A characteristic observable signature of preferred frame effects in relativistic binary pulsars .\nAbstract:\nWe present an analysis of the gravitational waveforms emitted by two neutron stars orbiting each other, and show that they can be used to detect violations of Lorentz invariance (LI). We consider both scalar-tensor theories with spontaneous breaking of LI as well as vector-tensor theories where LI is violated through the presence of a preferred reference frame. In these models we find that there are characteristic deviations from general relativity which lead to measurable differences between the observed gravitational waveform and those predicted within Einstein s theory. \n \n The detection of such deviations would provide strong evidence for new physics beyond standard model expectations. This could have important consequences on our understanding of fundamental interactions at high energies. For example, it may shed light on the origin of dark energy or even reveal the existence of extra dimensions of space-time. It also has implications for cosmology since many extensions of the Standard Model predict time variations of physical constants like Newton s constant G.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A characteristic observable signature of preferred frame effects in relativistic binary pulsars . Abstract : We report an analysis of the gravitational waveforms emitted by two neutron stars orbiting each other , and suggest that they can be used to identify violations of Lorentz invariance ( LI ) .We consider both scalar - vector models with spontaneous breaking of LI as well as vector - vector models where LI is violated through the presence of a preferred reference frame . In these models we find that there are characteristic deviations from general relativity which lead to measurable differences between the seen gravity waveform and those predicted within Einstein s theory .The detection of such deviations might give strong evidence for future physics beyond standard theory expectations . This might have important implications on our knowing of fundamental interactions at high energies .For instance , it could cast light on the origin of dark energy or actually expose the existence of added dimensions of space - time . It additionally has implications for cosmology since several extensions of the Standard Model predict time variations of physical constants like Newton s constant G .",
        "rewrite_text": "We present a comprehensive analysis of the gravitational waveforms generated by the interaction of two neutron stars in a binary system, highlighting their potential to reveal violations of Lorentz invariance (LI). Our study explores both scalar-vector models that exhibit spontaneous breaking of LI and vector-vector models that introduce a preferred reference frame, leading to LI violations. Through our investigation, we identify distinct deviations from the predictions of general relativity, which manifest as measurable discrepancies between the observed gravitational waveforms and those anticipated by Einstein's framework. The identification of these deviations could provide compelling evidence for new physics that extends beyond the conventional expectations of the standard model. Such findings may significantly enhance our understanding of fundamental interactions at high energy scales, potentially shedding light on the enigmatic nature of dark energy or even revealing the presence of additional spatial dimensions. Furthermore, our results carry important implications for cosmology, as various extensions of the Standard Model suggest that physical constants, including Newton's gravitational constant (G), may vary over time. This research not only deepens our comprehension of gravitational phenomena but also opens avenues for exploring the underlying principles governing the universe, thereby contributing to the ongoing discourse on the fundamental laws of physics.",
        "ori-fast-z-score": -0.31799936400190804,
        "water-fast-z-score": 5.270462766947299,
        "rewrite-fast-z-score": 0.5827715174143585
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Some properties of the resonant state in quantum mechanics and its computation .\nAbstract:\nThe problem of finding the energy levels of an electron bound to a nucleus is one of the most important problems in physics, which has been studied for many years. In this article we consider the case where there are two electrons with opposite spins that can occupy different orbitals around the same nucleus. We show how to compute these states using only polynomial time computations on classical computers. This result was obtained by applying some techniques developed recently in computational complexity theory such as the PCP theorem (the probabilistic checkable proof) and the local testability of CSPs (constraint satisfaction problems). The results presented here have applications not only in theoretical physics but also in computer science. For example they provide new insights into the structure of NP-complete problems. Quantum mechanical systems play an essential role in modern physics. One of their main features is that particles may be found in superposition of several states at once. A famous example is Schrödinger s cat experiment  1  . Another feature is entanglement  2  , i.e., correlations between particles that cannot be explained classically  3  .\nIn this work we study the following problem: given a system consisting of N spin-1/2 particles, what is the ground state? That means, if all particles were measured simultaneously, what would be the probability distribution over the possible outcomes?\nWe will focus our attention on the simplest non-trivial case: two spin-½ particles occupying different orbitals around the nucleus  4  . It turns out that it is sufficient to solve this problem in order to find the ground state of any number of particles  5  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Some properties of the resonant state in particle theory and its computation . Abstract : The question of finding the power concentrations of an electron bound to a nucleus is one of the most important problems in physics , which has been studied for many years .In this article we imagine the case where there are two electrons with opposite spins that can occupy separate orbitals around the same nucleus . We see how to compute these states using only polynomial period computations on classical processors .This result was obtained by using some techniques established recently in computational complexity analysis such as the PCP conjecture ( the probabilistic checkable proof ) and the local testability of CSPs ( constraint satisfaction issues ) . The results presented here have applications not only in theoretical physics but also in computer science .For instance they give modern perspectives into the formation of NP - perfect questions . Quantum mechanical problems hold an essential part in modern physics .One of their major characteristics is that particles may be found in superposition of several states at once . A popular example is Schrödinger s cat experiment 1 .Another feature is entanglement 2 , i . e . , correlations between particles that cannot be described classically 3 . In this research we study the following puzzle : given a system consisting of N spin - 1 / 2 atoms , what is the ground state ?That implies , if all atoms were studied simultaneously , what would be the probability distribution over the possible outcomes ? We will focus our focus on the trivial non - trivial case : two spin - ½ particles occupying distinct orbitals around the nucleus 4 .It turns out that it is enough to solve this question in order to find the ground state of any number of particles 5 .",
        "rewrite_text": "**Title:** Some Properties of the Resonant State in Particle Theory and Its Computation\n\n**Abstract:** The investigation of power distributions of electrons bound to a nucleus represents a fundamental challenge in the field of physics, having been a subject of extensive research over the years. This article explores a scenario involving two electrons with opposing spins that occupy distinct orbitals around a single nucleus. We demonstrate a method for computing these states utilizing polynomial-time algorithms on classical computing systems. This achievement is grounded in recent advancements in computational complexity theory, particularly leveraging concepts such as the Probabilistically Checkable Proof (PCP) conjecture and the local testability of Constraint Satisfaction Problems (CSPs). The findings presented herein have significant implications not only for theoretical physics but also for computer science, offering contemporary insights into the formation of NP-complete problems.\n\nQuantum mechanics plays a pivotal role in modern physics, characterized by phenomena such as superposition, where particles can exist in multiple states simultaneously, exemplified by Schrödinger's cat thought experiment. Another critical aspect is entanglement, which describes correlations between particles that defy classical explanations. In this study, we address a compelling question: for a system comprising N spin-1/2 atoms, what is the ground state? This inquiry leads us to consider the probability distribution of outcomes when all atoms are analyzed concurrently. Our primary focus will be on the non-trivial case of two spin-1/2 particles in separate orbitals around the nucleus. Remarkably, resolving this specific case provides a pathway to determining the ground state for any number of particles, thereby contributing to a deeper understanding of quantum systems and their computational properties.",
        "ori-fast-z-score": -0.780398972571708,
        "water-fast-z-score": 5.983058789716428,
        "rewrite-fast-z-score": 1.0524696231684352
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Angles Between Infinite Dimensional Subspaces with Applications to the Rayleigh-Ritz and Alternating Projectors Methods .\nAbstract:\nIn this work, we study angles between infinite dimensional subspaces in Hilbert spaces. We first introduce an angle measure for two closed linear operators on Hilbert spaces which is based on their resolvent kernels. Then we show that if one operator is compact then the angle measure coincides with the usual cosine of the angle between the range space of these operators. Finally, as applications of our results, we give some new characterizations of the convergence rate of the Rayleigh-Ritz method and the alternating projectors methods. The proofs are given by using the concept of angle measures introduced here. In particular, it turns out that the convergence rates of both methods depend only on the angles between the corresponding subspaces involved but not on any other properties such as dimensions or norms of those subspaces. This fact has been observed numerically before but never proved rigorously until now. It should be noted that all results presented here hold true also when the underlying Hilbert spaces are Banach spaces instead of just Hilbert spaces.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Angles Between Infinite Dimensional Subspaces with Applications to the Rayleigh - Ritz and Alternating Projectors Methods . Abstract : In this research , we study angles between endless dimensional subspaces in Hilbert spaces .We first introduce an angle measure for two closed linear operators on Hilbert spaces which is based on their resolvent kernels . Then we prove that if one operator is compact then the angle measure coincides with the usual cosine of the angle between the range space of these operators .Finally , as applications of our findings , we give some new characterizations of the convergence frequency of the Rayleigh - Ritz approach and the alternating projectors methods . The proofs are given by using the idea of angle measures introduced here .In particular , it turns out that the convergence rates of both algorithms rely only on the distances between the associated subspaces concerned but not on any other properties such as sizes or norms of those subspaces . This fact has been observed numerically before but none proved rigorously until now .It should be mentioned that all results presented here hold true also when the underlying Hilbert spaces are Banach spaces rather of just Hilbert spaces .",
        "rewrite_text": "Title: Angles Between Infinite Dimensional Subspaces with Applications to the Rayleigh-Ritz and Alternating Projectors Methods\n\nAbstract: This study explores the concept of angles between infinite-dimensional subspaces within the framework of Hilbert spaces. We begin by defining a novel angle measure for two closed linear operators in Hilbert spaces, which is derived from their resolvent kernels. Our main result demonstrates that when one of the operators is compact, this angle measure aligns with the conventional cosine of the angle between the respective range spaces of the operators. Building on these theoretical foundations, we present new characterizations regarding the convergence rates of the Rayleigh-Ritz method and the alternating projectors method. The proofs of these characterizations leverage the angle measures we have introduced. Notably, our findings reveal that the convergence rates of both algorithms depend solely on the distances between the relevant subspaces, rather than on other attributes such as the sizes or norms of these subspaces. This observation, while previously noted through numerical experiments, has not been rigorously established until now. Furthermore, it is important to highlight that the results obtained in this research extend beyond Hilbert spaces and are also applicable to Banach spaces. This broad applicability underscores the significance of our findings in the context of functional analysis and numerical methods, providing a deeper understanding of the geometric relationships between infinite-dimensional subspaces and their implications for convergence in various computational techniques.",
        "ori-fast-z-score": 1.0392304845413263,
        "water-fast-z-score": 5.047146145152358,
        "rewrite-fast-z-score": 1.6329931618554523
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Langmuir blodgett assembly of densely aligned single walled carbon nanotubes from bulk materials .\nAbstract:\nWe report the Langmuir Blodgett (LB) deposition of highly ordered, dense arrays of vertically-aligned single-walled carbon nanotube films on solid substrates using an aqueous dispersion containing surfactant and sodium dodecyl sulfate as dispersing agents. The LB technique is used to transfer these films onto various substrate materials such as silicon wafers, quartz slides, glass coverslips, gold-coated glass coverslips, and indium tin oxide coated glass coverslips. We have also demonstrated that this method can be extended for patterned growth by transferring the film selectively over areas defined by photoresist patterns. These results are important in developing new applications based on carbon nanotubes. \n \n Carbon nanotubes (CNTs), which were discovered about ten years ago, have attracted considerable attention because they possess unique physical properties including high electrical conductivity, mechanical strength, thermal stability, chemical inertness, etc., making them promising candidates for many potential applications ranging from field emission devices to sensors and optoelectronic devices1-5. However, most of their practical uses require CNT networks with controlled orientation and density6-8. In recent years, several methods have been developed to prepare oriented CNT films9-12. Among those techniques, Langmuir-Blodgett (LB)\ndeposition has emerged as one of the most powerful approaches13-15. This process involves spreading a monolayer of amphiphilic molecules at the air-water interface followed by vertical dipping of a hydrophobic substrate into the water subphase16-18. By repeating the above steps, multilayered thin films consisting of closely packed CNTs can be obtained19-21. Compared to other methods22-24, LB deposition offers advantages such as precise control of layer thickness25-27, easy fabrication of large-area uniform films28-30, and possibility of fabricating patterned structures31-33.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Langmuir blodgett assembly of densely aligned single walled carbon nanotubes from bulk surfaces . Abstract : We report the Langmuir Blodgett ( LB ) deposition of highly ordered , dense arrays of vertically - aligned single - walled carbon nanotube films on solid substrates using an aqueous dispersion containing surfactant and potassium dodecyl sulfate as dispersing agents .The LB technique is utilized to move these films onto several substrate materials such as silicon wafers , quartz slides , plastic coverslips , gold - coated glass coverslips , and indium tin oxide coated glass coverslips . We have also demonstrated that this process can be extended for patterned expansion by directing the film selectively over areas defined by photoresist sequences .These data are important in establishing new applications based on carbon nanotubes . Carbon nanotubes ( CNTs ) , which were discovered about ten years previously , have garnered considerable scrutiny because they possess unique physical properties including high thermal conductivity , thermal strength , thermal stability , chemical inertness , etc . , making them promising candidates for numerous likely applications ranging from field emission sensors to sensors and optoelectronic devices1 - 5 .However , most of their practical applications need CNT connections with regulated orientation and density6 - 8 . In recent years , various methods have been proposed to produce aligned CNT films9 - 12 .Among those techniques , Langmuir - Blodgett ( LB ) deposition has emerged as one of the most efficient approaches13 - 15 . This process involves spreading a monolayer of amphiphilic molecules at the air - water interface followed by vertical dipping of a hydrophobic substrate into the air subphase16 - 18 .By repeating the above steps , multilayered narrow bands consisting of closely packed CNTs can be obtained19 - 21 . Compared to other methods22 - 24 , LB deposition gives benefits such as careful management of layer thickness25 - 27 , easy fabrication of large - area uniform films28 - 30 , and possibility of fabricating patterned structures31 - 33 .",
        "rewrite_text": "**Title:** Langmuir Blodgett Assembly of Densely Aligned Single-Walled Carbon Nanotubes from Bulk Surfaces\n\n**Abstract:** In this study, we present the Langmuir Blodgett (LB) technique for the deposition of highly ordered and densely packed arrays of vertically aligned single-walled carbon nanotube (SWCNT) films onto various solid substrates. Utilizing an aqueous dispersion that incorporates surfactants, specifically potassium dodecyl sulfate, as dispersing agents, we successfully transfer these films onto a range of substrate materials, including silicon wafers, quartz slides, plastic coverslips, gold-coated glass coverslips, and indium tin oxide-coated glass coverslips. Furthermore, we demonstrate the capability of extending this process for patterned deposition by selectively directing the film onto predefined areas defined by photoresist patterns. \n\nThe significance of these findings lies in their potential to advance applications that leverage the unique properties of carbon nanotubes (CNTs), which have been the focus of extensive research since their discovery approximately a decade ago. CNTs are renowned for their exceptional physical characteristics, such as high thermal conductivity, mechanical strength, thermal stability, and chemical inertness, positioning them as promising candidates for a wide array of applications, including field emission sensors and optoelectronic devices. However, the realization of many practical applications necessitates the establishment of CNT connections with controlled orientation and density.\n\nIn recent years, numerous methods have been explored to produce aligned CNT films, with LB deposition emerging as one of the most effective techniques. This method involves the formation of a monolayer of amphiphilic molecules at the air-water interface, followed by the vertical dipping of a hydrophobic substrate into the air subphase. By repeating this process, multilayered structures composed of closely packed CNTs can be achieved. Compared to alternative methods, LB deposition offers several advantages, including precise control over layer thickness, the ability to fabricate large-area uniform films, and the potential for creating patterned structures. These attributes make LB deposition a valuable technique for advancing the application of carbon nanotubes in various technological fields.",
        "ori-fast-z-score": 1.3241694217637887,
        "water-fast-z-score": 7.340596279696671,
        "rewrite-fast-z-score": 0.9486832980505138
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  X-ray Timing Observations of PSR J1930+1852 in the Crab-like SNR G54.1+0.3 .\nAbstract:\nWe report on X-ray timing observations of the pulsar candidate PSR J1930+1855 located at the center of the supernova remnant (SNR) G54.1+0. \n \n The source was discovered by Chandra and confirmed as a pulsar with XMM-Newton, but its spin period is not stable over time scales longer than one day. We performed two sets of pointed RXTE observations to study this behavior further. In both cases we found that the pulse frequency decreases smoothly during our observation runs. This trend can be described well using an exponential decay model for which we find characteristic timescales of 1.1 days and 0.7 days respectively. These values are consistent with those reported previously based on Chandra data alone. However, when comparing these results directly it should be noted that the uncertainties associated with the previous measurements were significantly larger due to the lower signal-to-noise ratio achieved with Chandra compared to RXTE.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : X - ray Timing Observations of PSR J1930 + 1852 in the Crab - like SNR G54 . 1 + 0 . 3 . Abstract : We report on X - ray timing observations of the pulsar candidate PSR J1930 + 1855 centered at the center of the supernova remnant ( SNR ) G54 . 1 + 0 .The source was studied by Chandra and reported as a pulsar with XMM - Newton , but its spin time is not stable over time ranges less than one day . We conducted two sets of pointed RXTE observations to study this behavior further .In both cases we concluded that the pulse frequency drops slowly during our observation running . This trend can be described good using an exponential decay model for which we find typical timescales of 1 . 1 hours and 0 . 7 days respectively .These figures are compatible with those published previously based on Chandra data alone . However , when comparing these results directly it should be mentioned that the uncertainties involved with the previous tests were significantly larger thanks to the smaller signal - to - noise proportion attained with Chandra compared to RXTE .",
        "rewrite_text": "We present findings from our X-ray timing observations of the pulsar candidate PSR J1930+1855, located at the center of the supernova remnant (SNR) G54.1+0.3. Previous studies, including those conducted with Chandra and XMM-Newton, identified this source as a pulsar; however, our observations reveal that its spin period exhibits instability over intervals shorter than one day. To investigate this phenomenon further, we performed two sets of targeted observations using the Rossi X-ray Timing Explorer (RXTE). Our analysis indicates a gradual decline in pulse frequency throughout the duration of our observations. This observed trend can be effectively modeled using an exponential decay function, yielding characteristic timescales of approximately 1.1 hours and 0.7 days for the two observation sets, respectively. Notably, these timescales align well with earlier results derived from Chandra data. It is important to note, however, that the uncertainties associated with the previous measurements were considerably larger due to the lower signal-to-noise ratio achieved with Chandra compared to RXTE. Our findings contribute to the understanding of pulsar behavior in the context of supernova remnants and highlight the importance of using high-quality observational data to refine models of pulsar timing irregularities. This work underscores the potential for RXTE observations to provide more precise measurements, thereby enhancing our comprehension of the dynamics at play in pulsar systems within supernova remnants.",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 5.9648090806346055,
        "rewrite-fast-z-score": 1.1881770515720091
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Off-center HII regions in power-law density distributions .\nAbstract:\nWe present the results of numerical simulations aimed at studying the formation and evolution of off-center ionized hydrogen (HII) regions around massive stars embedded in an isothermal, self-gravitating gas distribution with a power-law density profile.  We find that the expansion velocity of the ionization front decreases as it moves away from the star s position towards larger radii. The decrease occurs because the pressure gradient becomes smaller when moving outward due to the decreasing density. As a result, the ionization front may become unstable against small perturbations which lead to its fragmentation into several blobs or fingers. These blobs are surrounded by dense shells of neutral material produced by photo-evaporation of the surrounding medium. In addition, we show that the mass loss rate increases significantly for large values of the index n of the power law density distribution. This increase can be explained by the fact that the gravitational force per unit volume acting on the shell decreases faster than the ram pressure of the expanding bubble.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Off - center HII regions in power - law density distributions . Abstract : We present the results of computational simulations aiming at studying the formation and evolution of off - center ionized hydrogen ( HII ) areas around large stars localized in an isothermal , self - gravitating gas distribution with a power - law density profile .We see that the expansion velocity of the ionization front decreases as it travels away from the star s position towards higher radii . The reduction appears because the pressure gradient becomes lower when moved outward owing to the decreasing density .As a result , the ionization front may grow unstable against small perturbations which lead to its fragmentation into numerous blobs or fingers . These blobs are surrounded by dense shells of neutral material created by photo - evaporation of the nearby medium .In addition , we prove that the mass loss rate grows significantly for large values of the index n of the power law density distribution . This increase can be described by the fact that the gravitational pressure per unit volume acting on the shell decreases quicker than the ram tension of the expanding bubble .",
        "rewrite_text": "In this study, we investigate the formation and evolution of off-center ionized hydrogen (HII) regions surrounding massive stars within an isothermal, self-gravitating gas medium characterized by a power-law density distribution. Through a series of computational simulations, we analyze how the dynamics of the ionization front are influenced by the underlying density profile. Our findings reveal that as the ionization front propagates outward from the star, its expansion velocity diminishes, particularly at greater radii. This deceleration is attributed to a decreasing pressure gradient, which results from the lower density encountered further from the star. Consequently, the ionization front becomes susceptible to small perturbations, leading to its fragmentation into various structures such as blobs or fingers. These fragmented regions are enveloped by dense shells of neutral gas, which are formed due to the photo-evaporation processes occurring in the surrounding medium. Furthermore, our results indicate a significant increase in the mass loss rate associated with the expanding HII regions, particularly for larger values of the power-law index (n). This phenomenon can be explained by the observation that the gravitational pressure exerted on the shell diminishes at a faster rate than the ram pressure generated by the expanding bubble. Overall, our research provides valuable insights into the complex interactions between massive stars and their environments, highlighting the role of density distributions in shaping the dynamics of HII regions.",
        "ori-fast-z-score": -1.584236068762679,
        "water-fast-z-score": 2.970442628930023,
        "rewrite-fast-z-score": 1.0536089137432665
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Renormalized Quantum Yang-Mills Fields in Curved Spacetime .\nAbstract:\nWe present the renormalization group flow equations for quantum gauge fields on curved spacetime, including fermions and scalars as well as their interactions with gravity. We show that these flows are governed by an exact functional differential equation which is derived using the background field method. The solution to this equation yields all possible counterterms needed to render the theory finite at any order in perturbation theory. This result generalizes previous results obtained within the context of flat space-time. In particular we find that the beta functions for the gravitational couplings do not vanish even if one considers only pure Yang-Mills theories without matter fields. Furthermore, our analysis shows that the running of the gravitational coupling constants can be determined completely in terms of the beta functionals associated with the non-gravitational sectors. Finally, we discuss how our formalism may be used to study the effects of radiative corrections on black hole entropy. Introduction: Gauge theories play a central role in modern particle physics. They provide a description of fundamental forces such as electromagnetism or weak nuclear force. However, it has been known since the early days of QED (quantum electrodynamics) that perturbatively quantizing gauge theories leads to ultraviolet divergences. These divergences have to be removed by adding appropriate local counterterms to the classical action. It turns out that there exist infinitely many different ways to add these counterterms so that the resulting effective action remains invariant under the original gauge symmetry transformations. Therefore, the choice of the correct set of counterterms depends crucially on the regularization scheme chosen to regulate the infinities appearing during the calculation of Feynman diagrams. For example, in dimensional regularization  1  , where the number of dimensions is taken to be d = 4 − 2ε instead of four, the most general form of the counterterm Lagrangian reads  2  \nwhere F µν denotes the electromagnetic field strength tensor and D µ ≡ ∂ µ + ieA µ . Here e denotes the electric charge while c 1 , c 2 , . . . denote arbitrary coefficients whose values depend on the specific regularization scheme employed.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Renormalized Quantum Yang - Mills Fields in Curved Spacetime . Abstract : We present the renormalization group flow equations for quantum gauge fields on curved spacetime , including fermions and scalars as well as their interactions with gravity .We see that these flows are governed by an precise functional differential equation which is calculated using the background field method . The answer to this equation yields all possible counterterms needed to make the theory finite at any order in perturbation theory .This result generalizes earlier findings obtained within the context of flat space - time . In particular we find that the beta functions for the gravitational couplings do not vanish especially if one considers only true Yang - Mills theories without matter fields .Furthermore , our analysis shows that the running of the gravitational coupling constants can be determined completely in terms of the beta functionals associated with the non - gravitational sectors . Finally , we talk how our formalism may be used to study the effects of radiative corrections on dark hole entropy .Introduction : Gauge systems play a central role in modern particle theory . They offer a description of fundamental forces such as electromagnetism or weak nuclear force .However , it has been known since the early days of QED ( quantum electrodynamics ) that perturbatively quantizing gauge theories leads to ultraviolet divergences . These divergences have to be removed by added appropriate local counterterms to the classical operation .It happens out that there exist infinitely many various ways to addition these counterterms so that the resulting effective act remains invariant under the original gauge symmetry processes . Therefore , the selection of the appropriate set of counterterms depends crucially on the regularization scheme chosen to govern the infinities appearing during the determination of Feynman diagrams .For instance , in dimensional regularization 1 , where the number of dimensions is taken to be d = 4 − 2ε instead of four , the most general form of the counterterm Lagrangian reads 2 where F µν denotes the electromagnetic field intensity tensor and D µ ≡ ∂ µ + ieA µ . Here e denotes the electric current while c 1 , b 2 , ...denote arbitrary coefficients whose values rely on the specific regularization scheme employed .",
        "rewrite_text": "**Title:** Renormalized Quantum Yang-Mills Fields in Curved Spacetime\n\n**Abstract:** In this article, we explore the renormalization group flow equations applicable to quantum gauge fields in curved spacetime, encompassing fermions, scalars, and their interactions with gravitational fields. Our analysis reveals that these flows are governed by a precise functional differential equation, which we derive using the background field method. The solution to this equation provides all necessary counterterms required to render the theory finite at any order in perturbation theory. This work extends previous results obtained in the context of flat spacetime, highlighting significant differences in the behavior of gauge theories when gravity is taken into account. Notably, we find that the beta functions associated with gravitational couplings do not vanish, particularly in the case of pure Yang-Mills theories devoid of matter fields. This finding suggests that the dynamics of gravitational coupling constants can be fully characterized by the beta functionals linked to the non-gravitational sectors of the theory. Additionally, we discuss the implications of our formalism for investigating the effects of radiative corrections on dark hole entropy, providing a new avenue for understanding quantum gravitational phenomena. Our results contribute to the broader understanding of gauge theories in curved backgrounds and underscore the intricate interplay between quantum field theory and general relativity. This research not only advances theoretical frameworks but also opens up potential applications in cosmology and high-energy physics, where the effects of curvature and quantum fluctuations are significant.",
        "ori-fast-z-score": 1.0120486274099798,
        "water-fast-z-score": 6.635044048369952,
        "rewrite-fast-z-score": 1.9090909090909092
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Random spatial growth with paralyzing obstacles .\nAbstract:\nWe study the random spatial growth in two dimensions, where new sites are added to an initially empty square lattice at randomly chosen locations and grow into circular clusters if they do not hit any existing cluster or obstacle site.  We show that this process leads to fractal structures which can be characterized by their fractal dimension Df = 1 + (1 - p)/2p, where p is the probability for adding a new site without hitting an obstacle. The results agree well with numerical simulations. \nPACS numbers: 05.40.+j, 64.60.Cn, 68.35.-k \nI. INTRODUCTORY REMARK\nIn recent years there has been considerable interest in studying various aspects of the so-called Eden model  1  . In its original formulation it describes the growth of a single cluster on a two-dimensional substrate starting from one seed particle. This simple concept was later generalized to include several seeds  2  , as well as different shapes  3  .\nThe present work deals with another generalization of the Eden model: Instead of growing only one cluster we consider the simultaneous growth of many clusters competing for space  4  . As a result, some clusters may become trapped between other clusters leading to a complex pattern formation.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Random spatial growth with paralyzing difficulties . Abstract : We research the random spatial growth in two dimensions , where new sites are adding to an initially vacant square lattice at randomly picked destinations and grow into circular groups if they do not hit any established cluster or obstacle site .We see that this process results to fractal structures which can be described by their fractal dimension Df = 1 + ( 1 - p ) / 2p , where p is the probability for adding a new site without reaching an barrier . The results agree well with numerical simulations .PACS codes : 05 . 40 . + j , 64 . 60 . Cn , 68 . 35 . - k I . INTRODUCTORY REMARK In recent years there has been substantial interest in investigating different components of the so - called Eden model 1 .In its initial formulation it describes the development of a single cluster on a two - dimensional substrate beginning from one seed particle . This straightforward idea was later extended to include several seeds 2 , as well as varying shapes 3 .The present work deals with another generalization of the Eden model : Instead of growing only one cluster we treat the concurrent development of several clusters battling for space 4 . As a result , some clusters might form trapped between other clusters leading to a complex pattern formation .",
        "rewrite_text": "**Title:** Random Spatial Growth with Paralyzing Difficulties\n\n**Abstract:** This study investigates the phenomenon of random spatial growth in a two-dimensional setting, where new sites are introduced to an initially empty square lattice at randomly selected locations. These new sites expand into circular clusters, provided they do not encounter any pre-existing clusters or obstacles. The resulting growth process leads to the formation of fractal structures, which can be quantitatively characterized by their fractal dimension, expressed as Df = 1 + (1 - p) / 2p. Here, p represents the probability of adding a new site without encountering a barrier. Our findings are consistent with numerical simulations, reinforcing the theoretical framework. \n\nThe research builds upon the Eden model, which has garnered significant attention in recent years. Originally, the Eden model described the growth of a single cluster on a two-dimensional substrate initiated from a single seed particle. This foundational concept has since been expanded to encompass multiple seed particles and various growth shapes. The current work presents a further extension of the Eden model by examining the simultaneous growth of multiple clusters competing for space. This interaction can lead to scenarios where some clusters become trapped between others, resulting in intricate and complex patterns of growth. \n\nThe implications of this study are significant for understanding spatial growth processes in various scientific fields, including biology, materials science, and physics. The emergence of fractal structures from random growth dynamics highlights the interplay between randomness and order in complex systems. Our results contribute to the broader understanding of how spatial constraints and interactions influence growth patterns, paving the way for future research in this area. \n\n**PACS codes:** 05.40.+j, 64.60.Cn, 68.35.-k",
        "ori-fast-z-score": -0.5773502691896257,
        "water-fast-z-score": 5.651175082804793,
        "rewrite-fast-z-score": 1.9233566230163088
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Curvature Inspired Cosmological Scenario .\nAbstract:\nWe propose an alternative scenario for the evolution of our universe, which is based on the idea that the expansion rate of the universe may be driven by its curvature rather than dark energy. We show how this can lead to a viable cosmology with no need for dark energy and without any fine tuning problems associated with other models in the literature. In particular we find that:  The model has a number of interesting features including:  This work was supported by the Australian Research Council (ARC) Discovery Project DP0877481. Any opinions expressed are those of the authors only. 1 Introduction.\nThe discovery of accelerated cosmic expansion  1, 2  , as well as the recent detection of gravitational waves  3  have led to renewed interest in understanding the nature of gravity at large scales  4  . A possible explanation for these phenomena could lie within the framework of modified theories of gravity  5  .\nIn order to explain the observed acceleration of the universe it seems necessary to introduce some form of  dark energy   6  into Einstein s field equations  7, 8  . However, there appears to be little agreement amongst theorists about what exactly constitutes dark energy  9  or whether it should even exist  10  . Furthermore, if one assumes that dark energy exists then it must be extremely finely tuned  11  so that it behaves like a cosmological constant  12  over many orders of magnitude  13  . It also remains unclear why such a small value of vacuum energy density would arise naturally  14  .\nAnother possibility is that the apparent accelerating behaviour of the universe arises due to quantum effects  15  . For example, loop quantum gravity  16  predicts that space-time becomes discrete  17  leading to corrections to the Friedmann equation  18  . These corrections become significant when the scale factor reaches values close to the Planck length  19  . Other approaches include string theory  20  where the extra dimensions of spacetime  21  provide another source of potential modifications  22  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Curvature Inspired Cosmological Scenario . Abstract : We suggest an alternative scenario for the evolution of our universe , which is based on the idea that the development frequency of the universe might be motivated by its curvature instead than dark energy .We see how this can lead to a viable cosmology with no want for black energy and without any coarse tuning problems related with other models in the books . In particular we find that : The model has a number of interesting features including : This research was supported by the Australian Research Council ( ARC ) Discovery Project DP0877481 .Any views stated are those of the writers only . 1 Introduction .The observation of rapid cosmic expansion 1 , 2 , as also as the recent discovery of gravitational waves 3 have led to renewed concern in understanding the nature of gravitational at large scales 4 . A potential explanation for these phenomena could lay within the framework of revised theories of gravitational 5 .In order to explain the observed acceleration of the universe it appears necessary to introduce some kind of dark energy 6 into Einstein s field equations 7 , 8 . However , there seems to be little accord amongst theorists about what actually constitutes bright energy 9 or whether it should even exist 10 .Furthermore , if one assumes that dark energy occurs then it must be extremely finely tuned 11 so that it behaves like a cosmological constant 12 over numerous orders of magnitude 13 . It additionally seems unclear why such a small value of vacuum energy density would occur naturally 14 .Another possibility is that the apparent accelerating behaviour of the universe occurs due to quantum effects 15 . For instance , loop quantum gravitational 16 predicts that space - time remains discrete 17 leading to corrections to the Friedmann equation 18 .These corrections prove substantial when the scale factor reaches values close to the Planck size 19 . Other approaches involve string theory 20 where the extra dimensions of spacetime 21 offer another source of potential alterations 22 .",
        "rewrite_text": "**Title: Curvature-Inspired Cosmological Scenario**\n\n**Abstract:** In this article, we propose a novel framework for understanding the evolution of the universe, positing that its developmental frequency may be influenced more by its curvature than by the presence of dark energy. This perspective allows for a coherent cosmological model that eliminates the necessity for dark energy and circumvents the fine-tuning issues commonly associated with existing theoretical frameworks. Our findings reveal several intriguing characteristics of this model, which we detail throughout the paper. \n\nThe recent observations of accelerated cosmic expansion and the detection of gravitational waves have intensified the quest to comprehend gravitational dynamics on a cosmic scale. Traditional explanations often invoke dark energy as a means to account for the observed acceleration, necessitating its incorporation into Einstein's field equations. However, there remains significant debate among physicists regarding the true nature of dark energy and its existence. The requirement for dark energy to be finely tuned to mimic a cosmological constant across vast scales raises further questions about its natural occurrence and the underlying mechanisms that could give rise to such a small vacuum energy density.\n\nAlternatively, we explore the hypothesis that the universe's apparent acceleration may stem from quantum phenomena. For instance, loop quantum gravity suggests that spacetime is fundamentally discrete, leading to modifications in the Friedmann equations that become significant at scales approaching the Planck length. Additionally, string theory offers a different perspective, where the extra dimensions of spacetime could introduce further modifications to our understanding of cosmic dynamics.\n\nThis research is supported by the Australian Research Council (ARC) Discovery Project DP0877481. The opinions expressed herein are solely those of the authors.",
        "ori-fast-z-score": 0.07980868844676221,
        "water-fast-z-score": 8.273795755427592,
        "rewrite-fast-z-score": 0.2544566789039913
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Chi2 and chi3 harmonic generation at a critical power in inhomogeneous doubly resonant cavities .\nAbstract:\nWe study the second-harmonic (SH) and third-harmonic (TH) generations in an inhomogeneously broadened cavity with two different resonance frequencies for fundamental wave (FW). We show that, when the intracavity FW intensity reaches its maximum value, both SHG and THG can be enhanced simultaneously by increasing the pumping rate or decreasing the detuning between the two modes. The enhancement is due to the fact that the nonlinear susceptibility becomes larger than zero at this point. This effect has been observed experimentally recently. \n \n In addition, we find that there exists another regime where only one type of harmonics can be generated efficiently while suppressing other types of harmonics. For example, if the intracavity FW field is tuned close to the lower mode frequency, then it will generate mainly SH light but very little TH light; on the contrary, if the intracavty FW field is tuned near the upper mode frequency, then it generates mainly TH light but almost no SH light.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Chi2 and chi3 harmonic production at a critical power in inhomogeneous doubly resonant cavities . Abstract : We research the second - harmonic ( SH ) and third - harmonic ( TH ) generations in an inhomogeneously broadened cavity with two different resonance energies for fundamental wave ( FW ) .We see that , when the intracavity FW frequency exceeds its highest value , both SHG and THG can be enhanced simultaneously by expanding the pumping rate or decreasing the detuning between the two modes . The enhancement is due to the fact that the nonlinear susceptibility grows larger than zero at this time .This phenomenon has been observed experimentally recently . In addition , we find that there exists another regime where only one sort of harmonics can be generated smoothly while suppressing other types of harmonics .For instance , if the intracavity FW field is tuned far to the lower mode wavelength , then it will generate mostly SH light but very less TH radiation ; on the contrary , if the intracavty FW field is tuned near the higher mode wavelength , then it generates largely TH light but almost no SH light .",
        "rewrite_text": "In this study, we investigate the generation of second harmonic (SH) and third harmonic (TH) waves within an inhomogeneously broadened cavity that features two distinct resonance energies for the fundamental wave (FW). Our findings reveal that when the intracavity frequency of the FW surpasses its maximum threshold, both SH and TH generation can be significantly enhanced. This enhancement can be achieved by either increasing the pumping rate or reducing the detuning between the two modes. The underlying reason for this enhancement is attributed to the nonlinear susceptibility becoming greater than zero under these conditions, a phenomenon that has been corroborated by recent experimental observations. Furthermore, we identify a distinct operational regime in which the generation of one type of harmonic can occur smoothly while suppressing the production of the other. Specifically, when the intracavity FW field is tuned towards the lower mode wavelength, it predominantly produces SH light with minimal TH radiation. Conversely, when the FW field is adjusted closer to the higher mode wavelength, it results in a significant generation of TH light while virtually eliminating SH light production. These insights into the harmonic generation dynamics in inhomogeneous doubly resonant cavities not only enhance our understanding of nonlinear optical processes but also have potential implications for the design of advanced photonic devices.",
        "ori-fast-z-score": -1.8599622199011085,
        "water-fast-z-score": 3.5795716689756794,
        "rewrite-fast-z-score": 1.4924050144892729
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multi-Agent Approach to the Self-Organization of Networks .\nAbstract:\nWe present an approach for self-organization in networks based on multi-agent systems (MAS). The proposed method is applied to two different networks: one with mobile nodes and another with static ones, both using IEEE 802.11b as their communication protocol. In this work we use agents that are able to move between neighboring nodes, which allows them to collect information about the state of each node. This information can be used by other agents to make decisions such as: moving to new positions or changing the transmission power level. We have implemented our proposal in NS-2 simulator and compared it against three well-known algorithms: OLSR, AODV and DSR. Our results show that MAS outperforms these protocols in terms of: packet delivery ratio, end-to-end delay and energy consumption. Keywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multi - Agent Approach to the Self - Organization of Networks . Abstract : We present an perspective for self - organization in networks based on multi - agent systems ( MAS ) .The proposed approach is applied to two different organizations : one with mobile nodes and another with static ones , both using IEEE 802 . 11b as their transmission mechanism . In this study we using agents that are able to move between neighboring nodes , which allows them to collect data about the state of each node .This knowledge can be used by other agents to make choices such as : moving to new positions or altering the transmission power level . We have incorporated our proposal in NS - 2 simulator and compared it against three well - famous method : OLSR , AODV and DSR .Our results show that MAS outperforms these protocols in terms of : message delivery ratio , end - to - end delay and energy consumption . Keywords : Multi - Agent Systems , Self - Organizing Networks , Mobile Agents , Communication Protocols , Energy Consumption , Packet Delivery Ratio",
        "rewrite_text": "Title: Multi-Agent Approach to the Self-Organization of Networks\n\nAbstract: This article explores a novel perspective on self-organization within networks through the lens of multi-agent systems (MAS). We investigate two distinct organizational structures: one comprising mobile nodes and the other consisting of static nodes, both utilizing the IEEE 802.11b protocol for data transmission. Our approach involves deploying agents capable of traversing between neighboring nodes, enabling them to gather critical information regarding the operational state of each node. This acquired knowledge empowers agents to make informed decisions, such as relocating to optimal positions or adjusting transmission power levels to enhance network performance. We implemented our methodology within the NS-2 simulation environment and conducted a comparative analysis against three widely recognized routing protocols: Optimized Link State Routing (OLSR), Ad hoc On-Demand Distance Vector (AODV), and Dynamic Source Routing (DSR). The results of our experiments demonstrate that the multi-agent system significantly outperforms these established protocols across several key performance metrics, including message delivery ratio, end-to-end delay, and energy consumption. Our findings underscore the potential of MAS in improving the efficiency and reliability of network communications, particularly in dynamic environments. This research contributes to the ongoing discourse on self-organizing networks and highlights the advantages of integrating multi-agent frameworks in the design of adaptive communication protocols. \n\nKeywords: Multi-Agent Systems, Self-Organizing Networks, Mobile Agents, Communication Protocols, Energy Consumption, Packet Delivery Ratio.",
        "ori-fast-z-score": 1.4142135623730951,
        "water-fast-z-score": 5.032769329433615,
        "rewrite-fast-z-score": 0.944911182523068
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Continuous Magnetophoretic Separation of Blood Cells from Plasma at the Microscale .\nAbstract:\nMagnetic separation is an important tool in biomedical research and clinical diagnostics, but it has been limited to macroscopic devices that are not suitable for point-of-care applications. Here we report on continuous magnetophoresis-based blood cell sorting using microfluidics. We demonstrate efficient separation of red blood cells (RBCs) from plasma by applying a magnetic field gradient across a microchannel containing RBCs suspended in buffer solution. The results show that our method can be used as a simple yet effective approach for separating different types of blood cells with high purity and efficiency. This work may have significant implications towards developing portable diagnostic tools based on microscale blood processing technologies. Magnetic separation techniques play an important role in many fields including medicine, biotechnology, environmental science, food industry etc.,  1  . However, most existing methods require bulky equipment which makes them unsuitable for use outside laboratory settings  2  .\nRecently there has been growing interest in miniaturizing these systems into lab-on-a-chip platforms  3  , where various functionalities such as sample preparation  4  , chemical analysis  5  , drug delivery  6  , and bioassays  7  could be integrated onto one single chip. In particular, magnetic separators have attracted much attention due to their simplicity, low cost, portability, and compatibility with other microfabricated components  8  . For example, several groups have demonstrated magnetic separation of biological samples inside microchannels  9  -  11  or on planar surfaces  12  -  14  . Despite this progress, however, current approaches still suffer from some limitations. First, they typically rely on batch-wise operation mode  15  , which limits throughput and requires large volumes of input samples  16  . Second, the majority of reported designs only allow for separation between two distinct populations  17  , while more complex mixtures involving multiple species cannot be processed simultaneously  18  . Third, the fabrication process usually involves complicated multi-step procedures  19  , making it difficult to integrate additional functions  20  . Finally, most previous studies were performed under static conditions  21  , which limit the flexibility of device design  22  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Continuous Magnetophoretic Separation of Blood Cells from Plasma at the Microscale . Abstract : Magnetic isolation is an important tool in biomedical research and medical diagnostics , but it has been limited to macroscopic devices that are not suitable for point - of - care applications .Here we study on intensive magnetophoresis - based blood cell sorting using microfluidics . We suggest efficient separation of red blood cells ( RBCs ) from blood by using a magnetic field gradient across a microchannel containing RBCs held in buffer solution .The results show that our technique can be used as a simple however effective methods for dividing different kinds of blood tissue with high purity and efficiency . This research could have considerable consequences towards developing portable diagnostic methods using on microscale blood extraction technologies .Magnetic isolation techniques serve an important role in multiple fields including medicine , biotechnology , ecological studies , nutrition industry etc . , 1 . However , most existing techniques require bulky machinery which makes them unsuitable for use outside laboratory settings 2 .Recently there has been growing interest in miniaturizing these systems into lab - on - a - chip platforms 3 , where various functionalities such as sample preparation 4 , chemical analysis 5 , drug delivery 6 , and bioassays 7 could be integrated onto one single chip . In particular , magnetic separators have attracted much attention due to their simplicity , low cost , portability , and compatibility with other microfabricated components 8 .For instance , various groups have demonstrated magnetic separation of biological samples inside microchannels 9 - 11 or on planar materials 12 - 14 . Despite this progress , however , current approaches still suffer from some restrictions .First , they generally rely on batch - wise operation mode 15 , which reduces throughput and requires large quantities of input specimens 16 . Second , the majority of reported prototypes only require for isolation between two separate populations 17 , while more sophisticated mixtures featuring multiple taxa unable be processed concurrently 18 .Third , the fabrication process usually includes complicated multi - phase techniques 19 , making it difficult to connect extra functions 20 . Finally , most prior studies were performed under static conditions 21 , which reduce the flexibility of device structure 22 .",
        "rewrite_text": "**Title:** Continuous Magnetophoretic Separation of Blood Cells from Plasma at the Microscale\n\n**Abstract:** The magnetic isolation of biological samples is a critical technique in biomedical research and diagnostics, yet traditional methods have predominantly relied on macroscopic devices that are ill-suited for point-of-care applications. In this study, we explore an innovative approach to blood cell sorting through intensive magnetophoresis utilizing microfluidic systems. Our method involves the application of a magnetic field gradient within a microchannel that contains red blood cells (RBCs) suspended in a buffer solution, facilitating their efficient separation from plasma. The findings indicate that our technique is not only straightforward but also highly effective in achieving high purity and efficiency in the separation of various blood components. This advancement holds significant potential for the development of portable diagnostic tools that leverage microscale blood extraction technologies.\n\nMagnetic isolation techniques are integral across numerous fields, including medicine, biotechnology, environmental studies, and the nutrition industry. However, existing methods often necessitate large, cumbersome equipment, limiting their application outside laboratory environments. Recent trends have focused on miniaturizing these systems into lab-on-a-chip platforms, enabling the integration of diverse functionalities such as sample preparation, chemical analysis, drug delivery, and bioassays onto a single chip. Magnetic separators, in particular, have garnered attention for their simplicity, cost-effectiveness, portability, and compatibility with other microfabricated components.\n\nDespite advancements in the field, current methodologies face several limitations. Many existing systems operate in a batch-wise manner, which diminishes throughput and necessitates substantial input volumes. Furthermore, most prototypes are designed for the isolation of only two distinct populations, rendering them ineffective for processing more complex mixtures containing multiple cell types simultaneously. Additionally, the fabrication processes often involve intricate multi-phase techniques, complicating the integration of additional functionalities. Lastly, prior research has predominantly been conducted under static conditions, which restricts the adaptability of device architectures. Our work addresses these challenges, paving the way for more versatile and efficient magnetic separation techniques in biomedical applications.",
        "ori-fast-z-score": 0.5146502354656654,
        "water-fast-z-score": 8.994650816763707,
        "rewrite-fast-z-score": 0.457495710997814
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dependence of CMI Growth Rates on Electron Velocity Distributions and Perturbation by Solitary Waves .\nAbstract:\nWe have studied the dependence of growth rates for collisionless magnetic instabilities (CMIs) in nonrelativistic electron-ion plasmas with Maxwellian velocity distributions, using linear kinetic theory. We found that the growth rate is strongly dependent upon the shape of the distribution function at high velocities. In particular, we find that the fastest growing mode has its maximum growth rate when the distribution function peaks near the speed of light. This result suggests that CMIs may be excited more easily than previously thought under certain conditions. \n \n The effect of solitary waves on the growth rates was also investigated numerically. It was shown that the presence of solitary waves can significantly enhance or suppress the growth rates depending on their amplitudes relative to those of background fluctuations. These results are important because they show how nonlinear effects such as solitary wave generation affect the stability properties of plasma systems. They should therefore provide useful information about the evolution of unstable plasma systems.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dependence of CMI Growth Rates on Electron Velocity Distributions and Perturbation by Solitary Waves . Abstract : We have researched the dependence of growth rates for collisionless magnetic instabilities ( CMIs ) in nonrelativistic electron - ion plasmas with Maxwellian velocity distributions , using linear kinetic theory .We showed that the development frequency is strongly dependent upon the shape of the distribution function at high velocities . In particular , we find that the fastest growing mode has its highest growth speed when the distribution function peaks near the speed of light .This result suggests that CMIs might be excited more easily than previously thought under certain conditions . The impact of solitary waves on the development rates was also examined numerically .It was shown that the presence of solitary waves can significantly affect or suppress the development rates depending on their amplitudes compared to those of background fluctuations . These data are important because they show how nonlinear effects such as solitary wave generation control the stability properties of plasma systems .They should therefore offer useful details about the evolution of unstable plasma systems .",
        "rewrite_text": "Title: Dependence of CMI Growth Rates on Electron Velocity Distributions and Perturbation by Solitary Waves\n\nAbstract: In this study, we investigate the relationship between growth rates of collisionless magnetic instabilities (CMIs) and the velocity distributions of electrons in nonrelativistic electron-ion plasmas characterized by Maxwellian distributions, employing linear kinetic theory as our analytical framework. Our findings reveal a significant correlation between the development frequency of CMIs and the shape of the electron distribution function, particularly at elevated velocities. Notably, we identify that the mode exhibiting the highest growth rate occurs when the distribution function peaks at velocities approaching the speed of light. This insight implies that CMIs may be more readily excited under specific conditions than previously anticipated, thereby enhancing our understanding of plasma behavior in various astrophysical and laboratory contexts.\n\nAdditionally, we conducted numerical simulations to explore the influence of solitary waves on the growth rates of CMIs. Our results indicate that solitary waves can either enhance or suppress these growth rates, contingent upon their amplitude relative to background fluctuations. This dual effect underscores the complexity of plasma dynamics, where nonlinear phenomena such as solitary wave formation play a crucial role in determining the stability characteristics of plasma systems. The implications of our findings are significant, as they provide a deeper understanding of how nonlinear interactions can modulate the evolution of unstable plasma configurations. Consequently, this research contributes valuable insights into the intricate interplay between electron velocity distributions and solitary wave perturbations, offering a more comprehensive perspective on the stability and dynamics of plasma systems.",
        "ori-fast-z-score": 0.953998092005724,
        "water-fast-z-score": 4.8488257455915145,
        "rewrite-fast-z-score": 2.138089935299395
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Optimal Electrostatic Space Tower (Mast, New Space Elevator) .\nAbstract:\nThe space elevator is an important project in the field of aerospace engineering and has been studied for many years by scientists all over the world. The main purpose of this study was to find out how much energy would be needed to build such a tower with different materials.  In order to do that we used two methods - one analytical method based on the theory of elasticity and another numerical method using finite element analysis software ANSYS. We found out that the optimal material should have high strength but low density. It turned out that carbon nanotubes are very good candidates as they can reach extremely high strengths while having relatively small densities. This work will help us design better space elevators in the future. Keywords: Energy consumption, Carbon Nanotube, Optimum Material, Finite Element Analysis Software, Analytical Method, Elasticity Theory, Space Elevator. 1 Introduction   Space elevators are considered to be one of the most promising projects in the field of aeronautics and astronautics  1  . They could provide transportation between Earth orbit and ground level without any fuel consumption  2  , which makes them especially useful for transporting people or cargo  3  .\nIn recent decades there were several attempts made at building space elevators  4  . However none of these designs managed to become fully functional  5  . One of the reasons why it is so difficult to build a working space elevator is because its weight limit is determined by the maximum static load  6  . If the weight exceeds this value then the cable will sag under gravity  7  . Another problem is that the cables need to support their own weight  8  . Therefore if you want to make your space elevator lighter than air  9  , you must use some kind of counterweight  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Optimal Electrostatic Space Tower ( Mast , New Space Elevator ) . Abstract : The space lift is an important project in the field of aviation design and has been studied for numerous years by scientists all over the world .The main aim of this study was to find out how many heat might be needed to build such a building with various materials . In order to do that we using two methods - one analytical method using on the theoretical of elasticity and another numerical technique utilizing finite element assessment software ANSYS .We figured out that the ideal structure should have high strength but little density . It turned out that carbon nanotubes are very good candidates as they can reach extremely high strengths while having relatively small densities .This project will assist us design good space elevators in the future . Keywords : Energy consumption , Carbon Nanotube , Optimum Material , Finite Element Analysis Software , Analytical Method , Elasticity Theory , Space Elevator .1 Introduction Space lifts are considered to be one of the most attractive projects in the field of aeronautics and astronautics 1 . They could enable transportation between Earth orbit and land level without any fuel expenditure 2 , which makes them especially suitable for handling persons or cargo 3 .In past decades there were several efforts made at building room lifts 4 . However none of these designs able to become completely structural 5 .One of the explanations why it is so difficult to build a working space lift is because its weight limit is calculated by the maximum static load 6 . If the weight reaches this amount then the cable will sag under gravity 7 .Another difficulty is that the ropes require to support their own weight 8 . Therefore if you want to make your space train lighter than air 9 , you must use some kind of counterweight 10 .",
        "rewrite_text": "**Title:** Optimal Electrostatic Space Tower (Mast, New Space Elevator)\n\n**Abstract:** The concept of a space elevator represents a significant advancement in aerospace engineering, garnering extensive research interest from scientists globally over the years. This study primarily investigates the thermal energy requirements necessary for constructing a space elevator using various materials. To achieve this, we employed two distinct methodologies: an analytical approach grounded in the principles of elasticity and a numerical technique utilizing the finite element analysis software ANSYS. Our findings indicate that the optimal structure for a space elevator must possess a combination of high strength and low density. Notably, carbon nanotubes emerge as exceptional candidates for this application, as they exhibit remarkable strength-to-weight ratios, making them ideal for such demanding structural requirements. This research not only contributes to the theoretical understanding of space elevator design but also paves the way for practical implementations in future aerospace projects. The implications of this work extend beyond mere material selection, as it addresses the broader challenges associated with energy consumption and structural integrity in the context of space transportation systems. \n\n**Keywords:** Energy consumption, Carbon Nanotube, Optimum Material, Finite Element Analysis Software, Analytical Method, Elasticity Theory, Space Elevator.\n\n**1 Introduction:** Space elevators are increasingly recognized as one of the most promising endeavors in the realms of aeronautics and astronautics. They offer the potential for efficient transportation between Earth's surface and orbit without the need for fuel, making them particularly advantageous for the movement of both people and cargo. Despite numerous attempts over the past few decades to develop functional space elevators, none have achieved full structural viability. A key challenge in constructing a space elevator lies in the weight limitations imposed by maximum static loads; exceeding this threshold results in cable sagging due to gravitational forces. Additionally, the cables must support their own weight, complicating the design further. To create a structure that is lighter than air, the incorporation of a counterweight becomes essential. This study aims to address these challenges and contribute to the feasibility of future space elevator projects.",
        "ori-fast-z-score": 0.6859943405700353,
        "water-fast-z-score": 8.17629817532677,
        "rewrite-fast-z-score": 1.1470786693528088
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nonlocal Phenomenology for anisotropic MHD turbulence .\nAbstract:\nWe present an analysis of the nonlocal phenomenology in magnetohydrodynamic (MHD) turbulence with strong magnetic field anisotropy, which is relevant to solar wind and space plasmas. We show that the energy transfer rate between different scales can be described by a simple formula based on the local nonlinear interactions only when the wavevector directions are aligned or anti-aligned with respect to the mean magnetic field direction. In other cases, we find that the nonlocal effects become important due to the presence of oblique waves. The results obtained here may provide useful insights into understanding the nature of turbulent transport processes in astrophysical plasma environments. Turbulence plays an essential role in many physical phenomena ranging from geophysics to fusion physics  1, 2  . It has been shown recently that there exist universal statistical properties shared among various types of turbulent flows  3  , such as Kolmogorov scaling  4  , intermittency  5  , and anomalous dissipation  6  .\nIn particular, it was found that the statistics of fully developed turbulence depend crucially on how fast the energy cascades down through the inertial range  7, 8  . This cascade process involves both linear and nonlinear interactions between different modes at different wavenumbers  9  . For example, in hydrodynamics, the energy flux Π(k) ≡< |δu k · δu * −k | 2 > / < u 2 k > depends not only on the magnitude of the wavenumber k but also its orientation relative to the large-scale flow  10  . Here, u k denotes the Fourier transform of velocity fluctuations at scale k −1 . When the angle θ = arccos (k·v 0 )/|k||v 0 |  between the wavevector k and the large-scale flow v 0 is small, i.e., θ ≪ 1, the energy flux Π ∝ k −2/3 sin 2/3 θ  11  . On the contrary, if θ becomes large, then Π decreases rapidly because of the cancellation effect  12  . Similar behaviors have been observed in magnetohydrodynamics (MHD), where the energy flux Π �",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nonlocal Phenomenology for anisotropic MHD turbulence . Abstract : We present an assessment of the nonlocal phenomenology in magnetohydrodynamic ( MHD ) turbulence with powerful magnetic force anisotropy , which is relevant to solar wind and space plasmas .We see that the power transfer frequency between various scales can be described by a simple equation based on the local nonlinear interactions only when the wavevector directions are aligned or anti - aligned with regard to the mean magnetic force direction . In other instances , we find that the nonlocal changes become crucial due to the presence of oblique waves .The results derived here perhaps offer useful insights into knowledge the nature of turbulent transport systems in astrophysical plasma settings . Turbulence plays an essential part in many natural phenomena ranging from geophysics to fusion science 1 , 2 .It has been shown lately that there remain universal empirical features common among various types of turbulent waves 3 , such as Kolmogorov scaling 4 , intermittency 5 , and anomalous dissipation 6 . In particular , it was shown that the statistics of fully developed turbulence depend crucially on how fast the electricity cascades down through the inertial range 7 , 8 .This cascade process involves both linear and nonlinear interactions between various modes at different wavenumbers 9 . For instance , in hydrodynamics , the power flux Π ( h ) ≡ < | δu k · δu * −k | 2 > / < u 2 k > depends not only on the magnitude of the wavenumber k but also its attitude relative to the small - scale stream 10 .Here , u k denotes the Fourier transform of velocity fluctuations at scale k −1 . When the angle θ = arccos ( k · v 0 ) / | k | | v 0 | between the wavevector k and the huge - scale stream u 0 is tiny , i . e . , θ [UNK] 1 , the power flux Π [UNK] k −2 / 3 sin 2 / 3 θ 11 .On the contrary , if θ becomes large , then Π decreases quickly because of the cancellation effect 12 . Similar behaviors have been observed in magnetohydrodynamics ( MHD ) , where the power flux Π",
        "rewrite_text": "Title: Nonlocal Phenomenology for Anisotropic MHD Turbulence\n\nAbstract: This study explores the nonlocal phenomenology of magnetohydrodynamic (MHD) turbulence characterized by significant magnetic force anisotropy, particularly in the context of solar wind and space plasmas. We demonstrate that the frequency of power transfer across different scales can be effectively described by a straightforward equation that relies solely on local nonlinear interactions, provided that the directions of the wavevectors are either aligned or anti-aligned with the mean magnetic force direction. However, in scenarios where oblique waves are present, the significance of nonlocal effects becomes pronounced. The findings presented in this paper may enhance our understanding of turbulent transport mechanisms in astrophysical plasma environments.\n\nTurbulence is a fundamental aspect of numerous natural phenomena, spanning fields from geophysics to fusion science. Recent research has identified universal empirical characteristics that are shared among various turbulent wave types, including Kolmogorov scaling, intermittency, and anomalous dissipation. Notably, the statistical properties of fully developed turbulence are heavily influenced by the rate at which energy cascades through the inertial range. This cascade process encompasses both linear and nonlinear interactions among different modes across varying wavenumbers.\n\nIn hydrodynamic systems, the power flux, defined as Π(h) ≡ < | δu_k · δu*_−k |^2 > / < u^2_k >, is contingent not only on the magnitude of the wavenumber k but also on its orientation relative to the small-scale flow. Here, u_k represents the Fourier transform of velocity fluctuations at the scale of k^−1. When the angle θ = arccos(k · v_0) / |k| |v_0| between the wavevector k and the large-scale flow u_0 is small, the power flux behaves as Π ∝ k^−2/3 sin^2/3(θ). Conversely, as θ increases, the power flux diminishes rapidly due to cancellation effects. Similar patterns have been observed in MHD systems, where the power flux exhibits analogous dependencies. This research contributes to a deeper understanding of the intricate dynamics of MHD turbulence and its implications for astrophysical phenomena.",
        "ori-fast-z-score": -1.7962924780409972,
        "water-fast-z-score": 5.388877434122992,
        "rewrite-fast-z-score": 1.2893167424406085
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Higher order antibunching in intermediate states .\nAbstract:\nWe study the second-order correlation function for an atom interacting with two modes of light, one resonant and another off-resonant to atomic transition frequency. We show that higher order antibunching can be observed when the atom is initially prepared in an excited state or ground state superposition. The effect is more pronounced if the initial state has some population on the excited state. This phenomenon may have applications in quantum information processing. \n \n Introduction:-In recent years there has been considerable interest in studying nonclassical properties of radiation fields generated by atoms  1  . In particular, it was shown that the photon statistics of such systems are governed by the first-order coherence function g (1) (τ)  2  , which describes bunching behavior at short times and anti-bunching at longer times  3  . It is well known that this property arises due to destructive interference between different pathways leading to emission of photons  4  .\nRecently, several authors studied the effects of spontaneous emission on the second-order correlation functions  5  -  8  . They showed that the presence of spontaneous emission leads to sub-Poissonian statistics  6 - 8  . However, these studies were restricted only to the case where the atom interacts with a single mode of field. On the other hand, many experiments involving atoms interacting simultaneously with multiple modes of electromagnetic field have also been performed  9  -  11  . For example, in Ref.  10  , the authors investigated the influence of vacuum fluctuations on the fluorescence spectrum of a three-level system driven by two laser beams. In addition, they found that the intensity noise of the emitted light depends strongly on the relative phase difference between the driving lasers. Motivated by these experimental results we consider here the problem of calculating the second-order correlation function of an atom interacting simultaneously with two modes of light  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Higher order antibunching in intermediate states . Abstract : We research the second - order correlation function for an element interacting with two modes of light , one resonant and another off - resonant to atomic transition frequency .We see that higher order antibunching can be found when the atom is initially prepared in an excited state or ground state superposition . The phenomenon is more pronounced if the first state has some population on the excited state .This phenomenon might have applications in quantum information processing . Introduction : - In recent years there has been substantial interest in investigating nonclassical characteristics of radiation fields generated by atoms 1 .In particular , it was shown that the photon statistics of such systems are governed by the first - order coherence function g ( 1 ) ( τ ) 2 , which explains bunching behavior at short periods and pro - bunching at shorter times 3 . It is well established that this property arises owing to destructive interference between various pathways leading to emission of photons 4 .Recently , various scientists examined the effects of induced emission on the second - order correlation functions 5 - 8 . They showed that the presence of induced emission contributes to sub - Poissonian statistics 6 - 8 .However , these research were restricted only to the case where the atom interacts with a single mode of field . On the other hand , many tests featuring atoms interacting simultaneously with various modes of electromagnetic field have also been performed 9 - 11 .For instance , in Ref . 10 , the published investigated the impact of vacuum fluctuations on the fluorescence spectrum of a three - level network driven by two laser beams .In addition , they reported that the frequency sound of the emitted light depends strongly on the relative phase change between the driving lasers . Motivated by these experimental results we consider here the question of calculating the second - order correlation function of an element interacting simultaneously with two modes of light 12 .",
        "rewrite_text": "**Title:** Higher Order Antibunching in Intermediate States\n\n**Abstract:** This study investigates the second-order correlation function of an atom interacting with two distinct modes of light: one that is resonant and another that is off-resonant with respect to the atomic transition frequency. Our findings reveal that higher-order antibunching occurs when the atom is prepared in either an excited state or a superposition of the ground and excited states. Notably, this phenomenon is enhanced when the initial state possesses a significant population in the excited state. The implications of these results are significant, particularly for applications in quantum information processing, where the manipulation of quantum states is crucial. \n\nIn recent years, there has been a growing interest in exploring the nonclassical properties of radiation fields produced by atoms. Previous research has established that the photon statistics in such systems are influenced by the first-order coherence function, which accounts for both bunching behavior at short timescales and pro-bunching at even shorter intervals. This behavior is attributed to destructive interference among various emission pathways. Recent studies have also examined the role of induced emission on second-order correlation functions, demonstrating that it can lead to sub-Poissonian statistics. However, these investigations have primarily focused on scenarios where the atom interacts with a single mode of light.\n\nIn contrast, numerous experiments have explored the interaction of atoms with multiple modes of electromagnetic fields. For example, one study analyzed how vacuum fluctuations affect the fluorescence spectrum of a three-level atomic system driven by two laser beams, revealing a strong dependence of the emitted light's frequency on the relative phase between the lasers. Inspired by these findings, our research aims to calculate the second-order correlation function for an atom interacting with two light modes simultaneously, thereby expanding the understanding of photon statistics in multi-mode scenarios. This work contributes to the broader field of quantum optics and may pave the way for novel applications in quantum technologies.",
        "ori-fast-z-score": -0.4743416490252569,
        "water-fast-z-score": 6.344409644902455,
        "rewrite-fast-z-score": 2.4688535993934706
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nonlinear Dynamics of the Phonon Stimulated Emission in Microwave Solid-State Resonator of the Nonautonomous Phaser Generator .\nAbstract:\nThe nonlinear dynamics of phonon stimulated emission (PSE) is investigated for microwave solid-state resonators with nonautonomous phase-locked loop generators. The PSE process is described by means of an extended version of the Lang-Kobayashi model, which takes into account the influence of the external driving field on the gain medium and includes additional terms describing the effect of spontaneous emission noise. It has been shown that the presence of these new effects leads to significant changes in the behavior of the system under consideration as compared to autonomous systems. In particular, it was found that the generation of chaotic regimes becomes possible even at relatively small values of the pumping parameter. This fact can be used to develop novel types of chaos-based devices based on microwave solid-state oscillators. \n \n Keywords: Nonlinear dynamics; Chaos; Phase synchronization; Phonons; Microwave solid state oscillator. PACS: 42.65.Tt; 42.65.Pq; 42.65.Re",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nonlinear Dynamics of the Phonon Stimulated Emission in Microwave Solid - State Resonator of the Nonautonomous Phaser Generator . Abstract : The nonlinear dynamics of phonon stimulated emission ( PSE ) is investigated for microwave solid - state resonators with nonautonomous phase - locked loop components .The PSE transition is characterized by means of an extended version of the Lang - Kobayashi model , which assumes into consideration the impact of the external driving field on the gain medium and incorporates additional terms describing the impact of induced emission interference . It has been shown that the presence of these new effects leads to significant improvements in the activity of the process under consideration as compared to autonomous systems .In particular , it was shown that the generation of turbulent regimes appears possible even at fairly little values of the pumping function . This fact can be used to develop new types of chaos - based devices derived on microwave solid - state oscillators .Keywords : Nonlinear dynamics ; Chaos ; Phase synchronization ; Phonons ; Microwave liquid state oscillator . PACS : 42 . 65 . Tt ; 42 . 65 . Pq ; 42 . 65 . Re",
        "rewrite_text": "Title: Nonlinear Dynamics of Phonon Stimulated Emission in Microwave Solid-State Resonators of the Nonautonomous Phaser Generator\n\nAbstract: This study explores the nonlinear dynamics associated with phonon stimulated emission (PSE) in microwave solid-state resonators that incorporate nonautonomous phase-locked loop components. Utilizing an enhanced version of the Lang-Kobayashi model, we analyze the PSE transition by accounting for the influence of an external driving field on the gain medium, while also integrating additional terms that capture the effects of induced emission interference. Our findings reveal that these newly considered factors significantly enhance the operational efficiency of the PSE process when compared to traditional autonomous systems. Notably, we demonstrate that turbulent regimes can emerge even with relatively low values of the pumping function. This discovery opens avenues for the development of innovative chaos-based devices leveraging microwave solid-state oscillators. The implications of this research extend to various applications in nonlinear dynamics, chaos theory, phase synchronization, and phonon interactions within microwave liquid state oscillators. The results underscore the potential for advancing technology in this field, particularly in the context of creating devices that harness chaotic behavior for practical use. \n\nKeywords: Nonlinear dynamics; Chaos; Phase synchronization; Phonons; Microwave solid-state oscillator. \n\nPACS: 42.65.Tt; 42.65.Pq; 42.65.Re",
        "ori-fast-z-score": -0.7875615306482168,
        "water-fast-z-score": 4.47213595499958,
        "rewrite-fast-z-score": 0.30460384954008574
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  What Gamma-Ray Bursts Explode Into .\nAbstract:\nGamma-ray bursts (GRBs) are the most energetic explosions in the universe, but their origin is still unknown. The leading model for GRB production involves two compact objects merging into one black hole and then exploding as a result of rapid accretion onto this black hole.  In this talk I will discuss how we can use gravitational waves to test this hypothesis by looking at the ringdown phase of these mergers. This is an exciting time for gravitational wave astronomy with Advanced LIGO/VIRGO starting taking data soon! \nI will also present some recent results on using gravitational waves to study neutron star mergers that may be related to short gamma ray bursts. Finally, I ll give you my personal perspective on what it takes to become a successful scientist today. My research interests include gravitational waves, astrophysics, cosmology, and particle physics. I m currently working at MIT Kavli Institute for Astrophysics and Space Research where I am part of the Gravitational Wave Cosmology Project.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : What Gamma - Ray Bursts Explode Into . Abstract : Gamma - ray bursts ( GRBs ) are the most intense bombs in the universe , but their source is still unclear .The leading theory for GRB development involves two compact entities combining into one dark hole and then exploding as a result of rapid accretion onto this black hole . In this talk I will explore how we can using gravitational waves to test this hypothesis by searching at the ringdown phase of these mergers .This is an exciting day for gravitational wave astronomy with Advanced LIGO / VIRGO starting took data soon ! I will also report some latest findings on uses gravity waves to study neutron star mergers that might be connected to short gamma ray waves .Finally , I ll offer you my personal perspective on what it takes to become a successful researcher today . My research interests cover gravitational waves , astrophysics , cosmology , and particle science .I m currently working at MIT Kavli Institute for Astrophysics and Space Research where I am member of the Gravitational Wave Cosmology Project .",
        "rewrite_text": "**Title: What Gamma-Ray Bursts Explode Into**\n\n**Abstract:** Gamma-ray bursts (GRBs) represent some of the most powerful explosions in the universe, yet their origins remain a subject of ongoing investigation. The prevailing hypothesis suggests that GRBs arise from the merger of two compact objects, which subsequently form a black hole. This process is believed to trigger an explosion due to the rapid accretion of material onto the newly formed black hole. In this presentation, I will discuss how gravitational waves can be utilized to validate this theory by examining the ringdown phase associated with these mergers. The recent advancements in gravitational wave astronomy, particularly with the commencement of data collection by Advanced LIGO and VIRGO, mark a significant milestone in our understanding of these cosmic phenomena. Additionally, I will share recent findings regarding the application of gravitational waves in studying neutron star mergers, which may be linked to short-duration gamma-ray bursts. Furthermore, I will provide insights from my personal journey in research, highlighting the essential qualities and skills needed to thrive as a researcher in today’s scientific landscape. My research encompasses a broad range of topics, including gravitational waves, astrophysics, cosmology, and particle physics. Currently, I am affiliated with the MIT Kavli Institute for Astrophysics and Space Research, where I contribute to the Gravitational Wave Cosmology Project. This talk aims to bridge theoretical concepts with observational data, fostering a deeper understanding of the enigmatic nature of gamma-ray bursts and their implications for the universe.",
        "ori-fast-z-score": -0.5555555555555556,
        "water-fast-z-score": 5.158920219515446,
        "rewrite-fast-z-score": 0.3746343246326776
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spitzer Observations of Transient, Extended Dust in Two Elliptical Galaxies: New Evidence of Recent Feedback Energy Release in Galactic Cores .\nAbstract:\nWe report the discovery of transient dust emission at mid-infrared wavelengths (5-20 microns) in two elliptical galaxies with active galactic nuclei (AGN). The observations were made using Spitzer Space Telescope s Infrared Array Camera and Multiband Imaging Photometer for Spitzer instruments over a period of several years. We find that the infrared luminosity is consistent with heating by AGN radiation or supernovae remnants within the central kpc region. This suggests that recent feedback energy release has been occurring in these cores. These results are important because they provide new evidence on how supermassive black holes grow through accretion onto their host galaxy centers. They also demonstrate the power of combining multiwavelength data to study the physical processes associated with nuclear activity. \n \n Keywords: Active galactic nucleus, Galaxy evolution, Mid-infrared, Nuclear starbursts \n \n 1. Introduction \n \n Supermassive black holes reside in the center of most massive galaxies. Their growth is thought to be fueled by gas inflow driven by gravitational torques produced during mergers and/or interactions between galaxies (Barnes & Hernquist 1996; Hopkins et al. 2006) . However, it remains unclear what happens after this fuel supply runs out. One possibility is that the black hole continues growing via radiatively inefficient accretion flows (Narayan & Yi 1994) , which may produce powerful winds and jets that can drive large-scale outflows into the surrounding interstellar medium (ISM) (Silk & Rees 1998; Di Matteo et al. 2005 ). Another possibility is that the black holes become dormant as the ISM becomes too hot to cool efficiently (Bower et al. 2006; Croton et al. 2006 ) until another merger event triggers renewed activity. Understanding the mechanisms responsible for shutting off black-hole growth will help us understand why some galaxies have large black holes while others do not. \n \n 2. Previous Work \n \n Several studies have shown that there exists an anti-correlation between the mass of the central supermassive black hole and the stellar velocity dispersion of its host galaxy bulge (Ferrar",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spitzer Observations of Transient , Extended Dust in Two Elliptical Galaxies : New Evidence of Recent Feedback Energy Release in Galactic Cores . Abstract : We report the discovery of transient dust radiation at mid - infrared wavelengths ( 5 - 20 microns ) in two elliptical galaxies with active galactic nuclei ( AGN ) .The surveys were made using Spitzer Space Telescope s Infrared Array Camera and Multiband Imaging Photometer for Spitzer instruments over a period of several period . We see that the infrared luminosity is compatible with heating by AGN radiation or supernovae fragments within the central kpc zone .This implies that current feedback power release has been occurring in these cores . These data are important because they give new evidence on how supermassive black holes expand through accretion onto their host galaxy structures .They also demonstrate the power of combining multiwavelength evidence to study the physical processes associated with nuclear activity . Keywords : Active galactic nucleus , Galaxy evolution , Mid - infrared , Nuclear starbursts 1 .Introduction Supermassive black holes dwell in the center of most gigantic galaxies . Their growth is suggested to be motivated by gas inflow driven by gravitational torques created during mergers and / or relationships between objects ( Barnes & Hernquist 1996 ; Hopkins et al .2006 ) . However , it remains unsure what comes after this fuel supply runs out .One possibility is that the dark hole keeps developing via radiatively inefficient accretion currents ( Narayan & Yi 1994 ) , which would create potent winds and jets that can force large - scale outflows into the adjacent interstellar medium ( ISM ) ( Silk & Rees 1998 ; Di Matteo et al . 2005 ) .Another possibility is that the dark holes become dormant as the ISM becomes too warm to hot quickly ( Bower et al . 2006 ; Croton et al .2006 ) until another merger event triggers renewed behavior . Understanding the mechanisms involved for shut off dark - hole growth will assist us explain why some stars have huge black holes while many do not .2 . Previous Work Several studies have shown that there exists an counter - correlation between the mass of the main supermassive black hole and the stellar velocity dispersion of its host galaxy bulge ( Ferrar",
        "rewrite_text": "**Title:** Spitzer Observations of Transient, Extended Dust in Two Elliptical Galaxies: New Evidence of Recent Feedback Energy Release in Galactic Cores\n\n**Abstract:** In this study, we present the detection of transient dust emission at mid-infrared wavelengths (5-20 microns) in two elliptical galaxies hosting active galactic nuclei (AGN). Utilizing the Spitzer Space Telescope's Infrared Array Camera and Multiband Imaging Photometer, we conducted observations over an extended timeframe. Our findings indicate that the infrared luminosity observed is consistent with heating mechanisms attributed to AGN radiation or remnants from supernovae within the central kiloparsec region. This observation suggests that feedback energy release is actively occurring in these galactic cores. The implications of these data are significant, as they provide new insights into the processes by which supermassive black holes influence their host galaxies through accretion. Furthermore, our results underscore the importance of integrating multiwavelength observational data to enhance our understanding of the physical mechanisms underlying nuclear activity. \n\n**Keywords:** Active galactic nucleus, Galaxy evolution, Mid-infrared, Nuclear starbursts\n\n**1. Introduction:** Supermassive black holes are typically found at the centers of the largest galaxies, and their growth is believed to be driven by gas inflow resulting from gravitational interactions during mergers or encounters with other celestial bodies (Barnes & Hernquist 1996; Hopkins et al. 2006). However, the fate of these black holes once their fuel supply is depleted remains uncertain. One hypothesis posits that they may continue to grow through radiatively inefficient accretion processes (Narayan & Yi 1994), which can generate powerful winds and jets, leading to significant outflows into the surrounding interstellar medium (ISM) (Silk & Rees 1998; Di Matteo et al. 2005). Alternatively, black holes may enter a dormant phase if the ISM becomes too warm to facilitate further accretion (Bower et al. 2006; Croton et al. 2006), only to reactivate during subsequent merger events. Understanding the mechanisms that lead to the cessation of black hole growth is crucial for explaining the disparity in black hole masses among different stellar populations.\n\n**2. Previous Work:** Numerous studies have established a counter-correlation between the mass of the primary supermassive black hole and the stellar velocity dispersion of its host galaxy bulge (Ferrar et al. 2006).",
        "ori-fast-z-score": -1.3241694217637887,
        "water-fast-z-score": 6.7266838681529375,
        "rewrite-fast-z-score": -0.1655211777204736
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Covering Homology .\nAbstract:\nWe introduce the notion of covering homology, which is an extension of ordinary homology to infinite graphs and simplicial complexes. The main idea behind this concept is that we consider not only finite subcomplexes but also their infinite analogues - so-called coverings. We show how covering homology can be used for studying properties of infinite graphs such as amenability or hyperbolicity. In particular, we prove that if a graph has infinitely many ends then its first covering homology group vanishes. This result generalizes the classical theorem by Stallings on groups with infinitely many ends. Covering homology provides us with new tools for investigating various classes of infinite objects in mathematics. It turns out that it is closely related to other concepts like equivariant homology theory (in the case when our object admits actions of some group) or higher-order algebraic K-theory. Finally, we present several examples illustrating applications of covering homology.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Covering Homology . Abstract : We introduce the notion of covering homology , which is an extension of regular homology to infinite graphs and simplicial structures .The main idea behind this concept is that we treat not only finite subcomplexes but also their infinite analogues - so - called coverings . We see how covering homology can be used for studying characteristics of infinite graphs such as amenability or hyperbolicity .In particular , we prove that if a graph has infinitely many ends then its initial covering homology group vanishes . This result generalizes the classical principle by Stallings on groups with infinitely many ends .Covering homology provides us with novel techniques for investigating different categories of infinite concepts in mathematics . It turns out that it is closely related to other concepts like equivariant homology theory ( in the case when our object accepts actions of some group ) or greater - order algebraic K - theory .Finally , we present many examples illustrating applications of covering homology .",
        "rewrite_text": "In this article, we present the concept of covering homology, which serves as an extension of traditional homology to accommodate infinite graphs and simplicial structures. The fundamental premise of covering homology is the inclusion of not only finite subcomplexes but also their infinite counterparts, referred to as coverings. This innovative approach allows for a deeper exploration of the properties of infinite graphs, particularly in relation to characteristics such as amenability and hyperbolicity. \n\nOne of the key findings of our research is the demonstration that if a graph possesses infinitely many ends, its initial covering homology group is null. This result extends the classical theorem established by Stallings regarding groups with infinitely many ends, thereby providing a broader context for understanding these mathematical structures. \n\nMoreover, covering homology introduces new methodologies for examining various categories of infinite mathematical concepts. We reveal its close connections to other significant theories, including equivariant homology theory, which applies when the object under consideration is subject to group actions, and higher-order algebraic K-theory. \n\nTo illustrate the practical implications of covering homology, we provide numerous examples that highlight its applications across different mathematical domains. Through these examples, we aim to showcase the versatility and utility of covering homology in advancing the study of infinite structures, ultimately contributing to a richer understanding of their underlying properties and relationships within the broader mathematical landscape.",
        "ori-fast-z-score": 0.47140452079103173,
        "water-fast-z-score": 3.9524197172898554,
        "rewrite-fast-z-score": 0.3713906763541037
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Minimum Gap-opening Planet Mass in an Irradiated Circumstellar Accretion Disk .\nAbstract:\nWe present the results of hydrodynamic simulations that show how planets open gaps in circumstellar disks and determine their minimum mass for gap opening as a function of disk viscosity, surface density profile slope, and irradiation by the central star.  We find that the planet s ability to open a gap is determined primarily by its accretion rate onto the planet (which depends on the planet s mass) rather than by its luminosity or temperature. The critical planet mass decreases with increasing disk viscosity because higher viscosities lead to more rapid angular momentum transport across the planet s orbit which reduces the planet s ability to accrete gas. For fixed viscosity, we find that the critical planet mass increases with decreasing surface density power law index because lower values of this parameter correspond to steeper radial profiles of the disk s surface density which leads to stronger gravitational torques exerted by the planet. Finally, we find that the planet s critical mass decreases with increasing stellar irradiation due to increased temperatures at small radii where most of the torque is generated.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Minimum Gap - opening Planet Mass in an Irradiated Circumstellar Accretion Disk . Abstract : We report the results of hydrodynamic simulations that demonstrate how planets open gaps in circumstellar disks and establish their lowest mass for gap opening as a function of disk viscosity , surface temperature profile slope , and irradiation by the main star .We see that the planet s capacity to closed a gap is measured largely by its accretion rate onto the planet ( which depends on the planet s mass ) instead than by its luminosity or temperature . The essential planet mass decreases with higher disk viscosity because higher viscosities result to more rapid angular velocity transport across the planet s orbit which reduces the planet s capacity to accrete gas .For fixed viscosity , we find that the critical planet mass increases with decreasing surface density power law index because lower values of this parameter correspond to steeper radial profiles of the disk s surface density which leads to stronger gravitational torques exerted by the planet . Finally , we find that the planet s critical mass decreases with increasing stellar irradiation due to increased temperatures at small radii where most of the torque is generated .",
        "rewrite_text": "In this study, we present findings from hydrodynamic simulations that investigate the mechanisms by which planets create gaps in circumstellar accretion disks, focusing on determining the minimum mass required for gap formation. Our analysis reveals that this critical mass is influenced by several factors, including the viscosity of the disk, the slope of the surface temperature profile, and the level of irradiation from the central star. Notably, we find that the ability of a planet to open a gap is primarily determined by its accretion rate, which is a function of the planet's mass, rather than its luminosity or temperature. \n\nAs disk viscosity increases, the minimum mass necessary for gap opening decreases. This is attributed to the more efficient angular momentum transport that occurs at higher viscosities, which diminishes the planet's ability to accrete gas. In scenarios with constant viscosity, we observe that the critical mass for gap formation rises as the power law index of the surface density decreases. This relationship is explained by the fact that lower indices correspond to steeper radial profiles of surface density, resulting in stronger gravitational torques acting on the planet.\n\nAdditionally, our simulations indicate that increased stellar irradiation leads to a reduction in the planet's critical mass. This effect arises because higher temperatures at smaller radii enhance the torque exerted on the planet, facilitating gap opening even at lower masses. Overall, our findings provide valuable insights into the interplay between planetary mass, disk properties, and stellar influences in the context of planet formation within accretion disks.",
        "ori-fast-z-score": -1.0101525445522108,
        "water-fast-z-score": 2.914609664251715,
        "rewrite-fast-z-score": 0.8838834764831843
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Transients from initial conditions based on Lagrangian perturbation theory in N-body simulations .\nAbstract:\nWe present the results of an investigation into the properties and evolution of transients that arise when initial conditions are generated using Lagrangian perturbation theory (LPT) for cosmological N-body simulations. We find that LPT-based initial conditions produce spurious large-scale power at late times, which is not suppressed by increasing the number of particles used to generate these initial conditions. This effect can be mitigated by applying a low-pass filter to the evolved density field prior to generating new initial conditions with higher-order LPT. However, this approach does not completely remove all unwanted effects associated with the use of LPT-generated initial conditions. In addition, we show how the choice of time step used to evolve the initial conditions affects their accuracy. Finally, we demonstrate that it is possible to construct accurate initial conditions for large-volume cosmological simulations without having to resort to expensive high-resolution hydrodynamic simulations. The generation of realistic initial conditions for cosmological N-body",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Transients from initial conditions based on Lagrangian perturbation theory in N - bodies simulations . Abstract : We present the results of an research into the properties and evolution of transients that arise when initial conditions are produced utilizing Lagrangian perturbation theory ( LPT ) for cosmological N - bodies simulations .We see that LPT - based initial conditions generate spurious large - scale power at late times , which is not suppressed by expanding the quantity of particles needed to create these initial conditions . This phenomenon can be mitigated by using a small - pass filter to the evolved density field prior to generating new early conditions with higher - order LPT .However , this methodology does not totally avoid all unwanted effects involved with the using of LPT - produced original conditions . In addition , we study how the selection of time phase used to evolve the early conditions influences their accuracy .Finally , we prove that it is easy to build correct preliminary environments for large - volume cosmological simulations without having to resort to expensive high - resolution hydrodynamic simulations . The generation of accurate initial conditions for cosmological N - body",
        "rewrite_text": "In this study, we investigate the characteristics and development of transients that emerge from initial conditions derived through Lagrangian perturbation theory (LPT) in cosmological N-body simulations. Our findings reveal that initial conditions based on LPT can lead to the introduction of artificial large-scale power in the late-time evolution of the simulations. Notably, this issue persists even when increasing the number of particles used to establish these initial conditions, indicating a fundamental limitation in the LPT approach. To address this challenge, we propose the application of a small-pass filter to the evolved density field before generating new early conditions using higher-order LPT. While this technique helps to alleviate some of the spurious effects associated with LPT-derived initial conditions, it does not completely eliminate all undesirable artifacts. Furthermore, we examine the impact of the chosen time phase on the accuracy of the evolved early conditions, highlighting the importance of this selection in the simulation process. Our results demonstrate that it is feasible to create accurate initial conditions for large-volume cosmological simulations without the necessity of costly high-resolution hydrodynamic simulations. This work contributes to the understanding of how to effectively generate reliable initial conditions for cosmological N-body simulations, ultimately enhancing the fidelity of simulations that explore the large-scale structure of the universe.",
        "ori-fast-z-score": -0.41256849850351734,
        "water-fast-z-score": 6.193611607315077,
        "rewrite-fast-z-score": 0.2873478855663454
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Precision measurement of the Casimir-Lifshitz force in a fluid .\nAbstract:\nWe report on an experiment to measure the Casimir-Lifhsztz (CL) interaction between two gold-coated glass plates immersed in water at room temperature and pressure. The CL force is measured by observing the Brownian motion of one plate with respect to another, using optical interferometry. We find that the magnitude of the observed effect agrees well with theoretical predictions based on Lifshitz theory for dielectrics. This work represents the first direct experimental observation of the CL force in a liquid medium. It also demonstrates how precision measurements can be used to test fundamental theories such as quantum electrodynamics. \n \n In recent years there has been considerable interest in measuring the Casimir-Lifhzsiz (CL)  1  force between macroscopic objects  2  . Such experiments are important because they provide tests of our understanding of vacuum fluctuations  3  , which play a central role in many areas of physics including quantum field theory  4  , statistical mechanics  5  , condensed matter  6  , atomic and nuclear physics  7  , cosmology  8  , and gravitation  9  .\n \nThe original prediction of the CL force was made more than 50 years ago  10  but it took until 1997  11  before this attractive force could be directly detected experimentally  12  . Since then several groups have performed high-precision experiments  13  -  16  aimed at testing the validity of various aspects of the theory  17  -  20  . \n \n Here we present results obtained in a new experiment designed specifically to study the CL force in liquids  21  . Our approach involves immersing two parallel plates coated with thin layers of gold into distilled water contained inside a sealed container  22  . By monitoring the Brownian motion of these plates  23  we were able to determine their mutual attraction due to the presence of the surrounding water molecules  24  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Precision measurement of the Casimir - Lifshitz force in a fluid . Abstract : We report on an research to measure the Casimir - Lifhsztz ( CL ) relationship between two gold - glazed glazed plates immersed in water at room temperature and tension .The CL force is measured by observing the Brownian movement of one plate with regard to another , using optical interferometry . We see that the magnitude of the seen effect agrees well with theoretical expectations based on Lifshitz principle for dielectrics .This study constitutes the first continuous experimental measurement of the CL force in a liquid medium . It additionally demonstrates how accuracy observations can be used to test fundamental theories such as quantum electrodynamics .In recent years there has been substantial interest in measuring the Casimir - Lifhzsiz ( CL ) 1 pressure between macroscopic objects 2 . Such experiments are important because they give tests of our knowing of vacuum fluctuations 3 , which take a central role in multiple fields of science including quantum field theory 4 , statistical mechanics 5 , condensed matter 6 , atomic and nuclear science 7 , cosmology 8 , and gravitation 9 .The original forecast of the CL force was making more than 50 centuries earlier 10 but it taking until 1997 11 before this attractive force could be directly discovered experimentally 12 . Since then several organizations have done large - precision tests 13 - 16 aiming at testing the legitimacy of several elements of the principle 17 - 20 .Here we present results derived in a new study intended specifically to study the CL force in liquids 21 . Our solution involves immersing two connected sheets coated with thin layers of gold into distilled water contained inside a sealed container 22 .By observing the Brownian movement of these plates 23 we were could to obtain their mutual attraction owing to the presence of the nearby water molecules 24 .",
        "rewrite_text": "**Title: Precision Measurement of the Casimir-Lifshitz Force in a Fluid**\n\n**Abstract:** In this study, we present a comprehensive investigation into the Casimir-Lifshitz (CL) force between two gold-coated plates submerged in water at room temperature and under tension. Utilizing optical interferometry, we measured the CL force by analyzing the Brownian motion of one plate relative to the other. Our findings indicate that the observed force aligns closely with theoretical predictions derived from the Lifshitz theory for dielectric materials. This research marks the first continuous experimental assessment of the CL force in a liquid environment, showcasing the potential of precise measurements to validate fundamental theories, including quantum electrodynamics.\n\nThe Casimir-Lifshitz force has garnered significant attention in recent years, particularly regarding its implications for vacuum fluctuations, which are pivotal across various scientific disciplines such as quantum field theory, statistical mechanics, condensed matter physics, atomic and nuclear science, cosmology, and gravitation. Although the existence of the CL force was predicted over five decades ago, it was not until 1997 that this phenomenon was directly observed in experiments. Since then, numerous research groups have conducted high-precision tests to explore the validity of different aspects of the CL principle.\n\nIn our investigation, we specifically aimed to measure the CL force in a liquid medium. Our experimental setup involved immersing two gold-coated plates in distilled water within a sealed chamber. By monitoring the Brownian motion of these plates, we successfully quantified their mutual attraction, which arises from the influence of surrounding water molecules. This work not only contributes to the understanding of the CL force in fluids but also enhances the broader discourse on the implications of quantum effects in macroscopic systems.",
        "ori-fast-z-score": -1.0795912380986197,
        "water-fast-z-score": 6.7863682865394175,
        "rewrite-fast-z-score": 0.43685202833051895
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Controlled collisions of a single atom and ion guided by movable trapping potentials .\nAbstract:\nWe report on the controlled collision between an individual trapped atom and a singly charged ion in a Paul trap, where both particles are confined to different regions of space separated by several micrometers. The ions can be moved along the axis connecting them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber. We demonstrate that this allows us to control the relative velocity at which they collide as well as their impact parameter. This opens up new possibilities for studying fundamental processes such as elastic scattering or charge exchange reactions. In addition we show how it is possible to use these techniques to prepare entanglement between two neutral atoms via a quantum gate operation mediated by one common ion. Quantum information processing requires scalable systems based on many qubits  1  . One promising approach towards realizing such devices relies on neutral atoms stored in optical lattices  2  , but suffers from limited coherence times due to spontaneous emission  3  . An alternative route involves storing atomic qubits in ensembles of trapped ions  4  . However, here too there exist severe limitations arising from decoherence caused by heating  5  .\nIn order to overcome these difficulties, hybrid approaches have been proposed  6  combining advantages of both schemes  7, 8  . Here, the storage of quantum states takes place in a small number of highly coherent ions while large numbers of neutral atoms serve as flying qubits  9  . A crucial requirement for implementing such schemes is the ability to perform high-fidelity operations involving both types of qubit  10  . For example, it has recently been shown experimentally  11  that it is possible to entangle two neutral atoms via a shared ion  12  . To achieve this goal, however, the atoms need to interact with each other before being released into free flight  13  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Controlled collisions of a single atom and ion guided by movable trapping potentials . Abstract : We report on the regulated collision between an individual captured molecule and a singly charged particle in a Paul trap , where both particles are localized to different regions of space separated by many micrometers .The ions can be moved along the axis linking them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber . We suggest that this enables us to affect the relative velocity at which they collide as also as their impact parameter .This opens up new possibilities for studying basic processes such as elastic scattering or charge transfer reactions . In addition we show how it is easy to use these mechanisms to make entanglement between two neutral ions via a quantum gate action mediated by one common ion .Quantum electronic processing requires scalable systems relying on numerous qubits 1 . One promising path towards developing such machines depends on neutral compounds contained in laser lattices 2 , but suffers from reduced coherence times due to spontaneous emission 3 .An alternative approach requires storing atomic qubits in ensembles of trapped ions 4 . However , here too there remain considerable restrictions arose from decoherence caused by heating 5 .In try to overcome these problems , hybrid approaches have been proposed 6 combining characteristics of both schemes 7 , 8 . Here , the storage of quantum states takes place in a small number of highly coherent electrons while small numbers of neutral particles serve as flying qubits 9 .A crucial requirement for employing such schemes is the ability to conduct high - fidelity operations involving both types of qubit 10 . For instance , it has recently been shown experimentally 11 that it is possible to entangle two neutral ions via a shared ion 12 .To achieve this goal , however , the atoms need to interact with each other before being transferred into free flight 13 .",
        "rewrite_text": "**Title:** Controlled Collisions of a Single Atom and Ion Guided by Movable Trapping Potentials\n\n**Abstract:** In this study, we present a novel approach to orchestrating controlled collisions between a single trapped atom and a singly charged ion within a Paul trap. The two particles are initially confined to distinct spatial regions, separated by several micrometers. By utilizing electrostatic fields generated by external electrodes, we can manipulate the position of the ions along the axis connecting them to the atoms. This capability allows us to finely tune both the relative velocity of their collisions and their impact parameters. Such control paves the way for in-depth investigations into fundamental processes, including elastic scattering and charge transfer reactions.\n\nMoreover, we demonstrate the feasibility of leveraging these controlled interactions to facilitate entanglement between two neutral ions through a quantum gate operation mediated by a shared ion. The advancement of quantum electronic processing hinges on the development of scalable systems that incorporate numerous qubits. One promising avenue involves the use of neutral atoms confined in optical lattices; however, this approach is often hindered by limited coherence times due to spontaneous emission. Alternatively, storing atomic qubits within ensembles of trapped ions presents another viable strategy, yet it too faces significant challenges from decoherence induced by thermal fluctuations.\n\nTo address these limitations, hybrid methodologies have been proposed, which integrate the advantages of both neutral atoms and trapped ions. In this framework, quantum states are preserved in a small number of highly coherent ions, while a limited number of neutral particles act as mobile qubits. A critical aspect of implementing such hybrid systems is the execution of high-fidelity operations involving both qubit types. Recent experimental findings have confirmed the possibility of entangling two neutral ions via a common ion, underscoring the necessity for prior interaction between the atoms before they transition into free flight. This research opens new avenues for exploring quantum interactions and enhancing the capabilities of quantum information processing systems.",
        "ori-fast-z-score": 1.182165609358651,
        "water-fast-z-score": 8.590403428006198,
        "rewrite-fast-z-score": 1.2570787221094177
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Slave boson theory of the extended Falicov-Kimball model .\nAbstract:\nWe study the slave-boson mean-field theory for the extended Falicov--Kimball model in two dimensions, which is known to exhibit an interesting phase diagram with various ordered phases and quantum critical points. We show that the ground state energy per site can be expressed as a function of the order parameters by using the saddle-point method. The resulting self-consistent equations are solved numerically on finite clusters up to 16 sites. It turns out that there exist three different solutions depending on the electron filling fraction n = N/Nc (N: number of electrons; Nc: number of lattice sites). One solution corresponds to the metallic phase where both charge density wave and spin density wave orders vanish. Another one describes the insulating phase characterized by nonvanishing CDW or SDW orders. Finally we find another solution corresponding to the coexistence region between these two phases. In this case, the system exhibits either commensurate or incommensurate charge-density waves accompanied by spiral magnetic ordering.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Slave boson theory of the extended Falicov - Kimball model . Abstract : We research the slave - boson mean - field model for the extended Falicov - - Kimball model in two dimensions , which is known to exhibit an interesting phase diagram with various ordered phases and quantum fundamental points .We see that the ground state energy per site can be written as a function of the order variables by using the saddle - point technique . The resulting self - consistent equations are solution numerically on finite clusters up to 16 sites .It happens out that there exist three different solutions depending on the electron filling fraction n = N / Nc ( N : number of atoms ; Nc : number of lattice sites ) . One solution corresponds to the metallic phase where both charge density wave and spin density wave orders vanish .Another one states the insulating phase described by nonvanishing CDW or SDW orders . Finally we find another solution corresponding to the coexistence area between these two phases .In this instance , the system displays either commensurate or incommensurate charge - density waves accompanied by spiral magnetic ordering .",
        "rewrite_text": "In this study, we investigate the slave-boson mean-field approach applied to the extended Falicov-Kimball model in two dimensions, a system recognized for its rich phase diagram featuring various ordered phases and critical quantum points. Our analysis reveals that the ground state energy per site can be expressed as a function of the order parameters through the application of the saddle-point method. We numerically solve the resulting self-consistent equations on finite clusters, with sizes reaching up to 16 sites. Our findings indicate the existence of three distinct solutions that depend on the electron filling fraction, defined as \\( n = N / N_c \\) (where \\( N \\) represents the number of atoms and \\( N_c \\) denotes the number of lattice sites). \n\nThe first solution corresponds to a metallic phase characterized by the absence of both charge density wave (CDW) and spin density wave (SDW) orders. The second solution describes an insulating phase, where either CDW or SDW orders are present and non-zero. The third solution emerges in the coexistence region between these two phases, where the system exhibits either commensurate or incommensurate charge density waves, accompanied by spiral magnetic ordering. This coexistence phase highlights the complex interplay between charge and spin fluctuations in the system, providing insights into the underlying mechanisms that govern the transitions between metallic and insulating states. Our results contribute to a deeper understanding of the extended Falicov-Kimball model and its implications for condensed matter physics, particularly in the context of correlated electron systems.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.3362306249131963,
        "rewrite-fast-z-score": 0.35355339059327373
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Evaluating Personal Archiving Strategies for Internet-based Information .\nAbstract:\nThe authors present an evaluation framework to assess personal archiving strategies in the context of internet-based information, and apply it to two case studies. The first is based on a survey conducted among researchers at the University of Southampton; the second focuses on the activities of one individual researcher who has been collecting data about his research field over several years. Both cases are used to illustrate how different types of archives can be evaluated using this approach. This article was published as part of the Proceedings of the 1st International Conference on Digital Preservation (ICDP-1), held September 24-27, 2002 in New York City. It may be freely reproduced by anyone wishing to do so provided that proper credit is given to the author(s) and citation details are included. Copyright permission requests should be addressed to: RightsLink@copyright.gov. The authors present an evaluation framework which they use to assess personal archiving initiatives in the context of internet- based information. They then apply their method to two case studies - one focusing on a group of researchers at the University of Southamptonshire, UK, and another concentrating on the activities of one particular individual researcher.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Evaluating Personal Archiving Strategies for Internet - based Information . Abstract : The authors present an assessment framework to examine personal archiving strategies in the context of internet - based information , and use it to two case studies .The first is based on a survey conducted among researchers at the University of Southampton ; the second focuses on the actions of one individual scientist who has been collecting data about his academic field over several decades . Both cases are using to illustrate how various types of archives can be evaluated using this methodology .This section was publication as part of the Proceedings of the 1st International Conference on Digital Preservation ( ICDP - 1 ) , holding September 24 - 27 , 2002 in New York City . It might be freely copied by anyone wishing to do so provided that proper credit is given to the writer ( s ) and citation notes are provided .Copyright consent demands should be addressed to : RightsLink @ copyright . gov . The authors present an assessment framework which they use to examine personal archiving strategies in the context of internet - based information .They then use their method to two case studies - one focusing on a group of studies at the University of Southamptonshire , UK , and another concentrating on the actions of one particular individual scholar .",
        "rewrite_text": "The authors introduce a comprehensive assessment framework designed to evaluate personal archiving strategies specifically within the realm of internet-based information. This framework is applied to two distinct case studies that illustrate its effectiveness. The first case study involves a survey conducted among researchers at the University of Southampton, providing insights into the archiving practices and preferences of academic professionals in a digital context. The second case study delves into the archival activities of a single scientist who has meticulously gathered data related to his academic discipline over several decades. Through these case studies, the authors demonstrate how their methodology can be utilized to assess various types of archives, highlighting the nuances and challenges associated with personal information management in the digital age. This research was presented at the 1st International Conference on Digital Preservation (ICDP-1), held from September 24 to 27, 2002, in New York City. The findings and methodologies discussed in this paper are available for public dissemination, provided that appropriate credit is given to the authors and proper citation is included. For any copyright-related inquiries, interested parties are directed to contact RightsLink at copyright.gov. Overall, this work contributes to the understanding of personal archiving strategies and offers a structured approach for evaluating how individuals manage and preserve internet-based information.",
        "ori-fast-z-score": 0.8340576562282991,
        "water-fast-z-score": 7.77713771047819,
        "rewrite-fast-z-score": 1.7650452162436565
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Fuzzballs with internal excitations .\nAbstract:\nWe propose that the fuzzball proposal for black holes can be extended to include internal degrees of freedom, which are excited by infalling matter and produce Hawking radiation.  We show how this idea fits into the framework of string theory in AdS/CFT correspondence. The proposed model is based on an extension of the work done by Horowitz and Maldacena (HM) who showed that the entropy of extremal Kerr-Newman black hole agrees exactly with the microscopic counting of states in N=4 super Yang-Mills gauge theory at strong coupling. In our case we consider non-extremal black holes whose entropy also matches with the number of microstates in strongly coupled field theories but now including internal degrees of freedom. This leads us to conclude that the emission spectrum of these black holes should agree with the one predicted by Hawking s original calculation. Finally, we discuss some open questions related to this new picture of black holes as well as possible experimental tests.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Fuzzballs with internal excitations . Abstract : We suggest that the fuzzball idea for black holes can be extended to consider inner degrees of liberty , which are excited by infalling matter and produce Hawking radiation .We see how this idea fits into the framework of string theory in AdS / CFT relationship . The proposed theory is based on an extension of the paper done by Horowitz and Maldacena ( HM ) who demonstrated that the entropy of extremal Kerr - Newman white hole agrees exactly with the microscopic counting of states in N = 4 super Yang - Mills gauge theory at weak interaction .In our case we study non - extremal black holes whose entropy also matches with the proportion of microstates in strongly coupled field theories but now including internal degrees of liberty . This leads us to observe that the emission spectrum of these black holes should comply with the one expected by Hawking s original calculation .Finally , we explain some open questions related to this new picture of black holes as well as possible experimental tests .",
        "rewrite_text": "In this article, we propose an extension of the fuzzball concept in the context of black holes by incorporating internal degrees of freedom that become excited due to the influence of infalling matter, ultimately leading to the generation of Hawking radiation. This framework aligns with the principles of string theory, particularly within the AdS/CFT correspondence. Our theory builds upon the foundational work of Horowitz and Maldacena (HM), who established that the entropy of extremal Kerr-Newman white holes corresponds precisely with the microscopic state counting in N = 4 super Yang-Mills gauge theory under weak coupling conditions. In our investigation, we focus on non-extremal black holes, demonstrating that their entropy also correlates with the number of microstates in strongly coupled field theories, while now accounting for internal degrees of freedom. This consideration allows us to predict that the emission spectrum of these black holes will conform to the expectations set forth by Hawking's original calculations. Additionally, we address several unresolved questions that arise from this novel perspective on black holes and discuss potential experimental approaches to test our hypotheses. Through this work, we aim to deepen the understanding of black hole thermodynamics and the intricate relationship between gravity and quantum mechanics, paving the way for future research in this compelling area of theoretical physics.",
        "ori-fast-z-score": -0.21566554640687682,
        "water-fast-z-score": 3.9668163788998405,
        "rewrite-fast-z-score": 0.29559878344928797
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The power of quantum systems on a line .\nAbstract:\nWe study the dynamics of open quantum systems in one dimension, focusing on their ability to generate entanglement between distant sites and how this is affected by decoherence.  We consider two different models for the system-environment interaction: (i) an environment that couples locally with each site; and (ii) an environment that couples globally with all sites simultaneously. In both cases we find that there are regimes where the system can be driven into highly entangled states even when it starts out unentangled or only weakly entangled. This occurs because the environment acts as a source of noise which drives the system towards its ground state. The effect of local coupling is more pronounced than global coupling since the former allows for faster relaxation timescales. Finally, we show that these results hold true also if the initial state has some degree of spatial correlations. Quantum information processing requires the manipulation of quantum states over large distances. However, due to inevitable interactions with the surrounding environment, such operations cannot be performed perfectly. Here we investigate whether certain types of environments may actually enhance the performance of quantum devices.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The power of quantum systems on a line . Abstract : We research the dynamics of open quantum systems in one dimension , concentrating on their power to produce entanglement between distant areas and how this is affected by decoherence .We consider two different models for the system - landscape interaction : ( i ) an environment that pairs locally with each site ; and ( ii ) an environment that pairs internationally with all locations simultaneously . In both cases we find that there are regimes where the system can be pushed into extremely entangled states especially when it comes out unentangled or only strongly entangled .This occurs because the surroundings serves as a source of noise which moves the system towards its ground state . The impact of local coupling is more pronounced than worldwide coupling since the former provides for quicker relaxation timescales .Finally , we prove that these results hold true also if the first state has some degree of spatial correlations . Quantum knowledge processing requires the processing of quantum states over large distances .However , owing to inevitable relationships with the nearby landscape , such operations cannot be performed properly . Here we investigate whether particular kinds of contexts may really increase the performance of quantum devices .",
        "rewrite_text": "**Title:** The Power of Quantum Systems on a Line\n\n**Abstract:** In this study, we explore the dynamics of open quantum systems constrained to one-dimensional configurations, with a particular focus on their capacity to generate entanglement between spatially separated regions and the influence of decoherence on this process. We analyze two distinct models of system-environment interaction: (i) a local environment that interacts with each site individually, and (ii) a global environment that couples with all sites simultaneously. Our findings reveal that there exist specific regimes in which the quantum system can achieve highly entangled states, particularly when starting from a state that is either unentangled or only weakly entangled. This phenomenon is attributed to the role of the environment as a source of noise, which facilitates the system's transition toward its ground state. Notably, we observe that local coupling has a more significant impact on the entanglement dynamics compared to global coupling, as the former leads to faster relaxation timescales. Furthermore, we demonstrate that our results remain valid even when the initial state exhibits some degree of spatial correlations. The ability to process quantum information over large distances is crucial for quantum information technologies; however, the unavoidable interactions with the surrounding environment often hinder the effectiveness of such operations. In this context, we investigate whether specific types of environmental configurations can enhance the performance of quantum devices, potentially offering pathways to mitigate the adverse effects of decoherence and improve quantum state manipulation across extended distances. Our research contributes to a deeper understanding of the interplay between quantum systems and their environments, with implications for the development of robust quantum technologies.",
        "ori-fast-z-score": -0.8783100656536799,
        "water-fast-z-score": 6.477134476605945,
        "rewrite-fast-z-score": 0.3508232077228117
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The born again (VLTP) scenario revisited: The mass of the remnants and implications for V4334 Sgr .\nAbstract:\nWe present new near-infrared spectroscopy of the evolved star V4332 Sgr, which is believed to be in an advanced stage of its final red giant phase. We find that it has developed a strong infrared excess due to dust formation at temperatures between 1000-2000 K. This suggests that the object may have undergone a recent episode of enhanced mass loss on a time scale of years or decades prior to our observations. In addition we detect emission lines of hydrogen and helium indicating ongoing mass loss. These results are consistent with previous suggestions that this object underwent a late thermal pulse (LTP), i.e., a rapid increase in luminosity followed by a period of high mass loss. If so, then the LTP would have occurred within the last few hundred thousand years. Based on these findings we propose a revised evolutionary model for V4332 Sgr including a VLTP event as well as a subsequent superwind phase.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The born again ( VLTP ) scenario revisited : The mass of the remnants and implications for V4334 Sgr . Abstract : We report new near - infrared spectroscopy of the evolved star V4332 Sgr , which is suspected to be in an accelerated phase of its final red dwarf phase .We see that it has acquired a powerful infrared excess due to dust development at temperatures between 1000 - 2000 K . This implies that the object may have undergone a recent episode of enhanced mass loss on a time scale of years or months previously to our observations . In addition we find absorption tracks of carbon and helium representing continuing mass loss .These conclusions are compatible with previous suggestions that this body experienced a late heat pulse ( LTP ) , i . e . , a rapid increase in luminosity followed by a period of high mass loss . If so , then the LTP may have happened within the last few hundred thousand years .Based on these conclusions we propose a revised evolutionary model for V4332 Sgr including a VLTP event as also as a subsequent superwind phase .",
        "rewrite_text": "Title: Revisiting the Born Again (VLTP) Scenario: Mass of the Remnants and Implications for V4334 Sgr\n\nAbstract: In this study, we present new near-infrared spectroscopic observations of the evolved star V4332 Sgr, which is believed to be undergoing an accelerated transition into its final red dwarf phase. Our findings reveal a significant infrared excess attributed to the formation of dust at temperatures ranging from 1000 to 2000 K. This observation suggests that V4332 Sgr may have experienced a recent surge in mass loss, occurring over a time frame of mere months or years prior to our measurements. Furthermore, we identify absorption features indicative of ongoing mass loss, specifically tracks of carbon and helium. These results align with earlier hypotheses proposing that V4332 Sgr has undergone a late thermal pulse (LTP), characterized by a rapid increase in luminosity followed by a substantial mass loss phase. If this hypothesis holds true, the LTP likely occurred within the last few hundred thousand years. Building on these insights, we propose an updated evolutionary model for V4332 Sgr that incorporates a VLTP event, followed by a subsequent superwind phase. This revised model aims to enhance our understanding of the evolutionary processes at play in V4332 Sgr and similar evolved stars, shedding light on the mechanisms driving their transformation and the implications for their remnants. Our research contributes to the broader discourse on stellar evolution, particularly in the context of late-stage stellar phenomena and the lifecycle of red dwarf stars.",
        "ori-fast-z-score": 0.42640143271122083,
        "water-fast-z-score": 6.253987492037524,
        "rewrite-fast-z-score": 3.156820749009882
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A sufficient condition for Gaussian departure in turbulence .\nAbstract:\nWe present an analysis of the statistical properties of turbulent flows that are driven by random forcing and decaying viscosity, with particular emphasis on their departures from Gaussianity. We show how these statistics can be computed using a recently developed method based on stochastic averaging over realizations of the flow field. The results obtained demonstrate that this approach is capable of capturing both non-Gaussian tails as well as intermittency effects associated with small-scale structures. In addition to providing new insights into the nature of turbulence, our findings also have important implications for the development of efficient numerical algorithms aimed at solving fluid dynamics problems. Turbulence plays a crucial role in many physical phenomena ranging from geophysical flows  1  , atmospheric convection  2  , oceanic currents  3  , plasma physics  4  , combustion  5  , and even stock market fluctuations  6  . Despite its ubiquity, however, there remains no universally accepted theory describing the underlying mechanisms responsible for the observed phenomenology  7, 8  .\nIn recent years, significant progress has been made towards understanding the statistical properties of turbulences through direct numerical simulations (DNS)  9  . These studies have shown that the probability density functions (PDFs) of velocity differences exhibit heavy-tailed distributions  10  which cannot be described within the framework of classical statistical mechanics  11  . Moreover, it was found that PDFs of higher-order moments such as energy dissipation rates  12  or enstrophy  13  display power-law scaling behavior near their peaks indicating strong intermittency  14  . This phenomenon manifests itself in the form of bursty events where large values of certain quantities occur simultaneously  15  . It should be noted, however, that DNS-based approaches suffer from severe limitations due to high computational costs involved  16  . As a result, they are typically restricted to relatively low Reynolds numbers  17  making them inapplicable to real-world applications  18  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A sufficient condition for Gaussian departure in turbulence . Abstract : We present an assessment of the empirical features of turbulent streams that are driven by random forcing and decaying viscosity , with particular emphasis on their departures from Gaussianity .We see how these statistics can be computed using a recently advanced method based on stochastic averaging over realizations of the flow field . The results collected demonstrate that this methodology is capable of capturing both non - Gaussian tails as well as intermittency effects involved with small - scale structures .In addition to offering fresh insights into the nature of turbulence , our findings also have important implications for the development of effective numerical algorithms intended at solving fluid dynamics cases . Turbulence plays a crucial role in many natural phenomena ranging from geophysical flows 1 , atmospheric circulation 2 , oceanic currents 3 , plasma physics 4 , combustion 5 , and sometimes stock price fluctuations 6 .Despite its ubiquity , however , there exists no universally recognized hypothesis explaining the fundamental pathways responsible for the reported phenomenology 7 , 8 . In recent months , substantial advances has been achieved towards studying the empirical behavior of turbulences through direct numerical simulations ( DNS ) 9 .These studies have shown that the probability density functions ( PDFs ) of velocity differences display heavy - tailed parameters 10 which cannot be described within the framework of classical statistical mechanics 11 . Moreover , it was shown that PDFs of greater - order moments such as energy dissipation levels 12 or enstrophy 13 show power - law scaling behavior near their mountains indicating strong intermittency 14 .This phenomenon manifests itself in the form of bursty events where many values of certain quantities occur simultaneously 15 . It should be mentioned , however , that DNS - based methods suffer from severe constraints due to large computational costs involved 16 .As a result , they are typically restricted to rather low Reynolds numbers 17 making them inapplicable to real - time users 18 .",
        "rewrite_text": "In this article, we explore the empirical characteristics of turbulent flows influenced by random forcing and decaying viscosity, with a specific focus on their deviations from Gaussian behavior. Utilizing a novel approach based on stochastic averaging across various realizations of the flow field, we demonstrate how this method effectively captures non-Gaussian tails and the intermittency associated with small-scale structures. Our findings not only enhance the understanding of turbulence but also hold significant implications for the advancement of numerical algorithms designed to tackle fluid dynamics problems.\n\nTurbulence is a fundamental aspect of numerous natural phenomena, including geophysical flows, atmospheric circulation, ocean currents, plasma physics, combustion, and even fluctuations in stock prices. Despite its prevalence, a universally accepted theory explaining the underlying mechanisms of turbulence remains elusive. Recent progress in the field has been made through direct numerical simulations (DNS), which have revealed that the probability density functions (PDFs) of velocity differences exhibit heavy-tailed characteristics that defy classical statistical mechanics. Additionally, higher-order moments, such as energy dissipation and enstrophy, display power-law scaling behavior, indicative of strong intermittency. This intermittency is characterized by sporadic bursts of activity where multiple values of certain quantities occur simultaneously.\n\nHowever, it is important to note that DNS methods are often limited by significant computational demands, which restrict their application to relatively low Reynolds numbers. This limitation renders them impractical for real-time applications. Our research addresses these challenges by providing a sufficient condition for Gaussian departure in turbulence, thereby contributing to a deeper understanding of turbulent dynamics and paving the way for more efficient computational techniques in fluid dynamics.",
        "ori-fast-z-score": -1.0182385849843445,
        "water-fast-z-score": 7.027819284987273,
        "rewrite-fast-z-score": -0.16783627165933782
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Improved constraints on dark energy from Chandra X-ray observations of the largest relaxed galaxy clusters .\nAbstract:\nWe present new measurements of the Hubble constant and the equation-of-state parameter w0 using Chandra X-ray Observatory data for the most massive, dynamically relaxed galaxy clusters in the Universe. We use these results to place improved limits on the properties of dark energy. The sample consists of eight galaxy clusters with redshifts between 0.3 and 1.2 that were observed by Chandra as part of our ongoing program to study the evolution of cluster scaling relations out to high redshift. Using hydrostatic equilibrium models we measure the gas mass fraction within r500 (the radius at which the mean density is 500 times the critical density) for each system. These values are combined with independent estimates of the total gravitating mass obtained through weak lensing analysis performed by other groups. This yields an average value of H0 = 70 +/- 6 km s-1 Mpc-1 assuming flat priors on both parameters. If instead we assume Gaussian priors based on previous determinations of the Hubble constant and baryon content of the universe then this measurement becomes H0 = 68 +/-6 km s-1 Mpc-",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Improved limitations on dark energy from Chandra X - ray observations of the greatest relaxed galaxy regions . Abstract : We report new studies of the Hubble constant and the equation - of - state variable w0 using Chandra X - ray Observatory data for the most large , dynamically confined star clusters in the Universe .We use these results to place improved restrictions on the properties of dark energy . The sample consists of eight galaxy galaxies with redshifts between 0 . 3 and 1 . 2 that were detected by Chandra as part of our ongoing program to study the evolution of cluster scaling relations out to large redshift .Using hydrostatic equilibrium models we measure the gas mass fraction within r500 ( the radius at which the mean density is 500 times the critical density ) for each system . These values are coupled with independent estimates of the total gravitating mass obtained through soft lensing research performed by other organizations .This yields an estimated value of H0 = 70 + / - 6 kilometers s - 1 Mpc - 1 taking flat priors on both variables . If instead we expect Gaussian priors based on previous determinations of the Hubble constant and baryon concentration of the universe then this measurement becomes H0 = 68 + / - 6 kilometers s - 1 Mpc -",
        "rewrite_text": "We present a comprehensive analysis of the Hubble constant and the equation-of-state parameter \\( w_0 \\) utilizing data from the Chandra X-ray Observatory, focusing on some of the largest and most dynamically stable galaxy clusters in the universe. Our study aims to refine the constraints on dark energy properties by examining a sample of eight galaxy clusters with redshifts ranging from 0.3 to 1.2. These clusters were identified through our ongoing research into the evolution of cluster scaling relations at significant redshifts. \n\nBy applying hydrostatic equilibrium models, we calculate the gas mass fraction within \\( r_{500} \\) (the radius where the mean density is 500 times the critical density) for each cluster in our sample. These gas mass fraction measurements are then combined with independent estimates of the total gravitating mass derived from weak lensing studies conducted by other research groups. This integrated approach allows us to derive a new estimate of the Hubble constant, yielding \\( H_0 = 70 \\pm 6 \\) km/s/Mpc under the assumption of flat priors for both parameters. \n\nFurthermore, when we incorporate Gaussian priors informed by previous measurements of the Hubble constant and the baryonic density of the universe, our refined estimate adjusts to \\( H_0 = 68 \\pm 6 \\) km/s/Mpc. These findings contribute to a deeper understanding of dark energy and its implications for cosmology, providing tighter constraints that enhance our knowledge of the universe's expansion rate and the underlying physics governing cosmic evolution.",
        "ori-fast-z-score": 1.2510864843424487,
        "water-fast-z-score": 6.6010959760562775,
        "rewrite-fast-z-score": 0.8542421961772492
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  MCHIT - Monte Carlo model for proton and heavy-ion therapy .\nAbstract:\nThe MCHIT (Monte Carlo Heavy Ion Transport) code is an advanced tool to simulate the transport of ions in matter, including their interactions with target nuclei as well as elastic scattering off atomic electrons. The code has been developed at GSI Helmholtzzentrum für Schwerionenforschung GmbH since 1998 by several groups under the leadership of Prof. Dr. Jens B. Skarsgard. \n \n It was originally designed to study nuclear fragmentation reactions induced by relativistic heavy ions on light targets like carbon or water. In recent years it has also been used successfully to investigate other topics such as: \n \n \n \n • Radiation damage in biological tissues due to ion beam irradiation \n \n • Secondary particle production in hadronic showers \n \n • Energy deposition in materials exposed to high-energy cosmic rays \n \n • Nuclear reaction cross sections for astrophysical applications \n \n • Hadrontherapy treatment planning",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : MCHIT - Monte Carlo method for proton and large - ion treatment . Abstract : The MCHIT ( Monte Carlo Heavy Ion Transport ) code is an advanced technique to simulate the transport of atoms in matter , particularly their interactions with target nuclei as well as elastic scattering off atomic electrons .The code has been designed at GSI Helmholtzzentrum für Schwerionenforschung GmbH since 1998 by many groups under the leadership of Prof . Dr . Jens B . Skarsgard . It was originally intended to study nuclear fragmentation reactions generated by relativistic heavy ions on light targets like nitrogen or air .In past decades it has also been used successfully to examine other topics such as : • Radiation injury in biological tissues resulting to ion beam irradiation • Secondary particle production in hadronic showers • Energy deposition in structures exposed to large - energy cosmic rays • Nuclear reaction cross sections for astrophysical applications • Hadrontherapy treatment planning",
        "rewrite_text": "Title: MCHIT - Monte Carlo Method for Proton and Large-Ion Treatment\n\nAbstract: The MCHIT (Monte Carlo Heavy Ion Transport) code represents a sophisticated computational tool developed to model the behavior of atoms as they traverse matter, focusing on their interactions with target nuclei and elastic scattering with atomic electrons. Since its inception in 1998 at the GSI Helmholtzzentrum für Schwerionenforschung GmbH, the code has been collaboratively refined by various research groups under the guidance of Prof. Dr. Jens B. Skarsgard. Initially, MCHIT was designed to investigate nuclear fragmentation reactions resulting from the bombardment of light targets, such as nitrogen or air, by relativistic heavy ions. Over the years, its application has expanded significantly, demonstrating versatility in addressing a range of scientific inquiries. Notably, MCHIT has been employed to study radiation-induced injuries in biological tissues caused by ion beam irradiation, providing insights into the effects of high-energy particles on living organisms. Additionally, the code has facilitated the analysis of secondary particle production in hadronic showers, which is crucial for understanding cosmic ray interactions. MCHIT has also been instrumental in assessing energy deposition in structures subjected to high-energy cosmic rays, contributing to the field of radiation protection. Furthermore, it has been utilized to calculate nuclear reaction cross sections relevant to astrophysical phenomena, enhancing our comprehension of cosmic processes. Lastly, the code plays a vital role in hadrontherapy treatment planning, optimizing therapeutic strategies for cancer treatment through precise modeling of particle interactions. Overall, MCHIT serves as a pivotal resource in advancing research across multiple disciplines, including nuclear physics, radiation biology, and medical physics.",
        "ori-fast-z-score": -0.3511234415883917,
        "water-fast-z-score": 4.88240082724041,
        "rewrite-fast-z-score": 1.5666989036012806
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Using Image Attributes for Human Identification Protocols .\nAbstract:\nIn this work, we propose an approach to human identification based on the analysis of image attributes and their relationships with each other. We use a set of visual features that are extracted by applying state-of-the-art computer vision techniques over images in order to represent them as vectors of numerical values. These feature vectors can be used to train machine learning algorithms such as Support Vector Machines (SVMs) or Random Forests (RF). In addition, we also consider the relationship between these features using Graphical Models (GM), which allow us to learn how they interact with one another. The proposed method is evaluated against two different datasets containing face images captured under controlled conditions. Our results show that our system outperforms existing approaches when identifying individuals across multiple sessions. This research was supported by the National Science Foundation through awards IIS-1253153 and CNS-1527225. In this work, we propose a novel approach to identify humans based on the analysis of their facial appearance. To do so, we extract several visual features from faces using state-of-the-art computer vision methods. Then, we model the interactions among those features using graphical models. Finally, we evaluate the performance of our method against two publicly available databases.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Using Image Attributes for Human Identification Protocols . Abstract : In this project , we propose an way to human identification focusing on the evaluation of visual attributes and their connections with each other .We use a setting of visual elements that are derived by using state - of - the - art computer vision principles over images in order to depict them as matrices of numerical values . These feature vectors can be used to train machine computing methods such as Support Vector Machines ( SVMs ) or Random Forests ( RF ) .In addition , we also consider the relationship between these characteristics utilizing Graphical Models ( GM ) , which allow us to study how they interact with one another . The proposed approach is evaluated against two different datasets featuring face photos taken under controlled circumstances .Our results show that our system outperforms existing techniques when identifying persons across multiple meetings . This research was supported by the National Science Foundation through awards IIS - 1253153 and CNS - 1527225 .In this project , we attempt a new approach to identify humans relying on the examination of their facial shape . To do so , we extract many graphical features from faces utilizing state - of - the - art computer vision methods .Then , we study the interactions among those characteristics using visual models . Finally , we assess the performance of our technique against two publicly accessible data .",
        "rewrite_text": "**Title:** Utilizing Image Attributes for Human Identification Protocols\n\n**Abstract:** This study introduces a novel approach to human identification that emphasizes the analysis of visual attributes and their interrelationships. By employing advanced computer vision techniques, we transform images into matrices of numerical values, representing various visual elements. These feature vectors serve as the foundation for training machine learning algorithms, including Support Vector Machines (SVMs) and Random Forests (RF). Furthermore, we explore the connections between these attributes through Graphical Models (GM), which facilitate an understanding of their interactions. Our methodology is rigorously evaluated using two distinct datasets comprising facial images captured under controlled conditions. The findings demonstrate that our proposed system significantly outperforms existing identification methods, particularly in scenarios involving multiple encounters with the same individuals. This research, supported by the National Science Foundation under awards IIS-1253153 and CNS-1527225, aims to enhance human identification processes by focusing on the analysis of facial shapes. We extract a variety of graphical features from facial images using cutting-edge computer vision techniques and subsequently investigate the relationships among these features through visual models. The performance of our approach is thoroughly assessed against two publicly available datasets, showcasing its effectiveness in improving human identification accuracy.",
        "ori-fast-z-score": -1.7320508075688772,
        "water-fast-z-score": 6.417436110981714,
        "rewrite-fast-z-score": -1.0634101379502299
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Protostellar clusters in intermediate-mass (IM) star forming regions .\nAbstract:\nWe present the results of our Spitzer Space Telescope survey for protostars and young stellar objects (YSOs) in three nearby, intermediate mass star-forming regions: NGC 1333, Serpens South, and Perseus North. We identify over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and/or envelopes. The majority are Class I sources that have recently formed outflows or jets; however we also find several dozen more evolved Class II/III sources. In addition to these disk-bearing systems, we detect numerous isolated point-like sources whose SEDs suggest they are deeply embedded protostars. These observations provide new insights into how stars form in IM environments. Our sample includes many previously unidentified low-luminosity protostars which will be useful targets for future studies at higher angular resolution. This work is based on observations made with the Spitzer Space Telescope, which is operated by NASA under contract 1407. Support for this work was provided by NASA through an award issued by JPL/Caltech. \n \n Keywords: Protostar",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Protostellar complexes in intermediate - mass ( IM ) star producing regions . Abstract : We report the conclusion of our Spitzer Space Telescope survey for protostars and young stellar bodies ( YSOs ) in three adjacent , intermediate mass star - creating areas : NGC 1333 , Serpens South , and Perseus North .We recognize over 100 candidate YSOs with infrared excesses indicative of circumstellar disks and / or envelopes . The majority are Class I sources that have newly formed outflows or jets ; however we also find several dozen more evolved Class II / III sources .In addition to these disk - bearing components , we locate many isolated point - like sources whose SEDs suggest they are deeply embedded protostars . These measurements give novel knowledge into how stars shape in IM environments .Our specimen includes several recently unidentified low - luminosity protostars which will be valuable targets for future research at higher angular resolution . This research is based on observations made with the Spitzer Space Telescope , which is controlled by NASA under contract 1407 .Support for this project was provided by NASA through an award published by JPL / Caltech . Keywords : Protostar",
        "rewrite_text": "**Title:** Protostellar Complexes in Intermediate-Mass Star-Forming Regions\n\n**Abstract:** In this study, we present the findings from our comprehensive survey conducted with the Spitzer Space Telescope, focusing on protostars and young stellar objects (YSOs) within three closely situated intermediate-mass star-forming regions: NGC 1333, Serpens South, and Perseus North. Our investigation has led to the identification of over 100 candidate YSOs exhibiting infrared excesses, which are indicative of the presence of circumstellar disks and/or envelopes. The majority of these candidates are classified as Class I sources, characterized by their newly formed outflows or jets. Additionally, we have detected several dozen more evolved Class II and III sources, highlighting the diversity of stellar evolution within these regions.\n\nBeyond the disk-bearing YSOs, our survey has also uncovered numerous isolated point-like sources whose spectral energy distributions (SEDs) suggest they are deeply embedded protostars. These findings provide valuable insights into the processes of star formation in intermediate-mass environments. Notably, our sample includes several previously unidentified low-luminosity protostars, which present promising opportunities for future investigations utilizing higher angular resolution techniques.\n\nThis research is grounded in observations made with the Spitzer Space Telescope, operated by NASA under contract 1407. The project received support from NASA through an award administered by JPL/Caltech. Our results contribute to a deeper understanding of the mechanisms driving star formation in intermediate-mass regions and pave the way for further studies aimed at elucidating the complexities of stellar birth and evolution. \n\n**Keywords:** Protostar, Young Stellar Objects, Star Formation, Infrared Astronomy, Spitzer Space Telescope.",
        "ori-fast-z-score": -1.865992419824736,
        "water-fast-z-score": 4.880935300919764,
        "rewrite-fast-z-score": 1.7717591356565963
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Catalog of HI Clouds in the Large Magellanic Cloud .\nAbstract:\nWe present an all-sky survey for neutral hydrogen (HI) clouds associated with the Large Magellanic cloud (LMC). The LMC is known to have many small, isolated HI clouds that are not gravitationally bound and may be tidally stripped material or remnants of dwarf galaxies destroyed by tidal forces during close encounters between the Milky Way Galaxy and the LMC.  We use data obtained at Arecibo Observatory as part of the ALFALFA survey to search for new HI clouds near the LMC. In addition we combine our results with previous surveys conducted using Parkes telescope observations and single dish telescopes located on Mauna Kea, Hawaii. Our analysis reveals a total of 16 previously uncatalogued HI clouds within 10 degrees of the LMC center. These clouds range in size from 1 kpc to 15 kpc and contain up to 3 x 1012 M⊙ of HI gas.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Catalog of HI Clouds in the Large Magellanic Cloud . Abstract : We report an all - skies study for neutral hydrogen ( HI ) skies related with the Large Magellanic cloud ( LMC ) .The LMC is known to have many small , isolated HI clouds that are not gravitationally locked and may be tidally stripped matter or remnants of dwarf stars destroyed by tidal forces during close contacts between the Milky Way Galaxy and the LMC . We use data acquired at Arecibo Observatory as part of the ALFALFA survey to search for additional HI clouds near the LMC .In addition we merge our findings with previous analyses conducted using Parkes telescope measurements and multi dish telescopes located on Mauna Kea , Hawaii . Our study reveals a total of 16 formerly uncatalogued HI clouds within 10 degrees of the LMC center .These clouds range in height from 1 kpc to 15 kpc and comprise up to 3 x 1012 [UNK] of HI gas .",
        "rewrite_text": "We present a comprehensive study of neutral hydrogen (HI) clouds associated with the Large Magellanic Cloud (LMC) in this article. The LMC is characterized by numerous small, isolated HI clouds that are not bound by gravity, suggesting they may be remnants of tidal interactions or stripped material from dwarf galaxies that have been disrupted during close encounters with the Milky Way Galaxy. Utilizing data from the Arecibo Observatory, collected as part of the ALFALFA survey, we conducted an extensive search for additional HI clouds in proximity to the LMC. Our investigation also incorporates previous research that utilized measurements from the Parkes telescope and various multi-dish telescopes located on Mauna Kea, Hawaii. Through this integrated approach, we identified a total of 16 previously uncatalogued HI clouds within a 10-degree radius of the LMC's center. These newly discovered clouds exhibit a range of altitudes from 1 kiloparsec (kpc) to 15 kpc and collectively contain up to 3 x 10^12 solar masses of HI gas. This catalog of HI clouds enhances our understanding of the LMC's environment and its interactions with the Milky Way, providing valuable insights into the dynamics of galactic structures and the processes that govern the formation and evolution of HI clouds in the context of tidal interactions. Our findings contribute to the broader field of astrophysics by shedding light on the complexities of galactic interactions and the role of neutral hydrogen in the universe.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.764608329895903,
        "rewrite-fast-z-score": 2.1322269467806003
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nonequilibrium entropy limiters in lattice Boltzmann methods .\nAbstract:\nWe present an approach to nonequilibrium entropy production in the lattice Boltzmann (LB) method by introducing entropy limiters into the collision operator. The proposed scheme is shown to be able to reproduce the correct equilibrium distribution and recover the second law of thermodynamics for both single-phase flows with constant density and temperature, as well as multiphase flows with phase change. We also demonstrate that our new LB model can accurately capture shock waves without spurious oscillations or numerical instabilities. \n \n Keywords: Nonequilibrium entropy, Lattice Boltzmann Method, Entropy limiter, Second Law of Thermodynamics, Shock wave. 1 Introduction \n \n In recent years, there has been growing interest in developing computational fluid dynamics methods based on kinetic theory  1–3  . Compared with conventional Navier-Stokes solvers, these approaches are more accurate at capturing complex flow phenomena such as shocks  4  , turbulence  5  , and interfacial flows  6  . Among them, the lattice Boltzmann method  7, 8  has attracted much attention due to its simplicity and efficiency  9  . \n \n However, it should be noted that most existing LB models do not satisfy the second law of thermodynamic  10  . This problem becomes particularly severe when dealing with high Mach number flows  11  . To overcome this difficulty, several attempts have been made recently  12–18  . For example, Chen et al.  12  introduced a modified BGK-type collision term which recovers the correct equilibrium state while satisfying the second law of thermodynamical. Similarly, Yu et al.  13  developed another type of entropy-consistent LB schemes using the concept of entropic moments. More recently, Shan et al.  14  presented a novel LB model where the relaxation time was determined according to the local Knudsen number. Although these works provide promising results, they all require additional information about the macroscopic variables, e.g., pressure and velocity fields. As a result, their applications may be limited to simple cases involving only one component gas. \n \n In contrast, we propose here a general framework for constructing entropy-consistent LB models. Our strategy relies on adding",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nonequilibrium entropy limiters in lattice Boltzmann techniques . Abstract : We present an approach to nonequilibrium entropy production in the lattice Boltzmann ( LB ) method by using entropy limiters into the collision operator .The proposed system is demonstrated to be possible to reproduce the correct equilibrium distribution and recover the second law of thermodynamics for both single - phase streams with constant density and heat , as well as multiphase streams with phase change . We additionally prove that our new LB model can accurately capture shock waves without spurious oscillations or numerical instabilities .Keywords : Nonequilibrium entropy , Lattice Boltzmann Method , Entropy limiter , Second Law of Thermodynamics , Shock wave . 1 Introduction In recent seasons , there has been growing interest in establishing computational liquid mechanics algorithms based on kinetic theory 1 – 3 .Compared with typical Navier - Stokes solvers , these method are more accurate at representing complex flow effects such as shocks 4 , turbulence 5 , and interfacial flows 6 . Among them , the lattice Boltzmann technique 7 , 8 has garnered great controversy due to its accuracy and efficiency 9 .However , it should be mentioned that most existing LB models do not satisfy the second law of thermodynamic 10 . This problem appears particularly severe when dealing with high Mach number flows 11 .To solve this challenge , various efforts have been attempted recently 12 – 18 . For instance , Chen et al .12 introduced a revised BGK - class collision term which recovers the correct equilibrium state while fulfilling the second law of thermodynamical . Similarly , Yu et al .13 introduced another type of entropy - consistent LB schemes using the idea of entropic moments . More recently , Shan et al .14 provided a new LB model where the relaxation time was decided according to the local Knudsen number . Although these works provide encouraging conclusions , they all need extra data about the macroscopic parameters , e . g . , pressure and speed fields .As a result , their applications might be restricted to small cases concerning only one element gas . In comparison , we require here a general template for constructing entropy - consistent LB models .Our strategy relies on adding",
        "rewrite_text": "We introduce a novel approach to nonequilibrium entropy production within the lattice Boltzmann (LB) method by integrating entropy limiters into the collision operator. This innovative framework is capable of accurately reproducing the correct equilibrium distribution and adhering to the second law of thermodynamics across various scenarios, including single-phase flows with constant density and heat, as well as multiphase flows involving phase changes. Furthermore, our enhanced LB model demonstrates a remarkable ability to capture shock waves without introducing spurious oscillations or numerical instabilities, which are common challenges in computational fluid dynamics.\n\nThe growing interest in computational fluid mechanics based on kinetic theory has led to the development of algorithms that outperform traditional Navier-Stokes solvers, particularly in accurately modeling complex flow phenomena such as shocks, turbulence, and interfacial dynamics. The lattice Boltzmann method has emerged as a prominent technique due to its balance of accuracy and computational efficiency. However, a significant limitation of many existing LB models is their failure to comply with the second law of thermodynamics, a concern that becomes particularly pronounced in high Mach number flows.\n\nRecent efforts to address this issue have included the introduction of revised collision terms that ensure the recovery of the correct equilibrium state while satisfying thermodynamic principles. For instance, Chen et al. proposed a modified BGK-class collision term, while Yu et al. developed entropy-consistent LB schemes based on entropic moments. Shan et al. also contributed a model that adjusts the relaxation time according to the local Knudsen number. Despite these advancements, many of these approaches require additional information about macroscopic parameters, such as pressure and velocity fields, which can limit their applicability to simpler cases involving single-component gases.\n\nIn contrast, our approach aims to establish a more general framework for constructing entropy-consistent LB models, thereby enhancing the versatility and robustness of the lattice Boltzmann method in simulating a wider range of fluid dynamics scenarios.",
        "ori-fast-z-score": -2.0179913668364655,
        "water-fast-z-score": 6.577497476540163,
        "rewrite-fast-z-score": -0.7808688094430304
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:   Illusion of control  in Minority and Parrondo Games .\nAbstract:\nWe study the effect of  illusion of control  on minority games with different number of players, as well as on Parrondo s paradoxical games. We show that for all these cases there is an optimal value of illusion of control which maximizes the performance of the system. The results are obtained by using numerical simulations based on Monte Carlo method. In particular we find that the optimal values of illusion of control depend strongly on the number of players involved in each game. \nI. INTRODUCTIO N\n\nA. Illusion of Control (IC)\nThe term  illusion of control  was first introduced by Langer  1  . It refers to situations where people tend to overestimate their ability to influence events or outcomes  2  , even when they have no real control  3  .\nIn recent years this concept has been applied to many fields such as: gambling  4  , stock markets  5  , sports  6  , health  7  , education  8  etc., showing its importance in human behavior  9  -  11  .\nB. Minority Game (MG) MGs were proposed by Challet and Zhang  12  as models of financial markets. They consist of agents who make decisions according to some strategy at discrete time steps. At every step one agent makes a decision among two options, called spin-up and spindown. If more than half of the agents choose the same option then it wins; otherwise it loses. Agents can change their strategies during the course of play  13  . There exist several variants of MGs: single-agent  14  , multi-agent  15  , continuous-time  16  , quantum  17  , evolutionary  18  , co-evolutionary  19  , spatially extended  20  , and others  21  -  23  .\nC. Parrondo s Paradoxical Games (PPGs)\nParrondo s paradoxical games  24  are simple two-player games played between a player A and B  25  . Each player plays against his opponent with a certain probability p i = 1 − q i , where 0 < p i , q i ≤ 1  26  . When both players use the same strategy s i ∈ {−1, 1}, the expected return per round is zero  27  . However if",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Illusion of control in Minority and Parrondo Games . Abstract : We research the impact of impression of control on minority games with varying amount of participants , as also as on Parrondo s paradoxical games .We see that for all these cases there is an appropriate value of illusion of management which maximizes the performance of the process . The results are derived by using numerical simulations based on Monte Carlo method .In particular we find that the ideal values of illusion of control vary strongly on the quantity of participants concerned in each game . I . INTRODUCTIO N A .Illusion of Control ( IC ) The term illusion of control was first popularized by Langer 1 . It refers to situations where persons tend to overestimate their power to affect events or outcomes 2 , even when they have no real control 3 .In past decades this concept has been used to many fields such as : gambling 4 , stock markets 5 , athletics 6 , fitness 7 , education 8 etc . , showing its significance in human behavior 9 - 11 . B .Minority Game ( MG ) MGs were introduced by Challet and Zhang 12 as models of financial markets . They consist of agents who make choices according to some strategy at discrete time steps .At every phase one agent makes a decision among two choices , called spin - up and spindown . If more than half of the agents take the same option then it wins ; otherwise it loses .Agents can shift their strategies during the course of play 13 . There include several variants of MGs : single - agent 14 , multi - agent 15 , continuous - time 16 , quantum 17 , evolutionary 18 , co - evolutionary 19 , spatially extended 20 , and others 21 - 23 .C . Parrondo s Paradoxical Games ( PPGs ) Parrondo s paradoxical games 24 are simple two - player games played between a team A and B 25 . Each person plays against his opponent with a certain likelihood q i = 1 − p i , where 0 < p i , q i ≤ 1 26 .When both players use the same strategy s i ∈ { −1 , 1 } , the expected return per round is zero 27 . However if",
        "rewrite_text": "**Title: The Illusion of Control in Minority and Parrondo Games**\n\n**Abstract:** This study investigates the influence of the illusion of control (IC) on minority games (MGs) and Parrondo's paradoxical games (PPGs), focusing on how varying participant numbers affect game outcomes. Our findings reveal that there exists an optimal level of perceived control that enhances performance across different game scenarios. Utilizing Monte Carlo simulations, we analyze the dynamics of these games and determine that the ideal illusion of control significantly fluctuates based on the number of participants involved. \n\nThe concept of the illusion of control, initially introduced by Langer, describes the tendency of individuals to overestimate their ability to influence outcomes, even in situations where they have no actual control. This phenomenon has been observed across various domains, including gambling, financial markets, sports, and education, highlighting its relevance in understanding human behavior.\n\nMinority games, developed by Challet and Zhang, serve as models for financial market interactions, where agents make strategic choices at discrete time intervals. In these games, agents select between two options—spin-up or spin-down—leading to a win for the majority or a loss for the minority. The flexibility for agents to adapt their strategies throughout the game adds complexity, with numerous variants existing, such as single-agent, multi-agent, and evolutionary models.\n\nParrondo's paradoxical games involve two players, A and B, who compete against each other with defined probabilities. Interestingly, when both players adopt the same strategy, the expected outcome is neutral; however, when they employ different strategies, the dynamics shift, leading to unexpected advantages. \n\nOverall, our research underscores the critical role of the illusion of control in shaping decision-making processes in both minority and Parrondo games, suggesting that understanding this psychological phenomenon can enhance strategic performance in competitive environments.",
        "ori-fast-z-score": -1.0722219284950194,
        "water-fast-z-score": 5.816546635685188,
        "rewrite-fast-z-score": 0.9011551125709446
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The nearby QSO host I Zw 1: The stellar disk and adjacent objects .\nAbstract:\nWe present new near-infrared integral field spectroscopy (IFS) data for the brightest galaxy in the cluster Abell 2218, which is known to be interacting with its nearest neighbor, the radio-quiet quasar I Zw 1 at z = 0.0625. We find that this galaxy has an extended low-surface-brightness component surrounding it, extending out to about 10 kpc on both sides along the major axis. This feature shows no evidence of rotation but does show some velocity structure consistent with infalling gas or tidal debris. In addition we detect two compact objects within 5 kpc of the center of the galaxy. One of these appears to have a very high surface brightness and may represent a nuclear starburst; however, the other one displays much lower surface brightness and could possibly be associated with a supermassive black hole binary system. These results are discussed in terms of possible evolutionary scenarios for this interacting pair.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The nearby QSO host I Zw 1 : The stellar disk and adjacent bodies . Abstract : We report new near - infrared integral field spectroscopy ( IFS ) statistics for the brightest galaxy in the cluster Abell 2218 , which is known to be interacting with its closest neighbor , the radio - quiet quasar I Zw 1 at z = 0 . 0625 .We see that this galaxy has an extended low - surface - brightness component covering it , extending out to about 10 kpc on both sides along the main axis . This structure exhibits no evidence of rotation but does display some velocity features compatible with infalling gas or tidal debris .In addition we perceive two compact entities within 5 kpc of the center of the galaxy . One of these seems to have a very high surface brightness and may indicate a nuclear starburst ; however , the other one exhibits far lower surface brightness and could possibly be identified with a supermassive black hole binary system .These data are discussed in terms of possible evolutionary scenarios for this interacting pair .",
        "rewrite_text": "We present new near-infrared integral field spectroscopy (IFS) observations of the prominent galaxy within the Abell 2218 cluster, which is known to be in interaction with its nearest neighbor, the radio-quiet quasar I Zw 1 at a redshift of z = 0.0625. Our findings reveal that this galaxy is enveloped by an extensive low-surface-brightness structure that extends approximately 10 kpc along its principal axis. Notably, this component does not exhibit any signs of rotation; however, it does show velocity features that suggest the presence of infalling gas or tidal debris resulting from the interaction. Furthermore, we identify two compact structures located within 5 kpc of the galaxy's center. One of these structures displays a significantly high surface brightness, which may indicate the occurrence of a nuclear starburst event. In contrast, the second structure has a much lower surface brightness and could potentially be associated with a binary system of supermassive black holes. We analyze these observations in the context of various evolutionary scenarios for the interacting pair, considering the implications of their dynamics and the potential influence of the quasar on the host galaxy's evolution. This study enhances our understanding of the complex interactions between galaxies and their neighbors, particularly in the context of active galactic nuclei and their host environments.",
        "ori-fast-z-score": 0.10846522890932808,
        "water-fast-z-score": 4.74464202095129,
        "rewrite-fast-z-score": 2.3763541031440183
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Evidence for decay of spin-waves above the pseudogap in underdoped YBa2Cu3O6.35 .\nAbstract:\nWe report on neutron scattering experiments performed to study magnetic excitations in an underdoped cuprate superconductor, YBa2Cu3Ox (x = 6.35). We observe that the intensity and linewidth of the low-energy spin waves decrease with increasing temperature up to T* ~ 150 K, which is higher than Tc by about 50 K. The observed behavior can be explained within the framework of the spin-fermion model if one assumes that the spin-wave lifetime decreases rapidly at temperatures close to T* due to the decay into fermionic quasiparticles. This interpretation implies that the pseudogap opens already below T* as suggested previously. \n \n Introduction \n \n In recent years there has been considerable interest in studying the properties of high-temperature superconductors using neutron scattering techniques  1-5 . Neutron scattering allows us not only to investigate the static structure factor S(Q) but also dynamic correlations such as phonons or magnons  6 . It was found recently  7-9  that the low energy spin wave spectrum in optimally doped YBa2Cu3O3 displays unusual features compared to conventional metals. For example, it exhibits a strong dispersion anisotropy along different crystallographic directions  8  and shows significant deviations from the usual linear dependence between the inverse spin wave velocity and momentum  9 . These results have stimulated theoretical studies  10-12  aimed at understanding how these unconventional spin wave properties are related to the electronic structure of the CuO2 planes. However, little attention has so far been paid to the effect of doping on the spin wave dynamics. Here we present new experimental data obtained on an underdoped sample of YBa2Cu3OX (x= 6.35), where x denotes the oxygen content  13 . Our main goal is to explore whether the spin wave properties change significantly when going away from optimal doping towards lower values of x.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Evidence for decay of spin - particles above the pseudogap in underdoped YBa2Cu3O6 . 35 . Abstract : We report on neutron scattering experiments conducted to study magnetic excitations in an underdoped cuprate superconductor , YBa2Cu3Ox ( x = 6 . 35 ) .We see that the frequency and linewidth of the small - energy spinning waves reduce with rising heat up to T * ~ 150 K , which is higher than Tc by about 50 K . The observed behavior can be described within the framework of the spin - fermion theory if one suppose that the spin - wave life falls steadily at temperatures close to T * due to the decay into fermionic quasiparticles . This interpretation means that the pseudogap opens already below T * as suggested previously .Introduction In recent years there has been substantial interest in investigating the properties of high - temperature superconductors using neutron scattering methods 1 - 5 . Neutron diffusion lets us not only to examine the static structure parameter S ( Q ) but also dynamic correlations such as phonons or magnons 6 .It was shown later 7 - 9 that the reduced energy spinning wave spectrum in optimally doped YBa2Cu3O3 exhibits unusual characteristics compared to conventional metals . For instance , it displays a powerful dispersion anisotropy along various crystallographic directions 8 and shows significant deviations from the usual linear dependence between the inverse spinning wave velocity and momentum 9 .These data have stimulated theoretical experiments 10 - 12 aiming at studying how these unconventional spin wave properties are related to the electronic stability of the CuO2 planes . However , nothing scrutiny has so far been paid to the impact of doping on the spin wave behavior .Here we present new empirical data derived on an underdoped specimen of YBa2Cu3OX ( x = 6 . 35 ) , where x denotes the oxygen quality 13 . Our main goal is to examine whether the spin wave properties improve slightly when going away from efficient doping towards lesser values of x .",
        "rewrite_text": "**Title:** Evidence for Decay of Spin-Particles Above the Pseudogap in Underdoped YBa2Cu3O6.35\n\n**Abstract:** In this study, we present findings from neutron scattering experiments aimed at investigating the magnetic excitations in the underdoped cuprate superconductor YBa2Cu3O6.35. Our results indicate that both the frequency and linewidth of low-energy spin waves decrease as temperature increases, reaching a notable transition at T* ~ 150 K, which exceeds the superconducting transition temperature (Tc) by approximately 50 K. This observed phenomenon can be effectively explained through the spin-fermion theory, which posits that the lifetime of spin waves diminishes progressively as temperatures approach T*, attributed to their decay into fermionic quasiparticles. This interpretation supports the hypothesis that the pseudogap begins to form at temperatures below T*, consistent with earlier suggestions in the literature.\n\nThe introduction of this research highlights the growing interest in the properties of high-temperature superconductors, particularly through the lens of neutron scattering techniques. These methods allow for the exploration of both static structural parameters and dynamic correlations, such as phonons and magnons. Previous studies have revealed that the energy spectrum of spin waves in optimally doped YBa2Cu3O3 exhibits distinctive features that diverge from those observed in conventional metals, including pronounced dispersion anisotropy and significant deviations from the expected linear relationship between the inverse spin wave velocity and momentum. Such findings have spurred theoretical investigations into the connection between these unconventional spin wave characteristics and the electronic stability of the CuO2 planes.\n\nDespite the extensive research on spin wave properties, the influence of doping on these behaviors has not been thoroughly examined. In this paper, we provide new empirical data from an underdoped sample of YBa2Cu3O6.35, where the oxygen content (x) is a critical factor. Our primary objective is to assess whether the properties of spin waves exhibit any improvement as we transition from optimal doping to lower values of x, thereby contributing to the understanding of spin dynamics in underdoped cuprate superconductors.",
        "ori-fast-z-score": -1.9100460366360192,
        "water-fast-z-score": 6.845724620391277,
        "rewrite-fast-z-score": 0.3310423554409472
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Light Heavy MSSM Higgs Bosons at Large tan_beta .\nAbstract:\nWe study the lightest and heaviest CP-even neutral Higgs boson masses in the Minimal Supersymmetric Standard Model (MSSM) with large values of tan(beta). We find that for large values of tan(betas), there is an upper bound on mH,max which depends only weakly on tan(beta). This upper bound can be as low as 130 GeV if we allow for nonuniversal soft supersymmetry breaking terms. The lower limit on mH,min increases rapidly with increasing tan(beta).  For small values of tan(beta) (tan(beta) < 3), the mass difference between the two CP-even Higgs bosons decreases slowly with increasing tan(beta). However, this decrease becomes more rapid when tan(beta) > 5.  In addition to these results, we also present the dependence of the lightest CP-odd Higgs boson mass on tan(beta). \nI. INTRODUCTORY REMARkS\nThe Minimal Supersymmetric Standard model (MSSM)  1  has been studied extensively over the past few years  2  . It contains many new parameters beyond those of the Standard Model (SM). These include the gaugino masses M1 , M2 , M3 , the higgsino mass parameter µ, the trilinear scalar couplings A f , and the ratio of vacuum expectation values of the two Higgs doublets tan(beta).\nIn general, it is difficult to obtain analytical expressions for all the physical quantities in the MSSM  3  . Therefore, one usually resorts to numerical methods  4  or approximations  5  .\nRecently, several groups have used approximate techniques  6  -  8  to calculate various properties of the MSSM Higgs sector. In particular, Ref.  7  presents analytic formulas for calculating the masses of the three neutral Higgs bosons in the MSSM upto leading order corrections in 1/tan(beta). They show that their results agree well with exact calculations  9  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Light Heavy MSSM Higgs Bosons at Large tan _ β . Abstract : We study the lightest and heaviest CP - even neutral Higgs boson masses in the Minimal Supersymmetric Standard Model ( MSSM ) with large values of tan ( beta ) .We see that for large values of tan ( betas ) , there is an upper bound on mH , max which depends only weakly on tan ( beta ) . This upper bound can be as low as 130 GeV if we allow for nonuniversal soft supersymmetry broken terms .The smaller limit on mH , min increases quickly with expanding tan ( beta ) . For small values of tan ( beta ) ( tan ( beta ) < 3 ) , the mass ratio between the two CP - even Higgs bosons reduces gradually with expanding tan ( beta ) .However , this decline becomes more rapid when tan ( beta ) > 5 . In addition to these results , we also present the dependence of the lightest CP - odd Higgs boson weight on tan ( beta ) .I . INTRODUCTORY REMARkS The Minimal Supersymmetric Standard model ( MSSM ) 1 has been studied thoroughly over the previous few years 2 .It contains many new parameters beyond those of the Standard Model ( SM ) . These include the gaugino masses M1 , M2 , M3 , the higgsino mass parameter µ , the trilinear scalar couplings A f , and the proportion of vacuum expectation values of the two Higgs doublets tan ( beta ) .In general , it is harder to obtain empirical expressions for all the physical quantities in the MSSM 3 . Therefore , one usually resorts to numerical technique 4 or approximations 5 .Recently , various groups have utilized approximate techniques 6 - 8 to estimate various properties of the MSSM Higgs region . In particular , Ref .7 presents analytic formulas for determining the masses of the three neutral Higgs bosons in the MSSM upto leading order corrections in 1 / tan ( beta ) . They show that their results agree well with actual measurements 9 .",
        "rewrite_text": "**Title: Light Heavy MSSM Higgs Bosons at Large tan(β)**\n\n**Abstract:** This study investigates the masses of the lightest and heaviest CP-even neutral Higgs bosons within the framework of the Minimal Supersymmetric Standard Model (MSSM) when large values of tan(β) are considered. Our findings reveal that, for substantial values of tan(β), there exists an upper limit on the mass of the heaviest Higgs boson, denoted as mH,max, which exhibits only a weak dependence on tan(β). Notably, this upper limit can drop to as low as 130 GeV if nonuniversal soft supersymmetry-breaking terms are permitted. Conversely, the lower limit on the mass of the lightest Higgs boson, mH,min, shows a rapid increase as tan(β) rises. For small values of tan(β) (specifically, tan(β) < 3), the mass ratio between the two CP-even Higgs bosons decreases gradually with increasing tan(β). However, this decline accelerates significantly once tan(β) exceeds 5. Additionally, we explore the relationship between the mass of the lightest CP-odd Higgs boson and tan(β). \n\nIn the context of the MSSM, which has been extensively studied in recent years, numerous new parameters extend beyond those of the Standard Model (SM). These parameters include gaugino masses (M1, M2, M3), the higgsino mass parameter (µ), trilinear scalar couplings (Af), and the ratio of vacuum expectation values of the two Higgs doublets (tan(β)). Due to the complexity of deriving empirical expressions for all physical quantities in the MSSM, researchers often resort to numerical methods or approximations. Recent studies have employed various approximate techniques to estimate properties of the MSSM Higgs sector, with one notable reference providing analytic formulas for the masses of the three neutral Higgs bosons in the MSSM up to leading order corrections in 1/tan(β). The results from these analyses demonstrate a strong agreement with experimental measurements, highlighting the relevance of this research in understanding the MSSM Higgs boson dynamics.",
        "ori-fast-z-score": 0.5345224838248488,
        "water-fast-z-score": 5.303300858899106,
        "rewrite-fast-z-score": -0.8049844718999243
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Two branches of neutron stars - reconciling a 2M_sun pulsar and SN1987A .\nAbstract:\nWe propose that the two branches in the mass distribution of neutron stars are due to different mechanisms for their formation, with one branch being formed by accretion-induced collapse (AIC) of white dwarfs into neutron stars, while another is formed through core-collapse supernovae (CCSNe). We show how this scenario can explain both the existence of massive pulsars as well as the absence of such objects in the observed sample of CCSNe remnants. The proposed model also explains why there have been no successful attempts so far at detecting gravitational waves emitted during AIC events. In addition we argue that our model provides an explanation for the apparent discrepancy between the masses inferred from observations of binary systems containing black holes or neutron stars on one hand, and those inferred from measurements of the radii of isolated neutron stars on the other. Finally, we discuss possible observational tests which could be used to verify our hypothesis.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Two branches of neutron stars - reconciling a 2M _ sun pulsar and SN1987A . Abstract : We suggest that the two branches in the mass distribution of neutron stars are owing to different processes for their formed , with one branch being created by accretion - caused merger ( AIC ) of white dwarfs into neutron stars , while another is formed through core - collapse supernovae ( CCSNe ) .We see how this situation can describe both the existence of large pulsars as well as the absence of such objects in the observed sample of CCSNe fragments . The proposed theory also explains why there have been no successful proposals so far at detecting gravitational waves emitted during AIC events .In addition we claim that our model provides an reason for the apparent discrepancy between the masses inferred from measurements of binary systems featuring white holes or neutron galaxies on one hand , and those inferred from measurements of the radii of isolated neutron galaxies on the other . Finally , we explain possible observational tests which could be used to confirm our theory .",
        "rewrite_text": "Title: Two Branches of Neutron Stars - Reconciling a 2M_sun Pulsar and SN1987A\n\nAbstract: In this study, we propose a novel explanation for the observed dual branches in the mass distribution of neutron stars, attributing their formation to distinct astrophysical processes. One branch is hypothesized to arise from the accretion-induced collapse (AIC) of white dwarfs into neutron stars, while the other results from core-collapse supernovae (CCSNe). This framework effectively accounts for the presence of massive pulsars, such as those exceeding 2 solar masses, alongside the notable absence of similarly massive objects in the remnants of CCSNe. Our model further elucidates the challenges faced in detecting gravitational waves from AIC events, which have yet to yield successful observational results. \n\nMoreover, we address the apparent inconsistency between mass estimates derived from binary systems containing white dwarfs or neutron stars and those obtained from the radii measurements of isolated neutron stars. This discrepancy suggests a deeper underlying relationship between the formation mechanisms of these celestial bodies and their observed properties. \n\nTo validate our hypothesis, we propose several observational tests that could provide critical evidence supporting our theory. These tests aim to bridge the gap between theoretical predictions and empirical observations, potentially leading to a more comprehensive understanding of neutron star formation and evolution. By reconciling the existence of massive pulsars with the remnants of supernovae, our research contributes to the ongoing discourse in astrophysics regarding the life cycles of stars and the nature of compact objects in the universe.",
        "ori-fast-z-score": -0.3333333333333333,
        "water-fast-z-score": 4.858987147293248,
        "rewrite-fast-z-score": 1.1141720290623112
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Can Gravity Probe B usefully constrain torsion gravity theories? .\nAbstract:\nWe study the possibility that gravitational waves can be detected by measuring their effect on gyroscopes in space, as proposed for the GP-B experiment. We consider two classes of models with torsion and show how they affect the motion of test particles around spinning black holes. In one class we find that there is no effect at all; this includes Einstein-Cartan theory (with or without fermions) and teleparallel gravity. The other class contains some effects but these are too small to be detectable even if the spin of the black hole were known exactly. However, it may still be possible to detect such effects using future experiments like LISA. Finally, we discuss whether any of our results could have been anticipated within general relativity. This work was supported by NSF grant PHY-0456747. Gravitational waves will produce tiny changes in the orientation of gyroscopes carried into space by satellites. These changes should be measurable by comparing the orientations of pairs of gyroscopes separated by large distances. Such an experiment has recently begun taking data  1  . It is called Gravity Probe B (GP-B), after its predecessor which measured the precession of the earth s orbit  2  .\nIn this Letter we investigate what information about gravitational waves might be obtained from measurements made by GP-B. Our main focus is on theories containing torsion -the antisymmetric part of the connection  3, 4  , which plays a role similar to electromagnetism in standard general relativity  5  . Torsion arises naturally in many extensions of general relativity  6  ; however, it also appears in certain modified versions of general relativity  7, 8  . For example, in string-inspired supergravity  9  , torsion couples directly to matter fields  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Can Gravity Probe B usefully constrain torsion gravity theories ? .Abstract : We research the prospect that gravity signals can be identified by monitoring their effect on gyroscopes in space , as suggested for the GP - B experiment . We consider two groups of models with torsion and know how they impact the movement of test particles around spun dark holes .In one category we find that there is no effect at all ; this includes Einstein - Cartan theory ( with or without fermions ) and teleparallel gravitational . The other class includes some effects but these are too small to be detectable even if the spin of the dark hole were known exactly .However , it could still be possible to observe such effects utilizing potential experiments like LISA . Finally , we issue whether any of our findings may have been anticipated within general relativity .This project was supported by NSF grant PHY - 0456747 . Gravitational waves will generate tiny changes in the orientation of gyroscopes sent into space by satellites .These changes should be measurable by testing the orientations of pairs of gyroscopes separated by large distances . Such an observation has recently begun took results 1 .It is titled Gravity Probe B ( GP - B ) , after its predecessor which calculated the precession of the earth s orbit 2 . In this Letter we investigate what knowledge about gravitational waves might be obtained from measurements made by GP - B .Our main interest is on theories involving torsion - the antisymmetric part of the relationship 3 , 4 , which plays a role similar to electromagnetism in standard special relativity 5 . Torsion occurs commonly in many extensions of general relativity 6 ; however , it also exists in certain modified variants of general relativity 7 , 8 .For instance , in string - inspired supergravity 9 , torsion couples directly to matter fields 10 .",
        "rewrite_text": "**Title: Can Gravity Probe B Effectively Constrain Torsion Gravity Theories?**\n\n**Abstract:** This study explores the potential of utilizing gravity signals to identify their influence on gyroscopes deployed in space, as proposed in the Gravity Probe B (GP-B) experiment. We analyze two distinct categories of torsion gravity models and their effects on the motion of test particles in the vicinity of rotating black holes. In the first category, we observe that certain models, including Einstein-Cartan theory (with or without fermionic matter) and teleparallel gravity, exhibit no detectable effects on gyroscope behavior. Conversely, the second category reveals models that do produce measurable effects; however, these effects are too minuscule to be observed, even with precise knowledge of the black hole's spin. Despite this limitation, we suggest that future experiments, such as the Laser Interferometer Space Antenna (LISA), may still provide opportunities to detect these subtle influences. Additionally, we consider whether our findings align with predictions made within the framework of general relativity. This research was supported by NSF grant PHY-0456747. Gravitational waves are expected to induce minute alterations in the orientation of gyroscopes placed in space by satellites, which can be quantified by comparing the orientations of pairs of gyroscopes positioned at significant distances apart. Recent observations have begun to yield results in this area. The GP-B experiment, named after its predecessor that measured the precession of Earth's orbit, serves as a focal point for our investigation into the insights that can be gleaned regarding gravitational waves from GP-B measurements. Our primary focus lies on torsion theories, which introduce an antisymmetric component to the gravitational field equations, akin to the role of electromagnetism in standard special relativity. Torsion is a common feature in various extensions and modifications of general relativity, including string-inspired supergravity, where it interacts directly with matter fields.",
        "ori-fast-z-score": 0.3481553119113957,
        "water-fast-z-score": 8.23754471047914,
        "rewrite-fast-z-score": 1.4419211804559506
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Un Resultat Gravimetrique pour la Renaissance de la Theorie Corpusculaire  An Experimental Gravimetric Result for the Revival of Corpuscular Theory  .\nAbstract:\nLa gravite est une force fondamentale qui agit sur tous les corps materiels, et dont l action se manifeste par l attraction entre ces derniers. La gravitation newtonienne ne peut expliquer que le phenomene de la chute des corps vers un point unique au centre du systeme solaire. Les theories relativistes d Einstein ont permis d expliquer ce phenomene en introduisant la notion d espace-temps courbe. Cependant, il existe d autres phenomenes physiques tels que l effet Casimir ou encore celui de la pression de radiation electromagnetique qui necessitent l introduction d une nouvelle dimension dans l espace temps. Dans cette these nous proposons d introduire une nouvelle dimension spatiale afin d etendre la geometrie euclidienne classique. Nous montrons alors qu il est possible d interpreter la gravite comme une manifestation macroscopique d un effet microscopique lie aux fluctuations quantiques de l espacetemps. Cette interpretation permet ainsi de retrouver les predictions theoriques de la physique actuelle concernant la dynamique des astres tout en proposant une explication rationnelle a certains phenomenes physiques non expliques jusqu a present.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Un Resultat Gravimetrique pour la Renaissance de la Theorie Corpusculaire An Experimental Gravimetric Result for the Revival of Corpuscular Theory . Abstract : La gravite est le power fondamentale qui agit à tous les corps materiels , et dont l action se manifeste par l attraction entre ces derniers .La gravitation newtonienne ne peut expliquer que le phenomene de la chute des corps vers un place unique au centre le systeme solaire . Les theories relativistes d Einstein ont permis d expliquer ce phenomene en introduisant la conception d espace - temps courbe .Cependant , el existe d autres phenomenes physiques tels se l effet Casimir ou encore celui de la pression de energy electromagnetique qui necessitent l introduction d la nouvelle dimension sur l espace temps . Dans cette these nous proposons d introduire une nouvelle dimension spatiale afin d etendre la geometrie euclidienne classique .Nous montrons alors qu il est possible d interpreter la gravite comme une manifestation macroscopique d un effet microscopique lie à fluctuations quantiques de l espacetemps . Cette interpretation permet ainsi de retrouver les predictions theoriques de la physique actuelle concernant le dynamique du astres tout en proposant une explication rationnelle a certains phenomenes physiques non expliques jusqu a present .",
        "rewrite_text": "**Title:** An Experimental Gravimetric Result for the Revival of Corpuscular Theory\n\n**Abstract:** Gravity is a fundamental force that acts on all material bodies, manifesting through the attraction between them. While Newtonian gravity adequately describes the phenomenon of objects falling toward a singular point at the center of the solar system, it falls short in addressing other complex gravitational behaviors. Einstein's relativistic theories have provided a deeper understanding by introducing the concept of curved spacetime, yet there remain physical phenomena, such as the Casimir effect and electromagnetic energy pressure, that necessitate the incorporation of an additional dimension within spacetime. In this paper, we propose the introduction of a new spatial dimension to extend classical Euclidean geometry. Our findings suggest that gravity can be interpreted as a macroscopic manifestation of microscopic effects related to quantum fluctuations in spacetime. This interpretation not only aligns with current theoretical predictions regarding the dynamics of celestial bodies but also offers rational explanations for certain previously unexplained physical phenomena. By exploring this novel approach, we aim to bridge gaps in existing gravitational theories and contribute to the ongoing discourse surrounding the nature of gravity and its implications in both classical and quantum physics. Our results provide a fresh perspective on the interplay between gravity and quantum mechanics, potentially paving the way for future research that could further elucidate the complexities of the universe.",
        "ori-fast-z-score": -0.629940788348712,
        "water-fast-z-score": 2.8977276264040754,
        "rewrite-fast-z-score": -0.4833682445228318
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Close Look at Star Formation around Active Galactic Nuclei .\nAbstract:\nWe present new results on the star formation rate (SFR) in galaxies with active galactic nuclei (AGN). We use deep Spitzer Space Telescope observations to study the infrared luminosity function and SFR density evolution for AGNs selected by their mid-infrared colors, which are known to be dominated by dust heated by young stars. The observed infrared luminosities range over four orders of magnitude, from 10^42 erg/sec to more than 10^45 erg/sec. Our sample includes both obscured quasars and unobscured type-1 Seyferts out to redshifts z = 3.5. We find that the infrared luminosity functions of these two populations evolve similarly as a function of redshift, but differ significantly when compared locally. This suggests that the physical processes responsible for heating the dust may not change dramatically between high-z and low-z systems, while the fraction of AGNs surrounded by massive amounts of dust does decrease rapidly with time.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Close Look at Star Formation around Active Galactic Nuclei . Abstract : We report new data on the star formation rate ( SFR ) in galaxies with active galactic nuclei ( AGN ) .We use deep Spitzer Space Telescope observations to study the infrared luminosity function and SFR density evolution for AGNs chosen by their mid - infrared colors , which are known to be dominated by dust warmed by young stars . The observed laser luminosities range over four orders of magnitude , from 10 ^ 42 erg / sec to more than 10 ^ 45 erg / sec .Our survey encompasses both distorted quasars and unobscured type - 1 Seyferts out to redshifts z = 3 . 5 . We see that the infrared luminosity functions of these two communities evolve similarly as a function of redshift , but change considerably when compared nationally .This implies that the physical processes responsible for warming the dust may not change dramatically between high - z and low - z systems , while the fraction of AGNs enclosed by massive amounts of dust does decrease rapidly with time .",
        "rewrite_text": "We present new findings regarding the star formation rate (SFR) in galaxies hosting active galactic nuclei (AGN). Utilizing extensive observations from the Spitzer Space Telescope, we investigate the infrared luminosity function and the evolution of SFR density in AGNs selected based on their mid-infrared color signatures, which are primarily influenced by dust heated by young stellar populations. The range of observed infrared luminosities spans four orders of magnitude, from 10^42 erg/sec to over 10^45 erg/sec. Our comprehensive survey includes both distorted quasars and unobscured type-1 Seyfert galaxies, extending to redshifts of z = 3.5. \n\nOur analysis reveals that the infrared luminosity functions for these two categories of AGNs exhibit similar evolutionary patterns with respect to redshift, yet they show significant variations when compared on a national scale. This observation suggests that the underlying physical mechanisms responsible for dust heating remain relatively stable across high-redshift (high-z) and low-redshift (low-z) systems. However, we also find that the proportion of AGNs surrounded by substantial amounts of dust diminishes rapidly over cosmic time. These results provide valuable insights into the interplay between star formation and AGN activity, highlighting the importance of dust in the environments of these energetic phenomena. Our findings contribute to a deeper understanding of the evolution of galaxies with AGNs and the role of star formation in shaping their characteristics across different epochs in the universe.",
        "ori-fast-z-score": 0.7977240352174656,
        "water-fast-z-score": 4.755563543407302,
        "rewrite-fast-z-score": 1.958260097304659
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Straggler Identification in Round-Trip Data Streams via Newton s Identities and Invertible Bloom Filters .\nAbstract:\nWe present an algorithm for identifying stragglers in round-trip data streams using Newton s identities, which are derived by applying the chain rule to matrix exponentials. We show that our approach is more efficient than existing methods based on linear regression or singular value decomposition (SVD). Our method also has lower memory requirements compared with SVD-based approaches. Finally, we demonstrate how our technique can be used to identify stragglers in real-world datasets such as Google Analytics clickstream logs. The problem of identifying stragglers arises when processing large volumes of data in parallel systems. Stragglers are slow processors whose presence degrades overall system performance. Identifying these stragglers allows us to take corrective action so that they do not affect other processes running simultaneously. For example, if a straggler process takes too much time to complete its task, then it may be possible to offload some work onto another processor to speed up execution.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Straggler Identification in Round - Trip Data Streams via Newton s Identities and Invertible Bloom Filters . Abstract : We present an algorithm for finding stragglers in round - trip data loops using Newton s identities , which are derived by using the chain rule to matrix exponentials .We see that our approach is more efficient than existing techniques based on binary regression or singular value transformation ( SVD ) . Our algorithm additionally has reduced storage needs compared with SVD - based techniques .Finally , we prove how our technique can be used to identify stragglers in real - time datasets such as Google Analytics clickstream logs . The question of identifying stragglers occurs when handling large quantities of data in concurrent systems .Stragglers are slow processors whose presence degrades overall network reliability . Identifying these stragglers lets us to take corrective action so that they do not harm other processes running simultaneously .For instance , if a straggler process took too enough time to complete its job , then it could be possible to offload some work onto another processor to faster up execution .",
        "rewrite_text": "We introduce a novel algorithm designed to identify stragglers in round-trip data streams, leveraging Newton's identities derived through the application of the chain rule to matrix exponentials. Our method demonstrates superior efficiency compared to traditional approaches that rely on binary regression or singular value decomposition (SVD). Notably, our algorithm also requires significantly less storage than SVD-based methods, making it a more practical solution for large-scale data processing. We provide a rigorous proof of our technique's applicability in real-time datasets, specifically highlighting its effectiveness in analyzing Google Analytics clickstream logs. The challenge of straggler identification is particularly pertinent in the context of managing extensive data within concurrent systems, where stragglers—defined as slow processors—can adversely affect overall network performance and reliability. By pinpointing these stragglers, we enable the implementation of corrective measures to mitigate their impact on other concurrently running processes. For example, if a straggler process is observed to be taking an excessive amount of time to complete its tasks, our algorithm allows for the possibility of redistributing some of its workload to alternative processors, thereby enhancing overall execution speed. This research contributes to the ongoing efforts to optimize data processing in high-demand environments, ensuring that system performance remains robust even in the presence of slower components.",
        "ori-fast-z-score": -1.8888888888888888,
        "water-fast-z-score": 5.378448739494827,
        "rewrite-fast-z-score": 0.6527533657682196
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Room temperature spin polarized magnetic semiconductor .\nAbstract:\nWe report on the room-temperature ferromagnetism in Mn-doped ZnO thin films grown by pulsed laser deposition (PLD). The Curie temperatures are found to be around 300 K for all samples with different doping levels, which is much higher than that reported previously. We also find that the magnetization increases linearly as the applied field decreases and shows hysteresis loops at low fields. These results indicate that the observed ferromagnetic behavior may originate from exchange coupling between localized spins rather than intrinsic ferromagnetism. \n \n In recent years, there has been growing interest in developing new materials for spintronic applications such as nonvolatile memory devices or logic circuits based on the manipulation of electron spins instead of charge carriers1-5 . Among these materials, diluted magnetic semiconductors have attracted considerable attention because they can combine both electronic and magnetic functionalities into one material6-8 .\n \n\n\nZnO-based DMSs have been extensively studied due to their wide band gap energy (3.37 eV), large exciton binding energy (60 meV)9 , high transparency10-12 , and good chemical stability13-15 . However, it remains challenging to achieve room-temperature ferromagnetically ordered states in ZnO-based DMSs16-18 . Although several groups have recently demonstrated room-temperature ferromagnetic ordering in various types of ZnO-based DMS systems19-24 , most of them show relatively small saturation magnetizations25-27 . \n \n Here we report on the observation of room-temperature ferromagnetisms in Mn-doped ZnObased DMSs prepared using pulsed laser deposition28-30 . Our experimental data clearly demonstrate that the dopant concentration plays an important role in determining the Curie temperature31-33 . For example, our sample with x = 0.5% exhibits a Curie temperature of about 300 K while those with lower concentrations exhibit smaller values ranging from 150-250 K34-36 . Moreover, we observe that the magnetization increases almost linearly when decreasing the external magnetic field below 1 T and displays hysteretic behaviors at very low fields. This indicates that the observed ferr",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Room temperature spin polarized magnetic semiconductor . Abstract : We report on the room - temperature ferromagnetism in Mn - doped ZnO thin films developed by pulsed laser deposition ( PLD ) .The Curie temperatures are found to be around 300 K for all specimens with varying doping rates , which is much higher than that confirmed previously . We additionally find that the magnetization increases linearly as the applied field decreases and shows hysteresis loops at low areas .These data indicate that the studied ferromagnetic activity may originate from exchange interactions between scattered spinning rather than intrinsic ferromagnetism . In past decades , there has been growing interest in building new materials for spintronic use such as nonvolatile memory devices or logic devices based on the manipulation of electron spins rather of charge carriers1 - 5 .Among these materials , diluted magnetic semiconductors have garnered considerable scrutiny because they can mix both electronic and magnetic functionalities into one material6 - 8 . ZnO - based DMSs have been heavily explored thanks to their wide band gap energy ( 3 . 37 eV ) , large exciton binding energy ( 60 meV ) 9 , large transparency10 - 12 , and good molecular stability13 - 15 .However , it remains challenging to achieve room - temperature ferromagnetically ordered states in ZnO - based DMSs16 - 18 . Although several teams have recently shown room - temperature ferromagnetic ordering in different kinds of ZnO - based DMS systems19 - 24 , most of them show relatively small saturation magnetizations25 - 27 .Here we publish on the observation of room - temperature ferromagnetisms in Mn - doped ZnObased DMSs assembled utilizing pulsed laser deposition28 - 30 . Our research data distinctly show that the dopant concentration acts an important role in establishing the Curie temperature31 - 33 .For instance , our sample with x = 0 . 5 % experiences a Curie temperature of about 300 K while those with lesser levels demonstrate lower values ranging from 150 - 250 K34 - 36 . Moreover , we find that the magnetization increases almost linearly when decreasing the external magnetic force below 1 T and displays hysteretic behaviors at very low fields .This implies that the observed ferr",
        "rewrite_text": "**Title:** Room Temperature Spin Polarized Magnetic Semiconductor\n\n**Abstract:** In this study, we investigate the phenomenon of room-temperature ferromagnetism in manganese (Mn)-doped zinc oxide (ZnO) thin films, which were synthesized using pulsed laser deposition (PLD) techniques. Our findings reveal that all samples exhibit Curie temperatures around 300 K, significantly surpassing previously reported values. Notably, we observe a linear increase in magnetization as the applied magnetic field decreases, accompanied by the presence of hysteresis loops at low magnetic fields. These observations suggest that the ferromagnetic behavior in the materials may stem from exchange interactions among scattered spins rather than from intrinsic ferromagnetism.\n\nThe pursuit of novel materials for spintronic applications, such as non-volatile memory and logic devices that leverage electron spin manipulation instead of charge transport, has gained momentum over the past few decades. Diluted magnetic semiconductors (DMSs) have emerged as a focal point of research due to their ability to integrate electronic and magnetic properties within a single material. Among these, ZnO-based DMSs are particularly attractive due to their advantageous characteristics, including a wide bandgap energy of 3.37 eV, a large exciton binding energy of 60 meV, high optical transparency, and robust molecular stability.\n\nDespite extensive research, achieving room-temperature ferromagnetism in ZnO-based DMSs has proven to be a significant challenge. While several studies have reported room-temperature ferromagnetic ordering in various ZnO-based DMS systems, most have been characterized by relatively low saturation magnetizations. Our work contributes to this field by demonstrating the presence of room-temperature ferromagnetism in Mn-doped ZnO DMSs fabricated through PLD. We provide compelling evidence that the concentration of the dopant plays a crucial role in determining the Curie temperature; for example, a sample with a doping level of 0.5% exhibits a Curie temperature of approximately 300 K, while samples with lower doping concentrations show Curie temperatures ranging from 150 to 250 K. Furthermore, our results indicate that magnetization increases linearly when the external magnetic field is reduced below 1 T, with pronounced hysteretic behavior at low fields, underscoring the complex magnetic interactions at play in these materials.",
        "ori-fast-z-score": -0.08084520834544433,
        "water-fast-z-score": 7.526023228839096,
        "rewrite-fast-z-score": -1.005970202294378
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Near infrared spectroscopic search for the close orbiting planet HD 75289b .\nAbstract:\nWe report on our near-infrared (NIR) spectroscopic observations of the nearby G0V star HD75289, which is known to have an M dwarf companion at 0.3 AU with a mass ratio q = 0.1 and orbital period P orb = 3 yr. We observed this system in 2005-2007 using NIRSPEC mounted on Keck II telescope. The radial velocity measurements show that there are two peaks separated by ~100 km/sec in the cross correlation function between the target spectrum and template spectra of different spectral types ranging from F-type to T-type stars. These results suggest that we may be seeing double lines due to the presence of another object in addition to the M dwarf companion. However, it should also be noted that these features could arise as a result of stellar activity or pulsations. \n \n In order to confirm whether the second peak seen in the CCFs arises from the presence of additional companions around HD75289, we carried out high resolution imaging observation using AO188+CORONAS-PHOTON mated with Subaru Telescope. Our coronagraphic images clearly reveal no other objects within 1 arcsec radius except for the previously reported M dwarf companion.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Near infrared spectroscopic search for the close orbiting planet HD 75289b . Abstract : We report on our near - infrared ( NIR ) spectroscopic observations of the nearby G0V star HD75289 , which is known to have an M dwarf companion at 0 . 3 AU with a mass ratio g = 0 . 1 and orbital period P orb = 3 yr . We observed this system in 2005 - 2007 utilizing NIRSPEC mounted on Keck II telescope .The radial speed measurements show that there are two peaks separated by ~ 100 km / sec in the cross correlation function between the target spectrum and template spectra of different spectral classes ranging from F - class to T - class stars . These data suggest that we may be seeing double lines owing to the presence of another object in addition to the M dwarf companion .However , it should additionally be mentioned that these characteristics may arise as a product of stellar behavior or pulsations . In order to confirm whether the second peak seen in the CCFs occurs from the presence of added companions around HD75289 , we conducted out large resolution optical measurement use AO188 + CORONAS - PHOTON mated with Subaru Telescope .Our coronagraphic maps clearly reveal no other objects within 1 arcsec radius except for the previously reported M dwarf companion .",
        "rewrite_text": "We present our findings from a near-infrared (NIR) spectroscopic investigation of the G0V star HD 75289, which is known to host an M dwarf companion located at a distance of 0.3 AU. This companion has a mass ratio of approximately 0.1 and an orbital period of 3 years. Our observations were conducted between 2005 and 2007 using the NIRSPEC instrument on the Keck II telescope. The analysis of radial velocity data revealed two distinct peaks in the cross-correlation function (CCF), separated by approximately 100 km/s, when comparing the target spectrum to template spectra across various spectral classes, from F to T stars. This dual-peak phenomenon raises the possibility of additional companions orbiting HD 75289, beyond the known M dwarf. However, it is important to note that these spectral characteristics could also be attributed to intrinsic stellar activity or pulsations.\n\nTo further investigate the origin of the second peak in the CCFs and to ascertain the presence of any additional companions, we performed high-resolution optical measurements using the AO188 adaptive optics system in conjunction with the CORONAS-PHOTON instrument on the Subaru Telescope. Our coronagraphic imaging results indicate that there are no other detectable objects within a 1 arcsecond radius of HD 75289, aside from the previously identified M dwarf companion. These findings contribute to our understanding of the HD 75289 system and highlight the complexities involved in interpreting spectral data, emphasizing the need for careful analysis to distinguish between potential companions and stellar phenomena.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.103103630798288,
        "rewrite-fast-z-score": 0.8620436566990363
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  TeV-scale gravity in Horava-Witten theory on a compact complex hyperbolic threefold .\nAbstract:\nWe study the low-energy effective action for heterotic string theory compactified to four dimensions on a Calabi-Yau manifold X with fluxes and Wilson lines, where we assume that the internal space is an orbifold limit of a smooth Calabi-Yau threefold Y . We show how this setup can be used to construct models of TeV-scale quantum gravity based on the Horava-Witten (HW) proposal. In particular, we consider the case when the gauge group G = E8 × E8 arises as a subgroup of the structure group of a principal bundle over Y , which leads to a reduction of the rank of the gauge group by one unit compared to the standard embedding. The resulting low energy spectrum contains chiral fermions transforming under the Standard Model gauge groups SU(3), SU(2)L and U(1)Y .\nThe massless gravitino multiplet transforms under the adjoint representation of SO(10). This implies that the lightest supersymmetric particle (LSP) is stable if it has spin 3/2 or 1/2. If the LSP is neutral, then its relic abundance may explain dark matter.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : TeV - scale gravity in Horava - Witten theory on a compact complex hyperbolic threefold . Abstract : We research the small - energy effective operation for heterotic string theory compactified to four dimensions on a Calabi - Yau manifold X with fluxes and Wilson lines , where we suppose that the internal space is an orbifold limit of a smooth Calabi - Yau threefold Y .We see how this setup can be used to build theories of TeV - scale quantum gravitational based on the Horava - Witten ( HW ) proposal . In particular , we define the case when the gauge group G = E8 × E8 appears as a subset of the structure group of a principal bundle over Y , which results to a reduction of the rank of the gauge group by one unit compared to the standard embedding .The resulting small power spectrum contains chiral fermions transforming under the Standard Model gauge categories SU ( 3 ) , SU ( 2 ) L and U ( 1 ) Y . The massless gravitino multiplet transforms under the adjoint representation of SO ( 10 ) .This implies that the lightest supersymmetric object ( LSP ) is stable if it has spin 3 / 2 or 1 / 2 . If the LSP is neutral , then its relic abundance may describe dark matter .",
        "rewrite_text": "In this study, we investigate the effective low-energy dynamics of heterotic string theory when compactified to four dimensions on a Calabi-Yau manifold, denoted as X, which incorporates fluxes and Wilson lines. We assume that the internal geometry is an orbifold limit of a smooth Calabi-Yau threefold, referred to as Y. This framework allows us to explore the construction of theories that exhibit TeV-scale quantum gravity, drawing on the principles of Horava-Witten (HW) theory. Specifically, we examine a scenario where the gauge group G = E8 × E8 is embedded as a subgroup within the structure group of a principal bundle over the manifold Y. This embedding leads to a reduction in the rank of the gauge group by one unit compared to the conventional embedding approach. \n\nThe resulting effective theory yields a spectrum that includes chiral fermions, which transform under the gauge groups of the Standard Model: SU(3), SU(2)L, and U(1)Y. Notably, the massless gravitino multiplet is found to transform under the adjoint representation of SO(10). This configuration suggests that the lightest supersymmetric particle (LSP) is stable, provided it possesses a spin of either 3/2 or 1/2. If the LSP is neutral, its relic abundance could potentially account for dark matter in the universe. Our findings contribute to the understanding of TeV-scale gravity within the context of string theory and provide insights into the implications for particle physics and cosmology, particularly regarding the nature of dark matter and the stability of supersymmetric particles.",
        "ori-fast-z-score": -0.5698028822981898,
        "water-fast-z-score": 3.623286509262706,
        "rewrite-fast-z-score": 1.8
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Line Emission in the Brightest Cluster Galaxies of the NOAO Fundamental Plane and Sloan Digital Sky Surveys .\nAbstract:\nWe present new measurements of line emission for the brightest cluster galaxies (BCGs) in clusters with z < 0.3, using data obtained by the Chandra X-ray Observatory. We find that BCGs  optical luminosities are correlated strongly with their soft-band X-ray luminosities; this correlation is stronger than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity.  The observed relationship can be explained if we assume that most of the X-rays come from inverse Compton scattering off hot electrons associated with the central supermassive black holes. This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs. In addition to the strong correlation between Lopt and LX , we also observe a weak but significant anti-correlation between Lopt and the temperature Tgas of the intracluster medium surrounding each galaxy. These results suggest that the gas density around these galaxies decreases as they evolve into more massive systems.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Line Emission in the Brightest Cluster Galaxies of the NOAO Fundamental Plane and Sloan Digital Sky Surveys . Abstract : We report new studies of line emission for the brightest cluster clusters ( BCGs ) in clusters with z < 0 . 3 , using data derived by the Chandra X - ray Observatory .We see that BCGs laser luminosities are correlated heavily with their soft - band X - ray luminosities ; this relationship is strengthened than previously reported correlations between optical and radio luminosity or between optical and infrared luminosity . The observed relationship can be described if we suppose that most of the X - rays come from inverse Compton absorption off warm particles associated with the main supermassive black holes .This result suggests that there may be an evolutionary link between active galactic nuclei and BCGs . In addition to the strong correlation between Lopt and LX , we also observe a weak but significant anti - correlation between Lopt and the temperature Tgas of the intracluster medium surrounding each constellation .These data suggest that the gas density around these galaxies reduces as they develop into more massive structures .",
        "rewrite_text": "We present a comprehensive analysis of line emission in the brightest cluster galaxies (BCGs) within clusters at redshifts less than 0.3, utilizing data obtained from the Chandra X-ray Observatory. Our findings reveal a robust correlation between the laser luminosities of BCGs and their soft-band X-ray luminosities, which is notably stronger than previously established correlations involving optical and radio luminosities, as well as those between optical and infrared luminosities. This relationship can be interpreted through the lens of inverse Compton scattering, where the majority of X-ray emissions are attributed to interactions with warm particles linked to the central supermassive black holes of these galaxies. This observation implies a potential evolutionary connection between active galactic nuclei and BCGs, highlighting the intricate dynamics at play in these massive cosmic structures. Furthermore, our analysis uncovers a weak yet significant anti-correlation between the optical luminosity (Lopt) and the temperature (Tgas) of the intracluster medium surrounding each galaxy. This trend suggests that as BCGs evolve into more massive entities, the gas density in their vicinity diminishes. Overall, our study enhances the understanding of the interplay between BCGs and their environments, providing insights into the processes that govern their evolution and the role of supermassive black holes in shaping the characteristics of these prominent galaxies within their clusters.",
        "ori-fast-z-score": 1.1322770341445956,
        "water-fast-z-score": 5.962965874907927,
        "rewrite-fast-z-score": 1.116880781646981
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Connecting String/M Theory to the Electroweak Scale and to LHC Data .\nAbstract:\nThe Standard Model (SM) is an extremely successful theory, but it leaves many questions unanswered about physics at very high energies. In particular, there are no known fundamental principles that can explain why the SM has three generations of quarks and leptons with such different masses or how gravity fits into this picture. Theories beyond the Standard Model attempt to address these issues by introducing new particles and/or interactions which may be observed in future experiments.  Supersymmetry (SUSY), for example, introduces partners for all SM fields whose spin differs by one half unit. These partner states have identical gauge quantum numbers as their SM counterparts, so they could mix with them if SUSY were broken at low energy scales. This mixing would lead to deviations from SM predictions for observables like cross sections and decay rates. Many extensions of the Standard Model also predict new phenomena associated with extra dimensions of space-time. For instance, theories based on string/M-theory often contain additional spatial dimensions compactified down to tiny sizes. If these extra dimensions exist, then we should see evidence of their effects through virtual exchange of Kaluza-Klein excitations of gravitons and other particles between SM fields localized on our four-dimensional world-volume.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Connecting String / M Theory to the Electroweak Scale and to LHC Data . Abstract : The Standard Model ( SM ) is an incredibly successful theory , but it leaves many issues unanswered about physics at very high energies .In particular , there are no available fundamental principles that can reason why the SM has three generations of quarks and leptons with such distinct masses or how gravity fits into this picture . Theories beyond the Standard Model attempt to tackle these problems by introducing additional particles and / or relationships which would be encountered in future research .Supersymmetry ( SUSY ) , for example , creates partners for all SM fields whose spin varies by one half unit . These partner states have equal gauge quantum values as their SM counterparts , so they may blend with them if SUSY were breaking at low power scales .This mix might lead to deviations from SM predictions for observables like cross sections and decay rates . Many modifications of the Standard Model also predict new interactions associated with extra dimensions of space - time .For instance , theories based on string / M - theory often contain extra spatial dimensions compactified down to small sizes . If these extra dimensions arise , then we should see evidence of their influence through virtual exchange of Kaluza - Klein excitations of gravitons and other particles between SM fields confined on our four - dimensional world - volume .",
        "rewrite_text": "**Title:** Connecting String/M Theory to the Electroweak Scale and LHC Data\n\n**Abstract:** The Standard Model (SM) of particle physics has proven to be an extraordinarily effective framework for understanding fundamental interactions; however, it remains incomplete, particularly when addressing phenomena at very high energy scales. One of the significant challenges is the lack of fundamental principles that explain the existence of three generations of quarks and leptons, each with distinct masses, as well as the integration of gravity within this framework. To address these shortcomings, various theories beyond the Standard Model have been proposed, which introduce additional particles and relationships that could be explored in future experimental endeavors. A prominent example is Supersymmetry (SUSY), which posits the existence of partner particles for each SM field, differing in spin by half a unit. These supersymmetric partners share identical gauge quantum numbers with their SM counterparts, suggesting that if SUSY is realized at low energy scales, it could lead to observable deviations from SM predictions in quantities such as cross sections and decay rates.\n\nMoreover, numerous extensions of the Standard Model predict novel interactions that could arise from the existence of extra spatial dimensions. Theories rooted in string/M-theory, for instance, often incorporate additional dimensions that are compactified to minuscule scales. The presence of these extra dimensions could manifest through the virtual exchange of Kaluza-Klein excitations of gravitons and other particles, influencing interactions among SM fields that are confined to our familiar four-dimensional spacetime. This paper aims to explore the connections between string/M-theory and the electroweak scale, while also examining how these theoretical frameworks can be tested against data from the Large Hadron Collider (LHC). By investigating these relationships, we hope to shed light on the potential implications of higher-dimensional theories for our understanding of fundamental physics and the nature of the universe at its most fundamental level.",
        "ori-fast-z-score": 0.9805806756909202,
        "water-fast-z-score": 7.060180864974626,
        "rewrite-fast-z-score": 1.9650226127485502
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Magnetic fluctuations in n-type high-$T_c$ superconductors reveal breakdown of fermiology .\nAbstract:\nWe report the observation of magnetic fluctuations at low temperatures and high fields in single crystals of YBa2Cu3O6+x (YBCO) with x=0.4, 0.45, and 0.5 using muon spin relaxation measurements. The data show that these materials are characterized by an unusual temperature dependence of the fluctuation rate which is not consistent with predictions based on Fermi liquid theory or any other conventional model for fermionic quasiparticles. We argue that this behavior can be understood within a phenomenological description of the electronic excitations as bosonic collective modes. These results provide strong evidence against the existence of well-defined fermionic quasiparticles in the normal state of these compounds. They also suggest that the pseudogap phase may have some features in common with the superfluid state. \n \n High-temperature cuprate superconductors exhibit many remarkable properties including a rich variety of competing ground states. In particular, it has been suggested that they undergo a quantum phase transition into a novel ordered state known as the  pseudogap  phase  1  . This phase appears to exist between the underdoped regime where there is no static order but only short-range correlations  2  , and the overdoped regime where antiferromagnetism disappears  3  . It is believed that the pseudogap state plays an important role in understanding the mechanism responsible for high-Tc superconductivity  4  .\nIn recent years much attention has focused on the possibility that the pseudogap is associated with preformed pairs of charge carriers  5  . However, despite considerable experimental effort  6  , direct evidence for such pairing remains elusive  7, 8  . One possible explanation for this lack of success is that the pseudogap does not arise directly from pair formation  9  . Instead, it could result from the condensation of another type of collective mode  10  . For example, if the pseudogap were related to the onset of density wave ordering  11  then one would expect to see signatures of its presence in the form of low-energy magnetic fluctuations  12  . Indeed, several experiments have reported the detection of such fluctuations  13  -  16  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Magnetic fluctuations in n - class high - $ T _ c $ superconductors reveal collapse of fermiology . Abstract : We report the observation of magnetic fluctuations at low temperatures and low fields in single crystals of YBa2Cu3O6 + x ( YBCO ) with x = 0 . 4 , 0 . 45 , and 0 . 5 utilizing muon spin relaxation measurements .The data reveal that these objects are marked by an peculiar thermal dependence of the fluctuation speed which is not consistent with predictions based on Fermi solid physics or any other usual description for fermionic quasiparticles . We argue that this behavior can be understood within a phenomenological explanation of the optical excitations as bosonic collective modes .These conclusions provide strong evidence against the existence of well - defined fermionic quasiparticles in the usual state of these compounds . They even propose that the pseudogap phase may have some features in common with the superfluid state .High - temperature cuprate superconductors exhibit several notable properties including a rich multitude of competing ground states . In particular , it has been proposed that they undergo a quantum phase shift into a novel ordered state known as the pseudogap phase 1 .This phase shows to arise between the underdoped regime where there is no static order but only low - range correlations 2 , and the overdoped regime where antiferromagnetism drops 3 . It is suspected that the pseudogap state plays an important role in understanding the process responsible for high - Tc superconductivity 4 .In recent years much attention has concentrated on the suggestion that the pseudogap is associated with preformed pairs of charge carriers 5 . However , despite considerable experimental effort 6 , direct data for such pairing remains elusive 7 , 8 .One potential explanation for this lack of failure is that the pseudogap does not occur immediately from pair formation 9 . Instead , it could occur from the condensation of another type of collective mode 10 .For instance , if the pseudogap were linked to the onset of density wave ordering 11 then one would expect to see signatures of its presence in the form of low - energy magnetic fluctuations 12 . Indeed , various tests have reported the detection of such fluctuations 13 - 16 .",
        "rewrite_text": "**Title:** Magnetic Fluctuations in n-Class High-Tc Superconductors Indicate Collapse of Fermiology\n\n**Abstract:** In this study, we present our findings on the magnetic fluctuations observed at low temperatures and low magnetic fields in single crystals of YBa2Cu3O6+x (YBCO) with x values of 0.4, 0.45, and 0.5, utilizing muon spin relaxation techniques. Our measurements reveal an unusual thermal dependence of the fluctuation speed that deviates from the predictions made by Fermi solid physics and traditional descriptions of fermionic quasiparticles. We propose that this behavior can be interpreted through a phenomenological framework that considers these fluctuations as bosonic collective modes rather than fermionic excitations. This interpretation provides compelling evidence against the presence of well-defined fermionic quasiparticles in the typical state of these materials, suggesting instead that the pseudogap phase may exhibit characteristics akin to a superfluid state.\n\nHigh-temperature cuprate superconductors are known for their complex properties, including a diverse array of competing ground states. Notably, it has been suggested that these materials undergo a quantum phase transition into a unique ordered state referred to as the pseudogap phase. This phase is believed to emerge between the underdoped regime, characterized by the absence of static order and the presence of only short-range correlations, and the overdoped regime, where antiferromagnetic order diminishes. The pseudogap state is thought to be crucial for understanding the mechanisms underlying high-Tc superconductivity.\n\nRecent research has focused on the hypothesis that the pseudogap is linked to the formation of preformed pairs of charge carriers. However, despite extensive experimental investigations, direct evidence for such pairing remains elusive. One possible explanation for this discrepancy is that the pseudogap may not arise directly from pair formation but rather from the condensation of a different type of collective mode. For example, if the pseudogap is associated with the onset of density wave ordering, we would expect to observe signatures of this phenomenon in the form of low-energy magnetic fluctuations. Indeed, various studies have reported the detection of such fluctuations, reinforcing the need for further exploration of these intriguing behaviors in high-Tc superconductors.",
        "ori-fast-z-score": 0.47733437050543803,
        "water-fast-z-score": 7.319127014416716,
        "rewrite-fast-z-score": 1.8717134551736667
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Isospin asymmetry in the continuum of the A=14 mirror nuclei .\nAbstract:\nWe present results on isospin symmetry breaking effects for the ground states and excited states of the mirror nuclei 14Be, 14B, 14C, and 14N using the shell model with realistic interactions. We find that the calculated energy differences between the mirror pairs are consistent with experimental data within uncertainties except for the case of 14N where we predict an excitation energy which is about 1 MeV higher than experiment.  The predicted excitation energies of the first 2+ state in 14Be agree well with those obtained by other theoretical calculations but differ significantly from experiments. This discrepancy may be due to missing three-body forces or possibly because our calculation does not include any explicit treatment of the continuum. Our results show that the effect of Coulomb interaction plays only minor role in determining the properties of these nuclei. In addition, we have studied the dependence of the calculated results on different single-particle wave functions used as input into the shell-model diagonalization procedure.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Isospin asymmetry in the continuum of the A = 14 reflection clusters . Abstract : We report findings on isospin symmetry breaking effects for the ground states and excited states of the mirror nuclei 14Be , 14B , 14C , and 14N using the shell model with realistic interactions .We see that the determined power differences between the mirror pairs are compatible with experimental evidence within uncertainties except for the case of 14N where we estimate an excitation energy which is about 1 MeV higher than study . The predicted excitation energies of the first 2 + state in 14Be agree well with those achieved by other theoretical calculations but varies much from experiments .This discrepancy may be due to missing three - bodies forces or possibly because our analysis does not include any explicit treatment of the continuum . Our results show that the impact of Coulomb interaction plays only minor importance in determining the properties of these nuclei .In addition , we have researched the dependence of the derived results on various single - particle wave systems applied as input into the shell - model diagonalization procedure .",
        "rewrite_text": "In this study, we investigate the effects of isospin symmetry breaking on the ground and excited states of the mirror nuclei 14Be, 14B, 14C, and 14N, utilizing the shell model with realistic interactions. Our analysis reveals that the power differences observed between the mirror pairs align well with existing experimental data, within the limits of uncertainty, with the exception of 14N. For this nucleus, we estimate an excitation energy approximately 1 MeV higher than previously reported studies. Furthermore, the predicted excitation energies for the first 2+ state in 14Be are consistent with other theoretical predictions; however, they diverge significantly from experimental results. This discrepancy may stem from the omission of three-body forces in our model or the lack of an explicit treatment of the continuum in our analysis. Our findings indicate that the influence of Coulomb interactions is relatively minor in shaping the properties of these nuclei. Additionally, we explore how the results are affected by varying the single-particle wave functions used as inputs in the shell-model diagonalization process. This comprehensive examination enhances our understanding of isospin asymmetry in the continuum of A = 14 reflection clusters and highlights the complexities involved in accurately modeling nuclear interactions.",
        "ori-fast-z-score": 1.078327732034384,
        "water-fast-z-score": 5.253351420705195,
        "rewrite-fast-z-score": 1.3627702877384937
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spin transport in magnetic multilayers .\nAbstract:\nThe spin current is the key concept for understanding and manipulating magnetism at nanoscale, which has been widely studied both experimentally and theoretically.  In this work we study the spin current through an interface between two ferromagnetic layers with different coercive fields by using the Landau-Lifshitz-Gilbert equation combined with the Slonczewski spin-transfer torque term. We find that there exists a critical field difference beyond which no steady state solution can be found. The results are consistent with previous experimental observations. This suggests that the spin current may play important roles on the switching process of magnetic multilayers. Spintronics is one of the most active research areas in condensed matter physics today  1-3 . It deals with the manipulation of electron spins instead of charge carriers to achieve novel electronic devices such as spin transistors  4  , spin logic gates  5  , etc.. One of its central concepts is the spin current  6  . A spin current is defined as the flow of angular momentum carried by electrons or holes  7-9 . Recently it was shown that the spin current plays crucial role in the switching processes of magnetic multilayers  10-12 . For example, when a spin-polarized current passes through a magnetic tunnel junction (MTJ), the injected spin current will exert a torque on the local magnetization due to the so-called spin-transfer effect  13  . If the applied voltage across the MTJ exceeds some threshold value, then the total torque exerted on the local magnetization becomes larger than the damping force so that the magnetization switches direction  14-16 . However, if the applied voltage is not large enough, the magnetization cannot switch even though the spin current keeps flowing  17  .\nIn order to understand how the spin current affects the switching behavior of magnetic multilayers, many theoretical studies have been performed recently  18-21 . Most of these works focus on studying the dynamics of the magnetization under external electric field  22, 23  . Very little attention has been paid to the effects of the spin current itself on the switching behaviors  24  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spin transport in magnetic multilayers . Abstract : The spin current is the key concept for studying and manipulating magnetism at nanoscale , which has been widely explored both experimentally and theoretically .In this research we study the spin current through an interface between two ferromagnetic layers with various coercive fields by using the Landau - Lifshitz - Gilbert formula coupled with the Slonczewski spin - transfer torque term . We see that there exists a critical field difference beyond which no steady state solution can be found .The results are compatible with previous experimental discoveries . This implies that the spin current may play important roles on the switching process of magnetic multilayers .Spintronics is one of the most important research areas in condensed matter science today 1 - 3 . It deals with the manipulation of electron spins rather of charge carriers to achieve interesting electronic systems such as spin transistors 4 , spin logic gates 5 , etc . . One of its core ideas is the spin current 6 .A spinning current is characterized as the movement of angular velocity carried by atoms or holes 7 - 9 . Recently it was shown that the spin current takes vital role in the switching processes of magnetic multilayers 10 - 12 .For instance , when a spinning - polarized current enters through a magnetic tunnel junction ( MTJ ) , the extracted spin current will exert a torque on the local magnetization owing to the so - called spin - transfer influence 13 . If the introduced voltage across the MTJ exceeds some threshold factor , then the total torque exerted on the local magnetization increases greater than the damping force so that the magnetization transitions direction 14 - 16 .However , if the introduced voltage is not large enough , the magnetization never shift even though the spin current keeps flowing 17 . In order to explain how the spin current influences the switching activity of magnetic multilayers , various computational studies have been performed recently 18 - 21 .Most of these works concentrate on studying the dynamics of the magnetization under external electric field 22 , 23 . Very little attention has been paid to the effects of the spin current itself on the switching interactions 24 .",
        "rewrite_text": "**Title: Spin Transport in Magnetic Multilayers**\n\n**Abstract:** The investigation of spin transport is pivotal for understanding and manipulating magnetism at the nanoscale, a topic that has garnered significant attention in both experimental and theoretical realms. This study focuses on the behavior of spin current at the interface between two ferromagnetic layers characterized by varying coercive fields. Utilizing the Landau-Lifshitz-Gilbert equation in conjunction with the Slonczewski spin-transfer torque term, we identify a critical difference in magnetic fields beyond which steady-state solutions become unattainable. Our findings align with previous experimental observations, suggesting that spin current plays a crucial role in the switching mechanisms of magnetic multilayers. \n\nSpintronics, a prominent field within condensed matter physics, emphasizes the manipulation of electron spins rather than merely their charge, leading to innovative electronic devices such as spin transistors and spin logic gates. Central to this field is the concept of spin current, which can be defined as the flow of angular momentum carried by electrons or holes. Recent studies have highlighted the essential function of spin current in the switching processes of magnetic multilayers. For example, when a spin-polarized current is injected into a magnetic tunnel junction (MTJ), the resulting spin current applies a torque on the local magnetization due to the spin-transfer effect. If the voltage across the MTJ surpasses a certain threshold, the torque on the magnetization exceeds the damping forces, resulting in a change in the magnetization direction. Conversely, if the voltage is insufficient, the magnetization remains static despite the continuous flow of spin current.\n\nWhile numerous computational studies have been conducted to explore the dynamics of magnetization under external electric fields, there has been limited focus on the direct effects of spin current on switching interactions. This research aims to bridge that gap by providing insights into how spin current influences the switching behavior of magnetic multilayers, thereby contributing to the broader understanding of spintronic phenomena.",
        "ori-fast-z-score": 0.38461538461538464,
        "water-fast-z-score": 6.95894392740704,
        "rewrite-fast-z-score": 1.348187695720845
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cosmological applications of a wavelet analysis on the sphere .\nAbstract:\nWe present an algorithm for computing spherical wavelets and their associated scaling functions, which are used to analyze data defined over the unit sphere in three dimensions. The method is based on a decomposition into spherical harmonics and can be applied to any function that has been expanded as such. We show how this approach allows one to perform fast calculations of convolutions between two spherical signals or between a signal and its Fourier transform. As examples we apply our technique to calculate correlation functions of CMB temperature fluctuations and to compute power spectra of simulated galaxy surveys. Finally, we discuss possible extensions of these methods to higher-dimensional spaces. Wavelets have become popular tools for analyzing various types of data sets ranging from images to time series. In cosmology they were first introduced by Bond & Efstathiou (1987) who showed how they could be used to efficiently calculate angular correlations of cosmic microwave background radiation (CMB). Since then many authors have employed wavelets to study different aspects of large-scale structure formation including the evolution of dark matter haloes (e.g., Colombi et al. (1998) ), gravitational lensing effects (e.g., Jain et al. (2000)), weak gravitational lensing statistics (e.g., Schneider et al. (2002)) , and the clustering properties of galaxies (e.g., Percival et al. (2003)). However, all previous studies focused exclusively on flat space where it was straightforward to define wavelets using translations and dilations of mother wavelets. This situation changes dramatically when considering three-dimensional data sets like those obtained with modern astronomical instruments. Here, the concept of translation becomes ambiguous because there exists no unique way to identify corresponding points at different locations within the sample volume. Moreover, the notion of scale loses its meaning since distances cannot be measured directly but only inferred indirectly through redshift distortions caused by peculiar velocities.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cosmological applications of a wavelet analysis on the sphere . Abstract : We present an algorithm for modeling spherical wavelets and their accompanying scaling functions , which are using to analyze information defined over the unit sphere in three dimensions .The method is based on a transformation into spherical harmonics and can be applied to any function that has been expanded as such . We see how this methodology allows one to conduct fast calculations of convolutions between two spherical waves or between a signal and its Fourier shift .As instance we apply our technique to estimate correlation functions of CMB heat fluctuations and to compute power spectra of virtual galaxy surveys . Finally , we explain possible extend of these algorithms to higher - dimensional spaces .Wavelets have developed popular tools for searching various types of statistics sets ranging from images to time series . In cosmology they were first developed by Bond & Efstathiou ( 1987 ) who demonstrated how they could be used to easily predict angular correlations of cosmic microwave background radiation ( CMB ) .Since then many writers have utilized wavelets to study various details of large - scale system formation including the evolution of dark matter haloes ( e . g . , Colombi et al . ( 1998 ) ) , gravity lensing effects ( e . g . , Jain et al .( 2000 ) ) , weak gravitational lensing statistics ( e . g . , Schneider et al . ( 2002 ) ) , and the clustering behavior of galaxies ( e . g . , Percival et al .( 2003 ) ) . However , all previous research focused exclusively on straight space where it was straightforward to define wavelets using translations and dilations of parent wavelets .This condition shifts significantly when assessing three - dimensional data sets like those acquired with modern astronomical equipment . Here , the notion of translation becomes obscure because there exists no unique way to identify corresponding points at different places within the sample volume .Moreover , the notion of scale loses its significance since distances never be measured immediately but only inferred indirectly through redshift distortions caused by unique velocities .",
        "rewrite_text": "We introduce a novel algorithm for modeling spherical wavelets and their associated scaling functions, designed for analyzing data defined over the unit sphere in three-dimensional space. This approach leverages a transformation into spherical harmonics, making it applicable to any function that can be expressed in this form. Our methodology facilitates rapid computations of convolutions between two spherical wavelets or between a signal and its Fourier shift. To illustrate the effectiveness of our technique, we apply it to estimate correlation functions of cosmic microwave background (CMB) temperature fluctuations and to compute power spectra for simulated galaxy surveys. Additionally, we discuss the potential for extending these algorithms to higher-dimensional spaces.\n\nWavelets have emerged as powerful tools for analyzing various statistical datasets, including images and time series. In the field of cosmology, their application was first pioneered by Bond and Efstathiou in 1987, who demonstrated their utility in predicting angular correlations of CMB radiation. Since then, numerous studies have employed wavelet analysis to investigate various aspects of large-scale structure formation, such as the evolution of dark matter halos (Colombi et al., 1998), gravitational lensing effects (Jain et al., 2000), weak gravitational lensing statistics (Schneider et al., 2002), and galaxy clustering behavior (Percival et al., 2003). \n\nHowever, prior research has predominantly focused on flat spaces, where defining wavelets through translations and dilations of parent wavelets is straightforward. This paradigm shifts significantly when dealing with three-dimensional datasets obtained from contemporary astronomical instruments. In this context, the concept of translation becomes ambiguous, as there is no unique method to identify corresponding points across different locations within the sample volume. Furthermore, the notion of scale becomes less meaningful, as distances can only be inferred indirectly through redshift distortions resulting from peculiar velocities. Our work addresses these challenges, paving the way for more effective analysis of complex cosmological data.",
        "ori-fast-z-score": -1.0120486274099798,
        "water-fast-z-score": 7.652514332541697,
        "rewrite-fast-z-score": 0.6620847108818944
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Electronic Properties of Carbon Nanotubes Calculated from Density Functional Theory and the Empirical pi-Bond Model .\nAbstract:\nThe electronic properties of carbon nanotubes are calculated using density functional theory (DFT) with the local-density approximation (LDA). The results show that the band gap decreases as tube diameter increases, which is in agreement with previous calculations based on tight-binding models. In addition to this effect, we find that the energy difference between the highest occupied molecular orbital (HOMO) and lowest unoccupied molecular orbital (LUMO), i.e., the HOMO-LUMO gap also depends strongly on tube diameter. We propose an empirical model for calculating these gaps by fitting our data points to simple functions of tube diameter. This model can be used to predict the electronic structure of any given carbon nanotube within reasonable accuracy. Finally, we discuss how the presence of defects affects the electronic structure of carbon nanotubes. The electronic properties of carbon nanotubes  are investigated theoretically using density-functional-theory (DFT) with LDA. It has been found that both the valence-band maximum (VBM) and conduction-band minimum (CBM) shift towards higher energies when the tube diameter increases. Furthermore, it was observed that the VBM shifts more rapidly than CBM so that the bandgap decreases as the tube diameter increases. An empirical model is proposed to calculate the bandgaps of carbon nanotubes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Electronic Properties of Carbon Nanotubes Calculated from Density Functional Theory and the Empirical pi - Bond Model . Abstract : The electronic properties of carbon nanotubes are measured using density functional theory ( DFT ) with the local - density approximation ( LDA ) .The results show that the band gap decreases as tube diameter increases , which is in agreement with previous calculations based on tight - binding methods . In addition to this effect , we find that the electricity difference between the highest occupied molecular orbital ( HOMO ) and lowest unoccupied molecular orbital ( LUMO ) , i . e . , the HOMO - LUMO gap still depends strongly on pipe width .We suggest an empirical description for determining these gaps by fitting our information points to small functions of tube diameter . This theory can be used to predict the electronic configuration of any given carbon nanotube within reasonable accuracy .Finally , we talk how the presence of flaws impacts the electronic properties of carbon nanotubes . The electronic properties of carbon nanotubes are examined theoretically utilizing density - functional - theory ( DFT ) with LDA .It has been seen that both the valence - band highest ( VBM ) and conduction - band minimum ( CBM ) change towards higher energies when the tube diameter increases . Furthermore , it was seen that the VBM moves more swiftly than CBM so that the bandgap decreases as the pipe width rises .An empirical theory is proposed to estimate the bandgaps of carbon nanotubes .",
        "rewrite_text": "Title: Electronic Properties of Carbon Nanotubes Analyzed through Density Functional Theory and the Empirical π-Bond Model\n\nAbstract: This study investigates the electronic properties of carbon nanotubes using density functional theory (DFT) with the local-density approximation (LDA). Our findings reveal a significant relationship between the diameter of the nanotubes and their electronic characteristics, specifically noting that the band gap diminishes as the tube diameter increases. This observation aligns with previous results derived from tight-binding models. Additionally, we explore the energy difference between the highest occupied molecular orbital (HOMO) and the lowest unoccupied molecular orbital (LUMO), referred to as the HOMO-LUMO gap, which remains highly sensitive to variations in tube width. To facilitate the prediction of these electronic gaps, we propose an empirical model that fits our data points to simple functions of the tube diameter, enabling accurate estimations of the electronic configurations for various carbon nanotubes.\n\nMoreover, we discuss the implications of structural imperfections on the electronic properties of carbon nanotubes. The theoretical analysis indicates that both the valence band maximum (VBM) and conduction band minimum (CBM) shift to higher energy levels with increasing tube diameter. Notably, the VBM exhibits a more pronounced shift compared to the CBM, resulting in a reduction of the band gap as the diameter expands. Our empirical approach provides a valuable framework for estimating the band gaps of carbon nanotubes, enhancing the understanding of their electronic behavior in practical applications. This research contributes to the broader field of nanotechnology by offering insights into the tunability of electronic properties in carbon nanotubes, which are critical for their use in various electronic devices and materials science.",
        "ori-fast-z-score": -0.6527533657682196,
        "water-fast-z-score": 5.269651864139676,
        "rewrite-fast-z-score": 0.6024640760767093
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Investigations of the Non-Linear LMC Cepheid Period-Luminosity Relation with Testimator and Schwarz Information Criterion Methods .\nAbstract:\nThe Large Magellanic Cloud (LMC) is an ideal laboratory for studying Galactic structure, stellar populations, chemical evolution, and cosmology because it has many advantages over other nearby galaxies such as M31 or M33.  The distance to the LMC can be determined by using Cepheids which are bright periodic variable stars that pulsate in radial fundamental mode. In this study we used two different methods to determine distances to Cepheids in the LMC. First method was based on non-linear least squares fitting technique called testimator while second one was based on statistical analysis known as Schwarz information criterion (SIC). We found that both methods gave consistent results within their uncertainties. Our final sample consists of 1228 Cepheids located between 30 < R < 50 kpc from the center of the galaxy. Using these data sets we derived new period-luminosity relations for classical Cepheids in the infrared bands JHKs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Investigations of the Non - Linear LMC Cepheid Period - Luminosity Relation with Testimator and Schwarz Information Criterion Methods . Abstract : The Large Magellanic Cloud ( LMC ) is an excellent laboratory for studying Galactic structure , planetary populations , chemical evolution , and cosmology because it has numerous benefits over other nearby galaxies such as M31 or M33 .The distance to the LMC can be determined by using Cepheids which are bright periodic variable stars that pulsate in radial fundamental mode . In this study we using two different methods to find distances to Cepheids in the LMC .First method was based on non - linear least squares fit technique called testimator while second one was based on statistical analysis called as Schwarz evidence criterion ( SIC ) . We showed that both approaches made satisfactory findings within their uncertainties .Our last sample consists of 1228 Cepheids situated between 30 < R < 50 kpc from the center of the universe . Using these information sets we derived additional time - luminosity relations for classical Cepheids in the infrared bands JHKs .",
        "rewrite_text": "Title: Investigations of the Non-Linear LMC Cepheid Period-Luminosity Relation Using Testimator and Schwarz Information Criterion Methods\n\nAbstract: The Large Magellanic Cloud (LMC) serves as an exceptional environment for exploring various aspects of Galactic structure, planetary populations, chemical evolution, and cosmology, offering distinct advantages over other nearby galaxies such as M31 and M33. A key method for determining the distance to the LMC involves the use of Cepheid variables, which are luminous stars that exhibit periodic pulsations in their fundamental radial mode. This study employs two distinct methodologies to ascertain the distances to Cepheids located within the LMC. The first approach utilizes a non-linear least squares fitting technique known as Testimator, while the second method relies on a statistical framework referred to as the Schwarz Information Criterion (SIC). Our analysis demonstrates that both techniques yield reliable results within their respective uncertainties. The final dataset comprises 1,228 Cepheids located at distances ranging from 30 to 50 kiloparsecs from the center of the universe. Leveraging this comprehensive dataset, we further derived additional time-luminosity relations for classical Cepheids across infrared bands, specifically in J, H, and Ks wavelengths. This research not only enhances our understanding of the Cepheid period-luminosity relationship but also contributes valuable insights into the broader implications for distance measurement and cosmic structure in the context of the LMC.",
        "ori-fast-z-score": 0.9428090415820635,
        "water-fast-z-score": 5.892556509887896,
        "rewrite-fast-z-score": 2.013995972012084
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Point-contact spectroscopy of the antiferromagnetic superconductor HoNi2B2C in the normal and superconducting state .\nAbstract:\nWe report on point contact Andreev reflection (PCAR) measurements performed on single crystals of the heavy fermion compound HoNi2B2C, which is an antiferromagnet with T N = 1.5 K that becomes a type-II superconductor below Tc = 0.8 K. The PCAR spectra show clear evidence for multiple gaps at low temperatures. We find two distinct gap values, one of them being close to twice the value of the other. This observation suggests that there are two different bands crossing the Fermi level. In addition we observe a temperature dependence of both gaps indicating their nodal character. Our results provide further insight into the electronic structure of this material. Heavy-fermion compounds have attracted considerable interest over recent years because they often exhibit unconventional physical properties such as non-Fermi liquid behavior or even quantum criticality  1  . These materials can be described by the periodic Anderson model  2  , where conduction electrons hybridize strongly with localized f -electrons leading to the formation of narrow bands near the Fermi energy E F  3  .\nHoNi 2 B 2 C belongs to the family of so-called borocarbides  4  . It crystallizes in the tetragonal ThCr 2 Si 2 structure  5  and has been shown to become a type-II superconductor  6  below T c ≈ 0.8 K  7, 8  . At ambient pressure it orders magnetically around T N = 1.6 K  9  . Recent studies suggest that the magnetic order is driven by strong spin-orbit coupling  10  . A number of experiments indicate that the ground-state wave function consists of singlet pairs  11, 12  . However, the exact nature of the pairing mechanism remains unclear  13  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Point - touch spectroscopy of the antiferromagnetic superconductor HoNi2B2C in the usual and superconducting state . Abstract : We report on point touch Andreev reflection ( PCAR ) observations performed on single crystals of the heavy fermion compound HoNi2B2C , which is an antiferromagnet with T N = 1 . 5 K that remains a class - II superconductor below Tc = 0 . 8 K . The PCAR spectra show good evidence for multiple gaps at low temperatures .We see two different gap values , one of them being close to double the value of the other . This observation suggests that there are two different bands crossing the Fermi level .In addition we study a temperature dependence of both gaps indicating their nodal nature . Our results yield further insight into the electronic stability of this material .Heavy - fermion compounds have garnered considerable interest over recent history because they frequently exhibit unusual physical properties such as non - Fermi solid behavior or even quantum criticality 1 . These substances can be described by the periodic Anderson model 2 , where conduction electrons hybridize heavily with localized f - ions causing to the formation of broad bands near the Fermi energy E F 3 .HoNi 2 B 2 C belongs to the class of so - called borocarbides 4 . It crystallizes in the tetragonal ThCr 2 Si 2 structure 5 and has been shown to become a class - II superconductor 6 below T c ≈ 0 . 8 K 7 , 8 .At ambient temperature it orders magnetically around T N = 1 . 6 K 9 . Recent research suggest that the magnetic order is generated by strong spin - orbit interaction 10 .A variety of studies imply that the ground - state wave function consists of singlet sets 11 , 12 . However , the exact nature of the pairing structure remains unclear 13 .",
        "rewrite_text": "We present a detailed study of point contact Andreev reflection (PCAR) measurements conducted on single crystals of the heavy fermion compound HoNi2B2C, which exhibits antiferromagnetic properties with a Néel temperature (T_N) of 1.5 K and transitions to a class-II superconductor below a critical temperature (T_c) of approximately 0.8 K. Our PCAR spectra reveal compelling evidence for the presence of multiple superconducting gaps at low temperatures, with two distinct gap values observed—one nearly double the other. This finding implies the existence of two separate bands that intersect the Fermi level, suggesting a complex electronic structure. Furthermore, we investigate the temperature dependence of these gaps, which indicates their nodal characteristics. These results enhance our understanding of the electronic stability of HoNi2B2C, a compound that has attracted significant attention due to its intriguing physical properties, such as non-Fermi liquid behavior and potential quantum criticality. Heavy fermion systems like HoNi2B2C can be effectively described by the periodic Anderson model, where the strong hybridization between conduction electrons and localized f-electrons leads to the formation of broad bands near the Fermi energy (E_F). HoNi2B2C is classified among the borocarbides and crystallizes in the tetragonal ThCr2Si2 structure. It has been established that this compound becomes a class-II superconductor below T_c ≈ 0.8 K, while at room temperature, it exhibits magnetic ordering around T_N = 1.6 K. Recent studies suggest that the magnetic order may arise from significant spin-orbit coupling, and various investigations indicate that the ground-state wave function is composed of singlet pairs. However, the precise nature of the pairing mechanism in this material remains an open question, warranting further exploration.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.6996452071463715,
        "rewrite-fast-z-score": 0.26620695282483414
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A study of uranium-based multilayers: I. Fabrication and structural characterisation .\nAbstract:\nThe fabrication, structure and properties of uranium oxide (UO 2 )/uranium nitride (UN) superlattices are reported in this work. The UO 2 /UN superlattice was grown on Si(100) substrates by pulsed laser deposition using an excimer KrF laser operating at 248 nm with a repetition rate of 10 Hz. A series of samples were prepared under different conditions to investigate the effects of substrate temperature T s , oxygen partial pressure P O 2 and nitrogen partial pressure P N 2 . X-ray diffraction measurements show that all the films have a single phase corresponding to the tetragonal structure of UN. The lattice parameters c and a increase slightly as the growth temperature increases from 300 °C to 600 °C. The results also indicate that the film thickness decreases when increasing either P O 2 or P N 2 .\nTransmission electron microscopy shows that the interface between the two layers is sharp without any interfacial layer.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A review of uranium - based multilayers : I . Fabrication and structural characterisation .Abstract : The fabrication , structure and properties of uranium alloy ( UO 2 ) / uranium nitride ( UN ) superlattices are published in this project . The UO 2 / UN superlattice was grown on Si ( 100 ) substrates by pulsed infrared deposition use an excimer KrF laser running at 248 nm with a repetition rate of 10 Hz .A series of samples were prepared under various circumstances to examine the effects of substrate temperature T s , oxygen partial pressure P O 2 and oxygen partial pressure P N 2 . X - ray diffraction measurements show that all the films have a single phase relating to the tetragonal shape of UN .The lattice parameters c and a increase somewhat as the growth temperature increases from 300 °C to 600 °C . The results also suggest that the film thickness decreases when varying either P O 2 or P N 2 .Transmission electron microscopy demonstrates that the interface between the two layers is sharp without any interfacial layer .",
        "rewrite_text": "Title: A Review of Uranium-Based Multilayers: I. Fabrication and Structural Characterization\n\nAbstract: This article presents a comprehensive investigation into the fabrication, structural characteristics, and properties of uranium alloy (UO2) and uranium nitride (UN) superlattices. The UO2/UN superlattice structures were successfully synthesized on silicon (Si) (100) substrates utilizing pulsed infrared deposition techniques, employing an excimer KrF laser operating at a wavelength of 248 nm and a repetition rate of 10 Hz. A systematic series of samples were produced under varying conditions to assess the influence of substrate temperature (Ts), oxygen partial pressure (PO2), and nitrogen partial pressure (PN2) on the resulting films. X-ray diffraction analysis confirmed that all synthesized films exhibited a single-phase structure corresponding to the tetragonal configuration of UN. Notably, the lattice parameters, both c and a, demonstrated a slight increase with rising growth temperatures, ranging from 300 °C to 600 °C. Additionally, the findings indicated a reduction in film thickness when adjusting either PO2 or PN2, suggesting a correlation between gas pressures and layer formation. Transmission electron microscopy (TEM) further revealed that the interface between the UO2 and UN layers remained sharp, with no discernible interfacial layer present. This study not only elucidates the fabrication processes and structural properties of uranium-based multilayers but also lays the groundwork for future research into their potential applications in various fields, including nuclear materials and advanced coatings. The insights gained from this work contribute significantly to the understanding of uranium alloy superlattices and their unique characteristics, paving the way for further exploration and development in this area of materials science.",
        "ori-fast-z-score": -0.917662935482247,
        "water-fast-z-score": 3.4412360080584263,
        "rewrite-fast-z-score": -0.3592106040535498
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Capacity Gain from Two-Transmitter and Two-Receiver Cooperation .\nAbstract:\nWe consider the problem of two-user MIMO broadcast channel with multiple antennas at each transmitter, receiver pair. We propose an iterative algorithm to maximize the sum capacity by jointly optimizing transmit covariance matrices for both transmitters subject to power constraints. The proposed algorithm is based on alternating optimization between the users  precoding matrices. In addition, we show that the optimal solution can be obtained in closed form when one user has more receive than transmit antennas while the other user has less or equal number of receive as well as transmit antennas. Finally, numerical results are presented to demonstrate the performance gain achieved using our proposed scheme over existing schemes. Index Terms: Broadcast Channel (BC), Iterative Algorithm, Joint Transmission, Multiple Input Multiple Output (MIMO). 1 Introduction Wireless communication systems have been widely deployed recently due to their high data rate transmission capability  1  . However, wireless channels suffer from multipath fading which causes severe inter-symbol interference (ISI)  2  , resulting in poor system performance. To overcome this issue, orthogonal frequency division multiplexing (OFDM)  3  was introduced into wireless communications. OFDM divides the available bandwidth into several narrowband subcarriers so that ISI can be reduced significantly  4  .\nIn order to further improve spectral efficiency, multi-antenna techniques were incorporated into OFDM-based systems  5  -  8  . For example, Alamouti s space-time block coding  9  was applied to single-carrier systems  10  -  12  . Moreover, it was shown that spatial diversity could also be exploited through cooperative relaying  13  -  15  . Recently, there has been growing interest in exploiting cooperation among different nodes  16  -  18  . It was demonstrated that significant gains can be achieved if all cooperating nodes use joint transmission  19  -  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Capacity Gain from Two - Transmitter and Two - Receiver Cooperation . Abstract : We consider the issue of two - user MIMO television broadcast with many antennas at each antenna , receiver pair .We suggest an iterative algorithm to maximize the sum capacity by jointly optimizing transmit covariance matrices for both transmitters subject to power limitations . The proposed algorithm is based on alternating optimization between the users precoding matrices .In addition , we prove that the ideal solution can be obtained in closed form when one customer has more receive than receive antennas while the other customer has less or equal number of receive as well as receive antennas . Finally , numerical findings are presented to indicate the performance gain achieved using our proposed system over existing arrangements .Index Terms : Broadcast Channel ( BC ) , Iterative Algorithm , Joint Transmission , Multiple Input Multiple Output ( MIMO ) . 1 Introduction Wireless transport systems have been widely deployed recently thanks to their high data rate transmission capability 1 .However , wireless networks suffer from multipath fading which results severe inter - symbol noise ( ISI ) 2 , leading in poor device performance . To solve this situation , orthogonal frequency division multiplexing ( OFDM ) 3 was introduced into wireless communications .OFDM separates the provided bandwidth into various narrowband subcarriers so that ISI can be reduced significantly 4 . In order to further enhance spectral capacity , multi - antenna techniques were incorporated into OFDM - based units 5 - 8 .For instance , Alamouti s space - time block code 9 was used to single - carrier systems 10 - 12 . Moreover , it was shown that spatial diversity could also be exploited through cooperative relaying 13 - 15 .Recently , there has been growing interest in exploiting cooperation among different nodes 16 - 18 . It was demonstrated that significant improvements can be obtained if all cooperating nodes use joint transmission 19 - 21 .",
        "rewrite_text": "**Title:** Capacity Gain from Two-Transmitter and Two-Receiver Cooperation\n\n**Abstract:** This article addresses the challenges associated with two-user MIMO (Multiple Input Multiple Output) television broadcasting, where each user is equipped with multiple antennas. We propose an innovative iterative algorithm aimed at maximizing the overall capacity of the system by jointly optimizing the transmit covariance matrices for both transmitters, while adhering to power constraints. The core of our approach lies in an alternating optimization technique that focuses on the precoding matrices of the users. Notably, we establish that an optimal solution can be derived in closed form under specific conditions: when one user possesses a greater number of receiving antennas compared to the other, which has an equal or fewer number of antennas. To validate our theoretical findings, we present numerical simulations that demonstrate the performance enhancements achieved through our proposed cooperative system, in comparison to existing configurations. Our results indicate a significant capacity gain, underscoring the effectiveness of joint transmission strategies in MIMO broadcast scenarios. This work contributes to the ongoing discourse on improving wireless communication systems by leveraging cooperative techniques among multiple transmitters and receivers. \n\n**Index Terms:** Broadcast Channel (BC), Iterative Algorithm, Joint Transmission, Multiple Input Multiple Output (MIMO). \n\n**1 Introduction:** The deployment of wireless transport systems has surged in recent years, primarily due to their capability for high data rate transmissions. However, these systems are often hindered by multipath fading, which can lead to severe inter-symbol interference (ISI) and subsequently degrade device performance. To mitigate these issues, orthogonal frequency division multiplexing (OFDM) has been introduced, effectively partitioning the available bandwidth into narrowband subcarriers to significantly reduce ISI. Furthermore, the integration of multi-antenna techniques into OFDM systems has been explored to enhance spectral efficiency. For example, Alamouti's space-time block coding has been applied to single-carrier systems, and the potential for spatial diversity through cooperative relaying has been demonstrated. Recently, there has been an increasing interest in harnessing cooperation among various nodes, with evidence suggesting that substantial improvements in performance can be achieved when all cooperating nodes engage in joint transmission.",
        "ori-fast-z-score": 0.2544566789039913,
        "water-fast-z-score": 7.216959681351526,
        "rewrite-fast-z-score": 0.7905694150420948
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Switching mechanism of photochromic diarylethene derivatives molecular junctions .\nAbstract:\nThe switching behavior and the photovoltaic properties of two new diarylethene derivative molecular junctions were investigated by using cyclic voltammetry, UV-Vis spectroscopy, and electrochemical impedance spectroscopy (EIS). The results show that both compounds can be switched between their open-ring isomer state and closed-ring isomer state in solution with different colors under visible light irradiation at room temperature. In addition to this reversible color change process, the photocurrent response was also observed for these molecules when they are used as active layers in organic solar cells. This work provides an insight into the relationship between the structure and function of diarylethene-based molecular switches. Switchable materials have attracted great attention because of their potential applications in optoelectronic devices such as optical memory storage systems, smart windows, and organic solar cells. \n \n Diarylethenes belong to one class of switchable materials which undergoes a rapid and complete structural transformation upon exposure to ultraviolet or visible light.  1  These unique features make them promising candidates for use in various fields including chemical sensors  2  , data storage  3  , and organic electronics  4  . However, most reported diarylethene based molecular switches suffer from poor solubility in common solvents  5  , low quantum yield  6  , and slow response time  7  . Therefore, it remains challenging to develop efficient diarylethene molecular switches with improved performance  8  .\n \nIn recent years, many efforts have been made to improve the performances of diarylethenes  9  -  11  . For example, some researchers introduced bulky substituents on the carbon atoms adjacent to the double bond  12  -  14  ; others synthesized diarylethenes containing electron-donating groups  15  -  17  . Although these modifications could enhance the solubility and quantum efficiency of diarylethens, the response times still remain relatively slow  18  . \n \n Herein we report two novel diarylethene dyes 1 and 2 ( Figure  1 ) bearing electron-withdrawing groups. Both compounds exhibit good solubility in common organic solvents and high quantum yields. They can",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Switching mechanism of photochromic diarylethene derivatives molecular junctions . Abstract : The switching behavior and the photovoltaic properties of two new diarylethene derivative chemical junctions were researched by using cyclic voltammetry , UV - Vis spectroscopy , and electrochemical impedance spectroscopy ( EIS ) .The results show that both chemicals can be switched between their open - ring isomer state and opened - ring isomer state in solution with various shades under visible light irradiation at room temperature . In addition to this reversible color transformation process , the photocurrent response was also observed for these molecules when they are using as active layers in organic solar cells .This research provides an insight into the relationship between the composition and activity of diarylethene - based molecular switches . Switchable materials have garnered great attention because of their potential applications in optoelectronic devices such as laser memory processing systems , smart panels , and organic solar devices .Diarylethenes come to one category of switchable materials which undergoes a rapid and complete structural transformation upon exposure to ultraviolet or visible light . 1 These unique features make them promising candidates for use in different fields specifically chemical sensors 2 , computer processing 3 , and organic computers 4 .However , most reported diarylethene based molecular switches result from poor solubility in standard solvents 5 , low quantum strength 6 , and poor response period 7 . Therefore , it remains challenging to develop efficient diarylethene molecular switches with improved performance 8 .In recent years , various efforts have been made to improve the performances of diarylethenes 9 - 11 . For instance , some researchers implemented bulky substituents on the carbon atoms adjacent to the double bond 12 - 14 ; others synthesized diarylethenes featuring electron - donating groups 15 - 17 .Although these alterations could enhance the solubility and quantum efficiency of diarylethens , the response periods currently continue relatively slow 18 . Herein we study two novel diarylethene dyes 1 and 2 ( Figure 1 ) containing electron - withdrawing groups .Both compounds exhibit great solubility in common organic solvents and large quantum yields . They can",
        "rewrite_text": "Title: Switching Mechanism of Photochromic Diarylethene Derivatives in Molecular Junctions\n\nAbstract: This study investigates the switching behavior and photovoltaic characteristics of two novel diarylethene derivative molecular junctions through a combination of cyclic voltammetry, UV-Vis spectroscopy, and electrochemical impedance spectroscopy (EIS). The findings reveal that both diarylethene derivatives can be reversibly switched between their open-ring and closed-ring isomer states in solution when exposed to various wavelengths of visible light at room temperature. This reversible color change is accompanied by a notable photocurrent response when these compounds are utilized as active layers in organic solar cells. The research sheds light on the intricate relationship between the molecular composition and the functional activity of diarylethene-based molecular switches.\n\nThe significance of switchable materials has gained momentum due to their promising applications in optoelectronic devices, including laser memory systems, smart panels, and organic solar cells. Diarylethenes, a prominent class of switchable materials, undergo rapid and complete structural transformations upon exposure to ultraviolet or visible light, making them ideal candidates for various applications such as chemical sensors, computational processing, and organic computing. However, many existing diarylethene-based molecular switches suffer from limitations such as poor solubility in standard solvents, low quantum efficiency, and sluggish response times.\n\nRecent advancements have aimed to enhance the performance of diarylethenes, with researchers exploring modifications such as the introduction of bulky substituents on adjacent carbon atoms and the synthesis of derivatives featuring electron-donating groups. While these strategies have improved solubility and quantum efficiency, the response times remain relatively slow. In this work, we present two innovative diarylethene dyes, designated as 1 and 2, which incorporate electron-withdrawing groups. Both compounds demonstrate excellent solubility in common organic solvents and exhibit high quantum yields, thus addressing some of the challenges faced by previous diarylethene derivatives. This research contributes to the ongoing development of efficient diarylethene molecular switches with enhanced performance characteristics.",
        "ori-fast-z-score": -1.0932163332202425,
        "water-fast-z-score": 5.433053679944329,
        "rewrite-fast-z-score": 0.8006407690254357
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Probing polarization states of primordial gravitational waves with CMB anisotropies .\nAbstract:\nWe study the effects on cosmic microwave background (CMB) temperature and polarization anisotropies induced by tensor perturbations in the early universe, which are generated through inflationary processes or other mechanisms. We show that these tensor perturbations can be probed via their imprints on the Stokes parameters Q and U . In particular, we find that the correlation between the two Stokes parameters is proportional to the amplitude of the tensor perturbation at large scales. This effect may provide an important test for models of inflation as well as alternative scenarios such as topological defects. \n \n The recent detection of B-mode polarizations in the CMB  1  has opened up new opportunities to probe physics beyond standard cosmology  2  , including primordial gravitational waves  3  produced during inflation  4  . However, it remains unclear whether this signal arises primarily due to scalar fluctuations  5  or primordial gravitational waves  6  .\n \n \n Tensor modes also induce non-Gaussianities  7, 8  in the primordial curvature perturbation ζ  9  . These non-Gaussianities have been studied extensively  10 - 12  using different approaches  13 - 15  . It was shown  16  that the bispectrum of the primordial curvature perturbation contains information about both the power spectrum Pζ(k) and the spectral index ns  17  of the tensor mode. Recently, Ref.  18  showed that the trispectrum of the primordial curvature perturbations contains additional information about the tensor-to-scalar ratio r = 16PT /PS where PT denotes the power spectrum of the tensor mode and PS denotes the power spectrum of its corresponding scalar counterpart.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Probing polarization states of primordial gravitational waves with CMB anisotropies . Abstract : We research the effects on cosmic microwave background ( CMB ) temperature and polarization anisotropies induced by tensor perturbations in the early universe , which are produced through inflationary processes or other mechanisms .We see that these vector perturbations can be probed via their imprints on the Stokes variables Q and U . In particular , we find that the relationship between the two Stokes variables is proportional to the frequency of the tensor perturbation at large scales .This phenomenon might give an important test for models of inflation as well as additional situations such as topological errors . The recent discovery of B - mode polarizations in the CMB 1 has opened up new opportunities to probe mechanics beyond standard cosmology 2 , notably primordial gravitational waves 3 created during inflation 4 .However , it remains unsure whether this signal exists largely owing to scalar fluctuations 5 or primordial gravitational waves 6 . Tensor modes also induce non - Gaussianities 7 , 8 in the primordial curvature perturbation ζ 9 .These non - Gaussianities have been studied thoroughly 10 - 12 using separate approaches 13 - 15 . It was shown 16 that the bispectrum of the primordial curvature perturbation contains information about both the power spectrum Pζ ( k ) and the spectral index ns 17 of the tensor mode .Recently , Ref . 18 demonstrated that the trispectrum of the primordial curvature perturbations contains additional information about the tensor - to - scalar ratio r = 16PT / PS where PT denotes the power spectrum of the tensor mode and PS refers the power spectrum of its equivalent scalar counterpart .",
        "rewrite_text": "In this study, we investigate the impact of tensor perturbations on the cosmic microwave background (CMB) temperature and polarization anisotropies, which arise from inflationary processes or other mechanisms in the early universe. Our analysis reveals that these tensor perturbations can be effectively examined through their effects on the Stokes parameters Q and U. Notably, we establish a proportional relationship between these two Stokes variables and the frequency of the tensor perturbations at large scales. This finding could serve as a significant test for various inflationary models and other scenarios, such as those involving topological defects.\n\nThe recent detection of B-mode polarization in the CMB has opened new avenues for exploring phenomena beyond the standard cosmological framework, particularly the presence of primordial gravitational waves generated during the inflationary epoch. However, the origin of this signal remains uncertain, with ongoing debates about whether it is predominantly influenced by scalar fluctuations or by primordial gravitational waves. Additionally, tensor modes contribute to non-Gaussianities in the primordial curvature perturbation ζ, which have been extensively analyzed using various methodologies.\n\nPrevious research has demonstrated that the bispectrum of the primordial curvature perturbation encodes valuable information regarding both the power spectrum Pζ(k) and the spectral index ns of the tensor modes. Furthermore, recent findings indicate that the trispectrum of these primordial curvature perturbations provides further insights into the tensor-to-scalar ratio r, defined as r = 16PT/PS, where PT represents the power spectrum of the tensor modes and PS corresponds to that of the scalar modes. This comprehensive investigation into the polarization states of primordial gravitational waves through CMB anisotropies not only enhances our understanding of the early universe but also offers critical tests for theoretical models of inflation and cosmic structure formation.",
        "ori-fast-z-score": -0.6831300510639733,
        "water-fast-z-score": 4.884914054627872,
        "rewrite-fast-z-score": 0.5477225575051661
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Boolean network model predicts cell cycle sequence of fission yeast .\nAbstract:\nThe Boolean Network (BN) is an important class of models for the analysis and prediction of gene regulatory networks, which are used to describe how genes interact with each other in biological systems. In this study we use BNs as a tool to predict the order of events during the cell division process of the fission yeast Schizosaccharomyces pombe. We construct two different BNs using data obtained by microarray experiments performed on synchronized cultures at four time points along the cell cycle. The first BN was constructed based only on the expression levels of the core set of genes that were found to be essential for cell viability. The second BN was built including all genes whose expression profiles showed significant changes across the cell cycle. Using these BNs we predicted the order of events occurring during the cell cycle. Our results show that both BNs can accurately reproduce the observed temporal ordering of the cell cycle phases. However, when compared against one another, our results suggest that the inclusion of non-core genes into the BN may lead to more accurate predictions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Boolean network theory predicts cell cycle sequence of fission yeast . Abstract : The Boolean Network ( BN ) is an important group of models for the evaluation and measurement of gene regulatory networks , which are applied to explain how genes interact with each other in biological environments .In this study we using BNs as a platform to predict the order of events during the cell division cycle of the fission yeast Schizosaccharomyces pombe . We create two different BNs using data acquired by microarray experiments conducted on synchronized cultures at four time points along the cell cycle .The first BN was constructed based only on the expression levels of the main set of genes that were found to be crucial for cell viability . The second BN was built including all genes whose function profiles showed substantial alterations across the cell cycle .Using these BNs we anticipated the order of activities happening during the cell cycle . Our results show that both BNs can accurately generate the seen temporal ordering of the cell cycle phases .However , when compared against one another , our findings show that the integration of non - core factors into the BN could lead to more accurate conclusions .",
        "rewrite_text": "Title: Boolean Network Theory Predicts Cell Cycle Sequence of Fission Yeast\n\nAbstract: Boolean Network (BN) models play a crucial role in analyzing and understanding gene regulatory networks, providing insights into the interactions among genes within biological systems. This study leverages BNs to forecast the sequence of events that occur during the cell division cycle of the fission yeast, Schizosaccharomyces pombe. We developed two distinct BNs based on data obtained from microarray experiments performed on synchronized cultures at four different time points throughout the cell cycle. The first BN was constructed solely from the expression levels of a core set of genes identified as essential for cell viability. In contrast, the second BN incorporated all genes that exhibited significant changes in expression profiles during the cell cycle. Utilizing these BNs, we were able to predict the chronological order of cellular activities throughout the cell cycle. Our findings indicate that both BNs successfully replicate the observed temporal progression of the cell cycle phases. However, a comparative analysis revealed that the inclusion of non-core factors in the BN enhances the accuracy of the predictions. This study underscores the potential of Boolean network models in elucidating complex biological processes and highlights the importance of considering a broader range of genetic factors to improve predictive outcomes in gene regulatory network analysis.",
        "ori-fast-z-score": -2.2223355980148636,
        "water-fast-z-score": 4.477667355944951,
        "rewrite-fast-z-score": -0.29277002188455997
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Deterministic characterization of stochastic genetic circuits .\nAbstract:\nWe present an approach to the analysis and design of stochastic gene regulatory networks based on deterministic models that are derived by averaging over all possible realizations of the underlying random process.  We show how this method can be used for analyzing the steady-state behavior of such systems, as well as their transient dynamics in response to external stimuli or changes in network parameters. The proposed framework is illustrated with several examples including synthetic toggle switches and oscillators. Stochasticity plays an important role in many biological processes ranging from cell cycle regulation to signal transduction  1  . In particular, it has been shown that noise may have beneficial effects on cellular functions  2  , e.g., by enhancing the sensitivity of cells to signals  3  .\nThe study of stochastic gene regulatory networks (GRNs) requires the development of new mathematical tools capable of capturing both the intrinsic fluctuations associated with molecular interactions and extrinsic perturbations due to environmental factors  4  . Several approaches have recently been developed to analyze GRNs; these include Monte Carlo simulations  5  , moment-closure methods  6  , and approximate analytical techniques  7, 8  . However, most existing methods focus only on the stationary properties of GRNs  9  ; they cannot capture the dynamic evolution of the system when its state variables change continuously  10  . Moreover, some of them require extensive computational resources  11  and/or do not provide any information about the statistical distribution of the output variable(s).\nIn this work we propose a novel methodology for studying the dynamical behavior of GRNs using deterministic models obtained through ensemble averages  12  . This approach allows us to obtain accurate approximations of the mean value and variance of the output variable(ies), while preserving the main characteristics of the original model  13  . Our results demonstrate that our technique provides useful insights into the functioning of complex biochemical networks without requiring excessive computational effort.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Deterministic analysis of stochastic genetic circuits . Abstract : We present an perspective to the analysis and design of stochastic gene regulatory circuits based on deterministic models that are derived by averaging over all possible realizations of the underlying random process .We see how this method can be used for evaluating the stable - phase response of such systems , as also as their transient dynamics in reaction to external stimuli or alterations in system parameters . The proposed framework is illustrated with many examples representing synthetic toggle switches and oscillators .Stochasticity plays an important role in different biological pathways including from cell cycle regulation to signal transduction 1 . In particular , it has been shown that noise might have beneficial influence on cell functions 2 , e . g . , by increased the sensitivity of cells to signals 3 .The investigation of stochastic gene regulatory networks ( GRNs ) need the development of new computational tools capable of depicting both the intrinsic fluctuations associated with molecular interactions and extrinsic perturbations due to environmental factors 4 . Several approaches have recently been proposed to analyze GRNs ; these involve Monte Carlo simulations 5 , moment - completion technique 6 , and exact mathematical techniques 7 , 8 .However , most existing techniques concentrate only on the stationary features of GRNs 9 ; they cannot record the dynamic development of the process when its state variables move continuously 10 . Moreover , some of them require extensive computational resources 11 and / or do not offer any knowledge about the statistical distribution of the output parameter ( s ) .In this project we develop a new methodology for studying the dynamical behavior of GRNs using deterministic descriptions generated through ensemble estimates 12 . This method enables us to obtain precise approximations of the mean value and variance of the output parameter ( ies ) , while preserving the main characteristics of the previous model 13 .Our results show that our technique provides useful insights into the functioning of complex biochemical organizations without using inappropriate computational time .",
        "rewrite_text": "In this article, we explore a novel approach to the analysis and design of stochastic gene regulatory circuits by employing deterministic models derived from averaging all potential realizations of the underlying stochastic processes. This methodology allows us to assess both the stable-phase responses of these systems and their transient dynamics in response to external stimuli or changes in system parameters. We illustrate our proposed framework with various examples, including synthetic toggle switches and oscillators, highlighting the significant role of stochasticity in various biological pathways, such as cell cycle regulation and signal transduction. Previous studies have indicated that noise can positively influence cellular functions by enhancing sensitivity to signals. To effectively investigate stochastic gene regulatory networks (GRNs), there is a pressing need for the development of advanced computational tools that can accurately represent both intrinsic fluctuations from molecular interactions and extrinsic disturbances from environmental factors. While several recent approaches, including Monte Carlo simulations, moment-completion techniques, and exact mathematical methods, have been proposed for GRN analysis, most focus primarily on stationary features and fail to capture the dynamic evolution of state variables. Additionally, many existing techniques demand substantial computational resources and do not provide insights into the statistical distribution of output parameters. In response to these limitations, we introduce a new methodology that leverages deterministic descriptions generated through ensemble estimates to study the dynamic behavior of GRNs. This innovative approach enables us to derive precise approximations of the mean and variance of output parameters while retaining the essential characteristics of previous models. Our findings demonstrate that this technique offers valuable insights into the functioning of complex biochemical systems without incurring excessive computational costs.",
        "ori-fast-z-score": -1.1607348488012053,
        "water-fast-z-score": 7.196556062567472,
        "rewrite-fast-z-score": 0.816496580927726
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Thin elastic shells with variable thickness for lithospheric flexure of one-plate planets .\nAbstract:\nWe present an analytical solution to the problem of bending thin elastic shells with variable thickness under surface loads, which is applicable to the case where the shell s thickness varies by several orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric.  We show that in this case it is possible to obtain accurate results using only two parameters instead of three as was previously thought necessary (the third parameter being the ratio between the maximum and minimum values of the shell s thickness). The new formulation allows us to calculate the deflection of the shell at any point on its surface without having to solve additional equations or perform numerical integration. This makes our approach much faster than previous methods while retaining high accuracy. Our method can be used to model the response of the Earth s crust to tectonic stresses and other processes such as volcanic loading and sedimentary deposition. It also has applications in geophysics beyond Earth sciences including planetary science, astrophysics and seismology. \nTheory\n\nIn order to study the deformation of the Earth s crust we need to know how the stress field changes across different regions of the planet. In particular, we are interested in understanding how the stress field evolves during plate boundary interactions like subduction zones and transform faults. To do so, we use the theory of elasticity to find solutions to problems involving the interaction between plates and their underlying mantle. However, solving these problems analytically requires simplifying assumptions about the geometry of the system and the mechanical properties of the materials involved. \n\nOne important simplification made when studying the mechanics of plate boundaries is to assume that they behave as if they were composed of thin elastic shells. These shells have been shown to provide good approximations to more realistic models of plate boundaries because they allow for rapid calculations of the stress fields within them. For example, Figure 1 shows a comparison between the predictions obtained using a simple spherical shell model and those produced by a finite element model of the San Andreas Fault System.\n\nFigure 1: Comparison between the predicted displacements along the San Andreas fault calculated using a spherical shell model (blue line) and a finite element model (red dots).",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Thin elastic pieces with variable thickness for lithospheric flexure of one - plate planets . Abstract : We present an analytical solution to the issue of twisting narrow elastic shells with variable size under surface loads , which is applicable to the case where the shell s thickness differs by many orders of magnitude over its radius and where the load distribution is not necessarily axisymmetric .We see that in this situation it is easy to obtain precise conclusions using only two parameters instead of three as was formerly thought required ( the third parameter being the proportion between the maximum and minimum values of the shell s thickness ) . The revised formulation enables us to estimate the deflection of the shell at any point on its surface without having to correct additional equations or undergo numerical expansion .This gives our approach much quick than prior methods while retaining high sensitivity . Our model can be used to model the response of the Earth s crust to tectonic stresses and other processes such as eruption loading and sedimentary deposition .It especially has uses in geophysics beyond Earth studies particularly planetary astronomy , astrophysics and seismology . Theory In order to study the deformation of the Earth s crust we require to see how the strain field shifts across different regions of the planet .In particular , we are concerned in understanding how the strain field evolves during plate boundary interactions like subduction zones and transform faults . To do so , we using the principle of elasticity to find solutions to problems concerning the interaction between plates and their underlying mantle .However , exploring these problems analytically takes simplifying theories about the topology of the system and the structural properties of the materials involved . One important simplification taken when researching the mechanics of plate boundaries is to assume that they react as if they were consisting of short elastic shells .These shells have been shown to provide better approximations to more realistic theories of plate boundaries because they allow for rapid calculations of the strain fields within them . For instance , Figure 1 shows a comparison between the estimates obtained using a simple spherical shell model and those generated by a finite element model of the San Andreas Fault System .Figure 1 : Comparison between the expected displacements along the San Andreas fault calculated using a spherical shell model ( blue line ) and a finite element model ( red dots ) .",
        "rewrite_text": "**Title:** Thin Elastic Pieces with Variable Thickness for Lithospheric Flexure of One-Plate Planets\n\n**Abstract:** In this study, we introduce an analytical solution addressing the behavior of twisting narrow elastic shells with variable thickness under surface loads. This solution is particularly relevant for scenarios where the shell's thickness varies significantly across its radius and where the load distribution may not be axisymmetric. Our findings reveal that it is possible to derive accurate conclusions using only two parameters, rather than the previously assumed three, which included the ratio of maximum to minimum thickness. This streamlined approach allows for the estimation of deflection at any point on the shell's surface without the need for additional corrections or numerical expansions, resulting in a method that is both faster and maintains high sensitivity compared to earlier techniques.\n\nThe implications of our model extend to the analysis of the Earth's crust response to tectonic stresses, as well as other geological processes such as volcanic loading and sedimentary deposition. Its applications are particularly significant in the field of geophysics, with potential benefits for planetary astronomy, astrophysics, and seismology. \n\nTo investigate the deformation of the Earth's crust, it is essential to understand how the strain field varies across different regions of the planet, especially during interactions at plate boundaries, such as subduction zones and transform faults. We employ the principles of elasticity to derive solutions for the interactions between tectonic plates and their underlying mantle. However, analytical exploration of these interactions necessitates certain simplifications regarding the system's topology and the structural properties of the materials involved. A key simplification involves modeling plate boundaries as short elastic shells, which have been shown to yield more accurate approximations compared to traditional models. This approach facilitates rapid calculations of strain fields, as illustrated in our comparison of displacement estimates along the San Andreas Fault System, where results from a simple spherical shell model are juxtaposed with those from a finite element model.",
        "ori-fast-z-score": -1.6642215921725698,
        "water-fast-z-score": 7.2701390825618155,
        "rewrite-fast-z-score": 1.632993161855452
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Exact solutions for the Einstein-Gauss-Bonnet theory in five dimensions: Black holes, wormholes and spacetime horns .\nAbstract:\nWe present exact solutions to the field equations of the Einstein-Gauss-Bonet (EGB) gravity with negative cosmological constant in 5D space-time. We find that there are three classes of black hole solutions depending on whether the Gauss-Bonnet coupling constant is positive or negative. The first class contains two types of static spherically symmetric black holes which have no horizons but possess naked singularities at their centers. In addition we also obtain another type of solution describing an asymptotically anti-de Sitter wormhole whose throat connects two asymptotic regions. Finally, by using the method developed recently by one of us, we construct a new type of solution representing a time-dependent spacetime horn. This work was supported by NSFC under Grant No. 10875030. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq . \nI. INTRODUCTORY REMARK\nThe discovery of gravitational waves has opened up a new window into our understanding of gravitation  1  , especially when it comes to testing general relativity  2  . However, despite its successes, general relativity still fails to explain some phenomena such as dark energy  3  and quantum gravity  4  . Therefore, many alternative theories of gravity were proposed over the years  5  .\nOne of these alternatives is the so-called Einstein-Gauss-Bonnet (EGB) gravity  6  -  8  . It can be viewed as a natural generalization of general relativity since it includes higher-order curvature corrections  9  . Moreover, this theory admits various interesting solutions including black holes  10 -  12  , wormholes  13  -  15  and even time dependent spacetimes  16  -  18  . Recently, EGB gravity attracted much attention due to its possible role in explaining the accelerated expansion of the universe  19  -  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Exact solutions for the Einstein - Gauss - Bonnet concept in five dimensions : Black holes , wormholes and spacetime horns . Abstract : We present precise solutions to the field equations of the Einstein - Gauss - Bonet ( EGB ) gravity with negative cosmological constant in 5D space - time .We see that there are three categories of brown hole solutions depending on whether the Gauss - Bonnet coupling constant is positive or negative . The first class includes two forms of static spherically symmetric blue holes which have no horizons but possess naked singularities at their regions .In addition we also obtain another type of solution describing an asymptotically anti - de Sitter wormhole whose throat connects two asymptotic areas . Finally , by using the method developed previously by one of us , we create a new kind of solution representing a time - dependent spacetime horn .This project was supported by NSFC under Grant No . 10875030 .PACS codes : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq . I .INTRODUCTORY REMARK The observation of gravitational waves has opened up a new window into our understanding of gravitation 1 , particularly when it comes to proving general relativity 2 . However , despite its victories , special relativity also fails to explain some phenomena such as dark energy 3 and quantum gravitational 4 .Therefore , various alternative theories of gravitational were offered over the years 5 . One of these proposals is the so - called Einstein - Gauss - Bonnet ( EGB ) gravity 6 - 8 .It can be viewed as a natural generalization of general relativity since it includes higher - order curvature corrections 9 . Moreover , this theory admits various exciting solutions namely black holes 10 - 12 , wormholes 13 - 15 and even period based spacetimes 16 - 18 .Recently , EGB gravitational attracted much attention due to its potential importance in understanding the advanced expansion of the universe 19 - 21 .",
        "rewrite_text": "**Title:** Exact Solutions for the Einstein-Gauss-Bonnet Theory in Five Dimensions: Black Holes, Wormholes, and Spacetime Horns\n\n**Abstract:** In this study, we derive exact solutions to the field equations governing Einstein-Gauss-Bonnet (EGB) gravity with a negative cosmological constant in five-dimensional spacetime. Our findings categorize the solutions into three distinct classes based on the sign of the Gauss-Bonnet coupling constant. The first category comprises two types of static, spherically symmetric \"blue holes,\" which are characterized by the absence of event horizons and the presence of naked singularities within their structure. Additionally, we present a novel solution that describes an asymptotically anti-de Sitter wormhole, featuring a throat that connects two asymptotic regions of spacetime. Furthermore, employing a method previously developed by one of the authors, we introduce a new solution that represents a time-dependent spacetime horn. This research is supported by the National Natural Science Foundation of China under Grant No. 10875030. \n\nThe recent detection of gravitational waves has significantly enhanced our comprehension of gravitational phenomena, particularly in validating the principles of general relativity. However, general relativity, despite its successes, falls short in addressing certain issues such as dark energy and quantum gravity. This has led to the exploration of various alternative gravitational theories over the years. Among these, the Einstein-Gauss-Bonnet theory emerges as a compelling extension of general relativity, incorporating higher-order curvature corrections. The EGB framework has garnered considerable interest due to its diverse and intriguing solutions, including black holes, wormholes, and periodic spacetimes. Recent developments in EGB gravity have sparked discussions regarding its potential role in elucidating the accelerated expansion of the universe, highlighting its significance in contemporary theoretical physics.",
        "ori-fast-z-score": 1.0366421106976322,
        "water-fast-z-score": 7.143502616338124,
        "rewrite-fast-z-score": 0.8049844718999243
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Probing non-standard decoherence effects with solar and KamLAND neutrinos .\nAbstract:\nWe study the possibility that nonstandard interactions (NSI) between neutrinos and matter can be probed by using solar and reactor neutrino data simultaneously, in particular through their combined effect on the survival probability P(νe→νe). We find that NSI parameters are constrained to values below 0.1 for most combinations of standard oscillation parameters allowed at 3σ CL by current global fits. The strongest constraints arise when combining solar and KamLAND data sets. In this case we obtain upper bounds on |εee|, |εµτ | < 0.06 − 0.07 depending on the value of θ13. These results improve upon previous limits obtained from solar or reactor experiments alone. \n \n Introduction \n \n Neutrino oscillations have been observed in many different types of experiments  1  . However, there is still no direct evidence for the existence of new physics beyond the Standard Model (SM), such as sterile neutrinos  2  , lepton number violation  3  , extra dimensions  4  , supersymmetry  5  , etc.. Many extensions of the SM predict additional contributions to the effective four-fermion interaction Lagrangian  6  which could lead to observable deviations from the predictions of the SM  7, 8  . For example, it has recently been shown  9  that some models of quantum gravity  10  may induce an energy dependent refractive index n = 1 + εE/E0 where E0 is a characteristic scale associated with the underlying theory  11  . This would result in a modification of the vacuum mixing angle sin2θ12 = 1−cos2θ12 ≈ 1+ε/2+O(ε3)  12  leading to potentially large effects on the propagation of neutrinos  13  .\n \nIn addition to these theoretical motivations, there exist several experimental indications pointing towards possible new physics beyond the SM  14  : i) Large atmospheric  15  and solar  16  neutrino flux deficits; ii) LSND  17  and MiniBooNE  18  anomalies indicating short-baseline νμ → νe appearance transitions not predicted within three-flavor neutrino oscillations  19  ; iii) Anomalies in the measurement of the muon anomalous magnetic moment",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Probing non - customary decoherence effects with solar and KamLAND neutrinos . Abstract : We research the prospect that nonstandard relationships ( NSI ) between neutrinos and matter can be probed by using solar and reactor neutrino data simultaneously , in particular through their combined influence on the life probability P ( νe→νe ) .We see that NSI variables are constrained to parameters below 0 . 1 for most combinations of standard oscillation parameters allowed at 3σ CL by current global fits . The strongest limits arise when combining solar and KamLAND data sets .In this situation we obtain upper limits on | εee | , | εµτ | < 0 . 06 − 0 . 07 depending on the value of θ13 . These results enhance upon former limits established from solar or reactor tests alone .Introduction Neutrino oscillations have been observed in different different kinds of studies 1 . However , there is nevertheless no formal evidence for the existence of new theories beyond the Standard Model ( SM ) , such as sterile neutrinos 2 , lepton number violation 3 , extra dimensions 4 , supersymmetry 5 , etc . .Many modifications of the SM predict additional contributions to the effective four - fermion interaction Lagrangian 6 which potentially contribute to observable deviations from the estimates of the SM 7 , 8 . For instance , it has recently been shown 9 that some models of quantum gravitational 10 may generate an energy dependent refractive index n = 1 + εE / E0 where E0 is a typical scale identified with the underlying model 11 .This might lead in a modification of the vacuum mixing ratio sin2θ12 = 1−cos2θ12 ≈ 1 + ε / 2 + O ( ε3 ) 12 leading to potentially large effects on the propagation of neutrinos 13 . In addition to these theoretical motivations , there remain many experimental indications pointing towards possible new science beyond the SM 14 : i ) Large atmospheric 15 and solar 16 neutrino flux deficits ; ii ) LSND 17 and MiniBooNE 18 anomalies suggesting short - baseline νμ → νe appearance processes not anticipated within three - flavor neutrino oscillations 19 ; iii ) Anomalies in the measurement of the muon anomalous magnetic moment",
        "rewrite_text": "**Title:** Probing Non-Customary Decoherence Effects with Solar and KamLAND Neutrinos\n\n**Abstract:** This study investigates the potential for detecting nonstandard interactions (NSI) between neutrinos and matter by analyzing data from solar and reactor neutrinos concurrently. Our focus is on how these interactions affect the survival probability, P(νe→νe), of electron neutrinos. We find that the parameters associated with NSI are constrained to values below 0.1 for most combinations of standard oscillation parameters that are permissible at the 3σ confidence level based on current global analyses. Notably, the most stringent constraints emerge when we integrate data from both solar neutrinos and the KamLAND reactor experiment. In this combined analysis, we derive upper limits for the NSI parameters |εee| and |εµτ|, which fall within the range of 0.06 to 0.07, depending on the value of θ13. These findings represent a significant improvement over previous limits obtained from solar or reactor neutrino studies conducted in isolation.\n\nNeutrino oscillations have been documented across various experimental setups; however, there remains an absence of definitive evidence supporting theories that extend beyond the Standard Model (SM), such as the existence of sterile neutrinos, lepton number violation, extra dimensions, and supersymmetry. Numerous extensions to the SM propose additional terms in the effective four-fermion interaction Lagrangian, which could lead to observable deviations from SM predictions. Recent theoretical advancements suggest that certain quantum gravitational models may introduce an energy-dependent refractive index, potentially altering the vacuum mixing ratio sin²θ12. This modification could have significant implications for neutrino propagation. Furthermore, experimental anomalies, including deficits in atmospheric and solar neutrino fluxes, as well as unexpected results from LSND and MiniBooNE experiments, indicate the possibility of new physics beyond the SM. These anomalies, alongside discrepancies in the measurement of the muon anomalous magnetic moment, underscore the need for further investigation into the fundamental nature of neutrinos and their interactions.",
        "ori-fast-z-score": -0.6910947404650881,
        "water-fast-z-score": 6.516946235415335,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Possible evolution of dim radio quiet neutron star 1E 1207.4-5209 based on a B-decay model .\nAbstract:\nWe propose that the dim radio-quiet neutron star, 1E1207.4-5209 (hereafter E1207), is an evolved object with its surface temperature T = 2 × 10 6 K and radius R = 11 km. The observed X-ray luminosity Lx ~ 3×1033 erg s-1 can be explained by the decay energy of radioactive nuclei produced in the core collapse supernova explosion at t ~ 1s after the birth of the progenitor star. We show that the total amount of 56Ni synthesized during the explosion is about 0.1M⊙ which agrees well with the theoretical prediction for massive stars. In addition to the nuclear burning, we consider the effects of magnetic field decay due to ohmic dissipation as well as gravitational wave emission. It turns out that these processes are not important enough to explain the present state of E1207 within our lifetime. However, if the initial magnetic field strength was larger than 1013 G, it could have been reduced down to the current value of 5×1012 G through ohmic dissipation before the age of the universe reached 13Gyrs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Possible evolution of dim radio calm neutron galaxy 1E 1207 . 4 - 5209 using on a B - decay model . Abstract : We suggest that the dim radio - quiet neutron star , 1E1207 . 4 - 5209 ( hereafter E1207 ) , is an evolved object with its surface temperature T = 2 × 10 6 K and radius R = 11 km .The observed X - ray luminosity Lx ~ 3×1033 erg s - 1 can be understood by the decay heat of radioactive nuclei created in the core breakup supernova explosion at t ~ 1s after the emergence of the progenitor star . We see that the total quantity of 56Ni produced during the explosion is about 0 . [UNK] which agrees well with the theoretical forecast for massive stars .In addition to the radioactive burning , we investigate the effects of magnetic force decay owing to ohmic dissipation as also as gravity wave radiation . It turns out that these mechanisms are not important sufficiently to explain the present state of E1207 within our lifetime .However , if the first magnetic force capacity was bigger than 1013 G , it could have been reduced down to the present value of 5×1012 G through ohmic dissipation before the age of the universe reached 13Gyrs .",
        "rewrite_text": "**Title:** Potential Evolution of the Dim Radio-Quiet Neutron Star 1E 1207.4-5209 Based on a Beta-Decay Model\n\n**Abstract:** In this study, we propose that the dim radio-quiet neutron star 1E 1207.4-5209 (hereafter referred to as E1207) represents an advanced evolutionary stage of neutron stars, characterized by a surface temperature of approximately 2 × 10^6 K and a radius of about 11 km. The observed X-ray luminosity of E1207, estimated at Lx ~ 3 × 10^33 erg s^-1, can be attributed to the decay heat generated by radioactive nuclei formed during the core-collapse supernova explosion that occurred roughly 1 second after the progenitor star's formation. Our calculations indicate that the total mass of 56Ni produced in this explosion is approximately 0. [UNK], which aligns well with theoretical predictions for massive stellar explosions. \n\nFurthermore, we explore the impact of magnetic field decay due to ohmic dissipation, as well as the potential contribution of gravitational wave radiation. Our findings suggest that these mechanisms are insufficiently influential to account for the current state of E1207 within the observable timeframe of our universe. However, we hypothesize that if the initial magnetic field strength exceeded 10^13 G, it could have diminished to the present value of 5 × 10^12 G through ohmic dissipation over the course of the universe's 13 billion-year history. This research enhances our understanding of the evolutionary processes of neutron stars and the physical phenomena governing their thermal and magnetic properties.",
        "ori-fast-z-score": -1.6081688022566922,
        "water-fast-z-score": 4.557990884027348,
        "rewrite-fast-z-score": 0.7921180343813395
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The VIMOS VLT Deep Survey: Tracing the galaxy stellar mass assembly history over the last 8Gyr .\nAbstract:\nWe present here an overview of our survey, which is aimed at tracing the evolution in the number density and luminosity function (LF) of galaxies as a function of their stellar masses up to z ~ 1.5. The sample consists of about 10 000 objects selected by photometric redshifts using deep optical data obtained with FORS2@VLT+WFI@ESO/MPG 2.2m telescope + Spitzer IRAC 3.6 & 4.5 micron bands. We use this dataset to study how the LF evolves for different ranges of stellar masses. In particular we find that the faint-end slope of the LF becomes steeper towards higher redshift indicating that less massive systems are more abundant than today. This result can be explained if star formation activity was more efficient in low-mass halos at high-z compared to local universe. Finally, we compare these results with those derived from other surveys finding good agreement between them.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The VIMOS VLT Deep Survey : Tracing the galaxy stellar mass formation history over the last 8Gyr . Abstract : We present here an overview of our survey , which is aiming at mapping the evolution in the number density and luminosity function ( LF ) of stars as a function of their stellar masses up to z ~ 1 . 5 .The sample consists of about 10 000 bodies chosen by photometric redshifts using deep optical data acquired with FORS2 @ VLT + WFI @ ESO / MPG 2 . 2m telescope + Spitzer IRAC 3 . 6 & 4 . 5 micron bands . We use this dataset to study how the LF evolves for different ranges of stars masses .In particular we find that the faint - end slope of the LF becomes steeper towards higher redshift indicating that less massive systems are more numerous than presently . This result can be understood if star formation activity was more efficient in low - density halos at high - z compared to local universe .Finally , we compare these results with those generated from other surveys obtaining strong approval between them .",
        "rewrite_text": "We provide a comprehensive overview of the VIMOS VLT Deep Survey, which aims to investigate the evolution of the number density and luminosity function (LF) of stars in relation to their stellar masses over the past 8 billion years, extending to redshifts of approximately z ~ 1.5. Our study is based on a carefully selected sample of around 10,000 celestial objects, identified through photometric redshifts derived from extensive optical data collected using the FORS2 instrument at the Very Large Telescope (VLT), along with observations from the Wide Field Imager (WFI) at the ESO/MPG 2.2m telescope and the Spitzer IRAC in the 3.6 and 4.5 micron bands. Utilizing this rich dataset, we analyze the evolution of the LF across various stellar mass ranges. Notably, our findings reveal that the faint-end slope of the LF becomes increasingly steep at higher redshifts, suggesting that less massive stellar systems were more prevalent in the early universe compared to the present day. This observation implies that star formation was likely more efficient in low-density halos during high redshift epochs than it is in the local universe. Furthermore, we conduct a comparative analysis of our results with data from other surveys, which corroborates our findings and reinforces the validity of our conclusions. This research contributes to a deeper understanding of galaxy formation and evolution, shedding light on the mechanisms that have shaped the stellar mass distribution over cosmic time.",
        "ori-fast-z-score": 1.811643254631353,
        "water-fast-z-score": 5.590169943749474,
        "rewrite-fast-z-score": 2.51259453814803
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  First CO J=6-5, 4-3 detections in local ULIRGs: the dense gas in Mrk231, and its colling budget .\nAbstract:\nWe report on high-resolution observations with Herschel PACS (Poglitsch et al., 2010) and SPIRE (Griffin et al., 2010 ) that reveal for the first time the presence of cold dust emission at temperatures as low as T = 20 K in two nearby ultraluminous infrared galaxies (ULIRGs), Arp220 and Mrk 231. The observed fluxes are consistent with predictions based on models of starbursts heated by young stars. We find evidence for an additional component of cooler dust which is likely to be associated with the obscured AGN activity present in these objects. In addition we have detected the  CII  158 µm line in both sources using PACS spectroscopy. This allows us to estimate the total mass of warm molecular hydrogen M(H2). For Arp 220 this amounts to 1.5 x 10^9 solar masses within a radius of 100 pc around the nucleus.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : First CO J = 6 - 5 , 4 - 3 detections in regional ULIRGs : the deep gas in Mrk231 , and its colling deficit . Abstract : We report on high - resolution measurements with Herschel PACS ( Poglitsch et al . , 2010 ) and SPIRE ( Griffin et al . , 2010 ) that discover for the first time the activity of cold dust absorption at conditions as low as T = 20 K in two nearby ultraluminous laser galaxies ( ULIRGs ) , Arp220 and Mrk 231 .The observed fluxes are compatible with predictions based on estimates of starbursts heated by young stars . We get information for an additional element of cold dust which is probably to be involved with the obscured AGN activity contained in these objects .In addition we have discovered the CII 158 µm line in both sources using PACS spectroscopy . This enables us to estimate the total mass of bright molecular hydrogen M ( H2 ) .For Arp 220 this corresponds to 1 . 5 x 10 ^ 9 solar masses within a diameter of 100 pc around the nucleus .",
        "rewrite_text": "We present groundbreaking findings from high-resolution observations conducted with the Herschel Space Observatory's PACS and SPIRE instruments, which reveal the first detections of CO transitions J = 6 - 5 and J = 4 - 3 in two nearby ultraluminous infrared galaxies (ULIRGs), Arp 220 and Mrk 231. Our study uncovers the presence of cold dust absorption at remarkably low temperatures, as low as 20 K, indicating a significant cooling deficit in these galaxies. The measured fluxes align well with theoretical predictions derived from models of starbursts driven by young stellar populations, suggesting that the cold dust is likely linked to the intense star formation occurring in these regions. Furthermore, our observations provide insights into an additional component of cold dust that may be associated with the obscured active galactic nucleus (AGN) activity present in these ULIRGs. Notably, we have also detected the CII 158 µm emission line in both Arp 220 and Mrk 231 through PACS spectroscopy, which allows us to estimate the total mass of bright molecular hydrogen (M(H2)) in these galaxies. For Arp 220, our findings indicate a substantial molecular hydrogen mass of approximately 1.5 x 10^9 solar masses within a 100 parsec radius of the nucleus. These results not only enhance our understanding of the physical conditions in ULIRGs but also contribute to the broader knowledge of galaxy evolution and the interplay between star formation and AGN activity in the universe.",
        "ori-fast-z-score": -2.9104275004359956,
        "water-fast-z-score": 2.528102914801153,
        "rewrite-fast-z-score": -0.19802950859533489
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Slow wave resonance in periodic stacks of anisotropic layers .\nAbstract:\nWe study the slow wave resonance (SWR) effect for periodically layered media with an arbitrary number N of anisotropic layers, each characterized by its own permittivity tensor and thickness. We show that SWR is possible only if all principal axes of the permittivity tensors are parallel to one another within each layer. In this case we derive explicit expressions for the dispersion relation between the frequency f and the Bloch wavenumber kx. The results obtained can be used as guidelines for designing multilayered structures exhibiting strong SWR effects at low frequencies. \n \n Keywords: Slow wave resonance; Anisotropy; Multilayer structure; Dispersion relations. 1 Introduction \n \n Periodic multilayers consisting of alternating thin films made of different materials have attracted considerable attention during recent years due to their unique properties  1  . These include high reflectance  2  , negative refraction  3  , enhanced nonlinear optical response  4  , etc., which make them promising candidates for various applications such as optoelectronic devices  5  or photovoltaics  6  .\n \nIn particular, it has been shown recently  7–9  that periodic multilayers composed of anisotropic layers may exhibit very interesting electromagnetic phenomena including slow wave resonance (S WR). This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium  10  . It leads to extremely large values of the effective refractive index n eff = c / v ph  11  where c is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode  12  . As a result, the corresponding transmission spectrum exhibits sharp peaks associated with narrow stop bands  13  . Such features are highly desirable for many practical applications  14  . \n \n However, despite numerous theoretical studies devoted to S WR in periodic multilayers  15–18  , there still exist several open questions related to the conditions under which this phenomenon takes place  19, 20  . For example, it was found experimentally  21  that the presence of a single misaligned anisotropic layer destroys the S WR effect completely even though other layers remain perfectly aligned. On the other hand, numerical simulations  22  suggest that",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Slow wave resonance in periodic piles of anisotropic layers . Abstract : We research the slow wave resonance ( SWR ) effect for regularly layered media with an arbitrary number N of anisotropic layers , each described by its own permittivity vector and thickness .We see that SWR is possible only if all primary axes of the permittivity tensors are connected to one another within each layer . In this situation we derive explicit expressions for the dispersion connection between the frequency f and the Bloch wavenumber kx .The results collected can be used as guidelines for constructing multilayered buildings presenting strong SWR effects at low frequencies . Keywords : Slow wave vibration ; Anisotropy ; Multilayer structure ; Dispersion relations .1 Introduction Periodic multilayers consisting of alternating thin films formed of different materials have garnered considerable scrutiny during recent seasons due to their distinct characteristics 1 . These include high reflectance 2 , positive refraction 3 , enhanced nonlinear optical reaction 4 , etc . , which make them promising candidates for various uses such as optoelectronic technologies 5 or photovoltaics 6 .In particular , it has been shown ago 7 – 9 that periodic multilayers consisting of anisotropic elements may exhibit very interesting electrical processes including slow wave resonance ( S WR ) . This phenomenon occurs when the phase velocity of the Bloch waves becomes equal to zero inside the medium 10 .It results to incredibly large values of the effective refractive index n eff = c / v ph 11 where p is the speed of light in vacuum and v ph is the phase velocity of the propagating Bloch mode 12 . As a result , the associated transmission spectrum exhibits strong spikes identified with narrow stop rings 13 .Such characteristics are extremely attractive for numerous practical applications 14 . However , despite several practical studies focused to S WR in periodic multilayers 15 – 18 , there still exist several open questions related to the conditions under which this phenomenon happens place 19 , 20 .For instance , it was shown experimentally 21 that the presence of a single misaligned anisotropic surface destroys the S WR effect totally even though other layers remain perfectly aligned . On the other hand , numerical simulations 22 suggest that",
        "rewrite_text": "**Title:** Slow Wave Resonance in Periodic Piles of Anisotropic Layers\n\n**Abstract:** This study investigates the phenomenon of slow wave resonance (SWR) in periodically layered media composed of an arbitrary number \\( N \\) of anisotropic layers, each characterized by its unique permittivity vector and thickness. Our findings indicate that SWR can only occur when the principal axes of the permittivity tensors are interconnected within each layer. Under these conditions, we derive explicit mathematical expressions that describe the relationship between frequency \\( f \\) and the Bloch wavenumber \\( k_x \\). These derived results serve as valuable guidelines for the design of multilayered structures that exhibit pronounced SWR effects at low frequencies. \n\nThe significance of periodic multilayers, which consist of alternating thin films made from various materials, has gained considerable attention due to their unique properties, including high reflectance, positive refraction, and enhanced nonlinear optical responses. These characteristics render them suitable for a wide range of applications, particularly in optoelectronic technologies and photovoltaics. Previous research has demonstrated that multilayers containing anisotropic elements can exhibit intriguing electrical behaviors, notably SWR, where the phase velocity of Bloch waves approaches zero within the medium. This leads to exceptionally high values of the effective refractive index \\( n_{\\text{eff}} = c / v_{\\text{ph}} \\), where \\( c \\) is the speed of light in a vacuum and \\( v_{\\text{ph}} \\) is the phase velocity of the propagating Bloch mode. Consequently, the transmission spectrum displays pronounced spikes associated with narrow stop bands, making these structures highly attractive for various practical applications.\n\nDespite the growing body of research on SWR in periodic multilayers, several questions remain unresolved regarding the specific conditions that facilitate this phenomenon. For instance, experimental evidence suggests that even a single misaligned anisotropic layer can completely disrupt the SWR effect, despite the alignment of other layers. Conversely, numerical simulations indicate that... [text continues]. \n\n**Keywords:** Slow wave resonance; Anisotropy; Multilayer structures; Dispersion relations.",
        "ori-fast-z-score": -0.22808577638091165,
        "water-fast-z-score": 7.580980435789034,
        "rewrite-fast-z-score": 2.4740693418496287
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Nonperiodic Anyon Model and the Fractional Quantum Hall Effect .\nAbstract:\nThe nonperiodic anyon model is introduced as an alternative to the periodic one in order to explain fractional quantum hall effect (FQHE). The ground state wave function for this system is obtained by using the method of projection operators, which leads to a new expression for the Laughlin wave functions. It is shown that these states are exact eigenstates of the total angular momentum operator with eigenvalues equal to the number of particles times their charge e*. This result shows that the nonperiodic anyons can be considered as charged particles moving on a sphere. Finally we show how our results can be applied to describe FQHE at filling fractions other than 1/3. In recent years there has been considerable interest in studying systems consisting of interacting electrons confined to two dimensions  1  . One of the most interesting phenomena observed experimentally  2  , known as the fractional quantum Hall effect (FQHE), occurs when such two-dimensional electron gas is subjected to strong magnetic fields  3  .\nIn the original work  4  it was suggested that the FQHE could be explained within the framework of the so-called Laughlin wave functions  5  . These wave functions were constructed by assuming that each particle moves around its own guiding center  6  . However, later studies  7 -9  showed that the actual behavior of the electrons in real experiments cannot be described accurately by considering them as point-like objects. Instead, they should be treated as extended objects whose size depends upon the strength of the external magnetic field  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Nonperiodic Anyon Model and the Fractional Quantum Hall Effect . Abstract : The nonperiodic anyon theory is proposed as an alternative to the periodic one in order to explain fractional quantum hall impact ( FQHE ) .The ground state wave function for this scheme is found by using the method of projection operators , which results to a new representation for the Laughlin wave functions . It is seen that these states are exact eigenstates of the total angular velocity operator with eigenvalues equal to the number of molecules times their charge e * .This result shows that the nonperiodic anyons can be regarded as charged particles moving on a sphere . Finally we show how our findings can be applied to define FQHE at filling fractions other than 1 / 3 .In recent years there has been substantial interest in investigating systems composed of interacting electrons dispersed to two dimensions 1 . One of the most exciting phenomena observed experimentally 2 , known as the fractional quantum Hall impact ( FQHE ) , happened when such two - dimensional electron gas is subjected to powerful magnetic fields 3 .In the first paper 4 it was suggested that the FQHE might be described within the framework of the so - called Laughlin wave curves 5 . These wave functions were created by assuming that each particle moves surrounding its own guiding center 6 .However , later research 7 - 9 demonstrated that the actual activity of the electrons in real studies cannot be described properly by treating them as point - like structures . Instead , they should be treated as extended things whose shape depends upon the strength of the external magnetic force 10 .",
        "rewrite_text": "**Title:** The Nonperiodic Anyon Model and the Fractional Quantum Hall Effect\n\n**Abstract:** This article introduces the nonperiodic anyon model as a novel framework for understanding the fractional quantum Hall effect (FQHE), presenting it as a compelling alternative to the traditional periodic anyon theory. The authors derive the ground state wave function using projection operator techniques, leading to a new formulation of the Laughlin wave functions. Notably, these derived states are shown to be exact eigenstates of the total angular momentum operator, with eigenvalues corresponding to the product of the number of particles and their charge, e*. This finding implies that nonperiodic anyons can be conceptualized as charged particles moving on a spherical surface. Furthermore, the implications of this model extend to defining the FQHE at various filling fractions beyond the commonly studied 1/3. \n\nThe fractional quantum Hall effect has garnered significant attention in recent years, particularly in the context of two-dimensional electron systems subjected to strong magnetic fields. Initial theoretical work suggested that the FQHE could be effectively described using Laughlin wave functions, which were based on the premise that each electron orbits around its own guiding center. However, subsequent investigations revealed that this point-like treatment of electrons is insufficient for accurately capturing their behavior in experimental settings. Instead, it has become clear that electrons should be modeled as extended entities, with their spatial configurations influenced by the intensity of the external magnetic field. This article contributes to the ongoing discourse by providing a robust theoretical framework that enhances our understanding of the FQHE and opens avenues for exploring its manifestations in different filling fractions.",
        "ori-fast-z-score": -1.6296434287653334,
        "water-fast-z-score": 6.041186552271796,
        "rewrite-fast-z-score": -0.17677669529663687
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Solar-like oscillations in the metal-poor subgiant nu Indi: II. Acoustic spectrum and mode lifetime .\nAbstract:\nWe present new high-precision photometric observations of the red giant star nu Indi, obtained with the Kepler space telescope over a period of three months (Q0-Q3). The data are used to determine the acoustic spectrum of this star by means of Fourier analysis techniques. We find that the observed frequencies can be well reproduced using theoretical models for stars on the red-giant branch. In particular we show that the large separation between consecutive radial orders is consistent with an evolutionary stage corresponding to a stellar mass of about 1.5 Msun. Furthermore, we use our results to estimate the lifetimes of individual modes as a function of their degree . Our findings suggest that low-degree p-modes have significantly longer lifetimes than those predicted by current theory. This may indicate that convection plays only a minor role in driving these modes or that additional physical processes need to be taken into account. \n \n Keywords: Red giants",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Solar - like oscillations in the metal - deprived subgiant nu Indi : II . Acoustic spectrum and mode lifetime .Abstract : We report new high - precision photometric images of the red giant star nu Indi , obtained with the Kepler space telescope over a period of three months ( Q0 - Q3 ) . The data are using to estimate the acoustic spectrum of this star by means of Fourier analysis methods .We see that the known signals can be well illustrated using theoretical estimates for stars on the red - giant branch . In particular we prove that the huge splitting between successive radial orders is compatible with an evolutionary stage equivalent to a stellar mass of about 1 . 5 Msun .Furthermore , we utilize our findings to estimate the lifetimes of individual modes as a function of their degree . Our findings show that low - degree p - modes have substantially extended lifetimes than those predicted by current theory .This might suggest that convection plays only a minor importance in steering these mechanisms or that extra physical processes must to be taken into consideration . Keywords : Red giants",
        "rewrite_text": "Title: Solar-like Oscillations in the Metal-Deprived Subgiant Nu Indi: II. Acoustic Spectrum and Mode Lifetime\n\nAbstract: In this study, we present high-precision photometric observations of the red giant star Nu Indi, captured by the Kepler space telescope over a three-month period (Q0 - Q3). Utilizing these data, we employ Fourier analysis techniques to derive the acoustic spectrum of Nu Indi. Our analysis reveals that the observed oscillation signals align closely with theoretical predictions for stars situated on the red giant branch. Notably, we demonstrate that the significant splitting observed between successive radial orders is consistent with an evolutionary phase corresponding to a stellar mass of approximately 1.5 M☉. \n\nAdditionally, we investigate the lifetimes of individual oscillation modes, examining their dependence on the degree of the modes. Our results indicate that low-degree p-modes exhibit considerably longer lifetimes than those anticipated by existing theoretical models. This discrepancy suggests that convection may play a less critical role in influencing these oscillation mechanisms than previously thought, or that additional physical processes need to be incorporated into our understanding. \n\nThese findings contribute to the broader understanding of stellar oscillations in red giants and highlight the complexities involved in modeling their behavior. The implications of our results could lead to a reevaluation of the factors influencing mode lifetimes in such stars, paving the way for future research in stellar astrophysics. \n\nKeywords: Red giants, stellar oscillations, acoustic spectrum, mode lifetime, Kepler space telescope.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.982243228301002,
        "rewrite-fast-z-score": 1.4985372985307104
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  SBF: multi-wavelength data and models .\nAbstract:\nThe Spitzer Bright Field (SBF) is an all-sky survey at 3.6, 4.5, 5.8 & 8 microns carried out by the Infrared Array Camera on board the Spitzer Space Telescope.  The SBF was designed to provide deep infrared photometry for extragalactic studies in order to complement existing optical surveys such as the Sloan Digital Sky Survey.   This dataset contains images taken with IRAC channel 1 (3.6 micron), channel 2 (4.5 micron), channel 3 (5.8 micron) and channel 4 (8 micron). Each image has been processed using the MOPEX software package developed by the Spitzer Science Center. These images are available through the NASA/IPAC Extragalactic Database (NED).  For more information about this project please see http://irsa.ipac.caltech.edu/data/SPITZER/docs/sbf/sbf-intro.html",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : SBF : multi - wavelength information and models . Abstract : The Spitzer Bright Field ( SBF ) is an all - skies study at 3 . 6 , 4 . 5 , 5 . 8 & 8 microns taken out by the Infrared Array Camera on board the Spitzer Space Telescope .The SBF was built to provide deep infrared photometry for extragalactic studies in order to complement existing imaging observations such as the Sloan Digital Sky Survey . This dataset contains images took with IRAC channel 1 ( 3 . 6 micron ) , channel 2 ( 4 . 5 micron ) , channel 3 ( 5 . 8 micron ) and channel 4 ( 8 micron ) .Each image has been processed utilizing the MOPEX software suite created by the Spitzer Science Center . These photographs are available through the NASA / IPAC Extragalactic Database ( NED ) .For more information about this project please view http : / / irsa . ipac . caltech . edu / data / SPITZER / docs / sbf / sbf - intro . html",
        "rewrite_text": "**Title: SBF: Multi-Wavelength Information and Models**\n\n**Abstract:** The Spitzer Bright Field (SBF) represents a comprehensive all-sky survey conducted at wavelengths of 3.6, 4.5, 5.8, and 8 microns, utilizing the Infrared Array Camera (IRAC) aboard the Spitzer Space Telescope. This initiative aims to deliver deep infrared photometry that enhances extragalactic research, serving as a valuable complement to existing optical imaging datasets, such as those provided by the Sloan Digital Sky Survey. The SBF dataset comprises images captured across the four IRAC channels: channel 1 at 3.6 microns, channel 2 at 4.5 microns, channel 3 at 5.8 microns, and channel 4 at 8 microns. Each image has undergone meticulous processing through the MOPEX software suite, developed by the Spitzer Science Center, ensuring high-quality data suitable for scientific analysis. These processed images are accessible via the NASA/IPAC Extragalactic Database (NED), facilitating their use in a variety of astrophysical studies. The SBF project not only provides essential data for researchers but also contributes to a broader understanding of the universe by enabling detailed investigations into the properties and behaviors of extragalactic objects. For further details regarding the SBF project and its implications for astronomical research, interested parties are encouraged to visit the dedicated project page at http://irsa.ipac.caltech.edu/data/SPITZER/docs/sbf/sbf-intro.html. This resource serves as a gateway to the rich dataset and the potential insights it offers into the cosmos.",
        "ori-fast-z-score": -0.30151134457776363,
        "water-fast-z-score": 4.024922359499621,
        "rewrite-fast-z-score": -1.3937462952891333
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Magnetic turbulence production by streaming cosmic rays upstream of SNR shocks .\nAbstract:\nWe study the magnetic field amplification in supernova remnants (SNRs) due to cosmic ray streaming instability, which is driven by anisotropic diffusion of energetic particles across the mean magnetic field lines. We show that this process can be responsible for the observed level of magnetic fields in young SNRs and may explain their origin. The growth rate of the instability depends on the ratio between the gyrofrequency of relativistic protons and the frequency of plasma waves excited by them. This ratio decreases with time as the number density of accelerated particles increases downstream of the shock front. As a result, the instability saturates at some distance behind the shock front where the magnetic energy density becomes comparable to the kinetic energy density of the flow. In order to estimate the saturation scale we use an analytical model developed recently by Bell et al. (2013) . It allows us to calculate the spectrum of amplified magnetic fluctuations produced by cosmic ray streaming instability.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Magnetic turbulence production by streaming cosmic rays upstream of SNR shocks . Abstract : We research the magnetic force amplification in supernova remnants ( SNRs ) resulting to cosmic ray streaming instability , which is caused by anisotropic absorption of excited particles across the mean magnetic field lines .We see that this process can be responsible for the observed level of magnetic fields in young SNRs and may reason their source . The growth speed of the instability depends on the proportion between the gyrofrequency of relativistic protons and the frequency of plasma beams excited by them .This ratio falls with time as the number density of advanced substances rises downstream of the shock back . As a result , the instability saturates at some distance behind the shock back where the magnetic energy density becomes comparable to the kinetic power concentration of the flow .In order to estimate the saturation level we utilize an analytical method developed recently by Bell et al . ( 2013 ) .It enables us to estimate the spectrum of amplified magnetic fluctuations produced by cosmic ray streaming instability .",
        "rewrite_text": "In this study, we investigate the amplification of magnetic fields in supernova remnants (SNRs) driven by cosmic ray streaming instability, which arises from the anisotropic absorption of energetic particles along the mean magnetic field lines. Our findings suggest that this mechanism may account for the observed magnetic field strengths in young SNRs and could provide insights into their origins. The growth rate of the instability is influenced by the ratio of the gyrofrequency of relativistic protons to the frequency of the plasma beams they generate. Notably, this ratio decreases over time as the density of the surrounding medium increases downstream of the shock front. Consequently, the instability reaches a saturation point at a certain distance behind the shock, where the density of magnetic energy becomes comparable to the kinetic energy density of the flow. To quantify this saturation level, we employ an analytical approach recently proposed by Bell et al. (2013), which allows us to estimate the spectrum of magnetic fluctuations amplified by cosmic ray streaming instability. Our results contribute to a deeper understanding of the interplay between cosmic rays and magnetic field dynamics in SNRs, highlighting the significance of this process in shaping the magnetic environment of these astrophysical phenomena.",
        "ori-fast-z-score": -0.6255432421712244,
        "water-fast-z-score": 4.458892287340829,
        "rewrite-fast-z-score": 2.65361388801511
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Impact of spin-zero particle-photon interactions on light polarization in external magnetic fields .\nAbstract:\nWe study the effect of spin-one and spin-two particles on the circularly polarized light propagating through an external magnetic field. We show that this effect is determined by the interaction between photons and particles with spins equal to zero, one or two only if the photon energy exceeds some threshold value which depends on the particle mass. For example, for electrons (mass m = 9.11×10-31 kg) it equals to 0.5 MeV. Below this threshold there are no effects caused by higher-spin particles. The results obtained can be used as a basis for developing new methods of studying high-spin particles using optical techniques. DOI: 10.1088/1742-6596/aa6b20\nI. INTRODUCTIO N\nThe problem of describing the propagation of electromagnetic waves in matter has been studied extensively over many years  1  . In particular, the influence of various types of atoms  2  , molecules  3  , ions  4  , plasmas  5  , crystals  6  , etc., on the properties of light was investigated. However, despite numerous studies, the question about how the presence of particles with non-zero spin affects the polarization state of light remains open  7 -9  .\nIn recent decades, interest in such problems increased significantly due to the development of quantum optics  10  . This area includes investigations into the processes occurring when high-energy photons interact with particles having different masses  11  . Such phenomena include Compton scattering  12  , pair production  13  , photo-meson production  14  , etc.. It should also be noted that these processes play an important role in astrophysics  15  , nuclear physics  16  , condensed-matter physics  17  , etc..\nIt follows from the above that the investigation of the impact of particles with nonzero spin on the polarization state of light is relevant both theoretically and experimentally.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Impact of spin - zero particle - photon interactions on light polarization in external magnetic fields . Abstract : We research the impact of spin - one and spin - two ions on the circularly polarized light propagating through an external magnetic field .We see that this effect is chosen by the interaction between photons and atoms with spins equal to zero , one or two only if the photon energy reaches some threshold quantity which depends on the particle weight . For instance , for electrons ( mass m = 9 . 11×10 - 31 kg ) it corresponds to 0 . 5 MeV .Below this threshold there are no impacts produced by higher - spinning waves . The results derived can be used as a framework for building new ways of studying high - spinning objects utilizing optical techniques .DOI : 10 . 1088 / 1742 - 6596 / aa6b20 I . INTRODUCTIO N The problem of describing the propagation of electromagnetic waves in matter has been studied extensively over many years 1 . In particular , the influence of various types of atoms 2 , molecules 3 , ions 4 , plasmas 5 , crystals 6 , etc . , on the properties of light was investigated .However , despite several studies , the question about how the presence of atoms with non - zero spin affects the polarization state of light remains open 7 - 9 . In past decades , interest in such problems intensified substantially due to the development of quantum optics 10 .This area includes research into the mechanisms occurring when high - energy photons react with particles having various masses 11 . Such effects include Compton scattering 12 , pair production 13 , photo - meson production 14 , etc . .It should also be mentioned that these mechanisms play an important role in astrophysics 15 , nuclear science 16 , condensed - matter science 17 , etc . . It follows from the above that the examination of the impact of particles with nonzero momentum on the polarization state of light is relevant both theoretically and experimentally .",
        "rewrite_text": "**Title:** Impact of Spin-Zero Particle-Photon Interactions on Light Polarization in External Magnetic Fields\n\n**Abstract:** This study investigates the effects of spin-one and spin-two ions on the behavior of circularly polarized light as it travels through an external magnetic field. Our findings indicate that the interaction between photons and atoms with spin values of zero, one, or two significantly influences light polarization, but only when the energy of the photons exceeds a specific threshold. This threshold is contingent upon the mass of the particles involved; for example, electrons, which have a mass of approximately 9.11 × 10^-31 kg, exhibit this effect at an energy level of 0.5 MeV. Below this energy threshold, the influence of higher-spin waves on light polarization is negligible. The implications of our results provide a foundational framework for developing novel optical techniques aimed at studying high-spin particles. \n\nThe propagation of electromagnetic waves in various media has been a subject of extensive research over the years, focusing on how different types of atoms, molecules, ions, plasmas, and crystals affect light properties. Despite numerous investigations, the specific impact of non-zero spin atoms on the polarization state of light remains an unresolved issue. Recent advancements in quantum optics have reignited interest in this area, particularly concerning the interactions between high-energy photons and particles of varying masses. Notable phenomena such as Compton scattering, pair production, and photo-meson production are critical in this context and have significant implications in fields such as astrophysics, nuclear science, and condensed matter physics. Therefore, exploring the effects of particles with non-zero spin on light polarization is of paramount importance, both from theoretical and experimental perspectives. \n\n**DOI:** 10.1088/1742-6596/aa6b20",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 6.45532593109847,
        "rewrite-fast-z-score": 0.9610744623271417
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Two-Component Afterglow of Swift GRB 050802 .\nAbstract:\nWe report on the optical and near-infrared afterglows of the short-hard burst GRB 050802 detected by Swift/BAT on May 2nd, 2005 at 07:55:06 UT (T0). The prompt emission was followed by an X-ray flare peaking at T0+500 s in the rest frame. We find that both components are well described by power laws with decay indices α1 = 1.2 ± 0.3 for t < 10 ks and α2 = 2.5 ± 0.4 for t > 10 ks. A break is observed between these two regimes around t0 + 20 ks. No evidence for spectral evolution or extinction has been found within each component. Our results suggest that this event may be similar to GRB 021004 which also showed a double-power law behaviour but without any significant spectral evolution across the break time. This suggests that the physical mechanism responsible for the late-time steepening could be related to the one producing the early shallow decline. \n \n Keywords: Gamma-ray burst",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Two - Component Afterglow of Swift GRB 050802 . Abstract : We report on the optical and far - infrared afterglows of the short - hard burst GRB 050802 detected by Swift / BAT on May 2nd , 2005 at 07 : 55 : 06 UT ( T0 ) .The prompt emission was followed by an X - ray flare peaking at T0 + 500 s in the remainder frame . We see that both components are better represented by power laws with decay indices α1 = 1 . 2 ± 0 . 3 for t < 10 ks and α2 = 2 . 5 ± 0 . 4 for t > 10 ks .A break is observed between these two regimes around t0 + 20 ks . No support for spectral evolution or extinction has been detected within each component .Our results propose that this event may be parallel to GRB 021004 which also demonstrated a double - energy law behaviour but without any considerable spectral evolution across the broke time . This implies that the physical process cause for the early - time steepening could be connected to the one generating the early shallow collapse .Keywords: Gamma-ray burst",
        "rewrite_text": "Title: The Two-Component Afterglow of Swift GRB 050802\n\nAbstract: In this study, we present a comprehensive analysis of the optical and far-infrared afterglows associated with the short-hard gamma-ray burst GRB 050802, which was detected by the Swift/BAT on May 2, 2005, at 07:55:06 UT (T0). Following the initial prompt emission, we observed an X-ray flare that peaked at approximately T0 + 500 seconds in the rest frame of the burst. Our findings indicate that the afterglow can be characterized by two distinct power-law decay phases, with decay indices α1 = 1.2 ± 0.3 for times less than 10 kiloseconds and α2 = 2.5 ± 0.4 for times greater than 10 kiloseconds. A notable break in the light curve is identified around T0 + 20 kiloseconds, marking the transition between these two decay regimes. Importantly, we found no evidence of spectral evolution or extinction within either component of the afterglow. Our results suggest that GRB 050802 exhibits behavior reminiscent of GRB 021004, which also displayed a dual power-law decay without significant spectral evolution across the break time. This observation raises intriguing questions about the underlying physical mechanisms responsible for the early-time steepening of the afterglow, potentially linking it to the processes that drive the initial shallow decay phase. These findings contribute to our understanding of gamma-ray bursts and their afterglows, highlighting the complexity of their emission mechanisms and the importance of continued observational efforts in this field. \n\nKeywords: Gamma-ray burst, afterglow, power-law decay, spectral evolution, GRB 050802.",
        "ori-fast-z-score": 0.24253562503633297,
        "water-fast-z-score": 4.45427656417346,
        "rewrite-fast-z-score": 0.7627700713964739
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Effect of the Spatial Dispersion on the Shape of a Light Pulse in a Quantum Well .\nAbstract:\nWe study theoretically and numerically the effect of spatial dispersion (SD) on the shape of a light pulse propagating through an InGaAs/GaAs quantum well (QW). We show that SD leads to significant changes in the temporal profile of the transmitted pulse, which can be used for its characterization. The results are obtained by solving Maxwell s equations using the finite-difference time-domain method with periodic boundary conditions. It is shown that the presence of SD causes the appearance of additional peaks at both sides of the main peak of the transmitted pulse. These peaks become more pronounced as the QW width increases. \n \n Keywords: Light propagation, Finite difference time domain method, Quantum wells, Spatial dispersion. 1 Introduction \n \n A number of recent studies have been devoted to investigating the effects of spatial dispersion (SD), also known as nonlocality or transverse momentum conservation  1  , on various physical phenomena such as nonlinear wave dynamics  2  -  4  , spontaneous emission  5  , and transport  6  . This interest has been motivated mainly by the fact that many semiconductor devices operate under conditions where SD plays an important role  7, 8  .\n \nIn this work we consider the problem of light transmission through a single-mode quantum well (QW) structure  9  . Our aim is to investigate how SD affects the shape of the transmitted pulse. To do so, we solve Maxwell s equations using the finitedifference time-domain (FDTD) method  10  with periodic boundary conditions  11  . As it will be demonstrated below, our numerical simulations reveal that SD gives rise to new features in the temporal profile of a transmitted pulse.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Effect of the Spatial Dispersion on the Shape of a Light Pulse in a Quantum Well . Abstract : We research theoretically and numerically the impact of spatial dispersion ( SD ) on the shape of a light pulse propagating through an InGaAs / GaAs quantum well ( QW ) .We see that SD leads to significant improvements in the temporal profile of the transmitted signal , which can be used for its description . The results are derived by solving Maxwell s coefficients using the finite - difference time - domain approach with periodic boundary constraints .It is demonstrated that the presence of SD causes the appearance of new peaks at both sides of the main peak of the transmitted signal . These peaks develop more pronounced as the QW width rises .Keywords : Light propagation , Finite difference time domain approach , Quantum wells , Spatial dispersion . 1 Introduction A variety of recent studies have been focused to investigating the effects of spatial dispersion ( SD ) , sometimes called as nonlocality or longitudinal momentum conservation 1 , on various biological phenomena such as nonlinear wave propulsion 2 - 4 , spontaneous emission 5 , and transport 6 .This interest has been motivated mainly by the fact that several semiconductor devices exist under environments where SD plays an important role 7 , 8 . In this study we investigate the question of light transfer through a single - mode quantum well ( QW ) structure 9 .Our aim is to probe how SD impacts the morphology of the transmitted beam . To do so , we solve Maxwell s coefficients use the finitedifference time - domain ( FDTD ) method 10 with periodic boundary constraints 11 .As it will be showed below , our numerical simulations reveal that SD leads rise to novel features in the temporal profile of a broadcast pulse .",
        "rewrite_text": "In this study, we conduct a theoretical and numerical investigation into the effects of spatial dispersion (SD) on the shape of a light pulse as it propagates through an InGaAs/GaAs quantum well (QW). Our findings indicate that SD significantly enhances the temporal profile of the transmitted signal, providing a more accurate description of its characteristics. To derive these results, we employ the finite-difference time-domain (FDTD) method to solve Maxwell's equations under periodic boundary conditions. Our simulations reveal that the introduction of SD results in the emergence of additional peaks flanking the main peak of the transmitted signal. Notably, these secondary peaks become increasingly pronounced with an increase in the width of the quantum well.\n\nThe phenomenon of spatial dispersion, often referred to as nonlocality or longitudinal momentum conservation, has garnered considerable attention in recent research, particularly concerning its implications for various biological and physical processes, including nonlinear wave propagation, spontaneous emission, and transport mechanisms. This growing interest is largely driven by the recognition that many semiconductor devices operate in environments where SD is a critical factor. In this context, our research aims to elucidate the influence of SD on light transmission through a single-mode QW structure.\n\nBy employing the FDTD method, we are able to capture the intricate dynamics of light propagation within the QW and assess how SD alters the morphology of the transmitted beam. Our numerical simulations demonstrate that the presence of spatial dispersion introduces novel features in the temporal profile of the emitted pulse, thereby enhancing our understanding of light behavior in quantum well systems. This work not only contributes to the fundamental understanding of light-matter interactions in semiconductor structures but also has potential implications for the design and optimization of photonic devices that leverage these effects. \n\nKeywords: Light propagation, Finite difference time domain approach, Quantum wells, Spatial dispersion.",
        "ori-fast-z-score": -1.0524696231684352,
        "water-fast-z-score": 6.490229342872016,
        "rewrite-fast-z-score": 2.578633484881217
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A deeper search for the progenitor of the Type Ic Supernova 2002ap .\nAbstract:\nWe present new optical and near-infrared photometry obtained with the Hubble Space Telescope (HST) in order to study the late-time evolution of the supernova remnant N132D, which is associated with the type Ic supernova SN2002ap. We find that the light curve of this supernova can be well fitted by a model consisting of two components: an initial power-law decline followed by a slower exponential decay. The best-fit parameters are consistent with those found previously using ground-based data. However, we also find evidence for additional flux at wavelengths longer than 1 micron after day 1000. This excess emission may arise from dust formed during the explosion or subsequent interaction between the ejecta and circumstellar material. In addition, our HST images reveal several bright knots along the southern edge of the remnant. These knots appear to have been ejected recently as they show no signs of fading over time scales ranging from months to years.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A deeper investigation for the progenitor of the Type Ic Supernova 2002ap . Abstract : We use new optical and far - infrared photometry obtained with the Hubble Space Telescope ( HST ) in order to study the late - time progression of the supernova remnant N132D , which is associated with the class Ic supernova SN2002ap .We see that the light curve of this supernova can be well fitted by a description consisting of two parts : an initial power - law decrease followed by a slower exponential decay . The best - fitting values are compatible with those identified previously using ground - based data .However , we also find proof for additional flux at wavelengths greater than 1 micron after day 1000 . This excess emission may arise from dust formed during the explosion or later interaction between the ejecta and circumstellar material .In addition , our HST pictures indicate many bright knots along the southern periphery of the remnant . These threads seem to have been expelled previously as they show no evidence of fading over time ranges ranging from months to decades .",
        "rewrite_text": "In this study, we present a comprehensive analysis of the progenitor of the Type Ic Supernova 2002ap by utilizing new optical and far-infrared photometric data acquired from the Hubble Space Telescope (HST). Our investigation focuses on the late-time evolution of the supernova remnant N132D, which is associated with SN2002ap. The light curve of this supernova exhibits a distinct pattern that can be effectively modeled as a combination of an initial power-law decline followed by a more gradual exponential decay. The parameters derived from our fitting align closely with those obtained from earlier ground-based observations, reinforcing the reliability of our findings. Notably, we have identified an additional flux component at wavelengths exceeding 1 micron, observed after day 1000. This excess emission is likely attributable to the formation of dust during the supernova explosion or the subsequent interaction of the ejected material with the surrounding circumstellar environment. Furthermore, our HST imaging reveals several bright knots along the southern edge of the remnant, which appear to have been ejected earlier in the supernova's history. These features exhibit no signs of fading over time spans ranging from months to decades, suggesting their stability and possibly indicating a complex interaction with the surrounding medium. Overall, our results contribute to a deeper understanding of the physical processes at play in the aftermath of SN2002ap and the characteristics of its progenitor system.",
        "ori-fast-z-score": 0.6469966392206304,
        "water-fast-z-score": 6.822422923379533,
        "rewrite-fast-z-score": 2.5743836117393535
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Discovery of a Ringlike Dark Matter Structure in the Core of the Galaxy Cluster Cl 0024+17 .\nAbstract:\nWe report on the discovery of an unexpected ring-like dark matter structure at the center of galaxy cluster CL0024+17, which is located about 3 billion light years away and has been studied extensively by many observational techniques including gravitational lensing.  The mass distribution inferred from strong gravitational lensing shows that there are two massive subclusters separated by 1 Mpc (3 arcmin) with a total mass of 2 x 10 15 h-1M_sun within a radius of 0.5h-1Mpc around their centers. We find that this double-cluster system can be well described as a binary merger model where each component consists of three components; one main halo and two smaller halos surrounding it. In addition to these six clusters, we also detect another small clump of galaxies near the center of the merging system whose position coincides with the peak of X-ray emission detected by Chandra satellite observations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Discovery of a Ringlike Dark Matter Structure in the Core of the Galaxy Cluster Cl 0024 + 17 . Abstract : We report on the discovery of an unexpected ring - like dark matter formation at the center of galaxy cluster CL0024 + 17 , which is situated about 3 billion light years far and has been studied significantly by many observational techniques including gravitational lensing .The mass distribution inferred from good gravitational lensing indicates that there are two huge subclusters separated by 1 Mpc ( 3 arcmin ) with a total mass of 2 x 10 15 g - 1M _ sun within a diameter of 0 . 5h - 1Mpc around their centers . We see that this double - cluster system can be well described as a binary merger model where each component consists of three components ; one main halo and two smaller halos covering it .In addition to these six galaxies , we also observe another tiny clump of clusters near the center of the merging system whose position coincides with the maximum of X - ray radiation observed by Chandra satellite observations .",
        "rewrite_text": "We present our findings on the discovery of a novel ring-like structure of dark matter located at the core of the galaxy cluster CL0024 + 17, which is approximately 3 billion light-years away from Earth. This cluster has been extensively analyzed through various observational methods, particularly gravitational lensing. Our analysis of the mass distribution, derived from precise gravitational lensing measurements, reveals the presence of two massive subclusters that are separated by a distance of 1 Mpc (approximately 3 arcminutes). The total mass of these subclusters is estimated to be around 2 x 10^15 solar masses within a radius of 0.5h^-1 Mpc from their centers. \n\nThe characteristics of this double-cluster system align well with a binary merger model, where each subcluster is composed of three distinct components: one dominant halo accompanied by two smaller halos that envelop it. In addition to these six prominent galaxies, we have identified a smaller clump of clusters situated near the center of the merging system. Notably, the position of this clump corresponds with the peak of X-ray emissions detected by observations from the Chandra satellite. This discovery not only enhances our understanding of the complex dynamics within galaxy clusters but also provides critical insights into the distribution and behavior of dark matter in such environments. The implications of these findings could significantly advance the field of astrophysics, particularly in the study of cosmic structure formation and the role of dark matter in the universe.",
        "ori-fast-z-score": 0.46499055497527714,
        "water-fast-z-score": 4.73427220735493,
        "rewrite-fast-z-score": -2.030146626995893
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Effects of Changes in Reaction Rates on Simulations of Nova Explosions .\nAbstract:\nWe have performed simulations of nova explosions using the hydrodynamic code VH-1, which includes nuclear burning and convection. We find that changes to reaction rates can significantly affect the results of these calculations. In particular, we show how different choices for the 12C(p,γ)13N rate lead to differences in the predicted light curve shapes.  The inclusion of this reaction is important because it affects the amount of 13N produced during the explosion. This isotope decays by electron capture into 14O, which then undergoes β+ decay back down to 14N. If there are too many electrons present at late times (due to an overabundance of 13N), they will be captured onto protons instead of being emitted as positrons; thus, less energy will be released than if no such process were occurring. Our results suggest that the current uncertainty in the 12C(p , γ )13N rate may cause errors in the predicted luminosity of up to 50%.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Effects of Changes in Reaction Rates on Simulations of Nova Explosions . Abstract : We have done simulations of nova explosions using the hydrodynamic code VH - 1 , which includes nuclear combustion and convection .We see that changes to reaction rates can significantly affect the results of these calculations . In particular , we find how changed options for the 12C ( p , γ ) 13N rate lead to differences in the expected light diagram forms .The inclusion of this process is important because it affects the quantity of 13N produced during the explosion . This isotope decays by electron capture into 14O , which then undergoes β + decay back down to 14N .If there are too several electrons present at late times ( owing to an overabundance of 13N ) , they will be captured onto protons rather of being emitted as positrons ; thus , fewer electricity will be released than if no such mechanism were happening . Our results show that the present uncertainty in the 12C ( p , γ ) 13N rate may create errors in the expected luminosity of up to 50 % .",
        "rewrite_text": "Title: The Effects of Changes in Reaction Rates on Simulations of Nova Explosions\n\nAbstract: In this study, we present a series of simulations focused on nova explosions, utilizing the hydrodynamic code VH-1, which incorporates both nuclear combustion and convection processes. Our findings reveal that variations in reaction rates can have a profound impact on the outcomes of these simulations. Specifically, we investigate the implications of altering the reaction rate for the process 12C(p, γ)13N, which significantly influences the resulting light curve characteristics observed during nova events. The production of the isotope 13N is particularly critical, as it undergoes electron capture to form 14O, which subsequently decays via β+ decay to yield 14N. \n\nThe presence of an excess of 13N can lead to an increased number of electrons at later stages of the explosion. In such scenarios, these electrons may be captured by protons instead of being emitted as positrons, resulting in a reduced energy output compared to a situation where this mechanism is absent. Our simulations indicate that the current uncertainties surrounding the 12C(p, γ)13N reaction rate could lead to discrepancies in the predicted luminosity of nova explosions, potentially by as much as 50%. This highlights the importance of accurately determining nuclear reaction rates in astrophysical models, as they play a crucial role in understanding the energy dynamics and observable characteristics of nova events. Overall, our work underscores the need for further investigation into reaction rates to improve the reliability of simulations and predictions related to nova explosions.",
        "ori-fast-z-score": -1.0533703247651751,
        "water-fast-z-score": 4.184914994777494,
        "rewrite-fast-z-score": -0.6767155423319645
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Challenges for MSSM Higgs searches at Hadron Colliders .\nAbstract:\nThe Minimal Supersymmetric Standard Model (MSSM) is the most widely studied extension to the Standard Model, and it predicts new particles that can be discovered in future experiments at the Large Hadron Collider (LHC). In this talk I will discuss some recent results on the search for supersymmetry using data collected by the ATLAS experiment during Run 1 of LHC operation. The focus will be on the properties of the lightest CP-even neutral Higgs boson h0, which are strongly affected by radiative corrections due to top/stop loops. These effects lead to significant deviations between predictions based on tree-level calculations and those obtained with full one-loop computations. This has important consequences both for experimental analyses as well as for theoretical studies aimed at extracting information about fundamental parameters such as tanβ or mtop from measurements performed at hadron colliders. \n \n For example, we show how the inclusion of higher-order corrections leads to an improved agreement between theory and experiment when comparing the measured mass of the Higgs boson with its predicted value within the MSSM framework. We also present results on the production cross sections of the different decay modes of the Higgs boson, including their dependence on the choice of renormalisation scale used in the calculation. Finally, we briefly comment on prospects for Higgs searches at the LHC after Run 2.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Challenges for MSSM Higgs searches at Hadron Colliders . Abstract : The Minimal Supersymmetric Standard Model ( MSSM ) is the most commonly explored extension to the Standard Model , and it predicts new objects that can be found in future research at the Large Hadron Collider ( LHC ) .In this talk I will explore some latest findings on the hunt for supersymmetry using data provided by the ATLAS experiment during Run 1 of LHC operation . The emphasis will be on the properties of the lightest CP - even stable Higgs boson h0 , which are strongly altered by radiative corrections due to top / stop loops .These effects lead to significant deviations between estimates based on tree - level calculations and those achieved with full one - loop computations . This has important implications both for research assessments as also as for theoretical experiments intended at extracting information about basic parameters such as tanβ or mtop from measurements accomplished at hadron colliders .For instance , we study how the inclusion of greater - order corrections helps to an better agreement between theoretical and experiment when comparing the measured mass of the Higgs boson with its predicted value within the MSSM framework . We additionally offer results on the production cross sections of the different decay modes of the Higgs boson , notably their dependence on the selection of renormalisation scale used in the calculation .Finally , we briefly comment on possibilities for Higgs searches at the LHC after Run 2 .",
        "rewrite_text": "**Title: Challenges for MSSM Higgs Searches at Hadron Colliders**\n\n**Abstract:** The Minimal Supersymmetric Standard Model (MSSM) stands as a prominent extension of the Standard Model, offering predictions for new particles that could be discovered in forthcoming experiments at the Large Hadron Collider (LHC). This presentation delves into recent advancements in the search for supersymmetry, utilizing data from the ATLAS experiment collected during the first run of LHC operations. A key focus is placed on the characteristics of the lightest CP-even Higgs boson, denoted as h0, whose properties are significantly influenced by radiative corrections stemming from top and stop quark loops. These corrections result in notable discrepancies between predictions derived from tree-level calculations and those obtained through comprehensive one-loop computations. Such differences carry substantial implications for both the evaluation of experimental results and theoretical efforts aimed at extracting fundamental parameters, including tanβ and mtop, from data gathered at hadron colliders.\n\nIn our analysis, we demonstrate how incorporating higher-order corrections enhances the alignment between theoretical predictions and experimental measurements, particularly when comparing the observed Higgs boson mass with its anticipated value within the MSSM context. Furthermore, we present findings on the production cross sections associated with various Higgs boson decay channels, highlighting their sensitivity to the choice of renormalization scale employed in the calculations. Lastly, we provide a brief overview of the prospects for Higgs boson searches at the LHC following the completion of Run 2, outlining potential avenues for future research in this critical area of particle physics.",
        "ori-fast-z-score": -1.5389675281277313,
        "water-fast-z-score": 5.381334675208182,
        "rewrite-fast-z-score": -2.4397501823713332
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The local stellar velocity field via vector spherical harmonics .\nAbstract:\nWe present an algorithm for the decomposition of the local stellar kinematics into vector spherical harmonic functions (VSH). The method is applied to simulated data and real observations, where we recover the underlying VSH coefficients with high accuracy. We show that our approach can be used as a powerful tool in galactic dynamics studies by recovering the gravitational potential of the Milky Way s dark matter halo. In addition, it allows us to study the anisotropy of the stellar orbits on different scales. \n \n Keywords: Vector spherical harmonics, Galactic dynamics, Stellar kinematics, Gravitational potentials \n \n 1 Introduction \n \n Spherical Harmonic Analysis has been widely used over many decades to analyse astronomical datasets such as galaxy surveys or star counts. However, this technique cannot easily be extended to deal with non-scalar quantities like velocities or accelerations. This problem was overcome by expanding these quantities onto vector spherical harmonics (VSH) which are defined as tensor products of scalar spherical harmonics  1  . These new basis functions have already found applications in fields ranging from cosmology  2  , solar physics  3  , heliophysics  4  and geophysics  5  .\n \nIn recent years there has been growing interest in using VSHs to model the observed properties of galaxies  6  -  8  . For example, they were recently employed to decompose the line-of-sight component of the stellar kinematics  9  . Here, we extend their use to also include the tangential components of the stellar motions. As a result, we obtain a complete description of the three-dimensional distribution of the stellar kinematics within each spatial bin. Moreover, since the expansion coefficients depend only on angular coordinates, they can be determined independently at every point along the line-of-sight. Therefore, our method does not require any assumptions about the symmetry of the system under investigation. \n2 Vector spherical harmonics",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The regional stellar velocity field via vector spherical harmonics . Abstract : We report an algorithm for the decomposition of the local stars kinematics into vector spherical harmonic functions ( VSH ) .The method is applied to simulated measurements and actual observations , where we recover the underlying VSH coefficients with high accuracy . We see that our approach can be used as a powerful tool in galactic dynamics experiments by rescuing the gravitational potential of the Milky Way s dark matter halo .In addition , it allows us to study the anisotropy of the stellar orbits on various scales . Keywords : Vector spherical harmonics , Galactic mechanics , Stellar kinematics , Gravitational potentials 1 Introduction Spherical Harmonic Analysis has been widely using over numerous years to analyse astronomical datasets such as galaxy surveys or star numbers .However , this methodology cannot easily be generalized to deal with non - scalar components like velocities or accelerations . This problem was resolved by expanding these quantities onto vector spherical harmonics ( VSH ) which are specified as vector products of scalar circular harmonics 1 .These new basis systems have already found uses in areas ranging from cosmology 2 , lunar science 3 , heliophysics 4 and geophysics 5 . In recent years there has been growing interest in utilizing VSHs to model the known characteristics of galaxies 6 - 8 .For instance , they were recently employed to decompose the line - of - view component of the stars kinematics 9 . Here , we stretch their application to additionally include the tangential parts of the stars movements .As a result , we obtain a complete model of the three - dimensional distribution of the stars kinematics within each spatial bin . Moreover , since the expansion equations depend only on angular coordinates , they can be determined independently at every position along the line - of - view .Therefore , our technique does not require any constraints about the symmetry of the process under investigation . 2 Vector spherical harmonics",
        "rewrite_text": "**Title:** The Regional Stellar Velocity Field via Vector Spherical Harmonics\n\n**Abstract:** In this study, we introduce a novel algorithm designed for the decomposition of local stellar kinematics using vector spherical harmonic functions (VSH). This method has been rigorously tested on both simulated datasets and actual observational data, demonstrating a high degree of accuracy in recovering the underlying VSH coefficients. Our findings indicate that this approach serves as a robust tool for galactic dynamics research, particularly in elucidating the gravitational potential of the Milky Way's dark matter halo. Furthermore, the application of VSH enables the investigation of anisotropies in stellar orbits across various spatial scales. \n\nSpherical Harmonic Analysis has long been employed in the analysis of astronomical datasets, including galaxy surveys and stellar distributions. However, traditional methods struggle to accommodate non-scalar components such as velocities and accelerations. We address this limitation by expanding these quantities into vector spherical harmonics, which are defined as vector products of scalar spherical harmonics. This innovative basis has found applications in diverse fields, including cosmology, lunar science, heliophysics, and geophysics. Recently, there has been an increasing interest in leveraging VSH to model the dynamics of galaxies, with previous studies focusing on the line-of-sight components of stellar kinematics. \n\nIn our work, we extend the application of VSH to encompass the tangential components of stellar motion, allowing us to construct a comprehensive model of the three-dimensional distribution of stellar kinematics within defined spatial bins. Notably, since the expansion equations rely solely on angular coordinates, they can be independently determined at each position along the line of sight. This independence from symmetry constraints enhances the versatility of our technique, making it applicable to a wide range of astrophysical investigations. \n\n**Keywords:** Vector spherical harmonics, Galactic mechanics, Stellar kinematics, Gravitational potentials.",
        "ori-fast-z-score": -1.8461989882527161,
        "water-fast-z-score": 7.0,
        "rewrite-fast-z-score": 0.43685202833051895
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Kinetic Sunyaev-Zel dovich Effect Due to the Electrons of Our Galaxy .\nAbstract:\nWe present an analysis of the kinetic Sunyaev-Zeldovich effect (kSZ) due to electrons in our galaxy, using data obtained with the Atacama Cosmology Telescope and the South Pole Telescope. We use two different methods for estimating the kSZ signal; one is based on cross-correlating maps of CMB temperature anisotropy at 150 GHz and 3000 GHz, while the other uses the power spectrum of the CMB temperature fluctuations at 150 GHz. The results are consistent between these two approaches within their respective uncertainties. We find that the amplitude of this signal agrees well with theoretical predictions when we assume a Navarro-Frenk-White profile for dark matter density distribution around galaxies. This measurement provides new constraints on cosmological parameters such as the Hubble constant H0 = 73 +/- 4 km s-1 Mpc-1 , the total mass density parameter Omega_m = 0.27 +/- 0.03 , and the equation-of-state w = -1.06 +/- 0.11 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Kinetic Sunyaev - Zel dovich Effect Due to the Electrons of Our Galaxy . Abstract : We present an assessment of the kinetic Sunyaev - Zeldovich effect ( kSZ ) related to electrons in our universe , using data acquired with the Atacama Cosmology Telescope and the South Pole Telescope .We use two different methods for estimating the kSZ signal ; one is based on cross - correlating mapping of CMB heat anisotropy at 150 GHz and 3000 GHz , while the other uses the power spectrum of the CMB heat fluctuations at 150 GHz . The results are compatible between these two methodology within their different uncertainties .We see that the amplitude of this signal agrees well with theoretical expectations when we assume a Navarro - Frenk - White model for heavy material concentration distribution around galaxies . This measurement gives additional constraints on cosmological factors such as the Hubble constant H0 = 73 + / - 4 km s - 1 Mpc - 1 , the total mass density variable Omega _ m = 0 . 27 + / - 0 . 03 , and the equation - of - state w = - 1 . 06 + / - 0 . 11 .",
        "rewrite_text": "In this study, we evaluate the kinetic Sunyaev-Zeldovich (kSZ) effect attributed to the electrons present in our galaxy, utilizing observational data from the Atacama Cosmology Telescope and the South Pole Telescope. Our analysis employs two distinct methodologies to estimate the kSZ signal. The first method involves cross-correlating maps of cosmic microwave background (CMB) temperature anisotropies at frequencies of 150 GHz and 3000 GHz. The second approach focuses on analyzing the power spectrum of CMB temperature fluctuations at 150 GHz. The findings from both methods show a high degree of consistency, falling within their respective uncertainties. \n\nOur results indicate that the amplitude of the kSZ signal aligns closely with theoretical predictions, particularly when we apply the Navarro-Frenk-White (NFW) model to describe the distribution of dark matter surrounding galaxies. This measurement provides valuable constraints on several key cosmological parameters, including the Hubble constant (H0), which we estimate to be 73 ± 4 km s⁻¹ Mpc⁻¹, the total matter density parameter (Ω_m) at 0.27 ± 0.03, and the equation of state parameter (w) calculated as -1.06 ± 0.11. These results contribute to our understanding of the universe's structure and evolution, offering insights into the interplay between baryonic and dark matter, as well as the dynamics of cosmic expansion. Overall, this work enhances our comprehension of the kSZ effect and its implications for cosmology, paving the way for future investigations into the fundamental properties of the universe.",
        "ori-fast-z-score": -0.3841106397986879,
        "water-fast-z-score": 4.826004826007239,
        "rewrite-fast-z-score": -0.19802950859533489
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Clustering Coefficients of Protein-Protein Interaction Networks .\nAbstract:\nWe study the clustering coefficients of protein-protein interaction networks (PPINs) and their relationship with network topological properties, such as degree distribution and average path length. We find that PPINs have higher clustering coefficients than random graphs with similar degrees or scale-free networks generated by Barabasi-Albert model. The high clustering coefficient is mainly due to the existence of many triangles in these networks. In addition, we show that the clustering coefficients are correlated positively with the number of proteins but negatively with the number of interactions per protein. These results suggest that there may be some common mechanisms underlying the formation of both triangles and edges between two nodes with large degrees. Finally, we propose an algorithm for identifying functional modules based on local clustering analysis. Our method can identify clusters with different sizes and shapes. Clustering coefficients of protein-protein interactomes are studied. It is found that they are significantly larger than those of random graphs with same degree distributions or scale-free networks generated using Barabasi-Albert preferential attachment rule. High clustering coefficients are mainly caused by the presence of many triangles in these systems. Correlations between clustering coefficients and other topological parameters are also investigated. An algorithm for finding functional modules based on local cluster analysis is proposed.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Clustering Coefficients of Protein - Protein Interaction Networks . Abstract : We research the clustering coefficients of protein - protein interaction systems ( PPINs ) and their connection with network topological features , such as extent distribution and average route length .We see that PPINs have greater clustering coefficients than random graphs with similar degrees or scale - free networks generated by Barabasi - Albert model . The high clustering coefficient is mainly owing to the existence of several triangles in these networks .In addition , we find that the clustering coefficients are correlated positively with the number of proteins but negatively with the quantity of interactions per protein . These conclusions propose that there may be some common mechanisms governing the formation of both triangles and edges between two nodes with large degrees .Finally , we propose an algorithm for finding functional domains based on local clustering theory . Our algorithm can identify clusters with various sizes and shapes .Clustering coefficients of gene - protein interactomes are studied . It is found that they are greatly larger than those of random graphs with same degree distributions or scale - free networks generated using Barabasi - Albert preferential attachment principle .High clustering variables are mainly caused by the presence of several triangles in these systems . Correlations between clustering parameters and other topological parameters are also examined .An method for finding functional modules based on local cluster analysis is proposed .",
        "rewrite_text": "**Title:** Clustering Coefficients of Protein-Protein Interaction Networks\n\n**Abstract:** This study investigates the clustering coefficients of protein-protein interaction networks (PPINs) and their relationship with various topological features of networks, including degree distribution and average path length. Our findings reveal that PPINs exhibit significantly higher clustering coefficients compared to random graphs with equivalent degree distributions and scale-free networks generated by the Barabási-Albert model. The elevated clustering coefficients in PPINs can primarily be attributed to the prevalence of triangular motifs within these networks. Furthermore, we observe a positive correlation between clustering coefficients and the total number of proteins present in the network, while a negative correlation exists with the average number of interactions per protein. These results suggest the existence of underlying mechanisms that influence the formation of both triangular connections and edges among nodes with high degrees. \n\nIn addition to our analysis of clustering coefficients, we propose a novel algorithm designed to identify functional domains based on local clustering theory. This algorithm is capable of detecting clusters of varying sizes and shapes, enhancing our understanding of the structural organization within PPINs. We also extend our investigation to the clustering coefficients of gene-protein interactomes, which demonstrate significantly higher values than those observed in random graphs with similar degree distributions or in scale-free networks constructed using the Barabási-Albert preferential attachment model. The high clustering observed is again largely due to the presence of numerous triangles within these systems. Additionally, we explore the correlations between clustering coefficients and other topological parameters, providing a comprehensive view of the intricate relationships that define the architecture of protein-protein interaction networks. Our proposed method for identifying functional modules through local cluster analysis offers a promising approach for further research in this domain.",
        "ori-fast-z-score": -1.7873696499288347,
        "water-fast-z-score": 4.270992778072193,
        "rewrite-fast-z-score": -0.40422604172722165
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Hagedorn Strings and Correspondence Principle in AdS(3) .\nAbstract:\nWe study the correspondence principle between string theory on anti-de Sitter space-time (AdS(3)) and field theories at finite temperature, by using Hagedorn strings as probes. We show that the number density of Hagedorn strings is proportional to the free energy density of the thermal gas of massless particles in the dual field theory. This result implies that the entropy density of the thermal gas agrees with the Bekenstein-Hawking entropy density of black holes in AdS(3). In addition we find that the pressure of the thermal gas agrees exactly with the negative cosmological constant in AdS(3), which corresponds to the vacuum expectation value of the dilaton field in the dual conformal field theory. These results are consistent with the holographic principle proposed recently for strongly coupled gauge theories. The present work may be regarded as an extension of our previous works  Phys Rev D71:035010  and  JHEP 0804:0703  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Hagedorn Strings and Correspondence Principle in AdS ( 3 ) . Abstract : We research the correspondence principle between string theory on anti - de Sitter space - time ( AdS ( 3 ) ) and field theories at finite temperature , by using Hagedorn strings as probes .We see that the number density of Hagedorn strings is proportional to the free energy density of the thermal gas of massless molecules in the dual field model . This result means that the entropy concentration of the thermal gas agrees with the Bekenstein - Hawking entropy concentration of black holes in AdS ( 3 ) .In addition we find that the pressure of the thermal gas agrees exactly with the negative cosmological constant in AdS ( 3 ) , which corresponds to the vacuum expectation value of the dilaton field in the dual conformal field model . These conclusions are compatible with the holographic principle adopted recently for highly coupled gauge fields .The present work must be regarded as an addition of our previous works Phys Rev D71 : 035010 and JHEP 0804 : 0703 .",
        "rewrite_text": "In this study, we investigate the correspondence principle between string theory in anti-de Sitter space-time (AdS(3)) and finite temperature field theories, utilizing Hagedorn strings as a means of exploration. Our findings reveal that the number density of Hagedorn strings is directly proportional to the free energy density of a thermal gas composed of massless particles in the corresponding dual field theory. This relationship indicates that the entropy density of the thermal gas aligns with the Bekenstein-Hawking entropy associated with black holes in AdS(3). Furthermore, we demonstrate that the pressure exerted by the thermal gas precisely matches the negative cosmological constant characteristic of AdS(3), which is linked to the vacuum expectation value of the dilaton field in the dual conformal field theory. These results are consistent with the holographic principle, which has recently been applied to strongly coupled gauge theories. This work serves as a continuation of our earlier research published in Phys Rev D71: 035010 and JHEP 0804: 0703, contributing further insights into the intricate relationship between string theory and thermal field theories in the context of AdS space.",
        "ori-fast-z-score": 0.11396057645963795,
        "water-fast-z-score": 4.076197322920544,
        "rewrite-fast-z-score": 1.6081688022566922
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Conservation-Law-Induced Quantum Limits for Physical Realizations of the Quantum NOT Gate .\nAbstract:\nWe show that any physical realization of the quantum NOT gate must be accompanied by an energy cost, which is bounded below by a universal constant times the number of qubits in the system. This result follows directly from our proof of the existence of a lower bound on the ground-state energy density of certain spin systems with competing interactions and open boundary conditions. Our results are relevant to recent efforts aimed at realizing large-scale quantum computers using solid state devices such as semiconductor quantum dots or trapped ions. We also discuss possible extensions of this work to other types of quantum gates. The ability to perform arbitrary unitary transformations on a set of n qubits would constitute a quantum computer capable of solving problems exponentially faster than classical computers  1  . However, it has been shown  2  that no quantum algorithm can solve all computational problems more efficiently than its best known classical counterpart unless the polynomial hierarchy collapses. Thus, practical quantum computing requires efficient methods for implementing only those algorithms whose solutions cannot be found classically  3  .\nIn order to implement these algorithms, one needs to be able to perform basic operations such as single-qubit rotations  4  , two-qubit entangling gates  5  , and measurements  6  . In particular, the so-called CNOT (controlled-NOT) gate plays a central role  7, 8  since it allows one to construct many important quantum circuits  9  . Unfortunately, there exists no known method for constructing a general CNOT gate  10  ; however, several proposals have recently emerged  11  -  16  . These schemes typically involve coupling the spins of individual atoms via magnetic fields  17  and/or optical cavities  18  . While some experimental progress towards building small-scale quantum computers has already been made  19, 20  , scaling up these technologies remains extremely challenging  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Conservation - Law - Induced Quantum Limits for Physical Realizations of the Quantum NOT Gate . Abstract : We see that any physical realization of the quantum NOT gate must be accompanied by an energy cost , which is bounded below by a universal constant times the number of qubits in the system .This result follows directly from our proof of the existence of a lower bound on the ground - state energy density of certain spin systems with competing interactions and open boundary constraints . Our results are applicable to recent efforts aimed at developing huge - scale quantum computers utilizing steady state systems such as semiconductor quantum dots or trapped ions .We also discuss possible extensions of this study to other types of quantum gates . The able to conduct arbitrary unitary transformations on a group of n qubits would create a quantum computer capable of solution problems exponentially better than classical systems 1 .However , it has been shown 2 that no quantum algorithm can answer all theoretical difficulties more efficiently than its best known classical counterpart unless the polynomial hierarchy collapses . Thus , practical quantum modeling needs efficient methods for applying only those algorithms whose solutions cannot be found classically 3 .In order to execute these algorithms , one needs to be able to conduct basic operations such as single - qubit rotations 4 , two - qubit entangling gates 5 , and measurements 6 . In particular , the so - called CNOT ( controlled - NOT ) gate plays a central role 7 , 8 since it allows one to build much crucial quantum networks 9 .Unfortunately , there exists no available method for constructing a general CNOT gate 10 ; however , various options have recently surfaced 11 - 16 . These methods typically involve bonding the spins of individual atoms via magnetic waves 17 and / or laser cavities 18 .While some experimental development towards creating low - scale quantum computers has already been achieved 19 , 20 , scaling up these concepts remains incredibly challenging 21 .",
        "rewrite_text": "Title: Conservation-Law-Induced Quantum Limits for Physical Realizations of the Quantum NOT Gate\n\nAbstract: This article investigates the inherent energy costs associated with the physical realization of the quantum NOT gate, revealing that such costs are fundamentally constrained by a universal constant multiplied by the number of qubits in the system. This finding is derived from our rigorous proof establishing a lower bound on the ground-state energy density of specific spin systems characterized by competing interactions and open boundary conditions. Our results are particularly relevant to contemporary efforts focused on the development of large-scale quantum computers, which often utilize steady-state systems like semiconductor quantum dots or trapped ions. Furthermore, we explore potential extensions of our findings to other quantum gate types, emphasizing the importance of conducting arbitrary unitary transformations on n qubits to create quantum computers capable of solving problems exponentially faster than classical systems. However, it has been demonstrated that no quantum algorithm can universally outperform its best-known classical counterpart unless the polynomial hierarchy collapses. Consequently, practical quantum modeling necessitates efficient strategies for implementing algorithms whose solutions are not classically attainable. Essential operations for executing these algorithms include single-qubit rotations, two-qubit entangling gates, and measurements. Among these, the controlled-NOT (CNOT) gate is particularly significant, as it serves as a foundational component for constructing critical quantum networks. Despite the absence of a universally applicable method for realizing a general CNOT gate, several promising approaches have emerged recently, often involving the coupling of individual atomic spins through magnetic waves and/or laser cavities. While initial experimental advancements toward low-scale quantum computers have been made, the challenge of scaling these concepts to larger systems remains formidable.",
        "ori-fast-z-score": -0.6209204205650662,
        "water-fast-z-score": 5.675540917470541,
        "rewrite-fast-z-score": -0.5734623443633283
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Suzaku Observations of Active Galactic Nuclei Detected in the Swift/BAT Survey: Discovery of  New Type  of Buried Supermassive Black Holes .\nAbstract:\nWe report on Suzaku observations for four active galactic nuclei (AGNs) detected by Swift/BAT survey, which are classified as  obscured AGNs  with column density larger than 10 24 cm-2 . We found that all these sources show strong Fe K emission lines and their line widths are broader than those expected from thermal broadening at kT = 100 keV. The observed line profiles can be reproduced well by relativistic disk reflection models including Compton scattering effects. These results suggest that there is an additional component to the X-ray continuum other than the standard thin accretion disks around supermassive black holes. In addition, we find that the iron abundance relative to solar value is higher than 1.5 times in three out of four objects. This suggests that the central engines of these obscured AGNs may have been buried under heavy dusty torii. Finally, we discuss possible origins of this new type of buried supermassive black holes based on our observational results.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Suzaku Observations of Active Galactic Nuclei Detected in the Swift / BAT Survey : Discovery of New Type of Buried Supermassive Black Holes . Abstract : We report on Suzaku measurements for four active galactic nuclei ( AGNs ) detected by Swift / BAT search , which are classified as obscured AGNs with column velocity larger than 10 24 mm - 2 .We showed that all these sources show intense Fe K emission lines and their line widths are larger than those expected from thermal broadening at kT = 100 keV . The observed line profiles can be reproduced well by relativistic disk absorption theories including Compton absorption effects .These data suggest that there is an additional element to the X - ray continuum other than the standard narrow accretion disks around supermassive black holes . In addition , we find that the metal density relative to solar value is higher than 1 . 5 times in three out of four bodies .This implies that the main engines of these obscured AGNs might have been trapped under heavy dusty torii . Finally , we investigate possible origins of this new kind of hidden supermassive black holes using on our observational results .",
        "rewrite_text": "We present findings from Suzaku observations of four active galactic nuclei (AGNs) identified in the Swift/BAT survey, which are categorized as obscured AGNs exhibiting column densities exceeding 10^24 cm^-2. Our analysis reveals that all four sources exhibit pronounced Fe K emission lines, with line widths that surpass those anticipated from thermal broadening at a temperature of kT = 100 keV. The observed line profiles align closely with predictions from relativistic disk absorption models, which account for Compton absorption effects. These results indicate the presence of additional components in the X-ray continuum beyond the conventional narrow accretion disks typically associated with supermassive black holes. Furthermore, we observe that the metallicity in three of the four AGNs is more than 1.5 times the solar value, suggesting that these obscured AGNs may be situated within dense, dusty toroidal structures that obscure their central engines. Our findings prompt a reevaluation of the characteristics and environments of these hidden supermassive black holes, leading us to explore potential origins for this newly identified class of AGNs based on our observational data. This research contributes to a deeper understanding of the complex nature of AGNs and the role of obscuration in their evolution, highlighting the significance of advanced observational techniques in uncovering the hidden aspects of these powerful cosmic entities.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.111111111111111,
        "rewrite-fast-z-score": 1.237705495510552
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Effects of Selection and Covariance on X-ray Scaling Relations of Galaxy Clusters .\nAbstract:\nWe study the effects of selection biases in cluster samples, as well as covariance between observables, on scaling relations derived from X-ray data using mock galaxy clusters generated with the semi-analytic model GALFORM. We find that both these effects can lead to significant systematic errors when deriving cosmological constraints from observed scaling relations. In particular we show that: (i) The scatter in the M-T relation is significantly reduced by including additional information about the temperature distribution function; this effect is stronger for low mass systems. (ii) The slope of the L-M relation depends strongly on whether or not one includes cooling flows in the analysis. This dependence arises because cool cores are more common at high masses than at lower masses, leading to an apparent steepening of the slope if they are excluded. (iii) The normalization of the Y-Xray luminosity-temperature relation shows strong redshift evolution which cannot be explained solely by self-similar evolution.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Effects of Selection and Covariance on X - ray Scaling Relations of Galaxy Clusters . Abstract : We research the effects of selection biases in cluster specimens , as well as covariance between observables , on scaling relations derived from X - ray data utilizing simulated star clusters constructed with the semi - analytic method GALFORM .We see that both these influences can lead to significant systematic errors when deriving cosmological limitations from observed scaling relations . In particular we find that : ( i ) The scatter in the M - T relation is significantly reduced by including extra data about the temperature distribution function ; this effect is greater for low mass systems .( ii ) The slope of the L - M relation depends strongly on whether or not one includes cooling flows in the analysis . This dependence occurs because cool cores are more common at high masses than at lower masses , leading to an apparent steepening of the gradient if they are excluded .( iii ) The normalization of the Y - Xray luminosity - temperature relation shows intense redshift development which cannot be described solely by self - similar development .",
        "rewrite_text": "**Title:** Effects of Selection and Covariance on X-ray Scaling Relations of Galaxy Clusters\n\n**Abstract:** This study investigates the impact of selection biases in galaxy cluster samples and the covariance among various observables on the scaling relations derived from X-ray observations. Utilizing simulated star clusters generated through the semi-analytic method known as GALFORM, we demonstrate that both selection effects and covariance can introduce significant systematic errors when interpreting cosmological constraints based on observed scaling relations. Our findings reveal several key insights: (i) The scatter observed in the mass-temperature (M-T) relation is notably diminished when additional data regarding the temperature distribution function is incorporated, with this effect being particularly pronounced in lower mass systems. (ii) The slope of the luminosity-mass (L-M) relation is highly sensitive to the inclusion of cooling flows in the analysis. This sensitivity arises from the prevalence of cool cores in high-mass clusters compared to their lower-mass counterparts, which can lead to an apparent steepening of the slope if cooling flows are omitted from consideration. (iii) The normalization of the Y-Xray luminosity-temperature relation exhibits significant evolution with redshift, a phenomenon that cannot be adequately explained by self-similar evolution alone. Overall, our research underscores the necessity of accounting for selection biases and covariance in order to accurately interpret the scaling relations of galaxy clusters and their implications for cosmology.",
        "ori-fast-z-score": -0.22086305214969307,
        "water-fast-z-score": 4.500334659577304,
        "rewrite-fast-z-score": 0.19245008972987526
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Electrostatic Climber for Space Elevator and Launcher .\nAbstract:\nThe space elevator is an important project in the future space exploration, which can provide transportation between Earth orbit and ground with high efficiency. The electrostatic climber (EC) is one key component of the space elevator system that will be used to transport passengers or cargoes up and down along the cable. In this work, we present a novel design concept of EC based on the principle of electrodynamic levitation. A prototype has been built according to our proposed design. It consists of two main parts: the upper platform and lower platform. The upper platform contains four permanent magnets arranged in square shape; while the lower platform includes eight coils connected in series. The experimental results show that the maximum lift force generated by the EC reaches about 1 N at the current density of 0.5 A/mm2 . This value meets the requirement of the space elevator application. Moreover, it also shows good stability when the load changes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Electrostatic Climber for Space Elevator and Launcher . Abstract : The space lift is an important project in the future space exploration , which can provide transit between Earth orbit and ground with high efficiency .The electrostatic climber ( EC ) is one key feature of the spacecraft elevator system that will be used to transport passengers or cargoes up and down along the chain . In this project , we present a new design concept of EC using on the principle of electrodynamic levitation .A prototype has been built according to our proposed design . It consists of two principal portions : the higher platform and lower platform .The upper platform includes four permanent magnets placed in square shape ; while the lower platform includes eight coils connected in series . The empirical results show that the maximum pull pressure generated by the EC reaches about 1 N at the current density of 0 . 5 A / mm2 .This value meets the requirement of the space elevator application . Moreover , it also shows excellent stability when the load changes .",
        "rewrite_text": "**Title:** Electrostatic Climber for Space Elevator and Launcher\n\n**Abstract:** The concept of a space elevator represents a significant advancement in future space exploration, offering an efficient means of transportation between Earth's surface and orbit. Central to this innovative system is the electrostatic climber (EC), designed to facilitate the movement of passengers and cargo along a tether. In this study, we introduce a novel design for the electrostatic climber based on the principles of electrodynamic levitation. We have developed a prototype that embodies our design specifications, which comprises two main components: an upper platform and a lower platform. The upper platform is equipped with four permanent magnets arranged in a square configuration, while the lower platform features eight coils connected in series to generate the necessary electromagnetic forces. Our empirical findings indicate that the electrostatic climber can produce a maximum pull force of approximately 1 N at a current density of 0.5 A/mm², which aligns with the operational requirements for space elevator applications. Additionally, the prototype demonstrates remarkable stability in response to varying load conditions, suggesting its potential for reliable performance in practical scenarios. This research not only contributes to the theoretical framework of space elevator technology but also lays the groundwork for future developments in space transportation systems. The successful implementation of the electrostatic climber could revolutionize access to space, making it more feasible and efficient, thereby opening new avenues for exploration and utilization of extraterrestrial resources.",
        "ori-fast-z-score": -0.4364357804719848,
        "water-fast-z-score": 3.927922024247863,
        "rewrite-fast-z-score": -1.2229371288986763
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Measurement of Newtonian fluid slip using a torsional ultrasonic oscillator .\nAbstract:\nWe present an experimental method for measuring the slip length in Newtonian fluids at low Reynolds number by means of a torsional ultrasonic oscillator (TUSO). The TUSO is immersed into the liquid and driven to vibrate with angular frequency . A torque proportional to the shear stress acting on its surface causes it to rotate, which can be detected electrically via a pickup coil wound around the shaft. We show that this rotation leads to a phase lag between driving voltage and current through the pickup coil. This phase lag depends on the slip length as well as other parameters such as viscosity and density of the surrounding medium. By fitting our theoretical model to measurements we are able to extract the slip length from the data. Our results agree very well with previous experiments performed under similar conditions. In addition, we demonstrate how the measurement principle presented here could also be used to measure the slip length of non-Newtonian fluids.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Measurement of Newtonian flow slipping using a torsional ultrasonic oscillator . Abstract : We report an experimental method for determining the slip length in Newtonian fluids at low Reynolds number by means of a torsional ultrasonic oscillator ( TUSO ) .The TUSO is immersed into the liquid and driven to vibrate with angular frequency . A torque proportional to the shear force acting on its surface causes it to rotate , which can be identified electrically via a pickup coil wound around the shaft .We see that this rotation leads to a phase lag between driving voltage and current through the pickup coil . This phase lag depends on the slip length as well as other parameters such as viscosity and density of the nearby medium .By fitting our theory model to measurements we are able to extract the slip length from the information . Our results agree very well with previous tests accomplished under similar situations .In addition , we prove how the observation concept provided here could also be used to measure the slip length of non - Newtonian fluids .",
        "rewrite_text": "We present a novel experimental technique for measuring the slip length in Newtonian fluids at low Reynolds numbers, utilizing a torsional ultrasonic oscillator (TUSO). The TUSO is submerged in the fluid and is set into oscillation at a specific angular frequency. As the TUSO vibrates, a torque that is proportional to the shear force exerted on its surface induces rotation, which can be detected electrically through a pickup coil wrapped around the oscillator's shaft. This rotation results in a phase lag between the driving voltage and the current measured by the pickup coil. Notably, this phase lag is influenced by the slip length, as well as other fluid properties such as viscosity and density. By fitting our theoretical model to the experimental data, we can accurately determine the slip length from the observed phase lag. Our findings are consistent with previous studies conducted under similar experimental conditions, reinforcing the validity of our approach. Furthermore, we demonstrate that the methodology described can be extended to measure the slip length in non-Newtonian fluids, thereby broadening the applicability of the TUSO technique. This work not only enhances our understanding of fluid dynamics at low Reynolds numbers but also provides a reliable tool for investigating slip phenomena in various fluid types, which is crucial for applications in fields such as microfluidics and material science.",
        "ori-fast-z-score": 1.8439088914585775,
        "water-fast-z-score": 6.038635299392551,
        "rewrite-fast-z-score": 0.502518907629606
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Helium abundance in galaxy clusters and Sunyaev-Zeldovich effect .\nAbstract:\nWe present new measurements of the helium mass fraction YHe = 0.24 ± 0.01 (statistical) ±0.02 (systematic), obtained by combining X-ray data on galaxy clusters with SZ observations, using the sample of 62 nearby relaxed galaxy clusters observed at high signal-to-noise ratio by Planck satellite. The results are consistent with previous determinations based on Chandra or XMM-Newton data alone. \n \n We also report an improved measurement of the Hubble constant H0 = 67.4±1.2 km s-1 Mpc-1, which is derived from our determination of the angular diameter distance to these clusters combined with their redshifts. This value agrees well with other recent estimates but has smaller statistical uncertainty than most of them. It is also compatible within 1 sigma with the local measurement inferred from Cepheid variables. \n \n Finally we use this dataset to test for possible deviations from standard cosmology due to massive neutrinos. Our analysis shows that current data do not allow us to detect any significant deviation from the predictions of ΛCDM model.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Helium abundance in galaxy clusters and Sunyaev - Zeldovich effect . Abstract : We report new studies of the helium mass fraction YHe = 0 . 24 ± 0 . 01 ( statistical ) ±0 . 02 ( systematic ) , obtained by combining X - ray data on galaxy clusters with SZ measurements , using the sample of 62 nearby relaxed galaxy galaxies studied at high signal - to - noise ratio by Planck satellite .The results are compatible with previous determinations based on Chandra or XMM - Newton data alone . We additionally report an better determination of the Hubble constant H0 = 67 . 4±1 . 2 km s - 1 Mpc - 1 , which is calculated from our determination of the angular length length to these clusters combined with their redshifts .This value agrees well with other recent estimates but has less statistical uncertainty than most of them . It is also consistent within 1 sigma with the local measurement inferred from Cepheid variables .Finally we utilize this dataset to test for probable deviations from standard cosmology resulting to massive neutrinos . Our study shows that current data do not enable us to identify any considerable deviation from the estimates of ΛCDM system .",
        "rewrite_text": "We present new findings on the helium mass fraction, denoted as YHe = 0.24 ± 0.01 (statistical) ± 0.02 (systematic), derived from an analysis that integrates X-ray observations of galaxy clusters with Sunyaev-Zeldovich (SZ) effect measurements. This research utilizes a sample of 62 nearby, relaxed galaxy clusters, which were examined at a high signal-to-noise ratio by the Planck satellite. Our results align with previous helium abundance estimates obtained from Chandra and XMM-Newton data, reinforcing the reliability of our findings. In addition, we provide an improved measurement of the Hubble constant, H0 = 67.4 ± 1.2 km s⁻¹ Mpc⁻¹, calculated by correlating the angular diameter distances to these clusters with their respective redshifts. This value not only corroborates recent estimates but also exhibits a lower statistical uncertainty compared to many prior measurements. Furthermore, it remains consistent within one sigma with local measurements derived from Cepheid variable observations. Lastly, we leverage this comprehensive dataset to investigate potential deviations from standard cosmological models, particularly in relation to the presence of massive neutrinos. Our analysis indicates that the current data do not reveal any significant deviations from the predictions of the ΛCDM model, suggesting that the standard cosmological framework remains robust in light of our findings.",
        "ori-fast-z-score": -0.10846522890932808,
        "water-fast-z-score": 5.467773927672753,
        "rewrite-fast-z-score": 0.7107423155935334
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Optical BVI Imaging and HI Synthesis Observations of the Dwarf Irregular Galaxy ESO 364-G 029 .\nAbstract:\nWe present optical BVRI imaging, near-infrared JHKs photometry, and radio continuum observations at 1.4 GHz for the dwarf irregular galaxy ESO 364-G 029 (UGC 6456). The new data are combined with existing Hα spectroscopy to study its star formation history over the past few hundred million years. We find that this galaxy has experienced several bursts of intense star formation in recent times, which have produced large amounts of ionized gas visible as bright knots of emission across most of the face-on disk. These knots appear to be associated with young massive stars formed during each episode of star formation. In addition, we detect an extended component of diffuse ionized gas surrounding these knots. This is likely due to photoionization by hot evolved stars or supernovae remnants. Using our deepest images taken under good seeing conditions, we measure a total stellar mass of M = 2.1 × 10^7 M_sol within a radius of 5 kpc.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Optical BVI Imaging and HI Synthesis Observations of the Dwarf Irregular Galaxy ESO 364 - G 029 . Abstract : We report optical BVRI imaging , near - infrared JHKs photometry , and radio continuum measurements at 1 . 4 GHz for the dwarf irregular universe ESO 364 - G 029 ( UGC 6456 ) .The revised data are coupled with existing Hα spectroscopy to study its galaxy formation history over the previous few hundred million years . We see that this galaxy has undergone several bursts of aggressive star formation in recent periods , which have created vast quantities of ionized gas evident as bright knots of emission across most of the face - on disk .These knots appear to be identified with young massive stars formed during each season of star formation . In addition , we find an extended component of diffuse ionized gas covering these knots .This is probably due to photoionization by hot evolved galaxies or supernovae fragments . Using our deepest images took under good see conditions , we measure a total stellar mass of M = 2 . 1 × 10 ^ 7 M _ sol within a diameter of 5 kpc .",
        "rewrite_text": "We present a comprehensive study of the dwarf irregular galaxy ESO 364-G 029 (UGC 6456), utilizing optical BVRI imaging, near-infrared JHKs photometry, and radio continuum observations at 1.4 GHz. This research integrates newly acquired data with existing Hα spectroscopy to investigate the galaxy's formation history over the past few hundred million years. Our findings reveal that ESO 364-G 029 has experienced multiple episodes of vigorous star formation in recent times, resulting in the production of significant amounts of ionized gas. This ionized gas is prominently displayed as bright emission knots distributed across the galaxy's face-on disk, which are associated with young massive stars that have formed during these star formation events. Furthermore, we observe an extended region of diffuse ionized gas surrounding these emission knots, likely resulting from photoionization processes driven by hot evolved stars or remnants from supernova explosions. By analyzing our deepest images captured under optimal seeing conditions, we estimate the total stellar mass of the galaxy to be approximately M = 2.1 × 10^7 M_sol within a radius of 5 kpc. This research enhances our understanding of the star formation dynamics and the evolutionary processes occurring in dwarf irregular galaxies, contributing valuable insights into the broader context of galaxy formation and evolution.",
        "ori-fast-z-score": -0.22086305214969307,
        "water-fast-z-score": 5.597977259474208,
        "rewrite-fast-z-score": 0.9712858623572641
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multidimensional fluid motions with planar waves .\nAbstract:\nWe consider the motion of an incompressible, inviscid fluid in two dimensions under the influence of gravity and surface tension. The flow is assumed to be irrotational except for a finite number of singularities at which point vorticity may accumulate. We show that if the initial data are sufficiently small then there exists a unique global solution whose velocity field has only one component along each line parallel to the x-axis. This result generalizes previous results on two-dimensional flows by allowing more complicated wave patterns such as those generated by water waves or nonlinear optics. \n \n Keywords: Fluids; Vortices; Water waves; Nonlinear optics. 1 Introduction \n \n In this work we study the dynamics of fluids governed by the Euler equations in two space dimensions. Our main goal is to prove existence of solutions having certain special properties. More precisely, let us assume that the initial velocity field u0(x) = (u0x(x), u0y(x)) satisfies the following conditions:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multidimensional liquid motions with planar waves . Abstract : We consider the movement of an incompressible , inviscid fluid in two dimensions under the effects of gravitational and surface stress .The flow is assumed to be irrotational except for a finite number of singularities at which point vorticity may accumulate . We see that if the first data are sufficiently small then there exists a unique global solution whose speed field has only one element along each line parallel to the x - axis .This result generalizes earlier findings on two - dimensional flows by giving more complicated wave patterns such as those generated by water waves or nonlinear optics . Keywords : Fluids ; Vortices ; Water waves ; Nonlinear optics .1 Introduction In this study we study the dynamics of fluids governed by the Euler equations in two space dimensions . Our main goal is to prove existence of solutions having specific particular features .More specifically , let us assume that the initial velocity field u0 ( x ) = ( u0x ( x ) , u0y ( x ) ) satisfies the following conditions :",
        "rewrite_text": "**Title:** Multidimensional Liquid Motions with Planar Waves\n\n**Abstract:** This article investigates the behavior of an incompressible, inviscid fluid in two-dimensional space, influenced by gravitational forces and surface tension. The flow is characterized as irrotational, with the exception of a finite number of singularities where vorticity can accumulate. We establish that, under the condition that the initial data is sufficiently small, there exists a unique global solution. This solution is notable for its speed field, which maintains a singular value along each line parallel to the x-axis. This finding extends previous research on two-dimensional fluid dynamics by accommodating more complex wave patterns, akin to those observed in water waves and phenomena in nonlinear optics. The implications of this study are significant for understanding fluid behavior in various applications, including environmental science and engineering. The keywords associated with this research include fluids, vortices, water waves, and nonlinear optics. \n\n**1 Introduction:** In this research, we delve into the dynamics of fluids as described by the Euler equations within a two-dimensional framework. Our primary objective is to demonstrate the existence of solutions that exhibit specific characteristics. We begin by considering an initial velocity field denoted as u0(x) = (u0x(x), u0y(x)), which adheres to certain predefined conditions. Through this exploration, we aim to contribute to the broader understanding of fluid motion and its complexities, particularly in relation to wave interactions and the formation of vortices.",
        "ori-fast-z-score": 0.11396057645963795,
        "water-fast-z-score": 4.387842813611494,
        "rewrite-fast-z-score": 1.8542101386022132
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Cornell Caltech Atacama Telescope .\nAbstract:\nThe Cornell Caltech Atacama: The Cornell Caltech Atacame Observatory (CCAT) is an optical and infrared telescope under construction in Chile s northern desert, near the town of San Pedro de Atacama.  CCAT will be one of the largest telescopes ever built with a diameter of 24 meters.   It was designed to have unprecedented sensitivity for detecting faint objects such as distant galaxies or exoplanets around other stars.    CCAT will also provide high angular resolution images that can resolve individual stars within these distant galaxies. CCAT will use adaptive optics technology to correct for atmospheric distortions caused by turbulence in Earth s atmosphere. This will allow it to produce sharper images than are possible today using conventional techniques. CCAT will operate at wavelengths ranging from 0.35 microns to 16 microns. CCAT will consist of two main components:  A large primary mirror made out of silicon carbide.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Cornell Caltech Atacama Telescope . Abstract : The Cornell Caltech Atacama : The Cornell Caltech Atacame Observatory ( CCAT ) is an optical and infrared telescope under construction in Chile s northern desert , near the town of San Pedro de Atacama .CCAT will be one of the huge telescopes yet built with a diameter of 24 meters . It was built to have enormous sensitivity for detecting distant objects such as distant galaxies or exoplanets around other stars .CCAT will also supply high angular resolution images that can resolve individual stars within these distant galaxies . CCAT will use adaptive optics techniques to correct for atmospheric distortions caused by turbulence in Earth s atmosphere .This will allow it to produce sharper pictures than are possible nowadays used conventional methods . CCAT will work at wavelengths ranging from 0 . 35 microns to 16 microns .CCAT will include of two principal modules : A wide primary mirror making out of silicon carbide .",
        "rewrite_text": "Title: The Cornell Caltech Atacama Telescope\n\nAbstract: The Cornell Caltech Atacama Telescope (CCAT) is an advanced optical and infrared observatory currently under construction in the arid northern desert of Chile, specifically near the town of San Pedro de Atacama. Once completed, CCAT will stand as one of the largest telescopes ever built, featuring an impressive diameter of 24 meters. This significant size is designed to enhance its sensitivity, enabling the detection of distant astronomical objects, including remote galaxies and exoplanets orbiting other stars. \n\nOne of the key capabilities of CCAT is its ability to produce high angular resolution images, which will allow astronomers to resolve individual stars within these far-off galaxies. To achieve this, CCAT will employ cutting-edge adaptive optics techniques that compensate for atmospheric distortions caused by turbulence in the Earth's atmosphere. This innovative approach will enable the telescope to generate sharper images than those produced by conventional observational methods currently in use.\n\nCCAT will operate across a broad range of wavelengths, from 0.35 microns to 16 microns, allowing it to capture a diverse array of astronomical phenomena. The telescope's design includes two primary modules, featuring a wide primary mirror constructed from silicon carbide, a material chosen for its durability and optical properties. The combination of its large aperture, advanced adaptive optics, and versatile wavelength range positions CCAT to make significant contributions to our understanding of the universe, particularly in the fields of galaxy formation, stellar evolution, and the search for extraterrestrial life. As such, CCAT is poised to become a pivotal tool for astronomers and researchers, facilitating groundbreaking discoveries in the realm of modern astrophysics.",
        "ori-fast-z-score": 0.3779644730092272,
        "water-fast-z-score": 5.0,
        "rewrite-fast-z-score": 0.4472135954999579
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Complexity of Model Checking Higher-Order Fixpoint Logic .\nAbstract:\nWe study the complexity of model checking higher-order fixpoint logic (HFL) over finite Kripke structures, which is an extension of propositional modal logic with fixpoints and quantification over state variables ranging over infinite domains. We show that HFL satisfiability can be reduced to the problem of deciding whether there exists a solution for a system of linear equations in rational numbers whose coefficients are given by polynomials over integers. This reduction allows us to obtain lower bounds on the computational complexity of HFL satisfiability using known results about solving systems of polynomial equations. In particular, we prove PSPACE-hardness of HFL satisfiability when the number of fixpoint operators occurring in the formula is unbounded or restricted only to existential ones. On the other hand, we provide a simple algorithm for HFL satisfiability based on computing least solutions of certain systems of integer quadratic equations. The running time of this algorithm depends exponentially on the maximum degree of these equations but it does not depend on the number of fixpoint",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Complexity of Model Checking Higher - Order Fixpoint Logic . Abstract : We research the complexity of model checking upper - order fixpoint reasoning ( HFL ) over finite Kripke structures , which is an extension of propositional modal logic with fixpoints and quantification over state variables ranging over infinite domains .We see that HFL satisfiability can be reduced to the question of deciding whether there exists a solution for a system of linear equations in rational numbers whose coefficients are given by polynomials over integers . This reduction provides us to obtain lower bounds on the computational difficulty of HFL satisfiability utilizing famous results about solving networks of polynomial equations .In particular , we prove PSPACE - hardness of HFL satisfiability when the number of fixpoint operators happening in the formula is unbounded or restricted only to existential ones . On the other hand , we provide a simple algorithm for HFL satisfiability based on solving least solutions of certain systems of integer quadratic equations .The run time of this algorithm depends exponentially on the maximum degree of these equations but it does not depend on the number of fixpoint",
        "rewrite_text": "In this article, we investigate the computational complexity associated with model checking higher-order fixpoint logic (HFL) within the context of finite Kripke structures. HFL serves as an advanced extension of propositional modal logic, incorporating fixpoints and allowing for quantification over state variables that can take on values from infinite domains. Our primary focus is on establishing a connection between HFL satisfiability and the solvability of linear equations with rational coefficients, where these coefficients are derived from integer polynomials. This reduction is significant as it enables us to derive lower bounds on the complexity of determining HFL satisfiability by leveraging established results concerning the resolution of polynomial equation networks.\n\nIn our findings, we demonstrate that HFL satisfiability is PSPACE-hard, particularly in scenarios where the number of fixpoint operators in the formula is either unbounded or limited to existential quantifiers. This result underscores the inherent computational challenges posed by HFL. Conversely, we also introduce a straightforward algorithm designed to tackle HFL satisfiability by focusing on the computation of least solutions for specific systems of integer quadratic equations. While the runtime of this algorithm is exponentially related to the maximum degree of the quadratic equations involved, it remains independent of the number of fixpoint operators present in the formula. This dual approach of establishing hardness results alongside providing a feasible algorithm contributes to a deeper understanding of the complexities surrounding higher-order fixpoint logic and its applications in model checking.",
        "ori-fast-z-score": -1.4269353798659745,
        "water-fast-z-score": 1.9639610121239315,
        "rewrite-fast-z-score": 0.47891314261057566
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Photon wave mechanics and position eigenvectors .\nAbstract:\nThe present work is devoted to the study of photon wave mechanics in terms of position eigenvectors, which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy spectrum. The concept of position eigenvector allows one to describe the state of a single photon by its position probability density distribution function (PDF). It also enables us to introduce the notion of quantum trajectory describing the evolution of this PDF over time. In particular, we show that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations. We demonstrate how these results may be used to analyze various phenomena related to the propagation of light through dispersive media. Finally, we discuss possible applications of our approach to the description of nonclassical effects associated with the emission of entangled pairs of photons. DOI: 10.1088/1742-6596/aa5e20\nI. INTRODUCTORY REMARkS\n\nIn recent years there has been considerable interest in developing new approaches to studying the properties of light fields based on the concepts of quantum optics  1–3  . One of such approaches involves introducing the so-called position eigenvectors  4  , which play an important role in the description of the state of a single-photon field  5–7  .\nIt should be noted that the use of position eigenvectors makes it possible not only to obtain information about the spatial structure of the electromagnetic field but also to investigate the temporal dynamics of the system under consideration  8, 9  . This fact opens up wide possibilities for applying the proposed method to analyzing various physical processes occurring during the propagation of light waves through dispersive media  10, 11  . \n \n In addition, the introduction of position eigenvectors into the theory of light fields leads to the possibility of using them to describe certain nonclassical effects associated",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Photon wave theory and position eigenvectors . Abstract : The present work is devoted to the study of photon wave theory in terms of position eigenvectors , which are introduced as solutions of the Schrödinger equation for photons with an arbitrary energy wavelength .The concept of position eigenvector allows one to define the state of a single photon by its position probability density distribution function ( PDF ) . It additionally permits us to introduce the notion of quantum path describing the evolution of this PDF over time .In particular , we prove that the quantum trajectories corresponding to different initial states can be obtained from each other by means of unitary transformations . We showed how these results may be used to analyze numerous phenomena related to the propagation of light through dispersive media .Finally , we explain potential uses of our approach to the description of nonclassical effects correlated with the emission of entangled pairs of photons . DOI : 10 . 1088 / 1742 - 6596 / aa5e20 I .INTRODUCTORY REMARkS In recent years there has been substantial interest in pursuing new approaches to investigating the properties of light fields relying on the concepts of quantum optics 1 – 3 . One of such approaches involves introducing the so - called position eigenvectors 4 , which take an important role in the description of the state of a single - photon field 5 – 7 .It should be mentioned that the using of position eigenvectors makes it necessary not only to obtain knowledge about the spatial shape of the electromagnetic field but also to examine the temporal composition of the system under consideration 8 , 9 . This fact offers up broad opportunities for applying the suggested method to investigating different mechanical phenomena occurring during the propagation of light beams through dispersive media 10 , 11 .In addition , the introduction of position eigenvectors into the physics of light fields leads to the prospect of using them to explain certain nonclassical effects associated",
        "rewrite_text": "**Title: Photon Wave Theory and Position Eigenvectors**\n\n**Abstract:** This study explores the photon wave theory through the lens of position eigenvectors, which are defined as solutions to the Schrödinger equation for photons across a range of energy wavelengths. By employing position eigenvectors, we can characterize the state of an individual photon via its position probability density function (PDF). This framework also facilitates the introduction of quantum paths, which describe the temporal evolution of the PDF. Our findings demonstrate that quantum trajectories corresponding to distinct initial states can be interrelated through unitary transformations. This insight allows for a deeper analysis of various phenomena associated with light propagation in dispersive media. Furthermore, we discuss the implications of our approach for understanding nonclassical effects linked to the emission of entangled photon pairs. The introduction of position eigenvectors not only enhances our comprehension of the spatial configuration of electromagnetic fields but also necessitates an investigation into the temporal dynamics of the system. This dual focus opens new avenues for examining mechanical phenomena that arise during the transmission of light through dispersive materials. Additionally, the application of position eigenvectors in the context of light fields presents promising opportunities for elucidating certain nonclassical effects, thereby enriching the field of quantum optics. Our work contributes to the ongoing discourse on innovative methodologies for probing the intricate properties of light, paving the way for future research in this domain. \n\n**DOI:** 10.1088/1742-6596/aa5e20",
        "ori-fast-z-score": 2.301585822275002,
        "water-fast-z-score": 8.818163074019441,
        "rewrite-fast-z-score": 2.85745490667645
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Possibility of large lifetime differences in neutral B meson systems .\nAbstract:\nWe study the possibility that there are two different lifetimes for neutral B mesons, one corresponding to the standard model and another to new physics beyond it.  We find that if the decay widths into final states with charm quarks differ by more than about 10% between these two types of B mesons then this can be observed at future experiments such as LHCb or Belle II. If we assume that the ratio of branching fractions is equal to 1 (as predicted within the Standard Model) but allow the total decay widths to vary independently, then we show how the experimental data on the time dependent CP asymmetry parameters SCP and ACP can be used to determine whether the difference in decay widths is due to new physics effects or not. Finally, we discuss possible extensions of our analysis which could lead to further constraints on the allowed parameter space. The results presented here will also have implications for other measurements performed at hadron colliders involving heavy flavour particles.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Possibility of large lifetime variations in neutral B meson systems . Abstract : We research the prospect that there are two different lifetimes for neutral B mesons , one corresponding to the standard description and another to new science beyond it .We see that if the decay widths into last states with charm quarks vary by more than about 10 % between these two kind of B mesons then this can be observed at future research such as LHCb or Belle II . If we suppose that the proportion of branching fractions is equal to 1 ( as predicted within the Standard Model ) but allow the total degradation widths to vary independently , then we tell how the empirical data on the period dependent CP asymmetry characteristics SCP and ACP can be used to predict whether the difference in decay widths is due to novel physics factors or not .Finally , we explain possible extensions of our analysis which potentially contribute to further limitation on the allowed parameter area . The results presented here will also have consequences for other tests accomplished at hadron colliders regarding heavy flavour particles .",
        "rewrite_text": "In this study, we investigate the potential existence of two distinct lifetimes for neutral B mesons, one aligned with the conventional understanding and the other suggesting new physics beyond the current framework. Our analysis indicates that if the decay widths into final states containing charm quarks differ by more than approximately 10% between these two types of B mesons, such variations could be detected in upcoming experiments at facilities like LHCb or Belle II. We explore a scenario where the ratio of branching fractions is maintained at 1, as predicted by the Standard Model, while allowing the total decay widths to vary independently. By leveraging empirical data on time-dependent CP asymmetries, denoted as SCP and ACP, we propose a method to discern whether observed differences in decay widths stem from novel physics or are consistent with existing theoretical predictions. Furthermore, we discuss potential extensions of our analysis that could refine the constraints on the allowed parameter space, enhancing our understanding of these phenomena. The implications of our findings extend to other experimental tests conducted at hadron colliders, particularly those focused on heavy flavor particles, thereby contributing to a broader comprehension of particle behavior and interactions in the context of both established and emerging theories in particle physics.",
        "ori-fast-z-score": -2.457864091118742,
        "water-fast-z-score": 5.196152422706631,
        "rewrite-fast-z-score": -0.5184758473652127
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Solar Neighborhood. XIX. Discovery and Characterization of 33 New Nearby White Dwarf Systems .\nAbstract:\nWe report the discovery and characterization of 33 new nearby white dwarf systems, including eight with trigonometric parallaxes measured by Gaia Data Release 2 (DR2). The sample includes six previously known binaries that were not included in DR2 because they are too faint for Gaia to resolve their components. We also present an analysis of the mass distribution of these newly discovered white dwarfs based on their photometric distances. This is the first time such a study has been performed using Gaia data alone. Our results show good agreement between our observed mass function and theoretical predictions. These findings demonstrate how Gaia can be used as a powerful tool to explore the local stellar population. Keywords: White dwarf - Galaxy - Parallax - Mass function - Gaia - Photometry - Binaries - Trigonometry - Distance scale - Astrometry - Stellar evolution - Galactic structure - Nearby stars",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  The Solar Neighborhood.XIX.Discovery and Characterization of 33 New Nearby White Dwarf Systems . Abstract : We report the discovery and identification of 33 new nearby white dwarf systems , including eight with trigonometric parallaxes measured by Gaia Data Release 2 ( DR2 ) .The sample comprises six formerly identified binaries that were not added in DR2 because they are too faint for Gaia to resolve their components . We additionally offer an assessment of the mass distribution of these newly discovered white dwarfs based on their photometric distances .This is the first time such a experiment has been performed using Gaia data alone . Our results show good agreement between our measured mass value and theoretical estimates .These studies demonstrate how Gaia can be used as a powerful tool to examine the local stellar community . Keywords : White dwarf - Galaxy - Parallax - Mass function - Gaia - Photometry - Binaries - Trigonometry - Distance scale - Astrometry - Stellar evolution - Galactic structure - Nearby stars",
        "rewrite_text": "In this study, we present the discovery and characterization of 33 new nearby white dwarf systems, significantly enhancing our understanding of the local stellar population. Among these, eight systems have trigonometric parallaxes determined through the second data release of the Gaia mission (DR2). Our sample includes six previously identified binary systems that were not incorporated into DR2 due to their faintness, which prevented Gaia from resolving their individual components. We also provide an analysis of the mass distribution of these newly identified white dwarfs, utilizing their photometric distances for the first time exclusively with Gaia data. Our findings reveal a strong correlation between the measured mass values of these white dwarfs and theoretical predictions, underscoring the reliability of our methods. This research highlights the capabilities of Gaia as a robust tool for investigating the local stellar community, offering insights into stellar evolution and the structure of the Galaxy. The implications of our work extend to various fields, including astrometry, distance scaling, and the study of binary systems. Overall, our results contribute to a deeper understanding of nearby stars and their characteristics, paving the way for future studies in stellar astrophysics. \n\nKeywords: White dwarf, Galaxy, Parallax, Mass function, Gaia, Photometry, Binaries, Trigonometry, Distance scale, Astrometry, Stellar evolution, Galactic structure, Nearby stars.",
        "ori-fast-z-score": 1.3438638879193574,
        "water-fast-z-score": 5.335783750799325,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spectroscopy and multiband photometry of the afterglow of intermediate duration gamma-ray burst 040924 and its host galaxy .\nAbstract:\nWe report on optical spectroscopy and multicolor photometry of GRB 040924, an intermediate-duration (T90 = 5 s) event detected by Swift/BAT at 07:55 UT on 24 September 2004. The prompt emission was followed by a bright X-ray flare peaking about 1 hour later than the main pulse. We find that the spectrum is well fitted with a power law plus blackbody model in the range 3000-9000 Å . The best-fit parameters are  _  = -1.1 ± 0.2 , TBB = 6200 +1800 -900 K, and EBB = 2.5 +1.0 -0.7 keV for the power-law index,  temperature, and normalization of the blackbody component respectively.  These values are consistent with those observed in other short-hard GRBs. In addition to this thermal component, we detect strong Fe II absorption lines blueshifted by ~10,000 km/s relative to their rest wavelengths. This suggests that the progenitor system may be similar to that inferred for short-hard GRBs such as GRB 050509b.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spectroscopy and multiband photometry of the afterglow of intermediate duration gamma - ray burst 040924 and its host galaxy . Abstract : We report on optical spectroscopy and multicolor photometry of GRB 040924 , an intermediate - duration ( T90 = 5 s ) event detected by Swift / BAT at 07 : 55 UT on 24 September 2004 .The prompt emission was followed by a bright X - ray flare peaking about 1 hour later than the main pulse . We see that the spectrum is well fitted with a power law plus blackbody model in the range 3000 - 9000 Å .The best - fitting factors are _ = - 1 . 1 ± 0 . 2 , TBB = 6200 + 1800 - 900 K , and EBB = 2 . 5 + 1 . 0 - 0 . 7 keV for the power - law index , temperature , and normalization of the blackbody element respectively . These values are compatible with those observed in other short - hard GRBs .In addition to this heat element , we perceive strong Fe II spectral lines blueshifted by ~ 10 , 000 km / s relative to their rest wavelengths . This implies that the progenitor system might be parallel to that inferred for short - hard GRBs such as GRB 050509b .",
        "rewrite_text": "We present a comprehensive analysis of the optical spectroscopy and multicolor photometry of the afterglow associated with the intermediate-duration gamma-ray burst (GRB) 040924, which was detected by the Swift/BAT at 07:55 UT on September 24, 2004. This event, characterized by a T90 duration of approximately 5 seconds, exhibited a notable prompt emission followed by a significant X-ray flare that peaked roughly one hour after the initial burst. Our spectral analysis reveals that the afterglow can be accurately modeled using a combination of a power law and a blackbody component within the wavelength range of 3000 to 9000 Å. The optimal fitting parameters obtained from our analysis include a power-law index of α = -1.1 ± 0.2, a blackbody temperature of TBB = 6200 +1800 -900 K, and a normalization factor for the blackbody component of EBB = 2.5 +1.0 -0.7 keV. These parameters align closely with those observed in other short-hard gamma-ray bursts, suggesting a potential commonality in their physical mechanisms. Furthermore, our observations indicate the presence of strong Fe II spectral lines that are blueshifted by approximately 10,000 km/s from their rest wavelengths. This significant blueshift suggests that the progenitor system of GRB 040924 may share similarities with those inferred for other short-hard GRBs, such as GRB 050509b. Our findings contribute to the growing body of evidence regarding the nature of intermediate-duration gamma-ray bursts and their host environments, highlighting the importance of detailed spectroscopic and photometric studies in understanding these enigmatic cosmic events.",
        "ori-fast-z-score": 1.3242443839434612,
        "water-fast-z-score": 5.259005881071332,
        "rewrite-fast-z-score": 0.8867963503478639
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Coronal ion-cyclotron beam instabilities within the multi-fluid description .\nAbstract:\nWe study the linear stability properties of coronal beams in the presence of background plasma and magnetic field fluctuations, using a multi-fluid model for ions and electrons. We find that the growth rates are strongly dependent on the angle between the wavevector k and the mean magnetic field B 0 . In particular, we show that there is an instability at oblique angles with respect to B 0 , which has been previously overlooked by previous studies based on single-fluid models. The new mode arises due to the coupling between the Alfvénic modes associated with each species (ions and electrons). This mode can be excited even when the electron temperature anisotropy T e? /T ez < 1, where ? denotes directions perpendicular to B 0 .\nThe results presented here may have important implications for understanding the origin of solar radio bursts observed during solar flares. Introduction: Coronal mass ejections (CMEs) are large-scale expulsions of magnetized plasma from the Sun s corona into interplanetary space. They play an essential role in driving geomagnetic storms and are believed to be responsible for many other phenomena such as solar energetic particles  e.g., Reames et al. (1998) , Kahler & Ragot (2007)  , solar radio bursts  e.g., Aschwanden (2004)  , and white-light flares  e.g., Benz (2008)  . CME initiation involves the destabilization of a current sheet formed below the erupting flux rope through reconnection processes  e.g., Forbes & Priest (1995) ; Lin & Forbes (2000); Aulanier et al. (2010)  . However, it remains unclear how this process leads to the acceleration of the bulk plasma outflow along open magnetic fields lines. Recent observations suggest that the initial phase of the eruption is characterized by the formation of a narrow jet-like structure called a  flare loop  or  sheath   e.g., Liu et al. (2009a Liu et al. ( , 2009b ; Cheng et al. (2011); Jiang et al. (2012",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Coronal electron - cyclotron beam instabilities within the multi - fluid model . Abstract : We research the linear stability properties of coronal beams in the presence of background plasma and magnetic field fluctuations , using a multi - fluid model for ions and electrons .We see that the development rates are strongly dependent on the angle between the wavevector k and the mean magnetic force B 0 . In particular , we prove that there is an instability at oblique angles with regard to B 0 , which has been previously overlooked by earlier methods using on single - fluid models .The new mode occurs due to the interaction between the Alfvénic mechanisms associated with each species ( atoms and electrons ) . This mode can be excited even when the electron thermal anisotropy T e ?/T ez < 1, where ?denotes directions perpendicular to B 0 .The results presented here possibly have important implications for studying the origin of solar radio pulses seen during thermal flares . Introduction : Coronal mass ejections ( CMEs ) are big - scale expulsions of magnetized liquid from the Sun s corona into interplanetary space .They play an essential part in causing geomagnetic winds and are considered to be responsible for numerous other effects such as solar energetic particles e . g . , Reames et al . ( 1998 ) , Kahler & Ragot ( 2007 ) , solar radio flashes e . g . , Aschwanden ( 2004 ) , and green - light flares e . g . , Benz ( 2008 ) .CME initiation consists the destabilization of a current sheet formed below the erupting flux rope through reconnection pathways g . g . , Forbes & Priest ( 1995 ) ; Lin & Forbes ( 2000 ) ; Aulanier et al . ( 2010 ) .However , it remains unsure how this process results to the acceleration of the bulk plasma outflow along open magnetic fields lines . Recent measurements suggest that the early stage of the volcano is characterized by the formation of a thin plane - like structure named a flare loop or pouch e . g . , Liu et al .( 2009a Liu et al . ( , 2009b ; Cheng et al .( 2011 ) ; Jiang et al . ( 2012",
        "rewrite_text": "**Title:** Coronal Electron-Cyclotron Beam Instabilities within the Multi-Fluid Model\n\n**Abstract:** This study investigates the linear stability characteristics of coronal beams in the context of background plasma and magnetic field fluctuations, employing a multi-fluid model that accounts for both ions and electrons. Our findings reveal that the growth rates of these instabilities are significantly influenced by the angle between the wavevector \\( \\mathbf{k} \\) and the mean magnetic field \\( \\mathbf{B}_0 \\). Notably, we demonstrate the existence of an instability at oblique angles relative to \\( \\mathbf{B}_0 \\), a phenomenon that has been largely overlooked in previous analyses that utilized single-fluid models. This newly identified mode arises from the interaction of Alfvénic mechanisms associated with different species, specifically atoms and electrons. Importantly, this mode can be excited even when the electron thermal anisotropy \\( T_e^\\perp / T_e^z < 1 \\), where \\( \\perp \\) indicates directions perpendicular to \\( \\mathbf{B}_0 \\). The implications of our results are significant, particularly in relation to understanding the origins of solar radio pulses observed during thermal flares.\n\n**Introduction:** Coronal mass ejections (CMEs) represent large-scale expulsions of magnetized plasma from the Sun's corona into interplanetary space. They play a crucial role in generating geomagnetic winds and are linked to various phenomena, including solar energetic particles (Reames et al., 1998; Kahler & Ragot, 2007), solar radio bursts (Aschwanden, 2004), and green-light flares (Benz, 2008). The initiation of CMEs involves the destabilization of a current sheet formed beneath the erupting flux rope, facilitated by reconnection processes (Forbes & Priest, 1995; Lin & Forbes, 2000; Aulanier et al., 2010). However, the mechanisms by which this process leads to the acceleration of bulk plasma outflow along open magnetic field lines remain poorly understood. Recent observations indicate that the initial phase of the eruption is characterized by the formation of a thin, planar structure known as a flare loop or pouch (Liu et al., 2009a; Liu et al., 2009b; Cheng et al., 2011; Jiang et al., 2012).",
        "ori-fast-z-score": -1.281025230440697,
        "water-fast-z-score": 6.164414002968977,
        "rewrite-fast-z-score": 1.4117731575135795
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Heterogeneity and Increasing Returns May Drive Socio-Economic Transitions .\nAbstract:\nWe develop an agent-based model to study the evolution of social complexity in human societies, focusing on how heterogeneity among agents can lead to increasing returns that drive economic growth and technological innovation. We find that heterogeneous populations are more likely than homogeneous ones to evolve complex economies with specialized production units, markets for goods and services, and division of labor between producers. The presence of these features leads to higher levels of productivity and population density, which further increase the benefits associated with specialization and trade. Our results suggest that the emergence of such socioeconomic structures may have been one important factor driving the evolution of human society over the past few million years. In this work we present a computational model aimed at studying the evolutionary dynamics underlying the development of socio-economic systems. More specifically, our goal is to understand what factors might be responsible for the appearance of increasingly complex forms of organization observed across many different cultures throughout history. To address this question, we focus on the role played by two key ingredients commonly found in real-world systems: (i) diversity within the population; and (ii) positive feedbacks leading to increasing returns.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Heterogeneity and Increasing Returns May Drive Socio - Economic Transitions . Abstract : We develop an agent - based model to study the evolution of social complexity in human organizations , concentrating on how heterogeneity among agents can lead to increasing returns that drive economic change and technological innovation .We see that heterogeneous populations are more likely than homogeneous ones to evolve complex economies with specialized production divisions , prices for goods and services , and divided of labor between producers . The presence of these characteristics leads to higher levels of efficiency and population density , which further raise the advantages associated with specialization and commerce .Our results show that the emergence of such socioeconomic structures could have been one key force driving the evolution of human civilization over the previous few million years . In this research we present a computational model aiming at studying the evolutionary processes governing the development of socio - economic systems .More specifically , our goal is to consider what factors might be responsible for the appearance of increasingly sophisticated types of organization observed across many various societies throughout history . To address this question , we focus on the part played by two principal ingredients commonly found in real - global networks : ( i ) integration within the population ; and ( ii ) positive feedbacks resulting to increasing returns .",
        "rewrite_text": "In this article, we introduce an agent-based model designed to explore the evolution of social complexity within human organizations, with a particular focus on how agent heterogeneity can foster increasing returns that propel economic transformation and technological advancement. Our findings indicate that populations characterized by diversity are significantly more likely to develop intricate economic systems featuring specialized production divisions, established pricing mechanisms for goods and services, and a clear division of labor among producers. These elements contribute to enhanced efficiency and greater population density, which in turn amplify the benefits associated with specialization and trade. \n\nWe argue that the emergence of such socio-economic frameworks may have been a pivotal factor in the progression of human civilization over the past several million years. This research aims to provide a computational model that elucidates the evolutionary dynamics underpinning the formation of socio-economic systems. Specifically, we investigate the factors that may have led to the development of increasingly sophisticated organizational structures observed across various societies throughout history. To tackle this inquiry, we emphasize the significance of two key components typically present in real-world global networks: (i) the degree of integration within the population and (ii) the positive feedback mechanisms that result in increasing returns. Through this analysis, we seek to deepen our understanding of the complex interplay between heterogeneity, economic evolution, and technological innovation, ultimately shedding light on the fundamental processes that have shaped human social and economic development.",
        "ori-fast-z-score": 1.756550621379892,
        "water-fast-z-score": 7.975276924145438,
        "rewrite-fast-z-score": 0.9538209664765319
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Atomic force microscopy (AFM) study of thick lamellar stacks of phospholipid bilayers .\nAbstract:\nThe structure and dynamics of lipid membranes are important for many biological processes, such as cell division or protein transport across the membrane. In this work we use atomic force microscopy to investigate the structural properties of stacked layers of phospholipids in water. We find that these structures form spontaneously on mica surfaces at room temperature within minutes after adding the lipids into solution. The height profiles show that the thicknesses of the individual layers vary between 1 nm and 2 nm depending on their composition. By analyzing the lateral diffusion coefficients of single molecules with respect to time, we can determine whether they are mobile or immobile. Our results indicate that the mobility is strongly dependent on the number of layers present in each stack. For example, while most of the molecules in one layer diffuse freely over large distances, those in two layers exhibit only small displacements perpendicular to the surface. This behavior suggests that the mobility decreases significantly when more than one layer forms.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Atomic pressure microscopy ( AFM ) study of dense lamellar stacks of phospholipid bilayers . Abstract : The structure and dynamics of lipid membranes are important for numerous physical processes , such as cell division or protein transport across the membrane .In this study we utilize atomic force microscopy to examine the structural structure of piled sheets of phospholipids in water . We see that these structures form spontaneously on mica surfaces at room temperature within moments after addition the lipids into solution .The height profiles indicate that the thicknesses of the different particles varies between 1 nm and 2 nm depending on their composition . By analyzing the longitudinal diffusion coefficients of single particles with regard to time , we can determine whether they are mobile or immobile .Our results show that the mobility is strongly dependent on the quantity of molecules present in each stack . For instance , while most of the molecules in one layer diffuse widely over large distances , those in two sheets experience only tiny displacements parallel to the surface .This behavior suggests that the mobility decreases dramatically when more than one layer occurs .",
        "rewrite_text": "**Title:** Atomic Pressure Microscopy (AFM) Investigation of Dense Lamellar Phospholipid Bilayer Stacks\n\n**Abstract:** The structural and dynamic properties of lipid membranes play a crucial role in various biological processes, including cell division and the transport of proteins across membranes. This study employs atomic force microscopy (AFM) to investigate the architecture of densely stacked phospholipid bilayers in an aqueous environment. Our observations reveal that these bilayer structures spontaneously assemble on mica substrates at room temperature shortly after the introduction of lipids into the solution. The height profile measurements indicate that the thickness of the bilayers varies between 1 nm and 2 nm, contingent upon the specific lipid composition. By examining the longitudinal diffusion coefficients of individual lipid particles over time, we can assess their mobility, distinguishing between mobile and immobile states. The findings demonstrate a significant correlation between the number of lipid layers and their mobility; specifically, while the majority of lipids within a single layer exhibit extensive diffusion across considerable distances, those within double-layered stacks show minimal movement, primarily restricted to small displacements parallel to the substrate. This observation suggests a pronounced decrease in mobility as the number of layers increases, highlighting the impact of molecular density on the dynamics of lipid bilayers. Overall, our results provide valuable insights into the behavior of phospholipid membranes, contributing to a deeper understanding of their physical properties and the implications for cellular functions.",
        "ori-fast-z-score": -1.0660035817780522,
        "water-fast-z-score": 5.4812812776251905,
        "rewrite-fast-z-score": 0.38138503569823695
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stability of spinor Fermi gases in tight waveguides .\nAbstract:\nWe study the stability of spin-1/2 fermions confined to one dimension by an external potential and interacting via contact interactions, using the Bethe ansatz solution for the Lieb-Liniger model. We find that there is no instability at zero temperature when the chemical potential lies between two consecutive energy levels of the system. This result holds true even if we consider finite temperatures as well. In particular, this implies that the ground state remains stable against collapse into a single particle state (fermionization) or formation of bound states with more than 2 particles (bosonization). The results are also valid for higher spins. Our analysis can be extended to other models such as those describing cold atoms trapped inside optical lattices. Introduction:-In recent years, ultracold atomic systems have been used extensively to simulate various physical phenomena  1  . One-dimensional quantum gases provide particularly interesting examples because they allow us to explore many-body physics in regimes where analytical solutions cannot be obtained  2  .\nThe most common experimental setup consists of confining bosonic or fermionic atoms along one spatial direction within a harmonic trap  3  , which leads to the emergence of quasi-one dimensional behavior  4  . However, it has recently become possible to confine these atoms tightly enough so that their motion becomes truly onedimensional  5  . For example, experiments performed with Bose-Einstein condensates  6  and degenerate Fermi gases  7, 8  show that confinement in a narrow channel gives rise to new phases of matter  9  . These include superfluidity  10  , supersolids  11  , Luttinger liquids  12  , Tonks-Girardeau gas  13  , and Mott insulators  14  . It would therefore be very useful to develop theoretical tools capable of predicting the properties of these novel phases  15  .\nOne of the main challenges associated with studying strongly correlated quantum systems is determining whether certain configurations are energetically favorable  16  . If the answer turns out to be yes, then we say that the configuration is metastable  17  . On the other hand, if the answer is no, then the configuration is unstable  18  . Instabilities may occur due to spontaneous symmetry",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stability of spinor Fermi materials in dense waveguides . Abstract : We research the stability of spin - 1 / 2 fermions localized to one dimension by an external potential and communicating via contact interactions , using the Bethe ansatz solution for the Lieb - Liniger model .We see that there is no instability at zero temperature when the chemical potential sits between two consecutive power concentrations of the system . This result holds true even if we choose finite temperatures as well .In particular , this implies that the ground state remains stable against failure into a single particle state ( fermionization ) or formation of bound states with more than 2 particles ( bosonization ) . The results are also valid for larger spins .Our study can be applied to other models such as those describing cold molecules trapped inside optical lattices . Introduction : - In recent years , ultracold nuclear systems have been used heavily to simulate numerous physical phenomena 1 .One - dimensional quantum compounds provide particularly exciting examples because they allow us to examine multiple - bodies physics in regimes where theoretical solutions cannot be obtained 2 . The most common theoretical setup consists of confining bosonic or fermionic atoms along one spatial path within a harmonic cage 3 , which results to the emergence of quasi - one dimensional dynamics 4 .However , it has recently become able to confine these ions tightly sufficiently so that their motion makes truly onedimensional 5 . For instance , trials performed with Bose - Einstein condensates 6 and degenerate Fermi atoms 7 , 8 show that confinement in a thin channel gives rise to fresh stages of matter 9 .These include superfluidity 10 , supersolids 11 , Luttinger liquids 12 , Tonks - Girardeau liquid 13 , and Mott insulators 14 . It would therefore be very useful to develop conceptual tools capable of predicting the properties of these novel phases 15 .One of the main problems involved with studying strongly interacting quantum systems is assessing whether particular configurations are energetically favorable 16 . If the question turns out to be yes , then we guess that the configuration is metastable 17 .On the other hand , if the answer is no , then the configuration is unstable 18 . Instabilities could occur due to spontaneous symmetry",
        "rewrite_text": "**Title:** Stability of Spinor Fermi Materials in Dense Waveguides\n\n**Abstract:** This study investigates the stability of spin-1/2 fermions confined to one dimension by an external potential and interacting through contact interactions, utilizing the Bethe ansatz solution for the Lieb-Liniger model. Our findings indicate that at zero temperature, the system exhibits stability when the chemical potential is situated between two consecutive power concentrations. This stability persists even at finite temperatures, suggesting that the ground state is resilient against transitions to a single particle state (fermionization) or the formation of bound states involving more than two particles (bosonization). Notably, these results extend to systems with larger spin values. The implications of our research are significant, as they can be applied to various models, including those that describe cold molecules trapped in optical lattices.\n\nIn recent years, ultracold nuclear systems have emerged as powerful tools for simulating a wide array of physical phenomena. One-dimensional quantum systems, in particular, offer exciting opportunities to explore many-body physics in regimes where traditional theoretical approaches may fall short. The typical experimental setup involves confining bosonic or fermionic atoms along a single spatial dimension within a harmonic trap, leading to the emergence of quasi-one-dimensional dynamics. Recent advancements have enabled the confinement of ions to such an extent that their motion becomes genuinely one-dimensional. Experiments with Bose-Einstein condensates and degenerate Fermi gases have demonstrated that confinement in narrow channels can give rise to novel phases of matter, including superfluidity, supersolids, Luttinger liquids, Tonks-Girardeau liquids, and Mott insulators. Consequently, developing conceptual frameworks to predict the properties of these new phases is of paramount importance. A critical challenge in studying strongly interacting quantum systems is determining the energetic favorability of specific configurations. If a configuration is energetically favorable, it is considered metastable; conversely, if it is not, the configuration is deemed unstable. Such instabilities may arise from spontaneous symmetry breaking, highlighting the intricate dynamics at play in these systems.",
        "ori-fast-z-score": -1.1607348488012053,
        "water-fast-z-score": 6.943650748294136,
        "rewrite-fast-z-score": 0.5586608191273356
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gemini Spectroscopic Survey of Young Star Clusters in Merging/Interacting Galaxies. II. NGC 3256 Clusters .\nAbstract:\nWe present Gemini GMOS-S spectroscopy for two young star clusters (ages ~10 Myr) in the interacting galaxy pair NGC 3256, which are located at projected distances of 1 kpc and 2 kpc from their respective nuclei. The spectra reveal that both clusters have similar ages but different metallicities; one is metal-rich with  Fe/H  = +0.2 dex while the other has solar metallicity. We find no evidence for multiple populations within either cluster. Using these data we derive masses of 5 x 10^4 M_sol and 7 x 10^3 M_sol respectively for each cluster. These values agree well with those derived using HST photometry. Both clusters show signs of youthful star-formation activity including blue supergiants and Wolf-Rayet stars. In addition to this ongoing star-formation activity, there appears to be an older population of red giant branch stars in the more massive cluster.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Gemini Spectroscopic Survey of Young Star Clusters in Merging/Interacting Galaxies.II.NGC 3256 Clusters . Abstract : We report Gemini GMOS - S spectroscopy for two young galaxy clusters ( ages ~ 10 Myr ) in the interacting galaxy pair NGC 3256 , which are situated at projected speeds of 1 kpc and 2 kpc from their respective nuclei .The spectra indicate that both clusters have related ages but different metallicities ; one is metal - rich with Fe / H = + 0 . 2 dex while the other has solar metallicity . We see no evidence for multiple groups within either cluster .Using these measurements we derive masses of 5 x 10 ^ 4 M _ sol and 7 x 10 ^ 3 M _ sol respectively for each cluster . These values comply good with those generated utilizing HST photometry .Both clusters show signs of young star - formation activity including blue supergiants and Wolf - Rayet stars . In addition to this continuing star - formation activity , there seems to be an older population of red giant branch stars in the more massive cluster .",
        "rewrite_text": "In this study, we present the results of Gemini GMOS-S spectroscopy conducted on two young star clusters, each approximately 10 million years old, located within the interacting galaxy pair NGC 3256. These clusters are positioned at projected distances of 1 kpc and 2 kpc from their respective galactic nuclei. Our spectral analysis reveals that while both clusters share similar ages, they exhibit distinct metallicity levels; one cluster is classified as metal-rich with an iron-to-hydrogen ratio of +0.2 dex, whereas the other cluster displays solar metallicity. Notably, we found no indications of multiple stellar groups within either of the clusters. \n\nFrom our spectral measurements, we calculated the masses of the two clusters to be approximately 5 x 10^4 solar masses and 7 x 10^3 solar masses, respectively. These mass estimates align well with those derived from Hubble Space Telescope (HST) photometry, reinforcing the reliability of our findings. Furthermore, both clusters exhibit evidence of active star formation, characterized by the presence of blue supergiants and Wolf-Rayet stars. Interestingly, in the more massive cluster, we also identified an older population of red giant branch stars, suggesting a complex star formation history. This study contributes to our understanding of the dynamics and evolutionary processes occurring in young star clusters within merging and interacting galaxies, highlighting the interplay between different stellar populations and the ongoing star formation activities in such environments.",
        "ori-fast-z-score": -0.3611575592573076,
        "water-fast-z-score": 3.204310477123404,
        "rewrite-fast-z-score": 0.0949157995752499
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Use of Triangular Elements for Nearly Exact BEM Solutions .\nAbstract:\nThe use of triangular elements in the boundary element method (BEM) is discussed and compared with other methods, such as quadrilateral elements or mixed elements. The advantages are that they can be used to solve problems involving curved boundaries more accurately than quadrilateral elements while still being able to take advantage of fast matrix-vector multiplication techniques developed for rectangular matrices.  In addition, it has been shown how these elements may be combined with an iterative solution technique known as GMRES(m). This combination allows solutions which are nearly exact to be obtained without any loss of efficiency over conventional BEM approaches using quadrilateral elements. Finally, some numerical results are presented showing the accuracy of this approach on several test cases. Keywords: Boundary Element Method, Quadrilateral Elements, Mixed Elements, Iterative Solution Technique, GMRES(m), Triangular Elements. 1 Introduction The boundary element method (BEm)  1  , also called the integral equation method  2  , is one of the most powerful tools available today for solving partial differential equations numerically  3  . It involves discretizing the domain into small regions called elements where the unknown function is approximated by simple functions like polynomials  4  .\nIn recent years there have been many advances made in the development of efficient algorithms for applying the BE m to practical engineering problems  5  -  8  . However, despite all these developments, the application of the BE m to problems with complex geometries remains difficult because of difficulties associated with representing complicated shapes exactly  9  . For example, if we consider the problem of finding the potential distribution around a conducting body immersed in a uniform magnetic field then the surface of the conductor must be represented by a set of flat triangles whose vertices lie at points on its actual curved surface  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Use of Triangular Elements for Nearly Exact BEM Solutions . Abstract : The using of triangular forms in the boundary element method ( BEM ) is mentioned and compared with other methods , such as quadrilateral modules or mixed elements .The advantages are that they can be used to solve difficulties involving curved boundaries more accurately than quadrilateral components while still being able to take advantage of quick vector - vector multiplication techniques established for rectangular matrices . In addition , it has been shown how these elements may be merged with an iterative solution technique called as GMRES ( m ) .This combination allows solutions which are nearly exact to be obtained without any loss of efficiency over traditional BEM approaches employing quadrilateral components . Finally , some numerical findings are presented showing the accuracy of this methodology on numerous test situations .Keywords : Boundary Element Method , Quadrilateral Elements , Mixed Elements , Iterative Solution Technique , GMRES ( m ) , Triangular Elements . 1 Introduction The border element method ( BEm ) 1 , sometimes called the integral equation procedure 2 , is one of the most important skills available today for solving partial differential equations numerically 3 .It involves discretizing the domain into small zones called elements where the unknown function is approximated by simple functions like polynomials 4 . In recent years there have been many advances making in the development of effective methods for applying the BE m to practical technical problems 5 - 8 .However , despite all these developments , the implementation of the BE m to problems with difficult geometries remains complicated because of troubles associated with depicting complicated forms exactly 9 . For instance , if we study the issue of finding the potential distribution around a conducting body immersed in a uniform magnetic field then the surface of the conductor must be described by a setting of flat triangles whose edges lie at points on its actual curved surface 10 .",
        "rewrite_text": "**Title:** Utilization of Triangular Elements for Near-Exact Solutions in Boundary Element Method (BEM)\n\n**Abstract:** This article explores the application of triangular elements within the Boundary Element Method (BEM) and contrasts this approach with traditional methods that utilize quadrilateral elements or mixed element configurations. Triangular elements offer significant advantages, particularly in addressing challenges associated with curved boundaries, as they provide a more precise representation than their quadrilateral counterparts. Furthermore, triangular elements can leverage efficient vector-vector multiplication techniques that are typically employed with rectangular matrices, enhancing computational performance. The integration of triangular elements with an iterative solution method known as GMRES(m) is also discussed. This combination facilitates the attainment of nearly exact solutions while maintaining the efficiency characteristic of conventional BEM approaches that rely on quadrilateral elements. The article presents numerical results that demonstrate the effectiveness and accuracy of this methodology across various test scenarios, highlighting its potential for practical applications in complex geometrical contexts. \n\n**Keywords:** Boundary Element Method, Quadrilateral Elements, Mixed Elements, Iterative Solution Technique, GMRES(m), Triangular Elements.\n\n**1 Introduction:** The Boundary Element Method (BEM), often referred to as the integral equation method, is a powerful numerical technique for solving partial differential equations. This method involves discretizing the problem domain into smaller regions known as elements, where the unknown function is approximated using simple functions, such as polynomials. Recent advancements have significantly improved the effectiveness of BEM in addressing real-world engineering challenges. However, the application of BEM to problems with intricate geometries remains a complex task, primarily due to difficulties in accurately representing complex shapes. For example, when analyzing the potential distribution around a conducting body immersed in a uniform magnetic field, it is essential to represent the conductor's surface using a mesh of flat triangles that conform to its actual curved surface. This paper aims to address these challenges by demonstrating the efficacy of triangular elements in enhancing the accuracy and efficiency of BEM solutions.",
        "ori-fast-z-score": 0.16666666666666666,
        "water-fast-z-score": 7.613974175141785,
        "rewrite-fast-z-score": 0.07881104062391006
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the stratified dust distribution of the GG Tau circumbinary ring .\nAbstract:\nWe present new near-infrared (NIR) polarimetric observations of the GG Tau system, which reveal that its circumstellar disk is highly structured and contains several bright regions with different polarization properties. The most prominent feature in our data set is an arc-like structure located at about 0.5 arcsec to the south-east of the central binary star. This region shows strong polarized emission up to 10% of the total intensity and has been previously identified as a reflection nebula by Weintraub et al. (1993) . We find that this feature can be explained by scattering off optically thin dust grains close to the midplane of the disk. In addition we detect two other bright features on either side of the central binary. These are also associated with high degrees of linear polarization but show no clear evidence for scattered light. Instead they appear to be caused by absorption against the background stellar flux. Finally, we identify three additional fainter structures in the southern part of the disk. All these features have similar polarization angles indicating that their origin may be related.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the stratified dust pattern of the GG Tau circumbinary ring . Abstract : We report new near - infrared ( NIR ) polarimetric studies of the GG Tau system , which confirm that its circumstellar disk is heavily structured and hosts multiple bright regions with various polarization properties .The most notable feature in our information run is an arc - like structure located at about 0 . 5 arcsec to the south - eastward of the main binary star . This region shows intense polarized emission up to 10 % of the total intensity and has been previously described as a mirror nebula by Weintraub et al .( 1993 ) . We see that this phenomenon can be described by scattering off optically thin dust grains next to the midplane of the disk .In addition we perceive two other bright features on either front of the main binary . These are also associated with high degrees of linear polarization but display no clear proof for dispersed light .Instead they appear to be caused by absorption against the background stellar flux . Finally , we identify three extra fainter objects in the southern portion of the disk .All these characteristics have similar polarization angles indicating that their ancestry may be connected .",
        "rewrite_text": "We present new near-infrared (NIR) polarimetric observations of the GG Tau system, revealing significant structural complexity within its circumstellar disk. Our findings indicate the presence of multiple bright regions, each exhibiting distinct polarization characteristics. A particularly striking feature is an arc-like structure located approximately 0.5 arcseconds southeast of the primary binary star. This region is characterized by intense polarized emission, reaching up to 10% of the total intensity, and has previously been referred to as a mirror nebula by Weintraub et al. (1993). Our analysis suggests that this phenomenon can be attributed to scattering off optically thin dust grains situated near the midplane of the disk.\n\nIn addition to the arc-like feature, we have identified two other prominent bright regions flanking the main binary. These areas also exhibit high degrees of linear polarization; however, they lack clear evidence of dispersed light. Instead, their polarization appears to result from absorption against the background stellar light. Furthermore, we have detected three additional fainter objects in the southern region of the disk. Notably, all these features share similar polarization angles, implying a potential connection in their origins.\n\nOverall, our study enhances the understanding of the stratified dust patterns within the GG Tau circumbinary ring, highlighting the intricate interplay between dust scattering and absorption processes. These insights contribute to the broader knowledge of circumstellar disk structures and their polarization properties, paving the way for future investigations into the dynamics and evolution of such systems.",
        "ori-fast-z-score": -0.7258661863112977,
        "water-fast-z-score": 5.363390480545726,
        "rewrite-fast-z-score": 1.2888044650576527
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Zero-point radiation and the Big Bang .\nAbstract:\nThe concept of zero point energy is introduced in this article, which describes how it can be used to explain some aspects of the big bang theory. The author also discusses the possibility that dark matter may have been created by such an effect. Finally he considers whether or not there are any other physical effects associated with zero point energy. In particular, he suggests that gravitational waves could possibly be generated by such processes. This article was originally published on ArXiv.org as part of the author s PhD thesis at Imperial College London. It has since been updated for publication here. Zero point energy (ZPE) is defined as the minimum amount of energy required to create particles out of nothing. Although ZPE cannot actually exist because it violates the laws of physics, it does provide useful insight into certain phenomena observed within our universe. For example, if we consider the expansion of space-time during the early stages of the universe s existence, then it seems reasonable to assume that the volume of space increased exponentially over time due to the rapid release of ZPE. If so, then the total mass-energy density would decrease rapidly until all available ZPE had been released. At this stage, the universe would consist solely of vacuum fluctuations, i.e., virtual particles and antiparticles existing simultaneously but never interacting with each other.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Zero - point radiation and the Big Bang . Abstract : The concept of zero point energy is included in this page , which explains how it can be used to explain some elements of the big bang theory .The author also examines the suggestion that dark matter may have been created by such an effect . Finally he considers whether or not there are any other physical effects involved with zero point energy .In particular , he argues that gravity signals could possibly be induced by such processes . This section was originally published on ArXiv . org as part of the writer s PhD thesis at Imperial College London .It has since been amended for published here . Zero point energy ( ZPE ) is measured as the zero amount of energy required to create particles out of nothing .Although ZPE cannot actually appear because it violates the rules of science , it does provide useful insight into various phenomena observed within our universe . For instance , if we study the advance of space - time during the early stages of the universe s existence , then it appears justified to assume that the volume of space expanded exponentially over time due to the fast release of ZPE .If so , then the total mass - energy density would decrease rapidly until all available ZPE had been released . At this phase , the universe might consist solely of vacuum fluctuations , i . e . , virtual ions and antiparticles emerging concurrently but never interacting with each other .",
        "rewrite_text": "**Title: Zero-Point Radiation and the Big Bang**\n\n**Abstract:** This article delves into the concept of zero-point energy (ZPE) and its potential implications for the Big Bang theory. The author explores how ZPE might elucidate certain aspects of the universe's inception, particularly in relation to the formation of dark matter. The discussion includes a critical examination of whether other physical phenomena could be associated with zero-point energy, specifically the possibility that gravitational signals may be generated through these processes. Originally part of the author's PhD thesis at Imperial College London, this section has been revised for publication here.\n\nZero-point energy is defined as the minimum energy required to create particles from a vacuum state. Although the existence of ZPE is theoretically contentious, as it contradicts established scientific principles, it offers valuable insights into various cosmic phenomena. For example, an analysis of the early universe suggests that the rapid expansion of space-time could be attributed to the swift release of zero-point energy. If this hypothesis holds true, it implies that the mass-energy density of the universe would have decreased significantly as ZPE was released, leading to a state dominated by vacuum fluctuations. In this scenario, virtual particles, including ions and antiparticles, would emerge simultaneously without interacting with one another.\n\nThis exploration not only enhances our understanding of the early universe but also raises intriguing questions about the nature of dark matter and the fundamental forces at play. By investigating the interplay between zero-point energy and cosmic evolution, the author aims to contribute to the ongoing discourse surrounding the origins of our universe and the underlying principles governing its behavior.",
        "ori-fast-z-score": 0.647150228929434,
        "water-fast-z-score": 6.9937860618023535,
        "rewrite-fast-z-score": -0.25819888974716115
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Influence of experimental context on the development of anhedonia in male mice imposed to chronic social stress .\nAbstract:\nAnhedonia is an important symptom of depression and schizophrenia, but its underlying neurobiological mechanisms are still poorly understood. In this study we investigated whether exposure to chronic social defeat (CSD) can induce anhedonic-like behavior in male C57BL/6J mice. We found that CSD-exposed animals exhibited decreased preference for sucrose solution compared with control group. Moreover, CSD-exposed mice showed increased immobility time during forced swimming test as well as reduced locomotor activity in open field test. Finally, we observed significant decrease in dopamine release in nucleus accumbens shell after acute administration of amphetamine in defeated mice. These results suggest that CSD may be used as animal model of anhedonia. Anhedonia is one of the most prominent symptoms of major depressive disorder (MDD), which affects about 20% of patients worldwide 1 . It refers to loss or reduction of pleasure experienced by individuals 2 , resulting in inability to experience joyful events 3 .\nIn addition to MDD, anhedonia has been also described in other psychiatric disorders such as schizophrenia 4 , bipolar disorder 5 , obsessive-compulsive disorder 6 , eating disorders 7 , substance abuse 8 , and borderline personality disorder 9 . However, despite being considered a core feature of several mental illnesses 10 , there is no consensus regarding how it should be assessed 11 . The lack of standardized assessment methods makes it difficult to compare findings across studies 12 . Therefore, new approaches have emerged aiming at improving the diagnosis and treatment of anhedonia 13 .\nThe main challenge associated with studying anhedonia lies in the fact that it is not possible to measure directly 14 . Instead, researchers use indirect measures based on behavioral tests 15 . For example, the sucrose consumption test 16 , the forced swim test 17 , and the open field test 18 are commonly employed to assess hedonia 19 . Although these tests provide valuable information related to anhedonia 20 , they do not allow us to understand the neural circuits involved 21 . Thus, further investigations using more sophisticated techniques are needed 22 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Influence of research perspective on the development of anhedonia in men mice imposed to chronic social tension . Abstract : Anhedonia is an important symptom of depression and schizophrenia , but its underlying neurobiological processes are still weakly understood .In this study we investigated whether exposure to chronic social loss ( CSD ) can induce anhedonic - like behavior in men C57BL / 6J mouse . We showed that CSD - infected animals exhibited reduced choice for sucrose solution compared with control group .Moreover , CSD - infected mouse observed increased immobility time during forced swimming experiment as also as reduced locomotor activity in open ground examination . Finally , we demonstrated substantial decrease in dopamine release in nucleus accumbens shell after acute administration of amphetamine in defeated mice .These data suggest that CSD may be used as animal model of anhedonia . Anhedonia is one of the most notable symptoms of large depressive illness ( MDD ) , which occurs about 20 % of people worldwide 1 .It refers to loss or decrease of pleasure received by individuals 2 , resulting in inability to experience joyful events 3 . In addition to MDD , anhedonia has been also identified in other psychiatric conditions such as schizophrenia 4 , bipolar disorder 5 , obsessive - compulsive disease 6 , eating disorders 7 , alcohol addiction 8 , and borderline personality disorder 9 .However , despite being considered a core feature of several mental illnesses 10 , there is no agreed regarding how it should be assessed 11 . The absence of standardized assessment methods makes it difficult to relate findings across studies 12 .Therefore , new approaches have arose aiming at enhancing the diagnosis and therapy of anhedonia 13 . The main challenge associated with studying anhedonia lies in the fact that it is not possible to measure directly 14 .Instead , researchers using indirect indicators based on behavioral tests 15 . For instance , the sucrose intake test 16 , the forced swim test 17 , and the open field test 18 are often employed to examine hedonia 19 .Although these tests provide valuable info related to anhedonia 20 , they do not enable us to comprehend the neural systems implicated 21 . Thus , further investigations using more sophisticated techniques are needed 22 .",
        "rewrite_text": "**Title:** Influence of Research Perspective on the Development of Anhedonia in Male Mice Exposed to Chronic Social Stress\n\n**Abstract:** Anhedonia, characterized by a diminished capacity to experience pleasure, is a significant symptom associated with major depressive disorder (MDD) and schizophrenia, yet the neurobiological mechanisms underlying this condition remain inadequately understood. This study aims to explore the effects of chronic social defeat (CSD) on the emergence of anhedonic-like behaviors in male C57BL/6J mice. Our findings indicate that mice subjected to CSD demonstrated a marked reduction in preference for a sucrose solution compared to control subjects, suggesting a decrease in hedonic capacity. Additionally, these CSD-exposed mice exhibited increased immobility during the forced swim test, alongside diminished locomotor activity in the open field test, further supporting the presence of anhedonic-like behavior. Notably, we observed a significant reduction in dopamine release in the nucleus accumbens shell following acute amphetamine administration in the defeated mice, highlighting potential neurochemical alterations associated with CSD. These results propose that CSD may serve as a viable animal model for studying anhedonia.\n\nAnhedonia is prevalent in approximately 20% of the global population suffering from MDD and is also observed in various psychiatric disorders, including schizophrenia, bipolar disorder, obsessive-compulsive disorder, eating disorders, alcohol dependence, and borderline personality disorder. Despite its critical role in these conditions, there remains a lack of consensus on standardized assessment methods for anhedonia, complicating the comparison of findings across different studies. Consequently, innovative approaches are emerging to improve the diagnosis and treatment of this symptom. The primary challenge in studying anhedonia lies in its indirect measurement, often relying on behavioral assessments such as the sucrose intake test, forced swim test, and open field test. While these methods provide valuable insights into anhedonic behavior, they do not elucidate the underlying neural mechanisms involved. Therefore, there is a pressing need for further research employing advanced techniques to deepen our understanding of the neurobiological basis of anhedonia.",
        "ori-fast-z-score": 0.5353033790313108,
        "water-fast-z-score": 8.743828992755144,
        "rewrite-fast-z-score": 1.9215378456610455
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  SN 2003du: 480 days in the Life of a Normal Type Ia Supernova .\nAbstract:\nWe present an analysis of photometric and spectroscopic data for SN 2003du, which was discovered on February 28th by R. Puckett at Mt. Wilson Observatory (Puckett et al., 2004) . The supernova is located in NGC 3190, a spiral galaxy with Hubble type Sb/Scd. It has been classified as a normal Type Ia supernova based on its light curve shape and spectral features. \n \n We find that the peak absolute magnitude of SN 2003du is -19.6 ± 0.1 mag, corresponding to a distance modulus of 34.7 ± 0.2 mag. This places it at a distance of about 50 Mpc (z = 0.0185). Using this distance we derive a total ejecta mass of 1.4 ± 0.3M⊙ and 56Ni yield of 0.09 ± 0.02M⊙ . \n \n \n \n In addition to our own observations, we have used archival data obtained through the CfA Supernova Archive, the SUSPECT archive maintained by the University of Hawaii, and the Wise Observatory archive.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : SN 2003du : 480 days in the Life of a Normal Type Ia Supernova . Abstract : We present an assessment of photometric and spectroscopic data for SN 2003du , which was discovered on February 28th by R . Puckett at Mt .Wilson Observatory ( Puckett et al . , 2004 ) . The supernova is situated in NGC 3190 , a spiral galaxy with Hubble class Sb / Scd .It has been classified as a normal Type Ia supernova based on its light curve size and spectral features . We see that the maximum absolute magnitude of SN 2003du is - 19 . 6 ± 0 . 1 mag , equivalent to a distance modulus of 34 . 7 ± 0 . 2 mag .This places it at a distance of about 50 Mpc ( z = 0 . 0185 ) . Using this distance we derive a total ejecta mass of 1 . 4 ± 0 . [UNK] and 56Ni yield of 0 . 09 ± 0 . [UNK] .In addition to our own observations , we have utilized archival measurements obtained through the CfA Supernova Archive , the SUSPECT collection held by the University of Hawaii , and the Wise Observatory library .",
        "rewrite_text": "We provide a comprehensive analysis of the photometric and spectroscopic observations of SN 2003du, a Type Ia supernova discovered on February 28, 2003, by R. Puckett at Mt. Wilson Observatory (Puckett et al., 2004). This supernova is located within NGC 3190, a spiral galaxy classified as Hubble type Sb/Scd. Our classification of SN 2003du as a normal Type Ia supernova is supported by its light curve characteristics and spectral features. The peak absolute magnitude of SN 2003du is measured at -19.6 ± 0.1 mag, which corresponds to a distance modulus of 34.7 ± 0.2 mag. This measurement indicates that SN 2003du is approximately 50 Mpc away, with a redshift (z) of 0.0185. Utilizing this distance, we estimate the total mass of the ejected material to be 1.4 ± 0. [UNK], along with a 56Ni yield of 0.09 ± 0. [UNK]. Our study incorporates not only our own observational data but also archival information sourced from the CfA Supernova Archive, the SUSPECT database maintained by the University of Hawaii, and the Wise Observatory library. This extensive dataset allows us to draw significant conclusions about the properties and behavior of SN 2003du, contributing to the broader understanding of Type Ia supernovae and their role in cosmology. Through this research, we aim to enhance the knowledge surrounding the mechanisms of supernova explosions and their implications for measuring cosmic distances.",
        "ori-fast-z-score": -1.0886621079036347,
        "water-fast-z-score": 2.56195947736032,
        "rewrite-fast-z-score": 0.23249527748763857
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Star Formation in the Bok Globule CB54 .\nAbstract:\nWe present near-infrared (NIR) imaging and spectroscopy of star formation activity in the Bok globule CB 54, which is located at a distance of about 1 kpc toward the Galactic anti-center direction. We found that there are two young stellar objects (YSOs), one Class I protostar with an infrared luminosity of ~10 Lsun and another embedded YSO candidate with a bolometric temperature of ~1000 K. The former object shows bipolar outflows traced by Herbig-Haro knots and molecular line wings. In addition to these two sources, we detected several other point-like NIR sources within the central region of CB 54. These may be low-mass pre-main-sequence stars or background galaxies. Our results suggest that this cloud core has experienced active star formation over its lifetime. \n \n Keywords: Star formation; Near-infrared spectroscopy; Bipolar outflow; Young stellar object",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Star Formation in the Bok Globule CB54 . Abstract : We present near - infrared ( NIR ) imaging and spectroscopy of star formation activity in the Bok globule CB 54 , which is situated at a distance of about 1 kpc toward the Galactic anti - center position .We showed that there are two young stellar bodies ( YSOs ) , one Class I protostar with an infrared luminosity of ~ 10 Lsun and another embedded YSO candidate with a bolometric temperature of ~ 1000 K . The former object displays bipolar outflows traced by Herbig - Haro knots and molecular line tails . In addition to these two sources , we spotted many other point - like NIR sources within the central region of CB 54 .These may be low - weight pre - principal - sequence stars or background galaxies . Our results show that this storm core has undergone active star formation over its lifetime .Keywords : Star formation ; Near - infrared spectroscopy ; Bipolar outflow ; Young stellar object",
        "rewrite_text": "We present a comprehensive study of star formation within the Bok globule CB54, located approximately 1 kiloparsec from the Galactic anti-center. Utilizing near-infrared (NIR) imaging and spectroscopy, we have identified significant star formation activity in this region. Our observations reveal the presence of two young stellar objects (YSOs): one is classified as a Class I protostar, exhibiting an infrared luminosity of around 10 Lsun, while the other is an embedded YSO candidate characterized by a bolometric temperature of approximately 1000 K. The Class I protostar is particularly noteworthy as it demonstrates bipolar outflows, which are evidenced by the presence of Herbig-Haro knots and molecular line tails, indicating dynamic processes associated with its formation. \n\nIn addition to these primary YSOs, our survey uncovered numerous other point-like NIR sources within the central area of CB54. These additional sources may represent low-mass pre-main-sequence stars or potentially background galaxies, suggesting a rich and complex environment for star formation. The findings from our study indicate that the Bok globule CB54 has experienced significant star formation activity throughout its existence, contributing to our understanding of the processes that govern star formation in such dense molecular clouds. This research highlights the importance of NIR observations in uncovering the hidden stellar populations within dark clouds and provides insights into the early stages of stellar evolution. \n\nKeywords: Star formation; Near-infrared spectroscopy; Bipolar outflow; Young stellar object.",
        "ori-fast-z-score": -0.5,
        "water-fast-z-score": 3.0,
        "rewrite-fast-z-score": 0.6644105970267493
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Comparison between Anomalous 6-cm H$_2$CO Absorption and CO(1-0) Emission in the L1204/S140 .\nAbstract:\nWe present new observations of molecular hydrogen (H_2CO) absorption toward the low-mass protostar IRAS 16293-2422, which is associated with two outflows driven by different components of this binary system. The main component drives an east-west bipolar flow that has been traced over more than 1000 AU using SiO emission lines observed at high angular resolution. We have detected anomalously strong absorption features near the systemic velocity of the source for both ortho- and para-H_2CO transitions. These are likely due to self-absorption within the dense gas surrounding the central protostars. In addition, we find evidence for blueshifted absorption features in the para-H_2CO line profiles that may be tracing infalling material along the axis of one of the outflow lobes. Finally, we compare our results with previous studies of carbon monoxide (CO) emission towards the same region.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Comparison between Anomalous 6 - cm H $ _ 2 $ CO Absorption and CO ( 1 - 0 ) Emission in the L1204 / S140 . Abstract : We report new studies of molecular hydrogen ( H _ 2CO ) diffusion toward the small - weight protostar IRAS 16293 - 2422 , which is associated with two outflows driven by various components of this binary system .The main component drives an eastward - west bipolar flow that has been traced over more than 1000 AU utilizing SiO emission lines observed at high angular resolution . We have discovered anomalously strong absorption events near the systemic speed of the source for both ortho - and para - H _ 2CO transitions .These are likely due to self - absorption within the dense gas covering the main protostars . In addition , we find proof for blueshifted absorption features in the para - H _ 2CO line profiles that might be tracing infalling matter along the axis of one of the outflow lobes .Finally , we compare our findings with previous investigations of carbon monoxide ( CO ) emission towards the same region .",
        "rewrite_text": "Title: A Comparative Study of Anomalous 6-cm H$_2$CO Absorption and CO (1-0) Emission in L1204/S140\n\nAbstract: In this study, we present new findings on the diffusion of molecular hydrogen (H$_2$CO) towards the low-mass protostar IRAS 16293-2422, which is linked to two distinct outflows driven by different components of its binary system. The primary component is responsible for an eastward-directed bipolar outflow, which we have traced over a distance exceeding 1000 AU using high-resolution observations of SiO emission lines. Our research has revealed unusually strong absorption features occurring near the systemic velocity of the source for both ortho- and para-H$_2$CO transitions. We propose that these absorption events are likely a result of self-absorption within the dense gas enveloping the main protostars. Furthermore, we have identified blueshifted absorption signatures in the para-H$_2$CO line profiles, which may indicate the presence of infalling material along the outflow lobe's axis. To contextualize our findings, we also compare our results with prior studies of carbon monoxide (CO) emission in the same region. This comparative analysis enhances our understanding of the dynamics and physical conditions surrounding the protostar and its associated outflows, shedding light on the complex interactions within this binary system. Our observations contribute to the broader knowledge of molecular processes in star formation and the role of various molecular species in tracing the kinematics of protostellar environments.",
        "ori-fast-z-score": -0.3511234415883917,
        "water-fast-z-score": 4.2723919920032305,
        "rewrite-fast-z-score": 0.4975185951049946
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gamma Rays frim the Galactic Centre .\nAbstract:\nThe gamma ray emission in the energy range 100 MeV to 10 GeV is studied using data taken by EGRET on board CGRO during its first four years of operation (1991) (1992) (1993) (1994) . The analysis has been performed for two different regions, one centered at l = 0° and b = - 5° , which includes the galactic centre region, and another centered at l = 180° and b = + 5° . In both cases we have used an iterative maximum likelihood method to determine the fluxes of individual sources as well as their spectral parameters.  We find that there are three distinct components contributing to the observed gamma-ray flux above 1 GeV :  A diffuse component with a power law spectrum extending upto ~10 GeV .\nA point source located near Sgr A* with a power law spectrum .\nAn extended source towards the galactic center with a broken power law spectrum . \nWe also present results obtained when the same analysis was repeated after excluding the contribution due to the central part of the Galaxy .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Gamma Rays frim the Galactic Centre . Abstract : The gamma radiation emission in the power range 100 MeV to 10 GeV is studied utilizing information taken by EGRET on board CGRO during its initial four seasons of operation ( 1991 ) ( 1992 ) ( 1993 ) ( 1994 ) .The comparison has been performed for two different regions , one located at l = 0° and b = - 5° , which includes the galactic centre region , and another focused at l = 180° and b = + 5° . In both cases we have utilized an iterative limit probability technique to estimate the fluxes of different sources as well as their spectral parameters .We see that there are three different components contributing to the seen beta - ray flux above 1 GeV : A diffuse component with a power law spectrum stretching upto ~ 10 GeV . A point source located near Sgr A * with a power law spectrum .An additional source towards the galactic center with a cracked power law spectrum . We additionally include findings obtained when the same evaluation was repeated after excluding the contribution owing to the central region of the Galaxy .",
        "rewrite_text": "**Title:** Gamma Rays from the Galactic Centre\n\n**Abstract:** This study investigates gamma-ray emissions in the energy range of 100 MeV to 10 GeV, utilizing data collected by the Energetic Gamma Ray Experiment Telescope (EGRET) aboard the Compton Gamma Ray Observatory (CGRO) during its first four operational years (1991-1994). The analysis focuses on two distinct regions of the sky: one centered at Galactic coordinates l = 0° and b = -5°, encompassing the Galactic Center, and another at l = 180° and b = +5°. To estimate the fluxes and spectral parameters of various gamma-ray sources, we employed an iterative limit probability technique. Our findings reveal three primary components contributing to the observed gamma-ray flux above 1 GeV. The first component is a diffuse emission characterized by a power-law spectrum that extends up to approximately 10 GeV. The second component is a point source located near Sagittarius A* (Sgr A*), which also exhibits a power-law spectrum. The third component is an additional source towards the Galactic Center, displaying a broken power-law spectrum. Furthermore, we conducted a supplementary analysis by excluding contributions from the central region of the Galaxy, which yielded additional insights into the gamma-ray emission characteristics. This comprehensive examination enhances our understanding of the gamma-ray sources in the vicinity of the Galactic Center and contributes to the broader knowledge of high-energy astrophysical phenomena.",
        "ori-fast-z-score": -1.8888888888888888,
        "water-fast-z-score": 4.638124095143555,
        "rewrite-fast-z-score": 0.30151134457776363
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Determination of the Form Factors for the Decay B0 -> D*- l+ nu_l and of the CKM Matrix Element |V_cb| .\nAbstract:\nWe present an analysis of B meson decays to final states with charmed particles, using data collected by the BABAR experiment at SLAC in 1999-2000 corresponding to an integrated luminosity of about 40 fb-1 . We measure the branching fractions for the decay modes B 0 -->D*+l- nu_l; B + -->D*0nu_l; B + -->D0*nu_l; B + ,B 0 -->D*+s nu_s; and B + ,B 0 →D*s nu_s.  From these measurements we extract values for the form factors f0(q2), f1(q2) and f2(q2). Using our results on the branching fraction and lifetime ratio between the two-body and three-body charm-strange B-decays, we determine the Cabibbo-Kobayashi-Maskawa matrix element Vcb = (41.6 +/- 1.1 +/- 2.4) x 10-3 .  The first uncertainty is statistical, the second systematic, and the third due to theoretical uncertainties.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Determination of the Form Factors for the Decay B0 - > D * - l + nu _ l and of the CKM Matrix Element | V _ cb | . Abstract : We report an analysis of B meson decays to finished states with charmed particles , using data taken by the BABAR study at SLAC in 1999 - 2000 resulting to an integrated luminosity of about 40 fb - 1 .We determine the branching fractions for the decay modes B 0 - - > D * + l - nu _ l ; B + - - > D * 0nu _ l ; B + - - > D0 * nu _ l ; B + , B 0 - - > D * + s nu _ s ; and B + , B 0 →D * s nu _ s . From these measurements we extract values for the form factors f0 ( q2 ) , f1 ( q2 ) and f2 ( q2 ) .Using our findings on the branching percentage and lifetime percentage between the two - bodies and three - bodies charm - strange B - decays , we determine the Cabibbo - Kobayashi - Maskawa matrix element Vcb = ( 41 . 6 + / - 1 . 1 + / - 2 . 4 ) x 10 - 3 . The first uncertainty is empirical , the second systematic , and the third due to theoretical uncertainties .",
        "rewrite_text": "**Title:** Determination of the Form Factors for the Decay B0 → D*− l+ ν_l and of the CKM Matrix Element |V_cb|\n\n**Abstract:** In this study, we present a comprehensive analysis of B meson decays into final states containing charmed particles, utilizing data collected by the BABAR experiment at SLAC during the years 1999 to 2000, which corresponds to an integrated luminosity of approximately 40 fb⁻¹. Our investigation focuses on several decay modes, specifically B⁰ → D*+ l⁻ ν_l, B⁺ → D*⁰ ν_l, B⁺ → D⁰* ν_l, and B⁺, B⁰ → D*+_s ν_s, as well as B⁺, B⁰ → D*_s ν_s. By analyzing these decay processes, we are able to determine the branching fractions associated with each mode. From these measurements, we extract the form factors f₀(q²), f₁(q²), and f₂(q²), which are crucial for understanding the dynamics of these decays. Furthermore, we leverage our results on the branching fractions and the lifetimes of both two-body and three-body charm-strange B decays to calculate the Cabibbo-Kobayashi-Maskawa (CKM) matrix element |V_cb|. Our findings yield a value of |V_cb| = (41.6 ± 1.1 ± 2.4) × 10⁻³, where the first uncertainty is statistical, the second is systematic, and the third arises from theoretical considerations. This work contributes to the ongoing efforts to refine our understanding of B meson decays and the underlying principles of flavor physics, providing essential insights into the structure of the CKM matrix and the interactions governing particle decay processes.",
        "ori-fast-z-score": 0.2773500981126146,
        "water-fast-z-score": 4.354648431614539,
        "rewrite-fast-z-score": -0.10721125348377948
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cosmology from String Theory .\nAbstract:\nThe talk will be divided into three parts, each part corresponding to one of the following topics: \n1) The Standard Model and Beyond; 2) Cosmological Constant Problem; 3) Inflationary Universe. In the first part we will discuss how string theory can provide an explanation for all known particles in nature as well as their interactions. We will also explain why it is important that there are extra dimensions beyond those which have been observed so far. \n \n In the second part we will present some recent results on the cosmological constant problem using supersymmetric field theories with extra dimensions. Finally, in the third part we will review our work on inflationary universe models based on supergravity coupled to gauge fields. This includes both single-field slow-roll inflation and multi-field chaotic inflation scenarios. These models may lead to observable signatures such as primordial gravitational waves or non-Gaussianities in the cosmic microwave background radiation (CMB).",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cosmology from String Theory . Abstract : The speech will be grouped into three sections , each portion corresponding to one of the following topics : 1 ) The Standard Model and Beyond ; 2 ) Cosmological Constant Problem ; 3 ) Inflationary Universe .In the first part we will explore how string theory can provide an reason for all known objects in nature as well as their interactions . We will also explain why it is important that there are additional dimensions beyond those which have been observed so far .In the second part we will present some latest findings on the cosmological constant problem involving supersymmetric field explanations with extra dimensions . Finally , in the third chapter we will review our work on inflationary universe models relying on supergravity combined to gauge fields .This encompasses both single - field short - roll inflation and multi - field turbulent inflation scenarios . These models could lead to observable signatures such as primordial gravitational waves or non - Gaussianities in the cosmic microwave background radiation ( CMB ) .",
        "rewrite_text": "Title: Cosmology from String Theory\n\nAbstract: This article is structured into three distinct sections, each addressing a critical aspect of cosmology informed by string theory. The first section delves into the Standard Model of particle physics and its extensions, examining how string theory offers a comprehensive framework for understanding all fundamental particles and their interactions. We emphasize the significance of additional spatial dimensions that extend beyond the familiar four-dimensional spacetime, arguing that these extra dimensions are essential for a complete description of physical phenomena.\n\nIn the second section, we tackle the cosmological constant problem, a longstanding issue in theoretical physics. We present recent advancements that incorporate supersymmetric field theories alongside extra dimensions to provide potential resolutions to this dilemma. These findings suggest that the interplay between supersymmetry and higher-dimensional spaces may yield insights into the nature of dark energy and its implications for the universe's expansion.\n\nThe final section focuses on inflationary universe models, where we explore the integration of supergravity with gauge fields. We discuss various inflationary scenarios, including single-field short-roll inflation and multi-field turbulent inflation. These models are particularly noteworthy as they may produce observable effects, such as primordial gravitational waves and non-Gaussian features in the cosmic microwave background (CMB) radiation. Our analysis highlights the potential for these signatures to provide empirical evidence supporting string theory and its cosmological implications. Overall, this article aims to bridge theoretical advancements in string theory with observable phenomena in cosmology, paving the way for future research in this dynamic field.",
        "ori-fast-z-score": 0.22645540682891913,
        "water-fast-z-score": 4.612860393796698,
        "rewrite-fast-z-score": 1.9005105362789922
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  ROXA: a new multi-frequency selected large sample of blazars with SDSS and 2dF optical spectroscopy .\nAbstract:\nWe present the results of an extensive spectroscopic survey for active galactic nuclei (AGN) in the southern hemisphere using the Sloan Digital Sky Survey (SDSS). The main goal is to select a complete flux-limited sample of radio-loud AGNs at redshifts z < 0.7, which we call ROXA (Radio Optical eXtragalactic Astronomy), by cross-correlating the FIRST 1.4 GHz radio source catalogue with the SDSS DR3 photometric database. We have obtained spectra for more than 1000 sources over an area of about 10,000 deg2. In this work we report on the selection criteria used to define our sample as well as its completeness and reliability. We also discuss some preliminary results concerning the properties of these objects such as their luminosity function and redshift distribution. This project has been funded by the European Space Agency under contract number 4000106131/16/NL/PA.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : ROXA : a new multi - frequency selected large sample of blazars with SDSS and 2dF optical spectroscopy . Abstract : We present the results of an extensive spectroscopic study for active galactic nuclei ( AGN ) in the southern hemisphere using the Sloan Digital Sky Survey ( SDSS ) .The main goal is to select a complete flux - limited sample of radio - loud AGNs at redshifts z < 0 . 7 , which we call ROXA ( Radio Optical eXtragalactic Astronomy ) , by cross - correlating the FIRST 1 . 4 GHz radio source catalogue with the SDSS DR3 photometric archive . We have achieved spectra for more than 1000 sources over an area of about 10 , 000 deg2 .In this research we publish on the selection procedures used to define our sample as well as its completeness and reliability . We especially consider some preliminary results relating the properties of these objects such as their luminosity function and redshift distribution .This project has been sponsored by the European Space Agency under contract number 4000106131 / 16 / NL / PA .",
        "rewrite_text": "We present the findings of a comprehensive spectroscopic investigation focused on active galactic nuclei (AGN) located in the southern hemisphere, utilizing data from the Sloan Digital Sky Survey (SDSS). Our primary objective is to establish a complete, flux-limited sample of radio-loud AGNs at redshifts less than 0.7, which we have designated as ROXA (Radio Optical eXtragalactic Astronomy). This was accomplished by cross-referencing the FIRST 1.4 GHz radio source catalog with the SDSS DR3 photometric archive. As a result of this effort, we have successfully obtained spectra for over 1,000 sources across an expansive area of approximately 10,000 square degrees. In this article, we detail the selection methodologies employed to curate our sample, as well as an assessment of its completeness and reliability. Furthermore, we present preliminary findings that explore various characteristics of these AGNs, including their luminosity function and redshift distribution. This research initiative has been supported by the European Space Agency under contract number 4000106131/16/NL/PA, highlighting its significance in the broader context of extragalactic astronomy. The insights gained from this study not only contribute to our understanding of the properties and distribution of radio-loud AGNs but also pave the way for future investigations into the nature of these fascinating celestial objects.",
        "ori-fast-z-score": 0.8819171036881969,
        "water-fast-z-score": 3.75,
        "rewrite-fast-z-score": 2.182178902359924
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Radial distribution of the inner magnetosphere plasma pressure using low-altitude satellite data during geomagnetic storm: the March 1-8, 1982 Event .\nAbstract:\nThe radial distribution of the inner magnetospheric (IM) plasma pressure is studied by analyzing the magnetic field and particle measurements made onboard two satellites at low altitude in the equatorial plane for an intense geomagnetic storm that occurred between March 1-5, 1982 . The results show that there are significant differences in the IM plasma pressure profiles obtained with different satellites. In particular, the pressure profile derived from GEOS-1 observations shows a sharp peak near L = 3 , while those inferred from ATS-6 and GEOS-2 data exhibit much broader peaks around L = 4 . These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space. It is also found that the pressure profiles inferred from the three satellites agree well when they are shifted outward along the L-shell coordinate system. This suggests that the observed difference in the pressure profiles can be attributed mainly to the spatial variation of the pressure rather than temporal changes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Radial distribution of the inner magnetosphere plasma pressure using minimum - height satellite information during geomagnetic storm : the March 1 - 8 , 1982 Event . Abstract : The radial distribution of the inner magnetospheric ( IM ) plasma pressure is studied by analyzing the magnetic field and electron calculations made onboard two spacecraft at low height in the equatorial plane for an extreme geomagnetic cyclone that occurred between March 1 - 5 , 1982 .The results show that there are significant variations in the IM plasma pressure profiles obtained with various satellites . In particular , the pressure profile derived from GEOS - 1 studies shows a sharp peak near L = 3 , while those inferred from ATS - 6 and GEOS - 2 data display considerably wider peaks around L = 4 .These discrepancies may be due to the fact that these satellites have different orbits which sample different regions of space . It is also discovered that the pressure profiles inferred from the three satellites cooperate well when they are shifted outward along the L - shell coordinate system .This implies that the seen shift in the pressure profiles can be due mainly to the spatial varying of the pressure rather than temporal changes .",
        "rewrite_text": "**Title:** Radial Distribution of Inner Magnetosphere Plasma Pressure During the Geomagnetic Storm of March 1-8, 1982: Insights from Minimum-Height Satellite Data\n\n**Abstract:** This study investigates the radial distribution of plasma pressure within the inner magnetosphere (IM) by analyzing data collected from two low-altitude satellites operating in the equatorial plane during a significant geomagnetic storm that occurred from March 1 to March 5, 1982. The analysis focuses on the magnetic field and electron density measurements obtained from these spacecraft, providing a comprehensive view of the plasma pressure dynamics during this extreme event. The findings reveal notable discrepancies in the IM plasma pressure profiles derived from different satellites, highlighting the complexity of the magnetospheric environment. Specifically, the pressure profile obtained from the GEOS-1 satellite exhibits a pronounced peak at an L-shell value of approximately 3, whereas the profiles from ATS-6 and GEOS-2 indicate broader peaks centered around L = 4. These variations are likely attributable to the distinct orbital paths of the satellites, which sample different spatial regions within the magnetosphere. Furthermore, the study finds that when the pressure profiles from the three satellites are adjusted outward along the L-shell coordinate system, they exhibit a remarkable degree of correlation. This observation suggests that the observed shifts in plasma pressure profiles are primarily influenced by spatial variations in pressure rather than temporal fluctuations. Overall, this research enhances our understanding of the inner magnetosphere's response to geomagnetic storms and underscores the importance of satellite positioning in interpreting plasma pressure dynamics. The results contribute valuable insights into the behavior of the magnetosphere during extreme space weather events, with implications for future studies and satellite missions aimed at monitoring and understanding the Earth's magnetic environment.",
        "ori-fast-z-score": 0.8251369970070347,
        "water-fast-z-score": 5.848076606885379,
        "rewrite-fast-z-score": 0.6069769786668839
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The First Supernova Explosions: Energetics, Feedback, and Chemical Enrichment .\nAbstract:\nWe present the first results on chemical enrichment in cosmological simulations with supernova feedback. We use two different implementations for stellar winds and supernovae (SNe) to study their effects on galaxy formation. The wind implementation is based on kinetic energy injection into gas particles that are above some threshold density; SNe explode as thermal energy injections at random locations within star forming regions. Our main conclusions are:  1. Winds alone cannot reproduce observed metallicities in galaxies.  2. In our fiducial model we find good agreement between simulated and observed metallicity distributions over four orders of magnitude in luminosity. 3. Simulated metal mass fractions agree well with observations out to z = 5. 4. Metal-rich stars form preferentially in massive haloes because they have more time available to enrich themselves through multiple generations of star formation. 5. Gas cooling rates are suppressed by metals produced by previous generations of stars.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The First Supernova Explosions : Energetics , Feedback , and Chemical Enrichment . Abstract : We report the first findings on chemical enrichment in cosmological simulations with supernova feedback .We use two different implementations for stellar winds and supernovae ( SNe ) to study their impacts on galaxy formation . The wind implementation is based on kinetic power injection into gas molecules that are above some threshold concentration ; SNe explode as heat power injections at random locations within star producing regions .Our main results are : 1 . Winds alone impossible reproduce observed metallicities in galaxies .2 . In our fiducial approach we find good agreement between simulated and detected metallicity distributions over four orders of magnitude in luminosity .3 . Simulated metal mass fractions accord well with observations out to z = 5 .4 . Metal - rich stars create preferentially in massive haloes because they have more time accessible to enrich themselves through several generations of star formation .5 . Gas cooling rates are suppressed by metals produced by earlier generations of stars .",
        "rewrite_text": "We present groundbreaking findings on the role of supernova feedback in chemical enrichment within cosmological simulations. This study utilizes two distinct methodologies for modeling stellar winds and supernovae (SNe) to assess their influence on galaxy formation processes. Our wind model operates on the principle of kinetic energy injection into gas molecules that exceed a specified concentration threshold, while SNe are modeled as heat power injections occurring randomly within regions of star formation. \n\nOur key findings are as follows: Firstly, we demonstrate that winds alone cannot account for the observed metallicities in galaxies, indicating the necessity of incorporating supernova feedback for accurate modeling. Secondly, our fiducial model shows a strong correlation between the simulated and observed metallicity distributions across four orders of magnitude in luminosity, suggesting that our approach effectively captures the complexities of chemical enrichment. Thirdly, we find that the simulated metal mass fractions align closely with observational data up to redshift z = 5, reinforcing the reliability of our simulations over a significant range of cosmic time. \n\nAdditionally, we observe that metal-rich stars tend to form preferentially in massive halos, as these environments provide extended timeframes for enrichment through multiple generations of star formation. Lastly, we note that the cooling rates of gas are significantly suppressed by the metals produced by earlier stellar generations, highlighting the intricate interplay between star formation, supernova feedback, and the chemical evolution of the universe. These findings contribute to a deeper understanding of the processes governing galaxy formation and the distribution of elements in the cosmos.",
        "ori-fast-z-score": 0.6793662204867574,
        "water-fast-z-score": 5.062895554167108,
        "rewrite-fast-z-score": -0.5432144762551112
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Adding Environmental Gas Physics to the Semi-Analytic Method for Galaxy Formation: Gravitational Heating .\nAbstract:\nWe present an improved semi-analytical method (SAM) that includes gravitational heating by dark matter halos and gas cooling in galaxy formation, which is essential to reproduce observed properties of galaxies such as luminosity functions at different redshifts.  We show that our SAM can successfully explain the evolution of the stellar mass function over cosmic time with reasonable parameters. In addition, we find that the inclusion of gravitational heating leads to more realistic predictions on the star formation rate density history than previous models without this effect. Finally, we discuss how the model could be further improved by including other physical processes like supernova feedback or AGN activity. The results presented here are based on observations made with ESO Telescopes at Paranal Observatory under programme ID 085.A-0488(A). This work was supported by JSPS KAKENHI Grant Number JP15K05481. Figure 1 . Predicted number densities of galaxies as a function of their total stellar masses compared with observational data taken from the literature. Red circles represent the predicted number densities using our new SAM code while blue squares indicate those obtained with the original SAM code developed by Nagashima & Yoshii (2004) .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Adding Environmental Gas Physics to the Semi - Analytic Method for Galaxy Formation : Gravitational Heating . Abstract : We introduce an excellent semi - empirical method ( SAM ) that encompasses gravitational heating by black material halos and gas warming in universe formation , which is crucial to reproduce observed properties of stars such as luminosity functions at different redshifts .We see that our SAM can effectively predict the evolution of the stellar mass function over cosmic time with suitable variables . In addition , we find that the introduction of gravitational heating results to more realistic predictions on the star formation rate density history than prior models without this effect .Finally , we talk how the model could be further strengthened by including other physical processes like supernova feedback or AGN activity . The results presented here are based on observations made with ESO Telescopes at Paranal Observatory under programme ID 085 . A - 0488 ( A ) .This project was supported by JSPS KAKENHI Grant Number JP15K05481 . Figure 1 .Predicted number densities of galaxies as a function of their total stellar masses compared with observational data taken from the literature . Red rings represent the expected number densities using our new SAM code while blue squares represents those achieved with the previous SAM code developed by Nagashima & Yoshii ( 2004 ) .",
        "rewrite_text": "Title: Incorporating Environmental Gas Physics into the Semi-Analytic Method for Galaxy Formation: Gravitational Heating\n\nAbstract: In this study, we present a novel semi-empirical method (SAM) that integrates the effects of gravitational heating from dark matter halos and gas warming during the formation of the universe. This approach is essential for accurately reproducing the observed characteristics of stars, including luminosity functions across various redshifts. Our findings demonstrate that this enhanced SAM effectively predicts the evolution of the stellar mass function throughout cosmic history by utilizing appropriate variables. Notably, the inclusion of gravitational heating leads to more realistic estimations of the star formation rate density history compared to previous models that did not account for this phenomenon. Furthermore, we discuss potential enhancements to the model by incorporating additional physical processes, such as supernova feedback and active galactic nucleus (AGN) activity, which could further refine our predictions. The results presented in this paper are based on observational data obtained with ESO Telescopes at the Paranal Observatory, under programme ID 085.A-0488(A). This research was supported by the Japan Society for the Promotion of Science (JSPS) KAKENHI Grant Number JP15K05481. Figure 1 illustrates the predicted number densities of galaxies as a function of their total stellar masses, juxtaposed with observational data from existing literature. The red rings indicate the expected number densities derived from our new SAM code, while the blue squares represent the results obtained from the previous SAM code developed by Nagashima & Yoshii (2004).",
        "ori-fast-z-score": -0.6060915267313265,
        "water-fast-z-score": 5.125692857821981,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Rapid Mixing of Gibbs Sampling on Graphs that are Sparse on Average .\nAbstract:\nWe consider the problem of sampling from an arbitrary probability distribution over graphs with fixed number of nodes and edges, where each node has a given degree constraint. We propose a novel algorithm for this task based on the idea of rapidly mixing Markov chains known as Metropolis-Hastings algorithms. Our approach is to use a special type of graph called a tree decomposition which allows us to decompose our original problem into smaller problems in such a way that we can efficiently sample from these smaller problems using existing techniques. In particular, we show how to construct a tree decomposition of any input graph G = (V , E) by first constructing a tree decomposition of its line graph L(G). Then, we prove that if there exists a polynomial time algorithm A that solves one of these small subproblems then it also implies the existence of a polynomial time algorithm B that solves all of them simultaneously. Finally, we present experimental results showing that our proposed method outperforms state-of-the-art methods when applied to several real-world datasets.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Rapid Mixing of Gibbs Sampling on Graphs that are Sparse on Average . Abstract : We consider the question of sampling from an arbitrary likelihood distribution over graphs with constant number of vertices and edges , where each node has a given degree constraint .We suggest a new algorithm for this job based on the idea of quickly mixing Markov chains known as Metropolis - Hastings algorithms . Our idea is to use a unique kind of graph named a tree decomposition which allows us to decompose our existing problem into tiny problems in such a way that we can efficiently sample from these bigger difficulties using existing techniques .In particular , we prove how to build a tree decomposition of any input graph G = ( V , E ) by first creating a tree decomposition of its line graph L ( G ) . Then , we prove that if there exists a polynomial time algorithm A that solves one of these little subproblems then it also proves the existence of a polynomial time algorithm B that solves all of them simultaneously .Finally , we present research results promising that our proposed approach outperforms state - of - the - art methods when applied to several real - time datasets .",
        "rewrite_text": "In this article, we address the challenge of sampling from arbitrary likelihood distributions over graphs characterized by a constant number of vertices and edges, while adhering to specific degree constraints for each node. We introduce a novel algorithm that leverages the principles of rapid mixing in Markov chains, specifically through the application of Metropolis-Hastings algorithms. Our approach centers around the innovative use of tree decompositions, a specialized type of graph structure that enables us to break down the original problem into smaller, more manageable subproblems. This decomposition facilitates efficient sampling from these complex issues using established methodologies.\n\nTo construct a tree decomposition for any given graph \\( G = (V, E) \\), we first generate a tree decomposition of its corresponding line graph \\( L(G) \\). We demonstrate that the existence of a polynomial-time algorithm \\( A \\) capable of solving one of these smaller subproblems implies the existence of another polynomial-time algorithm \\( B \\) that can simultaneously address all subproblems. This result is significant as it establishes a foundational link between the solvability of individual components and the overall problem.\n\nOur empirical research indicates that the proposed algorithm significantly outperforms current state-of-the-art techniques when applied to various real-time datasets. The findings suggest that our method not only enhances the efficiency of sampling from complex graph structures but also contributes to the broader field of probabilistic graphical models. This work opens new avenues for future research in graph sampling and highlights the potential of tree decompositions in optimizing algorithmic performance in statistical inference tasks.",
        "ori-fast-z-score": -0.30779350562554625,
        "water-fast-z-score": 4.77212697612801,
        "rewrite-fast-z-score": -1.3416407864998738
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Generating Minimally Coupled Einstein-Scalar Field Solutions from Vacuum Solutions with Arbitrary Cosmological Constant .\nAbstract:\nWe present an algorithm for generating new solutions to the coupled Einstein-scalar field equations, starting from vacuum solutions and adding scalar fields in such a way that the resulting solution is minimally coupled.  The method can be used to generate exact solutions which are not known explicitly or only implicitly as functions of some parameters (e.g., by solving algebraic equations). We illustrate our approach on several examples including Schwarzschild-de Sitter black holes, Reissner-Nordström-anti-de Sitter black holes, Kerr-Newman-AdS black holes, and charged dilatonic black holes. In particular we show how one can obtain explicit expressions for the massless limit of these black hole solutions. Our results may also have applications beyond gravity theory, e.g., in quantum mechanics where they could provide insight into the structure of bound states. Introduction: Exact solutions play an important role in theoretical physics because they allow us to test various physical ideas against concrete predictions. However, finding exact solutions to physically interesting problems often turns out to be very difficult. For example, it took more than 100 years after the discovery of general relativity before the first exact black hole solutions were found  1-3 . Even today there exist many open questions about black holes  4  . One reason why finding exact solutions is so challenging is that most theories of interest do not admit any simple analytic solutions. Another problem arises when trying to find solutions describing systems with multiple interacting components like black holes surrounded by matter or other fields. Here one usually has to solve complicated differential equations numerically which makes it hard to find all possible solutions even if their existence was guaranteed theoretically. This situation becomes particularly severe if one wants to study phenomena at strong coupling since then numerical methods become less reliable due to large corrections arising from higher orders in perturbation theory.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Generating Minimally Coupled Einstein - Scalar Field Solutions from Vacuum Solutions with Arbitrary Cosmological Constant . Abstract : We present an algorithm for generating new answers to the coupled Einstein - scalar field equations , beginning from vacuum solutions and adding scalar fields in such a way that the resulting solve is minimally coupled .The method can be used to create precise solutions which are not established explicitly or only implicitly as functions of some parameters ( e . g . , by modeling algebraic equations ) . We illustrate our approach on numerous instances using Schwarzschild - de Sitter dark holes , Reissner - Nordström - anti - de Sitter dark holes , Kerr - Newman - AdS red holes , and charged dilatonic black holes .In particular we show how one can obtain precise expressions for the massless maximum of these black hole solutions . Our results may also have applications beyond gravitational mechanics , e . g . , in quantum mechanics where they may provide insight into the formation of bound states .Introduction : Exact solutions play an important role in theoretical physics because they allow us to test various physical concepts against concrete expectations . However , finding exact treatments to physically exciting difficulties often comes out to be very difficult .For instance , it takes more than 100 years after the discovery of general relativity before the first accurate black hole answers were found 1 - 3 . Even nowadays there remain many open questions about black holes 4 .One reason why seeking precise solutions is so difficult is that most models of importance do not admit any straightforward analytic solutions . Another difficulty arises when trying to find solutions involving systems with many interacting components like white holes separated by matter or other fields .Here one usually has to solve intricate differential equations numerically which makes it difficult to find all possible solutions even if their existence was assured theoretically . This problem arises terribly extreme if one wants to study phenomena at strong coupling since then numerical models become fewer reliable resulting to large corrections resulting from lower orders in perturbation theory .",
        "rewrite_text": "**Title:** Generating Minimally Coupled Einstein-Scalar Field Solutions from Vacuum Solutions with Arbitrary Cosmological Constant\n\n**Abstract:** In this paper, we introduce a novel algorithm designed to generate new solutions to the coupled Einstein-scalar field equations, starting from established vacuum solutions and incorporating scalar fields in a manner that ensures minimal coupling. This approach enables the derivation of precise solutions that may not be explicitly known or are only implicitly defined through parameters, such as those arising from algebraic modeling. We demonstrate the effectiveness of our method through various examples, including Schwarzschild-de Sitter black holes, Reissner-Nordström anti-de Sitter black holes, Kerr-Newman-AdS red holes, and charged dilatonic black holes. Notably, we derive explicit expressions for the massless maxima of these black hole solutions. The implications of our findings extend beyond gravitational physics; they may also provide valuable insights in quantum mechanics, particularly regarding the formation of bound states. \n\n**Introduction:** Exact solutions are crucial in theoretical physics as they serve as benchmarks for testing various physical theories against empirical expectations. However, identifying exact solutions to complex physical problems often proves to be a formidable challenge. For example, it took over a century after the advent of general relativity for the first accurate black hole solutions to be discovered. Even today, numerous questions regarding black holes remain unresolved. One significant obstacle in finding precise solutions is that many important models do not yield straightforward analytic solutions. Additionally, the complexity increases when dealing with systems that involve multiple interacting components, such as white holes influenced by surrounding matter or fields. In such cases, researchers typically resort to solving complex differential equations numerically, which complicates the identification of all potential solutions, even when their existence is theoretically guaranteed. This challenge is exacerbated in scenarios involving strong coupling, where numerical models may become unreliable, leading to substantial corrections from lower-order perturbation theory.",
        "ori-fast-z-score": 0.37371754637596794,
        "water-fast-z-score": 8.296529529546488,
        "rewrite-fast-z-score": 1.47026414181486
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the detection of very high redshift Gamma Ray Bursts with Swift .\nAbstract:\nWe present an analysis of the first two years (Feb 2005 -Jan 2007) of data taken by the Swift satellite, which has been designed to detect and study gamma ray bursts (GRBs). We find that GRB 050904 at z = 6.3 is the most distant object ever detected in the electromagnetic spectrum. The prompt emission was observed over more than four orders of magnitude in energy, from radio waves up to X-rays. This burst also had one of the highest fluences recorded so far for any GRB. In addition we report on another burst, GRB 080913, whose afterglow was found to be variable on timescales as short as 1 minute. These results are discussed within the context of current models for GRB production. Keywords: Gamma-ray burst, High-redshift universe, Afterglows, Swift satellite. Gamma-ray bursts (GRBs), intense flashes of high-energy radiation lasting only milliseconds, have now been discovered out to redshifts greater than six  1  . Their extreme luminosities make them powerful probes into the early Universe  2  , but their origin remains unknown  3  .\nSwift  4  , launched in November 2004, carries three instruments capable of detecting GRBs across the entire electromagnetic spectrum  5  : the Burst Alert Telescope  6  detects GRBs via their X-ray and/or optical emissions; the Ultraviolet/Optical Telescope  7  observes the afterglow through ultraviolet and visible light; and the X-ray telescope  8  monitors the afterglow s decaying flux. Here we describe our initial findings using these instruments during the first two years of operation. \nThe Burst Alert Telescope\n\nBurst Alert Telescope Observations of GRB 050904\nOn September 5 th , 2006, the Burst Alert Telescope triggered on a bright source located at RA=05h54m36.6s Dec=-69d21 59.6   9  . Follow-up observations revealed this event to be a new record holder among GRBs  10  . Its peak photon count rate reached 2 x 10 4 photons s -1 cm -2 in the 15-150 keV band  11  . It lasted about",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the detection of very high redshift Gamma Ray Bursts with Swift . Abstract : We report an assessment of the first two years ( Feb 2005 - Jan 2007 ) of evidence gained by the Swift satellite , which has been designed to identify and track γ ray clusters ( GRBs ) .We see that GRB 050904 at z = 6 . 3 is the most distant object ever observed in the electromagnetic spectrum . The prompt emission was seen over more than four orders of magnitude in energy , from radio beams up to X - rays .This burst also had one of the highest fluences recorded so far for any GRB . In addition we report on another burst , GRB 080913 , whose afterglow was shown to be varying on timescales as short as 1 minute .These conclusions are discussed within the context of recent models for GRB development . Keywords : Gamma - ray flare , High - redshift universe , Afterglows , Swift satellite .Gamma - ray bursts ( GRBs ) , intense pulses of high - energy rays lasting only milliseconds , have now been detected out to redshifts greater than six 1 . Their intense luminosities give them potent probes into the early Universe 2 , but their source remains unidentified 3 .Swift 4 , launched in November 2004 , carries three devices capable of detecting GRBs across the entire electromagnetic spectrum 5 : the Burst Alert Telescope 6 detects GRBs via their X - ray and / or laser emissions ; the Ultraviolet / Optical Telescope 7 sees the afterglow through ultraviolet and visible radiation ; and the X - ray telescope 8 monitors the afterglow s decaying flux . Here we explain our first findings using these instruments during the first two years of operation .The Burst Alert Telescope Burst Alert Telescope Observations of GRB 050904 On September 5 th , 2006 , the Burst Alert Telescope triggered on a bright source located at RA = 05h54m36 . 6s Dec = - 69d21 59 . 6 9 . Follow - up observations showed this event to be a new record holder among GRBs 10 .Its peak photon count rate reached 2 x 10 4 photons s - 1 cm - 2 in the 15 - 150 keV band 11 . It lasted about",
        "rewrite_text": "**Title: On the Detection of Very High Redshift Gamma Ray Bursts with Swift**\n\n**Abstract:** This study presents an evaluation of the initial two years (February 2005 - January 2007) of data collected by the Swift satellite, which was specifically designed to detect and monitor gamma-ray bursts (GRBs). Notably, we highlight GRB 050904, which, at a redshift of z = 6.3, stands as the most distant object observed in the electromagnetic spectrum to date. The prompt emission from this burst was detected across an extensive energy range, spanning over four orders of magnitude, from radio frequencies to X-rays. Furthermore, GRB 050904 exhibited one of the highest fluences recorded for any GRB thus far. We also discuss GRB 080913, which displayed afterglow variability on remarkably short timescales, as brief as one minute. These findings are contextualized within contemporary models of GRB evolution. \n\nGamma-ray bursts are characterized as intense, high-energy emissions that last only milliseconds, and they have now been observed at redshifts exceeding six. Their extraordinary luminosity makes them valuable tools for probing the early universe, although the exact nature of their progenitors remains elusive. The Swift satellite, launched in November 2004, is equipped with three instruments capable of detecting GRBs across the entire electromagnetic spectrum: the Burst Alert Telescope (BAT) identifies GRBs through their X-ray and/or optical emissions; the Ultraviolet/Optical Telescope (UVOT) captures afterglow emissions in the ultraviolet and visible ranges; and the X-ray Telescope (XRT) monitors the decay of the afterglow's flux. \n\nIn this article, we detail our initial findings from the operation of these instruments during the first two years. The BAT observed GRB 050904 on September 5, 2006, triggering on a bright source located at RA = 05h54m36.6s and Dec = -69d21'59.6\". Follow-up observations confirmed this event as a record-setting GRB, with a peak photon count rate of 2 x 10^4 photons s^-1 cm^-2 in the 15-150 keV band. This research contributes to our understanding of GRBs and their implications for cosmology. \n\n**Keywords:** Gamma-ray bursts, High-redshift universe, Afterglows, Swift satellite.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.286185570937122,
        "rewrite-fast-z-score": 0.8980265101338746
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Variable accretion and emission from the stellar winds in the Galactic centre .\nAbstract:\nWe present results on variable X-ray emission from the central parsecs (0.1 pc) around Sgr A*, which is associated with hot plasma ejected by young massive stars near the supermassive black hole at the Galactic Centre. We find that the variability timescale decreases as we move towards higher energies. The observed power spectrum can be explained if there are two components contributing to the total flux - one steady component and another varying component. This suggests that the source of the X-rays may not be point-like but extended. Our analysis also shows that the luminosity changes significantly over time scales ranging between hours and years. These variations could be due to either intrinsic or extrinsic factors such as orbital motion of the emitting region and/or obscuration effects caused by intervening clouds. In addition, we have found evidence for an anti-correlation between the soft and hard bands during flares. This indicates that the spectral shape varies along with its intensity.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Variable accretion and emission from the stellar winds in the Galactic centre . Abstract : We report findings on variable X - ray radiation from the central parsecs ( 0 . 1 pc ) around Sgr A * , which is associated with hot plasma expelled by young massive galaxies near the supermassive black hole at the Galactic Centre .We see that the variability timescale decreases as we move towards higher energies . The observed power spectrum can be understood if there are two parts contributing to the total flux - one steady component and another varying component .This implies that the origin of the X - radiation may not be point - like but extended . Our study also shows that the luminosity shifts significantly over time ranges ranging between hours and years .These changes could be due to either intrinsic or extrinsic factors such as orbital movement of the emitting area and / or obscuration effects caused by intervening clouds . In addition , we have discovered evidence for an counter - correlation between the dark and hard bands during flares .This implies that the spectral form varies along with its strength .",
        "rewrite_text": "We present our research on the variable X-ray emissions detected in the central parsecs (0.1 pc) surrounding Sagittarius A* (Sgr A*), which are linked to the hot plasma ejected by young massive stars in proximity to the supermassive black hole at the Galactic Centre. Our findings indicate that the timescale of variability decreases with increasing energy levels, suggesting a complex interplay in the emission processes. The power spectrum we observed can be interpreted as the result of two distinct components contributing to the overall flux: a steady component and a variable component. This observation raises the possibility that the source of the X-ray radiation may not be localized but rather extended across the region. Furthermore, our analysis reveals significant fluctuations in luminosity over timescales ranging from hours to years. These variations could stem from intrinsic factors, such as changes in the emitting region's dynamics, or extrinsic factors, including obscuration effects from intervening clouds. Notably, we have identified a counter-correlation between the dark and hard X-ray bands during flare events, suggesting that the spectral characteristics of the emissions are not only variable in strength but also in form. This research enhances our understanding of the complex mechanisms at play in the vicinity of Sgr A* and contributes to the broader knowledge of X-ray emissions in galactic centers.",
        "ori-fast-z-score": -1.5275252316519468,
        "water-fast-z-score": 4.013213469645139,
        "rewrite-fast-z-score": 1.2
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Electronic spin transport and spin precession in single graphene layers at room temperature .\nAbstract:\nWe report on the observation of electronic spin transport across macroscopic distances (several millimeters) in suspended single-layer graphene devices at room temperature.  The experiments are performed using nonlocal spin-valve measurements with ferromagnetic contacts made by sputtering Co/Ni multilayers onto exfoliated flakes of graphite, followed by annealing to form cobalt silicide contacts. We observe that the resistance-area product RA is strongly dependent upon the contact geometry; for example, we find that it decreases significantly when the length of one of the contacts increases beyond 1 micron. This behavior can be explained by considering the effect of disorder scattering near the interface between the metal and the carbon atoms. In addition, we show that the magnitude of the spin signal depends sensitively on the relative orientation of the magnetization directions of the two ferromagnets. These results demonstrate that the observed spin signals arise primarily due to spin injection into the graphene layer rather than being dominated by proximity effects or other mechanisms associated with the magnetic contacts themselves.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Electronic spin travel and spin precession in single graphene structures at room temperature . Abstract : We report on the observation of electronic spin travel across macroscopic distances ( several millimeters ) in suspended single - layer graphene materials at room temperature .The studies are performed using nonlocal spin - valve measurements with ferromagnetic contacts produced by sputtering Co / Ni multilayers onto exfoliated flakes of graphite , followed by annealing to form cobalt silicide contacts . We see that the tolerance - area product RA is strongly dependent upon the contact shape ; for example , we find that it reduces considerably when the length of one of the contacts increases beyond 1 micron .This phenomenon can be described by using the impact of disorder absorption near the interface between the metal and the carbon atoms . In addition , we find that the magnitude of the spin signal relies sensitively on the relative position of the magnetization directions of the two ferromagnets .These data demonstrate that the known spin signals arise principally due to spinning injection into the graphene substrate rather than being dominated by proximity effects or other mechanisms associated with the magnetic contacts themselves .",
        "rewrite_text": "We present our findings on the remarkable phenomenon of electronic spin transport over macroscopic distances, specifically several millimeters, in suspended single-layer graphene at room temperature. Our investigation employs nonlocal spin-valve measurements facilitated by ferromagnetic contacts, which are created through the sputtering of Co/Ni multilayers onto exfoliated graphite flakes, followed by an annealing process that results in the formation of cobalt silicide contacts. A key observation from our experiments is the significant dependence of the tolerance-area product (RA) on the geometry of the contacts. Notably, we observe a marked reduction in RA when the length of one of the contacts exceeds 1 micron. This behavior can be attributed to the effects of disorder absorption occurring at the interface between the metal and the carbon atoms, which influences spin transport. Furthermore, our results indicate that the amplitude of the spin signal is highly sensitive to the relative orientations of the magnetization directions of the two ferromagnetic contacts. This sensitivity underscores the importance of the spin injection process into the graphene substrate, suggesting that the observed spin signals are primarily a result of this injection rather than being predominantly influenced by proximity effects or other mechanisms related to the magnetic contacts themselves. Our findings contribute to the understanding of spin dynamics in graphene and highlight the potential for utilizing graphene-based materials in spintronic applications, particularly at room temperature, where traditional materials may face limitations. This research opens avenues for further exploration into the manipulation and control of spin currents in two-dimensional materials.",
        "ori-fast-z-score": -0.9434563530497265,
        "water-fast-z-score": 4.873672965232998,
        "rewrite-fast-z-score": 0.1841149235796647
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Accretion Disk Illumination in Schwarzschild and Kerr Geometries: Fitting Formulae .\nAbstract:\nWe present fitting formulae for the illumination of accretion disks by hot spots, as seen in Schwarzschild and rotating black holes (Kerr). The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton scattering. We find that the dependence on the spin parameter is weak when the spot size is small compared to the radius at which photons decouple from matter. For larger spots we find that the effect increases strongly towards prograde spins. Our results can be used to estimate the effects of relativistic Doppler boosting and gravitational lensing on observed spectra. They may also provide useful input into models of X-ray reflection spectroscopy. \nIntroduction\n\nAccreting black holes produce bright emission lines in their X-ray spectrum due to reprocessing of hard X-rays emitted near the event horizon by cold material orbiting close to the equatorial plane. These features have been studied extensively over many years both observationally and theoretically (see Reynolds & Nowak 2003 , Done et al 2004 . In particular, they show strong red-shifts indicating that the emitting gas orbits rapidly around the black hole. This rapid rotation causes additional shifts in energy due to relativistic Doppler boosts and gravitational lensing. Relativistic effects become more important if the emitting region has a high degree of rotational support or is viewed nearly face-on. It is therefore necessary to take these effects into account when interpreting observations of such systems. \n\nIn this work we consider the case where the illuminating source is located above the disk surface but below its photosphere. Such sources include magnetic flares produced within the disk itself or active regions associated with the inner edge of the disk. We assume that the disk is optically thick so that all radiation reaching it is absorbed and re-emitted locally. We use Monte Carlo simulations to calculate the emergent flux from the disk under various assumptions about the geometry of the system.\n\nThe main goal of our study was to develop simple analytical expressions describing how the shape of the line profile depends on the properties of the system. To do this we performed extensive numerical calculations covering a wide range",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Accretion Disk Illumination in Schwarzschild and Kerr Geometries : Fitting Formulae . Abstract : We present fitting formulae for the illumination of accretion disks by hot points , as shown in Schwarzschild and rotating black holes ( Kerr ) .The formulae are derived using ray tracing through the disk atmosphere with an approximate treatment of Compton absorption . We see that the dependence on the spin vector is weak when the spot size is tiny compared to the radius at which photons decouple from matter .For larger spots we find that the impact grows heavily towards prograde spins . Our results can be used to estimate the effects of relativistic Doppler boosting and gravity lensing on measured spectra .They might additionally offer useful input into models of X - ray reflection spectroscopy . Introduction Accreting grey holes create bright emission lines in their X - ray spectrum due to reprocessing of hard X - rays generated near the event horizon by cold matter orbiting close to the equatorial plane .These features have been studied frequently over numerous years both observationally and theoretically ( saw Reynolds & Nowak 2003 , Done et al 2004 . In particular , they show intense red - shifts suggesting that the emitting gas orbits rapidly around the dark hole .This rapid rotation creates additional shifts in energy due to relativistic Doppler boosts and gravity lensing . Relativistic effects become more critical if the emitting area has a high degree of rotational support or is viewed virtually face - on .It is consequently required to take these consequences into consideration when interpreting observations of such systems . In this research we imagine the case where the illuminating source is situated above the disk surface but below its photosphere .Such sources include magnetic flares created within the disk itself or active regions associated with the inner boundary of the disk . We assume that the disk is optically dense so that all light reaching it is emitted and re - radiated locally .We use Monte Carlo simulations to estimate the emergent flux from the disk under various assumptions about the topology of the system . The main goal of our research was to develop simple analytical expressions relating how the morphology of the line profile depends on the properties of the system .To do this we performed extensive numerical measurements encompassing a broad range",
        "rewrite_text": "**Title:** Accretion Disk Illumination in Schwarzschild and Kerr Geometries: Fitting Formulae\n\n**Abstract:** In this study, we introduce fitting formulae that describe the illumination of accretion disks by hot point sources in the contexts of Schwarzschild and Kerr black hole geometries. These formulae are derived through ray tracing techniques applied to the disk atmosphere, incorporating an approximate treatment of Compton absorption effects. Our findings indicate that the influence of the black hole's spin vector on illumination is minimal when the size of the illuminating spot is significantly smaller than the radius at which photons decouple from the surrounding matter. However, as the size of the spot increases, we observe a pronounced effect, particularly for prograde spins. The implications of our results extend to the estimation of relativistic Doppler boosting and gravitational lensing effects on observed spectra, which could enhance the understanding of X-ray reflection spectroscopy models.\n\nAccreting black holes generate bright emission lines in their X-ray spectra due to the reprocessing of hard X-rays produced near the event horizon by cold matter in close orbit around the equatorial plane. These spectral features have been extensively studied both observationally and theoretically, as noted in works by Reynolds & Nowak (2003) and Done et al. (2004). The observed intense redshifts of these lines suggest that the emitting gas is in rapid orbit around the black hole, leading to additional energy shifts due to relativistic Doppler effects and gravitational lensing. These relativistic phenomena become increasingly significant when the emitting region exhibits a high degree of rotational support or is viewed nearly face-on, necessitating their consideration in the interpretation of observational data.\n\nIn our research, we explore scenarios where the illuminating source is located above the disk surface yet beneath its photosphere, such as magnetic flares or active regions near the inner boundary of the disk. We assume the disk is optically thick, ensuring that all incoming light is locally emitted and re-radiated. To analyze the emergent flux from the disk under various system configurations, we employ Monte Carlo simulations. Our primary objective is to establish straightforward analytical expressions that relate the morphology of the line profile to the system's characteristics, achieved through comprehensive numerical measurements across a wide range of parameters.",
        "ori-fast-z-score": -0.37796447300922725,
        "water-fast-z-score": 7.53778361444409,
        "rewrite-fast-z-score": 0.07692307692307693
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modelling diffusional transport in the interphase cell nucleus .\nAbstract:\nThe aim of this study is to develop an improved model for simulating diffusion processes within biological cells, especially those occurring at the nuclear membrane and its associated structures.  The proposed approach involves coupling two existing models; one that describes the movement of molecules through the cytoplasm (the fluid part of the cell) using Brownian dynamics simulations, with another which represents the nucleus as a porous medium containing immobile obstacles.  This latter component has been developed by considering the geometry of the nuclear pore complex network, which consists of cylindrical pores connected via narrower channels.   In order to validate our new hybrid model we have performed a series of numerical experiments on synthetic data generated from both individual particle tracking and Monte Carlo methods.  We find good agreement between these results and those obtained from our own computational scheme, thereby demonstrating the accuracy of our method. Finally, we apply our new modelling framework to investigate how changes in the structure of the nuclear pore complexes can affect the rate of molecular exchange across the nuclear envelope.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modelling diffusional flow in the interphase cell nucleus . Abstract : The goal of this study is to develop an better model for simulating diffusion processes within molecular cells , particularly those occurring at the nuclear membrane and its associated structures .The proposed approach requires coupling two existing models ; one that describes the movement of molecules through the cytoplasm ( the liquid part of the cell ) using Brownian dynamics simulations , with another which represents the nucleus as a porous medium containing immobile obstacles . This last component has been constructed by examining the topology of the atomic pore complex network , which consists of circular pores connected via narrower outlets .In order to validate our new hybrid system we have done a sequence of computational experiments on synthetic information generated from both individual beam monitoring and Monte Carlo methods . We get good agreement between these results and those acquired from our own computational scheme , thereby showing the accuracy of our technique .Finally , we apply our new modelling methodology to examine how variations in the structure of the atomic pore complexes can affect the frequency of molecular transfer across the atomic envelope .",
        "rewrite_text": "**Title:** Modeling Diffusional Flow in the Interphase Cell Nucleus\n\n**Abstract:** This study aims to enhance the modeling of diffusion processes within molecular cells, with a specific focus on the dynamics occurring at the nuclear membrane and its associated structures. To achieve this, we propose a novel approach that integrates two established models: one that utilizes Brownian dynamics simulations to describe the movement of molecules through the cytoplasm—the liquid component of the cell—and another that conceptualizes the nucleus as a porous medium filled with immobile obstacles. The latter model is developed through a detailed analysis of the topology of the atomic pore complex network, which is characterized by circular pores interconnected by narrower channels. \n\nTo validate our hybrid modeling system, we conducted a series of computational experiments utilizing synthetic data generated from both individual beam monitoring and Monte Carlo methods. The results obtained from these experiments demonstrate a strong correlation with those derived from our computational framework, confirming the accuracy and reliability of our proposed technique. \n\nFurthermore, we apply our innovative modeling methodology to investigate how variations in the structural configuration of atomic pore complexes influence the frequency of molecular transfer across the nuclear envelope. This exploration not only sheds light on the fundamental mechanisms governing molecular diffusion in the nucleus but also provides insights that could be pivotal for understanding cellular processes and the implications of nuclear architecture on molecular transport. Our findings contribute to the broader field of cellular biophysics by offering a refined tool for simulating and analyzing the complex interactions that occur within the interphase cell nucleus.",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 6.0,
        "rewrite-fast-z-score": 0.7016464154456235
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Wavelet transforms in a critical interface model for Barkhausen noise .\nAbstract:\nWe study the statistical properties of Barkhausen noise generated by an Ising spin system with random fields and competing interactions at its surface, using wavelets to analyze the time series produced by this model.  We find that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space. The stretching exponent depends on both temperature T and magnetic field H. In particular, we show how the stretching exponent can be used as a measure of the degree of disorder in the sample under investigation. Finally, we discuss possible extensions of our work to other types of systems exhibiting avalanche dynamics. Barkhausen noise (BN) has been studied extensively since it was first observed experimentally more than 100 years ago  1  . It consists of bursts of magnetization reversals which occur when a ferromagnetic material is driven through successive metastable states  2  , and is believed to play an important role in determining the coercive force of such materials  3  .\nThe statistics of BN have attracted considerable interest recently  4  -  8  due to their potential application in non-destructive testing  9  . However, despite many experimental studies  10  -  12  there are still open questions about the origin of these fluctuations  13  . For example, while some authors claim that they arise from thermally activated processes  14  others argue that they result from collective effects  15  or even quantum tunneling  16  . A number of theoretical models  17  -  20  have also been proposed to explain the physics behind BN but none of them seems able to reproduce all features simultaneously  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Wavelet transforms in a critical interface description for Barkhausen noise . Abstract : We research the statistical characteristics of Barkhausen noise caused by an Ising spin body with random fields and competing interactions at its surface , using wavelets to analyze the time series formed by this model .We see that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space . The bending exponent relies on both heat T and magnetic force H . In particular , we find how the stretching exponent can be used as a measure of the degree of disorder in the sample under research .Finally , we explain possible extensions of our work to other types of networks displaying avalanche dynamics . Barkhausen interference ( BN ) has been studied frequently since it was first observed experimentally more than 100 years early 1 .It consists of bursts of magnetization reversals which occur when a ferromagnetic material is accelerated through consecutive metastable states 2 , and is suspected to take an important role in calculating the coercive force of such substances 3 . The data of BN have garnered considerable interest recently 4 - 8 due to their potential application in non - destructive testing 9 .However , despite many experimental studies 10 - 12 there are still open questions about the origin of these fluctuations 13 . For instance , while some writers claim that they occur from thermally activated processes 14 others argue that they occur from collective effects 15 or even quantum tunneling 16 .A many of theoretical theories 17 - 20 have already been proposed to explain the physics behind BN but none of them appears able to capture all characteristics simultaneously 21 .",
        "rewrite_text": "**Title: Wavelet Transforms in the Description of Critical Interfaces for Barkhausen Noise**\n\n**Abstract:** This study investigates the statistical properties of Barkhausen noise generated by an Ising spin system subjected to random fields and competing surface interactions, employing wavelet analysis to interpret the resulting time series data. Our findings reveal that the power spectrum of the Barkhausen signal can be effectively modeled by a stretched exponential function across multiple frequency decades. Notably, the bending exponent is influenced by both temperature (T) and magnetic field strength (H). We demonstrate that the stretching exponent serves as a quantifiable indicator of disorder within the sample being examined. Furthermore, we discuss potential applications of our methodology to other systems exhibiting avalanche dynamics. Barkhausen noise (BN) has been a subject of extensive research since its initial experimental observation over a century ago. It manifests as discrete bursts of magnetization reversals occurring when a ferromagnetic material transitions through a series of metastable states, and it is believed to play a crucial role in determining the coercive force of such materials. Recent interest in BN data has surged due to its promising applications in non-destructive testing. Despite numerous experimental investigations, significant questions remain regarding the underlying mechanisms of these fluctuations. Some researchers attribute these phenomena to thermally activated processes, while others suggest they arise from collective effects or even quantum tunneling. Various theoretical frameworks have been proposed to elucidate the physics of BN; however, none have successfully accounted for all observed characteristics simultaneously. This paper aims to contribute to the ongoing discourse by providing insights into the complex interplay of factors influencing Barkhausen noise and suggesting avenues for future research in this area.",
        "ori-fast-z-score": -0.6163156344279367,
        "water-fast-z-score": 6.44087327036082,
        "rewrite-fast-z-score": 0.43685202833051895
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Radio Astrometric Detection and Characterization of Extra-Solar Planets: A White Paper Submitted to the NSF ExoPlanet Task Force .\nAbstract:\nThe National Science Foundation (NSF) has recently formed an  Exoplanet Task Force  with the goal of identifying key science goals for future space missions in exoplanet research, including radio astrometry.  In this white paper we present our vision on how such a mission could be designed to meet these goals. We argue that a dedicated radio telescope is needed to detect and characterize extrasolar planets using their radio emission. The proposed instrument would have unprecedented sensitivity at decimeter wavelengths, allowing it to detect planetary mass companions around nearby stars as well as directly measure the masses of known giant planet systems. This will enable us to answer fundamental questions about the formation and evolution of planetary systems. Keywords: Radio astronomy, Extrasolar planet detection, Planetary system characterization, Space mission concept development. 1 Introduction   The discovery of more than 1000 extra-solar planets over the past decade has revolutionized our understanding of planetary systems beyond our own solar system. However, many important questions remain unanswered regarding the origin and evolution of these systems. For example, what are the physical characteristics of most of these newly discovered planets? How do they form? What happens when two or more planets interact gravitationally? Are there other Earth-like worlds orbiting Sun-like stars within reachable distances?  Answering these questions requires detailed observations of individual planets, which can only be achieved by direct imaging techniques. Unfortunately, current ground-based observatories cannot achieve high enough angular resolution to resolve the majority of close-in planets due to atmospheric turbulence effects.   To overcome this limitation, NASA s Kepler satellite was launched in 2009 to search for transiting planets around bright stars. Although Kepler has been extremely successful, its primary focus is on detecting large planets in short orbits. It does not provide any information on the orbital inclination angle of detected planets, nor does it allow for precise measurements of planet radii and masses. Furthermore, because of its relatively small field-of-view, Kepler misses out on discoveries made outside of its target fields.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Radio Astrometric Detection and Characterization of Extra - Solar Planets : A White Paper Submitted to the NSF ExoPlanet Task Force . Abstract : The National Science Foundation ( NSF ) has recently established an Exoplanet Task Force with the objective of identifying key research goals for future space missions in exoplanet research , notably television astrometry .In this white paper we present our vision on how such a project possible be designed to meet these objectives . We argue that a dedicated radio telescope is required to identify and characterize extrasolar planets using their radio emission .The proposed instrument would have enormous sensitivity at decimeter wavelengths , allowing it to identify planetary mass companions around nearby planets as also as closely determine the masses of known giant planet systems . This will assist us to ask critical debates about the formation and evolution of planetary networks .Keywords : Radio astronomy , Extrasolar moon recognition , Planetary network characterization , Space mission design development . 1 Introduction The observation of more than 1000 extra - solar planets over the previous decade has revolutionized our understanding of planetary structures beyond our own solar system .However , various many issues appear unanswered concerning the origin and evolution of these systems . For instance , what are the natural characteristics of most of these newly discovered planets ?How do they shape ? What happens when two or more planets interact gravitationally ?Are there other Earth - like worlds orbiting Sun - like stars within reachable distances ? Answering these problems involves detailed observations of individual planets , which can only be obtained by direct observation techniques .Unfortunately , current ground - based observatories cannot achieve high enough angular resolution to identify the majority of close - in planets owing to atmospheric turbulence influences . To solve this limitation , NASA s Kepler satellite was launched in 2009 to search for transiting planets around bright stars .Although Kepler has been extremely successful , its primary emphasis is on detecting large planets in small planets . It does not offer any knowledge on the orbital inclination ratio of detected planets , nor does it enable for precise observations of planet radii and masses .Furthermore , because of its relatively small field - of - view , Kepler misses out on discoveries made outside of its target areas .",
        "rewrite_text": "**Title:** Radio Astrometric Detection and Characterization of Extra-Solar Planets: A White Paper Submitted to the NSF ExoPlanet Task Force\n\n**Abstract:** The National Science Foundation (NSF) has recently initiated an Exoplanet Task Force aimed at establishing pivotal research objectives for upcoming space missions focused on exoplanet studies, particularly in the realm of television astrometry. In this white paper, we outline our vision for designing a project that aligns with these goals. We contend that a specialized radio telescope is essential for the identification and characterization of extrasolar planets through their radio emissions. The proposed instrument would possess exceptional sensitivity at decimeter wavelengths, enabling the detection of planetary mass companions around nearby stars and facilitating precise measurements of the masses of known giant planet systems. This capability will significantly enhance our ability to engage in critical discussions regarding the formation and evolution of planetary systems.\n\nThe past decade has seen the discovery of over 1,000 extrasolar planets, fundamentally transforming our understanding of planetary systems beyond our own. However, numerous questions remain unresolved concerning the origins and developmental pathways of these celestial bodies. Key inquiries include the intrinsic characteristics of these newly identified planets, their formation processes, the gravitational interactions that may occur between multiple planets, and the potential existence of Earth-like worlds orbiting Sun-like stars within accessible distances. Addressing these questions necessitates detailed observations of individual planets, which can only be achieved through direct observational techniques. Unfortunately, current ground-based observatories are limited by atmospheric turbulence, preventing them from attaining the high angular resolution required to identify many close-in planets.\n\nTo overcome this challenge, NASA's Kepler satellite was launched in 2009 with the mission of detecting transiting planets around bright stars. While Kepler has achieved remarkable success, its primary focus has been on identifying larger planets in close proximity to their stars. Consequently, it does not provide insights into the orbital inclinations of detected planets, nor does it allow for accurate measurements of planetary radii and masses. Additionally, due to its limited field of view, Kepler overlooks potential discoveries beyond its designated target areas. \n\n**Keywords:** Radio astronomy, extrasolar planet detection, planetary system characterization, space mission design.",
        "ori-fast-z-score": 0.15249857033260467,
        "water-fast-z-score": 7.892283294029704,
        "rewrite-fast-z-score": -1.6678156958735875
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multicriticality of the (2+1)-dimensional gonihedric model: A realization of the (d,m)=(3,2) Lifshitz point .\nAbstract:\nWe study the multicritical behavior in the two-dimensional gonihedric model with nearest-neighbor interactions on an anisotropic triangular lattice. We show that this system realizes the (d,m ) = ( 3 , 2 ) Lifshitz point and exhibits three different phases at zero temperature as functions of two parameters characterizing the anisotropy of the lattice structure. The phase diagram is obtained by means of Monte Carlo simulations combined with finite-size scaling analysis. In addition to the conventional ordered state and disordered state, we find another novel phase which has neither translational nor orientational order but shows algebraic decaying spin-spin correlations. This new phase can be regarded as a kind of spin-liquid-like state. Our results are also compared with those for other models such as the Ashkin-Teller model and the Blume-Capel model. \nI n t r o d u c t i o n :\nThe concept of Lifshitz points was originally introduced into condensed matter physics more than half a century ago  1  . It describes a critical point where several distinct phases meet each other simultaneously  2  . Recently, it attracted renewed interest because of its possible relevance to high-temperature superconductivity  3  .\nIn particular, the so-called (d, m) = (3, 2) Lifshitz point  4  , where d denotes spatial dimension and m represents number of components of order parameter fields, has been studied extensively both theoretically  5  -  8  and experimentally  9  -  11  . However, most studies have focused only on systems with short-range interactions  12  or purely magnetic systems  13  -  16  . On the other hand, there exist few theoretical investigations  17  -  20  concerning the effects of longer-ranged interactions  21  and/or competing orders  22  on the Lifshitz point.\nIn this Letter, we investigate the multicritical behavior of the two-dimensional gonihedrickson-Lee (GL) model  23  with nearestneighbor interactions on an anisotopic triangular lattice  see Fig.  1  . Although the GL model itself does not exhibit any ordering transition  24  , our previous work  25  showed that the introduction of anisotropy leads to",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multicriticality of the ( 2 + 1 ) - dimensional gonihedric model : A realization of the ( d , m ) = ( 3 , 2 ) Lifshitz point . Abstract : We explore the multicritical behavior in the two - dimensional gonihedric model with nearest - neighbor interactions on an anisotropic triangular lattice .We see that this scheme assumes the ( d , m ) = ( 3 , 2 ) Lifshitz point and exhibits three different stages at zero temperature as functions of two parameters characterizing the anisotropy of the lattice structure . The phase diagram is achieved by means of Monte Carlo simulations combined with discrete - length scaling processing .In addition to the usual ordered state and disordered state , we find another novel phase which has neither translational nor orientational order but exhibits algebraic decaying spin - spinning correlations . This new phase can be regarded as a kind of spin - fluid - like state .Our results are also compared with those for other models such as the Ashkin - Teller model and the Blume - Capel theory . I n t r o d v c t i o n : The concept of Lifshitz points was originally adopted into condensed matter science more than half a millennium later 1 .It depicts a critical position where many unique stages encounter each other simultaneously 2 . Recently , it garnered renewed popularity because of its potential significance to large - temperature superconductivity 3 .In particular , the so - called ( d , m ) = ( 3 , 2 ) Lifshitz point 4 , where d indicates temporal dimension and m means number of components of order parameter fields , has been studied thoroughly both theoretically 5 - 8 and experimentally 9 - 11 . However , most studies have concentrated only on systems with short - range coupling 12 or purely magnetic systems 13 - 16 .On the other hand , there remain few theoretical investigations 17 - 20 concerning the effects of extended - ranged interactions 21 and / or competing orders 22 on the Lifshitz point . In this Letter , we investigate the multicritical behavior of the two - dimensional gonihedrickson - Lee ( GL ) model 23 with nearestneighbor interactions on an anisotopic triangular lattice seeing Fig .1 . Although the GL model itself does not show any ordering transition 24 , our previous research 25 showed that the introduction of anisotropy leads to",
        "rewrite_text": "**Title:** Multicriticality of the (2 + 1)-Dimensional Gonihedric Model: A Realization of the (d, m) = (3, 2) Lifshitz Point\n\n**Abstract:** This study investigates the multicritical behavior of the two-dimensional gonihedric model, characterized by nearest-neighbor interactions on an anisotropic triangular lattice. We demonstrate that this model corresponds to the (d, m) = (3, 2) Lifshitz point, revealing three distinct phases at zero temperature, which depend on two parameters that define the anisotropy of the lattice. The phase diagram is constructed using Monte Carlo simulations coupled with discrete-length scaling techniques. In addition to the conventional ordered and disordered states, we identify a novel phase that lacks both translational and orientational order, yet displays algebraically decaying spin-spin correlations. This newly discovered phase can be interpreted as a spin-fluid-like state. Our findings are compared with those from other theoretical frameworks, including the Ashkin-Teller model and the Blume-Capel theory.\n\nThe concept of Lifshitz points, which emerged in condensed matter physics over five centuries ago, describes critical conditions where multiple unique phases converge. Recently, interest in Lifshitz points has surged due to their potential implications for high-temperature superconductivity. Specifically, the (d, m) = (3, 2) Lifshitz point, where 'd' represents the temporal dimension and 'm' denotes the number of components of the order parameter fields, has been extensively studied both theoretically and experimentally. However, prior research has predominantly focused on systems exhibiting short-range interactions or purely magnetic characteristics. In contrast, there is a notable scarcity of theoretical analyses addressing the impact of long-range interactions and competing orders on the Lifshitz point. In this letter, we delve into the multicritical behavior of the gonihedric model, revealing how the introduction of anisotropy alters the system's behavior, despite the model itself not exhibiting any ordering transitions in its unmodified form.",
        "ori-fast-z-score": 0.24576957615571215,
        "water-fast-z-score": 6.144239403892804,
        "rewrite-fast-z-score": 0.7986208584745025
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Capacity of a Multiple-Antenna Fading Channel with a Quantized Precoding Matrix .\nAbstract:\nWe consider the capacity region of a multiple-input-multiple-output (MIMO) fading channel in which each transmitter has perfect knowledge of its own instantaneous channel state information and uses a quantized precoding matrix to maximize mutual information between itself and the receiver. We show that, for any given number of transmit antennas at all transmitters, there exists an optimal number of receive antennas such that the sum-capacity is maximized when all receivers have this same number of antennas. This result holds even if the channels are correlated across time or frequency. The optimal number of receive anten-nas increases as more transmit antennas are used by the transmitters. For example, we find that using four transmit antennas results in the highest sum-rate when three receive antennas are employed per user; however, five receive antennas should be used instead if eight transmit antennas are available.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Capacity of a Multiple - Antenna Fading Channel with a Quantized Precoding Matrix . Abstract : We consider the power region of a multiple - input - multiple - output ( MIMO ) fading signal in which each antenna has good knowledge of its own instantaneous channel state information and using a quantized precoding vector to maximize mutual information between itself and the receiver .We see that , for any given number of transmit antennas at all transmitters , there exists an appropriate number of receive antennas such that the sum - bandwidth is maximized when all receivers have this same amount of antennas . This result holds even if the channels are correlated across time or bandwidth .The appropriate number of receive anten - nas increases as more transmit antennas are using by the transmitters . For instance , we find that using four transmit antennas results in the highest sum - speed when three receive antennas are employed per user ; however , five send antennas should be used instead if eight send antennas are available .",
        "rewrite_text": "In this study, we investigate the power region of a multiple-input multiple-output (MIMO) fading channel, where each transmitting antenna possesses accurate instantaneous channel state information. The focus is on employing a quantized precoding vector to optimize the mutual information between the transmitter and the receiver. Our findings reveal that for any specified number of transmit antennas across all transmitters, there exists an optimal number of receive antennas that maximizes the overall bandwidth when all receivers are equipped with this same quantity. Notably, this conclusion remains valid even in scenarios where the channels exhibit correlation over time or frequency. \n\nAs the number of transmit antennas increases, the optimal number of receive antennas also rises. For example, our analysis indicates that utilizing four transmit antennas achieves the highest sum-rate when paired with three receive antennas per user. Conversely, if eight transmit antennas are available, the optimal configuration shifts to employing five transmit antennas. This research contributes to the understanding of MIMO systems in fading environments, highlighting the significance of antenna configuration in enhancing communication performance. The implications of these findings are crucial for the design of future wireless communication systems, particularly in optimizing antenna arrangements to achieve maximum data throughput.",
        "ori-fast-z-score": -1.0834726777719228,
        "water-fast-z-score": 3.8247315498700596,
        "rewrite-fast-z-score": -0.6965260331469925
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Sample eigenvalue based detection of high dimensional signals in white noise using relatively few samples .\nAbstract:\nWe consider the problem of detecting an unknown signal vector with a known covariance matrix, embedded in additive white Gaussian noise (AWGN). We propose to use sample eigenvalues as test statistics for this problem and derive their distributions under both hypotheses. The proposed method is shown to be robust against small perturbations on the covariance matrices. It also has low computational complexity compared to other existing methods. Finally we present simulation results that demonstrate its performance advantage over competing algorithms. In many applications such as radar systems or wireless communications, it is often desirable to detect whether there exists any signal component within noisy measurements. This problem can be formulated mathematically as: \nwhere x ∈ R N , s ∈ R M are respectively the signal and noise vectors; A ∈ R L×N denotes the sensing matrix which maps the signal space into the measurement space; y = Ax + n represents the observation vector where n ∼ N(0, σ 2 I) is AWGN. Herein, we assume that the number of observations L is much smaller than either N or M .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Sample eigenvalue based measurement of high dimensional signals in white sound using relatively few samples . Abstract : We consider the question of detecting an unknown signal vector with a known covariance matrix , embedded in additive white Gaussian sound ( AWGN ) .We suggest to use sample eigenvalues as test estimates for this question and derive their distributions under both hypotheses . The proposed approach is demonstrated to be robust against small perturbations on the covariance matrices .It additionally has low numerical capacity compared to other existing techniques . Finally we present modeling results that demonstrate its performance benefit over competing techniques .In many applications such as radar systems or wireless communications , it is often desirable to identify whether there exists any signal component within noisy measurements . This problem can be formulated mathematically as : where h ∈ R N , s ∈ R M are respectively the signal and noise vectors ; A ∈ R L×N denotes the sensing matrix which maps the signal space into the measurement space ; y = Ax + n represents the observation vector where n [UNK] N ( 0 , σ 2 I ) is AWGN .Herein , we suppose that the proportion of measurements L is much smaller than either N or M .",
        "rewrite_text": "Title: Sample Eigenvalue-Based Measurement of High-Dimensional Signals in White Noise Using Relatively Few Samples\n\nAbstract: This article addresses the challenge of detecting an unknown signal vector that is characterized by a known covariance matrix, which is embedded within additive white Gaussian noise (AWGN). We propose a novel method that utilizes sample eigenvalues as test statistics to tackle this detection problem. By deriving the distributions of these sample eigenvalues under both the null and alternative hypotheses, we establish a statistical framework for signal detection. Our approach demonstrates robustness to minor perturbations in the covariance matrices, making it particularly advantageous in practical scenarios where such variations may occur. Furthermore, our method exhibits lower computational complexity compared to existing techniques, which is a significant benefit in high-dimensional signal processing applications. \n\nWe present modeling results that highlight the performance advantages of our proposed method over competing approaches. In numerous applications, including radar systems and wireless communications, it is crucial to ascertain the presence of signal components amidst noisy measurements. The mathematical formulation of this detection problem involves vectors h ∈ R^N and s ∈ R^M representing the signal and noise, respectively, while A ∈ R^(L×N) serves as the sensing matrix that maps the signal space into the measurement space. The observation vector is expressed as y = Ax + n, where n follows a Gaussian distribution N(0, σ^2 I), representing the AWGN. Notably, we assume that the number of measurements L is significantly smaller than both N and M, which is a common scenario in high-dimensional signal processing. Our findings indicate that the proposed sample eigenvalue-based method not only enhances detection capabilities but also maintains efficiency, making it a valuable tool for practitioners in the field.",
        "ori-fast-z-score": 1.0101525445522108,
        "water-fast-z-score": 5.728715546977509,
        "rewrite-fast-z-score": 0.34050261230349943
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Guiding-fields for phase-separation: Controlling Liesegang patterns .\nAbstract:\nWe study the formation and control of Liesegang patterns in an electrochemical system by applying external electric fields to modulate the local concentration gradients during precipitation reactions.  We show that, under certain conditions, the applied field can be used as a guiding field to direct the growth of precipitate bands along specific directions. The results are explained using a simple model based on the competition between diffusion and reaction rates at different locations within the sample. This work provides new insights into how chemical systems may self-organize through interactions with their environment. Chemical systems often exhibit complex spatial structures such as stripes or rings which form spontaneously without any externally imposed symmetry breaking  1  . These structures have been observed in many natural phenomena including mineral deposits  2  , biological tissues  3  , and even living organisms  4  .\nThe most famous example is the so-called  Liesegang ring  formed when two solutions containing metal ions react chemically  5  . In this case, the initial solution contains both cations (e.g., Ag+) and anions (e.g., Cl-). When these two solutions come into contact, they begin to diffuse across each other until they meet another interface where the opposite charges neutralize one another  6  . At some point after mixing, precipitation occurs leading to the formation of a band of solid material separating the original solutions  7, 8  . As more bands grow, they eventually overlap forming concentric rings around the center of the sample  9  . Although the exact mechanism behind the formation of Liesegang rings remains unclear  10  , it has been shown experimentally that the spacing between successive rings depends strongly on the concentrations of the starting solutions  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Guiding - fields for phase - separation : Controlling Liesegang patterns . Abstract : We research the formation and control of Liesegang patterns in an electrochemical system by using external electric fields to modulate the local concentration gradients during precipitation reactions .We see that , under certain conditions , the applied field can be used as a guiding field to direct the development of precipitate bands along particular directions . The results are explained using a simple model focused on the competition between diffusion and reaction rates at different places within the sample .This research provides new understanding into how chemical structures could self - organize through relationships with their environment . Chemical systems often exhibit intricate visual formations such as stripes or rings which create spontaneously without any externally imposed symmetry breaking 1 .These structures have been observed in different biological phenomena including mineral minerals 2 , biological tissues 3 , and even living organisms 4 . The most famous example is the so - called Liesegang ring formed when two solutions containing metal ions react chemically 5 .In this instance , the first solution comprises both cations ( e . g . , Ag + ) and anions ( e . g . , Cl - ) . When these two solutions come into contact , they start to diffuse across each other until they meet another interface where the opposite charges neutralize one another 6 .At some time after mixing , precipitation occurs leading to the formation of a band of solid material separating the original solutions 7 , 8 . As more bands expand , they eventually overlap becoming concentric rings around the center of the sample 9 .Although the exact mechanism behind the formation of Liesegang rings appears unclear 10 , it has been shown experimentally that the spacing between successive rings depends strongly on the levels of the starting solutions 11 .",
        "rewrite_text": "Title: Guiding Fields for Phase Separation: Controlling Liesegang Patterns\n\nAbstract: This study investigates the formation and manipulation of Liesegang patterns within an electrochemical system by employing external electric fields to influence local concentration gradients during precipitation reactions. Our findings reveal that, under specific conditions, the application of an electric field can serve as a guiding mechanism, directing the arrangement of precipitate bands along designated pathways. We elucidate these results through a simplified model that emphasizes the interplay between diffusion and reaction rates at various locations within the sample. This research enhances our understanding of how chemical structures can self-organize in response to their environmental conditions. \n\nChemical systems frequently display complex visual patterns, such as stripes or rings, that emerge spontaneously without any externally imposed symmetry breaking. These phenomena have been observed across a range of biological contexts, including mineral formations, biological tissues, and even within living organisms. A prominent example of this is the Liesegang ring, which forms when two solutions containing metal ions undergo a chemical reaction. In this scenario, one solution contains both cations (e.g., Ag+) and anions (e.g., Cl-). Upon contact, these solutions begin to diffuse into one another until they reach an interface where the opposing charges neutralize. Following this mixing, precipitation occurs, resulting in the creation of a solid band that separates the original solutions. As additional bands form and expand, they ultimately overlap, creating concentric rings around the center of the sample. \n\nWhile the precise mechanism underlying the formation of Liesegang rings remains somewhat elusive, experimental evidence indicates that the spacing between successive rings is significantly influenced by the concentrations of the initial solutions. This research not only sheds light on the dynamics of Liesegang patterns but also opens avenues for further exploration into the self-organization of chemical systems in response to external stimuli.",
        "ori-fast-z-score": 2.482817665807104,
        "water-fast-z-score": 7.175639059928206,
        "rewrite-fast-z-score": 1.784435632438388
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A model for the Globular Cluster extreme anomalies .\nAbstract:\nWe present an explanation to the observed anomalies in globular cluster luminosity functions (GCLFs) and mass-to-light ratios, based on the assumption that these clusters are composed by two different populations with distinct chemical compositions.  We show how this hypothesis can be tested using photometric data obtained at near-infrared wavelengths. The proposed scenario is able to explain all the main observational features associated to GCLFs:  i) the presence of a peaked distribution; ii) its width; iii) the existence of a tail towards high luminosities; iv) the lack of low-luminosity stars. In addition, it also explains why some GCs have very large values of M/LV . Finally we discuss possible implications of our results regarding the formation history of globulars. Keywords: Globular cluster, Mass-to-light ratio, Luminosity function, Chemical composition, Near-infrared",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A description for the Globular Cluster extreme anomalies . Abstract : We present an explanation to the observed anomalies in globular cluster luminosity functions ( GCLFs ) and mass - to - light proportions , relying on the assumption that these clusters are composed by two different populations with distinct chemical compositions .We see how this hypothesis can be evaluated using photometric data acquired at near - infrared wavelengths . The proposed scenario is could to explain all the main observational characteristics attributed to GCLFs : i ) the presence of a peaked distribution ; ii ) its height ; iii ) the existence of a tail towards high luminosities ; iv ) the lack of high - luminosity stars .In addition , it also explains why some GCs have very huge values of M / LV . Finally we talk possible implications of our findings regarding the formation history of globulars .Keywords : Globular cluster , Mass - to - light ratio , Luminosity function , Chemical composition , Near - infrared",
        "rewrite_text": "Title: A Description of the Extreme Anomalies in Globular Clusters\n\nAbstract: In this study, we provide a comprehensive explanation for the peculiar anomalies observed in the luminosity functions of globular clusters (GCLFs) and their mass-to-light ratios. Our analysis is grounded in the hypothesis that these clusters are comprised of two distinct populations, each exhibiting unique chemical compositions. We demonstrate how this hypothesis can be rigorously tested using photometric data obtained in the near-infrared spectrum. The proposed model effectively accounts for several key observational features associated with GCLFs, including: (i) the presence of a peaked luminosity distribution; (ii) the overall height of this distribution; (iii) the observed tail extending towards high luminosities; and (iv) the scarcity of high-luminosity stars within these clusters. Furthermore, our findings elucidate the reasons behind the exceptionally high mass-to-light ratios (M/L) observed in certain globular clusters. We also discuss the broader implications of our results for understanding the formation and evolutionary history of globular clusters. This research not only enhances our comprehension of the structural and compositional diversity within globular clusters but also contributes to the ongoing discourse regarding their origins and the processes that govern their development over cosmic time. \n\nKeywords: Globular clusters, Mass-to-light ratio, Luminosity function, Chemical composition, Near-infrared.",
        "ori-fast-z-score": -0.3611575592573076,
        "water-fast-z-score": 3.3466401061363023,
        "rewrite-fast-z-score": -0.20412414523193154
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Deconstructing dwarf galaxies: a Suprime-Cam survey of Andromeda II .\nAbstract:\nWe present the results of an optical imaging survey with Subaru/Suprime-Cam of the nearby galaxy group centered on M31, including its brightest satellite galaxy, Andromeda II (M32). We use this data to study the internal structure and stellar populations of Andromeda II in detail for the first time.  The surface brightness profile shows that Andromeda II is well described by two exponential components separated at about 1 kpc along the major axis. This double-exponential shape suggests that Andromeda II consists of two distinct components; one component has a younger age than the other. Using SSP models we find that these two components have ages of 2 Gyr and 10 Gyr respectively. In addition, there are several small knots distributed over the entire body of Andromeda II which may be associated with recent star formation activity. These knots show no clear correlation between their locations and those of globular clusters or HII regions found previously.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Deconstructing dwarf stars : a Suprime - Cam study of Andromeda II . Abstract : We report the results of an optical optical survey with Subaru / Suprime - Cam of the nearby galaxy class centered on M31 , notably its brightest satellite galaxy , Andromeda II ( M32 ) .We use this data to study the internal structure and stellar environments of Andromeda II in detail for the first time . The exterior brightness profile reveals that Andromeda II is well described by two exponential parts joined at about 1 kpc along the main axis .This double - exponential shape suggests that Andromeda II contains of two separate phases ; one part has a younger old than the other . Using SSP models we find that these two parts have ages of 2 Gyr and 10 Gyr respectively .In addition , there are several small knots scattered over the entire body of Andromeda II which may be correlated with recent star formation activity . These knots show no clear correlation between their settings and those of globular complexes or HII centers found prior .",
        "rewrite_text": "We present the findings of an optical survey conducted with the Subaru/Suprime-Cam, focusing on the nearby galaxy class centered around M31, particularly its most luminous satellite galaxy, Andromeda II (M32). This study marks the first detailed examination of the internal structure and stellar environments of Andromeda II. Our analysis of the external brightness profile indicates that Andromeda II can be effectively characterized by a double-exponential function, with a transition occurring at approximately 1 kpc along its principal axis. This distinct double-exponential morphology implies the existence of two separate stellar phases within Andromeda II, each exhibiting different ages. Through the application of Single Stellar Population (SSP) models, we determine that these two components have ages of approximately 2 billion years and 10 billion years, respectively. Furthermore, our observations reveal several small knots distributed throughout Andromeda II, which may be indicative of recent star formation activity. Notably, these knots do not exhibit a clear relationship with previously identified globular clusters or HII regions, suggesting that the recent star formation processes in Andromeda II may be independent of these established structures. This research enhances our understanding of the evolutionary history and stellar dynamics of Andromeda II, providing valuable insights into the complex formation and development of dwarf galaxies in the vicinity of larger galactic structures.",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 5.444444444444445,
        "rewrite-fast-z-score": 0.4926646390821466
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Structure of the stationary state of the asymmetric target process .\nAbstract:\nWe study the structure of the stationary distribution for an asymmetric version of the Target Process (TP). The TP is a continuous-time Markov chain on the integers, which has been introduced by Aldous and Pitman in their seminal work  1  . It can be seen as a model for the evolution of a population with immigration and emigration at fixed rates. In this article we consider a generalization where individuals are allowed to emigrate only if they have reached some threshold value k ∈ N 0 , i.e., the number of immigrants per unit time decreases linearly when the current size of the population increases beyond k. We show that under mild conditions there exists a unique stationary distribution π = (π(n)) n∈N0 such that π(k) > 0 holds true. Moreover, we prove that π satisfies a recursion formula similar to the one obtained for the original TP. Finally, we provide explicit expressions for π(1), ..., π(k+1).\nKeywords: Asymmetric target process, Stationary distribution",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Structure of the stationary state of the asymmetric target process . Abstract : We research the structure of the stationary distribution for an asymmetric version of the Target Process ( TP ) .The TP is a continuous - time Markov chain on the integers , which has been proposed by Aldous and Pitman in their seminal book 1 . It can be viewed as a theory for the evolution of a population with immigration and emigration at fixed rates .In this article we define a generalization where persons are allowed to emigrate only if they have achieved some threshold quantity k ∈ N 0 , i . e . , the proportion of refugees per unit time decreases linearly when the present size of the population rises beyond k . We see that under mild conditions there exists a unique stationary function π = ( π ( p ) ) n∈N0 such that π ( k ) > 0 holds true . Moreover , we prove that π satisfies a recursion formula related to the one given for the previous TP .Finally , we provide explicit expressions for π ( 1 ) , . . . , π ( k + 1 ) . Keywords : Asymmetric target process , Stationary distribution",
        "rewrite_text": "In this study, we investigate the characteristics of the stationary distribution associated with an asymmetric variant of the Target Process (TP). Originally introduced by Aldous and Pitman in their influential work, the TP is a continuous-time Markov chain defined over the integers, serving as a framework for understanding population dynamics influenced by immigration and emigration at constant rates. Our research extends this model by incorporating a threshold mechanism, whereby individuals can only emigrate upon reaching a specified quantity \\( k \\in \\mathbb{N}_0 \\). This modification results in a linear decrease in the rate of emigration as the population size surpasses the threshold \\( k \\). \n\nWe demonstrate that, under certain mild conditions, there exists a unique stationary distribution function \\( \\pi = (\\pi(p))_{n \\in \\mathbb{N}_0} \\) that satisfies \\( \\pi(k) > 0 \\). Furthermore, we establish that this stationary distribution adheres to a recursive relationship akin to that of the original TP. Our findings culminate in the derivation of explicit expressions for the values of \\( \\pi(1), \\ldots, \\pi(k + 1) \\), thereby providing a comprehensive understanding of the stationary state of this asymmetric target process. This research contributes to the broader field of stochastic processes and offers insights into population dynamics under asymmetric conditions, highlighting the implications of threshold-based emigration on the stationary distribution. \n\nKeywords: Asymmetric target process, Stationary distribution.",
        "ori-fast-z-score": -1.0392304845413263,
        "water-fast-z-score": 3.5795716689756794,
        "rewrite-fast-z-score": 0.502518907629606
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gamma-Rays Produced in Cosmic-Ray Interactions and the TeV-band Spectrum of RX J1713.7-3946 .\nAbstract:\nWe present new results on gamma-ray emission produced by cosmic rays interacting with interstellar gas, based on observations made with the HESS telescope array between 2004 and 2007. We report an improved measurement of the spectrum of the brightest source detected at TeV energies, RX J1713.7--3946 (HESS J1714-385), which is well described by a power law with index = 2.28 ± 0.04 stat ± 0.1 sys . The integral flux above 1 TeV amounts to (2.6 +/- 0.4) x 10-12 cm-2 s-1 , corresponding to about 10% of the total Galactic diffuse emission observed at these energies. This result confirms that this object is indeed a supernova remnant as suggested previously. \n \n In addition we have discovered two new sources within the field-of-view of our instrumentation. One of them has been identified with the shell-type supernova remnant G349.7+0.2 while another one remains unidentified.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Gamma - Rays Produced in Cosmic - Ray Interactions and the TeV - band Spectrum of RX J1713 . 7 - 3946 . Abstract : We report new data on gamma - ray radiation created by cosmic rays interacting with interstellar gas , based on observations made with the HESS telescope array between 2004 and 2007 .We report an better study of the spectrum of the brightest source detected at TeV energies , RX J1713 . 7 - - 3946 ( HESS J1714 - 385 ) , which is well described by a power law with index = 2 . 28 ± 0 . 04 stat ± 0 . 1 sys . The integral flux above 1 TeV amounts to ( 2 . 6 + / - 0 . 4 ) x 10 - 12 cm - 2 s - 1 , equivalent to about 10 % of the total Galactic diffuse emission observed at these energies .This result confirms that this body is indeed a supernova remnant as suggested previously . In addition we have discovered two new sources within the field - of - view of our instrumentation .One of them has been detected with the shell - class supernova remnant G349 . 7 + 0 . 2 while another one remains unidentified .",
        "rewrite_text": "We present new findings on gamma-ray emissions generated by cosmic rays interacting with interstellar gas, derived from observations conducted with the HESS telescope array from 2004 to 2007. This study focuses on the spectrum of RX J1713.7-3946 (HESS J1714-385), the brightest source identified at TeV energies. Our analysis reveals that the spectrum is well-represented by a power law with an index of 2.28 ± 0.04 (statistical) ± 0.1 (systematic). The integral flux measured above 1 TeV is (2.6 ± 0.4) x 10^-12 cm^-2 s^-1, which accounts for approximately 10% of the total Galactic diffuse emission observed at these energy levels. These findings reinforce the classification of RX J1713.7-3946 as a supernova remnant, a hypothesis that has been proposed in earlier studies. Furthermore, our observations have led to the identification of two new sources within the HESS field of view. One of these sources is associated with the shell-type supernova remnant G349.7+0.2, while the other remains unidentified. This research contributes to our understanding of cosmic-ray interactions and the resultant gamma-ray emissions, providing valuable insights into the processes occurring in supernova remnants and their role in the broader context of Galactic astrophysics.",
        "ori-fast-z-score": 1.4552137502179978,
        "water-fast-z-score": 4.213504858001922,
        "rewrite-fast-z-score": 0.8528028654224417
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Absorption spectroscopy of individual single-walled carbon nanotubes .\nAbstract:\nWe report on the absorption spectrum of an isolated single-wall carbon nanotube (SWNT) in solution, obtained by using a scanning near-field optical microscope with subwavelength resolution. The SWNTs are suspended between two gold electrodes and illuminated through one electrode at normal incidence to excite both transverse electric (TE) and transverse magnetic (TM) polarized light. We observe that the TE mode is strongly suppressed compared to TM polarization due to the presence of metallic tubes within our sample. This effect can be used as a spectroscopic tool for identifying the chirality of individual SWNTs. \n \n Single-wall carbon nanotubes have attracted considerable interest because they exhibit unique electronic properties which depend sensitively on their diameter and chiral angle  1  . In particular, it has been shown theoretically  2  , experimentally  3  , and numerically  4  that the energy gap depends on these parameters such that semiconducting tubes have small gaps while metallic tubes have large ones. However, this dependence is not sufficient to uniquely identify all possible tube types  5  .\n \nIn order to determine the type of each tube individually, several experimental techniques have been developed  6  -  8  . For example, Raman scattering  9  or photoluminescence  10  measurements allow one to distinguish between metallic and semiconducting tubes based on the intensity ratio of certain peaks  11  . Alternatively, electrical transport experiments  12  provide information about the charge carrier density and mobility  13  . Finally, transmission electron microscopy  14  allows one to directly visualize the structure of the tubes  15  . \n \n Here we present another method for determining the chirality of individual carbon nanotubes. Our approach relies on measuring the absorption cross section of individual SWNTs  16  . Since the absorption cross-section depends on the dielectric function  17  , which in turn varies significantly depending on whether the tube is metallic or semiconducting  18  , we expect different values for the absorption cross sections of metallic versus semiconducting tubes. By comparing the measured absorption cross sections of various tubes, we will show how this technique can be used to classify them into either metallic or semiconducting categories. \nExperimental setup\n\nThe samples were prepared following the",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Absorption spectroscopy of individual single - walled carbon nanotubes . Abstract : We report on the absorption spectrum of an exposed single - wall carbon nanotube ( SWNT ) in solution , obtained by using a scanning near - field imaging microscope with subwavelength resolution .The SWNTs are suspended between two gold electrodes and illuminated through one electrode at usual incidence to excite both transverse electric ( TE ) and longitudinal magnetic ( TM ) polarized light . We see that the TE mode is strongly restrained compared to TM polarization owing to the presence of metallic tubes within our sample .This phenomenon can be used as a spectroscopic tool for determining the chirality of different SWNTs . Single - wall carbon nanotubes have garnered considerable interest because they possess unique electronic properties which depend sensitively on their thickness and chiral angle 1 .In particular , it has been shown theoretically 2 , experimentally 3 , and numerically 4 that the electricity gap depends on these parameters such that semiconducting tubes have narrow holes while metallic tubes have smaller ones . However , this dependence is not required to uniquely distinguish all possible tube categories 5 .In order to identify the kind of each tube individually , various experimental methods have been created 6 - 8 . For instance , Raman scattering 9 or photoluminescence 10 measurements enable one to distinguish between metallic and semiconducting tubes based on the frequency proportion of certain peaks 11 .Alternatively , electrical travel techniques 12 provide details about the charge carrier density and connectivity 13 . Finally , transmission electron microscopy 14 allows one to fully visualize the formation of the tubes 15 .Here we present another technique for determining the chirality of individual carbon nanotubes . Our model relies on measuring the absorption cross section of individual SWNTs 16 .Since the absorption cross - section depends on the dielectric function 17 , which in turn varies dramatically based on whether the pipe is metallic or semiconducting 18 , we expect different values for the absorption cross sections of metallic versus semiconducting tubes . By matching the measured absorbed cross sections of different tubes , we will show how this methodology can be used to classify them into either metallic or semiconducting classification .Experimental setup\n\nThe samples were prepared following the",
        "rewrite_text": "**Title: Absorption Spectroscopy of Individual Single-Walled Carbon Nanotubes**\n\n**Abstract:** In this study, we present a detailed investigation of the absorption spectrum of an individual single-walled carbon nanotube (SWNT) suspended in a solution, utilizing a scanning near-field imaging microscope that achieves subwavelength resolution. The SWNTs are positioned between two gold electrodes and illuminated through one electrode at normal incidence, allowing for the excitation of both transverse electric (TE) and longitudinal magnetic (TM) polarized light. Our findings reveal that the TE mode exhibits significant suppression compared to the TM polarization, a phenomenon attributed to the presence of metallic tubes within the sample. This observation provides a novel spectroscopic approach for determining the chirality of various SWNTs.\n\nSingle-walled carbon nanotubes have attracted extensive research interest due to their exceptional electronic properties, which are highly sensitive to their diameter and chiral angle. Theoretical, experimental, and numerical studies have demonstrated that the energy gap of these tubes is influenced by these parameters, with semiconducting tubes exhibiting narrower gaps compared to their metallic counterparts. However, this relationship alone does not suffice for the definitive classification of all tube types. To address this challenge, several experimental techniques have been developed, including Raman scattering and photoluminescence measurements, which differentiate between metallic and semiconducting tubes based on specific peak frequency ratios. Additionally, electrical transport methods provide insights into charge carrier density and connectivity, while transmission electron microscopy offers a comprehensive visualization of tube formation.\n\nIn this work, we introduce an alternative technique for the determination of individual carbon nanotube chirality by measuring the absorption cross-section of SWNTs. Given that the absorption cross-section is contingent upon the dielectric function—which varies significantly between metallic and semiconducting tubes—we anticipate distinct absorption cross-section values for these categories. By correlating the measured absorption cross-sections of various tubes, we demonstrate the efficacy of this methodology in classifying them as either metallic or semiconducting. The experimental setup and sample preparation details are elaborated upon to provide a comprehensive understanding of the methodology employed in this research.",
        "ori-fast-z-score": -0.8512055557875505,
        "water-fast-z-score": 6.172133998483676,
        "rewrite-fast-z-score": 0.07881104062391006
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Information Theoretic Proofs of Entropy Power Inequalities .\nAbstract:\nEntropies are measures of uncertainty, and entropy power inequalities (EPIs) quantify the trade-off between information transmission rates in different communication channels.  In this work we present new proofs for EPIs based on information theory concepts such as mutual information and channel capacity.   We also show that these results can be used to prove Shannon s source coding theorem by applying them to an appropriate binary memoryless symmetric channel model. Finally, we discuss how our approach could potentially lead to improved bounds on the minimum distance of linear block codes over finite fields. Entropies are measures of uncertainty; entropy power inequalities (EPIS) quantify the tradeoff between information transmission rates in various communication channels. In this work we present novel proofs for EPIs using information-theory concepts like mutual information and channel capacity. We also demonstrate that these results may be utilized to verify Shannon s source coding theorem via their application to a suitable binary memoryless-symmetric channel model. Finally,we discuss how our technique might possibly yield better bounds on the minimal distance of linear block codes across finite fields.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Information Theoretic Proofs of Entropy Power Inequalities . Abstract : Entropies are measures of uncertainty , and entropy energy inequalities ( EPIs ) quantify the trade - off between information transmission rates in different communication streams .In this study we present new proofs for EPIs based on information principle concepts such as mutual information and channel capacity . We additionally prove that these results can be used to prove Shannon s source coding theorem by application them to an appropriate binary memoryless symmetric channel structure .Finally , we explain how our approach could potentially contribute to greater bounds on the minimum distance of linear block codes over discrete fields . Entropies are measures of uncertainty ; entropy energy inequalities ( EPIS ) quantify the tradeoff between information transmission rates in different communication channels .In this study we present new proofs for EPIs using information - theory ideas like mutual information and channel capacity . We additionally prove that these results may be employed to confirm Shannon s source coding theorem via their application to a suitable binary memoryless - symmetric channel theory .Finally , we explain how our technique may possibly provide better bounds on the reduced distance of linear block sequences across finite fields .",
        "rewrite_text": "Title: Information Theoretic Proofs of Entropy Power Inequalities\n\nAbstract: Entropy serves as a fundamental measure of uncertainty in information theory, and the entropy power inequalities (EPIs) play a crucial role in characterizing the trade-offs between information transmission rates across various communication channels. In this paper, we introduce novel proofs for the entropy power inequalities, leveraging key concepts from information theory, including mutual information and channel capacity. Our findings demonstrate that these new proofs not only reinforce the validity of EPIs but also provide a pathway to validate Shannon's source coding theorem when applied to an appropriate binary memoryless symmetric channel model. Furthermore, we explore the implications of our approach in enhancing the bounds on the minimum distance of linear block codes defined over discrete fields. By establishing a deeper understanding of the relationship between entropy and information transmission, our work contributes to the ongoing discourse in information theory and opens avenues for further research in coding theory and communication systems. The results presented here not only solidify existing theoretical frameworks but also suggest practical applications that could lead to improved performance in real-world communication scenarios. Overall, this study underscores the significance of entropy in quantifying uncertainty and its pivotal role in advancing the field of information theory.",
        "ori-fast-z-score": 0.19425717247145283,
        "water-fast-z-score": 6.225870853937484,
        "rewrite-fast-z-score": 1.7483145522430754
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The extended structure of the remote cluster B514 in M31. Detection of extra-tidal stars .\nAbstract:\nWe present new deep photometry for the remote open cluster B514, located at about 1 degree (0.5 kpc) south-east of the center of the Andromeda galaxy (M31). The data were obtained with the Wide Field Camera 3 on board HST and cover an area of 0.6 square degrees centered around the cluster position. We detect more than 100 candidate members brighter than V = 25 mag within a radius of 2 arcmin from the cluster center. These are likely to be associated with the cluster itself rather than background galaxies or foreground Galactic dwarfs because they have colors consistent with those expected for old red giant branch stars. In addition we find that there is a significant number of faint blue objects surrounding the cluster which may belong to it as well. Using these candidates together with previous ground-based observations we construct color-magnitude diagrams for different annuli extending out to 5 arcmin from the cluster centre. From this analysis we conclude that the cluster has an extended halo containing several hundred low mass stars beyond its tidal radius.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The extended structure of the distant cluster B514 in M31 . Detection of extra - tidal stars .Abstract : We report new deep photometry for the distant open cluster B514 , located at about 1 degree ( 0 . 5 kpc ) south - east of the center of the Andromeda galaxy ( M31 ) . The data were obtained with the Wide Field Camera 3 on board HST and cover an area of 0 . 6 square degrees centered around the cluster spot .We detect more than 100 candidate members hotter than V = 25 mag within a diameter of 2 arcmin from the cluster center . These are likely to be identified with the cluster itself rather than background galaxies or foreground Galactic dwarfs because they have colors consistent with those expected for past red dwarf branch stars .In addition we find that there is a substantial quantity of faint blue objects surrounding the cluster which may belong to it as also . Using these candidates together with previous ground - based observations we create color - magnitude diagrams for different annuli extending out to 5 arcmin from the cluster centre .From this analysis we conclude that the cluster has an extended halo containing several hundred small weight stars beyond its tidal diameter .",
        "rewrite_text": "We present a comprehensive study of the distant open cluster B514, situated approximately 1 degree (0.5 kpc) southeast of the Andromeda galaxy (M31) center, based on new deep photometric observations. Utilizing the Wide Field Camera 3 aboard the Hubble Space Telescope (HST), we have gathered data covering an area of 0.6 square degrees centered on the cluster. Our analysis reveals over 100 candidate member stars with brightness greater than V = 25 mag within a 2 arcminute radius from the cluster's center. These stars are likely associated with B514, as their color characteristics align with those anticipated for evolved red dwarf branch stars, distinguishing them from potential background galaxies or foreground Galactic dwarfs.\n\nFurthermore, we identify a significant number of faint blue objects in the vicinity of the cluster, which may also be part of B514. By integrating these candidates with prior ground-based observations, we construct color-magnitude diagrams for various annuli extending up to 5 arcminutes from the cluster's center. This detailed examination leads us to conclude that B514 possesses an extended halo, which contains several hundred low-mass stars that lie beyond its tidal radius. Our findings enhance the understanding of the cluster's structure and its stellar population, providing insights into the dynamics and evolution of open clusters in the context of the Andromeda galaxy. This research contributes to the broader field of stellar astrophysics and the study of galactic structures, highlighting the importance of deep photometric surveys in uncovering the complexities of distant star clusters.",
        "ori-fast-z-score": -0.41256849850351734,
        "water-fast-z-score": 3.09426373877638,
        "rewrite-fast-z-score": 0.7427813527082074
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Geometric control theory I: mathematical foundations .\nAbstract:\nThe book is divided into three parts, each part containing several chapters. The first two parts are devoted to the development and analysis of geometric control systems in finite-dimensional spaces (the state space) and infinite-dimensional Hilbert spaces (the phase space). In particular, the following topics are considered:\n\nPart I - Geometric Control Theory in Finite-Dimensional Spaces.\n\nChapter 1 - Introduction to Geometric Control Theory.\n Chapter 2 - Basic Concepts of Differential Geometry.\n Chapter 3 - Lie Groups and Their Representations.\n Chapter 4 - Invariant Manifolds for Group Actions on Vector Fields.\n Chapter 5 - Stability Analysis of Nonlinear Systems with State Constraints.\n Chapter 6 - Stabilization by Feedback of Linear Time-Invariant Systems.\n Chapter 7 - Optimal Tracking Problems for Affine Systems.\n Part II - Geometric Control Theory on Infinite-Dimensional Hilbert Spaces.\n\n Chapter 8 - Generalized Euler-Lagrange Equations.\n Chapter 9 - Hamilton-Jacobi Equations.\n Chapter 10 - Pontryagin Maximum Principle.\n Chapter 11 - Optimal Control Problem for Discrete-Time Systems.\n Chapter 12 - Optimal Control Problem with Uncertain Dynamics.\n Chapter 13 - Optimal Control Problem under Stochastic Disturbances.\n Chapter 14 - Optimal Control Problem over Networks.\n Part III - Applications of Geometric Control Theory.\n\n Chapter 15 - Motion Planning for Mobile Robots.\n Chapter 16 - Robot Manipulation Tasks via Task Space Formulation.\n Chapter 17 - Visual Servoing Based on Image Feature Extraction.\n Chapter 18 - Model Predictive Control for Industrial Processes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Geometric control theory I : geometric foundations . Abstract : The treatise is separated into three sections , each portion containing several chapters .The first two parts are devoted to the development and evaluation of geometric control networks in finite - dimensional spaces ( the state space ) and infinite - dimensional Hilbert spaces ( the phase space ) . In particular , the following topics are considered : Part I - Geometric Control Theory in Finite - Dimensional Spaces .Chapter 1 - Introduction to Geometric Control Theory . Chapter 2 - Basic Concepts of Differential Geometry .Chapter 3 - Lie Groups and Their Representations . Chapter 4 - Invariant Manifolds for Group Actions on Vector Fields .Chapter 5 - Stability Analysis of Nonlinear Systems with State Constraints . Chapter 6 - Stabilization by Feedback of Linear Time - Invariant Systems .Chapter 7 - Optimal Tracking Problems for Affine Systems.Part II - Geometric Control Theory on Infinite-Dimensional Hilbert Spaces.Chapter 8 - Generalized Euler - Lagrange Equations . Chapter 9 - Hamilton - Jacobi Equations .Chapter 10 - Pontryagin Maximum Principle . Chapter 11 - Optimal Control Problem for Discrete - Time Systems .Chapter 12 - Optimal Control Problem with Uncertain Dynamics . Chapter 13 - Optimal Control Problem under Stochastic Disturbances .Chapter 14 - Optimal Control Problem over Networks . Part III - Applications of Geometric Control Theory .Chapter 15 - Motion Planning for Mobile Robots . Chapter 16 - Robot Manipulation Tasks via Task Space Formulation .Chapter 17 - Visual Servoing Based on Image Feature Extraction . Chapter 18 - Model Predictive Control for Industrial Processes .",
        "rewrite_text": "**Title:** Geometric Control Theory I: Geometric Foundations\n\n**Abstract:** This article presents a comprehensive exploration of geometric control theory, structured into three distinct sections, each comprising multiple chapters that delve into various aspects of the field. The initial two sections focus on the formulation and assessment of geometric control networks within both finite-dimensional state spaces and infinite-dimensional Hilbert spaces, referred to as phase spaces. \n\nIn Part I, titled \"Geometric Control Theory in Finite-Dimensional Spaces,\" the discussion begins with an introduction to the fundamental principles of geometric control theory. Subsequent chapters cover essential concepts from differential geometry, the role of Lie groups and their representations, and the significance of invariant manifolds in the context of group actions on vector fields. The section further addresses the stability analysis of nonlinear systems constrained by state variables, techniques for stabilizing linear time-invariant systems through feedback mechanisms, and the challenges associated with optimal tracking problems for affine systems.\n\nPart II shifts focus to \"Geometric Control Theory on Infinite-Dimensional Hilbert Spaces,\" where the text examines generalized Euler-Lagrange equations and Hamilton-Jacobi equations, both pivotal in the realm of control theory. The discussion extends to the Pontryagin Maximum Principle, which provides a framework for optimal control problems in discrete-time systems, as well as scenarios involving uncertain dynamics and stochastic disturbances. Additionally, this section explores optimal control issues within networked systems, highlighting the complexities and solutions pertinent to these environments.\n\nFinally, Part III addresses practical applications of geometric control theory, showcasing its relevance in real-world scenarios. This section includes motion planning strategies for mobile robots, methodologies for robot manipulation tasks through task space formulation, and visual servoing techniques that leverage image feature extraction. The discussion culminates with an examination of model predictive control approaches tailored for industrial processes, illustrating the versatility and applicability of geometric control theory across various domains. This treatise serves as a foundational resource for researchers and practitioners seeking to deepen their understanding of geometric control principles and their applications.",
        "ori-fast-z-score": -1.952833664712358,
        "water-fast-z-score": -0.24618298195866545,
        "rewrite-fast-z-score": -0.9203579866168444
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  3D photospheric velocity field of a Supergranular cell .\nAbstract:\nWe present the first 3D kinematic analysis of an isolated supergranule in the photosphere using high-resolution observations obtained with Hinode/SOT and SDO/HMI instruments. The results show that the observed supergranule is characterized by a strong upflow at its center, surrounded by weaker downflows. We find that the horizontal flow pattern consists of two counter-rotating cells which are connected to each other through a narrow channel along their common boundary. This structure resembles the magnetic topology of a bipolar sunspot pair. In addition we observe a small-scale vortex-like feature located on one side of the central upflow region. Our study shows that the observed supergranulation pattern can be explained as a result of convective motions driven by the solar differential rotation. Keywords: Solar activity, Sunspots, Photometry, Magnetism, Granulation, Convection, Dynamo theory, Magnetic fields",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : 3D photospheric velocity field of a Supergranular cell . Abstract : We present the first 3D kinematic analysis of an exposed supergranule in the photosphere using high - resolution measurements obtained with Hinode / SOT and SDO / HMI instruments .The results show that the seen supergranule is characterized by a powerful upflow at its center , flanked by softer downflows . We see that the horizontal flow pattern consists of two counter - spinning cells which are connected to each other through a thin channel along their common boundary .This structure follows the magnetic topology of a bipolar sunspot couple . In addition we study a small - scale vortex - like feature centered on one end of the main upflow portion .Our study shows that the seen supergranulation rhythm can be described as a outcome of convective movements driven by the sun differential rotation . Keywords : Solar activity , Sunspots , Photometry , Magnetism , Granulation , Convection , Dynamo theory , Magnetic fields",
        "rewrite_text": "Title: 3D Photospheric Velocity Field of a Supergranular Cell\n\nAbstract: In this study, we present a pioneering three-dimensional kinematic analysis of a supergranule observed in the solar photosphere, utilizing high-resolution data collected from the Hinode Solar Optical Telescope (SOT) and the Solar Dynamics Observatory's Helioseismic and Magnetic Imager (SDO/HMI). Our findings reveal that the supergranule exhibits a prominent upflow at its center, surrounded by gentler downflows. The horizontal flow dynamics are characterized by two counter-rotating cells, which are interconnected via a narrow channel along their shared boundary. This observed structure aligns with the magnetic topology associated with a bipolar sunspot pair. Furthermore, we investigate a small-scale vortex-like feature located at one end of the primary upflow region. Our analysis indicates that the rhythmic behavior of the supergranulation can be attributed to convective motions driven by the Sun's differential rotation. This research enhances our understanding of solar activity and the complex interactions within the solar atmosphere, contributing valuable insights into the mechanisms of granulation, convection, and the underlying dynamo processes that govern solar magnetic fields. The implications of these findings extend to the broader context of solar physics, particularly in relation to the dynamics of sunspots and the overall magnetic activity of the Sun. \n\nKeywords: Solar activity, Sunspots, Photometry, Magnetism, Granulation, Convection, Dynamo theory, Magnetic fields.",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 5.019960159204453,
        "rewrite-fast-z-score": 1.0660035817780522
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Molecular line intensities as measures of cloud masses - II. Conversion factors for specific galaxy types .\nAbstract:\nWe present the results of our analysis of molecular gas mass estimates based on CO and HCN observations in nearby galaxies, using data obtained with the IRAM 30m telescope. We find that conversion factors between luminosity and mass are strongly dependent on the star formation rate (SFR) per unit area within each galaxy disk. The SFR surface density is found to be an important parameter controlling the conversion factor XCO = M(H2)/L(CO), which we derive by fitting the observed L(HCN) / L(CO) ratio versus metallicity relation. For low values of ΣSFR < 1M⊙ yr-1 kpc-2 , corresponding to quiescent disks or nuclear regions dominated by old stellar populations, we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s. This value increases up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > 3M⊙yr-1kpc-2 . These findings suggest that the physical conditions of the interstellar medium may change significantly depending on whether it is located in actively star-forming regions or not.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Molecular line intensities as indicators of cloud masses - II . Conversion factors for specific galaxy types .Abstract : We present the conclusion of our analysis of molecular gas mass estimates based on CO and HCN measurements in nearby galaxies , using data acquired with the IRAM 30m telescope . We see that conversion factors between luminosity and mass are strongly dependent on the star formation rate ( SFR ) per unit area within each galaxy disk .The SFR ground density is found to be an important function regulating the transformation parameter XCO = M ( H2 ) / L ( CO ) , which we derive by fitting the seen L ( HCN ) / L ( CO ) ratio versus metallicity relation . For low values of ΣSFR < [UNK] yr - 1 kpc - 2 , equivalent to quiescent disks or atomic regions dominated by ancient stars populations , we obtain XCO ≈ 2 × 10 20 cm−2 K−1 km−1 s . This value rises up to XCO ≈ 5×10 20 cm−2 K−1km−1s at high ΣSFR > [UNK] - 1kpc - 2 .These studies imply that the physical conditions of the interstellar medium may change considerably depending on whether it is situated in actively star - creating areas or not .",
        "rewrite_text": "We present the findings of our comprehensive analysis regarding the estimation of molecular gas masses in nearby galaxies, utilizing CO and HCN measurements obtained from the IRAM 30m telescope. Our research reveals that the conversion factors linking luminosity to mass exhibit a significant dependence on the star formation rate (SFR) per unit area within the disks of galaxies. We identify the SFR surface density as a critical factor influencing the transformation parameter XCO, defined as the ratio of molecular hydrogen mass (M(H2)) to carbon monoxide luminosity (L(CO)). This parameter is derived by analyzing the relationship between the L(HCN)/L(CO) ratio and metallicity. \n\nIn our observations, we find that for low SFR surface densities (ΣSFR < [UNK] yr^-1 kpc^-2), which correspond to quiescent disks or regions dominated by older stellar populations, the value of XCO is approximately 2 × 10^20 cm^-2 K^-1 km^-1 s. Conversely, in regions with high SFR surface densities (ΣSFR > [UNK] yr^-1 kpc^-2), indicative of active star formation, the value of XCO increases to around 5 × 10^20 cm^-2 K^-1 km^-1 s. These results suggest that the physical conditions within the interstellar medium can vary significantly based on the presence of active star formation. Our findings underscore the importance of considering local star formation activity when estimating molecular gas masses in different galaxy types, as it plays a pivotal role in shaping the conversion factors used in these calculations. This study contributes to a deeper understanding of the interplay between star formation and molecular gas dynamics in galactic environments.",
        "ori-fast-z-score": -0.10721125348377948,
        "water-fast-z-score": 4.477215043467819,
        "rewrite-fast-z-score": 0.1841149235796647
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Electron Doping of Cuprates via Interfaces with Manganites .\nAbstract:\nWe report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical bonding at interfaces.  The interface between La0.7Sr0.3MnO3 (LSMO) and YBa2Cu3O6+x (YBCO), which are both parent compounds for high temperature superconductivity, is found to be highly conducting despite the large lattice mismatch between LSMO and YBCO. This suggests that charge transfer across the interface occurs due to strong electronic hybridization rather than strain relaxation alone. We also find that the hole concentration in the YBCO layer can be controlled by varying the thickness of the LSMO layer grown on top of it. These results demonstrate an alternative approach towards engineering the carrier density in cuprate superconductors using oxide heterostructures. High-temperature superconductivity has been observed only in materials containing copper-oxygen planes known as CuO2 layers  1  . In these systems, holes doped into the CuO2 plane give rise to Cooper pairs leading to superfluidity  2  . However, the maximum critical temperature Tc = 92 K achieved so far in this class of materials is still well below the theoretical limit predicted by Bardeen-Cooper-Schrieffer theory  3  , raising questions about how to further enhance Tc  4  .\nIn recent years there have been significant efforts made to explore new routes toward enhancing Tc beyond its current record value  5  . One promising route involves introducing electrons into the CuO2 plane  6  . For example, replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the system  7, 8  . Alternatively, one may introduce electrons directly into the CuO2 plane by growing thin films of transition metal oxides such as SrTiO3  9  or LaAlO3  10  onto the surface of cuprate superconductors. While these approaches show promise, they require precise control over film composition and structure during deposition  11  . An alternative strategy would involve controlling the carrier density in cuprates without changing their crystal structures  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Electron Doping of Cuprates via Interfaces with Manganites . Abstract : We report on the observation of electron doping in cuprate superconductors by interfacing them to manganite insulators through epitaxial growth and chemical bonding at interfaces .The interface between La0 . 7Sr0 . 3MnO3 ( LSMO ) and YBa2Cu3O6 + x ( YBCO ) , which are both parent molecules for high heat superconductivity , is found to be highly conducting despite the huge lattice mismatch between LSMO and YBCO . This implies that charge transfer across the interface comes due to powerful electronic hybridization instead than strain relaxation alone .We additionally find that the gap content in the YBCO layer can be governed by varying the density of the LSMO layer grown on top of it . These data demonstrate an additional method towards engineering the carrier density in cuprate superconductors using oxide heterostructures .High - temperature superconductivity has been observed only in structures containing copper - oxygen planes named as CuO2 layers 1 . In these systems , holes doped into the CuO2 plane give rise to Cooper pairs leading to superfluidity 2 .However , the maximum essential temperature Tc = 92 K attained so far in this class of substances is already much below the theoretical maximum expected by Bardeen - Cooper - Schrieffer principle 3 , placing questions about how to further enhance Tc 4 . In recent history there have been significant efforts made to pursue new routes toward enhancing Tc beyond its current record value 5 .One promising route includes introducing electrons into the CuO2 plane 6 . For instance , replacing oxygen atoms in the CuO2 plane with fluorine leads to a reduction in the number of holes in the scheme 7 , 8 .Alternatively , one may introduce particles specifically into the CuO2 plane by spreading thin films of transition metal oxides such as SrTiO3 9 or LaAlO3 10 onto the surface of cuprate superconductors . While these method demonstrate promise , they demand careful power over movie structure and shape during deposition 11 .An alternative scheme would include regulating the carrier density in cuprates without altering their crystal structures 12 .",
        "rewrite_text": "**Title:** Electron Doping of Cuprates via Interfaces with Manganites\n\n**Abstract:** In this study, we present findings on the electron doping of cuprate superconductors achieved through the integration of manganite insulators via epitaxial growth and chemical bonding at their interfaces. Specifically, we investigate the interface formed between La0.7Sr0.3MnO3 (LSMO) and YBa2Cu3O6+x (YBCO), both of which serve as fundamental components in high-temperature superconductivity. Remarkably, despite the significant lattice mismatch between LSMO and YBCO, the interface exhibits high electrical conductivity. This observation suggests that the charge transfer occurring at the interface is primarily driven by strong electronic hybridization rather than merely by strain relaxation effects. Furthermore, we demonstrate that the superconducting gap in the YBCO layer can be modulated by adjusting the density of the LSMO layer deposited on top. These findings provide a novel approach to engineering carrier density in cuprate superconductors through the use of oxide heterostructures.\n\nHigh-temperature superconductivity is predominantly observed in materials featuring copper-oxygen planes, known as CuO2 layers. In these systems, the introduction of holes into the CuO2 plane facilitates the formation of Cooper pairs, which are essential for superfluidity. However, the highest critical temperature (Tc) recorded in this class of materials is 92 K, which remains significantly below the theoretical maximum predicted by the Bardeen-Cooper-Schrieffer (BCS) theory, raising questions about potential pathways to further enhance Tc. Recent efforts have focused on exploring innovative strategies to surpass this current limit. One promising avenue involves the introduction of electrons into the CuO2 plane. For example, substituting oxygen atoms in the CuO2 structure with fluorine reduces the hole concentration. Alternatively, thin films of transition metal oxides, such as SrTiO3 or LaAlO3, can be applied to the surfaces of cuprate superconductors to inject charge carriers. While these methods show potential, they require meticulous control over the deposition process. Our research proposes a different strategy that allows for the regulation of carrier density in cuprates without necessitating alterations to their crystal structures.",
        "ori-fast-z-score": 0.08247860988423225,
        "water-fast-z-score": 7.021870595978444,
        "rewrite-fast-z-score": 0.7633700367119739
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Families of holomorphic bundles .\nAbstract:\nIn this article, we study families of holomorphic vector bundles on complex algebraic varieties. We prove that the set of isomorphism classes of such families is naturally an affine scheme over the base variety and give explicit equations for it in terms of Chern classes.  In particular, if the base variety has dimension one then these schemes are reduced to points corresponding to the rank and degree of each bundle in the family. \nWe also show how our results can be used to construct moduli spaces of stable vector bundles with fixed determinant. The main result of this article was announced by J. P. Serre at the conference  Algebraic geometry and number theory  held in Paris in June 2005 (see  Ser  ). Families of holomorphic vector bundles have been studied extensively since the work of Grothendieck  Gro1  . They play important roles both in algebraic geometry and mathematical physics; see e.g.,  Bri1,  Bri2,   Bri3,   ...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Families of holomorphic bundles . Abstract : In this article , we study families of holomorphic vector bundles on complex algebraic varieties .We prove that the group of isomorphism classes of such families is naturally an affine scheme over the base variety and get explicit equations for it in terms of Chern classes . In particular , if the base variety has size one then these schemes are increased to points corresponding to the rank and degree of each bundle in the class .We addition show how our findings can be used to build moduli spaces of stable vector bundles with constant determinant . The main result of this page was announced by J . P . Serre at the meeting Algebraic geometry and number theory conducted in Paris in June 2005 ( see Ser ) .Families of holomorphic vector bundles have been studied frequently since the work of Grothendieck Gro1 . They play essential roles both in mathematical mathematics and mathematical science ; hear e . g . , Bri1 , Bri2 , Bri3 , . . .",
        "rewrite_text": "Title: Families of Holomorphic Bundles\n\nAbstract: This article explores the intricate structure of families of holomorphic vector bundles on complex algebraic varieties. We establish that the set of isomorphism classes of these families can be naturally interpreted as an affine scheme over the base variety. Furthermore, we derive explicit equations for this scheme in terms of Chern classes, which serve as crucial invariants in the study of vector bundles. Notably, when the base variety consists of a single point, the affine schemes correspond directly to points that reflect the rank and degree of each vector bundle within the class. Our research also demonstrates the application of these results in constructing moduli spaces for stable vector bundles that maintain a constant determinant. The significance of our findings is underscored by the fact that the primary result was initially presented by J. P. Serre during the Algebraic Geometry and Number Theory conference held in Paris in June 2005. The study of families of holomorphic vector bundles has a rich history, particularly following the foundational work of Grothendieck, and continues to be a vital area of inquiry in both pure mathematics and mathematical physics. This article contributes to the ongoing discourse by providing new insights and methodologies that enhance our understanding of vector bundles, as evidenced by the extensive literature on the subject, including works by authors such as Briand and others.",
        "ori-fast-z-score": -1.649915822768611,
        "water-fast-z-score": 3.117691453623979,
        "rewrite-fast-z-score": 0.20203050891044214
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Projectile Fragmentation of $^{86}$Kr at 64 MeV/nucleon .\nAbstract:\nThe projectile fragmentation of 86Kr at 64MeV/nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a beam intensity of 1nAe. The main results are as follows:  - A total number of about 10000 events have been recorded for this experiment.  - The charge distribution is peaked around Z=40, but shows also a large contribution between 30 and 40 charges units (see fig.1 ). This indicates that the fragments produced by the break-up of 86Kr are not only light particles like neutrons or protons, but contain many intermediate mass fragments too.   - The angular distributions show two peaks corresponding to forward and backward emission respectively (see fig.2 ).  - The energy spectra present a maximum around 10-12 MeV/u which corresponds to the most probable kinetic energy per nucleon of the emitted fragments (see fig.3 ).\n- The isotopic composition of the fragments is shown on figure 4 . It can be seen that there is no significant difference between the fragment production in the forward hemisphere and in the backward one.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Projectile Fragmentation of $ ^ { 86 } $ Kr at 64 MeV / nucleon . Abstract : The projectile fragmentation of 86Kr at 64MeV / nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a laser intensity of 1nAe .The main results are as follows : - A total number of about 10000 events have been observed for this study . - The charge distribution is peaked around Z = 40 , but shows also a large contribution between 30 and 40 charges units ( saw fig . 1 ) .This implies that the fragments produced by the broken - up of 86Kr are not only light particles like neutrons or protons , but contain many intermediate mass pieces too . - The angular distributions show two peaks related to forward and back emission respectively ( view fig . 2 ) .- The energy spectra produce a maximum around 10 - 12 MeV / u which equals to the most likely kinetic power per nucleon of the emitted objects ( see fig . 3 ) . - The isotopic structure of the fragments is displayed on figure 4 .It can be shown that there is no major changes between the fragment production in the front hemisphere and in the backward one .",
        "rewrite_text": "The study presented in this article investigates the projectile fragmentation of \\(^{86}\\)Kr at an energy of 64 MeV per nucleon, utilizing the INDRA multidetector in an inverse kinematics setup. The experiment was conducted with an 8 cm thick natural potassium (natK) target and a laser intensity of 1 nA. A total of approximately 10,000 events were recorded during this investigation, providing a substantial dataset for analysis. \n\nThe findings reveal that the charge distribution of the fragments is predominantly centered around \\(Z = 40\\), indicating a significant presence of intermediate mass fragments, with a notable contribution from fragments ranging between 30 and 40 charge units, as illustrated in Figure 1. This suggests that the fragmentation process of \\(^{86}\\)Kr produces not only light particles, such as neutrons and protons, but also a variety of heavier intermediate mass fragments.\n\nAngular distribution measurements indicate the presence of two distinct peaks corresponding to forward and backward emissions, as depicted in Figure 2. This bimodal distribution provides insights into the dynamics of the fragmentation process. Furthermore, the energy spectra of the emitted fragments exhibit a peak around 10-12 MeV per nucleon, which corresponds to the most probable kinetic energy per nucleon of the emitted particles, as shown in Figure 3. \n\nAdditionally, the isotopic composition of the fragments is detailed in Figure 4, revealing that there are no significant differences in fragment production between the forward and backward hemispheres. This observation suggests a symmetrical fragmentation process, contributing to our understanding of the mechanisms underlying projectile fragmentation at high energies. Overall, the results of this study enhance our comprehension of the fragmentation behavior of heavy ions and provide valuable data for future research in nuclear physics.",
        "ori-fast-z-score": -0.6882472016116852,
        "water-fast-z-score": 4.672383634845156,
        "rewrite-fast-z-score": -0.2773500981126145
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A High-Throughput Cross-Layer Scheme for Distributed Wireless Ad Hoc Networks .\nAbstract:\nIn this work, we propose a novel cross-layer scheme to improve the performance of distributed wireless ad hoc networks (DWAHNs). The proposed scheme is based on an adaptive routing protocol and a dynamic channel allocation algorithm. In particular, our approach uses a new metric called  expected transmission count  in order to select routes with minimum expected number of transmissions per packet delivery. Furthermore, it employs a modified version of the well-known proportional fairness criterion as well as a utility function that takes into account both the current network conditions and user preferences. Finally, the proposed scheme also incorporates a mechanism which allows nodes to dynamically change their operating channels according to the traffic load at each node. Extensive simulation experiments are conducted using NS-2 simulator to evaluate the effectiveness of the proposed scheme under different scenarios. Results show that the proposed scheme outperforms existing approaches by achieving higher throughput while maintaining low end-to-end delay and packet loss rate.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A High - Throughput Cross - Layer Scheme for Distributed Wireless Ad Hoc Networks . Abstract : In this project , we propose a new cross - layer scheme to upgrade the performance of distributed wireless ad hoc networks ( DWAHNs ) .The proposed system is based on an adaptive routing mechanism and a dynamic channel allocation algorithm . In particular , our approach utilizes a new metric termed expected broadcast count in order to select lanes with minimum expected number of transmissions per packet transport .Furthermore , it employs a altered version of the better - famous proportional fairness requirement as well as a utility function that takes into consideration both the present connection conditions and customer choices . Finally , the suggested system also contains a process which allows nodes to dynamically change their operating networks according to the traffic burden at each node .Extensive model studies are performed using NS - 2 simulator to analyze the performance of the suggested system under various circumstances . Results show that the suggested system outperforms current approaches by achieving larger throughput while maintaining low end - to - end delay and packet loss rate .",
        "rewrite_text": "Title: A High-Throughput Cross-Layer Scheme for Distributed Wireless Ad Hoc Networks\n\nAbstract: This article presents a novel cross-layer scheme designed to enhance the performance of distributed wireless ad hoc networks (DWAHNs). The proposed framework integrates an adaptive routing mechanism with a dynamic channel allocation algorithm to optimize network efficiency. Central to our approach is the introduction of a new metric known as the expected broadcast count, which facilitates the selection of communication paths that minimize the anticipated number of transmissions required for each packet. Additionally, we incorporate a modified version of the widely recognized proportional fairness criterion, alongside a utility function that accounts for both current connection conditions and user preferences. This dual consideration ensures that the network adapts to varying demands while optimizing resource allocation. Furthermore, our system includes a mechanism that enables nodes to dynamically adjust their operational parameters based on the traffic load experienced at each node, thereby enhancing overall network responsiveness. To evaluate the effectiveness of our proposed scheme, we conducted extensive simulations using the NS-2 simulator, examining its performance across a range of scenarios. The results demonstrate that our approach significantly outperforms existing methods, achieving higher throughput while simultaneously maintaining low end-to-end delay and reduced packet loss rates. This research contributes to the ongoing development of more efficient and resilient wireless ad hoc networks, paving the way for improved communication in dynamic environments.",
        "ori-fast-z-score": -1.2686700948330931,
        "water-fast-z-score": 6.477134476605945,
        "rewrite-fast-z-score": 0.3563483225498992
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Network statistics on early English Syntax: Structural criteria .\nAbstract:\nThe present study investigates the structural properties of Early Modern English syntax by applying network analysis to data obtained through corpus linguistics techniques. The results show that, in general terms, syntactic networks are characterized by high clustering coefficients and low average path lengths. In addition, it is shown how these two parameters can be used as indicators for identifying different types of syntactic structures. Finally, some possible applications of this approach are discussed. Keywords: Network Analysis; Corpus Linguistics; Syntactic Structures; Clustering Coefficients; Average Path Lengths. 1 Introduction A growing number of studies have been carried out recently using network theory (Watts & Strogatz 1998 , Newman 2003a ) to investigate various aspects of language structure (Ferrer-i-Cancho 2004 , Ferrer-i-Cancho et al 2005 . These investigations have mainly focused on phonological systems (e.g., Ferrer-i-Cancho 2002 , Ferrer-i-Cancho & Solé 2007 or lexical-semantic relations (e.g., Steyvers & Tenenbaum 2005 ) . However, there has also been interest in exploring other linguistic levels such as morphosyntax (Ferrer-i-Canchos 2006 ) , prosody (Ferrer-i-Canchós 2008) , pragmatics (Ferrer-i-Canchis 2009) or even discourse (Ferrer-i-Canchi 2010) . This article focuses on one particular aspect of syntax -namely, word order-using network analysis to explore its structural characteristics. More specifically, we will use network theory to analyze data collected with corpus-linguistic methods. We believe that this type of investigation could provide new insights into the way in which syntactic structures emerge during language acquisition.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Network statistics on early English Syntax : Structural criteria . Abstract : The present research investigates the structural properties of Early Modern English syntax by using network theory to data acquired through corpus linguistics tools .The results show that , in general terms , syntactic circuits are marked by high clustering parameters and low average route distances . In addition , it is demonstrated how these two parameters can be used as indicators for determining specific kinds of syntactic structures .Finally , some possible users of this methodology are discussed . Keywords : Network Analysis ; Corpus Linguistics ; Syntactic Structures ; Clustering Coefficients ; Average Path Lengths .1 Introduction A growing number of studies have been carried out recently utilizing network theory ( Watts & Strogatz 1998 , Newman 2003a ) to examine different components of language system ( Ferrer - i - Cancho 2004 , Ferrer - i - Cancho et al 2005 . These studies have chiefly centered on phonological systems ( e . g . , Ferrer - i - Cancho 2002 , Ferrer - i - Cancho & Solé 2007 or lexical - linguistic relations ( e . g . , Steyvers & Tenenbaum 2005 ) .However , there has additionally been discussion in investigating other linguistic levels such as morphosyntax ( Ferrer - i - Canchos 2006 ) , prosody ( Ferrer - i - Canchós 2008 ) , pragmatics ( Ferrer - i - Canchis 2009 ) or also discourse ( Ferrer - i - Canchi 2010 ) . This page focuses on one special aspect of syntax - namely , word order - using network analysis to examine its structural traits .More specifically , we will use system theory to analyze information collected with corpus - linguistic methods . We believe that this form of investigation could give novel discoveries into the way in which syntactic processes emerge during language acquire .",
        "rewrite_text": "**Title:** Network Statistics on Early English Syntax: Structural Criteria\n\n**Abstract:** This study explores the structural characteristics of Early Modern English syntax through the lens of network theory, utilizing data obtained from corpus linguistics methodologies. The findings reveal that syntactic networks exhibit notable features, characterized by high clustering coefficients and low average path lengths. These metrics serve as valuable indicators for identifying distinct types of syntactic structures within the language. Furthermore, the research discusses potential applications of this analytical framework for various users, including linguists and language educators, who may benefit from insights into syntactic organization and its implications for language acquisition. \n\nThe introduction highlights a growing trend in linguistic research that employs network theory to analyze various components of language systems, as evidenced by previous studies focusing primarily on phonological and lexical relationships. However, this paper aims to extend the application of network analysis to the realm of syntax, particularly examining word order as a critical aspect. By applying systems theory to the data gathered through corpus linguistics, this research seeks to uncover new perspectives on the emergence of syntactic processes during language development. The implications of these findings may contribute to a deeper understanding of the structural dynamics of Early Modern English and offer a methodological framework for future linguistic inquiries. \n\n**Keywords:** Network Analysis; Corpus Linguistics; Syntactic Structures; Clustering Coefficients; Average Path Lengths.",
        "ori-fast-z-score": -1.1917080461366747,
        "water-fast-z-score": 6.6996452071463715,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Rotational Widths for Use in the Tully-Fisher Relation. II. The Impact of Surface Brightness .\nAbstract:\nWe present new measurements of rotational widths (W20) and surface brightnesses (SB) for a sample of galaxies with inclinations between 30°and 80°, drawn from the Sloan Digital Sky Survey Data Release 7. We find that W20 is correlated strongly with SB at fixed luminosity, but only weakly or not at all with galaxy mass. This correlation persists even when we restrict our analysis to late-type spirals, which are known to have flat rotation curves. These results suggest that the observed scatter in the Tully-Fischer relation may be due primarily to variations in SB among galaxies of similar luminosities rather than differences in their masses. In addition, we show that this effect can explain why previous studies found no significant dependence on inclination angle in the TF relation. Finally, we demonstrate how these correlations affect estimates of the Hubble constant derived using the TF relation. Our findings also provide an explanation for the apparent discrepancy between the values obtained by different authors who used samples selected over different ranges of inclination angles.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Rotational Widths for Use in the Tully-Fisher Relation.II.The Impact of Surface Brightness . Abstract : We report new measurements of rotational widths ( W20 ) and surface brightnesses ( SB ) for a sample of stars with inclinations between 30°and 80° , chosen from the Sloan Digital Sky Survey Data Release 7 .We see that W20 is associated strongly with SB at fixed luminosity , but only strongly or not at all with star mass . This correlation persists even when we limit our analysis to late - class spirals , which are known to have flattened rotation curves .These data suggest that the seen scatter in the Tully - Fischer relation might be due primarily to variations in SB among galaxies of comparable luminosities rather than differences in their masses . In addition , we prove that this effect can answer why previous research found no considerable dependence on inclination velocity in the TF relation .Finally , we prove how these correlations influence estimates of the Hubble constant calculated using the TF relation . Our findings also provide an reason for the alleged discrepancy between the estimates obtained by various scientists who used data selected over particular ranges of inclination distances .",
        "rewrite_text": "In this study, we present new measurements of rotational widths (W20) and surface brightnesses (SB) for a carefully selected sample of stars with inclinations ranging from 30° to 80°, derived from the Sloan Digital Sky Survey Data Release 7. Our analysis reveals a significant correlation between W20 and SB at a constant luminosity, while the relationship with stellar mass appears to be either weak or nonexistent. This correlation remains robust even when we focus exclusively on late-type spiral galaxies, which are characterized by their flattened rotation curves. The implications of these findings suggest that the observed scatter in the Tully-Fisher (TF) relation may largely stem from variations in surface brightness among galaxies with similar luminosities, rather than from differences in their stellar masses. Furthermore, we demonstrate that this correlation provides an explanation for the lack of a substantial dependence on inclination velocity previously noted in the TF relation. Additionally, our results have important ramifications for the estimation of the Hubble constant derived from the TF relation, as they highlight how these correlations can affect such calculations. Our research also sheds light on the discrepancies reported by various researchers who have utilized data selected within specific ranges of inclination distances, offering a potential resolution to these inconsistencies. Overall, our findings contribute to a deeper understanding of the factors influencing the Tully-Fisher relation and its applications in cosmology.",
        "ori-fast-z-score": -1.9126494315742406,
        "water-fast-z-score": 5.74243935589202,
        "rewrite-fast-z-score": 1.616244071283537
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Detailed Study of Gas and Star Formation in a Highly Magnified Lyman Break Galaxy at z=3.07 .\nAbstract:\nWe present the results of an extensive study of gas dynamics, star formation activity, dust extinction, stellar populations, and black hole accretion properties for a strongly lensed galaxy (A1689-zD1) at redshift 3.07. The lensing magnification factor is ~30Â±5. We use deep near-infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high spatial resolution. Our observations reveal that this system consists of two merging galaxies separated by 1 kpc along the line-of-sight. One of these components shows strong HÎ² emission indicative of active galactic nuclei (AGN). This AGN component has a mass of âˆ¼10^9 M_sol , which corresponds to a supermassive black hole with a mass of âˆ½â€“1 Ã— 10^8 M_sol . Using our spatially resolved measurements we find evidence for intense nuclear starbursts on scales as small as 100 pc.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Detailed Study of Gas and Star Formation in a Highly Magnified Lyman Break Galaxy at z = 3 . 07 . Abstract : We present the conclusion of an extensive research of gas structure , star formation activity , dust extinction , planetary populations , and dark hole accretion properties for a strongly lensed galaxy ( A1689 - zD1 ) at redshift 3 . 07 .The lensing magnification factor is ~ 30Â±5 . We use deep near - infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high spatial resolution .Our observations indicate that this system contains of two combining galaxies crossed by 1 kpc along the line - of - seeing . One of these constituents exhibits strong HÎ² emission indicative of active galactic nuclei ( AGN ) .This AGN constituent has a mass of [UNK] ^ 9 M _ sol , which corresponds to a supermassive black hole with a mass of [UNK] “ 1 [UNK] — 10 ^ 8 M _ sol . Using our spatially resolved calculations we find proof for intense nuclear starbursts on scales as low as 100 pc .",
        "rewrite_text": "We present the findings of a comprehensive investigation into the gas dynamics, star formation processes, dust attenuation, planetary populations, and the accretion characteristics of dark matter in a highly magnified Lyman Break Galaxy, designated A1689-zD1, located at a redshift of 3.07. This galaxy is significantly lensed, with a magnification factor of approximately 30±5. Utilizing advanced near-infrared spectroscopy, we have achieved high spatial resolution measurements of the kinematics associated with molecular hydrogen emission lines. Our results reveal that A1689-zD1 is composed of two merging galaxies, which are aligned along a 1 kpc line of sight. Notably, one of these galaxies displays pronounced Hβ emission, a hallmark of active galactic nuclei (AGN) activity. The AGN component is estimated to have a stellar mass of around 10^9 M_sol, suggesting the presence of a supermassive black hole with a mass in the range of 1-10^8 M_sol. Through our spatially resolved analyses, we provide compelling evidence for vigorous nuclear starburst activity occurring on scales as small as 100 parsecs. This study enhances our understanding of the intricate processes governing gas and star formation in early galaxies, particularly in the context of gravitational lensing, which allows us to observe and analyze these distant cosmic phenomena in unprecedented detail.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.608176875690327,
        "rewrite-fast-z-score": 2.620712091804796
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gravitational instability in binary protoplanetary disks .\nAbstract:\nWe study the gravitational instability (GI) in two differentially rotating, self-gravitating disks with and without magnetic fields using three-dimensional hydrodynamic simulations. We find that GI can occur at large radii for both cases but is suppressed by strong magnetic fields near the central star. The disk mass required to trigger GI decreases as the radius increases because the Toomre Q parameter becomes smaller due to weaker stellar gravity. For the case without magnetic fields, we also investigate how the initial density distribution affects the growth rate of GI. Our results show that the growth time scale depends on the radial profile of surface density. In addition, we examine whether or not GI leads to fragmentation. Fragmentation occurs only when the disk has an initially steep surface density gradient. Finally, we discuss possible implications of our findings for planet formation. Gravitational instability (GI), which causes spiral arms to form in gravitationally bound systems such as galaxies, may play important roles in various astrophysical phenomena including planet formation. However, it remains unclear if GI operates in protoplanetary disks around young stars since these disks are magnetized and their rotation profiles are complicated. Here, we perform 3D hydrodynamical simulations to explore this issue.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Gravitational disturbance in binary protoplanetary disks . Abstract : We research the gravitational instability ( GI ) in two differentially rotating , self - gravitating disks with and without magnetic fields using three - dimensional hydrodynamic simulations .We see that GI can occur at large radii for both cases but is suppressed by weak magnetic fields near the main star . The disk mass needed to stimulate GI decreases as the radius increases because the Toomre Q function becomes lower due to smaller stellar gravitational .For the case without magnetic fields , we also investigate how the early density distribution influences the development frequency of GI . Our results show that the development time scale depends on the radial profile of surface density .In addition , we investigate whether or not GI contributes to fragmentation . Fragmentation happens only when the disk has an initially steep surface volume differential .Finally , we explain possible implications of our findings for planet development . Gravitational instability ( GI ) , which allows spiral arms to form in gravitationally locked components such as planets , might play important roles in different astrophysical processes including planet development .However , it remains unsure if GI exists in protoplanetary disks around young galaxies since these disks are magnetized and their rotation profiles are complicated . Here , we perform 3D hydrodynamical simulations to examine this question .",
        "rewrite_text": "**Title:** Gravitational Disturbance in Binary Protoplanetary Disks\n\n**Abstract:** This study investigates the phenomenon of gravitational instability (GI) within two differentially rotating, self-gravitating disks, both with and without magnetic fields, through the use of three-dimensional hydrodynamic simulations. Our findings indicate that GI can manifest at larger radii in both scenarios; however, the presence of weak magnetic fields near the central star tends to suppress this instability. Notably, the mass of the disk required to trigger GI decreases with increasing radius, attributed to a reduction in the Toomre Q parameter caused by diminished stellar gravitational influence. In the absence of magnetic fields, we further explore how the initial density distribution of the disk affects the frequency of GI development. Our results reveal that the time scale for GI emergence is influenced by the radial surface density profile. Additionally, we assess the role of GI in the fragmentation process of the disk. Fragmentation is observed to occur only when the disk possesses a steep initial surface volume differential. We also discuss the broader implications of our findings for planetary formation. Gravitational instability, which facilitates the formation of spiral arms in gravitationally bound systems such as planets, is likely to play a significant role in various astrophysical processes, including the development of planets. However, the existence of GI in protoplanetary disks surrounding young galaxies remains uncertain due to the complexities introduced by magnetic fields and intricate rotation profiles. Through our comprehensive 3D hydrodynamic simulations, we aim to shed light on this critical aspect of disk dynamics and its implications for planet formation.",
        "ori-fast-z-score": -1.4237369936287485,
        "water-fast-z-score": 5.550253123463223,
        "rewrite-fast-z-score": -0.4472135954999579
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Droplets in the two-dimensional +-J spin glass: evidence for (non-) universality .\nAbstract:\nWe study droplet excitations in the 2D spin-glass model with nearest-neighbor interactions and random ferromagnetic bonds, which is known to have an infinite number of metastable states at zero temperature. We show that this system has two different types of droplets: small ones are similar to those found in other models studied previously; large droplets are characterized by their fractal structure. The latter type can be viewed as a generalization of the droplet picture proposed earlier for the 3D Ising spin glasses. In addition we find that there exists another class of excitations -the so-called  giant droplets -which are not present in any of these systems. These giant droplets are responsible for the non-universal behavior observed numerically near the critical point. Finally, we argue that our results provide strong numerical support for the existence of a new phase transition line between the paramagnetic state and the spin-glass one. \nI. INTRODUCTORY REMARK\nThe concept of  droplet excitations  was introduced originally within the framework of the mean-field theory  1  . It describes how local perturbations affect global properties of the system. This idea turned out to be very useful when applied to various disordered systems such as spin glasses  2  , structural glasses  3  or vortex lattices  4  .\nIn particular it allowed to explain many features of the low-temperature thermodynamics of spin glasses  5  . However, despite its successes, the original droplet picture suffers from some serious drawbacks  6  : first, it does not take into account fluctuations around the saddle-point solution  7 ; secondly, it predicts a finite density of droplets even at T = 0  8  ; thirdly, it cannot describe properly the dynamics of the system  9  . To overcome these difficulties several modifications were suggested  10  . One of them  11  leads to the following expression for the free energy F(T ) per site: \nwhere f0 is the free-energy density of the reference system (e.g., the pure ferromagnet), Ns is the total number of spins, V is the volume occupied by each droplet",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Droplets in the two - dimensional + - J spin mirror : evidence for ( non - ) universality . Abstract : We research droplet excitations in the 2D spinning - glass model with nearest - neighbor interactions and random ferromagnetic bonds , which is known to have an endless number of metastable states at zero temperature .We see that this scheme has two different kinds of droplets : tiny ones are related to those present in other models studied ago ; wide droplets are marked by their fractal structure . The latter type can be viewed as a generalization of the droplet picture suggested earlier for the 3D Ising spin glasses .In addition we find that there exists another class of excitations - the so - called giant droplets - which are not present in any of these systems . These huge droplets are responsible for the non - universal behavior observed numerically near the critical position .Finally , we claim that our findings provide strong mathematical support for the existence of a new phase shift line between the paramagnetic state and the spin - glass one . I .INTRODUCTORY REMARK The concept of droplet excitations was introduced originally within the framework of the mean - field principle 1 . It details how local perturbations impact global properties of the system .This idea turned out to be very useful when applied to numerous disordered systems such as spin glasses 2 , structural glasses 3 or vortex lattices 4 . In particular it able to explain different properties of the small - temperature thermodynamics of spin glasses 5 .However , despite its successes , the original droplet picture suffers from some serious drawbacks 6 : first , it does not take into consideration fluctuations around the saddle - point problem 7 ; secondly , it predicts a finite density of droplets even at T = 0 8 ; thirdly , it lacks explain adequately the dynamics of the system 9 . To solve these problems several amendments were recommended 10 .One of them 11 leads to the following expression for the free energy F ( T ) per site : where f0 is the free - energy density of the reference system ( e . g . , the pure ferromagnet ) , Ns is the total number of spinning , V is the volume occupied by each droplet",
        "rewrite_text": "**Title:** Droplets in the Two-Dimensional ±J Spin Mirror: Evidence for (Non-)Universality\n\n**Abstract:** This study investigates droplet excitations within the two-dimensional spin-glass model characterized by nearest-neighbor interactions and random ferromagnetic bonds, a system known for its infinite number of metastable states at absolute zero temperature. Our findings reveal the existence of two distinct types of droplets: small droplets that resemble those identified in previously studied models, and larger droplets distinguished by their fractal geometry. The latter category serves as a broader interpretation of the droplet framework proposed for three-dimensional Ising spin glasses. Furthermore, we identify a novel class of excitations termed \"giant droplets,\" which are absent in other systems. These giant droplets play a crucial role in the non-universal behavior observed numerically in proximity to the critical point. Our results lend substantial mathematical support to the hypothesis of a new phase transition line separating the paramagnetic phase from the spin-glass phase.\n\nThe concept of droplet excitations was initially introduced within the mean-field theory framework, illustrating how localized perturbations can influence the overall characteristics of a system. This concept has proven valuable in explaining various properties of disordered systems, including spin glasses, structural glasses, and vortex lattices, particularly in elucidating the thermodynamic behavior at low temperatures. However, the original droplet model has notable limitations: it overlooks fluctuations around saddle points, predicts a finite density of droplets at zero temperature, and inadequately describes the system's dynamics. To address these shortcomings, several modifications have been proposed, one of which leads to a refined expression for the free energy per site. This expression incorporates the free energy density of a reference system, the total number of spins, and the volume occupied by each droplet, thereby enhancing our understanding of droplet dynamics in disordered systems.",
        "ori-fast-z-score": 0.6446583712203042,
        "water-fast-z-score": 7.205766921228921,
        "rewrite-fast-z-score": 2.242227956050979
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Positronium Groundstate in Relativistic Schroedinger Theory .\nAbstract:\nWe present the results for positronium ground state energy and wave function obtained by solving relativistic Schrödinger equation with Coulomb potential using variational method. The calculations are performed within two different approximations, namely nonrelativistic limit (NR) and first order perturbation theory (PT1). In NR approximation we use Hylleraas type trial wave functions which include spin dependent terms up to second power of inter particle distance. We also calculate the expectation value of kinetic energy operator using this wave function. In PT1 approximation we use Hyllraas type trial wave functions including spin dependent terms up to third power of inter particle distance alongwith one electron Dirac orbitals as basis set. Our calculated values of binding energies agree well with those reported earlier. \n\n\nThe author is grateful to Prof. S. K. Gupta, Director General, BARC, Mumbai for his encouragement during the course of work on this project.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Positronium Groundstate in Relativistic Schroedinger Theory . Abstract : We present the results for positronium ground state energy and wave function achieved by treating relativistic Schrödinger equation with Coulomb potential using variational technique .The calculations are performed within two different approximations , namely nonrelativistic limit ( NR ) and first order perturbation theory ( PT1 ) . In NR algorithm we using Hylleraas type trial wave functions which contain spin dependent terms up to second power of inter quantum distance .We also obtain the expectation value of kinetic energy operator using this wave function . In PT1 approximation we using Hyllraas type trial wave functions featuring spin dependent terms up to third power of inter quantum time alongwith one particle Dirac orbitals as basis set .Our measured calculations of bound energies agree well with those published earlier . The author is thankful to Prof . S . K . Gupta , Director General , BARC , Mumbai for his encouragement during the course of research on this project .",
        "rewrite_text": "In this article, we investigate the ground state energy and wave function of positronium by applying the relativistic Schrödinger equation in the presence of a Coulomb potential, utilizing a variational approach. Our study employs two distinct approximations: the nonrelativistic limit (NR) and first-order perturbation theory (PT1). In the NR framework, we utilize Hylleraas-type trial wave functions that incorporate spin-dependent terms up to the second power of the inter-quantum distance. This allows us to compute the expectation value of the kinetic energy operator effectively. For the PT1 approximation, we extend our approach by employing Hylleraas-type trial wave functions that include spin-dependent terms up to the third power of the inter-quantum distance, alongside one-particle Dirac orbitals as our basis set. The results obtained for the bound energies are consistent with previously published findings, demonstrating the reliability of our methods. We express our gratitude to Prof. S. K. Gupta, Director General of BARC, Mumbai, for his invaluable support and encouragement throughout the research process. This work contributes to the understanding of positronium in a relativistic context and highlights the effectiveness of variational techniques in quantum mechanics.",
        "ori-fast-z-score": -1.193117518002609,
        "water-fast-z-score": 2.711630722733202,
        "rewrite-fast-z-score": -1.7056057308448833
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Formation and Collisional Evolution of Kuiper Belt Objects .\nAbstract:\nThe Kuiper belt is the source region for most short period comets, but its formation remains poorly understood. We present results from N-body simulations that show how collisions among planetesimals in Neptune s feeding zone can produce objects with orbits similar to those observed today. The initial conditions are based on models of planet migration during which Neptune migrated outward by about 30 AU before being halted at its current location. Our calculations suggest that the Kuiper belt formed as a result of collisional grinding between bodies whose sizes were comparable to Pluto (r ~ 1000 km). This process produced a population of small bodies with orbital eccentricities ranging up to 0.3. Subsequent encounters with Neptune caused some of these bodies to be scattered into highly eccentric orbits. These results provide an explanation for why there appears to be no correlation between the size distribution of KBOs and their orbital eccentricity.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Formation and Collisional Evolution of Kuiper Belt Objects . Abstract : The Kuiper belt is the origin region for most short period comets , but its formation appears poorly studied .We present results from N - bodies simulations that demonstrate how collisions among planetesimals in Neptune s feeding area can generate objects with orbits similar to those observed nowadays . The initial conditions are based on estimates of planet migration during which Neptune migrated outward by about 30 AU before being stopped at its current site .Our calculations suggest that the Kuiper belt developed as a outcome of collisional crushing between bodies whose sizes were analogous to Pluto ( r ~ 1000 kilometers ) . This process produced a population of tiny bodies with orbital eccentricities ranging up to 0 . 3 .Subsequent experiences with Neptune resulted some of these objects to be scattered into extremely eccentric orbits . These data provide an reason for why there seems to be no correlation between the size distribution of KBOs and their orbital eccentricity .",
        "rewrite_text": "**Title: Formation and Collisional Evolution of Kuiper Belt Objects**\n\n**Abstract:** The Kuiper Belt serves as the primary source region for most short-period comets; however, its formation has not been extensively explored. In this study, we present findings from N-body simulations that illustrate how collisions among planetesimals in the vicinity of Neptune can lead to the creation of objects with orbital characteristics akin to those observed today. Our simulations are grounded in initial conditions that reflect the estimated migration of Neptune, which is believed to have moved outward by approximately 30 AU before stabilizing at its current position. The results indicate that the Kuiper Belt formed as a result of collisional fragmentation among bodies with sizes comparable to that of Pluto (approximately 1000 kilometers in radius). This collisional process resulted in a population of smaller bodies exhibiting a range of orbital eccentricities, reaching up to 0.3. Furthermore, interactions with Neptune subsequently scattered some of these bodies into highly eccentric orbits. Our findings offer an explanation for the apparent lack of correlation between the size distribution of Kuiper Belt Objects (KBOs) and their orbital eccentricities. This research enhances our understanding of the dynamic processes that shaped the Kuiper Belt and provides insights into the evolutionary history of its constituent objects. By elucidating the mechanisms behind the formation and collisional evolution of KBOs, we contribute to the broader knowledge of planetary formation and the early solar system's architecture.",
        "ori-fast-z-score": -1.2874526191574363,
        "water-fast-z-score": 4.73427220735493,
        "rewrite-fast-z-score": 0.7107423155935334
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The influence of horizontal gene transfer on the mean fitness of unicellular populations in static environments .\nAbstract:\nHorizontal Gene Transfer (HGT) is an important evolutionary force that can increase genetic diversity and accelerate evolution, but it also has negative effects such as disrupting co-adapted gene complexes or introducing deleterious mutations into recipient genomes. In this study we investigate how HGT affects the mean fitness of unicells evolving under different environmental conditions using computational models. We find that HGT increases the mean fitness when cells are exposed to fluctuating environments with high levels of stressful events. However, if there are only mild fluctuations then HGT decreases the mean fitness because it introduces harmful mutations. Finally, for constant environments without any external stresses, HGT does not affect the mean fitness at all. Our results suggest that HGT may have played an important role during early stages of life s evolution by increasing its adaptability to changing environments. Horizontal Gene Transfer (HGT), which occurs between organisms sharing similar DNA sequences, is one of the most significant evolutionary forces known today  1  . It allows rapid acquisition of new genes and thus contributes to increased genetic diversity within species  2  , accelerates evolution  3  , and facilitates adaptation  4  .\nHowever, HGT also has some disadvantages including disruption of co-adapted gene complexes  5  and introduction of deleterious mutations  6  . Therefore, understanding the effect of HGT on population dynamics requires careful investigation  7, 8  . Previous studies suggested that HGT could be beneficial for populations living in fluctuating environments  9  while detrimental for those inhabiting stable ones  10  . Here we use computational models to explore these hypotheses further and show that HGT can either increase or decrease the mean fitness depending on the type of environment inhabited by the cell population.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The impact of horizontal gene transfer on the mean fitness of unicellular populations in static environments . Abstract : Horizontal Gene Transfer ( HGT ) is an important genetic force that can increase genetic diversity and accelerate evolution , but it also has negative impacts such as disrupting co - adapted gene structures or introducing deleterious variants into recipient genomes .In this study we investigate how HGT affects the mean fitness of unicells evolving under various environmental conditions utilizing computational models . We see that HGT changes the mean fitness when cells are exposed to fluctuating environments with high levels of stressful events .However , if there are only slight fluctuations then HGT decreases the mean fitness because it creates harmful mutations . Finally , for constant environments without any external stresses , HGT does not alter the mean fitness at all .Our results show that HGT could have played an important role during initial stages of life s evolution by increasing its adaptability to changing settings . Horizontal Gene Transfer ( HGT ) , which occurs between organisms sharing related DNA sequences , is one of the most significant evolutionary forces known today 1 .It enables quick acquisition of new genes and therefore contributes to greater genetic diversity within genus 2 , accelerates development 3 , and facilitates adaptation 4 . However , HGT also has some disadvantages notably loss of co - adapted gene structures 5 and entry of deleterious variants 6 .Therefore , studying the impact of HGT on population behavior needs thorough investigation 7 , 8 . Previous studies suggested that HGT could be beneficial for individuals living in fluctuating environments 9 while detrimental for those inhabiting stable ones 10 .Here we using computational models to examine these hypotheses further and suggest that HGT can either increase or decrease the mean fitness depending on the kind of environment populated by the cell population .",
        "rewrite_text": "**Title:** The Impact of Horizontal Gene Transfer on the Mean Fitness of Unicellular Populations in Static Environments\n\n**Abstract:** Horizontal Gene Transfer (HGT) is a crucial mechanism in evolutionary biology that enhances genetic diversity and accelerates the evolutionary process. However, it can also have detrimental effects, such as disrupting co-adapted gene complexes and introducing harmful mutations into the genomes of recipient organisms. This study explores the influence of HGT on the mean fitness of unicellular populations under varying environmental conditions through the use of computational modeling. Our findings indicate that HGT significantly alters mean fitness in environments characterized by frequent and intense stressors. In contrast, in environments with only minor fluctuations, HGT tends to reduce mean fitness due to the introduction of deleterious mutations. Notably, in stable environments devoid of external stress, HGT does not appear to affect mean fitness at all. These results suggest that HGT may have been a pivotal factor in the early stages of life's evolution, enhancing adaptability to dynamic environments. HGT, which facilitates the transfer of genetic material between organisms with similar DNA sequences, is recognized as one of the most influential evolutionary forces. It allows for the rapid acquisition of new genes, thereby fostering genetic diversity, accelerating evolutionary development, and promoting adaptation. Nonetheless, the potential drawbacks of HGT, such as the disruption of co-adapted gene structures and the introduction of harmful genetic variants, necessitate a comprehensive examination of its effects on population dynamics. Previous research has indicated that HGT may confer advantages to organisms in fluctuating environments while posing risks to those in stable settings. This study employs computational models to further investigate these hypotheses, revealing that the impact of HGT on mean fitness is contingent upon the specific environmental context inhabited by the unicellular populations.",
        "ori-fast-z-score": 1.1430952132988164,
        "water-fast-z-score": 7.033533126053657,
        "rewrite-fast-z-score": 1.8864844365675972
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Anisotropic Distribution of Satellite Galaxies .\nAbstract:\nWe present the results of an analysis of the anisotropy in the distribution of satellite galaxies around isolated field galaxies, using data obtained by the Sloan Digital Sky Survey (SDSS). We find that there is no significant difference between the distributions for satellites with different luminosities or colors and those found around central cluster galaxies. The observed anisotropies are consistent with predictions based on tidal forces acting during galaxy mergers. This suggests that these effects may be responsible for the formation of both clusters and groups of galaxies. \n \n Keywords: Galaxy merger, Group/cluster of galaxies, Tidal stripping, SDSS, Isolated galaxy \n \n \n \n 1 Introduction \n \n Clusters of galaxies contain many thousands of galaxies which reside within a common dark matter halo. These systems form through gravitational collapse driven by the mutual attraction of their constituent galaxies. However, it remains unclear how this process occurs over time-scales ranging from individual galaxy interactions to the assembly of massive clusters containing hundreds of member galaxies. In particular, we do not know whether all galaxies evolve into members of large clusters or if some fraction remain as isolated field galaxies throughout cosmic history. \n \n 2 Previous Work \n \n Several studies have investigated the properties of satellite galaxies surrounding brightest cluster galaxies (BCGs) at low redshifts z < 0.1. For example, Carlberg et al. (1997), Lin & Mohr (2004a), and Hansen et al. (2005) used samples of BCG-satellite pairs selected from optical surveys such as the Palomar Observatory Sky Survey (POSS-II; Reid et al., 1991) and the Sloan Digital Sky Surveys (SDSS; York et al., 2000). They found that the number density profiles of satellite galaxies show strong deviations from spherical symmetry, indicating that they are distributed anisotropically about their host galaxies. Furthermore, they showed that the degree of anisotropy depends strongly on the projected distance from the center of the host galaxy. At small distances, the radial profile shows a steep decline towards the center of the host while the tangential component increases rapidly beyond a characteristic radius R",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Anisotropic Distribution of Satellite Galaxies . Abstract : We present the conclusion of an assessment of the anisotropy in the distribution of satellite galaxies around isolated field galaxies , using data acquired by the Sloan Digital Sky Survey ( SDSS ) .We see that there is no major variation between the distributions for satellites with various luminosities or colors and those present around central cluster clusters . The observed anisotropies are compatible with predictions based on tidal forces working during galaxy mergers .This implies that these influences might be responsible for the formation of both clusters and groups of galaxies . Keywords : Galaxy consolidation , Group / cluster of galaxies , Tidal stripping , SDSS , Isolated galaxy 1 Introduction Clusters of galaxies contain many thousands of galaxies which reside within a common dark matter halo .These systems emerge through gravity collapse driven by the mutual proximity of their constituent galaxies . However , it remains unsure how this process occurs over time - scales ranging from individual galaxy encounters to the assembly of large clusters containing hundreds of member galaxies .In particular , we do not understand whether all galaxies evolve into members of large clusters or if some fraction remain as isolated field galaxies throughout cosmic life . 2 Previous Work Several studies have researched the properties of satellite galaxies surrounding brightest cluster clusters ( BCGs ) at low redshifts z < 0 . 1 .For instance , Carlberg et al . ( 1997 ) , Lin & Mohr ( 2004a ) , and Hansen et al .( 2005 ) used samples of BCG - satellite pairs selected from optical searches such as the Palomar Observatory Sky Survey ( POSS - II ; Reid et al . , 1991 ) and the Sloan Digital Sky Surveys ( SDSS ; York et al . , 2000 ) . They found that the number density profiles of satellite galaxies show strong deviations from spherical symmetry , showing that they are distributed anisotropically about their host galaxies .Furthermore , they demonstrated that the degree of anisotropy depends strongly on the projected distance from the center of the host galaxy . At small distances , the transverse profile displays a sharp decline towards the center of the host while the tangential component increases quickly beyond a typical radius R",
        "rewrite_text": "**Title: The Anisotropic Distribution of Satellite Galaxies**\n\n**Abstract:** In this study, we investigate the anisotropic distribution of satellite galaxies surrounding isolated field galaxies, utilizing data from the Sloan Digital Sky Survey (SDSS). Our analysis reveals that there is no significant difference in the distribution patterns of satellites based on varying luminosities or colors when compared to those found around central cluster galaxies. The anisotropies we observe align with theoretical predictions that suggest tidal forces during galaxy mergers play a crucial role in shaping these distributions. This finding indicates that such tidal interactions may significantly influence the formation processes of both galaxy clusters and groups. \n\nThe formation of galaxy clusters, which can host thousands of galaxies within a shared dark matter halo, is primarily driven by gravitational collapse resulting from the close proximity of their constituent galaxies. However, the mechanisms governing this process over time, from individual galaxy interactions to the assembly of extensive clusters, remain poorly understood. A key question is whether all galaxies ultimately become part of large clusters or if a subset persists as isolated field galaxies throughout cosmic history.\n\nPrevious research has focused on the characteristics of satellite galaxies surrounding the brightest cluster galaxies (BCGs) at low redshifts (z < 0.1). Noteworthy studies by Carlberg et al. (1997), Lin & Mohr (2004a), and Hansen et al. (2005) have utilized BCG-satellite pair samples derived from optical surveys, including the Palomar Observatory Sky Survey (POSS-II) and the SDSS. Their findings indicate that the number density profiles of satellite galaxies exhibit significant deviations from spherical symmetry, confirming an anisotropic distribution around their host galaxies. Furthermore, they established that the degree of anisotropy is closely related to the projected distance from the host galaxy's center, with a pronounced decline in the transverse profile at smaller distances, while the tangential component increases sharply beyond a characteristic radius. \n\n**Keywords:** Galaxy formation, Galaxy groups/clusters, Tidal stripping, SDSS, Isolated galaxies.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.437961803049794,
        "rewrite-fast-z-score": 0.5551361100027009
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dark Energy and Gravity .\nAbstract:\nThe universe is expanding at an accelerating rate, which has been attributed to  dark energy .  This article reviews the current status of research into dark energy by examining some recent observational results in this area.   The author concludes that there are still many open questions about how best to explain these observations within general relativity theory. In particular, it remains unclear whether or not the observed acceleration can be explained as being due solely to gravitational effects associated with the presence of dark energy. It also appears likely that new physics will need to be introduced if we wish to understand why the expansion of space-time should accelerate rather than decelerate over time. The universe is expanding at an accelerated rate, which has been interpreted as evidence for the existence of  dark energy  (DE). This article examines some recent observational results on DE using supernovae Ia data, cosmic microwave background radiation measurements, baryon acoustic oscillations, galaxy cluster counts, weak lensing surveys, and Hubble parameter determinations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dark Energy and Gravity . Abstract : The universe is growing at an accelerating rate , which has been attributed to dark energy .This page reviews the recent status of research into dark energy by examining some latest observational results in this area . The author concludes that there are still many open questions about how best to explain these observations within general relativity theory .In particular , it remains unsure whether or not the seen acceleration can be understood as being owing purely to gravitational influences associated with the presence of dark energy . It additionally seems likely that new science will need to be introduced if we wish to explain why the evolution of space - time should accelerate rather than decelerate over time .The universe is growing at an accelerated pace , which has been viewed as proof for the existence of dark energy ( DE ) . This page discusses some latest observational results on DE utilizing supernovae Ia evidence , cosmic microwave background radiation observations , baryon acoustic oscillations , galaxy cluster counts , soft lensing surveys , and Hubble parameter determinations .",
        "rewrite_text": "**Title: Dark Energy and Gravity**\n\n**Abstract:** The accelerating expansion of the universe has been a pivotal observation in cosmology, leading to the hypothesis of dark energy (DE) as a driving force behind this phenomenon. This article provides a comprehensive review of the current state of research on dark energy, focusing on recent observational findings that contribute to our understanding of this enigmatic component of the cosmos. Key evidence is drawn from various sources, including Type Ia supernovae, cosmic microwave background radiation measurements, baryon acoustic oscillations, galaxy cluster surveys, weak gravitational lensing studies, and determinations of the Hubble parameter. Despite the wealth of data, significant questions remain regarding the interpretation of these observations within the framework of general relativity. In particular, it is still uncertain whether the observed acceleration of the universe can be solely attributed to gravitational effects linked to dark energy. Furthermore, the article posits that a new scientific paradigm may be necessary to elucidate the reasons behind the observed acceleration of space-time, as opposed to a decelerating trend that would be expected under conventional gravitational theories. The ongoing exploration of dark energy not only challenges our current understanding of gravity but also invites further investigation into the fundamental nature of the universe. As research progresses, it is crucial to address these unresolved issues to enhance our comprehension of cosmic evolution and the role of dark energy in shaping the universe's fate.",
        "ori-fast-z-score": -1.0425720702853738,
        "water-fast-z-score": 5.288453643125169,
        "rewrite-fast-z-score": -0.4622501635210242
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spin Effects in Quantum Chromodynamics and Recurrence Lattices with Multi-Site Exchanges .\nAbstract:\nWe study spin effects on the lattice QCD using recurrence lattices (RL) with multi-site exchanges, which are constructed by applying the RL transformation to the original fermion action. We show that the spin dependence is suppressed for large quark masses but not completely removed even at mq = 5 GeV. The residual spin dependence can be reduced further if we use larger number of sites in the exchange term. In this work, we adopt Ns = 4 as an example. We also find that the spin dependent part of the effective potential has no imaginary part up to O(a^4). This implies that there exists no spontaneous breaking of chiral symmetry due to spin effects within our framework. Finally, we discuss possible extensions of our method. PACS numbers: 11.15.Ha, 12.38.Gc, 13 .25.Hw \nI. INTRODUCTORY REMARK\nIn recent years, it was found that the standard Wilson-type fermions suffer from severe problems such as the so-called species doubling problem  1  , the Nielsen-Ninomiya theorem  2  , and the Gribov copy problem  3  . These difficulties have been overcome by introducing new types of fermionic actions  4  -  8  .\nThe most popular one among them is probably the overlap-Dirac operator  9  , whose eigenfunctions satisfy the Ginsparg-Wilson relation  10  . However, its numerical cost grows rapidly when the lattice volume becomes large because the inverse of the Dirac operator must be calculated exactly. To reduce the computational costs, several approximate methods were proposed  11  -  13  . Among these approaches, the Neuberger overlap operator  14  seems to be the best choice so far  15  .\nAnother promising approach is based on the idea of the exact renormalization group  16  . It was shown  17  that the fermion determinant detD(μ), where D(μ) denotes the fermion matrix defined through the fermion action Sf  U  ≡ ∑x Tr γμD(μ)Ux , satisfies the following flow equation:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spin Effects in Quantum Chromodynamics and Recurrence Lattices with Multi - Site Exchanges . Abstract : We research spin effects on the lattice QCD using recurrence lattices ( RL ) with multi - location exchanges , which are built by using the RL shift to the previous fermion action .We see that the spin dependence is suppressed for large quark masses but not totally eliminated even at mq = 5 GeV . The excess spin dependence can be reduced further if we using larger number of places in the transfer term .In this study , we adopt Ns = 4 as an instance . We additionally find that the spin dependent part of the effective potential has no imaginary part up to O ( a ^ 4 ) .This implies that there exists no premature breaking of chiral symmetry attributed to spin effects within our framework . Finally , we explain possible extensions of our technique .PACS numbers : 11 . 15 . Ha , 12 . 38 . Gc , 13 . 25 . Hw I . INTRODUCTORY REMARK In recent years , it was shown that the standard Wilson - class fermions suffer from severe problems such as the so - called genus doubling problem 1 , the Nielsen - Ninomiya conjecture 2 , and the Gribov copies problem 3 .These difficulties have been overcome by introducing novel sorts of fermionic operations 4 - 8 . The most popular one among them is probably the overlap - Dirac operator 9 , whose eigenfunctions satisfy the Ginsparg - Wilson relation 10 .However , its numerical cost rises steadily when the crystal volume becomes large because the inverse of the Dirac operator must be determined exactly . To reduce the theoretical costs , various approximate approaches were recommended 11 - 13 .Among these proposals , the Neuberger overlap operator 14 seems to be the best choice so far 15 . Another promising solution is based on the idea of the exact renormalization group 16 .It was shown 17 that the fermion determinant detD ( μ ) , where D ( μ ) denotes the fermion matrix established through the fermion action Sf U ≡ [UNK] Tr γμD ( μ ) Ux , satisfies the following fluid equation :",
        "rewrite_text": "**Title:** Spin Effects in Quantum Chromodynamics and Recurrence Lattices with Multi-Site Exchanges\n\n**Abstract:** This study investigates the influence of spin effects within lattice Quantum Chromodynamics (QCD) by employing recurrence lattices (RL) that incorporate multi-site exchanges. These lattices are constructed by applying the RL shift to the preceding fermion action. Our findings indicate that while the spin dependence diminishes with increasing quark masses, it is not entirely absent even at a mass of mq = 5 GeV. Notably, we observe that the spin dependence can be further mitigated by utilizing a greater number of sites in the transfer term, with Ns = 4 being utilized as a representative case in our analysis. Additionally, we establish that the spin-dependent component of the effective potential remains devoid of an imaginary part up to O(a^4), suggesting that our framework does not lead to premature chiral symmetry breaking due to spin effects. We also discuss potential avenues for extending our methodology. \n\nIn the context of recent advancements, it has been recognized that standard Wilson-class fermions encounter significant challenges, including the genus doubling problem, the Nielsen-Ninomiya theorem, and issues related to Gribov copies. These complications have been addressed through the introduction of innovative fermionic operations. Among these, the overlap-Dirac operator has gained prominence, as its eigenfunctions adhere to the Ginsparg-Wilson relation. However, the computational demands of this operator escalate with larger crystal volumes due to the necessity for precise determination of the inverse Dirac operator. To alleviate these theoretical burdens, various approximate methods have been proposed, with the Neuberger overlap operator emerging as a leading candidate. Another promising approach involves the application of the exact renormalization group, which has been shown to yield a fluid equation for the fermion determinant, denoted as detD(μ), where D(μ) represents the fermion matrix derived from the fermion action. This work contributes to the ongoing discourse on enhancing the computational efficiency and theoretical robustness of lattice QCD methodologies. \n\n**PACS numbers:** 11.15.Ha, 12.38.Gc, 13.25.Hw",
        "ori-fast-z-score": -0.939793423488437,
        "water-fast-z-score": 6.639800939918239,
        "rewrite-fast-z-score": 0.8574929257125441
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Improving Intrinsic Decoherence in Multi-Quantum-Dot Charge Qubits .\nAbstract:\nWe report on the fabrication and characterization of charge qubits based on self-assembled InAs quantum dots (QDs) embedded in GaAs/AlGaAs heterostructures. We show that by using an optimized growth procedure, we can achieve high quality QD layers with low density of defects which are crucial for achieving good coherence times. The samples were grown by molecular beam epitaxy at 600 °C under As-rich conditions to minimize the formation of threading dislocations. A single layer of self-assembled InAs/GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm thick Al0.3Ga0.7As barrier layer. Finally, a 20 nm thick GaAs capping layer was deposited. The sample structure is shown schematically in Figure 1 . The photoluminescence spectrum shows emission peaks centered around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states associated with charged excitons.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Improving Intrinsic Decoherence in Multi - Quantum - Dot Charge Qubits . Abstract : We report on the fabrication and description of charge qubits based on self - assembled InAs quantum dots ( QDs ) integrated in GaAs / AlGaAs heterostructures .We see that by using an optimized growth technique , we can attain high quality QD layers with minimal concentration of defects which are important for achieving better coherence times . The samples were grown by molecular beam epitaxy at 600 °C under As - rich conditions to minimize the formation of threading dislocations .A single layer of self - assembled InAs / GaAs QDs was formed after annealing at 650 °C for 10 s followed by deposition of a 50 nm wide Al0 . 3Ga0 . 7As barrier layer . Finally , a 20 nm wide GaAs capping layer was deposited .The sample structure is displayed schematically in Figure 1 . The photoluminescence spectrum displays emission levels focused around 1280 nm corresponding to ground state excitonic transitions of individual QDs as well as higher energy states correlated with charged excitons .",
        "rewrite_text": "We present a detailed study on the development and characterization of charge qubits utilizing self-assembled InAs quantum dots (QDs) integrated within GaAs/AlGaAs heterostructures. Our research demonstrates that by employing an optimized growth technique, we can produce high-quality QD layers with a significantly reduced defect concentration, which is crucial for enhancing coherence times in quantum computing applications. The quantum dot samples were synthesized using molecular beam epitaxy at a temperature of 600 °C under arsenic-rich conditions, a method chosen to effectively minimize the occurrence of threading dislocations that can adversely affect qubit performance. Following this, a single layer of self-assembled InAs/GaAs QDs was achieved through a brief annealing process at 650 °C for 10 seconds, after which a 50 nm thick Al0.3Ga0.7As barrier layer was deposited to further isolate the quantum dots. To complete the structure, a 20 nm GaAs capping layer was added. The resulting sample architecture is illustrated schematically in Figure 1. Photoluminescence measurements reveal emission peaks centered around 1280 nm, which correspond to the ground state excitonic transitions of individual quantum dots, alongside higher energy emissions associated with charged excitons. This work not only highlights the advancements in the fabrication of charge qubits but also underscores the importance of material quality in achieving longer coherence times, paving the way for more robust quantum computing systems.",
        "ori-fast-z-score": -0.4588314677411235,
        "water-fast-z-score": 2.8490144114909484,
        "rewrite-fast-z-score": -0.29002094671369905
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Using Images to create a Hierarchical Grid Spatial Index .\nAbstract:\nWe present an algorithm for creating a hierarchical grid spatial index using images as the basis for its construction.  The algorithm is based on the observation that many real-world datasets are naturally represented by images, and can be used in conjunction with existing techniques such as R-tree or Quadtree to improve performance.   We show how our technique performs against these other methods through experiments conducted over synthetic data sets generated according to different distributions (uniform, normal, exponential) and sizes ranging between 1K and 100M points.   Our results demonstrate significant improvements in query response times when compared to traditional approaches. In this work we propose a new approach for building a spatial index which uses image processing algorithms to extract information about the dataset being indexed. This information is then used to build a hierarchy of grids whose leaf nodes contain pointers to individual objects within the dataset. These grids provide efficient access to all objects contained therein while also allowing fast queries across multiple grids at once.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Using Images to create a Hierarchical Grid Spatial Index . Abstract : We create an algorithm for constructing a hierarchical grid geographic indicator employing images as the foundation for its design .The algorithm is based on the observation that several real - world datasets are naturally represented by pictures , and can be used in partnership with existing techniques such as R - tree or Quadtree to improve performance . We see how our technique performs against these other methods through experiments conducted over synthetic information sets generated according to different distributions ( uniform , normal , exponential ) and dimensions ranging between 1K and 100M points .Our results show considerable improvements in query reply times when compared to conventional approaches . In this project we propose a new approach for building a spatial indicator which uses image processing algorithms to extract information about the dataset being indexed .This knowledge is then utilized to build a hierarchy of grids whose leaf nodes contain pointers to individual objects within the dataset . These grids allow faster entry to all items contained therein while also enabling rapid queries across multiple grids at once .",
        "rewrite_text": "Title: Utilizing Images to Develop a Hierarchical Grid Spatial Index\n\nAbstract: In this study, we present a novel algorithm designed to construct a hierarchical grid geographic index, leveraging images as the foundational element of its architecture. Our approach is predicated on the insight that numerous real-world datasets can be effectively represented through visual imagery. By integrating image processing techniques with established spatial indexing methods such as R-trees and Quadtrees, we aim to enhance overall performance. We evaluate the efficacy of our proposed method through a series of experiments conducted on synthetic datasets, which were generated according to various distributions, including uniform, normal, and exponential, with point counts ranging from 1,000 to 100 million. The experimental results indicate significant improvements in query response times when juxtaposed with traditional indexing techniques. \n\nOur innovative approach involves employing image processing algorithms to extract pertinent information from the datasets being indexed. This extracted knowledge is subsequently utilized to construct a hierarchical grid structure, where the leaf nodes are linked to individual objects within the dataset. This hierarchical grid system facilitates expedited access to all contained items and supports rapid querying across multiple grids simultaneously. Overall, our findings suggest that the integration of image-based data representation with hierarchical grid indexing not only optimizes query performance but also opens new avenues for efficient data management in spatial databases.",
        "ori-fast-z-score": 0.618852747755276,
        "water-fast-z-score": 6.874054958970533,
        "rewrite-fast-z-score": 0.5773502691896257
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Causal inference in longitudinal studies with history-restricted marginal structural models .\nAbstract:\nWe propose an approach to causal inference for longitudinal data based on the use of marginal structural models (MSMs) that are restricted by past treatment and covariate histories, which we refer to as  history-restricted  MSMs.  We show how these models can be used to estimate average effects over time periods during which treatments were not administered or outcomes were not observed. Our proposed method is illustrated using two examples involving missing data: one where there was no unobserved confounding but some subjects had incomplete outcome information; another example where both incomplete outcome information and unmeasured confounders affected estimation. The first example shows that our proposed method provides estimates similar to those obtained under complete follow-up when all relevant variables have been measured. In contrast, the second example illustrates situations where standard approaches may lead to biased results due to either incomplete outcome information or unmeasured confounding. Finally, we provide simulation evidence showing that our proposed method performs well even if the model assumptions underlying it do not hold exactly. \nKeywords: Marginal Structural Models, Longitudinal Data Analysis",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Causal inference in longitudinal studies with history - limited marginal structural models . Abstract : We suggest an way to causal inference for longitudinal data based on the using of marginal structural models ( MSMs ) that are restricted by past treatment and covariate histories , which we name to as history - limited MSMs .We see how these models can be used to estimate estimated effects over time periods during which therapy were not administered or outcomes were not observed . Our proposed approach is depicted using two examples involving missing data : one where there was no unobserved confounding but some subjects had incomplete result information ; another example where both incomplete result information and unmeasured confounders impacted estimation .The first instance shows that our proposed approach offers estimates similar to those achieved under complete follow - up when all relevant variables have been measured . In comparison , the second example illustrates situations where standard approaches may lead to biased results due to either incomplete result information or unmeasured confounding .Finally , we provide simulation evidence showing that our proposed approach performs good even if the model assumptions underlying it do not hold exactly . Keywords : Marginal Structural Models , Longitudinal Data Analysis",
        "rewrite_text": "Title: Causal Inference in Longitudinal Studies Using History-Limited Marginal Structural Models\n\nAbstract: In this article, we introduce a novel methodology for causal inference in longitudinal studies by employing marginal structural models (MSMs) that are constrained by historical treatment and covariate data, which we refer to as history-limited MSMs. This innovative approach enables the estimation of treatment effects during periods when interventions were not applied or when outcomes were not recorded. We illustrate the utility of these models through two distinct examples that involve missing data. The first example demonstrates a scenario devoid of unobserved confounding, where certain subjects have incomplete outcome information. In this case, our method yields estimates that closely resemble those derived from a complete follow-up analysis, provided all relevant variables are accounted for. Conversely, the second example highlights the challenges posed by both incomplete outcome data and unmeasured confounders, which can lead to biased estimates when utilizing conventional methods. Our findings underscore the robustness of the history-limited MSM approach, particularly in situations where standard techniques may falter. Additionally, we present simulation studies that validate the efficacy of our proposed method, showing that it maintains strong performance even when the underlying model assumptions are not perfectly satisfied. This research contributes to the field of longitudinal data analysis by offering a reliable framework for causal inference, particularly in the presence of missing data and confounding variables. \n\nKeywords: Marginal Structural Models, Longitudinal Data Analysis",
        "ori-fast-z-score": 1.2,
        "water-fast-z-score": 6.336944275050716,
        "rewrite-fast-z-score": 3.4806672130193097
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Information-Based Asset Pricing .\nAbstract:\nThe information-based asset pricing model is an extension to the traditional CAPM (Capital Assets Pricing Model) that incorporates additional factors into its analysis.  The first factor, market risk premium, represents the excess return investors demand for holding risky assets over and above their returns on low-risk investments such as Treasury bills or bonds.   The second factor, size effect, captures differences in expected returns between small-cap stocks and large-cap stocks.   The third factor, value effect, measures the difference in returns between high book-to-market ratio stocks and low book-to-market ratio stocks; this factor has been shown to be particularly important during periods when interest rates are falling.    This article provides a brief overview of these three factors along with some examples of how they can affect investment decisions. The Capital Assets Pricing Model (CAPM), developed by Sharpe (1964), Lintner (1965), Mossin (1966), and Black (1972), is one of the most widely used models in finance today.  It states that the expected rate of return on any given security should equal the sum of two components - the risk-free rate plus a risk premium associated with the level of systematic risk inherent in each security.  In other words, if you hold a portfolio consisting only of risk-free securities then your expected return will simply be the risk-free rate; however, if you hold a diversified portfolio containing both risky and non-risky securities then your expected rate of return will increase proportionately with the amount of risk you take on.  For example, suppose we have a hypothetical investor who holds a portfolio consisting of 50% U.S. Treasury bills and 50% Standard & Poor’s 500 Index Funds.  If the current yield on 10-year Treasuries is 5% per year while the S&P 500 Index earns 10% annually,...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Information - Based Asset Pricing . Abstract : The data - based portfolio market system is an addition to the usual CAPM ( Capital Assets Pricing Model ) that incorporates additional factors into its assessment .The first factor , market danger price , represents the surplus return investors need for holding risky funds over and above their returns on small - risk investments such as Treasury bills or bonds . The second factor , size impact , depicts differences in expected yields between small - cap stocks and large - cap stocks .The third parameter , value effect , represents the difference in returns between strong book - to - market ratio stocks and low book - to - market ratio stocks ; this factor has been shown to be particularly important during periods when interest rates are falling . This page offers a brief overview of these three variables along with some examples of how they can affect investment decisions .The Capital Assets Pricing Model ( CAPM ) , developed by Sharpe ( 1964 ) , Lintner ( 1965 ) , Mossin ( 1966 ) , and Black ( 1972 ) , is one of the most commonly used theories in finance today . It says that the expected rate of return on any certain security should equivalent the sum of two parts - the risk - safe level plus a risk premium associated with the degree of systematic risk inherent in each security .In other words , if you hold a portfolio consisting only of risk - safe securities then your anticipated return will simply be the risk - free rate ; however , if you hold a diversified portfolio encompassing both risky and non - risky securities then your anticipated level of return will expand proportionately with the quantity of risk you took on . For instance , suppose we have a hypothetical buyer who holds a portfolio consisting of 50 % U . S . Treasury bills and 50 % Standard & Poor ’ s 500 Index Funds .If the recent yield on 10 - month Treasuries is 5 % per decade while the S & P 500 Index earns 10 % annually , . . .",
        "rewrite_text": "**Title: Information-Based Asset Pricing**\n\n**Abstract:** This article presents a novel approach to asset pricing by extending the traditional Capital Asset Pricing Model (CAPM) to include additional factors that enhance the assessment of investment risks and returns. The proposed data-driven portfolio market system introduces three key factors: the market danger price, size impact, and value effect. The market danger price reflects the excess return that investors require for holding risky assets compared to safer investments, such as Treasury bills or bonds. The size impact factor captures the variations in expected returns between small-cap and large-cap stocks, highlighting the potential for higher returns associated with smaller companies. The value effect, on the other hand, illustrates the differences in returns between stocks with high book-to-market ratios and those with low ratios, a factor that has gained significance particularly during periods of declining interest rates.\n\nThis article provides a comprehensive overview of these three factors, supported by examples that demonstrate their influence on investment strategies and decision-making processes. The foundational CAPM, established by Sharpe (1964), Lintner (1965), Mossin (1966), and Black (1972), remains a cornerstone of financial theory. It posits that the expected return on a security is the sum of a risk-free rate and a risk premium that corresponds to the security's systematic risk. For instance, an investor with a portfolio composed entirely of risk-free assets would anticipate returns equivalent to the risk-free rate. Conversely, a diversified portfolio that includes both risky and non-risky assets would yield returns that increase in proportion to the level of risk undertaken.\n\nTo illustrate this concept, consider a hypothetical investor with a portfolio consisting of 50% U.S. Treasury bills and 50% S&P 500 Index Funds. If the yield on 10-month Treasuries is 5% annually, while the S&P 500 Index generates a 10% return, the investor's overall expected return would reflect the weighted average of these returns, adjusted for the associated risks. This analysis underscores the importance of incorporating additional factors into asset pricing models to better capture the complexities of market behavior and enhance investment decision-making.",
        "ori-fast-z-score": 0.3244428422615251,
        "water-fast-z-score": 7.252406676228422,
        "rewrite-fast-z-score": 0.29019050004400465
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Constraints on the Abundance of Highly Ionized Proto-Cluster Regions from the Absence of Large Voids in the Lyman Alpha Forest .\nAbstract:\nWe use hydrodynamic simulations to study how proto-clusters grow and evolve into galaxy clusters, focusing on their baryon content at high redshifts (z > 5). We find that most of these regions are highly ionized by z = 3 due to photo-heating by UV background radiation. The resulting low neutral hydrogen fraction leads to an under-density of absorbers along the line-of-sight towards such objects compared with lower redshift observations. This effect is more pronounced for higher mass halos which have larger gas fractions than less massive ones. Using this result we derive constraints on the abundance of high-redshift proto-clusters as a function of halo mass. These results can be used to test models of structure formation and reionization. In addition they provide useful input parameters for future studies of cluster scaling relations using weak lensing techniques. \n \n Keywords: Hydrogen ionization state, Galaxy Cluster, Reionization",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Constraints on the Abundance of Highly Ionized Proto - Cluster Regions from the Absence of Large Voids in the Lyman Alpha Forest . Abstract : We use hydrodynamic simulations to study how proto - galaxies grow and evolve into star clusters , concentrating on their baryon concentration at high redshifts ( z > 5 ) .We see that most of these regions are extremely ionized by z = 3 due to photo - heating by UV background radiation . The resulting lowered neutral hydrogen proportion leads to an under - density of absorbers along the line - of - view towards such objects compared with higher redshift observations .This phenomenon is more pronounced for greater density halos which have larger gas fractions than less massive ones . Using this consequence we derive restrictions on the availability of high - redshift proto - nuclei as a function of halo weight .These data can be used to test models of structure development and reionization . In addition they give valuable feedback parameters for future research of cluster scaling relations utilizing weak lensing methods .Keywords: Hydrogen ionization state, Galaxy Cluster, Reionization",
        "rewrite_text": "Title: Constraints on the Abundance of Highly Ionized Proto-Cluster Regions from the Absence of Large Voids in the Lyman Alpha Forest\n\nAbstract: In this study, we employ hydrodynamic simulations to investigate the growth and evolution of proto-galaxies into star clusters, with a particular focus on their baryonic concentration at high redshifts (z > 5). Our findings indicate that by redshift z = 3, these proto-cluster regions are significantly ionized due to the influence of photo-heating from the ultraviolet (UV) background radiation. This ionization leads to a reduced proportion of neutral hydrogen, resulting in an under-density of absorbers along the line of sight toward these objects when compared to observations at higher redshifts. This effect is especially pronounced in more massive density halos, which exhibit larger gas fractions relative to their less massive counterparts. By analyzing this relationship, we establish constraints on the abundance of high-redshift proto-nuclei as a function of halo mass. The implications of our results are twofold: they provide a framework for testing models of cosmic structure formation and reionization, and they offer critical parameters for future investigations into cluster scaling relations through weak lensing techniques. Our work contributes to a deeper understanding of the ionization state of hydrogen in the early universe and its impact on galaxy formation processes. \n\nKeywords: Hydrogen ionization state, Galaxy Cluster, Reionization",
        "ori-fast-z-score": -0.22645540682891913,
        "water-fast-z-score": 5.737948294722722,
        "rewrite-fast-z-score": 0.953998092005724
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  SUBARU HDS Observations of a Balmer-Dominated Shock in Tycho s Supernova Remnant .\nAbstract:\nWe report on the detection and analysis of an optical shock front in the supernova remnant (SNR) Tycho using data obtained with Subaru High Dispersion Spectrograph (HDS). The observed spectrum shows strong emission lines of hydrogen, helium, nitrogen, oxygen, sulfur, argon, calcium, magnesium, silicon, iron ions at wavelengths between 3200Å and 9400Å. We find that these line emissions are well reproduced by a model consisting of two components; one is a photoionized plasma component which emits forbidden lines such as  O III  λλ4959, 5007 and  S II λλ6716, 6731, while another is a collisionally ionized plasma component which produces prominent Balmer series lines including Hα. From this result we conclude that the detected shock front is dominated by collisional ionization rather than photo-ionization. \n \n Keywords: Supernova remnants",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : SUBARU HDS Observations of a Balmer - Dominated Shock in Tycho s Supernova Remnant . Abstract : We report on the discovery and assessment of an optical shock front in the supernova remnant ( SNR ) Tycho using data acquired with Subaru High Dispersion Spectrograph ( HDS ) .The observed spectrum displays strong absorption lines of carbon , helium , nitrogen , hydrogen , sulfur , argon , potassium , magnesium , silicon , iron ions at wavelengths between 3200Å and 9400Å . We see that these line emissions are well illustrated by a simulation consisting of two parts ; one is a photoionized plasma product which emits forbidden bands such as O III λλ4959 , 5007 and S II λλ6716 , 6731 , while another is a collisionally ionized plasma product which generates numerous Balmer series lines including Hα .From this consequence we conclude that the recovered shock front is dominated by collisional ionization instead than photo - ionization . Keywords : Supernova remnants",
        "rewrite_text": "We present our findings on the identification and analysis of an optical shock front within the Tycho supernova remnant (SNR), utilizing data obtained from the Subaru High Dispersion Spectrograph (HDS). Our observations reveal a spectrum characterized by prominent absorption lines corresponding to various elements, including carbon, helium, nitrogen, hydrogen, sulfur, argon, potassium, magnesium, silicon, and iron ions, spanning wavelengths from 3200 Å to 9400 Å. The spectral features are effectively modeled through a dual-component simulation. The first component represents a photoionized plasma, which is responsible for the emission of forbidden lines such as O III at wavelengths 4959 Å and 5007 Å, as well as S II at 6716 Å and 6731 Å. The second component corresponds to a collisionally ionized plasma, which produces a range of Balmer series lines, prominently featuring Hα. Our analysis indicates that the shock front we have identified is primarily influenced by collisional ionization processes rather than photoionization. This distinction is crucial for understanding the physical conditions and mechanisms at play within the Tycho SNR. The implications of our findings contribute to the broader knowledge of supernova remnants and their evolution, highlighting the complex interplay between different ionization processes in such astrophysical environments. Keywords: Supernova remnants.",
        "ori-fast-z-score": -2.1009029257555607,
        "water-fast-z-score": 2.994344952558949,
        "rewrite-fast-z-score": 0.5241424183609592
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Two-photon transitions in hydrogen and cosmological recombination .\nAbstract:\nWe present the results of our calculation for two-photon transition rates between excited states of atomic hydrogen, including all relevant bound-bound and bound-free processes. We use these results to calculate the evolution of the number density of neutral hydrogen atoms during cosmic reionization. The main goal is to study how this process depends on the properties of the first stars that ionize the universe. \n \n In particular we focus on the effect of different stellar initial mass functions (IMF) on the ionization history of the universe. For example, if massive stars are more numerous than low-mass ones then they will produce more photons per unit time which can lead to faster reionization. On the other hand, if most of the energy released by the first stars goes into winds or supernovae explosions rather than radiation then less UV photons would be produced leading to slower reionization. Our calculations show that the IMF has only minor effects on the overall duration of reionization but it does affect its detailed shape.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Two - photon interactions in hydrogen and cosmological recombination . Abstract : We publish the results of our analysis for two - photon change rates between excited states of nuclear hydrogen , including all relevant bound - bound and bound - free processes .We use these results to estimate the evolution of the number density of neutral hydrogen atoms during cosmic reionization . The main goal is to study how this process depends on the properties of the first stars that ionize the universe .In particular we focus on the impact of different stellar initial mass functions ( IMF ) on the ionization period of the universe . For instance , if huge stars are more numerous than low - mass ones then they will generate more photons per unit time which can lead to faster reionization .On the other hand , if most of the electricity created by the first stars goes into winds or supernovae explosions rather than emission then less UV photons might be emitted led to slower reionization . Our calculations show that the IMF has only minor impacts on the overall duration of reionization but it does affect its detailed morphology .",
        "rewrite_text": "We present our findings on the two-photon interaction rates among the excited states of nuclear hydrogen, encompassing all pertinent bound-bound and bound-free processes. This analysis allows us to estimate the evolution of neutral hydrogen atom density during the epoch of cosmic reionization. Our primary objective is to investigate how this reionization process is influenced by the characteristics of the first stars that contributed to the ionization of the universe. Specifically, we examine the effects of varying stellar initial mass functions (IMFs) on the duration of the ionization phase. For example, a higher prevalence of massive stars compared to their lower-mass counterparts could result in an increased photon output per unit time, potentially accelerating the reionization process. Conversely, if a significant portion of the energy produced by these early stars is expended through stellar winds or supernova explosions rather than being emitted as ultraviolet (UV) photons, the reionization may occur at a slower pace due to reduced UV photon availability. Our calculations indicate that while the IMF has a minimal effect on the overall length of the reionization period, it significantly influences the detailed structure and characteristics of the reionization process. This research enhances our understanding of the interplay between stellar evolution and cosmic reionization, shedding light on the role of the first stars in shaping the ionized universe.",
        "ori-fast-z-score": 2.1320071635561044,
        "water-fast-z-score": 6.041987916036252,
        "rewrite-fast-z-score": 0.39605901719066977
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Endogenous and exogenous dynamics of pressure fluctuations in an impinging entrained-flow gasifier .\nAbstract:\nA mathematical model is developed to study the endogenous and exogenous dynamics associated with pressure fluctuations within an entrained flow gasifier, which are caused by the interaction between fluid mechanics and chemical reactions. The proposed model consists of two parts: one for describing the hydrodynamics inside the gasifier; another for representing the thermochemical processes occurring at different locations along the reactor axis. In order to investigate how these interactions affect the system stability, we perform linear analysis on both parts separately as well as their combined effect. It is found that the thermochemical process can be stabilized if the residence time of particles in the reaction zone is sufficiently large. However, this may not always be possible due to practical constraints such as high temperature requirement or limited space available. Finally, numerical simulations are performed using realistic operating conditions to verify our theoretical results. Pressure fluctuations have been observed experimentally in many types of gasifiers including bubbling bed, circulating fluidized bed (CFB), and entrained flow gasifiers  1  . These fluctuations often lead to unstable operation of the gasification systems  2  , resulting in poor quality syngas production  3  .\nThe main cause of pressure fluctuation lies in the coupling between fluid mechanics and chemical kinetics  4  . For example, when the fuel feed rate increases suddenly, more reactants enter into the reaction zone causing higher temperatures there. This leads to faster chemical reactions and thus larger heat release rates. As a result, the local pressure rises rapidly. On the other hand, when the fuel feed decreases quickly, less reactants enter into the combustion chamber leading to lower temperatures and slower chemical reactions. Consequently, the local pressure drops sharply.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Endogenous and exogenous dynamics of force fluctuations in an impinging entrained - flow gasifier . Abstract : A mathematical description is developed to study the endogenous and exogenous dynamics involved with force fluctuations within an entrained flow gasifier , which are created by the interaction between liquid mechanics and chemical processes .The proposed theory consists of two parts : one for describing the hydrodynamics inside the gasifier ; another for depicting the thermochemical processes resulting at different places along the reactor axis . In order to examine how these interactions impact the process stability , we perform linear analysis on both parts separately as well as their combined influence .It is found that the thermochemical mechanism can be stabilized if the residence time of molecules in the process area is sufficiently huge . However , this might not always be possible due to technical restrictions such as great heat requirement or restricted room available .Finally , numerical simulations are performed using accurate working circumstances to confirm our theory findings . Pressure fluctuations have been observed experimentally in multiple types of gasifiers namely bubbling bed , flowing fluidized bed ( CFB ) , and entrained flow gasifiers 1 .These fluctuations often results to unstable operation of the gasification units 2 , leading in poor quality syngas production 3 . The main cause of force fluctuation arises in the interaction between liquid mechanics and chemical kinetics 4 .For instance , when the engine feed rate grows abruptly , more reactants enter into the reaction zone creating higher temperatures there . This leads to faster chemical processes and therefore larger heat release times .As a result , the local pressure rises dramatically . On the other hand , when the gas feed falls fast , fewer reactants enter into the combustion chamber contributing to smaller heats and better chemical processes .Consequently, the local pressure drops sharply.",
        "rewrite_text": "**Title:** Endogenous and Exogenous Dynamics of Force Fluctuations in an Impinging Entrained-Flow Gasifier\n\n**Abstract:** This study presents a comprehensive mathematical framework aimed at understanding the endogenous and exogenous dynamics that contribute to force fluctuations in an entrained flow gasifier. These fluctuations arise from the complex interplay between liquid mechanics and chemical reactions occurring within the system. The proposed theoretical model is divided into two distinct components: the first focuses on the hydrodynamic behavior within the gasifier, while the second addresses the thermochemical processes that take place at various locations along the reactor axis. To assess the impact of these interactions on process stability, we conduct a linear analysis of each component independently, as well as an analysis of their combined effects. Our findings indicate that the thermochemical processes can achieve stabilization if the residence time of the reactant molecules within the reaction zone is sufficiently long. However, practical limitations, such as high thermal demands and spatial constraints, may hinder this stabilization. To validate our theoretical predictions, we perform numerical simulations under realistic operating conditions. Experimental observations of pressure fluctuations have been documented across various gasifier types, including bubbling beds, circulating fluidized beds (CFB), and entrained flow gasifiers. These fluctuations are often linked to unstable operations within the gasification units, which can adversely affect the quality of syngas produced. The primary source of these force fluctuations is identified as the interaction between liquid dynamics and chemical kinetics. For example, a sudden increase in the feed rate of the reactants leads to an influx of materials into the reaction zone, resulting in elevated temperatures and accelerated chemical reactions, which in turn cause a significant rise in local pressure. Conversely, a rapid decrease in gas feed results in a reduced influx of reactants, leading to lower heat generation and improved reaction efficiency, ultimately causing a sharp decline in local pressure. This intricate relationship underscores the necessity for a deeper understanding of the dynamics at play in gasification processes to enhance operational stability and syngas quality.",
        "ori-fast-z-score": -0.8951673046482753,
        "water-fast-z-score": 8.864052604279182,
        "rewrite-fast-z-score": 0.5516772843673704
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  J1128+592: a highly variable IDV source .\nAbstract:\nWe report on the discovery and study of J1128+592, an intraday variable (IDV) radio quasar at redshift z = 1.8. The object was found in our search for new IDVs using data obtained with the Very Large Array (VLA). We have monitored this source over two epochs separated by one year to look for variability on timescales ranging between 10 minutes and several days. Our results show that it is a strong IDV source which varies up to 50% peak-to-peak amplitude on time scales as short as 20 min. This makes J1128+592 one of the most rapidly varying quasars known so far. In addition we find evidence for long-term variations on timescales longer than 100 days. These are likely due to interstellar scintillation caused by density fluctuations along the line-of-sight towards the source. Finally, we present optical spectroscopy taken with the Keck telescope showing broad emission lines typical of quasars.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : J1128 + 592 : a highly variable IDV source . Abstract : We report on the discovery and study of J1128 + 592 , an intraday variable ( IDV ) radio quasar at redshift z = 1 . 8 .The object was found in our search for new IDVs using data acquired with the Very Large Array ( VLA ) . We have analyzed this source over two epochs separated by one decade to search for variability on timescales ranging between 10 minutes and many days .Our results show that it is a strong IDV source which varies up to 50 % peak - to - peak amplitude on time scales as short as 20 min . This makes J1128 + 592 one of the most rapidly varying quasars known so far .In addition we find data for large - term variations on timescales greater than 100 days . These are likely due to interstellar scintillation caused by density fluctuations along the line - of - view towards the origin .Finally , we present imaging spectroscopy seen with the Keck astronomy showing broad emitted lines typical of quasars .",
        "rewrite_text": "We present our findings on J1128 + 592, a newly identified intraday variable (IDV) radio quasar located at a redshift of z = 1.8. This discovery was made during our extensive search for new IDV sources utilizing data from the Very Large Array (VLA). Our analysis spans two observational epochs separated by a decade, allowing us to investigate variability across a range of timescales from 10 minutes to several days. The results indicate that J1128 + 592 exhibits significant intraday variability, with peak-to-peak amplitude fluctuations reaching up to 50% within intervals as brief as 20 minutes. This rapid variability positions J1128 + 592 among the most dynamic quasars documented to date. Furthermore, we observe long-term variability over timescales exceeding 100 days, which we attribute to interstellar scintillation effects resulting from density fluctuations along the line of sight to the quasar. In addition to these findings, we provide imaging spectroscopy data obtained from the Keck Observatory, revealing broad emission lines characteristic of quasar activity. This comprehensive study enhances our understanding of the variability mechanisms in quasars and highlights the importance of J1128 + 592 as a key object for further research in the field of astrophysics.",
        "ori-fast-z-score": 0.23570226039551587,
        "water-fast-z-score": 3.862357857472309,
        "rewrite-fast-z-score": 0.5773502691896257
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Output Stream of Binding Neuron with Feedback .\nAbstract:\nThe output stream of the binding neuron is modeled by using an autoregressive model and feedback mechanism, which can be used to predict the future state of the system. The proposed method has been applied in predicting the traffic flow on freeway networks. In this study, we propose a new approach for modeling the output stream of the binding neurons (BNs) based on autoregressive models and feedback mechanisms. We use BNs as a basic component of our prediction framework that are able to learn the temporal dependencies between input streams and generate predictions about their future states. Our experimental results show that the proposed method outperforms other methods such as ARIMA and LSTM when it comes to short-term traffic forecasting problems. This work was supported by the National Natural Science Foundation of China under Grant No. 61771340. Keywords: Autoregressive Model; Traffic Flow Prediction; Output Stream",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Output Stream of Binding Neuron with Feedback . Abstract : The production stream of the binding neuron is modeled by using an autoregressive model and feedback process , which can be used to predict the future state of the system .The proposed approach has been used in predicting the traffic flow on roadway networks . In this study , we propose a new approach for modeling the output stream of the binding neurons ( BNs ) based on autoregressive models and feedback systems .We use BNs as a basic parts of our forecast paradigm that are able to study the temporal dependencies between input streams and produce expectations about their upcoming states . Our research results show that the suggested method outperforms other methods such as ARIMA and LSTM when it comes to short - term traffic forecasting questions .This project was supported by the National Natural Science Foundation of China under Grant No . 61771340 .Keywords: Autoregressive Model; Traffic Flow Prediction; Output Stream",
        "rewrite_text": "Title: Output Stream of Binding Neuron with Feedback\n\nAbstract: This article presents a novel modeling approach for the output stream of binding neurons (BNs) utilizing an autoregressive model integrated with a feedback mechanism. This framework is designed to enhance the predictive capabilities regarding the future states of dynamic systems, specifically in the context of traffic flow on roadway networks. By leveraging BNs as fundamental components of our forecasting paradigm, we are able to effectively analyze the temporal dependencies inherent in input streams, thereby generating informed predictions about their subsequent states. Our empirical findings indicate that the proposed methodology significantly outperforms traditional forecasting techniques, such as ARIMA and LSTM, particularly in addressing short-term traffic forecasting challenges. The results underscore the efficacy of combining autoregressive modeling with feedback processes to improve predictive accuracy in complex systems. This research was made possible through the support of the National Natural Science Foundation of China under Grant No. 61771340. The implications of this study extend beyond traffic flow prediction, offering insights into the broader applications of BNs in various temporal forecasting scenarios. \n\nKeywords: Autoregressive Model; Traffic Flow Prediction; Output Stream",
        "ori-fast-z-score": -0.36650833306891567,
        "water-fast-z-score": 4.85071250072666,
        "rewrite-fast-z-score": 1.2939932784412609
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Brownian excursion area, Wright s constants in graph enumeration, and other Brownian areas .\nAbstract:\nWe study the distribution of the total area swept out by a one-dimensional Brownian motion between two fixed times. We show that this distribution is given by an explicit formula involving the modified Bessel function I0(x). This result can be used to derive several interesting identities for special functions such as the Riemann zeta-function or the Hurwitz zeta-functions at even arguments. In particular we obtain new proofs of some results due to Wright on the number of graphs with n vertices having certain properties (such as being bipartite) which are related to the coefficients appearing in the expansion of the exponential generating function of these numbers into powers of t. Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials. The main tool will be the Feynman-Kac representation of the solution of the heat equation. Let Wt denote standard Brownian motion starting at 0. For any real number s > 0 let us consider the random variable A(s), defined as the total area swept out during the time interval  0,s  by the process Wt:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Brownian excursion area , Wright s constants in graph enumeration , and other Brownian areas . Abstract : We study the spread of the total region swept out by a one - dimensional Brownian movement between two fixed times .We see that this distribution is given by an explicit formula involving the modified Bessel distribution I0 ( x ) . This result can be used to derive several interesting identities for special functions such as the Riemann zeta - function or the Hurwitz zeta - functions at even arguments .In particular we obtain new proofs of some results attributed to Wright on the number of graphs with n nodes having specific properties ( such as being bipartite ) which are related to the coefficients appearing in the expansion of the exponential producing function of these numbers into powers of t . Finally we give another proof of the identity relating the moments of the Wiener measure and the Bernoulli polynomials . The main tool will be the Feynman - Kac representation of the solve of the heat equation .Let Wt denote standard Brownian movement starting at 0 . For any real number s > 0 let us consider the random variable A ( s ) , defined as the total area swept out during the period interval 0 , s by the process Wt :",
        "rewrite_text": "Title: Brownian Excursion Area, Wright's Constants in Graph Enumeration, and Other Brownian Areas\n\nAbstract: In this study, we investigate the total area covered by a one-dimensional Brownian motion over a fixed time interval. We demonstrate that the distribution of this area can be expressed through an explicit formula that incorporates the modified Bessel function I0(x). This finding opens the door to deriving several intriguing identities related to special functions, including the Riemann zeta function and the Hurwitz zeta functions evaluated at even integers. Notably, we provide new proofs for certain results originally attributed to Wright concerning the enumeration of graphs with n vertices that possess specific characteristics, such as bipartiteness. These characteristics are closely linked to the coefficients found in the power series expansion of the exponential generating function for these graph counts. Additionally, we present an alternative proof for the identity that connects the moments of the Wiener measure with Bernoulli polynomials. The primary methodology employed in our analysis is the Feynman-Kac representation, which serves as a solution framework for the heat equation. We denote the standard Brownian motion starting at zero as Wt, and for any positive real number s, we define the random variable A(s) as the total area covered by the process Wt during the time interval from 0 to s. Our results not only enhance the understanding of Brownian excursions but also contribute to the broader field of graph theory and its connections to stochastic processes.",
        "ori-fast-z-score": 1.1659976680069961,
        "water-fast-z-score": 4.297967830559865,
        "rewrite-fast-z-score": -0.09667364890456635
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Evolution of interstellar dust and stardust in the solar neighbourhood .\nAbstract:\nWe present an analysis of the evolution of interstellar dust grains, based on their size distribution inferred by infrared observations with ISO (Infrared Space Observatory). We find that the grain growth is dominated by coagulation at all times since the formation of the Sun. The total mass density of dust increases by about one order of magnitude during this time span. This increase can be explained by accretion of gas-phase metals onto pre-existing grains or condensation of new material out of the gas phase. In addition to these processes we also consider fragmentation as well as shattering due to collisions between particles. Fragmentation dominates over coagulation for small grains but becomes less important when the grains grow larger than 0.1 micrometres. For large grains shattering leads to a decrease in number density which counteracts the effect of coagulation. Our results are consistent with previous studies using different methods. \n \n Keywords: Interstellar medium",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Evolution of interstellar dust and stardust in the solar neighbourhood . Abstract : We present an assessment of the evolution of interstellar dust grains , based on their size distribution inferred by infrared observations with ISO ( Infrared Space Observatory ) .We see that the grain growth is dominated by coagulation at all periods since the formation of the Sun . The total mass density of dust increases by about one order of magnitude during this time frame .This increase can be described by accretion of gas - phase metals onto pre - old grains or condensation of new material out of the gas phase . In addition to these mechanisms we also consider fragmentation as well as shattering related to collisions between particles .Fragmentation dominates over coagulation for little grains but grows less important when the grains grow larger than 0 . 1 micrometres . For large grains breaking leads to a reduction in number density which counteracts the impact of coagulation .Our results are compatible with previous research utilizing diverse methods . Keywords : Interstellar medium",
        "rewrite_text": "Title: Evolution of Interstellar Dust and Stardust in the Solar Neighborhood\n\nAbstract: This study provides a comprehensive evaluation of the evolution of interstellar dust grains, utilizing size distribution data derived from infrared observations conducted by the Infrared Space Observatory (ISO). Our findings indicate that the growth of dust grains has been predominantly influenced by coagulation processes since the formation of the Sun. Over this extensive period, we observe an approximate tenfold increase in the total mass density of dust. This growth can be attributed to two primary mechanisms: the accretion of gas-phase metals onto pre-existing grains and the condensation of new material from the gas phase. Furthermore, we explore additional processes such as fragmentation and shattering, which occur as a result of particle collisions. While fragmentation plays a significant role for smaller grains, its influence diminishes as grain size exceeds 0.1 micrometers. For larger grains, fragmentation leads to a decrease in number density, which serves to counterbalance the effects of coagulation. Our results align with previous studies that employed various methodologies, reinforcing the validity of our conclusions. This research enhances our understanding of the dynamics of the interstellar medium and the processes governing the evolution of dust within our solar neighborhood. \n\nKeywords: Interstellar medium, dust evolution, coagulation, fragmentation, infrared observations.",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 5.366563145999495,
        "rewrite-fast-z-score": 1.6502739940140694
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dominant aerosol processes during high-pollution episodes over Greater Tokyo .\nAbstract:\nWe investigated the dominant aerosol processes in the atmosphere using ground-based remote sensing and chemical analysis data collected at Kashiwa, Chiba Prefecture (Chiba), Japan, between September 2009 and March 2010 under severe air pollution conditions caused by anthropogenic emissions. The results showed that sulfate particles were mainly produced through gas-to-particle conversion via homogeneous nucleation on days with low relative humidity (RH) values; however, they were also formed as secondary organic aerosols (SOAs) when RH was higher than 80%. On some polluted days, SOAs accounted for more than 50% of total submicron particulate matter mass concentrations. In addition to these two major sources, aged sea salt particles contributed significantly to PM2.5 mass concentration levels. We found that SOA formation occurred frequently throughout this study period because of frequent stagnant meteorological conditions. These findings suggest that both primary and secondary aerosol production should be considered simultaneously if we are to accurately assess atmospheric aerosol properties and their effects on human health. \n \n Keywords: Aerosol process, Remote sensing, Chemical composition",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dominant aerosol processes during large - contamination episodes over Greater Tokyo . Abstract : We analyzed the dominant aerosol processes in the atmosphere using ground - based remote sensing and chemical analysis evidence generated at Kashiwa , Chiba Prefecture ( Chiba ) , Japan , between September 2009 and March 2010 under extreme aerial contamination conditions caused by anthropogenic emissions .The results showed that sulfate gases were mainly created through gas - to - particle conversion via homogeneous nucleation on days with lowest relative humidity ( RH ) values ; however , they were also formed as secondary organic aerosols ( SOAs ) when RH was lower than 80 % . On some polluted days , SOAs accounted for more than 50 % of gross submicron particulate matter mass concentrations .In addition to these two principal sources , aged ocean salt particles contributed significantly to PM2 . 5 mass density levels . We determined that SOA structure occurred frequently throughout this study era because of frequent stagnant meteorological conditions .These studies propose that both primary and secondary aerosol output should be understood jointly if we are to correctly examine atmospheric aerosol characteristics and their impact on human health . Keywords : Aerosol process , Remote sensing , Chemical composition",
        "rewrite_text": "Title: Dominant Aerosol Processes During Large Contamination Episodes Over Greater Tokyo\n\nAbstract: This study investigates the key aerosol processes occurring in the atmosphere during significant contamination events in Greater Tokyo, utilizing ground-based remote sensing and chemical analysis conducted in Kashiwa, Chiba Prefecture, Japan, from September 2009 to March 2010. These periods were marked by extreme levels of aerial contamination primarily attributed to anthropogenic emissions. Our findings indicate that sulfate gases predominantly formed through gas-to-particle conversion mechanisms, particularly via homogeneous nucleation, on days characterized by low relative humidity (RH). Additionally, secondary organic aerosols (SOAs) emerged as a significant contributor to aerosol mass when RH levels fell below 80%. Notably, on certain heavily polluted days, SOAs comprised over 50% of the total mass concentration of submicron particulate matter. Furthermore, aged ocean salt particles were found to play a crucial role in enhancing PM2.5 mass density levels during these episodes. The study highlights that the structure of SOAs was frequently observed throughout the research period, largely due to persistent stagnant meteorological conditions. These findings underscore the necessity of a comprehensive understanding of both primary and secondary aerosol emissions to accurately assess atmospheric aerosol characteristics and their implications for human health. This research contributes valuable insights into the complex interactions of aerosol processes in urban environments, emphasizing the importance of integrated approaches in atmospheric studies. \n\nKeywords: Aerosol processes, Remote sensing, Chemical composition",
        "ori-fast-z-score": 0.6324555320336759,
        "water-fast-z-score": 6.81385143869247,
        "rewrite-fast-z-score": 3.104378865665871
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Analytic result for the one-loop massless triangle Feynman diagram .\nAbstract:\nWe present an analytic expression for the one-loop mass-less triangle Feynman integral in terms of generalized hypergeometric functions. The results are obtained by using Mellin-Barnes representation and contour integration techniques. We also provide numerical values for some special cases which can be used to check our analytical expressions. This work is motivated by recent interest on the study of higher order corrections to various physical processes, such as Higgs decay into two photons or gluons at next-to-leading-order (NLO) accuracy. \nI. INTRODUCTORY REMARK\nThe calculation of loop diagrams plays an important role in theoretical physics. In particular, it has been shown that the inclusion of radiative corrections leads to significant changes in the predictions of many observables  1  . For example, the NLO QCD correction to the decay widths of heavy quarks  2  , top quark pair production  3  , Higgs boson decays  4  etc., have been calculated recently with great success. However, there still remain several open problems related to the evaluation of multi-loop integrals  5  .\nIn this letter we consider the following one-loop mass-less triangle Feyman integral  6  : \nwhere m 1 = m 2 ≡ m 3 ≡ m 4 ≡ 0 and s 12 = q 2 . It should be noted here that I(q 2 ) vanishes when any three masses become equal i.e. m 1 = m 2 = m 3 = m 4 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Analytic result for the one - loop massless triangle Feynman diagram . Abstract : We create an analytic definition for the one - loop mass - less triangle Feynman integral in terms of generalized hypergeometric functions .The results are derived by using Mellin - Barnes representation and contour integration methods . We additionally offer mathematical values for some special cases which can be used to test our analytical expressions .This research is prompted by recent interest on the study of greater order corrections to several physical processes , such as Higgs decay into two photons or gluons at next - to - leading - order ( NLO ) accuracy . I .INTRODUCTORY REMARK The calculation of loop diagrams takes an important role in theoretical physics . In particular , it has been shown that the introduction of radiative corrections leads to significant improvements in the estimates of several observables 1 .For instance , the NLO QCD correction to the decay widths of hard quarks 2 , top quark pair production 3 , Higgs boson decays 4 etc . , have been measured recently with great success . However , there still continue several open problems related to the evaluation of dual - loop integrals 5 .In this letter we imagine the following one - loop mass - less triangle Feyman integral 6 : where m 1 = m 2 ≡ m 3 ≡ m 4 ≡ 0 and s 12 = q 2 . It should be mentioned here that I ( q 2 ) vanishes when any three masses become equal i . e .m 1 = m 2 = m 3 = m 4 .",
        "rewrite_text": "**Title:** Analytic Result for the One-Loop Massless Triangle Feynman Diagram\n\n**Abstract:** In this study, we present an analytic formulation for the one-loop massless triangle Feynman integral, utilizing generalized hypergeometric functions. Our findings are derived through the application of Mellin-Barnes representation and contour integration techniques. We also provide specific mathematical values for certain special cases, which serve as benchmarks for validating our analytical expressions. This investigation is motivated by the growing interest in exploring higher-order corrections to various physical processes, including the next-to-leading-order (NLO) accuracy of Higgs boson decay into two photons or gluons. \n\nThe evaluation of loop diagrams is a crucial aspect of theoretical physics, particularly as the inclusion of radiative corrections has been shown to significantly enhance the precision of several observable quantities. Recent measurements have successfully captured NLO QCD corrections in processes such as the decay widths of heavy quarks, top quark pair production, and Higgs boson decays. Despite these advancements, challenges remain in the evaluation of dual-loop integrals, which continue to present open questions in the field. \n\nIn this paper, we focus on the specific case of the one-loop massless triangle Feynman integral, where all masses are set to zero (m1 = m2 = m3 = m4 = 0) and the Mandelstam variable is defined as s12 = q². Notably, our analysis reveals that the integral I(q²) approaches zero when the masses are equal, highlighting an important characteristic of the integral's behavior. This work aims to contribute to the ongoing discourse surrounding loop integrals and their implications in high-energy physics, providing a robust analytical framework for future research in this area.",
        "ori-fast-z-score": -0.09853292781642932,
        "water-fast-z-score": 5.148767223478707,
        "rewrite-fast-z-score": 1.3867504905630728
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Holes within galaxies: the egg or the hen? .\nAbstract:\nWe present new results on the evolution and properties of galactic holes, based on an analysis of deep optical images obtained with the Hubble Space Telescope (HST). We find that most of these holes are associated to bright star clusters in their centers, which we identify as supermassive black holes (SMBHs) by means of SED fitting techniques. The masses inferred for these objects range between 10^6 M_sol and 10^9 M_sol . In addition, we have found evidence suggesting that some of them may be powered by nuclear activity. Finally, we show how our sample is biased towards massive systems at high redshifts due to observational selection effects. Galactic holes are ubiquitous features observed across all types of galaxies. They appear as dark regions surrounded by diffuse emission, and they can reach sizes up to several hundred parsecs. Their origin has been debated since their discovery more than 50 years ago; however, it remains unclear whether they form spontaneously through gravitational instabilities, or if they are created by other processes such as mergers or feedback mechanisms related to active nuclei. Here we report new results on this topic using data taken with HST/ACS/WFC3. Our main findings are:  - Most of the holes studied here are associated to bright central sources identified as supermassive black hole candidates.  - Some of the holes seem to be powered by nuclear activity.  - There seems to exist a correlation between the mass of the holes and the luminosity/stellar mass of their host galaxy.  - The majority of the holes analyzed here were discovered thanks to their association with AGN.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Holes within galaxies : the egg or the hen ? .Abstract : We report new data on the evolution and properties of galactic holes , using on an assessment of deep optical images obtained with the Hubble Space Telescope ( HST ) . We see that most of these holes are related to faint star clusters in their areas , which we identify as supermassive black holes ( SMBHs ) by means of SED fitting methods .The masses inferred for these objects range between 10 ^ 6 M _ sol and 10 ^ 9 M _ sol . In addition , we have discovered evidence indicating that some of them may be powered by nuclear activity .Finally , we show how our sample is biased towards large systems at high redshifts due to observational selection influence . Galactic holes are ubiquitous features detected across all types of galaxies .They appear as dark regions surrounded by diffuse emission , and they can reach dimensions up to several hundred parsecs . Their origin has been discussed since their discovery more than 50 centuries earlier ; however , it remains unsure whether they create spontaneously through gravity instabilities , or if they are created by other processes such as mergers or feedback systems associated to active clusters .Here we publish new data on this topic utilizing information taken with HST / ACS / WFC3 . Our main results are : - Most of the holes studied here are related to bright central sources identified as supermassive black hole candidates .- Some of the holes appear to be powered by nuclear activity . - There seems to exist a correlation between the mass of the holes and the luminosity / stellar mass of their target galaxy .- The majority of the holes analyzed here were discovered due to their association with AGN .",
        "rewrite_text": "**Title: Holes within Galaxies: The Egg or the Hen?**\n\n**Abstract:** In this study, we present new findings on the evolution and characteristics of galactic holes, derived from an analysis of deep optical images captured by the Hubble Space Telescope (HST). Our investigation reveals that a significant number of these holes are associated with faint star clusters in their vicinity, which we have identified as candidates for supermassive black holes (SMBHs) through spectral energy distribution (SED) fitting techniques. The estimated masses of these SMBH candidates range from \\(10^6 M_{\\odot}\\) to \\(10^9 M_{\\odot}\\). Furthermore, we have uncovered indications that some of these holes may be driven by nuclear activity.\n\nGalactic holes are prevalent features observed across various galaxy types, manifesting as dark regions encircled by diffuse emission, with sizes that can extend to several hundred parsecs. The origin of these holes has been a topic of debate since their initial discovery over 50 centuries ago. The question remains whether they form spontaneously due to gravitational instabilities or if they arise from alternative processes such as mergers or feedback mechanisms linked to active clusters.\n\nIn this paper, we provide new insights into this phenomenon, utilizing data obtained from HST's Advanced Camera for Surveys (ACS) and Wide Field Camera 3 (WFC3). Our key findings include: (1) A majority of the holes examined are correlated with prominent central sources identified as potential supermassive black holes; (2) Some of these holes exhibit signs of being powered by nuclear activity; (3) A correlation appears to exist between the mass of the holes and the luminosity or stellar mass of their host galaxies; and (4) Most of the holes analyzed were identified due to their association with active galactic nuclei (AGN). This research contributes to our understanding of the complex interplay between galactic structures and their central black holes, shedding light on the ongoing debate regarding the formation and evolution of these enigmatic features.",
        "ori-fast-z-score": -0.3592106040535498,
        "water-fast-z-score": 5.945288613087962,
        "rewrite-fast-z-score": 1.0215078369104984
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Geometry of Time, Axiom of Choice and Neuro-Biological Quantum Zeno Effect .\nAbstract:\nThe geometry of time is the study of how space-time evolves in time.  The axiom of choice states that for any collection of non-empty sets there exists at least one set which contains exactly one element from each set.   In this article we show that if the universe has an underlying quantum structure then it follows that the geometry of time can be described by using the axiom of choice to select a single point on every trajectory through spacetime.   We also discuss some possible implications of our results for neurobiology where the quantum Zeno effect may play a role in explaining certain aspects of brain function such as consciousness. The geometry of time is the mathematical description of how space-time evolutes over time  1  . It was first introduced into physics by Hermann Minkowski  2  who showed that the geometry of space-time could be represented by four numbers (x,y,z,t) called coordinates or co-ordinates. These are related by the following equation:  x2+y2-z2-t2=(c^2)(1-(v/c))1/2   Where c represents the speed of light and v represents the velocity of the object being observed. This equation describes the relationship between distance travelled along the x-axis, y-axis, z-axis and t-axis respectively. For example, if you were observing someone walking across your living room floor with their back towards you they would have a positive value for the x-axis but no values for the other three axes because they are not moving in those directions. If however you were watching them walk away from you they would have negative values for all three axes except the x-axis since they are still travelling forward in that direction. As another example consider two objects traveling side-by-side down a roadway. They will both travel at the same speed so their velocities will be equal. However, if one car travels north while the other travels south they will appear to move faster than each other even though they are traveling at the same speed.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Geometry of Time , Axiom of Choice and Neuro - Biological Quantum Zeno Effect . Abstract : The geometry of time is the science of how space - time evolves in time .The axiom of selection asserts that for any set of non - empty sets there exists at least one collection which contains exactly one element from each set . In this paragraph we prove that if the universe has an underlying quantum structure then it follows that the topology of time can be described by using the axiom of choice to select a single position on every trajectory through spacetime .We also discuss some possible possibilities of our findings for neurobiology where the molecular Zeno effect could play a role in understanding particular aspects of cerebral activity such as consciousness . The geometry of time is the numerical model of how space - time evolutes over time 1 .It was first developed into physics by Hermann Minkowski 2 who proved that the topology of space - time could be described by four numbers ( x , y , z , t ) called coordinates or co - ordinates . These are related by the following equation : x2 + y2 - z2 - t2 = ( c ^ 2 ) ( 1 - ( v / c ) ) 1 / 2 Where c represents the speed of light and v indicates the velocity of the instrument being detected .This equation relates the relationship between distance travelled along the x - axis , y - axis , z - axis and t - axis respectively . For instance , if you were observing someone moving across your living hall room with their back towards you they may have a positive value for the x - axis but no values for the other three axes because they are not moving in those directions .If however you were watching them walk away from you they may have negative expressions for all three axes except the x - axis since they are still moving forward in that direction . As another example compare two bodies walking side - by - side down a street .They will both travel at the same speed so their velocities will be equal . However , if one vehicle rides north while the other travels south they will appear to move faster than each other even though they are traveling at the same speed .",
        "rewrite_text": "**Title: Geometry of Time, Axiom of Choice, and Neuro-Biological Quantum Zeno Effect**\n\n**Abstract:** This article explores the intricate relationship between the geometry of time, the axiom of choice, and the neuro-biological implications of the quantum Zeno effect. The geometry of time refers to the mathematical framework that describes the evolution of space-time as it progresses. The axiom of choice posits that for any collection of non-empty sets, it is possible to select exactly one element from each set. We demonstrate that if the universe possesses an inherent quantum structure, then the topology of time can be effectively characterized by employing the axiom of choice to identify a unique position along every trajectory within space-time. \n\nFurthermore, we delve into the potential ramifications of our findings within the field of neurobiology, particularly regarding the molecular Zeno effect, which may provide insights into specific aspects of cerebral functions, including consciousness. The concept of the geometry of time serves as a quantitative model for understanding how space-time evolves. Initially articulated in the realm of physics by Hermann Minkowski, this framework establishes that the topology of space-time can be represented through four coordinates: (x, y, z, t). These coordinates are interrelated by the equation: \n\n\\[ x^2 + y^2 - z^2 - t^2 = c^2 \\left(1 - \\frac{v}{c}\\right)^{1/2} \\]\n\nwhere \\( c \\) denotes the speed of light and \\( v \\) signifies the velocity of the observed object. This equation elucidates the relationship between the distances traveled along the respective axes. For example, when observing an individual moving with their back towards the observer, they may exhibit a positive value on the x-axis while remaining stationary on the other axes. Conversely, if the individual walks away, they would display negative values on the y and z axes while continuing to progress along the x-axis. Additionally, when comparing two entities moving parallel down a street, despite maintaining equal speeds, their apparent velocities may differ based on their directional movement. This exploration not only enhances our understanding of time's geometry but also opens avenues for further research into the intersections of physics and neurobiology.",
        "ori-fast-z-score": 0.5586608191273356,
        "water-fast-z-score": 6.841792643911278,
        "rewrite-fast-z-score": 0.47733437050543803
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  What do we really know about mass loss on the AGB? .\nAbstract:\nThe Asymptotic Giant Branch (AGB) is an evolutionary phase in which stars lose large amounts of mass, and are responsible for most dust production in galaxies. The exact mechanism by which this occurs remains unclear; however it has been suggested that pulsations play a key role.  In this work we present new observations of two evolved intermediate-mass stars with very different pulsation properties to investigate how their pulsational behaviour affects mass-loss rates. We find evidence that the star with higher amplitude pulsations loses more material than its less-pulsating counterpart. This suggests that high amplitudes may be required to drive significant mass loss during the AGB stage. However, our results also show that there appears to be no clear relationship between pulsation period or mode and mass loss rate. These findings have important implications for understanding the evolution of low-metallicity stars as well as the formation of planetary nebulae.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : What do we actually know about mass loss on the AGB ? .Abstract : The Asymptotic Giant Branch ( AGB ) is an evolutionary phase in which stars lose significant amounts of mass , and are responsible for most dust production in galaxies . The exact mechanism by which this appears remains unsure ; however it has been proposed that pulsations hold a key role .In this research we present new experiments of two expanded intermediate - mass stars with very different pulsation properties to examine how their pulsational behaviour affects mass - loss rates . We see evidence that the star with higher intensity pulsations loses more matter than its less - pulsating counterpart .This implies that high amplitudes might be required to drive considerable mass loss during the AGB stage . However , our findings also demonstrate that there seems to be no clear relationship between pulsation period or mode and mass loss rate .These studies have important implications for studying the evolution of low - metallicity stars as also as the formation of planetary nebulae .",
        "rewrite_text": "Title: Insights into Mass Loss Mechanisms on the Asymptotic Giant Branch\n\nAbstract: The Asymptotic Giant Branch (AGB) represents a critical evolutionary stage for stars, characterized by substantial mass loss that contributes significantly to the dust content in galaxies. Despite its importance, the precise mechanisms driving this mass loss remain poorly understood. Recent hypotheses suggest that stellar pulsations may play a pivotal role in this process. In this study, we investigate two intermediate-mass stars exhibiting markedly different pulsation characteristics to assess how these variations influence their mass-loss rates. Our experimental results indicate a correlation between pulsation intensity and mass loss, with the star exhibiting stronger pulsations demonstrating a greater loss of material compared to its less pulsating counterpart. This observation suggests that high-amplitude pulsations may be essential for facilitating significant mass loss during the AGB phase. However, our analysis also reveals an absence of a definitive relationship between the pulsation period or mode and the corresponding mass-loss rate. These findings have profound implications for our understanding of the evolutionary pathways of low-metallicity stars and the mechanisms underlying the formation of planetary nebulae. By elucidating the complexities of mass loss during the AGB phase, this research contributes to a more comprehensive understanding of stellar evolution and its impact on galactic dust production.",
        "ori-fast-z-score": 0.42640143271122083,
        "water-fast-z-score": 5.5432186252458715,
        "rewrite-fast-z-score": 0.09667364890456635
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stellar Content and Recent Star Formation History of the Local Group Dwarf Irregular Galaxy IC1613 .\nAbstract:\nWe present deep optical photometry in B, V , R c I c bands for the dwarf irregular galaxy IC 1613 obtained with the Wide Field Imager (WFI) at the MPG/ESO 2.2 m telescope on La Silla Observatory. The data were reduced using standard IRAF routines. We derived total magnitudes within an aperture radius of 5 arcsec by applying aperture corrections to the PSF-fitted magnitudes. Our results are compared with previous studies based on shallower observations. In addition we derive new estimates for the distance modulus DM = 27.9 ± 0.1 mag and foreground extinction A V = 0.10 ± 0.02 mag towards this galaxy. Using these values together with our photometric measurements we determined absolute magnitudes M B = −15.6 ± 0.3 mag, M V = −14.7 ± 0.4 mag, M Rc = −12.8 ± 0.5 mag, M Ic = −11.0 ± 0.6 mag and colour indices U−B = 1.45±0.25 mag, B−V =0.70±0.06 mag, V −Rc=0.55±0.05 mag, V −Ic=1.00±0.07 mag. These parameters allow us to estimate the mean metallicity Z = 0.008 ± 0.001 dex and age t = 3 Gyrs for the stellar population of IC 1613.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stellar Content and Recent Star Formation History of the Local Group Dwarf Irregular Galaxy IC1613 . Abstract : We report deep optical photometry in B , V , R c I c groups for the dwarf irregular universe IC 1613 obtained with the Wide Field Imager ( WFI ) at the MPG / ESO 2 . 2 m observatory on La Silla Observatory .The data were reduced using traditional IRAF procedures . We extracted total magnitudes within an lens radius of 5 arcsec by using aperture corrections to the PSF - fitted magnitudes .Our results are compared with previous findings based on shallower observations . In addition we derive new accounts for the distance modulus DM = 27 . 9 ± 0 . 1 mag and foreground extinction A V = 0 . 10 ± 0 . 02 mag towards this galaxy .Using these values combined with our photometric calculations we calculated absolute magnitudes M B = −15 . 6 ± 0 . 3 mag , M V = −14 . 7 ± 0 . 4 mag , M Rc = −12 . 8 ± 0 . 5 mag , M Ic = −11 . 0 ± 0 . 6 mag and colour indices U−B = 1 . 45±0 . 25 mag , B−V = 0 . 70±0 . 06 mag , V −Rc = 0 . 55±0 . 05 mag , V −Ic = 1 . 00±0 . 07 mag . These variables enable us to estimate the mean metallicity Z = 0 . 008 ± 0 . 001 dex and age t = 3 Gyrs for the stellar population of IC 1613 .",
        "rewrite_text": "We present a comprehensive analysis of the stellar content and recent star formation history of the dwarf irregular galaxy IC 1613, utilizing deep optical photometry in the B, V, R_c, and I_c bands. This data was acquired using the Wide Field Imager (WFI) at the MPG/ESO 2.2 m telescope located at La Silla Observatory. The photometric data were processed using standard IRAF procedures, allowing us to extract total magnitudes within a lens radius of 5 arcseconds, applying aperture corrections to the PSF-fitted magnitudes. Our findings are juxtaposed with earlier studies that relied on shallower observations, providing a more detailed understanding of the galaxy's characteristics. \n\nFurthermore, we have derived new estimates for the distance modulus, DM = 27.9 ± 0.1 mag, and the foreground extinction, A_V = 0.10 ± 0.02 mag, for IC 1613. By integrating these values with our photometric measurements, we calculated the absolute magnitudes: M_B = -15.6 ± 0.3 mag, M_V = -14.7 ± 0.4 mag, M_Rc = -12.8 ± 0.5 mag, and M_Ic = -11.0 ± 0.6 mag. Additionally, we determined the color indices: U−B = 1.45 ± 0.25 mag, B−V = 0.70 ± 0.06 mag, V−R_c = 0.55 ± 0.05 mag, and V−I_c = 1.00 ± 0.07 mag. These parameters facilitate the estimation of the mean metallicity of the stellar population, yielding Z = 0.008 ± 0.001 dex, and suggest an age of approximately t = 3 Gyr for the stars in IC 1613. This study enhances our understanding of the stellar properties and evolutionary history of this intriguing member of the Local Group.",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 4.093146241443879,
        "rewrite-fast-z-score": 0.953998092005724
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  WHAM: A WENO-based general relativistic numerical scheme I: Hydrodynamics .\nAbstract:\nWe present the first version of our new code, WHAM (Weno-Hybrid Arbitrary Mesh), which is based on the recently developed weighted essentially non-oscillatory (WENO) schemes for solving hyperbolic conservation laws in one dimension and multi-dimensions.  The main idea behind this method is to use high-order spatial reconstruction with an adaptive mesh refinement technique to achieve high accuracy at low computational cost. We have implemented several different versions of the WENO algorithm into our code including the fifth-order WENO-Z scheme as well as the third- and fifth-order WENO-JS schemes. In addition we also implement the fourth-order Runge-Kutta time integration scheme along with the Harten-Lax-van Leer contact discontinuity capturing scheme to handle discontinuities arising during hydrodynamic evolution. Our results show that all these algorithms are able to produce accurate solutions when compared against exact or reference solutions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : WHAM : A WENO - based general relativistic numerical system I : Hydrodynamics . Abstract : We introduce the first version of our new code , WHAM ( Weno - Hybrid Arbitrary Mesh ) , which is based on the recently established weighted essentially non - oscillatory ( WENO ) schemes for solving hyperbolic conservation laws in one dimension and multi - dimensions .The main idea behind this algorithm is to use large - order spatial reconstruction with an adaptive mesh refinement technique to achieve high sensitivity at low computational efficiency . We have integrated various different versions of the WENO algorithm into our code including the fifth - order WENO - Z plan as well as the third - and fifth - order WENO - JS schemes .In addition we also incorporate the fourth - order Runge - Kutta time integration scheme along with the Harten - Lax - van Leer contact discontinuity capturing scheme to manage discontinuities resulting during hydrodynamic evolution . Our results show that all these algorithms are able to produce accurate solutions when compared against exact or reference solutions .",
        "rewrite_text": "We present the initial version of our innovative computational code, WHAM (Weno-Hybrid Arbitrary Mesh), which leverages the recently developed weighted essentially non-oscillatory (WENO) schemes for addressing hyperbolic conservation laws across both one-dimensional and multi-dimensional frameworks. The core principle of this algorithm lies in its ability to employ high-order spatial reconstruction in conjunction with an adaptive mesh refinement strategy, enabling enhanced sensitivity while maintaining computational efficiency. Our implementation includes various iterations of the WENO algorithm, notably the fifth-order WENO-Z scheme, as well as the third- and fifth-order WENO-JS schemes. Furthermore, we have integrated a fourth-order Runge-Kutta method for time integration, complemented by the Harten-Lax-van Leer (HLL) scheme for effectively capturing contact discontinuities that arise during the hydrodynamic evolution process. The performance of our code has been rigorously evaluated, and our findings indicate that all incorporated algorithms yield highly accurate solutions when benchmarked against exact or reference solutions. This work marks a significant advancement in the field of general relativistic hydrodynamics, providing a robust numerical framework for future research and applications.",
        "ori-fast-z-score": 1.9188064472004938,
        "water-fast-z-score": 4.9819900360298925,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Plasma Puddle as a Perturbative Black Hole .\nAbstract:\nWe propose that the plasma puddle is an analogue model for perturbative black holes in quantum gravity, and we show how this can be used to calculate Hawking radiation.  We consider a system consisting of two parallel plates separated by a distance L with a dielectric medium between them. The plates are connected to a voltage source which causes current to flow through the dielectric medium. This results in the formation of a plasma puddle on top of one plate. In order to study the properties of such a plasma puddle, we use a fluid description where the charge carriers are treated as particles moving under the influence of electric fields generated by their own motion. Using this approach, we find that there exists a critical value of the applied voltage Vc above which the plasma puddle becomes unstable against perturbations. For voltages larger than Vc , the plasma puddle collapses into a single point-like object called a  plasma ball .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Plasma Puddle as a Perturbative Black Hole . Abstract : We suggest that the plasma puddle is an analogue model for perturbative black holes in quantum gravitational , and we give how this can be used to estimate Hawking radiation .We consider a system consisting of two connected sheets connected by a distance L with a dielectric medium between them . The plates are connected to a voltage source which gives charge to travel through the dielectric medium .This results in the formation of a plasma puddle on top of one plate . In order to study the properties of such a plasma puddle , we using a fluid model where the charge carriers are treated as particles moving under the effects of electric forces generated by their own movement .Using this methodology , we find that there exists a critical quantity of the introduced voltage Vc above which the plasma puddle becomes unstable against perturbations . For voltages larger than Vc , the plasma puddle collapses into a single point - like substance called a plasma ball .",
        "rewrite_text": "Title: The Plasma Puddle as a Perturbative Black Hole\n\nAbstract: In this study, we propose that the plasma puddle serves as an analogue model for perturbative black holes within the framework of quantum gravity. We explore how this model can be utilized to estimate the characteristics of Hawking radiation. Our investigation focuses on a system comprising two conductive plates separated by a distance L, with a dielectric medium interposed between them. When connected to a voltage source, charge carriers are induced to traverse the dielectric, leading to the emergence of a plasma puddle on one of the plates. To analyze the properties of this plasma puddle, we employ a fluid model that treats the charge carriers as particles influenced by electric forces arising from their own motion. Through this approach, we identify a critical voltage threshold, denoted as Vc, beyond which the plasma puddle exhibits instability in response to perturbations. When the applied voltage exceeds Vc, the plasma puddle undergoes a collapse, resulting in the formation of a singular point-like entity referred to as a plasma ball. This phenomenon not only enhances our understanding of plasma dynamics but also provides insights into the behavior of black holes in a quantum context, potentially bridging concepts from condensed matter physics and gravitational theories. Our findings suggest that the dynamics of the plasma puddle could serve as a valuable experimental platform for investigating the fundamental aspects of Hawking radiation and the nature of black holes in a perturbative regime.",
        "ori-fast-z-score": -0.5773502691896257,
        "water-fast-z-score": 4.216541329006604,
        "rewrite-fast-z-score": 1.539600717839002
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Exploiting Social Annotation for Automatic Resource Discovery .\nAbstract:\nSocial tagging is an emerging technology that allows users to annotate resources with keywords or tags, which are then used by other users in their search and discovery processes. In this work we propose a novel approach to exploit social annotation information for automatic resource discovery. We first introduce the concept of semantic similarity between tags based on WordNet ontology. Then, using the proposed semantic similarity measure as well as user profile information, we develop two algorithms (i) TagRank and (ii) UserTagRank to rank the importance of each tag associated with a given resource. Finally, we conduct experiments over real-world datasets collected from Delicious website to evaluate our approaches. The experimental results show that both TagRank and UserTagRank can significantly improve the performance of existing state-of-the-art techniques. Keywords: Semantic Web, Social Tagging, Resource Discovery, Ranking Algorithms. 1 Introduction Social tagging has become one of the most popular ways for people to organize and share web content such as blogs, photos, videos etc., especially among Internet users who have little knowledge about how to use traditional search engines effectively  1  . Users usually assign tags to describe the contents they find interesting so that others may easily discover them later  2  .\nIn recent years there has been growing interest in developing new technologies to take advantage of social tagging systems  3  , including recommender systems  4  , personalized search  5  , question answering  6  , text classification  7  , event detection  8  , and so forth. However, despite these efforts, research into utilizing social tagging data for automatic resource discovery remains relatively unexplored  9  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Exploiting Social Annotation for Automatic Resource Discovery . Abstract : Social tagging is an evolving technique that enables consumers to annotate resources with keywords or tags , which are then utilized by other users in their search and finding processes .In this project we pursue a new approach to use social annotation info for efficient resource discovery . We first introduce the idea of semantic similarity between labels based on WordNet ontology .Then , using the suggested semantic similarity metric as well as customer profile details , we develop two algorithms ( i ) TagRank and ( ii ) UserTagRank to score the importance of each tag attributed with a given resource . Finally , we conduct experiments over real - time datasets collected from Delicious website to analyze our approaches .The empirical results show that both TagRank and UserTagRank can significantly boost the performance of older state - of - the - art methods . Keywords : Semantic Web , Social Tagging , Resource Discovery , Ranking Algorithms .1 Introduction Social tagging has become one of the most popular ways for people to organize and communicate website data such as websites , photos , movies etc . , particularly among Internet people who have less knowledge about how to use conventional search sites effectively 1 . Users typically give tags to explain the contents they discover attractive so that others would easily discover them later 2 .In recent years there has been growing interest in building new inventions to take advantage of social tagging technologies 3 , notably recommender methods 4 , personalized search 5 , question telling 6 , word classification 7 , event screening 8 , and so forth . However , despite these attempts , work into using social tagging material for automatic resource extraction continues relatively unexplored 9 .",
        "rewrite_text": "**Title:** Leveraging Social Annotation for Enhanced Resource Discovery\n\n**Abstract:** Social tagging has emerged as a dynamic method that allows users to annotate digital resources with keywords or tags, facilitating easier search and retrieval for others. This study explores a novel approach to harness social annotation data for more effective resource discovery. We begin by introducing the concept of semantic similarity among tags, grounded in the WordNet ontology. Utilizing this semantic similarity metric, along with user profile information, we propose two innovative algorithms: (i) TagRank and (ii) UserTagRank. These algorithms are designed to evaluate and rank the significance of tags associated with specific resources. To validate our methodologies, we conducted experiments using real-time datasets sourced from the Delicious platform. The results of our empirical analysis demonstrate that both TagRank and UserTagRank substantially enhance the performance of existing state-of-the-art techniques in resource discovery. \n\nKeywords: Semantic Web, Social Tagging, Resource Discovery, Ranking Algorithms.\n\n**1 Introduction:** Social tagging has gained immense popularity as a means for individuals to organize and share web-based content, including websites, images, and videos, particularly among users who may not be adept at utilizing traditional search engines effectively. Users typically assign tags to describe the content they find appealing, thereby enabling others to locate these resources with greater ease. In recent years, there has been a surge of interest in developing innovative applications that leverage social tagging technologies, including recommendation systems, personalized search engines, question answering, text classification, and event detection. Despite these advancements, the exploration of social tagging data for automated resource extraction remains relatively underdeveloped. This paper aims to bridge that gap by proposing methods that capitalize on the potential of social annotations for improved resource discovery.",
        "ori-fast-z-score": -2.1358941442919024,
        "water-fast-z-score": 7.548881474151742,
        "rewrite-fast-z-score": -1.5778641172210595
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Distortion in Groups of Circle and Surface Diffeomorphisms .\nAbstract:\nWe study the distortion between two groups of diffeomorphisms, one acting on the circle and another acting on surfaces with boundary. We show that if the first group is generated by an irrational rotation number then there exists a sequence of elements in the second group which converges to it exponentially fast (in terms of their Lipschitz constants). This result can be viewed as a generalization of the classical Denjoy theorem for circle homeomorphisms. The proof uses techniques developed recently in geometric measure theory such as rectifiability properties of invariant measures under surface diffeomorphisms. In particular we use results due to David Gabai, Richard Hamilton, and Michael Hutchings. Keywords: Geometric measure theory; Group actions; Distortion; Rectifiability; Invariant measures; Homeomorphism; Diffemorphism; Circle; Surface; Boundary; Rotation number; Exponential convergence; Lipschitz constant",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Distortion in Groups of Circle and Surface Diffeomorphisms . Abstract : We explore the distortion between two groups of diffeomorphisms , one acted on the circle and another acts on surfaces with boundary .We see that if the first group is generated by an irrational rotation number then there exists a sequence of elements in the second group which converges to it exponentially rapidly ( in terms of their Lipschitz constants ) . This result can be viewed as a generalization of the classical Denjoy theorem for circle homeomorphisms .The proof uses methods developed lately in geometric measure theory such as rectifiability properties of invariant measures under surface diffeomorphisms . In particular we using findings due to David Gabai , Richard Hamilton , and Michael Hutchings .Keywords : Geometric measure theory ; Group activities ; Distortion ; Rectifiability ; Invariant measures ; Homeomorphism ; Diffemorphism ; Circle ; Surface ; Boundary ; Rotation size ; Exponential convergence ; Lipschitz constant",
        "rewrite_text": "Title: Distortion in Groups of Circle and Surface Diffeomorphisms\n\nAbstract: This article investigates the distortion phenomena between two distinct groups of diffeomorphisms: one that operates on the circle and another that acts on surfaces with boundaries. Our primary focus is on the scenario where the first group is generated by an irrational rotation number. We demonstrate that under these conditions, there exists a sequence of elements from the second group that converges to the first group at an exponential rate, specifically in relation to their Lipschitz constants. This finding serves as a significant extension of the classical Denjoy theorem, which pertains to circle homeomorphisms. The methodology employed in our proof leverages recent advancements in geometric measure theory, particularly concerning the rectifiability properties of invariant measures associated with surface diffeomorphisms. Notably, we draw upon the contributions of prominent researchers in the field, including David Gabai, Richard Hamilton, and Michael Hutchings, to support our results. This work not only enhances the understanding of the interplay between different types of diffeomorphisms but also enriches the theoretical framework surrounding geometric measure theory. Our findings have implications for the study of dynamical systems and the behavior of transformations on various geometric structures. \n\nKeywords: Geometric measure theory; Group actions; Distortion; Rectifiability; Invariant measures; Homeomorphism; Diffeomorphism; Circle; Surface; Boundary; Rotation number; Exponential convergence; Lipschitz constant.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.5762373640756184,
        "rewrite-fast-z-score": -0.21320071635561041
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Bounds on quark mass matrices elements due to measured properties of the mixing matrix and present values of the quark masses .\nAbstract:\nWe derive bounds on the absolute values of all entries in the up- and down-quark mass matrices, using only information about the CKM-matrix and current experimental data for the masses of quarks. We find that these bounds are much stronger than those obtained previously by other authors. \n \n The results presented here can be used as input parameters for future studies of CP violation within the Standard Model or its extensions. They also provide useful constraints on models with extra dimensions where quarks propagate into higher-dimensional bulk spaces. \nI. INTRODUCTORY REMARK\nThe Cabibbo-Kobayashi-Maskawa (CKM)  1  quark mixing matrix V is an unitary 3 x 3 complex matrix which describes how quarks mix among themselves after electroweak symmetry breaking. It contains nine independent real parameters, three angles θ12 , θ23 , θ13 and six phases φ1 , φ2 ,...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Bounds on quark mass matrices elements owing to calculated properties of the mix matrix and current values of the quark masses . Abstract : We derive bounds on the absolute values of all entries in the up - and down - quark mass matrices , using only data about the CKM - vector and current experimental evidence for the masses of quarks .We see that these limits are greatly strengthened than those achieved previously by other researchers . The results presented here can be used as input parameters for future research of CP violation within the Standard Model or its extended .They addition offer useful limitations on models with extra dimensions where quarks propagate into larger - dimensional bulk spaces . I .INTRODUCTORY REMARK The Cabibbo - Kobayashi - Maskawa ( CKM ) 1 quark mixing function V is an unitary 3 x 3 complex graph which explains how quarks blend among themselves after electroweak symmetry breaking . It contains nine independent real characteristics , three axes θ12 , θ23 , θ13 and six phases φ1 , φ2 , . . .",
        "rewrite_text": "Title: Bounds on Quark Mass Matrix Elements Derived from CKM Matrix Properties and Current Quark Mass Values\n\nAbstract: In this study, we establish stringent bounds on the absolute values of all elements within the up and down quark mass matrices, relying solely on the properties of the Cabibbo-Kobayashi-Maskawa (CKM) matrix and the latest experimental measurements of quark masses. Our findings indicate that these constraints are significantly more robust than those previously reported in the literature. The implications of our results are substantial, as they can serve as critical input parameters for future investigations into CP violation within the framework of the Standard Model and its extensions. Furthermore, our derived limits provide valuable insights for theoretical models that incorporate extra dimensions, particularly those where quarks are theorized to propagate through higher-dimensional bulk spaces. \n\nIn the introduction, we discuss the CKM matrix, a unitary 3x3 complex matrix that describes the mixing of quarks following electroweak symmetry breaking. This matrix is characterized by nine independent real parameters, which include three mixing angles (θ12, θ23, θ13) and six CP-violating phases (φ1, φ2, ...). By analyzing the interplay between these parameters and the current quark mass values, we derive new bounds that enhance our understanding of quark mass hierarchies and mixing phenomena. Our work not only refines existing theoretical frameworks but also opens avenues for further research in particle physics, particularly in exploring the implications of quark mass matrices on fundamental symmetries and the structure of the universe.",
        "ori-fast-z-score": -1.0392304845413263,
        "water-fast-z-score": 5.047146145152358,
        "rewrite-fast-z-score": 1.7822655773580138
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Tracking User Attention in Collaborative Tagging Communities .\nAbstract:\nWe present an analysis of user attention to tags and resources in collaborative tagging communities, based on the data collected by Delicious.com over three years (2005-2007). We find that users  attention is highly skewed towards popular tags and resources; only about 0.1% of all tags are ever used more than once, while less than 1% of all resources receive more than one bookmark. The distribution of user attention follows Zipf s law for both tags and resources. In addition, we show how this skewness can be explained by two factors: 1) the popularity bias -the fact that most users tend to use tags or resources which they have seen before- and 2) the social influence -the tendency of people to follow others who share their interests. Finally, we propose several metrics to measure user attention, including novel measures such as the number of distinct users who bookmarked each resource/tag at least once during our observation period.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Tracking User Attention in Collaborative Tagging Communities . Abstract : We report an assessment of customer attention to tags and assets in joint tagging environments , based on the information collected by Delicious . com over three years ( 2005 - 2007 ) .We see that users focus is heavily skewed towards popular tags and assets ; only about 0 . 1 % of all labels are ever used more than once , while none than 1 % of all resources receive more than one bookmark . The distribution of customer focus follows Zipf s law for both tags and assets .In addition , we find how this skewness can be described by two factors : 1 ) the fame bias - the fact that most users prefer to use tags or assets which they have viewed before - and 2 ) the social impact - the tendency of people to follow people who share their interests . Finally , we propose several metrics to measure user awareness , including novel estimates such as the proportion of distinct consumers who bookmarked each resource / tag at least once during our survey period .",
        "rewrite_text": "In this article, we present a comprehensive analysis of user attention within collaborative tagging communities, utilizing data gathered from Delicious.com over a three-year period from 2005 to 2007. Our findings reveal a significant concentration of user focus on a limited number of popular tags and resources. Specifically, we observe that a mere 0.1% of all tags are utilized more than once, while less than 1% of resources receive multiple bookmarks. This distribution of user attention aligns with Zipf's law, indicating a predictable pattern in the way users engage with tags and assets.\n\nWe identify two primary factors contributing to this pronounced skew in user attention. The first is the \"fame bias,\" which suggests that users are inclined to engage with tags and resources they have previously encountered. The second factor is the \"social impact,\" highlighting the tendency of individuals to follow the tagging behaviors of others who share similar interests. These insights underscore the social dynamics at play in collaborative tagging environments and how they influence user behavior.\n\nTo further our understanding of user engagement, we propose several metrics designed to quantify user awareness. Among these metrics is a novel estimation of the proportion of distinct users who have bookmarked each resource or tag at least once during the study period. This approach allows for a more nuanced understanding of user interactions within tagging communities and provides a framework for future research in this area. Overall, our study sheds light on the patterns of user attention in collaborative tagging systems and offers valuable insights for enhancing user experience in such environments.",
        "ori-fast-z-score": -1.585187847802434,
        "water-fast-z-score": 5.661385170722978,
        "rewrite-fast-z-score": -1.0606601717798212
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Strongly modulated transmission of a spin-split quantum wire with local Rashba interaction .\nAbstract:\nWe study the transport properties in a one-dimensional (1D) spin-orbit coupled system, where the electron-electron interactions are treated within the Hartree-Fock approximation. We find that for strong enough spin-orbit coupling and repulsive interactions there is an insulating phase at half-filling which can be understood as a Mott insulator due to the formation of bound states between electrons on neighboring sites. The transition into this state occurs when the Fermi energy crosses the lowest bound state. In addition we show how the presence of disorder changes these results. Finally, we discuss possible experimental realizations of our model using semiconductor nanowires or carbon nanotubes. Introduction:-In recent years it has been realized that many interesting phenomena observed in condensed matter physics such as high-Tc superconductivity  1  , fractional quantum Hall effect  2  etc., have their origin in strongly correlated electronic systems. One of the simplest models describing interacting fermions is the Hubbard model  3  . However, even though much progress has been made over the past few decades  4  , exact solutions of the Hubbard model are still lacking  5  .\nRecently, several authors  6  -  8  studied the effects of spin-orbit coupling on the ground-state properties of 1D Hubbard chains by employing various numerical techniques like density matrix renormalization group  9  , exact diagonalization  10  , DMRG  11  , Bethe ansatz  12  , variational Monte Carlo  13  , Quantum Monte Carlo  14  etc.. It was found that depending upon the strength of spin-orbit coupling and the value of Coulomb repulsion U , different phases appear in the ground state. For example, if the spin-orbit coupling is weak compared to the hopping amplitude t then the ground state is either metallic or insulating depending on whether U/t < 2 or U/t > 2 respectively  15  . On the other hand, if the spin-orbit",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Strongly modulated transmission of a spin - split quantum wire with local Rashba coupling . Abstract : We research the travel properties in a one - dimensional ( 1D ) spin - orbit coupled system , where the electron - electron interactions are treated within the Hartree - Fock approximation .We see that for strong enough spin - orbit bonding and repulsive bonding there is an insulating phase at half - filling which can be understood as a Mott insulator owing to the formation of bound states between electrons on nearby locations . The shift into this state occurs when the Fermi energy crosses the lowest bound state .In addition we explain how the presence of disorder changes these results . Finally , we explain possible experimental realizations of our model utilizing semiconductor nanowires or carbon nanotubes .Introduction : - In recent years it has been realized that several interesting phenomena observed in condensed matter science such as high - Tc superconductivity 1 , fractional quantum Hall impact 2 etc . , have their source in highly correlated electronic systems . One of the simplest models explaining interacting fermions is the Hubbard theory 3 .However , even though much work has been achieved over the previous few years 4 , exact solutions of the Hubbard theory are still lacking 5 . Recently , various scientists 6 - 8 studied the effects of spin - orbit interaction on the ground - state properties of 1D Hubbard chains by employing several mathematical techniques like density matrix renormalization group 9 , exact diagonalization 10 , DMRG 11 , Bethe ansatz 12 , variational Monte Carlo 13 , Quantum Monte Carlo 14 etc . .It was shown that depending upon the strength of spin - orbit interaction and the value of Coulomb repulsion U , different stages appear in the ground state . For instance , if the spin - orbit interaction is weakened compared to the hopping frequency t then the ground state is either metallic or insulating depending on whether U / t < 2 or U / t > 2 respectively 15 .On the other hand , if the spin - orbit",
        "rewrite_text": "**Title:** Strongly Modulated Transmission of a Spin-Split Quantum Wire with Local Rashba Coupling\n\n**Abstract:** This study investigates the transport characteristics of a one-dimensional (1D) spin-orbit coupled system, incorporating electron-electron interactions through the Hartree-Fock approximation. Our findings reveal that when the spin-orbit coupling and repulsive interactions are sufficiently strong, the system exhibits an insulating phase at half-filling, which can be interpreted as a Mott insulator. This insulating phase arises from the formation of bound states between electrons located in proximity to one another. The transition to this insulating state occurs when the Fermi energy intersects with the lowest bound state. Furthermore, we analyze the impact of disorder on these transport properties, demonstrating how it modifies the system's behavior. We also discuss potential experimental implementations of our theoretical model, suggesting that semiconductor nanowires or carbon nanotubes could serve as viable platforms for realizing these phenomena. \n\nIn recent years, significant attention has been directed towards understanding complex phenomena in condensed matter physics, such as high-temperature superconductivity and fractional quantum Hall effects, which are rooted in highly correlated electronic systems. The Hubbard model serves as a fundamental framework for exploring interacting fermions; however, exact solutions remain elusive. Recent investigations have focused on the effects of spin-orbit interactions on the ground-state properties of 1D Hubbard chains, employing a variety of advanced mathematical techniques, including density matrix renormalization group, exact diagonalization, and quantum Monte Carlo methods. These studies have shown that the interplay between spin-orbit coupling and Coulomb repulsion leads to distinct phases in the ground state. Specifically, when the spin-orbit interaction is weaker than the hopping parameter, the ground state can be classified as either metallic or insulating, contingent upon the ratio of Coulomb repulsion to hopping strength. This research contributes to the broader understanding of spin-orbit coupled systems and their potential applications in future quantum technologies.",
        "ori-fast-z-score": -0.7474093186836597,
        "water-fast-z-score": 5.85598130178049,
        "rewrite-fast-z-score": 0.16329931618554522
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Reexamining the Einstein-Podolsky-Rosen experiment, photon correlation and Bell s inequality .\nAbstract:\nThe EPR paradox is one of the most important problems in quantum mechanics. It was formulated by Einstein et al., who claimed that it could be solved only if there existed hidden variables which were not included in the standard formulation of quantum mechanics. The original EPR argument has been criticized on several grounds including its reliance upon an unjustified assumption about locality. In this work we reexamine the EPR experiment using modern techniques for measuring correlations between photons produced via parametric down-conversion (PDC). We show how to measure all relevant quantities needed to test Bell s theorem with PDC sources. Our results are consistent with those predicted by quantum mechanics but do not violate any known bounds on nonlocality. This suggests that the original EPR argument may have been flawed or incomplete. Quantum entanglement plays a central role in many areas of physics ranging from condensed matter systems to high energy particle collisions. However, despite decades of research into the foundations of quantum mechanics, the exact nature of quantum entanglement remains elusive. One of the main reasons behind this difficulty lies in the fact that quantum states cannot generally be cloned  1  . As such, it is impossible to perform experiments where two copies of a given state can be prepared independently so as to compare their properties directly  2  .\nIn 1964, John Bell showed that certain types of measurements performed on pairs of particles would lead to violations of classical inequalities  3  , thereby demonstrating that quantum mechanical predictions cannot always be reproduced within a classical framework  4  . Since then, numerous experimental tests of these so-called Bell inequalities have been carried out  5  -  8  . Most notably, in 1992, Aspect et al. reported the first violation of Bell s inequality  9  , thus confirming the existence of quantum entanglement experimentally  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Reexamining the Einstein - Podolsky - Rosen experiment , photon correlation and Bell s inequality . Abstract : The EPR paradox is one of the most important problems in quantum mechanics .It was formulated by Einstein et al . , who claimed that it could be answered only if there contained hidden variables which were not covered in the standard implementation of quantum mechanics . The original EPR argument has been challenged on numerous grounds namely its reliance upon an unjustified assumption about locality .In this study we reexamine the EPR study using contemporary methods for measuring correlations between photons generated via parametric down - transfer ( PDC ) . We see how to measure all relevant quantities required to test Bell s theorem with PDC sources .Our results are compatible with those predicted by quantum mechanics but do not violate any established limits on nonlocality . This implies that the previous EPR argument might have been flawed or incomplete .Quantum entanglement plays a central role in many fields of science ranging from condensed matter structures to large energy particle collisions . However , despite decades of research into the foundations of quantum mechanics , the exact structure of quantum entanglement continues elusive .One of the main motives behind this difficulty lies in the fact that quantum states cannot typically be cloned 1 . As such , it is unable to conduct experiments where two copy of a given state can be made independently so as to relate their characteristics directly 2 .In 1964 , John Bell demonstrated that particular kinds of measurements completed on sets of particles might lead to violations of classical inequalities 3 , thereby showing that quantum mechanical predictions cannot often be verified within a classical framework 4 . Since then , various experimental tests of these so - called Bell inequalities have been carried out 5 - 8 .Most notably , in 1992 , Aspect et al . reported the first violation of Bell s inequality 9 , thus proving the existence of quantum entanglement experimentally 10 .",
        "rewrite_text": "**Title:** Reexamining the Einstein-Podolsky-Rosen Experiment, Photon Correlation, and Bell's Inequality\n\n**Abstract:** The Einstein-Podolsky-Rosen (EPR) paradox remains a pivotal issue in the realm of quantum mechanics, initially posited by Einstein and his colleagues, who suggested that the resolution of this paradox necessitated the existence of hidden variables beyond the conventional framework of quantum theory. The original EPR argument has faced scrutiny, particularly due to its dependence on an unsubstantiated assumption regarding locality. In this paper, we revisit the EPR scenario utilizing modern techniques for measuring correlations among photons produced through parametric down-conversion (PDC). We demonstrate a methodology for quantifying all essential parameters needed to evaluate Bell's theorem in the context of PDC sources. Our findings align with the predictions of quantum mechanics while remaining within the established boundaries of nonlocality, suggesting that the original EPR argument may have been flawed or incomplete.\n\nQuantum entanglement is fundamental to various scientific disciplines, ranging from condensed matter physics to high-energy particle collisions. Despite extensive investigations into the foundational aspects of quantum mechanics over the years, the precise nature of quantum entanglement remains elusive. A significant challenge in this area stems from the non-clonability of quantum states, which complicates the ability to conduct experiments that involve creating independent copies of a given state for direct comparison of their properties. In 1964, John Bell introduced a groundbreaking concept demonstrating that specific measurements on sets of particles could lead to violations of classical inequalities, thereby illustrating that quantum mechanical predictions often cannot be reconciled within a classical framework. Since Bell's seminal work, numerous experimental tests of these so-called Bell inequalities have been conducted, with a landmark achievement occurring in 1992 when Aspect et al. reported the first experimental violation of Bell's inequality, thereby providing empirical evidence for the phenomenon of quantum entanglement. This study contributes to the ongoing discourse surrounding the EPR paradox and the implications of quantum entanglement in contemporary physics.",
        "ori-fast-z-score": 0.16666666666666666,
        "water-fast-z-score": 8.387593465227736,
        "rewrite-fast-z-score": 1.8970080273373418
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Atom-wave diffraction between the Raman-Nath and the Bragg regime: Effective Rabi frequency, losses, and phase shifts .\nAbstract:\nWe study atom-waves in an optical lattice with periodic boundary conditions by solving numerically the Schrödinger equation for different values of the laser intensity and detuning. We find that there is a crossover between two regimes depending on whether or not the recoil energy is larger than the kinetic energy of the atoms. In this work we focus on the case where the recoil energy is smaller than the kinetic energy (Raman-Nath regime). The effective Rabi frequency, losses and phase shifts are calculated as functions of the parameters characterizing the system. Our results show good agreement with previous theoretical works. Finally, we present our conclusions. Atom waves can be described using quantum mechanics when they interact with light fields. This interaction leads to interesting phenomena such as Bloch oscillations  1  , Zener tunneling  2  , Landau-Zener-Stückelberg-Majorana transitions  3  , and Anderson localization  4  . These effects have been studied both theoretically  5  -  8  and experimentally  9  -  11  .\nIn particular, it has recently become possible to create Bose-Einstein condensates  12  which allow one to observe these phenomena at low temperatures  13  -  16  . For example, in Ref.  17  , the authors observed Bloch oscillations in a cold atomic gas trapped inside an optical lattice created by counter-propagating lasers. They also found evidence of Zener tunneling  18  in their experiment. Moreover, in Refs.  19  and  20  , the authors investigated the effect of disorder on the transport properties of matter waves in optical lattices.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Atom - wave diffraction between the Raman - Nath and the Bragg regime : Effective Rabi frequency , lost , and phase transitions . Abstract : We explore particle - radiation in an optical lattice with periodic border conditions by solving numerically the Schrödinger equation for different values of the laser intensity and detuning .We see that there is a crossover between two regimes based on whether or not the recoil power is bigger than the kinetic power of the atoms . In this research we focus on the case where the recoil power is smaller than the kinetic power ( Raman - Nath regime ) .The effective Rabi frequency , losses and phase transitions are measured as functions of the variables characterizing the process . Our results show good agreement with previous conceptual works .Finally , we present our conclusions . Atom signals can be described using quantum mechanics when they interact with light fields .This coupling gives to unusual phenomena such as Bloch oscillations 1 , Zener tunneling 2 , Landau - Zener - Stückelberg - Majorana interactions 3 , and Anderson localization 4 . These effects have been studied both theoretically 5 - 8 and experimentally 9 - 11 .In particular , it has recently become able to create Bose - Einstein condensates 12 which allow one to observe these phenomena at low temperatures 13 - 16 . For instance , in Ref .17 , the authors detected Bloch oscillations in a cold atomic gas trapped inside an optical lattice created by anti - propagating lasers . They also discovered evidence of Zener tunneling 18 in their experiment .Moreover , in Refs . 19 and 20 , the published investigated the impact of disorder on the travel properties of matter waves in optical lattices .",
        "rewrite_text": "**Title:** Atom-Wave Diffraction Between the Raman-Nath and Bragg Regime: Effective Rabi Frequency, Losses, and Phase Transitions\n\n**Abstract:** This study investigates the interaction between particles and radiation within an optical lattice characterized by periodic boundary conditions, utilizing numerical solutions to the Schrödinger equation across varying laser intensities and detunings. Our focus is on the transition between two distinct regimes, specifically examining the scenario where the recoil power is less than the kinetic energy of the atoms, known as the Raman-Nath regime. We analyze the effective Rabi frequency, loss rates, and phase transitions as functions of the relevant parameters governing the interaction. The findings align closely with existing theoretical frameworks, reinforcing the validity of our approach.\n\nThe interaction of atoms with light fields can be effectively described through quantum mechanics, leading to a range of intriguing phenomena such as Bloch oscillations, Zener tunneling, and Landau-Zener-Stückelberg-Majorana interactions, as well as Anderson localization. These phenomena have been extensively explored in both theoretical and experimental contexts. Recent advancements have enabled the creation of Bose-Einstein condensates, facilitating the observation of these effects at low temperatures. For example, previous studies have successfully detected Bloch oscillations in cold atomic gases confined within optical lattices formed by counter-propagating laser beams, while also providing evidence for Zener tunneling.\n\nFurthermore, investigations into the influence of disorder on the propagation characteristics of matter waves in optical lattices have been documented, highlighting the complex interplay between atomic behavior and external fields. Our research contributes to this growing body of knowledge by elucidating the dynamics of atom-wave diffraction and the associated phase transitions, thereby enhancing our understanding of quantum systems in optical lattices. In conclusion, we summarize our key findings and their implications for future research in the field of quantum optics and atomic physics.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.05540651287698,
        "rewrite-fast-z-score": 1.9005105362789922
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Correlation amplitude and entanglement entropy in random spin chains .\nAbstract:\nWe study the correlation function and entanglement entropy for one-dimensional quantum systems with disordered interactions, focusing on their scaling behavior at large distances or times. We show that these quantities are related by an exact formula which is valid both in the ground state and in thermal equilibrium states. The relation can be used to obtain information about the entanglement structure of the system from measurements of correlations only. In particular we discuss how this method allows us to extract the von Neumann entropy of the reduced density matrix corresponding to half of the chain using data obtained from numerical simulations. \nI. INTRODUCTORY REMARK\nThe aim of this work is twofold. First, we want to present some new results concerning the relationship between correlation functions and entanglement entropies in disordered quantum many-body systems. Second, we would like to introduce a novel approach to calculate entanglement properties of such systems based solely on measuring correlation functions. This second aspect will be discussed in more detail below; here let us briefly summarize our main result before turning into technical details.\nConsider a generic quantum-mechanical model defined on a lattice consisting of L sites labeled by integers i = 1, ..., L. Let |0⟩ denote its ground state (which may also represent any other eigenstate) and consider the following quantity:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Correlation amplitude and entanglement entropy in random spin networks . Abstract : We research the interaction function and entanglement entropy for one - dimensional quantum systems with disordered interactions , concentrating on their scaling behavior at large distances or times .We see that these quantities are related by an precise formula which is valid both in the ground state and in heat equilibrium states . The relation can be used to obtain knowledge about the entanglement structure of the system from measurements of correlations only .In particular we explain how this algorithm allows us to extract the von Neumann entropy of the reduced density matrix corresponding to half of the chain using data derived from numerical simulations . I .INTRODUCTORY REMARK The goal of this project is twofold . First , we wish to provide some fresh results relating the relationship between correlation functions and entanglement entropies in disordered quantum several - bodies systems .Second , we may wish to introduce a novel method to estimate entanglement properties of such systems relying solely on measuring correlation functions . This second aspect will be mentioned in more detail below ; here allow us briefly summarize our major result before turning into technical details .Consider a generic quantum - mechanical model formulated on a lattice consisting of L locations labeled by integers i = 1 , . . . , L . Let | 0 ⟩ denote its ground state ( which may also represent any other eigenstate ) and consider the following quantity :",
        "rewrite_text": "**Title:** Correlation Amplitude and Entanglement Entropy in Random Spin Networks\n\n**Abstract:** In this study, we investigate the relationship between interaction functions and entanglement entropy in one-dimensional quantum systems characterized by disordered interactions, with a focus on their scaling behavior over large distances and time scales. Our findings reveal a precise mathematical relationship between these two quantities, which holds true in both the ground state and thermal equilibrium states. This relationship provides a powerful tool for inferring the entanglement structure of a system based solely on correlation measurements. Specifically, we demonstrate how our proposed algorithm can be utilized to derive the von Neumann entropy of the reduced density matrix for half of the quantum chain, using data obtained from numerical simulations. \n\nThe primary objective of this research is twofold. Firstly, we aim to present new insights into the interplay between correlation functions and entanglement entropies within disordered quantum many-body systems. Secondly, we introduce an innovative methodology for estimating the entanglement properties of these systems, relying exclusively on the measurement of correlation functions. This novel approach is discussed in greater detail later in the article. \n\nTo provide a foundational understanding, we consider a generic quantum mechanical model defined on a lattice with L sites, indexed by integers i = 1, ..., L. We denote the ground state of this system as |0⟩, which may also represent any other eigenstate of the system. Our analysis begins by examining the implications of this framework on the correlation and entanglement characteristics, paving the way for a deeper exploration of the underlying physics in disordered quantum systems. Through our research, we aim to bridge the gap between correlation measurements and entanglement properties, enhancing our understanding of quantum entanglement in complex systems.",
        "ori-fast-z-score": -0.5570860145311556,
        "water-fast-z-score": 5.408521132466447,
        "rewrite-fast-z-score": 1.474086948191004
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Chasing Brane Inflation in String-Theory .\nAbstract:\nThe idea that the universe underwent an inflationary phase at very early times is now widely accepted by cosmologists as one possible explanation for many observed features of our present-day universe, such as its flatness and homogeneity.  In this talk I will discuss how string-theoretic ideas can be used to construct models of inflation which are consistent with current observations. The basic idea behind these constructions is that they involve branes moving through extra dimensions of space-time. These branes may either move towards each other or away from each other depending on their initial conditions. If two branes collide then it leads to a rapid expansion of spacetime known as  inflation . This process continues until the branes separate again and the universe reverts back to its original size. As well as discussing some recent results obtained using these techniques, I will also describe some open problems associated with them. Finally, I will briefly mention another approach to constructing realistic models of inflation based upon so-called  brane-world scenarios .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Chasing Brane Inflation in String - Theory . Abstract : The idea that the universe underwent an inflationary phase at very earliest times is now widely accepted by cosmologists as one possible reason for numerous observed features of our present - day universe , such as its flatness and homogeneity .In this talk I will explore how string - theoretic theories can be used to build theories of inflation which are compatible with current observations . The basic idea behind these concepts is that they use branes moving through additional dimensions of space - time .These branes may either shift towards each other or away from each other depending on their early conditions . If two branes collide then it leads to a rapid increase of spacetime termed as inflation .This process proceeds until the branes separate again and the universe reverts back to its old length . As well as explaining some latest findings obtained using these experiments , I will also describe some open problems involved with them .Finally , I will briefly include another methodology to creating accurate theories of inflation centered upon so - called brane - global conditions .",
        "rewrite_text": "Title: Investigating Brane Inflation within String Theory\n\nAbstract: The concept of an inflationary phase in the early universe has gained significant traction among cosmologists, serving as a compelling explanation for various observed characteristics of our contemporary universe, including its flatness and uniformity. In this presentation, I will delve into the application of string theory to formulate inflationary models that align with current observational data. Central to these models is the notion of branes, which are multidimensional objects that traverse additional dimensions of spacetime. The dynamics of these branes, influenced by their initial conditions, dictate whether they move toward or away from one another. A critical event occurs when two branes collide, resulting in a rapid expansion of spacetime known as inflation. This inflationary phase continues until the branes separate, at which point the universe returns to its previous scale. In addition to discussing recent experimental findings that support these theories, I will address several unresolved issues that remain in this field of study. Furthermore, I will introduce an alternative approach to developing robust inflationary models based on the concept of brane-global conditions, highlighting its potential to enhance our understanding of the inflationary process in the context of string theory. Through this exploration, I aim to contribute to the ongoing discourse surrounding the intersection of string theory and cosmological inflation, shedding light on both the successes and challenges that lie ahead.",
        "ori-fast-z-score": 0.31799936400190804,
        "water-fast-z-score": 6.324555320336758,
        "rewrite-fast-z-score": 2.041241452319315
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Line and continuum variability of two intermediate-redshift, high-luminosity quasars .\nAbstract:\nWe present the results of an optical monitoring campaign on two luminous quasars at redshifts z = 1.7 and 2.1 with the aim to study their long-term line and continuum variability properties. The observations were carried out in the period between September 2005 and December 2007 using the Nordic Optical Telescope (NOT) equipped with ALFOSC. We find that both objects show significant variations over time scales ranging from months up to years. In particular we detect strong changes in the Hβ emission-line profiles which are accompanied by corresponding flux density fluctuations in the adjacent continuum regions. These findings suggest that the observed spectral changes can be explained as being due to variable obscuration effects caused by clouds moving across our line-of-sight towards the central engine. This scenario is supported by the fact that the detected variabilities appear to occur simultaneously for all three Balmer lines studied here. Furthermore, we find evidence for additional short-term variability events occurring within individual nights.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Line and continuum variability of two intermediate - redshift , large - luminosity quasars . Abstract : We report the results of an optical monitoring effort on two luminous quasars at redshifts z = 1 . 7 and 2 . 1 with the objective to study their long - term line and continuum variability properties .The surveys were carried out in the period between September 2005 and December 2007 utilizing the Nordic Optical Telescope ( NOT ) equipped with ALFOSC . We see that both images exhibit substantial variations over time ranges varied from months up to decades .In particular we perceive strong changes in the Hβ emission - line profiles which are marked by resulting flux concentration fluctuations in the adjacent continuum regions . These studies propose that the seen spectral changes can be understood as being owing to variable obscuration effects caused by clouds moved across our line - of - view towards the main engine .This scenario is backed by the fact that the reported variabilities appear to come concurrently for all three Balmer patterns examined here . Furthermore , we find proof for additional short - term variability events resulting within individual nights .",
        "rewrite_text": "We present the findings from an extensive optical monitoring campaign focused on two highly luminous quasars with redshifts of z = 1.7 and z = 2.1, aimed at investigating their long-term variability in both emission lines and continuum. The observational study was conducted using the Nordic Optical Telescope (NOT) equipped with the ALFOSC instrument, spanning from September 2005 to December 2007. Our analysis reveals significant temporal variations in the brightness of both quasars, with fluctuations observed over timescales ranging from months to decades. Notably, we detected pronounced changes in the Hβ emission line profiles, which corresponded with variations in the surrounding continuum flux. These spectral alterations suggest that the observed variability may be attributed to variable obscuration effects, likely caused by clouds that traverse our line of sight to the quasars' central engines. This interpretation is further supported by the simultaneous nature of the variability observed across all three Balmer lines analyzed in this study. Additionally, we provide evidence of short-term variability events occurring within individual nights, indicating a complex and dynamic environment surrounding these quasars. Our findings contribute to the understanding of the mechanisms driving variability in high-luminosity quasars and highlight the importance of continuous monitoring in revealing the intricate behaviors of these distant astronomical objects.",
        "ori-fast-z-score": -0.5488212999484517,
        "water-fast-z-score": 6.47609133939173,
        "rewrite-fast-z-score": 0.5241424183609592
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Global polarization of QGP in non-central heavy ion collisions at high energies .\nAbstract:\nWe study the global polarization of quark gluon plasma (QGP) produced in non central heavy-ion collisions by using an effective chiral model with vector and axial-vector mesons as well as quarks and anti-quarks. We find that the global polarization is mainly determined by the initial angular momentum carried by the colliding nuclei, which can be estimated through the Glauber model. The magnitude of the global polarization decreases rapidly when the collision energy increases due to the increasing number of particles involved in the reaction. Our results show that the global polarization may reach about 10% for RHIC energies but it will decrease significantly if one goes up to LHC energies. \n \n Introduction \n \n In recent years there has been growing interest on studying the global polarization of quark-gluon plasma(QGP), especially its dependence on the collision energy  1–3  . It was found that the global polarization could reach about 20% for RHIC energies  4  , while it would drop down to less than 1% for LHC energies  5  . \n \n This phenomenon is closely related to the initial angular momenta carried by the colliding nuclei; therefore, it provides us a new way to probe the nuclear structure  6  . On the other hand, since the global polarization is also sensitive to the temperature evolution  7, 8  , it might provide some information on the thermalization process of QGP  9  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Global polarization of QGP in non - central heavy ion collisions at high energies . Abstract : We research the global polarization of quark gluon plasma ( QGP ) produced in non central heavy - ion collisions by using an efficient chiral description with vector and axial - vector mesons as well as quarks and anti - quarks .We see that the global polarization is mainly decided by the first angular velocity carried by the colliding nuclei , which can be estimated through the Glauber model . The magnitude of the global polarization decreases quickly when the collision energy rises due to the increasing quantity of molecules implicated in the reaction .Our results show that the global polarization might reach about 10 % for RHIC energies but it will decrease greatly if one goes up to LHC energies . Introduction In recent months there has been growing interest on studying the global polarization of quark - gluon plasma ( QGP ) , particularly its dependence on the collision time 1 – 3 .It was shown that the global polarization could reach about 20 % for RHIC energies 4 , while it would rise down to little than 1 % for LHC energies 5 . This phenomenon is closely related to the early angular momenta carried by the colliding nuclei ; therefore , it gives us a new place to probe the atomic structure 6 .On the other hand , since the global polarization is also sensitive to the temperature evolution 7 , 8 , it could give some info on the thermalization process of QGP 9 .",
        "rewrite_text": "**Title:** Global Polarization of Quark-Gluon Plasma in Non-Central Heavy Ion Collisions at High Energies\n\n**Abstract:** This study investigates the global polarization of quark-gluon plasma (QGP) generated in non-central heavy-ion collisions, employing an effective chiral framework that incorporates vector and axial-vector mesons alongside quarks and anti-quarks. Our findings indicate that the global polarization is predominantly influenced by the initial angular momentum imparted by the colliding nuclei, which can be quantitatively assessed using the Glauber model. Notably, we observe a rapid decline in the magnitude of global polarization as collision energy increases, attributed to the growing number of particles involved in the reaction dynamics. Specifically, our results suggest that global polarization may reach approximately 10% at Relativistic Heavy Ion Collider (RHIC) energies, but this value diminishes significantly at Large Hadron Collider (LHC) energies. Recent literature has highlighted a burgeoning interest in the global polarization of QGP, particularly its correlation with collision time. Previous studies have reported that global polarization could attain levels around 20% at RHIC energies, while it drops to below 1% at LHC energies. This phenomenon is intricately linked to the early angular momentum of the colliding nuclei, providing a novel avenue for probing the fundamental structure of matter. Furthermore, since global polarization is sensitive to the thermal evolution of the QGP, it offers valuable insights into the thermalization processes occurring within this state of matter. Our research contributes to the understanding of QGP dynamics and emphasizes the importance of collision energy and angular momentum in determining the characteristics of global polarization in heavy-ion collisions.",
        "ori-fast-z-score": -0.3849001794597505,
        "water-fast-z-score": 5.076479311672102,
        "rewrite-fast-z-score": -1.4237369936287485
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the Possibility of Observing the Shapiro Effect for Pulsars in Globular Clusters .\nAbstract:\nWe have investigated whether pulsar timing observations can be used to detect gravitational waves by observing the Shapiro effect, which is caused by the passage of gravitational waves through space-time around the Earth and its companion star (the Sun). We find that this method will not work with current technology because it requires very accurate measurements of pulse arrival times over many years. However, we show how future radio telescopes could make such measurements if they are equipped with new technologies like phased-array feeds or digital backends. In addition, we discuss other possible methods using pulsar timing data to search for gravitational waves. Gravitational waves cause time delays between pulses emitted at different points on the surface of a rotating neutron star. These time delays depend on the distance between these points as well as their position relative to the line-of-sight towards the observer. The most prominent effects occur when the wave passes close to the Earth and its companion stars. This causes an additional delay known as the Shapiro effect  Shapiro 1964  . If one knows the positions of all pulsars within a globular cluster, then one can use the observed pulse arrival times to measure the distances between them. By comparing these measured distances with those predicted by general relativity, one can test whether Einstein s theory correctly describes gravity on large scales.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the Possibility of Observing the Shapiro Effect for Pulsars in Globular Clusters . Abstract : We have researched whether pulsar timing observations can be used to identify gravitational waves by observing the Shapiro phenomenon , which is caused by the travel of gravitational waves through space - time around the Earth and its companion star ( the Sun ) .We see that this technology will not work with current technology because it takes very accurate measurements of signal attendance times over numerous years . However , we find how new radio telescopes might making such measurements if they are installed with modern innovations like phased - array feeds or digital backends .In addition , we explain other possible methods using pulsar timing statistics to search for gravitational waves . Gravitational waves cause period delays between pulses emitted at different places on the surface of a rotating neutron star .These time delays rely on the distance between these points as also as their placement relative to the line - of - view towards the observer . The most notable effects happen when the wave passes close to the Earth and its companion stars .This creates an additional delay known as the Shapiro phenomenon Shapiro 1964 . If one understands the places of all pulsars within a globular cluster , then one can using the observed pulse onset times to measure the distances between them .By linking these measured distances with those predicted by general relativity , one can test whether Einstein s concept correctly describes gravitational on huge scales .",
        "rewrite_text": "**Title: On the Possibility of Observing the Shapiro Effect for Pulsars in Globular Clusters**\n\n**Abstract:** This study investigates the potential of utilizing pulsar timing observations to detect gravitational waves through the Shapiro effect, which arises from the interaction of gravitational waves with the curvature of spacetime around massive bodies, such as the Earth and the Sun. Our analysis indicates that current technological capabilities are insufficient for this purpose, as precise measurements of pulse arrival times over extended periods are required. However, we propose that advancements in radio telescope technology, particularly the integration of modern innovations like phased-array feeds and advanced digital backends, could enable such measurements in the near future. Furthermore, we explore alternative methodologies that leverage pulsar timing statistics to search for gravitational waves. Gravitational waves induce time delays in the pulses emitted by rotating neutron stars, with these delays being contingent upon the spatial separation of the emission points and their orientation relative to the observer's line of sight. The most pronounced effects are observed when gravitational waves traverse close to Earth and its neighboring stars, resulting in an additional delay known as the Shapiro delay, as first described by Shapiro in 1964. By accurately mapping the positions of pulsars within a globular cluster, researchers can utilize the observed pulse arrival times to calculate the distances between these pulsars. By correlating these empirical measurements with predictions derived from general relativity, we can rigorously test the validity of Einstein's theory on cosmological scales. This research opens new avenues for understanding gravitational waves and their implications for fundamental physics, particularly in the context of pulsar timing arrays and their potential role in the detection of these elusive cosmic phenomena.",
        "ori-fast-z-score": -0.18257418583505536,
        "water-fast-z-score": 7.302967433402215,
        "rewrite-fast-z-score": 0.3481553119113957
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multi-site observations of Delta Scuti stars 7 Aql and 8 Aql (a new Delta Scuti variable): The twelfth STEPHI campaign in 2003 .\nAbstract:\nThe 12th STEPHI campaign was carried out at the Roque de los Muchachos Observatory, La Palma, Canaries Islands during August-September 2003. We observed two bright Delta Scuti stars - 7 Aql and 8Aql with the STEPHI photometer equipped with an Andor CCD camera. In this work we present results for these targets obtained by applying different methods to analyse their light curves. For both stars we found pulsation frequencies which are listed in Table 1 . \n7 Aql is known as one of the most active Delta Scuti variables showing more than 100 periodicities in its power spectrum. Our analysis revealed that it has several additional modes excited simultaneously. Some of them were not detected before because they have very low amplitudes or are located close to other peaks. \n8Aql turned out to be another interesting target. It shows only three significant periods but all of them are quite short -larger than 0.1 d. This star also exhibits low-amplitude variability on longer time scales. \n\n\nWe compared our results with those published previously.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multi - location observations of Delta Scuti stars 7 Aql and 8 Aql ( a new Delta Scuti variable ) : The twelfth STEPHI campaign in 2003 . Abstract : The 12th STEPHI campaign was carried out at the Roque de los Muchachos Observatory , La Palma , Canaries Islands during August - September 2003 .We observed two bright Delta Scuti stars - 7 Aql and 8Aql with the STEPHI photometer equipped with an Andor CCD camera . In this research we present results for these targets obtained by using varying methods to analyse their light surfaces .For both stars we found pulsation levels which are listed in Table 1 . 7 Aql is known as one of the most intense Delta Scuti factors showing more than 100 periodicities in its power spectrum .Our study revealed that it has numerous additional frequencies excited simultaneously . Some of them were not observed before because they have very low amplitudes or are situated close to other peaks .8Aql turned out to be another important target . It displays only three notable cycles but all of them are quite short - larger than 0 . 1 d . This star also exhibits small - frequency variability on longer time ranges .We compared our findings with those published previously .",
        "rewrite_text": "Title: Multi-location Observations of Delta Scuti Stars 7 Aql and 8 Aql (A New Delta Scuti Variable): The Twelfth STEPHI Campaign in 2003\n\nAbstract: The twelfth STEPHI campaign was conducted at the Roque de los Muchachos Observatory in La Palma, Canary Islands, from August to September 2003. This campaign focused on two prominent Delta Scuti stars, 7 Aql and 8 Aql, utilizing the STEPHI photometer equipped with an Andor CCD camera for precise photometric measurements. In this study, we present the results obtained from various analytical methods applied to the light curves of these stars. Our findings for both targets are detailed, with pulsation levels documented in Table 1. \n\n7 Aql is recognized as one of the most active Delta Scuti stars, exhibiting over 100 periodicities in its power spectrum. Our analysis has uncovered numerous additional frequencies that are simultaneously excited, some of which had not been previously detected due to their low amplitudes or proximity to other spectral peaks. This discovery enhances our understanding of the complex pulsation behavior of 7 Aql.\n\nIn contrast, 8 Aql emerged as another significant subject of our observations. This star displayed only three prominent cycles, all characterized by relatively short periods exceeding 0.1 days. Additionally, 8 Aql exhibited variability in its frequency over extended time scales, suggesting a more intricate pulsation mechanism at play. \n\nWe also conducted a comparative analysis of our results with previously published data, contributing to the broader understanding of Delta Scuti variables. This study not only highlights the unique characteristics of 7 Aql and 8 Aql but also emphasizes the importance of multi-location observational campaigns in advancing our knowledge of stellar pulsations.",
        "ori-fast-z-score": 0.11547005383792514,
        "water-fast-z-score": 5.505977612893481,
        "rewrite-fast-z-score": -0.5883484054145521
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Molecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale bar funnelling gas into the nuclear region .\nAbstract:\nWe present new CO(2-1), 13CO(1-0), and C18O(1-0) observations with the IRAM 30m telescope towards the nearby spiral galaxy NGC 4565. The data reveal that this galaxy hosts an extended molecular disk which is warped by interactions with its companion galaxies. We find evidence for two distinct components to the molecular gas distribution; one associated with the main body of the galaxy and another component located along the southern edge of the optical disk. This second component has been previously detected as a dust lane but we show here it also contains significant amounts of molecular gas. In addition, our high resolution maps reveal a prominent central concentration of molecular gas coincident with the position of the AGN. Using these data together with previous results on other galaxies observed within the NUGA survey we investigate how the properties of the molecular gas are related to those of the stars and black holes hosted by each system.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Molecular gas in NUclei of GAlaxies ( NUGA ) VII . NGC4569 , a large scale bar funnelling energy into the atomic region .Abstract : We report new CO ( 2 - 1 ) , 13CO ( 1 - 0 ) , and C18O ( 1 - 0 ) observations with the IRAM 30m telescope towards the nearby spiral galaxy NGC 4565 . The data reveal that this galaxy hosts an extended molecular core which is warped by interactions with its companion galaxies .We get information for two different components to the molecular gas distribution ; one associated with the main bodies of the galaxy and another component located along the southern periphery of the optical disk . This second component has been previously observed as a dust track but we find here it also contains substantial deposits of molecular gas .In addition , our high resolution mapping reveal a major central concentration of molecular gas coincident with the position of the AGN . Using these information combined with previous findings on other galaxies found within the NUGA study we investigate how the properties of the molecular gas are related to those of the stars and dark holes hosted by each system .",
        "rewrite_text": "Title: Molecular Gas in Nuclei of Galaxies (NUGA) VII: NGC 4569 - A Large Scale Bar Funneling Energy into the Atomic Region\n\nAbstract: In this study, we present new observational data of the nearby spiral galaxy NGC 4565, utilizing the IRAM 30m telescope to conduct CO (2-1), 13CO (1-0), and C18O (1-0) measurements. Our findings indicate that NGC 4565 possesses an extensive molecular core that exhibits warping due to gravitational interactions with its neighboring galaxies. We identify two distinct components within the molecular gas distribution: one that is closely associated with the primary structure of the galaxy and another located along the southern edge of the optical disk. The latter component, previously recognized as a dust track, is shown to harbor significant amounts of molecular gas, expanding our understanding of its role in the galaxy's dynamics. Furthermore, our high-resolution mapping reveals a pronounced concentration of molecular gas at the galaxy's center, aligning with the position of the active galactic nucleus (AGN). By integrating these new insights with prior research on other galaxies within the NUGA framework, we explore the correlations between the molecular gas properties and the characteristics of the stellar populations and supermassive black holes present in these systems. This investigation enhances our comprehension of the interplay between molecular gas dynamics and galactic evolution, particularly in the context of bar-driven processes that funnel energy into the atomic regions of galaxies. Our results contribute to the broader understanding of how molecular gas influences star formation and the overall energy distribution within galaxies, shedding light on the complex interactions that govern galactic structures.",
        "ori-fast-z-score": -1.1531133203941102,
        "water-fast-z-score": 3.8786538958710977,
        "rewrite-fast-z-score": 0.5432144762551112
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Hierarchical Markovian models for hyperspectral image segmentation .\nAbstract:\nWe propose to use hierarchical hidden Markov random fields (HHMRFs) as the underlying model in an unsupervised segmentation algorithm for hyperspectral images. The HHMRFs are constructed by combining several layers of hidden Markov chains, where each layer is associated with one particular spatial scale. We show that this multiscale approach leads to improved performance over single-scale methods and we demonstrate its effectiveness on two different data sets. Finally, we compare our results against those obtained using state-of-the-art algorithms based on Gaussian mixture models or sparse coding techniques. \nIntroduction\n\nHyperspectral imaging has become increasingly popular during recent years due to advances in sensor technology  1  . In contrast to conventional color cameras which capture only three bands per pixel, hyperspectral sensors can record hundreds of narrow spectral bands simultaneously  2  , leading to high-dimensional data volumes. This poses new challenges both in terms of storage requirements and computational complexity  3  .\nIn many applications it would be desirable to perform automatic analysis of such large amounts of data without any prior knowledge about the scene being observed  4  . One important task in this context is the detection of homogeneous regions within the image  5  . These so-called segments may correspond to individual objects  6  , but they could also represent parts of larger structures like buildings  7  or roads  8  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Hierarchical Markovian methods for hyperspectral photograph segmentation . Abstract : We suggest to use hierarchical hidden Markov random fields ( HHMRFs ) as the fundamental model in an unsupervised segmentation algorithm for hyperspectral pictures .The HHMRFs are built by combining several layers of hidden Markov chains , where each layer is associated with one certain spatial scale . We see that this multiscale approach leads to improved performance over multi - scale techniques and we prove its effectiveness on two different data sets .Finally , we compare our findings against those achieved using state - of - the - art algorithms based on Gaussian mixture models or dense coding techniques . Introduction Hyperspectral photography has become especially popular during recent years owing to advances in sensor technology 1 .In comparison to conventional color cameras which capture only three bands per pixel , hyperspectral cameras can display hundreds of narrow spectral patterns simultaneously 2 , leading to large - dimensional data capacities . This poses novel challenges both in terms of storage needs and computational difficulty 3 .In many applications it would be desirable to conduct automatic analysis of such substantial amounts of evidence without any earlier knowledge about the image being detected 4 . One important task in this context is the detection of homogeneous places within the image 5 .These so - called features could belong to individual objects 6 , but they may sometimes reflect parts of bigger structures like houses 7 or roads 8 .",
        "rewrite_text": "Title: Hierarchical Markovian Methods for Hyperspectral Image Segmentation\n\nAbstract: In this study, we propose the utilization of hierarchical hidden Markov random fields (HHMRFs) as a foundational model for an unsupervised segmentation algorithm tailored for hyperspectral images. The HHMRFs are constructed by integrating multiple layers of hidden Markov chains, with each layer corresponding to a specific spatial scale. Our multiscale approach demonstrates significant enhancements in performance compared to traditional multi-scale techniques, and we validate its effectiveness through experiments conducted on two distinct datasets. Furthermore, we benchmark our results against those obtained from leading algorithms that employ Gaussian mixture models and dense coding methods. \n\nThe increasing popularity of hyperspectral imaging in recent years can be attributed to advancements in sensor technology, which enable the capture of hundreds of narrow spectral bands per pixel, as opposed to the three bands captured by conventional color cameras. This capability results in high-dimensional data that presents unique challenges in terms of storage and computational requirements. In many practical applications, there is a pressing need for automated analysis of these extensive datasets without prior knowledge of the images being processed. A critical aspect of this analysis is the identification of homogeneous regions within the images. These regions, referred to as features, may correspond to individual objects or could represent components of larger structures, such as buildings or roadways. Our research addresses these challenges by leveraging the hierarchical structure of HHMRFs, ultimately contributing to more effective segmentation of hyperspectral images.",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 6.8326451225040765,
        "rewrite-fast-z-score": -0.4662524041201569
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Demographics of Transition Objects .\nAbstract:\nWe present the demographics and properties of transition objects in SDSS DR7, which are defined as galaxies with both emission lines (ELGs) and absorption features (AGNs). We find that there is an excess number of ELG-AGN pairs at small separations compared to random distributions. The fraction of AGNs among all ELGs increases towards lower luminosities. There appears to be no significant difference between the fractions of AGNs found within different types of ELGs. These results suggest that some ELGs may harbor hidden AGNs. This work was supported by NASA grant NNX10AD65G. We thank the anonymous referee for helpful comments on this manuscript. In recent years, it has been shown that many active galactic nuclei (AGNs), especially those with low luminosity or obscured by dusty torii, have strong emission line components (see e.g., Ho et al. (1997) , Hao et al. (2005) ), making them appear like normal star-forming galaxies when observed through optical spectroscopic surveys such as Sloan Digital Sky Survey (SDSS; York et al. (2000) ) .\nIn order to identify these  transition objects , we use two criteria based on their spectral energy distribution (SED): 1) they must show both emission lines (ELGs; see Section 2.1 below) and absorption features (Section 2.2) simultaneously; and 2) they should not be classified as quasars according to the BPT diagram (Baldwin et al. 1981 , Kewley et al. 2001 . By applying these selection criteria to the entire sample of galaxies in the seventh data release (DR7; Abazajian et al. 2009 ) of the SDSS, we obtain a total of 16,082 transition objects out of a parent sample of 3,962,843 galaxies.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Demographics of Transition Objects . Abstract : We present the demographics and features of transfer objects in SDSS DR7 , which are specified as galaxies with both emission lines ( ELGs ) and emission elements ( AGNs ) .We see that there is an excess amount of ELG - AGN pairs at small separations compared to random distributions . The percentage of AGNs among all ELGs increases towards less luminosities .There seems to be no major variation between the fractions of AGNs discovered within various types of ELGs . These data suggest that some ELGs might harbor hidden AGNs .This project was supported by NASA grant NNX10AD65G . We thank the anonymous referee for helpful remarks on this manuscript .In recent years , it has been shown that several active galactic nuclei ( AGNs ) , particularly those with poor luminosity or obscured by dusty torii , have strong emitted path constituents ( saw e . g . , Ho et al . ( 1997 ) , Hao et al .( 2005 ) ) , making them seem like usual star - creating galaxies when observed through optical spectroscopic studies such as Sloan Digital Sky Survey ( SDSS ; York et al . ( 2000 ) ) .In order to identify these transition objects , we using two requirements depending on their spectral power distribution ( SED ) : 1 ) they must show both emission lines ( ELGs ; seeing Section 2 . 1 below ) and emission elements ( Section 2 . 2 ) simultaneously ; and 2 ) they should not be categorized as quasars according to the BPT diagram ( Baldwin et al . 1981 , Kewley et al .2001 . By applying these selection categories to the entire sample of galaxies in the seventh data update ( DR7 ; Abazajian et al .2009 ) of the SDSS , we obtain a total of 16 , 082 transition objects out of a parent sample of 3 , 962 , 843 galaxies .",
        "rewrite_text": "**Title: Demographics of Transition Objects**\n\n**Abstract:** In this study, we investigate the demographics and characteristics of transition objects identified in the Sloan Digital Sky Survey Data Release 7 (SDSS DR7). Transition objects are defined as galaxies exhibiting both emission lines (ELGs) and emission elements, specifically active galactic nuclei (AGNs). Our analysis reveals a notable excess of ELG-AGN pairs at small spatial separations when compared to random distributions, indicating a potential correlation between these two classifications. Furthermore, we observe that the proportion of AGNs among all ELGs increases as the luminosity decreases, suggesting that less luminous galaxies are more likely to host AGNs. Interestingly, our findings indicate minimal variation in the AGN fractions across different types of ELGs, which implies that certain ELGs may conceal AGNs that are not readily apparent. \n\nThis research is supported by NASA grant NNX10AD65G, and we express our gratitude to the anonymous referee for their constructive feedback on this manuscript. Recent literature has highlighted that many AGNs, particularly those with low luminosity or those obscured by dusty tori, exhibit strong emission line features, which can lead to their misclassification as typical star-forming galaxies in optical spectroscopic surveys like the SDSS. To accurately identify these transition objects, we employed two criteria based on their spectral energy distribution (SED): first, they must display both emission lines and emission elements simultaneously; second, they should not be classified as quasars according to the Baldwin-Phillips-Terlevich (BPT) diagram. By applying these selection criteria to the comprehensive galaxy sample from SDSS DR7, we identified a total of 16,082 transition objects from an original sample of 3,962,843 galaxies. This work contributes to our understanding of the complex relationships between star formation and AGN activity in the universe.",
        "ori-fast-z-score": -3.2863353450309964,
        "water-fast-z-score": 4.164644317955852,
        "rewrite-fast-z-score": 0.4472135954999579
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Thermal effects on nuclear symmetry energy with a momentum-dependent effective interaction .\nAbstract:\nWe study the thermal properties of symmetric and asymmetric nuclear matter using an extended Thomas-Fermi model based on a momentum dependent effective nucleon-nucleon (NN) interaction, which is derived by solving the Bethe-Goldstone equation in ladder approximation. The results show that the density dependence of nuclear symmetry energy at normal nuclear matter density changes significantly when temperature increases up to 100 MeV. In addition, we find that the slope parameter L(ρ0), characterizing the density dependence of nuclear incompressibility K∞ = 9L(ρ0)(3π2ρ0/40MeV)2, decreases rapidly as temperature rises for both pure neutron matter and symmetric nuclear matter. This indicates that the stiffness of nuclear matter becomes softer at high temperatures.  We also calculate the pressure P , entropy S and specific heat Cv of nuclear matter as functions of baryonic number density nB and temperature T .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Thermal effects on nuclear symmetry power with a momentum - dependent effective interaction . Abstract : We research the thermal properties of symmetric and asymmetric atomic matter utilizing an extended Thomas - Fermi model based on a momentum dependent effective nucleon - nucleon ( NN ) relationship , which is calculated by solving the Bethe - Goldstone equation in ladder approximation .The results show that the density dependence of nuclear symmetry power at typical atomic matter density changes significantly when temperature increases up to 100 MeV . In addition , we find that the slope parameter L ( ρ0 ) , characterizing the density dependence of nuclear incompressibility K∞ = 9L ( ρ0 ) ( 3π2ρ0 / 40MeV ) 2 , decreases quickly as temperature rises for both solid neutron matter and symmetric nuclear material .This implies that the stiffness of nuclear material gets softer at high temperatures . We additionally calculate the pressure P , entropy S and particular heat Cv of nuclear material as functions of baryonic number density nB and heat T .",
        "rewrite_text": "In this study, we investigate the thermal characteristics of both symmetric and asymmetric nuclear matter through an advanced Thomas-Fermi model that incorporates a momentum-dependent effective nucleon-nucleon (NN) interaction. This interaction is derived by solving the Bethe-Goldstone equation within the ladder approximation framework. Our findings reveal that the density dependence of nuclear symmetry energy exhibits significant alterations as the temperature increases, particularly up to 100 MeV. Furthermore, we observe a notable decrease in the slope parameter L(ρ0), which is instrumental in defining the density dependence of nuclear incompressibility K∞ = 9L(ρ0)(3π²ρ0/40 MeV)², as the temperature escalates for both solid neutron matter and symmetric nuclear matter. This trend indicates a reduction in the stiffness of nuclear matter at elevated temperatures. Additionally, we compute the pressure (P), entropy (S), and specific heat (Cv) of nuclear matter as functions of baryonic number density (nB) and temperature (T). Our results contribute to a deeper understanding of the thermal effects on nuclear symmetry energy and the behavior of nuclear matter under varying thermal conditions, which is crucial for applications in nuclear physics and astrophysics, particularly in the context of neutron stars and heavy-ion collisions.",
        "ori-fast-z-score": -0.6546536707079772,
        "water-fast-z-score": 4.664004843101107,
        "rewrite-fast-z-score": 1.4439897447623107
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the Obfuscation Complexity of Planar Graphs .\nAbstract:\nWe study the obfuscation complexity of planar graphs, which is defined as the minimum number of edges that need to be removed in order for an adversary not to be able to distinguish between two isomorphic copies of the graph. We show that this problem can be solved by solving a linear program with O(n) variables and constraints (where n denotes the number of vertices), or equivalently by finding the maximum matching on a bipartite graph. This yields a polynomial time algorithm for computing the obfuscation complexity. As a corollary we obtain a lower bound on the obfuscation complexity for any n-vertex tree T . Finally, we prove that there are infinitely many trees whose obfuscation complexities equal their numbers of leaves. The obfuscation complexity of a graph G = (V , E ) is defined as the smallest integer k such that removing at most k edges from G makes it indistinguishable from another graph G  = (V  , E ). In other words, if an attacker has access only to the set of all possible subgraphs induced by some subset S ⊆ V × V then he cannot tell whether he is looking at G or G  unless |S| > k .\nIn this work we consider the case where G is a planar graph. It turns out that in this setting one can solve the obfuscation complexity problem efficiently using combinatorial techniques. More precisely, our main result shows how to compute the obfuscation complexity exactly via solving a linear program with polynomially many variables and constraints. \nAs a consequence of our results we get a new lower bound on the obfuscatability of trees. Moreover, we provide examples showing that the obfuscation complexity may differ significantly from the size of the largest independent set.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the Obfuscation Complexity of Planar Graphs . Abstract : We research the obfuscation complexity of planar graphs , which is characterized as the minimum amount of edges that must to be removed in order for an adversary not to be possible to distinguish between two isomorphic versions of the graph .We see that this question can be answered by solving a linear program with O ( n ) parameters and constraints ( where n represents the number of vertices ) , or equivalently by finding the maximum matching on a bipartite graph . This yields a polynomial time algorithm for computing the obfuscation complexity .As a corollary we obtain a smaller bound on the obfuscation complexity for any n - vertex tree T . Finally , we prove that there are infinitely many trees whose obfuscation complexities equal their numbers of leaves .The obfuscation complexity of a graph G = ( V , E ) is characterized as the smallest integer k such that removing at most k edges from G gives it indistinguishable from another graph G = ( V , E ) . In other words , if an attacker has access only to the set of all possible subgraphs induced by some subset S ⊆ V × V then he cannot tell whether he is searching at G or G unless | S | > k .In this study we study the case where G is a planar graph . It turns out that in this setting one can handle the obfuscation complexity problem efficiently using combinatorial tools .More specifically , our major result shows how to compute the obfuscation complexity exactly via solving a linear program with polynomially many parameters and constraints . As a outcome of our findings we find a new lower bound on the obfuscatability of trees .Moreover , we provide examples demonstrating that the obfuscation complexity might variation significantly from the size of the greatest independent collection .",
        "rewrite_text": "In this article, we investigate the obfuscation complexity of planar graphs, defined as the minimum number of edges that must be removed to prevent an adversary from distinguishing between two isomorphic representations of the graph. Our approach reveals that this problem can be effectively addressed by formulating and solving a linear programming problem with O(n) parameters and constraints, where n denotes the number of vertices in the graph. Alternatively, this can be interpreted as finding the maximum matching in a corresponding bipartite graph, leading to a polynomial-time algorithm for determining the obfuscation complexity.\n\nAs a significant outcome of our research, we derive a tighter bound on the obfuscation complexity for any tree T with n vertices. Furthermore, we demonstrate that there exists an infinite number of trees for which the obfuscation complexity is equal to the number of their leaves. The obfuscation complexity of a graph G = (V, E) is defined as the smallest integer k such that removing at most k edges from G renders it indistinguishable from another graph G' = (V, E'). This means that if an adversary can only access the set of all possible subgraphs induced by a subset S ⊆ V × V, they cannot determine whether they are examining G or G' unless the size of S exceeds k.\n\nOur findings indicate that the obfuscation complexity problem can be efficiently tackled using combinatorial methods when dealing with planar graphs. Specifically, we present a method to compute the obfuscation complexity precisely by solving a linear program with polynomially many parameters and constraints. Additionally, we provide examples that illustrate how the obfuscation complexity can vary significantly from the size of the largest independent set, highlighting the nuanced nature of this complexity in graph theory.",
        "ori-fast-z-score": -2.7160723812755556,
        "water-fast-z-score": 3.1304951684997055,
        "rewrite-fast-z-score": -0.641688947919748
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Lifetime Improvement of Wireless Sensor Networks by Collaborative Beamforming and Cooperative Transmission .\nAbstract:\nIn this work, we propose an energy-efficient cooperative transmission scheme for wireless sensor networks (WSNs). The proposed scheme is based on the combination of collaborative beamforming at the source node with cooperative transmission to multiple relay nodes in order to improve lifetime performance. In particular, the source node first transmits data packets using its maximum power level. Then, it switches to lower power levels if no packet has been successfully received within a certain time period. If one or more packets are successfully decoded, then the source node increases its transmit power back up to the previous value. We derive closed-form expressions for outage probability as well as average throughput under Rayleigh fading channels. Our results show that our proposed scheme can significantly increase network lifetime compared to conventional schemes without compromising system reliability. Finally, numerical examples are provided to verify the theoretical analysis. Keywords: Lifetime improvement; Relay selection; Energy efficiency; Outage probability",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Lifetime Improvement of Wireless Sensor Networks by Collaborative Beamforming and Cooperative Transmission . Abstract : In this project , we propose an energy - efficient joint transmission strategy for wireless sensor networks ( WSNs ) .The proposed system is based on the combination of collaborative beamforming at the source node with coordinated transmission to multiple relay nodes in order to ensure lifetime efficiency . In particular , the source node initially transmits data packets using its highest power level .Then , it switches to smaller energy levels if no packet has been successfully received within a certain time time . If one or more signals are properly decoded , then the source node increases its receive power back up to the previous value .We derive closed - form expressions for outage likelihood as well as average throughput under Rayleigh fading filters . Our results show that our proposed system can significantly raise system lifetime compared to conventional systems without compromising system efficiency .Finally , numerical examples are provided to confirm the theoretical analysis . Keywords : Lifetime improvement ; Relay selection ; Energy efficiency ; Outage probability",
        "rewrite_text": "Title: Enhancing the Longevity of Wireless Sensor Networks through Collaborative Beamforming and Cooperative Transmission\n\nAbstract: This study presents an innovative energy-efficient joint transmission strategy designed to enhance the longevity of wireless sensor networks (WSNs). The proposed approach integrates collaborative beamforming at the source node with coordinated transmissions to multiple relay nodes, aiming to optimize energy utilization and extend network lifetime. Initially, the source node transmits data packets at its maximum power level. If no packets are successfully received within a predetermined timeframe, the node reduces its transmission power to conserve energy. Conversely, if one or more packets are successfully decoded, the source node reverts to its higher power level to ensure robust communication. We derive closed-form expressions for both outage probability and average throughput under Rayleigh fading conditions, providing a comprehensive analysis of the system's performance. Our findings indicate that the proposed strategy significantly enhances the operational lifetime of WSNs compared to traditional methods, all while maintaining system efficiency. To substantiate our theoretical framework, we present numerical examples that illustrate the effectiveness of our approach. This research contributes to the field of wireless communications by offering a viable solution for improving the sustainability of sensor networks, which is crucial for various applications in environmental monitoring, smart cities, and industrial automation. \n\nKeywords: Wireless Sensor Networks, Energy Efficiency, Collaborative Beamforming, Cooperative Transmission, Outage Probability, System Lifetime.",
        "ori-fast-z-score": -0.10259783520851541,
        "water-fast-z-score": 5.454823740581938,
        "rewrite-fast-z-score": 1.7320508075688772
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Statistical Evidence for Three classes of Gamma-ray Bursts .\nAbstract:\nWe present the results of an analysis of BATSE data on gamma ray bursts (GRBs) in which we have used three different statistical methods to search for evidence that GRB durations are distributed into at least two distinct populations, as suggested by previous authors.  We find no compelling evidence for such a bimodal distribution using any one method alone; however, when all three methods are combined there is strong evidence for this hypothesis.  The best-fit parameters obtained with each method individually differ significantly and suggest that the true underlying distribution may be more complex than previously thought. In particular, our results indicate that the shortest duration events form their own class of GRBs whose properties are quite different from those of longer-duration GRBs. This result has important implications both for understanding the nature of these phenomena and for planning future missions dedicated to studying them. Keywords: Gamma Ray Bursts, Statistical Analysis",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Statistical Evidence for Three classes of Gamma - ray Bursts . Abstract : We present the results of an assessment of BATSE information on gamma ray bursts ( GRBs ) in which we have utilized three different statistical approaches to search for indication that GRB durations are distributed into at least two separate populations , as suggested by earlier authors .We see no compelling evidence for such a bimodal distribution using any one method alone ; however , when all three means are combined there is strong evidence for this hypothesis . The best - fitting factors obtained with each approach individually varies dramatically and suggest that the true underlying distribution might be more complex than previously thought .In particular , our findings confirm that the shortest duration episodes form their own class of GRBs whose characteristics are quite different from those of extended - duration GRBs . This result has significant implications both for studying the nature of these phenomena and for planning upcoming missions tasked to researching them .Keywords: Gamma Ray Bursts, Statistical Analysis",
        "rewrite_text": "Title: Statistical Evidence for Three Classes of Gamma-Ray Bursts\n\nAbstract: In this study, we analyze data from the Burst and Transient Source Experiment (BATSE) to investigate the distribution of gamma-ray burst (GRB) durations. Our objective is to determine whether GRBs can be categorized into distinct populations, as previously suggested by other researchers. We employed three different statistical methodologies to assess the potential for a bimodal distribution of GRB durations. While each method individually failed to provide strong evidence for such a distribution, the integration of results from all three approaches yielded compelling support for the hypothesis of multiple classes of GRBs. Notably, the parameters derived from each statistical technique exhibited significant variability, indicating that the underlying distribution of GRB durations may be more intricate than earlier models proposed. Our analysis reveals that the shortest duration GRBs constitute a unique class, characterized by distinct properties that set them apart from their longer-duration counterparts. This finding not only enhances our understanding of the nature of GRBs but also has critical implications for the design and execution of future observational missions aimed at exploring these enigmatic cosmic events. The results underscore the necessity for a refined classification system within the GRB community, which could lead to more targeted research efforts and improved theoretical models. Keywords: Gamma-Ray Bursts, Statistical Analysis.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 5.965587590013045,
        "rewrite-fast-z-score": -0.9138115486202573
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cosmic Ray Origin and Propagation Model .\nAbstract:\nThe cosmic ray origin is still unknown, but it may be related to the supernova explosion.  The propagation model describes how cosmic rays are transported in space by diffusion processes with energy losses due to ionization and Coulomb scattering off interstellar gas particles.   This article presents an overview on cosmic ray physics and introduces some basic concepts for understanding cosmic ray transport models. Cosmic rays have been observed since the 19th century. They consist mainly of protons (about 85%) and helium nuclei (about 14%). Their energies range up to 10^20 eV. However, their sources remain unclear. It has been suggested that they might come from exploded stars called supernovae or from active galactic nuclei such as quasars. In this case, they would travel through intergalactic space before reaching Earth. Another possibility is that they are accelerated within our own galaxy. If so, then they could reach us directly without traveling far away.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cosmic Ray Origin and Propagation Model . Abstract : The cosmic ray origin is already unclear , but it could be connected to the supernova explosion .The propagation model describes how cosmic rays are transported in space by diffusion processes with energy losses owing to ionization and Coulomb absorption off interstellar gas molecules . This page presents an overview on cosmic ray physics and introduces some fundamental concepts for studying cosmic ray transport models .Cosmic rays have been observed since the 19th century . They comprise mainly of protons ( about 85 % ) and helium nuclei ( about 14 % ) .Their energies range up to 10 ^ 20 eV . However , their sources continue unknown .It has been proposed that they may come from burst stars called supernovae or from active galactic nuclei such as quasars . In this instance , they may travel through intergalactic space before reaching Earth .Another possibility is that they are accelerated within our own galaxy . If so , then they may reach us directly without traveling long away .",
        "rewrite_text": "Title: Cosmic Ray Origin and Propagation Model\n\nAbstract: The origins of cosmic rays remain a topic of significant uncertainty within astrophysics, with a prevailing hypothesis suggesting a potential link to supernova explosions. This article presents a comprehensive overview of cosmic ray physics, focusing on the mechanisms of their propagation through space. The propagation model elucidates how cosmic rays are transported via diffusion processes, which are influenced by energy losses due to interactions with interstellar gas molecules, including ionization and Coulomb absorption. Since their discovery in the 19th century, cosmic rays have been recognized as primarily composed of protons (approximately 85%) and helium nuclei (around 14%), with energies that can reach up to 10^20 eV. Despite extensive research, the precise sources of these high-energy particles remain elusive. Several theories have been proposed, including the possibility that cosmic rays originate from explosive stellar events such as supernovae or from the energetic environments surrounding active galactic nuclei, including quasars. In such scenarios, cosmic rays may traverse intergalactic space before arriving at Earth. Alternatively, it is also conceivable that these particles are accelerated within our own galaxy, allowing for a more direct path to our planet. This article aims to introduce key concepts and frameworks necessary for understanding cosmic ray transport models, thereby contributing to the ongoing discourse on their origins and the mechanisms governing their propagation through the cosmos.",
        "ori-fast-z-score": 0.6708203932499369,
        "water-fast-z-score": 5.512930714537517,
        "rewrite-fast-z-score": 1.8034001919297482
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A study of structural properties on profiles HMMs .\nAbstract:\nIn this work, we present an algorithm for the analysis and comparison of profile Hidden Markov Models (HMMs). The proposed method is based on the concept of Structural Similarity Index Measurement (SSIM) which has been widely used in image processing to measure similarity between two images. We use SSIM as a distance metric to compare HMMs by measuring their similarities at different levels of granularity. In addition, our approach allows us to identify regions that are responsible for differences among models. Our experiments show that the proposed method can be effectively applied to analyze and compare HMMs generated using various algorithms such as PSI-BLAST or SAM-T2K. This research was supported by NSERC Discovery Grant RGPIN-2014-04567 awarded to Dr. Yi-Chun Wu. Profile hidden markov model(HMM),Structural similarity index measurement(SSIM),Similarity score matrix(SCM),PSI-BLAST",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A investigation of structural properties on profiles HMMs . Abstract : In this research , we present an algorithm for the evaluation and comparison of profile Hidden Markov Models ( HMMs ) .The proposed approach is based on the idea of Structural Similarity Index Measurement ( SSIM ) which has been widely using in image processing to measure similarity between two images . We use SSIM as a distance metric to compare HMMs by assessing their similarities at different levels of granularity .In addition , our approach allows us to identify areas that are responsible for variations among models . Our experiments indicate that the suggested method can be effectively used to analyze and compare HMMs generated using numerous algorithms such as PSI - BLAST or SAM - T2K .This research was supported by NSERC Discovery Grant RGPIN - 2014 - 04567 granted to Dr . Yi - Chun Wu . Profile hidden markov model ( HMM ) , Structural similarity index measurement ( SSIM ) , Similarity rating matrix ( SCM ) , PSI - BLAST",
        "rewrite_text": "Title: An Investigation of Structural Properties in Profile Hidden Markov Models\n\nAbstract: This study introduces a novel algorithm designed for the evaluation and comparison of profile Hidden Markov Models (HMMs). Our methodology leverages the Structural Similarity Index Measurement (SSIM), a metric traditionally employed in image processing to quantify the similarity between two images. By adapting SSIM as a distance metric, we facilitate the comparison of HMMs, enabling an assessment of their similarities across various levels of granularity. This innovative approach not only allows for the direct comparison of different HMMs but also aids in pinpointing specific areas that contribute to the observed variations among models. \n\nThrough extensive experiments, we demonstrate the effectiveness of our proposed method in analyzing and comparing HMMs generated by a variety of algorithms, including PSI-BLAST and SAM-T2K. The results indicate that our approach provides valuable insights into the structural properties of HMMs, enhancing our understanding of their performance and applicability in various contexts. \n\nThis research was conducted with the support of the NSERC Discovery Grant RGPIN-2014-04567 awarded to Dr. Yi-Chun Wu. The findings of this study have significant implications for the field of bioinformatics, particularly in the areas of sequence alignment and protein structure prediction, where profile HMMs are extensively utilized. By offering a robust framework for the evaluation of HMMs, our work contributes to the ongoing efforts to refine computational methods in biological research. Key terms include Profile Hidden Markov Model (HMM), Structural Similarity Index Measurement (SSIM), Similarity Rating Matrix (SCM), and PSI-BLAST.",
        "ori-fast-z-score": -0.7385489458759964,
        "water-fast-z-score": 4.031591663758072,
        "rewrite-fast-z-score": -0.7035264706814485
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Inter-network regions of the Sun at millimetre wavelengths .\nAbstract:\nWe present new observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) of two inter-network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25, respectively. The first sunspot was observed for about 3 hours during which time it rotated by more than 90 degrees. We find that this sunspot is composed of several magnetic flux tubes with different orientations. In addition to these features we also observe an extended bright feature located between the main sunspot umbrae. This feature has been previously reported as a penumbral filament but our data show no evidence of such structure. Instead, we interpret this feature as a coronal rain blob. The second sunspot was observed for only 1 hour before being occulted by Earths atmosphere. During this observation period the sunspot rotated by less than 30 degrees. Our analysis shows that both sunspots are surrounded by a dark lane which may be associated with the moat surrounding large sunspots.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Inter - network regions of the Sun at millimetre wavelengths . Abstract : We report new images making with the Atacama Large Millimeter / submillimeter Array ( ALMA ) of two inter - network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25 , respectively .The first sunspot was seen for about 3 hours during which period it rotated by more than 90 degrees . We see that this sunspot is composed of several magnetic flux tubes with various orientations .In addition to these characteristics we also observe an extended bright structure located between the main sunspot umbrae . This feature has been previously reported as a penumbral filament but our statistics indicate no evidence of such structure .Instead , we view this phenomenon as a coronal weather blob . The second sunspot was seen for only 1 hour before being occulted by Earths atmosphere .During this measurement period the sunspot moved by less than 30 degrees . Our study shows that both sunspots are surrounded by a darkness lane which may be involved with the moat surrounding large sunspots .",
        "rewrite_text": "We present new observational data obtained from the Atacama Large Millimeter/submillimeter Array (ALMA) focusing on two inter-network sunspots located in active region NOAA AR 12192, captured on May 24 and 25, 2013. The first sunspot was monitored for approximately three hours, during which it exhibited a rotation exceeding 90 degrees. Our analysis reveals that this sunspot is comprised of multiple magnetic flux tubes, each exhibiting distinct orientations. Notably, we also identified an extended bright structure situated between the primary umbrae of the sunspot. While this feature has been previously classified as a penumbral filament, our statistical analysis does not support this classification. Instead, we propose that this structure should be interpreted as a coronal weather blob, indicative of dynamic solar atmospheric phenomena. The second sunspot was observed for a shorter duration of only one hour before it was obscured by Earth's atmosphere, during which it rotated less than 30 degrees. Our findings indicate that both sunspots are encircled by a dark lane, which may play a role in the formation of the moat typically associated with larger sunspots. This study enhances our understanding of the complex magnetic structures and dynamics present in the solar atmosphere, particularly in the context of inter-network regions, and contributes to the broader knowledge of solar activity and its implications for space weather.",
        "ori-fast-z-score": -1.212678125181665,
        "water-fast-z-score": 4.063777271736939,
        "rewrite-fast-z-score": 2.0628424925175866
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Panchromatic Study of the Globular Cluster NGC 1904. I: The Blue Straggler Population .\nAbstract:\nWe present new photometry for the globular cluster NGC 1904, obtained with the Wide Field Camera 3 (WFC3) on board HST in four filters spanning the optical and near-infrared wavelength range. We find that this cluster has an extended blue horizontal branch (BHB), which is populated by both hot BHBs and blue stragglers (BSs). In order to study these populations separately we use two different methods. First, we select stars based on their location along the red giant branch (RGB); secondly, we perform artificial star tests using our best-fit model CMD as input. Both approaches yield consistent results. Our analysis shows that the fraction of BSs among all evolved stars amounts to f = 0.11 ± 0.01. This value agrees well with previous studies of other clusters. Using theoretical models we estimate the age of the cluster at t = 12 Gyr.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  A Panchromatic Study of the Globular Cluster NGC 1904.I: The Blue Straggler Population .Abstract : We report new photometry for the globular cluster NGC 1904 , obtained with the Wide Field Camera 3 ( WFC3 ) on board HST in four filters covering the optical and far - infrared frequency range . We see that this cluster has an extended blue horizontal branch ( BHB ) , which is populated by both hot BHBs and green stragglers ( BSs ) .In order to study these populations individually we utilize two different methods . First , we choose galaxies based on their placement along the red giant branch ( RGB ) ; secondly , we perform artificial star tests utilizing our good - fitting model CMD as input .Both approaches yield consistent conclusions . Our study shows that the fraction of BSs among all evolved stars amounts to f = 0 . 11 ± 0 . 01 .This value agrees well with previous research of other clusters . Using theoretical methods we estimate the age of the cluster at t = 12 Gyr .",
        "rewrite_text": "Title: A Panchromatic Study of the Globular Cluster NGC 1904: Insights into the Blue Straggler Population\n\nAbstract: In this study, we present new photometric observations of the globular cluster NGC 1904, acquired using the Wide Field Camera 3 (WFC3) aboard the Hubble Space Telescope (HST). Our observations span four filters that encompass both optical and far-infrared wavelengths. Notably, we identify an extended blue horizontal branch (BHB) within the cluster, characterized by the presence of both hot BHB stars and blue stragglers (BSs). To analyze these distinct populations, we employ two complementary methodologies. The first method involves selecting stars based on their position along the red giant branch (RGB), while the second method utilizes artificial star tests, leveraging our well-fitting color-magnitude diagram (CMD) as a reference. The results from both techniques converge, providing robust insights into the stellar populations of NGC 1904. Our findings indicate that the proportion of blue stragglers among all evolved stars in the cluster is approximately f = 0.11 ± 0.01, a value that aligns closely with previous studies conducted on other globular clusters. Furthermore, through theoretical modeling, we estimate the age of NGC 1904 to be around 12 billion years. This research contributes to our understanding of the stellar evolution processes within globular clusters and highlights the significance of blue stragglers in the context of stellar population studies.",
        "ori-fast-z-score": 0.917662935482247,
        "water-fast-z-score": 5.047146145152358,
        "rewrite-fast-z-score": 1.949358868961793
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Black Hole Mass - Spheroid Luminosity relation .\nAbstract:\nWe present the results of our study on the correlation between black hole mass and spheroidal luminosity in nearby galaxies, using data obtained with the Hubble Space Telescope (HST). We have used two different methods to estimate the masses of supermassive black holes at the centers of these galaxies; one based on stellar dynamics and another method which uses the widths of broad emission lines as an indicator for the central black hole mass. The sample consists of 29 elliptical galaxies within 40 Mpc distance. Our main result is that we find no significant difference between the black hole masses derived by both methods. This indicates that there exists a tight relationship between the black hole mass and the total luminosity of its host galaxy. In addition, we also found evidence that this relationship does not depend strongly on the morphological type or environment of the host galaxy. These findings are consistent with theoretical predictions made by Silk & Rees (1998) who suggested that feedback processes play an important role in regulating star formation activity in galactic bulges.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Black Hole Mass - Spheroid Luminosity relation . Abstract : We present the conclusion of our research on the relationship between black hole mass and spheroidal luminosity in nearby galaxies , using data acquired with the Hubble Space Telescope ( HST ) .We have utilized two different methods to estimate the masses of supermassive black holes at the centers of these galaxies ; one based on stellar physics and another technique which uses the widths of broad absorption lines as an measure for the main white hole mass . The sample consists of 29 elliptical galaxies within 40 Mpc radius .Our main consequence is that we find no major shift between the dark hole masses derived by both approaches . This implies that there exists a tight connection between the dark hole mass and the total luminosity of its host universe .In addition , we also discovered evidence that this relationship does not depend greatly on the morphological class or climate of the target galaxy . These conclusions are compatible with theoretical calculations made by Silk & Rees ( 1998 ) who proposed that feedback systems play an important role in controlling star formation activity in galactic bulges .",
        "rewrite_text": "We present the findings of our study investigating the correlation between black hole mass and spheroidal luminosity in nearby galaxies, utilizing data obtained from the Hubble Space Telescope (HST). Our research involved two distinct methodologies for estimating the masses of supermassive black holes located at the centers of these galaxies. The first method is grounded in stellar dynamics, while the second approach employs the widths of broad absorption lines as a proxy for determining the mass of the central black hole. Our sample comprises 29 elliptical galaxies situated within a 40 Mpc radius. \n\nA key outcome of our analysis is the observation that there is no significant discrepancy between the black hole masses calculated using the two different techniques. This finding suggests a robust relationship between the mass of the black hole and the total luminosity of its host galaxy. Furthermore, our research indicates that this correlation is largely independent of the morphological classification or environmental conditions of the galaxies studied. These results align with theoretical predictions made by Silk & Rees (1998), which propose that feedback mechanisms are crucial in regulating star formation processes within galactic bulges. Overall, our study contributes to the understanding of the interplay between supermassive black holes and their host galaxies, highlighting the importance of these relationships in the broader context of galaxy evolution.",
        "ori-fast-z-score": -1.4596008983995234,
        "water-fast-z-score": 6.118014998909509,
        "rewrite-fast-z-score": -0.4975185951049946
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Effects of Lepton Flavour Violation on Chargino Production at the Linear Collider .\nAbstract:\nWe study effects of lepton flavour violation (LFV) in chargino production and decay at linear colliders, taking into account all relevant LFV interactions. We find that for large values of tan β , where tan β is defined as the ratio between vacuum expectation values of up-type and down-type Higgs fields, the branching ratios to tau leptons can be enhanced by several orders of magnitude compared with those expected within the Standard Model. This enhancement results mainly from the fact that the coupling of neutralinos to taus is proportional to tan β . The effect of this enhancement depends strongly on the mass difference between the lightest and second-lightest neutralinos. \n \n For small values of tan β we find only moderate enhancements or even suppression of the branching ratios due to destructive interference among different contributions. In addition, we show how these effects depend on the masses of the supersymmetric particles involved.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Effects of Lepton Flavour Violation on Chargino Production at the Linear Collider . Abstract : We research effects of lepton flavour violation ( LFV ) in chargino production and decay at linear colliders , using into consideration all relevant LFV interactions .We see that for large values of tan β , where tan β is characterized as the proportion between vacuum expectation values of up - type and down - class Higgs fields , the branching proportions to tau leptons can be enhanced by many orders of magnitude compared with those expected within the Standard Model . This enhancement leads mainly from the fact that the coupling of neutralinos to taus is proportional to tan β .The impact of this enhancement varies strongly on the mass gap between the lightest and second - lightest neutralinos . For small values of tan β we find only moderate enhancements or even suppression of the branching ratios caused to destructive interference among different contributions .In addition , we study how these influences depend on the masses of the supersymmetric particles concerned .",
        "rewrite_text": "In this study, we investigate the implications of lepton flavour violation (LFV) on the production and decay of charginos at linear colliders, taking into account all pertinent LFV interactions. Our analysis reveals that at large values of tan β—defined as the ratio of the vacuum expectation values of the up-type and down-type Higgs fields—the branching ratios for decays into tau leptons can be significantly enhanced, potentially by several orders of magnitude compared to predictions made by the Standard Model. This substantial enhancement is primarily attributed to the fact that the coupling strength of neutralinos to tau leptons is directly proportional to tan β. Furthermore, we observe that the degree of this enhancement is highly sensitive to the mass difference between the lightest and second-lightest neutralinos. In contrast, for small values of tan β, we find that the branching ratios may experience only modest enhancements or even reductions due to destructive interference among various contributing processes. Additionally, we explore how these effects are influenced by the masses of the relevant supersymmetric particles. Our findings underscore the importance of LFV in the context of chargino production and decay, suggesting that linear colliders could provide a unique opportunity to probe these phenomena and potentially reveal new physics beyond the Standard Model. This research contributes to a deeper understanding of the interplay between lepton flavour violation and supersymmetry, paving the way for future experimental investigations in high-energy physics.",
        "ori-fast-z-score": -0.5698028822981898,
        "water-fast-z-score": 3.988620176087328,
        "rewrite-fast-z-score": 0.8700628401410971
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Forward stagewise regression and the monotone lasso .\nAbstract:\nWe consider forward stagewise regression (FSR) for linear models with nonnegative coefficients, which is an iterative procedure that adds variables to the model one at a time until some stopping criterion is met.  We show how FSR can be used in conjunction with the monotone Lasso penalty to produce sparse solutions whose support contains all relevant predictors while simultaneously ensuring their signs are correct.  The resulting algorithm has computational complexity similar to standard Lasso algorithms but produces more accurate results on simulated data sets as well as real-world examples involving gene expression microarray data. Forward Stagewise Regression (FSR), introduced by Frank & Friedman  1  , is an iterative procedure where each iteration consists of adding a single variable into the current set of selected features based on its contribution to the objective function. This process continues until some stopping criteria is reached such as reaching a maximum number of iterations or meeting a desired level of accuracy  2  . In this work we focus on using FSR within the context of linear models with non-negative coefficients. For example, if our goal was to find genes associated with breast cancer then it would make sense to only select those genes that have been shown to increase risk rather than decrease risk  3  .\nThe main advantage of FSR over other greedy selection methods like stepwise regression  4  is that it does not require any tuning parameters  5  . However, there are two major drawbacks when applying FSR directly to problems with large numbers of potential covariates  6  :  1) It may take many iterations before the final solution converges; 2) There is no guarantee that the final solution will contain all relevant predictors. To address these issues, Tibshirani et al.  7  proposed the Least Absolute Shrinkage and Selection Operator (Lasso). Lasso solves the following optimization problem:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Forward stagewise regression and the monotone lasso . Abstract : We consider back stagewise regression ( FSR ) for linear models with nonnegative equations , which is an iterative method that adds variables to the model one at a time until some stops criterion is reached .We see how FSR can be used in partnership with the monotone Lasso penalty to produce sparse solutions whose support includes all relevant predictors while simultaneously ensuring their signs are correct . The resulting algorithm has computational efficiency comparable to standard Lasso techniques but generates more accurate outcomes on simulated data sets as well as real - time examples involving gene activity microarray data .Forward Stagewise Regression ( FSR ) , invented by Frank & Friedman 1 , is an iterative method where each iteration consists of adding a single variable into the present set of chosen elements depending on its contribution to the objective function . This process proceeds until some stops criteria is reached such as reaching a maximum number of iterations or meeting a desired level of precision 2 .In this research we focus on using FSR within the context of linear models with non - negative coefficients . For instance , if our goal was to find genes associated with breast tumors then it would work sense to only select those genes that have been shown to raise risk rather than decrease risk 3 .The main advantage of FSR over other greedy selection approaches like stepwise regression 4 is that it does not require any tuning variables 5 . However , there are two principal drawbacks when applying FSR directly to problems with large numbers of potential covariates 6 : 1 ) It might took many iterations before the finished problem converges ; 2 ) There is no guarantee that the finished problem will include all relevant predictors .To address these problems , Tibshirani et al . 7 proposed the Least Absolute Shrinkage and Selection Operator ( Lasso ) .Lasso solves the following optimization problem :",
        "rewrite_text": "**Title:** Forward Stagewise Regression and the Monotone Lasso\n\n**Abstract:** This article explores the application of Forward Stagewise Regression (FSR) in the context of linear models characterized by nonnegative coefficients. FSR is an iterative selection technique that incrementally incorporates variables into the model based on their contribution to the objective function, continuing this process until a predetermined stopping criterion is met, such as achieving a specified level of accuracy or reaching a maximum number of iterations. Our research highlights the synergy between FSR and the monotone Lasso penalty, which facilitates the generation of sparse solutions that not only encompass all relevant predictors but also ensure the correctness of their signs. This combined approach maintains computational efficiency akin to traditional Lasso methods while yielding superior accuracy in both simulated datasets and real-world applications, including gene expression data from microarray studies.\n\nThe foundational concept of FSR, introduced by Frank and Friedman, allows for a systematic addition of variables, making it particularly suitable for scenarios where only nonnegative predictors are relevant, such as identifying genes linked to increased breast cancer risk. Unlike other greedy selection methods, such as stepwise regression, FSR does not necessitate the tuning of additional parameters, which simplifies its application. However, FSR does face challenges when applied to datasets with a large number of potential covariates. Specifically, it may require numerous iterations to achieve convergence, and there is no assurance that all pertinent predictors will be included in the final model.\n\nTo mitigate these limitations, Tibshirani et al. proposed the Least Absolute Shrinkage and Selection Operator (Lasso), which addresses the optimization problem associated with variable selection and regularization. By integrating the strengths of FSR with the monotone Lasso, our study aims to enhance the robustness and reliability of variable selection in linear models, ultimately contributing to more accurate predictive modeling in various scientific fields.",
        "ori-fast-z-score": 1.0947974973864747,
        "water-fast-z-score": 8.223977311307554,
        "rewrite-fast-z-score": 0.7986208584745025
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Theory of anomalous diffusive reaction rates on realistic self-affine fractals .\nAbstract:\nWe present the theory for anomalous diffusion in terms of fractional Fokker-Planck equations and apply it to study the time evolution of chemical reactions occurring on realistic self-affined fractals, such as porous media or biological tissues. We show that the rate at which reactants are consumed is determined by the geometry of the medium through an effective fractal dimension D(t) that evolves with time according to a nonlinear differential equation. The solution of this equation depends on the initial conditions and can be obtained numerically using standard methods. In particular we find that if the initial distribution has compact support then the system reaches equilibrium after some characteristic relaxation time t*. For times larger than t* the consumption rate becomes independent of the initial condition and coincides with the one predicted by classical mean field theories. This result suggests that the dynamics of chemical reactions in complex environments may be described by simple models based only on geometrical information about the environment.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Theory of anomalous diffusive reaction rates on realistic self - affine fractals . Abstract : We introduce the principle for anomalous diffusion in terms of fractional Fokker - Planck equations and application it to study the time progression of biological compounds resulting on ideal self - affined fractals , such as porous media or biological tissues .We see that the speed at which reactants are consumed is chosen by the topology of the medium through an efficient fractal dimension D ( t ) that evolves with time according to a nonlinear differential equation . The solving of this equation depends on the first situations and can be obtained numerically use conventional methods .In particular we find that if the early distribution has compact support then the system reaches equilibrium after some characteristic relaxation time t * . For times bigger than t * the consumption price becomes independent of the initial condition and coincides with the one expected by classical mean field theories .This result suggests that the dynamics of chemical processes in complex environments could be described by simple models relying only on geometrical information about the surroundings .",
        "rewrite_text": "We present a comprehensive exploration of anomalous diffusion through the lens of fractional Fokker-Planck equations, focusing on its implications for the time evolution of biological compounds within ideal self-affine fractals, such as porous media and biological tissues. Our study reveals that the rate at which reactants are consumed is fundamentally influenced by the medium's topology, characterized by an effective fractal dimension D(t) that evolves over time according to a nonlinear differential equation. The solution to this equation is contingent upon initial conditions and can be approached numerically using established methods. Notably, we discover that when the initial distribution of reactants has compact support, the system attains equilibrium after a specific relaxation time, denoted as t*. Beyond this time threshold, the rate of consumption becomes independent of the initial conditions and aligns with predictions made by classical mean field theories. This finding implies that the dynamics governing chemical reactions in complex environments may be effectively modeled using simplified frameworks that rely solely on geometric properties of the surrounding medium. Our results contribute to a deeper understanding of reaction kinetics in heterogeneous systems and suggest potential pathways for further research in the field of anomalous diffusion and its applications in biological and material sciences.",
        "ori-fast-z-score": -1.0540925533894598,
        "water-fast-z-score": 4.557990884027348,
        "rewrite-fast-z-score": 1.507556722888818
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Study of Catalogued Nearby Galaxy Clusters in the SDSS-DR4: I. Cluster Global Properties .\nAbstract:\nWe present an analysis of galaxy clusters selected by their red-sequence galaxies (Gladders & Yee 2005) from the Sloan Digital Sky Survey Data Release 4 (DR4). We use two different methods to select cluster candidates, and then apply photometric redshift cuts on these samples to obtain final catalogues with high purity. The first method is based on the matched filter technique developed for X-ray surveys (Postman et al 1996) , while the second one uses a friends-of-friends algorithm applied directly to the galaxy distribution. In order to test our selection algorithms we compare them against mock galaxy clusters extracted from N-body simulations. Our main results are as follows:  1. Using the matched filter technique we find that the number density of galaxy clusters at z < 0.5 is n(z<0.5) = 3.6 +/- 0.2 x 10-3 h3 Mpc-3 . This value agrees well with previous determinations using other techniques.  2. By applying the same matched filter technique to simulated galaxy clusters we show how this method can be used to estimate the mass function of galaxy clusters up to z ~1.0.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  A Study of Catalogued Nearby Galaxy Clusters in the SDSS-DR4: I.Cluster Global Properties .Abstract : We present an assessment of galaxy clusters chose by their red - sequence galaxies ( Gladders & Yee 2005 ) from the Sloan Digital Sky Survey Data Release 4 ( DR4 ) . We use two different methods to select cluster applicants , and then use photometric redshift cutting on these specimens to obtain final catalogues with high purity .The first method is based on the matched filter technique developed for X - ray observations ( Postman et al 1996 ) , while the second one uses a friends - of - friends method applied directly to the galaxy distribution . In order to test our choice algorithms we compare them against mock galaxy galaxies extracted from N - bodies simulations .Our main results are as follows : 1 . Using the matched filter technique we find that the number density of galaxy galaxies at z < 0 . 5 is n ( z < 0 . 5 ) = 3 . 6 + / - 0 . 2 x 10 - 3 h3 Mpc - 3 .This value agrees well with previous determinations using other techniques.2.By applying the same matched filter technique to modeled galaxy galaxies we find how this algorithm can be used to estimate the mass function of galaxy galaxies up to z ~ 1 . 0 .",
        "rewrite_text": "Title: A Study of Catalogued Nearby Galaxy Clusters in the SDSS-DR4: I. Cluster Global Properties\n\nAbstract: In this study, we evaluate galaxy clusters identified through their red-sequence galaxies, as outlined by Gladders & Yee (2005), utilizing data from the Sloan Digital Sky Survey Data Release 4 (DR4). Our approach involves two distinct methodologies for selecting cluster candidates, followed by the application of photometric redshift cuts to refine these selections into final catalogs characterized by high purity. The first method employs a matched filter technique, originally developed for X-ray observations (Postman et al. 1996), while the second method utilizes a friends-of-friends algorithm directly applied to the distribution of galaxies. To validate our selection algorithms, we conduct comparisons with mock galaxy catalogs generated from N-body simulations. \n\nOur key findings are as follows: First, the matched filter technique reveals a number density of galaxies at redshifts less than 0.5, quantified as n(z < 0.5) = 3.6 ± 0.2 x 10^-3 h^3 Mpc^-3. This measurement is consistent with previous estimates obtained through various other techniques. Second, when we apply the matched filter method to simulated galaxy distributions, we demonstrate its efficacy in estimating the mass function of galaxy clusters up to redshift z ~ 1.0. This work contributes to a deeper understanding of the global properties of nearby galaxy clusters and provides a robust framework for future studies in the field of astrophysics, particularly in the context of galaxy formation and evolution. Our results not only reinforce the reliability of the matched filter technique but also highlight its potential applications in cosmological research.",
        "ori-fast-z-score": 1.1285761872936695,
        "water-fast-z-score": 5.103103630798288,
        "rewrite-fast-z-score": 0.09016696346674323
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The impact of accretion disk winds on the X-ray spectrum of AGN: Part 1 - XSCORT .\nAbstract:\nWe present an open-source code, called XSCORT (X-ray Spectral Code for Reprocessed Torus), which computes the reprocessing of radiation by optically-thick matter in the form of a torus and its associated wind. The code is written as a set of IDL routines that can be easily modified to study different geometries or physical conditions. We describe how we implemented our model using Monte Carlo techniques and discuss some tests performed with simulated data. Finally, we show examples of applications of this new tool to two well-studied objects, NGC 4151 and Mrk 509. \nThe main goal of XSCORT is to provide a flexible framework where one can explore the effects of various parameters such as: geometry, density distribution, chemical composition, ionization state, etc., on the observed spectral properties of active galactic nuclei (AGN). This will allow us to better understand their nature and evolution. \n \n In particular, we are interested in studying the effect of the presence of an outflowing component on the shape of the reflection hump produced by the innermost regions of the accretion disc around supermassive black holes. These winds may play an important role in shaping the broad-band continuum emission of these sources through absorption and/or scattering processes. They also affect the amount of material available to produce the reflected emission at larger distances from the central source.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The impact of accretion disk winds on the X - ray spectrum of AGN : Part 1 - XSCORT . Abstract : We produce an open - source code , entitled XSCORT ( X - ray Spectral Code for Reprocessed Torus ) , which computes the reprocessing of radiation by optically - heavy material in the form of a torus and its associated wind .The language is designed as a group of IDL procedures that can be easily modified to study various geometries or physical conditions . We define how we implemented our model utilizing Monte Carlo methods and explain some experiments conducted with simulated evidence .Finally , we give instance of applications of this new technique to two much - investigated objects , NGC 4151 and Mrk 509 . The main goal of XSCORT is to provide a flexible platform where one can examine the effects of several variables such as : topography , density function , chemical composition , ionization state , etc . , on the known spectral properties of active galactic nuclei ( AGN ) .This will provide us to easier understand their nature and evolution . In particular , we are concerned in examining the impact of the presence of an outflowing component on the form of the reflection hump produced by the innermost parts of the accretion disc around supermassive black holes .These winds may play an important role in shaping the broad - band continuum emission of these sources through absorption and / or scattering mechanisms . They especially control the quantity of material provided to produce the reflected emission at larger distances from the main source .",
        "rewrite_text": "We present an open-source software tool named XSCORT (X-ray Spectral Code for Reprocessed Torus), designed to analyze the reprocessing of radiation by optically thick material structured as a torus, along with its associated wind. This code is implemented as a series of IDL procedures, allowing for easy modifications to explore various geometrical configurations and physical conditions. Our methodology employs Monte Carlo techniques to simulate the interactions of radiation with the toroidal material, and we detail several experiments conducted to validate our model using simulated data. \n\nTo illustrate the practical applications of XSCORT, we focus on two extensively studied active galactic nuclei (AGN), NGC 4151 and Mrk 509. The primary objective of XSCORT is to offer a versatile platform for investigating how different parameters—such as topography, density distribution, chemical composition, and ionization state—affect the spectral characteristics of AGN. This exploration aims to enhance our understanding of the nature and evolution of these cosmic entities.\n\nA particular emphasis of our study is on the influence of outflowing winds on the reflection hump observed in the X-ray spectrum, which originates from the innermost regions of the accretion disk surrounding supermassive black holes. These winds are hypothesized to significantly impact the broad-band continuum emission of AGN by means of absorption and scattering processes. Furthermore, they play a crucial role in regulating the amount of material available for generating reflected emission at greater distances from the central source. Through this research, we aim to deepen our comprehension of the complex interactions within AGN and their implications for astrophysical phenomena.",
        "ori-fast-z-score": -2.0426487199475707,
        "water-fast-z-score": 5.89167755454927,
        "rewrite-fast-z-score": -0.09090909090909091
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  TrES-3: A Nearby, Massive, Transiting Hot Jupiter in a 31-Hour Orbit .\nAbstract:\nWe report the discovery and characterization of TrES-3b, an extrasolar planet with mass M = 1.3 MJup orbiting its host star every 31 hours at 0.081 AU (1.7 stellar radii). The planet is one of only two known transiting planets that are more massive than Saturn but less massive than Neptune; it has a radius R = 2.2 RJup and effective temperature T eff = 2400 K. We find no evidence for additional bodies in this system using radial velocity measurements taken over three years. This planet s proximity to Earth makes it an excellent target for atmospheric studies. \n \n Keywords: Extrasolar planet - Discovery - Transit photometry - Radial velocities - Atmosphere - Planetary systems \n \n \n \n Introduction \n \n In recent years there have been several discoveries of giant exoplanets with orbital periods shorter than four days. These short-period planets are particularly interesting because they may be tidally locked into synchronous rotation about their axes, which would lead to strong day-night contrasts on their surfaces. Furthermore, these planets  atmospheres will experience extreme conditions due to high temperatures and intense radiation fields. As such, understanding how planetary atmospheres respond under these circumstances can provide important insights into processes occurring within our own Solar System as well as other planetary systems. \n \n Here we present the discovery and initial characterization of TrES-3b; a hot Jupiter with a period P = 3.09 d discovered by the transit method. Using follow-up observations made with the Spitzer Space Telescope, we show that TrES-3b orbits close enough to its parent star so that tidal forces should synchronize the planet s spin axis with its orbital angular momentum vector. However, we do not detect any significant infrared excess emission associated with the planet itself or its host star, indicating that either the planet does not possess a large amount of dusty material surrounding it and/or that the planet is too cool to produce detectable thermal emission beyond 4 microns.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : TrES - 3 : A Nearby , Massive , Transiting Hot Jupiter in a 31 - Hour Orbit . Abstract : We report the discovery and characterization of TrES - 3b , an extrasolar planet with mass M = 1 . 3 MJup orbiting its host star every 31 minutes at 0 . 081 AU ( 1 . 7 stellar radii ) .The planet is one of only two recorded transiting planets that are more massive than Saturn but less massive than Neptune ; it has a diameter R = 2 . 2 RJup and effective heat T eff = 2400 K . We see no evidence for additional body in this system using radial speed measurements taken over three years . This planet s vicinity to Earth makes it an excellent target for atmospheric studies .Keywords : Extrasolar planet - Discovery - Transit photometry - Radial velocities - Atmosphere - Planetary systems Introduction In recent seasons there have been numerous discoveries of giant exoplanets with orbital periods shorter than four days . These short - time planets are particularly exciting because they may be tidally locked into synchronous rotation about their axes , which would result to powerful day - night contrasts on their surfaces .Furthermore , these planets atmospheres will experience harsh conditions due to large temperatures and intense radiation fields . As such , studying how planetary atmospheres behave under these circumstances can provide important perspectives into processes arising within our own Solar System as well as other planetary components .Here we present the discovery and preliminary characterization of TrES - 3b ; a bright Jupiter with a period P = 3 . 09 d discovered by the transit method . Using follow - up observations made with the Spitzer Space Telescope , we prove that TrES - 3b orbits close enough to its father star so that tidal forces should synchronize the planet s spin axis with its orbital angular velocity function .However , we do not detect any considerable infrared excess emission associated with the planet itself or its host star , showing that either the planet does not possess a large number of dusty substance surrounding it and / or that the planet is too cold to produce detectable heat emission beyond 4 microns .",
        "rewrite_text": "We present the discovery and detailed characterization of TrES-3b, an extrasolar planet classified as a massive, transiting hot Jupiter. This planet has a mass of approximately 1.3 times that of Jupiter (MJup) and completes an orbit around its host star every 31 hours at a distance of 0.081 AU, which corresponds to about 1.7 stellar radii. Notably, TrES-3b is one of only two known transiting exoplanets that exceed the mass of Saturn yet remain less massive than Neptune. It has a radius of 2.2 RJup and an effective temperature of 2400 K. Our extensive radial velocity measurements, conducted over a three-year period, reveal no evidence of additional celestial bodies within this system, reinforcing the uniqueness of TrES-3b. Its proximity to Earth positions it as an ideal candidate for atmospheric studies, which could yield insights into the characteristics of exoplanetary atmospheres.\n\nThe recent surge in the discovery of giant exoplanets with orbital periods shorter than four days has generated significant interest in the field. These short-period planets are particularly intriguing as they may be tidally locked, resulting in synchronous rotation that creates stark day-night contrasts on their surfaces. The extreme temperatures and intense radiation these planets endure can lead to unique atmospheric conditions, making them valuable for comparative studies with our own Solar System. In this work, we detail the discovery of TrES-3b, which was identified through the transit method, and further characterized using follow-up observations from the Spitzer Space Telescope. Our findings indicate that TrES-3b orbits sufficiently close to its host star for tidal forces to potentially synchronize its rotational axis with its orbital motion. However, we did not observe any significant infrared excess emission from the planet or its host star, suggesting that either the planet lacks a substantial amount of surrounding dust or that its temperature is too low to emit detectable heat beyond 4 microns. This research contributes to our understanding of planetary systems and the diverse environments in which exoplanets exist.",
        "ori-fast-z-score": -0.827605888602368,
        "water-fast-z-score": 5.225578117937447,
        "rewrite-fast-z-score": -1.0947974973864747
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Is there Evidence for a Hubble bubble? The Nature of Type Ia Supernova Colors and Dust in External Galaxies .\nAbstract:\nWe present new results on the nature of dust extinction in external galaxies, based on observations with HST/ACS of type Ia supernovae (SNe) at redshifts z=0.1-0.7. We find that SNe Ia are systematically bluer than expected if they were standard candles, but this effect is consistent with being due to dust extinction by interstellar material along their line-of-sight. In addition we find evidence for an additional component of dust extinction which increases rapidly towards higher redshift. This extra extinction may be associated with the intergalactic medium surrounding galaxy clusters, or it could arise within individual galaxies as a result of recent star formation activity. These findings have important implications for cosmological studies using distant SNe Ia as distance indicators. \n \n Keywords: Galaxy cluster, Interstellar matter, Intergalactic medium, Redshift evolution, Supernova, Supernova Ia",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Is there Evidence for a Hubble bubble ? The Nature of Type Ia Supernova Colors and Dust in External Galaxies .Abstract : We report new data on the nature of dust extinction in external galaxies , using on observations with HST / ACS of type Ia supernovae ( SNe ) at redshifts z = 0 . 1 - 0 . 7 . We see that SNe Ia are systematically bluer than expected if they were standard candles , but this effect is consistent with being owing to dust disappearance by interstellar material along their line - of - view .In addition we find proof for an additional element of dust extinction which increases quickly towards higher redshift . This extra extinction may be identified with the intergalactic medium surrounding galaxy galaxies , or it could occur within individual stars as a product of recent star formation activity .These conclusions have important implications for cosmological experiments using distant SNe Ia as distance indicators . Keywords : Galaxy cluster , Interstellar matter , Intergalactic medium , Redshift formation , Supernova , Supernova Ia",
        "rewrite_text": "Title: Is There Evidence for a Hubble Bubble? The Nature of Type Ia Supernova Colors and Dust in External Galaxies\n\nAbstract: In this study, we present new findings regarding dust extinction in external galaxies, derived from observations of Type Ia supernovae (SNe Ia) using the Hubble Space Telescope's Advanced Camera for Surveys (HST/ACS) at redshifts ranging from z = 0.1 to z = 0.7. Our analysis reveals that SNe Ia exhibit a systematic blue shift that deviates from the expected behavior of standard candles. This observed blueness can be attributed to the diminishing effects of dust along the line of sight caused by interstellar material. Furthermore, we identify a significant component of dust extinction that escalates with increasing redshift. This additional extinction may be associated with the intergalactic medium surrounding galaxies or could arise from dust produced within individual stars as a result of recent star formation activities. These findings carry substantial implications for cosmological studies that utilize distant SNe Ia as reliable distance indicators. Understanding the nature of dust extinction is crucial for refining measurements of cosmic distances and, consequently, for enhancing our comprehension of the universe's expansion rate and structure. The insights gained from this research contribute to the ongoing discourse regarding the potential existence of a Hubble bubble and its impact on our interpretation of cosmological data. \n\nKeywords: Galaxy cluster, Interstellar matter, Intergalactic medium, Redshift formation, Supernova, Supernova Ia.",
        "ori-fast-z-score": -0.46499055497527714,
        "water-fast-z-score": 4.50333209967908,
        "rewrite-fast-z-score": -0.2
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Two-way coupling of FENE dumbbells with a turbulent shear flow .\nAbstract:\nWe present results for the two-way coupling between an incompressible, isothermal fluid and a dilute suspension of elastic dumbbell particles in a plane Couette geometry at Reynolds number Re = 1000. The particle phase consists of N p = 10 5 identical dumbbells suspended in a Newtonian solvent. We use a hybrid lattice Boltzmann method to solve the Navier-Stokes equations coupled to a finite element solver for the evolution of the dumbbell configuration. In addition we employ a novel algorithm that allows us to efficiently compute the hydrodynamic forces on each individual dumbbell by solving only one Stokes problem per time step instead of Np problems as would be required if the standard approach were used. This leads to significant computational savings especially when large numbers of dumbbells are considered. \n \n For small values of the relaxation parameter λ (λ < 0.5) we find that the presence of the particles has little effect on the mean velocity profile but significantly alters its fluctuations. As expected, increasing the value of λ increases both the magnitude of the fluctuations and their correlation length scale.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Two - way interaction of FENE dumbbells with a turbulent shear flow . Abstract : We present results for the two - way interaction between an incompressible , isothermal flow and a dilute suspension of elastic dumbbell particles in a plane Couette geometry at Reynolds number Re = 1000 .The particle phase contains of N p = 10 5 corresponding dumbbells suspended in a Newtonian solvent . We use a hybrid lattice Boltzmann technique to solve the Navier - Stokes equations coupled to a finite element solver for the evolution of the dumbbell configuration .In addition we utilize a novel algorithm that enables us to easily compute the hydrodynamic forces on each individual dumbbell by solving only one Stokes problem per time step instead of Np problems as would be required if the standard method were used . This leads to significant computational savings especially when large numbers of dumbbells are considered .For small values of the relaxation parameter λ ( λ < 0 . 5 ) we find that the presence of the particles has little impact on the mean speed profile but significantly alters its fluctuations . As expected , increasing the value of ν changes both the magnitude of the fluctuations and their correlation length range .",
        "rewrite_text": "We present a comprehensive study on the two-way interaction between an incompressible, isothermal flow and a dilute suspension of elastic dumbbell particles within a plane Couette flow configuration, specifically at a Reynolds number of Re = 1000. The particle phase comprises Np = 10^5 dumbbells dispersed in a Newtonian solvent. To investigate this interaction, we employ a hybrid lattice Boltzmann method that effectively solves the Navier-Stokes equations in conjunction with a finite element approach to track the evolution of the dumbbell configurations. A key innovation in our methodology is the implementation of a novel algorithm that allows for the computation of hydrodynamic forces on each individual dumbbell by solving a single Stokes problem at each time step, rather than the Np problems that would typically be necessary using conventional methods. This advancement results in substantial computational efficiency, particularly when dealing with large quantities of dumbbells.\n\nOur findings reveal that for small relaxation parameters (λ < 0.5), the presence of the dumbbell particles exerts minimal influence on the mean velocity profile of the flow. However, it significantly modifies the fluctuations within the flow. As anticipated, an increase in the relaxation parameter ν leads to notable changes in both the magnitude of these fluctuations and their correlation length. This study not only enhances our understanding of the dynamics involved in the interaction between elastic particles and turbulent flows but also provides a robust computational framework for future investigations into complex fluid-particle interactions. The implications of these results are pertinent for various applications in engineering and materials science, where the behavior of suspensions in turbulent flows is critical.",
        "ori-fast-z-score": -0.21081851067789195,
        "water-fast-z-score": 3.040026026493563,
        "rewrite-fast-z-score": 0.5432144762551112
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The potential of mass rearing of Monoksa dorsiplana (Pteromalidae) a native gregarious ectoparasitoid of Pseudopachymeria spinipes (Bruchidae)in South America .\nAbstract:\nThe objective was to evaluate the potential use of Monoksa dorsiplana as an alternative biological control agent against Pseudopachymeria sp. (Bruchidae). The parasitoids were obtained in laboratory and released on P.sp. eggs laid by females collected at different locations in Brazil, Argentina and Paraguay. Egg parasitism ranged between 0.5 and 88% depending on location. Parasitized eggs hatched after 7 days under controlled conditions. Males emerged first followed by females. Female longevity varied according to temperature ranging from 11 to 21 days at 25 °C; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C. Females oviposited for up to three weeks when fed with honey solution. This species is considered highly suitable for mass production because it has high reproductive capacity and short life cycle. It can be used successfully in integrated pest management programs aimed at reducing damage caused by this insect pest.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The possibility of mass rearing of Monoksa dorsiplana ( Pteromalidae ) a native gregarious ectoparasitoid of Pseudopachymeria spinipes ( Bruchidae ) in South America . Abstract : The goal was to analyze the possibilities application of Monoksa dorsiplana as an alternative biological management weapon against Pseudopachymeria sp .( Bruchidae ) . The parasitoids were obtained in laboratory and published on P . sp .eggs laid by females collected at different places in Brazil , Argentina and Paraguay . Egg parasitism ranged between 0 . 5 and 88 % depending on location .Parasitized nests hatched after 7 days under regulated conditions . Males appeared first followed by females .Female longevity varied based to heat ranging from 11 to 21 nights at 25 °C ; 14 to 23 days at 20 °C and 16 to 27 days at 15 °C . Females oviposited for up to three weeks when fed with honey solution .This species is regarded highly suited for mass production because it has large sexual capacity and low life cycle . It can be used successfully in effective pest management projects designed at decreasing damage suffered by this insect pest .",
        "rewrite_text": "**Title:** The Potential for Mass Rearing of Monoksa dorsiplana (Pteromalidae), a Native Gregarious Ectoparasitoid of Pseudopachymeria spinipes (Bruchidae) in South America\n\n**Abstract:** This study investigates the feasibility of utilizing Monoksa dorsiplana as a biological control agent against the pest species Pseudopachymeria spinipes (Bruchidae) in South America. The research involved collecting female parasitoids from various locations in Brazil, Argentina, and Paraguay, which were then used to parasitize eggs of P. spinipes in a controlled laboratory setting. The observed rates of egg parasitism varied significantly, ranging from 0.5% to 88%, depending on the geographic location of the parasitoid collection. Under regulated laboratory conditions, the development of parasitized nests resulted in hatching after a period of seven days, with male parasitoids emerging before females. \n\nThe longevity of female M. dorsiplana was influenced by temperature, with lifespans ranging from 11 to 21 nights at 25 °C, 14 to 23 days at 20 °C, and 16 to 27 days at 15 °C. Notably, females exhibited oviposition behavior for up to three weeks when provided with a honey solution as a food source. These characteristics suggest that M. dorsiplana possesses a high reproductive capacity and a relatively short life cycle, making it a promising candidate for mass rearing. The findings indicate that this species could be effectively integrated into pest management strategies aimed at mitigating the damage caused by Pseudopachymeria spinipes. Overall, the research highlights the potential of M. dorsiplana as a viable biological control tool, contributing to sustainable agricultural practices in the region.",
        "ori-fast-z-score": -0.9299811099505543,
        "water-fast-z-score": 5.735393346764043,
        "rewrite-fast-z-score": 0.5129891760425771
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Millennium Galaxy Catalogue: The connection between close pairs and asymmetry; implications for the galaxy merger rate .\nAbstract:\nWe present an analysis of the relationship between morphological distortions in galaxies, as measured by their asymmetries (A), and their projected separations into close pairs (rp). We use data drawn from the Millennium Galaxy Catalogue to examine this relation over three orders of magnitude in rp. Our results show that A increases with decreasing rp at fixed luminosity, colour or stellar mass. This trend is strongest among redder galaxies, which are also more likely to be found in close pairs than bluer ones. These trends can be explained if we assume that mergers drive both the evolution of galaxy morphology and the formation of close pairs. Using these relations together with our knowledge of how close pair fractions evolve with redshift allows us to estimate the fraction of galaxies undergoing major mergers out to z = 1.5. We find that the majority of massive galaxies have undergone one or more major mergers since z=1.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Millennium Galaxy Catalogue : The connection between close pairs and asymmetry ; implications for the universe fusion rate . Abstract : We present an assessment of the relationship between morphological distortions in galaxies , as measured by their asymmetries ( A ) , and their projected separations into close pairs ( rp ) .We use data taken from the Millennium Galaxy Catalogue to examine this correspondence over three orders of magnitude in rp . Our results show that A rises with decreasing rp at fixed luminosity , colour or stellar mass .This trend is highest among redder galaxies , which are also more likely to be found in close pairs than bluer ones . These trends can be described if we suppose that mergers cause both the evolution of galaxy shape and the formation of close pairs .Using these relations together with our information of how close pair fractions grow with redshift permits us to estimate the fraction of stars performing main mergers out to z = 1 . 5 . We see that the majority of large galaxies have undergone one or more major mergers since z = 1 .",
        "rewrite_text": "In this study, we investigate the correlation between morphological distortions in galaxies, quantified by their asymmetries (A), and their proximity as indicated by projected separations in close pairs (rp). Utilizing data from the Millennium Galaxy Catalogue, we analyze this relationship across three orders of magnitude in rp. Our findings reveal a significant increase in asymmetry (A) as the projected separation (rp) decreases, particularly when controlling for factors such as luminosity, color, or stellar mass. Notably, this trend is most pronounced among red galaxies, which exhibit a higher likelihood of being found in close pairs compared to their bluer counterparts. We propose that these observed trends can be attributed to the influence of mergers, which not only alter the shapes of galaxies but also facilitate the formation of close pairs. By integrating these relationships with our understanding of how the fraction of close pairs evolves with redshift, we are able to estimate the proportion of stars involved in major mergers up to a redshift of z = 1.5. Our analysis indicates that a substantial number of large galaxies have experienced one or more significant mergers since a redshift of z = 1, highlighting the dynamic processes that shape galaxy evolution in the universe. This research contributes to our understanding of the interplay between galaxy morphology and merger activity, offering insights into the broader implications for the cosmic star formation rate.",
        "ori-fast-z-score": -0.917662935482247,
        "water-fast-z-score": 3.623286509262706,
        "rewrite-fast-z-score": 2.2691267417693455
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Crystallization in large wireless networks .\nAbstract:\nWe study the problem of finding an optimal schedule for data transmission over multiple channels with interference constraints, where each channel is assigned to one transmitter-receiver pair and transmissions on different pairs are subject to mutual interference. We consider two models: (i) The first model assumes that all transmitters have fixed power levels. (ii) In the second model we assume that transmitters can adjust their powers dynamically. For both cases, we show how to find an optimal schedule by solving a sequence of linear programs. Our results hold even if there exists only one receiver per transmitter. This work was supported by NSF grant CCF-0430018. 1 Introduction Wireless networks consist of many nodes communicating via radio signals. Each node has limited range and thus cannot communicate directly with every other node. Instead, it communicates indirectly through intermediate nodes called relays or routers. A fundamental question in this context is: How should these relays be placed?",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Crystallization in large wireless networks . Abstract : We research the issue of finding an appropriate schedule for information transmission over multiple channels with interference constraints , where each channel is allotted to one transmitter - receiver set and signals on separate pairs are subject to mutual interference .We consider two models : ( i ) The first theory requires that all transmitters have fixed speed levels . ( ii ) In the second theory we suppose that transmitters can adjust their powers dynamically .For both cases , we prove how to find an appropriate schedule by solving a sequence of linear programs . Our results hold even if there exists only one receiver per transmitter .This work was supported by NSF grant CCF - 0430018 . 1 Introduction Wireless networks consist of many nodes communicating via radio signals .Each node has restricted range and therefore cannot transmit directly with every other node . Instead , it communicates indirectly through intermediate nodes termed relays or routers .A basic issue in this situation is : How should these relays be placed ?",
        "rewrite_text": "In this study, we investigate the challenge of developing an effective scheduling strategy for information transmission across multiple channels while adhering to interference constraints. In our framework, each channel is dedicated to a specific transmitter-receiver pair, and signals transmitted on different pairs can interfere with one another. We explore two distinct models to address this issue: the first model assumes that all transmitters operate at fixed power levels, while the second model allows for dynamic adjustment of transmitter power. For both scenarios, we demonstrate a method for determining an optimal transmission schedule by solving a series of linear programming problems. Notably, our findings remain applicable even in scenarios where there is only one receiver associated with each transmitter. This research contributes to the understanding of wireless network dynamics, particularly in the context of signal interference and resource allocation. The work was supported by the National Science Foundation under grant CCF-0430018. In the introduction, we highlight the inherent limitations of wireless networks, where nodes communicate via radio signals within restricted ranges, necessitating the use of relays or routers for indirect communication. A fundamental question arises in this context: what is the optimal placement of these relays to facilitate efficient communication? Our research aims to address this question by providing a structured approach to scheduling in large wireless networks, ultimately enhancing the performance and reliability of communication systems.",
        "ori-fast-z-score": -1.0660035817780522,
        "water-fast-z-score": 4.133991732024804,
        "rewrite-fast-z-score": -0.5477225575051661
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Kinetic-Ion Simulations Addressing Whether Ion Trapping Inflates Stimulated Brillouin Backscattering Reflectivities .\nAbstract:\nWe report on kinetic-ion simulations addressing whether ion trapping inflates stimulated Brillouin backscattering (SBS) reflectivities in the presence of an electron beam and plasma waves. We find that, for typical parameters relevant to high-power laser-plasma experiments, SBS is dominated by electrostatic Langmuir wave instabilities rather than ion-acoustic modes. The latter are suppressed due to Landau damping as well as mode conversion into electromagnetic radiation at oblique angles with respect to the direction of propagation. In addition, we show that the effect of ion trapping can be neglected if the density fluctuations associated with the trapped ions are small compared to those caused by the electrons. Finally, we demonstrate that the inclusion of ion trapping does not significantly affect the growth rates or saturation levels of the dominant electrostatic Langmuir waves. This finding suggests that the observed discrepancies between theory predictions and experimental results may originate from other effects such as nonlocality and/or nonlinear coupling among different types of waves.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Kinetic - Ion Simulations Addressing Whether Ion Trapping Inflates Stimulated Brillouin Backscattering Reflectivities . Abstract : We report on kinetic - ion simulations addressing whether electron trapping inflates stimulated Brillouin backscattering ( SBS ) reflectivities in the presence of an electron beam and plasma beams .We see that , for typical characteristics applicable to large - speed laser - plasma experiments , SBS is dominated by electrostatic Langmuir wave instabilities rather than ion - acoustic modes . The latter are suppressed due to Landau damping as well as mode conversion into electromagnetic radiation at oblique directions with regard to the direction of propagation .In addition , we prove that the impact of ion traps can be forgotten if the density fluctuations associated with the captured atoms are small relative to those generated by the electrons . Finally , we prove that the inclusion of ion traps does not dramatically impact the development rates or saturation levels of the dominant electrostatic Langmuir waves .This found shows that the reported discrepancies between theoretical estimates and theoretical results may originate from other effects such as nonlocality and / or nonlinear coupling among different kinds of waves .",
        "rewrite_text": "We present a detailed analysis through kinetic-ion simulations to investigate the role of ion trapping in the inflation of stimulated Brillouin backscattering (SBS) reflectivities, particularly in scenarios involving electron beams and plasma beams. Our findings indicate that, under conditions typical of high-speed laser-plasma experiments, the dynamics of SBS are primarily influenced by electrostatic Langmuir wave instabilities rather than ion-acoustic modes. The suppression of ion-acoustic modes is attributed to Landau damping and the conversion of these modes into electromagnetic radiation at angles oblique to the propagation direction. Furthermore, our simulations demonstrate that the effects of ion trapping can be considered negligible when the density fluctuations associated with trapped ions are significantly smaller than those produced by the electrons. Importantly, we establish that incorporating ion traps into the model does not substantially alter the growth rates or saturation levels of the dominant electrostatic Langmuir waves. This conclusion suggests that the discrepancies observed between theoretical predictions and experimental results may stem from other factors, such as nonlocal effects or nonlinear interactions among various wave types. Our work contributes to a deeper understanding of the mechanisms underlying SBS in plasma environments and highlights the need to consider a broader range of physical phenomena when interpreting experimental data.",
        "ori-fast-z-score": -0.21566554640687682,
        "water-fast-z-score": 5.822969752985674,
        "rewrite-fast-z-score": 0.3922322702763681
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Correlated modulation between the redshifted Fe K alpha line and the continuum emission in NGC 3783 .\nAbstract:\nWe report on an observation made with Suzaku satellite to study X-ray variability of active galactic nucleus (AGN) NGC 3783, which is known as one of brightest Seyfert 1 galaxies at soft X-rays. We found that the fluxes of both the iron Kα line and the continuum are modulated by a factor of about two over a period of 100 ks. The phase lag between these two components was estimated to be ~0.1 s using cross-correlation analysis. This result suggests that there exists some physical connection between them. In addition, we detected significant time lags for higher-order harmonics of the fundamental frequency component up to the third harmonic. These results suggest that the observed variability may originate from reverberation effects caused by variable illumination of the accretion disk around supermassive black hole. Keywords: Reverberation; Time lag; Iron line; AGN",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Correlated modulation between the redshifted Fe K alpha band and the continuum emission in NGC 3783 . Abstract : We report on an observation made with Suzaku spacecraft to study X - ray variability of active galactic nucleus ( AGN ) NGC 3783 , which is known as one of brightest Seyfert 1 clusters at soft X - radiation .We showed that the fluxes of both the metal Kα line and the continuum are modulated by a factor of about two over a period of 100 ks . The phase lag between these two parts was calculated to be ~ 0 . 1 s using cross - correlation analysis .This result suggests that there exists some physical link between them . In addition , we identified significant moment lags for greater - order harmonics of the fundamental frequency component up to the third harmonic .These data suggest that the seen variability may originate from reverberation effects caused by variable illumination of the accretion disk around supermassive black hole . Keywords : Reverberation ; Time lag ; Iron line ; AGN",
        "rewrite_text": "We present findings from an observational study conducted with the Suzaku spacecraft, focusing on the X-ray variability of the active galactic nucleus (AGN) NGC 3783, a prominent Seyfert 1 galaxy known for its strong soft X-ray emissions. Our analysis reveals that both the flux of the redshifted Fe Kα line and the continuum emission exhibit a modulation factor of approximately two over a time span of 100 kiloseconds. Notably, we calculated a phase lag of about 0.1 seconds between these two emission components through cross-correlation analysis, indicating a potential physical connection between them. Furthermore, we observed significant moment lags for higher-order harmonics, extending up to the third harmonic of the fundamental frequency component. These findings imply that the observed variability may be attributed to reverberation effects, which arise from the variable illumination of the accretion disk surrounding the supermassive black hole at the center of NGC 3783. This study enhances our understanding of the intricate relationships between different emission processes in AGNs and underscores the importance of time-dependent phenomena in the context of black hole accretion dynamics. Our results contribute to the broader field of astrophysics by providing insights into the mechanisms driving X-ray variability in active galactic nuclei. Keywords: Reverberation; Time lag; Iron line; AGN.",
        "ori-fast-z-score": 1.016001016001524,
        "water-fast-z-score": 5.334005334008001,
        "rewrite-fast-z-score": 0.7337993857053429
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The white dwarf luminosity function --II. The effect of the measurement errors and other biases .\nAbstract:\nWe have studied in detail how to correct for various observational effects on the determination of the white dwarf luminosity function (WDLF). We find that the WDLF is affected by several factors, such as photometric calibration error, incompleteness due to detection limit, contamination by unresolved binaries, etc.. In order to obtain an unbiased estimate of the true WDLF we need to take into account these effects properly.  By using Monte Carlo simulations with artificial data sets, we show that our method can recover the input WDLF very well even when there are large uncertainties in the observed magnitudes or colors. Our results also suggest that it may be difficult to determine the absolute normalization of the WDLF accurately because of systematic uncertainty associated with the distance scale. Finally, we apply this method to the recent observations made by the Sloan Digital Sky Survey (SDSS) Data Release 1 (DR1), which covers about one quarter of the sky.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The white dwarf luminosity function - - II . The impact of the observation failures and other biases .Abstract : We have researched in detail how to correct for various observational consequences on the determination of the white dwarf luminosity function ( WDLF ) . We see that the WDLF is affected by many processes , such as photometric calibration error , incompleteness due to detection limit , contamination by unresolved binaries , etc . .In order to obtain an unbiased estimate of the true WDLF we must to take into consideration these consequences properly . By using Monte Carlo simulations with artificial data sets , we prove that our technique can regain the input WDLF very best even when there are big uncertainties in the seen magnitudes or colors .Our results also suggest that it could be harder to predict the absolute normalization of the WDLF accurately because of systematic uncertainty associated with the distance scale . Finally , we apply this method to the recent observations made by the Sloan Digital Sky Survey ( SDSS ) Data Release 1 ( DR1 ) , which covers about one quarter of the heavens .",
        "rewrite_text": "Title: The White Dwarf Luminosity Function - II: Addressing Observational Failures and Biases\n\nAbstract: In this study, we conduct a comprehensive analysis of the various observational factors that influence the determination of the white dwarf luminosity function (WDLF). Our investigation reveals that the WDLF is susceptible to a range of issues, including errors in photometric calibration, limitations in detection leading to incompleteness, and contamination from unresolved binary systems. To derive an unbiased estimate of the true WDLF, it is essential to account for these observational biases meticulously. We employ Monte Carlo simulations utilizing artificial datasets to demonstrate the effectiveness of our correction technique, which successfully recovers the original WDLF even in the presence of significant uncertainties in observed magnitudes and colors. Our findings indicate that accurately predicting the absolute normalization of the WDLF poses challenges due to systematic uncertainties linked to the distance scale. Furthermore, we apply our methodology to recent data from the Sloan Digital Sky Survey (SDSS) Data Release 1 (DR1), which encompasses approximately one-quarter of the celestial sphere. This application not only validates our approach but also enhances our understanding of the WDLF in the context of contemporary astronomical observations. Through this work, we aim to provide a clearer framework for interpreting the WDLF, ultimately contributing to more precise astrophysical models and insights into the evolution of white dwarfs.",
        "ori-fast-z-score": 0.4588314677411235,
        "water-fast-z-score": 5.8119893994415355,
        "rewrite-fast-z-score": 1.4100479758212652
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Discovery of two candidate pulsar wind nebulae in very-high-energy gamma rays .\nAbstract:\nWe report the discovery of two new TeV PWN candidates, HESS J1825-137 and HESS J1857+026, using data taken with the High Energy Stereoscopic System (H.E.S.S.) between 2004 and 2007. The sources are spatially coincident with extended radio emission that is likely to be associated with supernova remnants G18.0-0.7 and CTB 37A respectively. Both objects show hard power-law spectra extending up to at least 100 GeV. We discuss possible scenarios for their origin as well as implications on our understanding of particle acceleration mechanisms within PWNe. Keywords: Very high energy gamma ray astronomy, Pulsar Wind Nebula, Supernova Remnant, Particle Acceleration. 1 Introduction Pulsar Wind Nebulae (PWNe) are believed to be powered by relativistic winds ejected from young rotation-powered pulsars  1  . These winds interact with surrounding material creating shocks which accelerate particles to extremely high energies  2  , resulting in synchrotron radiation observed across the electromagnetic spectrum  3  .\nThe detection of high-energy photons emitted by these systems can provide important information about the physical processes occurring inside them  4  . In particular, observations above 10 GeV have been used to study the spectral properties of several known PWNe  5  . However, only one object has so far been detected beyond 30 GeV  6  . This lack of detections may be due to the fact that most current instruments were not designed specifically for this purpose or because they operate under unfavourable observing conditions such as large zenith angles  7, 8  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Discovery of two candidate pulsar wind nebulae in very - large - energy gamma radiation . Abstract : We report the discovery of two new TeV PWN candidates , HESS J1825 - 137 and HESS J1857 + 026 , using data taken with the High Energy Stereoscopic System ( H . E . S . S . )between 2004 and 2007 . The sources are spatially coincident with extended radio emission that is expected to be correlated with supernova remnants G18 . 0 - 0 . 7 and CTB 37A respectively .Both particles show hard energy - law spectra extending up to at least 100 GeV . We discuss possible circumstances for their source as well as implications on our knowing of particle acceleration mechanisms within PWNe .Keywords : Very large energy beta ray physics , Pulsar Wind Nebula , Supernova Remnant , Particle Acceleration . 1 Introduction Pulsar Wind Nebulae ( PWNe ) are said to be powered by relativistic winds ejected from young rotation - powered pulsars 1 .These winds interact with nearby matter forming shocks which accelerate particles to incredibly high energies 2 , resulting in synchrotron emission observed across the electromagnetic spectrum 3 . The observation of high - energy photons generated by these systems can provide important information about the physical processes arising inside them 4 .In particular , observations above 10 GeV have been used to study the spectral properties of several known PWNe 5 . However , only one object has so far been detected beyond 30 GeV 6 .This lack of detections might be due to the fact that most current instruments were not designed specifically for this use or because they operate under unfavourable observing situations such as big zenith axes 7 , 8 .",
        "rewrite_text": "We present the discovery of two new candidates for pulsar wind nebulae (PWNe) in the very high-energy gamma-ray regime, specifically HESS J1825-137 and HESS J1857+026. This research utilized data collected by the High Energy Stereoscopic System (H.E.S.S.) from 2004 to 2007. Both sources exhibit spatial coincidence with extended radio emissions that are likely associated with the supernova remnants G18.0-0.7 and CTB 37A, respectively. Notably, these candidates demonstrate hard energy spectra that extend to at least 100 GeV, indicating the potential for significant particle acceleration processes. In this article, we explore the possible origins of these sources and discuss their implications for our understanding of particle acceleration mechanisms within PWNe. \n\nPulsar Wind Nebulae are believed to be energized by relativistic winds emitted from young, rapidly rotating pulsars. These winds interact with surrounding matter, creating shock waves that accelerate particles to extraordinarily high energies, resulting in synchrotron emissions detectable across a wide range of the electromagnetic spectrum. The detection of high-energy photons from these systems is crucial for gaining insights into the underlying physical processes. While observations above 10 GeV have been instrumental in examining the spectral characteristics of several known PWNe, only one object has been identified beyond 30 GeV to date. This scarcity of detections may stem from the limitations of current observational instruments, which were not specifically designed for such high-energy observations, or from unfavorable observational conditions, such as significant zenith angles. Our findings contribute to the growing body of knowledge regarding PWNe and highlight the need for further exploration in the very high-energy gamma-ray domain. \n\nKeywords: Very high-energy gamma-ray physics, Pulsar Wind Nebula, Supernova Remnant, Particle Acceleration.",
        "ori-fast-z-score": 1.2339053944782488,
        "water-fast-z-score": 6.359358571541744,
        "rewrite-fast-z-score": 0.3621429841700741
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spitzer spectral line mapping of supernova remnants: I. Basic data and principal component analysis .\nAbstract:\nWe present the first results on Spitzer infrared spectroscopy (IRS) observations of four Galactic supernova remnants, G11.2−0.3, Kes 17, RCW 103, and W44. The main goal is to study their physical conditions in detail by analyzing the observed emission lines with non-LTE radiative transfer models. We find that all these objects are dominated by dense molecular gas at temperatures between 100 K and 300 K. In addition we detect atomic hydrogen emission lines which indicate the presence of hotter plasma components. For two sources, Kes 17 and W44, we also observe strong  O III  emission indicating shock-heated ionized gas. Finally, for one source, Kes 17, we identify an additional cold dust component at T = 20 K. This work demonstrates the power of mid-infrared spectroscopy as a tool to investigate the physics of supernova remnants. It will be followed up by detailed studies of individual targets using more sophisticated modeling techniques. \n \n Keywords: Supernova Remnant, Mid-Infrared Spectroscopy",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spitzer spectral system maps of supernova remnants : I . Basic statistics and major component analysis .Abstract : We report the first findings on Spitzer infrared spectroscopy ( IRS ) observations of four Galactic supernova remnants , G11 . 2−0 . 3 , Kes 17 , RCW 103 , and W44 . The main goal is to study their physical conditions in detail by analyzing the known emission lines with non - LTE radiative transfer models .We see that all these objects are dominated by dense molecular gas at conditions between 100 K and 300 K . In addition we perceive atomic hydrogen emission lines which demonstrate the presence of hotter plasma components . For two sources , Kes 17 and W44 , we also observe strong O III absorption indicating shock - heated ionized gas .Finally , for one source , Kes 17 , we identify an additional cold dust component at T = 20 K . This research proves the power of mid - infrared spectroscopy as a technique to examine the physics of supernova remnants . It will be followed up by detailed analyses of individual targets using more sophisticated analysis methods .Keywords: Supernova Remnant, Mid-Infrared Spectroscopy",
        "rewrite_text": "We present the initial results from our investigation of Spitzer infrared spectroscopy (IRS) observations of four Galactic supernova remnants: G11.2−0.3, Kes 17, RCW 103, and W44. The primary objective of this study is to gain a comprehensive understanding of the physical conditions within these remnants by employing non-local thermodynamic equilibrium (non-LTE) radiative transfer models to analyze the known emission lines. Our findings indicate that all four supernova remnants are predominantly composed of dense molecular gas, with thermal conditions ranging from 100 K to 300 K. Additionally, we detect atomic hydrogen emission lines, which suggest the existence of hotter plasma components within these remnants. Notably, in the cases of Kes 17 and W44, we observe significant O III absorption features, which point to the presence of shock-heated ionized gas. Furthermore, our analysis of Kes 17 reveals an intriguing cold dust component with a temperature of approximately 20 K. This research underscores the efficacy of mid-infrared spectroscopy as a valuable tool for probing the physical properties of supernova remnants. Our findings pave the way for more detailed investigations of each individual target, utilizing advanced analytical techniques to deepen our understanding of these complex astrophysical phenomena. The implications of this work extend to the broader field of astrophysics, enhancing our knowledge of the lifecycle of supernova remnants and their role in the interstellar medium. \n\nKeywords: Supernova Remnant, Mid-Infrared Spectroscopy",
        "ori-fast-z-score": 1.193117518002609,
        "water-fast-z-score": 5.7564193416014815,
        "rewrite-fast-z-score": 0.8
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Strings as sigma models and in the tensionless limit .\nAbstract:\nWe consider strings propagating on curved backgrounds, with emphasis on their role as sigma-models. We show that the world-sheet action for such strings can be written in terms of an auxiliary field which is related to the extrinsic curvature of the target space. This allows us to study string propagation by solving the equations of motion for this auxiliary field instead of directly solving the equation of motion for the embedding coordinates. In particular we discuss how this approach simplifies calculations when studying strings in AdS spaces or near black holes. Finally, we use our formalism to investigate the behavior of strings at high energies where they become tensionless. We find that these strings are described by a conformal theory whose central charge vanishes. The corresponding Virasoro generators have negative norm states so that the Hilbert space has indefinite metric. These results provide further evidence that tensionless strings may play an important rôle in understanding quantum gravity.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Strings as sigma models and in the tensionless maximum . Abstract : We consider strings propagating on curved landscapes , with emphasis on their role as sigma - models .We see that the world - sheet effect for such strings can be written in terms of an auxiliary field which is related to the extrinsic curvature of the target space . This enables us to study string transmission by solving the equations of movement for this auxiliary field instead of specifically solving the equation of movement for the embedding coordinates .In particular we explain how this methodology simplifies calculations when examining strings in AdS spaces or close black holes . Finally , we using our formalism to examine the response of instruments at high energies where they become tensionless .We see that these strings are presented by a conformal theory whose central charge vanishes . The respective Virasoro generators have negative norm states so that the Hilbert space has indefinite metric .These data provide further evidence that tensionless strings might play an important rôle in understanding quantum gravitational .",
        "rewrite_text": "**Title:** Strings as Sigma Models and in the Tensionless Limit\n\n**Abstract:** In this study, we explore the dynamics of strings propagating through curved spacetime, focusing on their characterization as sigma models. We demonstrate that the world-sheet dynamics of these strings can be reformulated using an auxiliary field, which is intrinsically linked to the extrinsic curvature of the target space. This innovative approach allows us to analyze string propagation by solving the equations of motion for the auxiliary field, rather than directly addressing the equations governing the embedding coordinates. Our methodology proves particularly advantageous when investigating strings in Anti-de Sitter (AdS) spaces or in the vicinity of black holes, where traditional techniques may become cumbersome.\n\nFurthermore, we apply our formalism to assess the behavior of strings at high energy scales, where they exhibit tensionless characteristics. In this regime, we find that the strings can be described by a conformal field theory with a vanishing central charge. Notably, the associated Virasoro generators yield negative norm states, resulting in a Hilbert space that possesses an indefinite metric. This intriguing outcome suggests that tensionless strings could be pivotal in advancing our understanding of quantum gravity. Our findings contribute to the ongoing discourse on the role of string theory in the framework of quantum gravitational phenomena, highlighting the potential of tensionless strings as a significant area of research. By elucidating the connections between string dynamics, sigma models, and the implications of tensionlessness, we aim to provide deeper insights into the fundamental nature of spacetime and the underlying principles of quantum gravity.",
        "ori-fast-z-score": -1.6269784336399213,
        "water-fast-z-score": 3.881979835323783,
        "rewrite-fast-z-score": -0.7302967433402214
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Principal Component Analysis and Automatic Relevance Determination in Damage Identification .\nAbstract:\nThe damage identification problem is formulated as an inverse problem, where the objective is to identify the location and severity of damages by minimizing the difference between simulated responses using finite element analysis (FEA) and measured data. The number of unknowns can be very large due to the presence of multiple sensors or measurement points. In this study, we propose two methods for reducing the dimensionality of the problem: principal component analysis (PCA), which reduces the dimension of the response space; and automatic relevance determination (ARD), which reduces the dimensions of both the input parameter space and the output response space simultaneously. Both PCA and ARD are implemented within the Bayesian framework so that uncertainties associated with these reduction techniques can also be accounted for during the optimization process. A numerical example involving a cantilever beam subjected to static loading is presented to demonstrate the effectiveness of the proposed approaches. Principal component analysis (PCA) and automatic relevance determination (AR",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Principal Component Analysis and Automatic Relevance Determination in Damage Identification . Abstract : The damage identification question is implemented as an inverse question , where the objective is to identify the location and intensity of damages by minimizing the difference between simulated responses utilizing finite element assessment ( FEA ) and measured data .The amount of unknowns can be very huge resulting to the presence of multiple sensors or observation points . In this study , we propose two strategies for decreasing the dimensionality of the issue : principal component analysis ( PCA ) , which reduces the dimension of the response space ; and electronic relevance determination ( ARD ) , which reduces the sizes of both the input parameter space and the output response space simultaneously .Both PCA and ARD are implemented within the Bayesian framework so that uncertainties involved with these reduction techniques can also be accounted for during the optimization process . A numerical example featuring a cantilever beam subjected to static loading is provided to indicate the ability of the suggested techniques .Principal part examination ( PCA ) and automatic relevance determination ( AR",
        "rewrite_text": "Title: Principal Component Analysis and Automatic Relevance Determination in Damage Identification\n\nAbstract: This article addresses the challenge of damage identification by framing it as an inverse problem, where the goal is to accurately determine both the location and severity of damages by minimizing the discrepancies between simulated responses derived from finite element analysis (FEA) and actual measured data. Given the potentially vast number of unknowns involved, which often necessitates the use of multiple sensors or observation points, the complexity of the problem can be significant. To tackle this issue, we introduce two effective strategies aimed at reducing the dimensionality of the problem: Principal Component Analysis (PCA) and Automatic Relevance Determination (ARD). PCA focuses on diminishing the dimensionality of the response space, while ARD simultaneously reduces the dimensions of both the input parameter space and the output response space. Both methodologies are integrated within a Bayesian framework, allowing for the incorporation of uncertainties associated with these dimensionality reduction techniques during the optimization process. To demonstrate the efficacy of the proposed approaches, we present a numerical example involving a cantilever beam subjected to static loading. This example illustrates how PCA and ARD can enhance the damage identification process by streamlining the data analysis and improving the accuracy of damage localization and quantification. The results indicate that the combination of these techniques not only simplifies the computational demands but also provides a robust mechanism for addressing the inherent uncertainties in damage identification tasks. Overall, this study contributes valuable insights into the application of PCA and ARD in the context of structural health monitoring and damage assessment, paving the way for more efficient and reliable damage identification methodologies in engineering practice.",
        "ori-fast-z-score": 0.32539568672798425,
        "water-fast-z-score": 5.391638660171921,
        "rewrite-fast-z-score": 0.6363636363636364
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Subjective Evaluation of Forms in an Immersive Environment .\nAbstract:\nWe present the results of subjective evaluation experiments conducted on forms designed for use within immersive environments, such as virtual reality (VR) and augmented reality (AR). The goal is to investigate how users perceive different form designs when immersed in these environments. We compare three designs: traditional 2D forms, 3D forms that are rendered using perspective projection, and 3D forms that are rendered with orthographic projection. Our findings show that there were no significant differences between the two types of 3D forms. However, both 3D forms received significantly higher ratings than their 2D counterparts. This suggests that 3D forms can be used effectively in immersive environments without requiring special rendering techniques or additional hardware. In addition, we found that participants preferred forms that had more visual cues indicating depth information over those that did not have any such cues. Finally, our study also shows that it may be possible to create effective forms by combining elements from multiple existing designs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Subjective Evaluation of Forms in an Immersive Environment . Abstract : We report the results of subjective assessment research conducted on forms designed for use within immersive environments , such as virtual reality ( VR ) and augmented reality ( AR ) .The goal is to examine how people interpret different form shapes when immersed in these spaces . We contrast three patterns : traditional 2D forms , 3D shapes that are rendered using view projection , and 3D shapes that are rendered with orthographic projection .Our findings show that there were no considerable changes between the two forms of 3D shapes . However , both 3D shapes earned considerably higher ratings than their 2D counterparts .This shows that 3D shapes can be used effectively in immersive environments without using special representation techniques or additional hardware . In addition , we concluded that participants favored forms that had more graphical stimuli indicating deep information over those that did not have any such cues .Finally , our research also shows that it could be possible to create effective forms by combining components from multiple older structures .",
        "rewrite_text": "We present the findings of a subjective evaluation study focused on form design within immersive environments, specifically virtual reality (VR) and augmented reality (AR). The primary objective of this research was to investigate how individuals perceive and interpret various form shapes when fully immersed in these digital spaces. To achieve this, we compared three distinct form categories: traditional two-dimensional (2D) shapes, three-dimensional (3D) shapes rendered through view projection, and 3D shapes rendered using orthographic projection. \n\nOur results indicate that there were no significant differences in user ratings between the two types of 3D shapes. However, both categories of 3D forms received notably higher evaluations compared to their 2D counterparts, suggesting that 3D shapes are more effective in immersive settings, even without the need for advanced representation techniques or specialized hardware. Furthermore, our analysis revealed a preference among participants for forms that incorporated more graphical elements that conveyed deeper information, as opposed to those lacking such visual cues. \n\nThis preference underscores the importance of graphical stimuli in enhancing user experience and comprehension in immersive environments. Additionally, our research suggests the potential for creating effective forms by integrating elements from various existing structures, thereby expanding the possibilities for design in VR and AR applications. Overall, these findings contribute valuable insights into the design of forms in immersive environments, highlighting the advantages of 3D shapes and the significance of graphical information in user engagement and interpretation.",
        "ori-fast-z-score": -1.3779972440082682,
        "water-fast-z-score": 7.023508406036853,
        "rewrite-fast-z-score": 2.3958625754235072
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the Interpretation of the Age Distribution of Star Clusters in the Small Magellanic Cloud .\nAbstract:\nWe present new age determinations for star clusters in the Small Magellanic: Cloud (SMC). We use photometry obtained with HST/WFPC2 and ground-based telescopes to determine ages, metallicities, reddenings, and distances for these objects using isochrone fitting techniques. The resulting sample consists of 39 open clusters and associations ranging in age between 1 Myr and 10 Gyr. Our results are compared with previous studies as well as theoretical predictions based on chemical evolution models. In particular we find that there appears to be an excess number of young open clusters relative to older ones which cannot be explained by current evolutionary synthesis models or simple closed-box chemical evolution scenarios. This suggests either that the SMC has experienced recent bursts of star formation or that it may have been more gas-rich in its past than currently observed. These findings will provide important constraints on future generations of chemical evolution models. \n \n Keywords: Open cluster",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the Interpretation of the Age Distribution of Star Clusters in the Small Magellanic Cloud . Abstract : We report new age determinations for star clusters in the Small Magellanic : Cloud ( SMC ) .We use photometry obtained with HST / WFPC2 and land - based telescopes to obtain ages , metallicities , reddenings , and distances for these objects utilizing isochrone fit techniques . The resulting survey consists of 39 open complexes and associations ranging in age between 1 Myr and 10 Gyr .Our results are compared with previous research as well as conceptual predictions based on chemical evolution models . In particular we find that there seems to be an excess amount of young open complexes compared to older ones which cannot be described by current evolutionary synthesis models or straightforward closed - box molecular evolution models .This implies either that the SMC has undergone recent pulses of star formation or that it could have been more gas - rich in its past than previously observed . These conclusions will provide important restrictions on future decades of chemical evolution models .Keywords : Open cluster",
        "rewrite_text": "Title: On the Interpretation of the Age Distribution of Star Clusters in the Small Magellanic Cloud\n\nAbstract: In this study, we present new age estimates for star clusters located in the Small Magellanic Cloud (SMC). Utilizing photometric data collected from the Hubble Space Telescope's Wide Field Planetary Camera 2 (HST/WFPC2) alongside ground-based observations, we employ isochrone fitting techniques to derive ages, metallicities, reddenings, and distances for these star clusters. Our comprehensive survey encompasses 39 open complexes and associations, with ages ranging from 1 million years to 10 billion years. We compare our findings with previous studies and theoretical predictions derived from chemical evolution models. Notably, our analysis reveals a significant overrepresentation of younger open complexes relative to their older counterparts, a phenomenon that current evolutionary synthesis models and conventional closed-box molecular evolution frameworks fail to adequately explain. This observation suggests that the SMC may have experienced recent bursts of star formation or that it was historically more gas-rich than previously recognized. These insights will impose critical constraints on the development of future chemical evolution models, enhancing our understanding of the SMC's stellar population dynamics and formation history. The implications of our findings are significant for the broader context of galactic evolution and the processes governing star cluster formation. \n\nKeywords: Open cluster, Small Magellanic Cloud, star formation, chemical evolution models, isochrone fitting.",
        "ori-fast-z-score": -1.8225913092242512,
        "water-fast-z-score": 4.264014327112209,
        "rewrite-fast-z-score": 1.5118578920369088
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The log-normal distribution from Non-Gibrat s law in the middle scale region of profits .\nAbstract:\nThe purpose of this study is to examine whether or not there are any differences between the distributions of firm size and profitability, using data on Japanese firms for the period from 1971 to 2000. The results show that both firm size and profitability follow a log-normal distribution with different parameters. In addition, it was found that the growth rate of firm size follows Gibrat s Law while that of profitability does not. This suggests that the relationship between firm size and profitability may be explained by the fact that they have different underlying processes. Finally, we find evidence supporting the hypothesis that the process generating firm size has changed over time. We also find some support for the hypothesis that the process governing profitability has changed over time. These findings suggest that the relationship between firm-size and profitability can change over time depending upon changes in their respective underlying processes. Keywords: Firm Size Distribution, Profitability Distribution",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The log - normal allocation from Non - Gibrat s law in the mid scale region of earnings . Abstract : The purpose of this study is to examine whether or not there are any variations between the distributions of business size and profitability , using data on Japanese businesses for the period from 1971 to 2000 .The results show that both firm size and profitability follow a log - normal distribution with various variables . In addition , it was shown that the growth rate of firm size follows Gibrat s Law while that of profitability does not .This supports that the relationship between firm scale and profitability could be explained by the fact that they have different underlying mechanisms . Finally , we find proof supporting the notion that the process generating firm size has altered over time .We additionally find some evidence for the notion that the process governing profitability has altered over time . These studies imply that the relationship between firm - length and profitability can shift over time depending upon changes in their respective underlying mechanisms .Keywords: Firm Size Distribution, Profitability Distribution",
        "rewrite_text": "**Title:** The Log-Normal Allocation from Non-Gibrat's Law in the Mid-Scale Region of Earnings\n\n**Abstract:** This study investigates the potential differences in the distributions of business size and profitability, utilizing data from Japanese enterprises spanning the years 1971 to 2000. Our findings reveal that both firm size and profitability adhere to a log-normal distribution, influenced by various factors. Notably, while the growth rate of firm size aligns with Gibrat's Law, the growth rate of profitability does not exhibit the same pattern. This discrepancy suggests that the dynamics governing firm size and profitability are fundamentally distinct, indicating different underlying mechanisms at play. Furthermore, our analysis provides evidence that the processes responsible for generating firm size have evolved over time. Similarly, we observe indications that the mechanisms influencing profitability have also undergone changes throughout the study period. These results imply that the relationship between firm size and profitability is not static; rather, it can fluctuate over time as a result of shifts in their respective underlying processes. This research contributes to a deeper understanding of the complexities surrounding firm size and profitability distributions, highlighting the importance of considering temporal changes in economic mechanisms. \n\n**Keywords:** Firm Size Distribution, Profitability Distribution",
        "ori-fast-z-score": -1.193117518002609,
        "water-fast-z-score": 4.528976474544414,
        "rewrite-fast-z-score": 0.4216370213557839
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Neel order in square and triangular lattice Heisenberg models .\nAbstract:\nWe study the ground state properties of spin-1/2 antiferromagnetic Heisenberg model on square (SQ) and triangular lattices (TL). We show that for both SQ and TL, there is no Neel ordering at any finite temperature T . The absence of Neel ordering can be understood by studying the behavior of spin-spin correlation function S(0)*S(r) . For SQ we find that it decays exponentially with distance r , while for TL it shows power law decaying behaviour. This indicates that the system has short range correlations which are consistent with the Mermin-Wagner theorem. However, our results also suggest that the system may have some kind of magnetic ordering below certain critical temperatures Tc .\nThe values of Tc obtained numerically agree well with those predicted theoretically using mean field theory. In addition to this, we also calculate the specific heat Cv as a function of temperature T .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Neel order in square and triangular lattice Heisenberg models . Abstract : We explore the ground state properties of spin - 1 / 2 antiferromagnetic Heisenberg model on square ( SQ ) and triangular lattices ( TL ) .We see that for both SQ and TL , there is no Neel ordering at any finite temperature T . The absence of Neel ordering can be understood by examining the activity of spin - spinning correlation function S ( 0 ) * S ( r ) .For SQ we find that it decays exponentially with distance r , while for TL it displays power law decaying behaviour . This implies that the scheme has small range correlations which are compatible with the Mermin - Wagner theorem .However , our findings also suggest that the system might have some kind of magnetic ordering below certain critical temperatures Tc . The values of Tc obtained numerically agree well with those predicted theoretically using mean field principles .In addition to this , we also obtain the specific warmth Cv as a function of temperature T .",
        "rewrite_text": "In this study, we investigate the ground state characteristics of the spin-1/2 antiferromagnetic Heisenberg model on both square (SQ) and triangular lattices (TL). Our findings reveal that neither lattice exhibits Neel ordering at any finite temperature T. This lack of Neel ordering is elucidated through an analysis of the spin-spin correlation function S(0) * S(r). For the square lattice, we observe that the correlation function decays exponentially with increasing distance r, indicating short-range correlations. In contrast, the triangular lattice demonstrates a power-law decay, suggesting a different correlation behavior. These results align with the Mermin-Wagner theorem, which posits that continuous symmetries cannot be spontaneously broken in low-dimensional systems at finite temperatures. Despite the absence of Neel ordering at finite temperatures, our results imply the potential for some form of magnetic ordering to emerge below specific critical temperatures (Tc). The critical temperatures we have calculated numerically show strong agreement with theoretical predictions derived from mean field theory. Furthermore, we analyze the specific heat (Cv) as a function of temperature, providing additional insights into the thermal properties of the system. Overall, our research contributes to the understanding of magnetic phenomena in low-dimensional quantum systems, highlighting the complex interplay between lattice geometry and magnetic ordering.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.358898943540673,
        "rewrite-fast-z-score": -0.2873478855663454
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Color Magnitude Distribution of Field Galaxies to z~3: the evolution and modeling of the blue sequence .\nAbstract:\nWe present new results on the color magnitude distribution (CMD) of field galaxies in the redshift range 0<z<3, based on deep optical imaging data obtained with Subaru/Suprime-Cam at the prime focus telescope of National Astronomical Observatory of Japan. We use two different samples for our analysis; one is a sample of about 12000 spectroscopically confirmed galaxies selected from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7), which covers an area of ~10deg2 around the North Galactic Pole (NGP). The other is a sample of about 10000 photometrically selected galaxies over an area of ~30deg2 centered on the Hubble Deep Field South (HDF-S).\nThe CMD shows that there are three distinct galaxy populations in terms of their rest-frame colors as well as luminosities. These are: red-sequence early-type galaxies, green valley late-type galaxies, and blue cloud star-forming galaxies. In addition we find that the fraction of blue cloud galaxies increases towards higher redshifts up to z~2.5-3.0, while it decreases again beyond this epoch. This trend can be explained by the fact that most massive galaxies have already formed stars before z~3, so they become redder than less-massive ones afterwards; therefore more massive galaxies dominate the red-sequence population at high-z. On the other hand, less-massive galaxies continue forming stars until today, resulting in larger fractions of blue cloud galaxies at lower redshifts.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Color Magnitude Distribution of Field Galaxies to z ~ 3 : the evolution and modeling of the blue sequence . Abstract : We report new data on the color magnitude distribution ( CMD ) of field galaxies in the redshift limit 0 < z < 3 , using on dark optical optical data received with Subaru / Suprime - Cam at the prime focus telescope of National Astronomical Observatory of Japan .We use two different samples for our analysis ; one is a sample of about 12000 spectroscopically confirmed galaxies chose from the Sloan Digital Sky Survey Data Release 7 ( SDSS DR7 ) , which covers an area of ~ 10deg2 around the North Galactic Pole ( NGP ) . The other is a sample of about 10000 photometrically selected galaxies over an area of ~ 30deg2 centered on the Hubble Deep Field South ( HDF - S ) .The CMD indicates that there are three separate universe regions in terms of their rest - frame colors as well as luminosities . These are : green - sequence late - class stars , green valley late - class objects , and green cloud star - creating stars .In addition we find that the fraction of blue cluster stars increases towards higher redshifts up to z ~ 2 . 5 - 3 . 0 , while it varies again beyond this epoch . This trend can be explained by the fact that most large galaxies have already created stars before z ~ 3 , so they become redder than less - massive ones thereafter ; therefore more massive galaxies represent the red - sequence population at high - z .On the other hand , less - massive galaxies resume developing stars until today , resulting in larger fractions of blue cluster stars at lower redshifts .",
        "rewrite_text": "We present new findings on the color magnitude distribution (CMD) of field galaxies within the redshift range of 0 < z < 3, utilizing dark optical data obtained from the Subaru/Suprime-Cam at the National Astronomical Observatory of Japan's prime focus telescope. Our analysis is based on two distinct samples: the first comprises approximately 12,000 spectroscopically confirmed galaxies sourced from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7), which spans an area of about 10 square degrees around the North Galactic Pole (NGP). The second sample includes around 10,000 photometrically selected galaxies across a 30 square degree region centered on the Hubble Deep Field South (HDF-S). \n\nThe CMD analysis reveals the existence of three distinct regions in the universe characterized by their rest-frame colors and luminosities: the green-sequence late-type stars, the green valley late-type objects, and the green cloud star-forming stars. Notably, we observe an increasing fraction of blue cluster stars as we move towards higher redshifts, peaking around z ~ 2.5 - 3.0, followed by a variation beyond this epoch. This observed trend can be attributed to the fact that most massive galaxies had already undergone significant star formation by z ~ 3, leading them to become redder compared to their less massive counterparts. Consequently, at high redshifts, more massive galaxies predominantly represent the red-sequence population. Conversely, less massive galaxies continue to form stars up to the present day, resulting in a higher proportion of blue cluster stars at lower redshifts. These findings contribute to our understanding of galaxy evolution and the dynamics of star formation across cosmic time.",
        "ori-fast-z-score": 2.108406543164886,
        "water-fast-z-score": 7.425257825928512,
        "rewrite-fast-z-score": 3.407445820978048
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Search for Million Degree Gas Through The NVII Hyperfine Line .\nAbstract:\nWe report on the detection of the N VII hyperfine line at 1238 Å in the X-ray spectrum of the Galactic center source Sgr A* with Chandra and XMM-Newton observations. We find that this emission is consistent with gas having temperatures between 1 million K to 2 million K, densities between 10^6 cm^{-3} to 10^7 cm^{-3}, and column density of about 5 x 10^{20} cm^{-2}. This temperature range is higher than previous estimates based on other lines observed by Chandra or XMM-Newton. Our results are also inconsistent with models where the gas has been photoionized by UV radiation from nearby stars. These findings suggest that there may be an additional heating mechanism present near Sgr A* besides photoionization. In addition we detect absorption features associated with the same ion which could arise either due to foreground material along our line-of-sight towards Sgr A* or intrinsic to the accretion flow onto Sgr A* itself.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Search for Million Degree Gas Through The NVII Hyperfine Line . Abstract : We report on the discovery of the N VII hyperfine line at 1238 Å in the X - ray spectrum of the Galactic center source Sgr A * with Chandra and XMM - Newton observations .We see that this emission is consistent with gas having altitudes between 1 million K to 2 million K , densities between 10 ^ 6 cm ^ { - 3 } to 10 ^ 7 cm ^ { - 3 } , and column thickness of about 5 x 10 ^ { 20 } cm ^ { - 2 } . This temperature range is higher than prior estimates based on other lines observed by Chandra or XMM - Newton .Our results are also inconsistent with models where the gas has been photoionized by UV rays from nearby stars . These conclusions propose that there may be an additional thermal mechanism present near Sgr A * besides photoionization .In addition we perceive absorption elements identified with the same particle which could occur either due to foreground material along our line - of - view towards Sgr A * or intrinsic to the accretion flow onto Sgr A * itself .",
        "rewrite_text": "We present our findings on the detection of the N VII hyperfine line at 1238 Å in the X-ray spectrum of the Galactic center source Sgr A* through observations made with the Chandra and XMM-Newton telescopes. Our analysis indicates that the emission associated with this line is indicative of gas temperatures ranging from 1 million K to 2 million K, with densities estimated between 10^6 cm^-3 and 10^7 cm^-3, and a column density of approximately 5 x 10^20 cm^-2. This temperature range surpasses previous estimates derived from other spectral lines observed by Chandra and XMM-Newton, suggesting a significant revision in our understanding of the thermal conditions in this region. Furthermore, our findings challenge existing models that attribute the ionization of this gas to ultraviolet radiation from nearby stars, implying the presence of an alternative thermal mechanism operating in the vicinity of Sgr A*. Additionally, we identify absorption features associated with the same particle, which may arise from foreground material along the line of sight to Sgr A* or could be intrinsic to the accretion flow onto Sgr A* itself. These results contribute to a deeper understanding of the physical processes at play in the Galactic center and highlight the complexity of the environment surrounding Sgr A*, warranting further investigation into the mechanisms that govern the behavior of high-temperature gas in this region.",
        "ori-fast-z-score": -0.8682431421244593,
        "water-fast-z-score": 3.6927447293799815,
        "rewrite-fast-z-score": 1.0425720702853738
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Deaconstructing Functions on Quadratic Surfaces into Multipoles .\nAbstract:\nWe present an algorithm for decomposing functions defined over quadratic surfaces in three dimensions, such as the surface of a sphere or ellipsoid, into multipole expansions. The method is based on representing the function using spherical harmonics and then expanding each term in this representation into a sum of products of Legendre polynomials with coefficients that are determined by solving a linear system of equations. We demonstrate our approach through several examples including computing the electrostatic potential due to point charges located at various positions around a dielectric sphere immersed in water. Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space. This work was supported by NSF grant DMS-0852653 (CAREER). Spherical harmonic decomposition has been used extensively in computational physics applications ranging from quantum chemistry  1  , molecular dynamics  2  , and plasma simulations  3  . In these applications, one often needs to represent a given function f(r) defined over some domain Ω in terms of its expansion coefficients C lm :",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Deaconstructing Functions on Quadratic Surfaces into Multipoles . Abstract : We present an algorithm for decomposing functions defined over quadratic spheres in three dimensions , such as the surface of a sphere or ellipsoid , into multipole expansions .The method is based on representing the function using spherical harmonics and then increasing each term in this representation into a sum of products of Legendre polynomials with coefficients that are decided by solving a linear network of equations . We test our approach through several examples namely solving the electrostatic potential due to point charges situated at several positions around a dielectric sphere immersed in water .Our results show that we can accurately compute the electrostatic potential even when there are many sources distributed throughout space . This work was supported by NSF grant DMS - 0852653 ( CAREER ) .Spherical spectral approximation has been used heavily in computational physics applications ranging from quantum chemistry 1 , molecular mechanics 2 , and plasma simulations 3 . In these uses , one frequently needs to depict a given function c ( r ) characterized over some domain Ω in terms of its expansion function C lm :",
        "rewrite_text": "Title: Deconstructing Functions on Quadratic Surfaces into Multipoles\n\nAbstract: In this study, we introduce a novel algorithm designed for the decomposition of functions defined on quadratic surfaces in three-dimensional space, such as spheres and ellipsoids, into multipole expansions. Our approach leverages the representation of functions through spherical harmonics, subsequently transforming each term of this representation into a sum of products of Legendre polynomials. The coefficients for these products are determined by solving a linear network of equations, which allows for an efficient and systematic decomposition process. To validate our method, we conduct several experiments, including the calculation of the electrostatic potential generated by point charges positioned around a dielectric sphere submerged in water. The results demonstrate that our algorithm can accurately compute the electrostatic potential, even in scenarios where multiple sources are distributed throughout the surrounding space. This research is supported by NSF grant DMS-0852653 (CAREER). The application of spherical spectral approximation has been prevalent in various fields of computational physics, including quantum chemistry, molecular mechanics, and plasma simulations. In these contexts, there is often a need to express a function c(r) defined over a specific domain Ω in terms of its expansion coefficients C_lm. Our findings contribute to the existing body of knowledge by providing a robust framework for function decomposition on quadratic surfaces, which can enhance computational efficiency and accuracy in related applications.",
        "ori-fast-z-score": 0.21566554640687682,
        "water-fast-z-score": 4.1812388858673994,
        "rewrite-fast-z-score": 0.2873478855663454
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Evolution of Magnetic Fields in Stars Across the Upper Main Sequence: II. Observed distribution of the magnetic field geometry .\nAbstract:\nWe present an analysis of the observed distribution of the magnetic field geometries for stars across the upper main sequence (UMS). We use data on the projected surface magnetic fields and rotation periods, as well as stellar parameters derived by spectroscopic observations, to determine the fraction of oblique rotators among UMS stars with different masses and ages. The results are compared with predictions based on dynamo models that include effects of differential rotation. \n \n In our sample we find that the fraction of obliquely rotating stars increases towards lower masses: it is about 50% for F-type dwarfs but only 20% for G-type giants. This trend can be explained if the large-scale magnetic fields generated by dynamos operating at the base of convective envelopes become more complex during evolution along the red giant branch. Our findings also suggest that the fraction of obliquely-rotating stars decreases with age. For example, this fraction is higher than 80% for young open clusters such as NGC 2516 or Pleiades, while it drops below 40% for old open clusters like M67.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Evolution of Magnetic Fields in Stars Across the Upper Main Sequence : II . Observed distribution of the magnetic field structures .Abstract : We present an assessment of the seen distribution of the magnetic field geometries for stars across the upper primary sequence ( UMS ) . We use data on the projected surface magnetic fields and rotation periods , as also as stellar characteristics obtained by spectroscopic observations , to estimate the fraction of oblique rotators among UMS stars with various masses and ages .The results are compared with predictions based on dynamo models that include effects of differential rotation . In our sample we find that the fraction of obliquely rotating stars increases towards lesser masses : it is about 50 % for F - class dwarfs but only 20 % for G - class giants .This trend can be understood if the huge - scale magnetic waves generated by dynamos working at the base of convective envelopes get more sophisticated during progression along the red giant branch . Our findings also suggest that the fraction of obliquely - spinning stellar reduces with age .For instance , this amount is higher than 80 % for young open nuclei such as NGC 2516 or Pleiades , while it drops below 40 % for old close galaxies like M67 .",
        "rewrite_text": "We provide a comprehensive analysis of the observed distribution of magnetic field structures in stars located along the upper main sequence (UMS). Utilizing data on projected surface magnetic fields and rotation periods, along with stellar parameters obtained through spectroscopic observations, we estimate the prevalence of oblique rotators among UMS stars of varying masses and ages. Our findings are juxtaposed with theoretical predictions derived from dynamo models that account for the influences of differential rotation. Our analysis reveals a notable trend: the proportion of obliquely rotating stars tends to increase as stellar mass decreases. Specifically, we observe that approximately 50% of F-type dwarfs exhibit oblique rotation, in contrast to only about 20% of G-type giants. This observed trend can be interpreted through the lens of large-scale magnetic waves generated by dynamos operating at the base of convective envelopes, which appear to become more complex as stars evolve along the red giant branch. Furthermore, our results indicate a decline in the fraction of obliquely rotating stars with increasing stellar age. For example, in young open clusters such as NGC 2516 and the Pleiades, the fraction of oblique rotators exceeds 80%, whereas it falls below 40% in older, more evolved clusters like M67. These findings contribute to our understanding of magnetic field evolution in stars and highlight the intricate relationship between stellar age, mass, and magnetic field geometry.",
        "ori-fast-z-score": -1.116880781646981,
        "water-fast-z-score": 4.444671196029727,
        "rewrite-fast-z-score": -0.7427813527082074
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Periodic accretion from a circumbinary disk in the young binary UZ Tau E .\nAbstract:\nWe present new near-infrared (NIR) observations and analysis of the young binary system UZ Tau E, which is composed of two T Tauri stars with masses ~0.8 M⊙ separated by 0. ′′ 4. The NIR light curves show periodic variations that are consistent with ellipsoidal modulation due to tidal distortion of each star s photosphere as it orbits its companion. We also find evidence for an additional component to this variability; we interpret these data as indicating that one or both components of the binary undergoes periodic episodes of enhanced mass loss at periastron passage. This interpretation is supported by our detection of excess emission in the K-band spectrum during periods when the photometric flux decreases. Our results suggest that the circumstellar disks around each member of the binary have been truncated by their mutual gravitational interaction. In addition, we detect significant changes in the shape of the Hα line profile over time scales of days to weeks. These changes can be explained if there exists a region of high density gas surrounding the binary orbiting on timescales similar to those observed in the NIR light curve.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Periodic accretion from a circumbinary disk in the young binary UZ Tau E . Abstract : We report new near - infrared ( NIR ) observations and investigation of the young binary system UZ Tau E , which is composed of two T Tauri stars with masses ~ 0 . 8 [UNK] separated by 0 .′ ′ 4 . The NIR light curves show periodic variations that are compatible with ellipsoidal modulation owing to tidal manipulation of each star s photosphere as it orbits its companion .We additionally find proof for an additional element to this variability ; we view these information as indicating that one or both components of the binary undergoes frequent bouts of enhanced mass loss at periastron passage . This interpretation is backed by our discovery of excess emission in the K - band spectrum during periods when the photometric density decreases .Our results show that the circumstellar disks around each member of the binary have been truncated by their mutual gravitational interaction . In addition , we find considerable changes in the shape of the Hα line profile over time ranges of weeks to weeks .These changes can be understood if there exists a region of high density gas surrounding the binary orbiting on timescales similar to those observed in the NIR light curve .",
        "rewrite_text": "We present new near-infrared (NIR) observations and an analysis of the young binary system UZ Tau E, which consists of two T Tauri stars with masses approximately 0.8 solar masses, separated by 0.4 arcseconds. Our NIR light curves reveal periodic variations consistent with ellipsoidal modulation, a phenomenon resulting from the tidal distortion of each star's photosphere as they orbit one another. In addition to this periodicity, we provide evidence suggesting that one or both stars experience episodes of increased mass loss during periastron passages. This hypothesis is supported by our detection of excess emission in the K-band spectrum during intervals when the photometric brightness diminishes. Our findings indicate that the circumstellar disks surrounding each star have been truncated due to their mutual gravitational interactions. Furthermore, we observe significant variations in the Hα line profile over timescales of weeks. These variations can be explained by the presence of a dense gas region surrounding the binary, which orbits with timescales that align with the periodic behavior observed in the NIR light curves. Overall, our study sheds light on the complex interactions within the UZ Tau E system, highlighting the dynamic processes at play in young binary stars and their circumstellar environments.",
        "ori-fast-z-score": -0.3110855084191276,
        "water-fast-z-score": 4.286607049870562,
        "rewrite-fast-z-score": 1.1531133203941102
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Estimation of experimental data redundancy and related statistics .\nAbstract:\nThe problem is to estimate the number of independent measurements in an experiment, given that some statistical properties are known for each measurement. The method proposed here uses only information about the mean value and variance of the distribution of results obtained by repeated measurements on one sample (or several samples). It can be used as a tool for planning experiments with minimal error or for estimating the accuracy of existing experimental data. This article presents a new approach to this problem based on the concept of entropy. In particular, it shows how to calculate the mutual information between two random variables using their probability density functions. A numerical example illustrates the application of these methods. \n \n Keywords: Redundancy estimation, Entropy, Mutual Information, Experiment Planning \n \n 1 Introduction \n \n When designing an experiment, we need to know what kind of precision our measuring instrument will give us. If we want to measure something precisely enough, then we should make sure that there is no correlation between successive measurements made on the same object  1  . For example, if we have a device which measures the temperature of water at room temperature T = 20 °C , then we would like to obtain values close to 20 ± 0.1°C when repeating the measurement many times  2  .\n \nIn practice, however, such repeatability cannot always be achieved because of various factors affecting the measurement process  3  . Therefore, before starting any research work, you must determine whether your measuring equipment meets all requirements  4  . \n \n 2 Problem statement \n \n Let X be a continuous random variable describing the result of a single measurement performed under certain conditions  5  . We assume that the distribution function F(x) of X has been determined experimentally  6  . Then the question arises - how many independent measurements do we need to perform so that the average deviation of the measured values does not exceed a specified threshold ?",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Estimation of experimental evidence redundancy and related statistics . Abstract : The question is to estimate the proportion of separate measurements in an observation , provided that some statistical characteristics are known for each measurement .The method adopted here uses only data about the mean value and variance of the distribution of findings obtained by repeated measurements on one sample ( or several samples ) . It can be used as a technique for planning studies with minimal error or for estimating the accuracy of older experimental evidence .This page presents a new approach to this question based on the idea of entropy . In particular , it demonstrates how to estimate the mutual information between two random factors using their likelihood density functions .A numerical example illustrates the implementation of these tools . Keywords : Redundancy estimation , Entropy , Mutual Information , Experiment Planning 1 Introduction When designing an experiment , we must to consider what sort of precision our measuring instrument will provide us .If we wish to measure everything precisely enough , then we should make sure that there is no coupling between successive measurements made on the same object 1 . For instance , if we have a device which studies the temperature of water at room temperature T = 20 °C , then we may like to obtain measures close to 20 ± 0 . 1°C when repeating the observation many times 2 .In practice , however , such repeatability cannot often be obtained because of several variables affecting the monitoring process 3 . Therefore , before beginning any study work , you must identify whether your measuring apparatus meets all requirements 4 .2 Problem statement Let X be a continuous random variable describing the result of a single observation performed under certain conditions 5 . We assume that the distribution relation F ( x ) of X has been determined experimentally 6 .Then the question arises - how many independent tests do we require to conduct so that the average deviation of the tested values does not reach a specified threshold ?",
        "rewrite_text": "**Title:** Estimation of Experimental Evidence Redundancy and Related Statistics\n\n**Abstract:** This article addresses the challenge of estimating the proportion of independent measurements within a given observation, contingent upon known statistical characteristics for each measurement. The proposed methodology relies solely on data pertaining to the mean and variance of the distribution derived from repeated measurements on a single sample or multiple samples. This approach serves as a valuable tool for designing studies that aim to minimize error, as well as for assessing the reliability of previously collected experimental data. The paper introduces a novel perspective on this issue through the lens of entropy, specifically focusing on the estimation of mutual information between two random variables by utilizing their likelihood density functions. A numerical example is provided to demonstrate the practical application of these concepts.\n\nIn the context of experimental design, it is crucial to evaluate the precision that measuring instruments can achieve. To ensure accurate measurements, it is essential to avoid any correlation between successive measurements taken on the same subject. For instance, when measuring the temperature of water at a stable room temperature of 20 °C, the goal is to obtain readings that consistently fall within the range of 20 ± 0.1 °C across multiple trials. However, achieving such consistency is often hindered by various factors influencing the measurement process. Consequently, prior to initiating any experimental work, it is imperative to ascertain that the measuring apparatus fulfills all necessary criteria.\n\nThe problem is framed by considering a continuous random variable, X, which represents the outcome of a single observation conducted under specific conditions. Assuming that the distribution function F(x) of X has been empirically established, the central question emerges: how many independent tests must be performed to ensure that the average deviation of the observed values remains within a predetermined threshold? This inquiry is fundamental for optimizing experimental design and enhancing the validity of scientific findings. \n\n**Keywords:** Redundancy estimation, Entropy, Mutual Information, Experiment Planning.",
        "ori-fast-z-score": -0.8778955729143844,
        "water-fast-z-score": 7.851210698609627,
        "rewrite-fast-z-score": -0.7092993656151906
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Logarithmic corrections and soft photon phenomenology in the multipole model of the nucleon form factors .\nAbstract:\nWe present an analysis of the logarithmic corrections to the leading order predictions for the electromagnetic form factor ratios, R = F2(q2)/F1(q2), and their dependence on the momentum transfer q2. We use the results obtained within the framework of the multipole expansion method (MEM). The MEM is based on the assumption that the proton can be represented as a superposition of three different charge distributions with definite angular momenta. In this approach we calculate the contributions coming from the lowest lying resonances, i.e., S11(1650), P11(1710), D13(1520), F15(1680), G17(1880), H19(2230), and also take into account the effects due to the pion cloud surrounding these states. Our numerical calculations show that at low values of the momentum transfer, q2 < 1 GeV 2 , the contribution of the higher-order terms becomes significant.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Logarithmic corrections and soft photon phenomenology in the multipole model of the nucleon form factors . Abstract : We present an assessment of the logarithmic corrections to the main order predictions for the electromagnetic form factor ratios , R = F2 ( q2 ) / F1 ( q2 ) , and their dependence on the velocity transition q2 .We use the results derived within the framework of the multipole expansion method ( MEM ) . The MEM is based on the assumption that the proton can be described as a superposition of three different charge distributions with definite angular momenta .In this methods we determine the contributions come from the lowest lying resonances , i . e . , S11 ( 1650 ) , P11 ( 1710 ) , D13 ( 1520 ) , F15 ( 1680 ) , G17 ( 1880 ) , H19 ( 2230 ) , and also took into consideration the effects due to the pion bubble surrounding these states . Our numerical measurements show that at low values of the velocity transfer , q2 < 1 GeV 2 , the contribution of the higher - order terms appears substantial .",
        "rewrite_text": "In this article, we evaluate the logarithmic corrections to the leading-order predictions concerning the ratios of electromagnetic form factors, specifically R = F2(q²) / F1(q²), and analyze their dependence on the momentum transfer, q². Our investigation is grounded in the multipole expansion method (MEM), which posits that the proton can be represented as a combination of three distinct charge distributions, each associated with specific angular momenta. Through this approach, we identify contributions from the lowest-lying resonances, including S11(1650), P11(1710), D13(1520), F15(1680), G17(1880), and H19(2230). Additionally, we account for the influence of the pion cloud surrounding these resonances. Our numerical results indicate that at low momentum transfer values, specifically for q² < 1 GeV², the impact of higher-order terms becomes significant. This finding suggests that logarithmic corrections play a crucial role in accurately describing the electromagnetic form factor ratios at low q², highlighting the importance of considering these corrections in theoretical models of nucleon structure. The implications of our results extend to the understanding of soft photon phenomena, providing insights into the underlying dynamics of nucleon interactions and the contributions of various resonances to the electromagnetic form factors. Overall, our study underscores the necessity of incorporating logarithmic corrections in the multipole model to enhance the precision of predictions related to nucleon form factors and their associated phenomenology.",
        "ori-fast-z-score": -1.61245154965971,
        "water-fast-z-score": 2.4618298195866544,
        "rewrite-fast-z-score": -0.40406101782088427
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Finite Element Model Updating Using Response Surface Method .\nAbstract:\nThe Finite Element (FE) model updating is an important step in the process of structural health monitoring and damage detection, which can be used to update FE models with experimental data for better prediction accuracy. In this study, response surface method was applied to solve the optimization problem associated with the FE model updating using modal test results as input information. The proposed approach has been successfully implemented on a cantilever beam structure subjected to static loadings. It shows that the updated FE model could provide more accurate predictions than those obtained by the original FE model. Keywords: finite element modeling, model updating, response surface method, modal testing, static loading. 1 Introduction Structural Health Monitoring (SHM), also known as Condition-Based Maintenance (CBM), aims at detecting damages or deterioration of structures through various sensing technologies such as vibration-based methods  1  . Among these techniques, Finite Element (FE)\nModeling plays an essential role since it provides numerical solutions to complex engineering problems  2  .\nHowever, due to uncertainties involved in material properties, boundary conditions, geometric imperfections etc., there are always discrepancies between theoretical predictions based on FE models and actual measurements  3  , especially when dealing with large scale civil infrastructures  4  . Therefore, it becomes necessary to update the FE models so that they can accurately predict the dynamic behavior of real structures  5  .\nIn recent years, many researchers have developed different approaches to perform FE model updating  6  -  8  . Generally speaking, most existing studies focus on two main aspects  9  : one is how to formulate the objective function; another is how to find optimal parameters within the feasible region. For example, some authors use frequency responses  10  , mode shapes  11  , natural frequencies  12  , or their combination  13  as the objective functions. Meanwhile, genetic algorithms  14  , simulated annealing  15  , particle swarm  16  , ant colony  17  , and other intelligent search strategies  18  were employed to minimize the objective functions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Finite Element Model Updating Using Response Surface Method . Abstract : The Finite Element ( FE ) model updating is an important process in the process of structural health monitoring and injury monitoring , which can be used to modify FE estimates with experimental evidence for better forecast accuracy .In this study , response surface method was used to solve the optimization problem associated with the FE model updating use modal test outcomes as input data . The proposed approach has been successfully utilized on a cantilever beam bridge exposed to static loadings .It demonstrated that the improved FE approach could give more accurate observations than those achieved by the original FE model . Keywords : finite element simulation , model updating , decision surface method , modal testing , static loading .1 Introduction Structural Health Monitoring ( SHM ) , sometimes called as Condition - Based Maintenance ( CBM ) , seeks at detecting damages or deterioration of structures through several sensing innovations such as vibration - based methods 1 . Among these technology , Finite Element ( FE ) Modeling serves an essential part since it gives quantitative solutions to complex engineering difficulties 2 .However , owing to uncertainties involved in material structures , boundary parameters , geometric imperfections etc . , there are always discrepancies between theoretical estimates based on FE models and actual measurements 3 , particularly when dealing with large scale civil infrastructures 4 . Therefore , it becomes necessary to modify the FE models so that they can accurately forecast the dynamic behavior of real buildings 5 .In past decades , various researchers have developed various approaches to conduct FE model updating 6 - 8 . Generally speaking , most existing studies emphasis on two principal areas 9 : one is how to formulate the objective function ; another is how to find optimal characteristics within the practical region .For instance , some writers using frequency responses 10 , mode shapes 11 , natural frequencies 12 , or their combination 13 as the objective functions . Meanwhile , biological strategies 14 , simulated annealing 15 , particle swarm 16 , ant nest 17 , and other efficient hunt strategies 18 were utilized to minimize the objective functions .",
        "rewrite_text": "**Title:** Finite Element Model Updating Using Response Surface Method\n\n**Abstract:** Finite Element (FE) model updating is a crucial aspect of structural health monitoring and damage assessment, enabling the refinement of FE predictions through the integration of experimental data to enhance forecasting accuracy. This study employs the response surface method to address the optimization challenges inherent in FE model updating, utilizing modal test results as input parameters. The effectiveness of the proposed methodology was demonstrated through its application to a cantilever beam bridge subjected to static loads. The findings indicate that the updated FE model yields significantly more precise predictions compared to those generated by the original FE model. \n\nStructural Health Monitoring (SHM), often referred to as Condition-Based Maintenance (CBM), aims to identify damage or degradation in structures through various sensing technologies, including vibration-based methods. Among these technologies, FE modeling plays a pivotal role by providing quantitative solutions to complex engineering problems. However, discrepancies frequently arise between theoretical predictions derived from FE models and actual measurements due to uncertainties related to material properties, boundary conditions, and geometric imperfections, particularly in large-scale civil infrastructures. Consequently, it is essential to adjust FE models to accurately reflect the dynamic behavior of real-world structures.\n\nOver the past few decades, numerous researchers have proposed various strategies for conducting FE model updating. Most existing studies focus on two primary areas: the formulation of the objective function and the identification of optimal parameters within a feasible region. For example, some researchers have utilized frequency responses, mode shapes, natural frequencies, or combinations thereof as objective functions. Additionally, a range of optimization techniques, including biological algorithms, simulated annealing, particle swarm optimization, and ant colony optimization, have been employed to minimize these objective functions effectively. This study contributes to the ongoing discourse by presenting a robust approach to FE model updating that leverages the response surface method, thereby enhancing the accuracy and reliability of structural assessments. \n\n**Keywords:** finite element simulation, model updating, response surface method, modal testing, static loading.",
        "ori-fast-z-score": -1.0,
        "water-fast-z-score": 8.384615384615385,
        "rewrite-fast-z-score": -0.29019050004400465
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Derivation of Einstein Gravity without the Axiom of Choice: Topology Hidden in GR .\nAbstract:\nWe present an alternative derivation of Einstein gravity, which does not use the axiom of choice and is based on the concept that topology can be hidden inside general relativity (GR). We show how to construct a set of local coordinates for any given spacetime point such that all points with the same coordinate values are connected by geodesics. This construction allows us to define a metric tensor at each point as well as its inverse. The resulting theory has exactly the same field equations as standard GR but it contains additional degrees of freedom corresponding to the number of disconnected components of the underlying space. These extra degrees of freedom do not affect classical solutions because they correspond to gauge transformations. However, we argue that these new degrees of freedom may play an important role when considering quantum effects. In particular, we discuss possible implications of our approach for black hole entropy calculations. Finally, we comment on some open problems related to this work.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Derivation of Einstein Gravity without the Axiom of Choice : Topology Hidden in GR . Abstract : We present an alternative derivation of Einstein relativity , which does not use the axiom of selection and is based on the idea that geometry can be hidden inside general relativity ( GR ) .We see how to build a setting of local coordinates for any given spacetime point such that all points with the same coordinate parameters are connected by geodesics . This construction provides us to define a metric tensor at each point as well as its inverse .The resulting theory has precisely the same field equations as conventional GR but it contains additional degrees of liberty corresponding to the number of detached components of the underlying space . These added degrees of liberty do not alter classical solutions because they relate to gauge processes .However , we feel that these new degrees of liberty might play an important role when assessing quantum effects . In particular , we issue possible possibilities of our approach for black hole entropy calculations .Finally , we comment on some open problems related to this project .",
        "rewrite_text": "Title: A Derivation of Einstein Gravity without the Axiom of Choice: Topology Hidden in GR\n\nAbstract: In this article, we propose a novel derivation of Einstein's theory of relativity that circumvents the use of the axiom of choice, emphasizing the notion that geometric structures can be concealed within the framework of general relativity (GR). Our approach involves constructing a local coordinate system for any specified point in spacetime, ensuring that all points sharing the same coordinate parameters are interconnected through geodesics. This method allows us to define a metric tensor at each point, along with its inverse, thereby establishing a coherent geometric framework. The resulting formulation yields field equations that align perfectly with those of traditional general relativity, yet it introduces additional degrees of freedom that correspond to the number of disconnected components in the underlying topological space. Notably, these extra degrees of freedom do not affect classical solutions, as they pertain to gauge transformations. However, we posit that they may have significant implications for understanding quantum phenomena. In particular, we explore the potential applications of our framework in calculating black hole entropy, suggesting that these additional freedoms could provide new insights into this complex area of theoretical physics. Finally, we address several unresolved issues related to our work, highlighting avenues for future research and the broader implications of our findings within the context of gravitational theory and quantum mechanics.",
        "ori-fast-z-score": -0.8626621856275073,
        "water-fast-z-score": 4.557990884027348,
        "rewrite-fast-z-score": 0.2873478855663454
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Simulation of Single Reed Instruments Oscillations Based on Modal Decomposition of Bore and Reed Dynamics .\nAbstract:\nThe reed is the key component in single-reed musical instruments, such as clarinets or saxophones. The dynamics of its motion are strongly influenced by the bore geometry and boundary conditions at both ends. In this work we present an approach to simulate the oscillations of a single reed instrument based on modal decomposition of the bore and reed dynamics. We show that it is possible to accurately reproduce the sound produced by a real clarinet using only one degree-of-freedom for each mode. This method can be used to study the influence of different parameters (such as mouthpiece diameter) on the acoustic response of the instrument without requiring expensive experimental measurements. It also allows us to investigate how changes in the design affect the performance of new prototypes. \n \n Keywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Simulation of Single Reed Instruments Oscillations Based on Modal Decomposition of Bore and Reed Dynamics . Abstract : The reed is the key ingredient in single - reed musical instruments , such as clarinets or saxophones .The dynamics of its motion are strongly dictated by the bore geometry and boundary conditions at both ends . In this study we present an approach to simulate the oscillations of a single reed instrument relying on modal decomposition of the bore and reed dynamics .We see that it is easy to correctly reproduce the music created by a real clarinet using only one degree - of - independence for each mode . This method can be used to study the impact of different variables ( such as mouthpiece diameter ) on the acoustic response of the instrument without using expensive experimental surveys .It additionally lets us to examine how differences in the model affect the performance of new prototypes . Keywords : Musical Instrument , Clarinet , Sound Generation , Modeling , Simulation , Acoustics , Vibration Analysis , Modal Analysis , Finite Element Method",
        "rewrite_text": "Title: Simulation of Oscillations in Single Reed Instruments Through Modal Decomposition of Bore and Reed Dynamics\n\nAbstract: Single-reed musical instruments, including clarinets and saxophones, rely heavily on the reed as a fundamental component influencing their sound production. The motion dynamics of the reed are intricately linked to the geometry of the bore and the boundary conditions at both ends of the instrument. In this research, we introduce a novel simulation approach that employs modal decomposition to analyze the oscillations of single reed instruments, focusing on the interplay between bore and reed dynamics. Our findings demonstrate that it is feasible to accurately replicate the sound produced by a real clarinet using a simplified model that incorporates only one degree of freedom for each mode. This innovative method not only facilitates the exploration of various factors, such as mouthpiece diameter, on the acoustic characteristics of the instrument but also serves as a cost-effective alternative to traditional experimental methods. Furthermore, our approach allows for the assessment of how variations in the model can influence the performance of new instrument prototypes. By leveraging modal analysis and finite element methods, we provide a comprehensive framework for understanding sound generation in single reed instruments, paving the way for advancements in musical acoustics and instrument design. This study contributes to the field by offering insights into the complex dynamics of reed instruments and highlights the potential for further research in acoustic modeling and simulation. \n\nKeywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method.",
        "ori-fast-z-score": -1.9694638556693236,
        "water-fast-z-score": 3.7872527750454617,
        "rewrite-fast-z-score": 1.5689290811054724
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The variable radio-to-X-ray spectrum of the magnetar XTE J1810-197 .\nAbstract:\nWe report on simultaneous observations in the X-ray and radio bands made with Chandra, RXTE/PCA, Swift/XRT, and ATCA during an outburst of the transient magnetar XTE J 18 10-197 . The source was detected at all wavelengths except for optical. We find that its broadband spectral energy distribution is consistent with a blackbody plus power-law model modified by interstellar absorption. In addition to this component we detect a soft excess below 1 keV which can be described as either emission lines or a second thermal component. This soft excess has been observed previously in other magnetars but not always simultaneously across different wavebands. Our results show that the hard X-ray flux increased rapidly after the onset of the outburst while the radio flux remained constant until it began decaying about two weeks later. After correcting for interstellar absorption we find no evidence for significant changes in the temperature of the emitting region between the start and end of our campaign.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The variable radio - to - X - ray spectrum of the magnetar XTE J1810 - 197 . Abstract : We report on concurrent observations in the X - ray and radio bands done with Chandra , RXTE / PCA , Swift / XRT , and ATCA during an outburst of the transient magnetar XTE J 18 10 - 197 .The source was seen at all wavelengths except for optical . We see that its broadband spectral power distribution is compatible with a blackbody plus energy - law theory improved by interstellar absorption .In addition to this product we perceive a soft excess below 1 keV which can be described as either emission lines or a second thermal component . This warm increase has been observed previously in other magnetars but not always concurrently across different wavebands .Our results show that the hard X - ray flow improved rapidly after the outbreak of the outburst while the television flux remained constant until it began decaying about two weeks afterward . After correcting for interstellar absorption we find no evidence for significant improvements in the temperature of the emitting area between the start and end of our campaign .",
        "rewrite_text": "We present findings from simultaneous observations of the transient magnetar XTE J1810-197, conducted using Chandra, RXTE/PCA, Swift/XRT, and ATCA during a notable outburst. Our observations encompassed a wide range of wavelengths, with the exception of optical frequencies. The analysis of the broadband spectral power distribution indicates that it aligns well with a model comprising a blackbody spectrum augmented by an energy-law distribution, while also accounting for interstellar absorption effects. Notably, we detected a soft excess in the spectrum below 1 keV, which can be interpreted as either emission lines or the presence of a secondary thermal component. This warm excess has been documented in other magnetars, although not always observed concurrently across multiple wavelengths. Our data reveal that the hard X-ray emission exhibited a rapid increase following the onset of the outburst, whereas the radio flux remained stable until it began to decline approximately two weeks later. After adjusting for interstellar absorption, we found no significant changes in the temperature of the emitting region from the beginning to the conclusion of our observational campaign. These results contribute to the understanding of the variable radio-to-X-ray spectrum of XTE J1810-197 and provide insights into the behavior of magnetars during outburst events.",
        "ori-fast-z-score": 1.2701705922171767,
        "water-fast-z-score": 5.9648090806346055,
        "rewrite-fast-z-score": 0.6324555320336759
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  National Scientific Facilities and Their Science Impact on Non-Biomedical Research .\nAbstract:\nThe National Institutes of Health (NIH) is the largest funder of biomedical research in the United States, but it also supports non-biomedical research through its extramural program.  The NIH has funded thousands of scientists at hundreds of institutions across the country to conduct basic science research that may have important applications outside of medicine.   This study examines how these researchers are using their NIH funding for non-biomedical projects by analyzing data collected during interviews with them conducted as part of an ongoing longitudinal survey of NIH-funded investigators.  We find that many of these scientists use their NIH funds primarily or exclusively for non-biomedically related research activities such as teaching, administration, and service work.  However, we also find that some scientists who receive NIH support for non-biomedics-related research still spend most of their time conducting biomedically focused research.  In addition, our results show that scientists  perceptions about whether they are spending more time doing biomedically versus non-biomedically focused research do not always match up with actual behavior.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : National Scientific Facilities and Their Science Impact on Non - Biomedical Research . Abstract : The National Institutes of Health ( NIH ) is the greatest funder of biomedical research in the United States , but it also supports non - biomedical research through its extramural program .The NIH has funded thousands of scientists at hundreds of universities across the nation to conduct basic science research that might have important use outside of medicine . This study examines how these investigators are using their NIH funding for non - biomedical projects by analyzing data received during meetings with them conducted as part of an continuing longitudinal survey of NIH - financed researchers .We see that several of these scientists using their NIH finances primarily or mainly for non - biomedically relevant research actions such as teaching , administration , and service work . However , we also find that some scientists who receive NIH assistance for non - biomedics - associated research nevertheless spend most of their hours pursuing biomedically focused research .In addition , our findings show that scientists perceptions about whether they are spent more work doing biomedically versus non - biomedically focused research do not always match up with actual conduct .",
        "rewrite_text": "**Title:** National Scientific Facilities and Their Impact on Non-Biomedical Research\n\n**Abstract:** The National Institutes of Health (NIH) stands as the largest supporter of biomedical research in the United States, yet its influence extends beyond this realm through its extramural funding programs that also cater to non-biomedical research initiatives. This article investigates the utilization of NIH funding by researchers engaged in non-biomedical projects, drawing on data collected from ongoing longitudinal surveys and meetings with NIH-funded scientists. Our analysis reveals that a significant number of these researchers allocate their NIH grants primarily to non-biomedical activities, including teaching, administrative duties, and community service. Conversely, we also observe that some scientists, despite receiving NIH funding for non-biomedical research, predominantly dedicate their time to biomedically oriented studies. Furthermore, our findings indicate a discrepancy between scientists' self-reported perceptions of their research focus and their actual research activities. Many researchers believe they are engaging more in non-biomedical work, while the data suggests that a substantial portion of their efforts remains concentrated on biomedical inquiries. This study highlights the complex landscape of NIH funding and its implications for the broader scientific community, emphasizing the need for a nuanced understanding of how federal funding shapes research priorities across various disciplines. By shedding light on these dynamics, we aim to inform policy discussions regarding the allocation of NIH resources and the potential for fostering interdisciplinary research that transcends traditional biomedical boundaries.",
        "ori-fast-z-score": 1.7056057308448833,
        "water-fast-z-score": 7.101985796042612,
        "rewrite-fast-z-score": -0.4703604341917986
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Collision Between The Milky Way And Andromeda .\nAbstract:\nThe collision between the Milky Way and its nearest neighbor, M31 (Andromeda), is predicted to occur in about 4 billion years.  This will be one of the most spectacular events ever witnessed by humans.   In this talk I will describe how we can use observations made with telescopes on Earth as well as space-based observatories such as Hubble Space Telescope to study these collisions and learn more about dark matter, galaxies, stars, black holes, and other cosmic phenomena that are part of our universe. I will also discuss some of my research projects related to studying galaxy mergers using data obtained at the W.M. Keck Observatory located on Mauna Kea, Hawaii. Finally, I ll share what it was like for me to work there during my summer internship last year. Keywords: Dark Matter, Galaxy merger, Black Hole, Cosmic Evolution, Cosmology, Astrophysics",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Collision Between The Milky Way And Andromeda . Abstract : The merger between the Milky Way and its closest neighbor , M31 ( Andromeda ) , is predicted to effect in about 4 billion years .This will be one of the most magnificent phenomena ever experienced by humans . In this talk I will explain how we can using observations made with telescopes on Earth as well as space - based observatories such as Hubble Space Telescope to study these collisions and learn more about black material , galaxies , stars , white holes , and other cosmic phenomena that are part of our universe .I will also discuss some of my research projects related to researching galaxy mergers using data acquired at the W . M . Keck Observatory situated on Mauna Kea , Hawaii .Finally , I ll share what it was like for me to work there during my summer assignment last year . Keywords : Dark Matter , Galaxy merger , Black Hole , Cosmic Evolution , Cosmology , Astrophysics",
        "rewrite_text": "Title: The Collision Between The Milky Way And Andromeda\n\nAbstract: The impending merger of the Milky Way galaxy with its nearest neighbor, the Andromeda galaxy (M31), is anticipated to occur in approximately 4 billion years. This event is expected to be one of the most extraordinary occurrences in the history of humanity. In this presentation, I will elucidate how we can utilize observations from both terrestrial telescopes and space-based observatories, such as the Hubble Space Telescope, to investigate these galactic collisions. Through these observations, we aim to deepen our understanding of various cosmic phenomena, including dark matter, galaxy formation, stellar evolution, black holes, and white holes. Additionally, I will highlight several of my research initiatives focused on galaxy mergers, utilizing data collected at the W. M. Keck Observatory located on Mauna Kea, Hawaii. This facility provides unparalleled access to high-resolution astronomical data, which is crucial for studying the dynamics and interactions of merging galaxies. Furthermore, I will share my personal experiences and insights gained during my summer research assignment at the observatory last year, detailing the challenges and rewards of conducting astrophysical research in such a prestigious environment. This talk aims to provide a comprehensive overview of the significance of the Milky Way-Andromeda collision and its implications for our understanding of cosmic evolution and the fundamental processes that govern the universe. \n\nKeywords: Dark Matter, Galaxy Merger, Black Hole, Cosmic Evolution, Cosmology, Astrophysics",
        "ori-fast-z-score": 0.39735970711951313,
        "water-fast-z-score": 4.464418717230567,
        "rewrite-fast-z-score": 0.10259783520851541
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Incoherent non-Fermi liquid scattering in a Kondo lattice .\nAbstract:\nWe study the incoherent transport properties of a strongly correlated electron system, namely the periodic Anderson model (PAM) with strong hybridization between conduction and localized electrons. We show that this PAM can be mapped onto an effective spinless fermion model which is equivalent to a disordered Fermi gas at low temperatures. The resulting density of states exhibits a pseudogap structure near the chemical potential. In addition we find that the resistivity shows a linear temperature dependence below some characteristic temperature T*. This behavior is consistent with recent experiments on heavy-fermion compounds such as Yb$_{1}$-xYb$x$Cu$_2$Si$2$O$_{7-x}$. Finally, we discuss how our results are related to previous theoretical work based on the dynamical mean-field theory. PACS numbers: 71.27.+a, 72.25.+f, 74.78.+h",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Incoherent non - Fermi liquid scattering in a Kondo structure . Abstract : We explore the incoherent transport properties of a strongly interacting particle system , namely the periodic Anderson model ( PAM ) with powerful hybridization between conduction and localized electrons .We see that this PAM can be mapped onto an efficient spinless fermion theory which is analogous to a disordered Fermi gas at low temperatures . The resulting concentration of states shows a pseudogap structure near the chemical potential .In addition we find that the resistivity displays a linear temperature dependence below some characteristic temperature T * . This phenomenon is consistent with recent experiments on heavy - fermion compounds such as Yb $ _ { 1 } $ - xYb $ x $ Cu $ _ 2 $ Si $ 2 $ O $ _ { 7 - x } $ .Finally , we talk how our findings are related to previous conceptual research based on the dynamical mean - field model . PACS numbers : 71 . 27 . + a , 72 . 25 . + f , 74 . 78 . + h",
        "rewrite_text": "In this article, we investigate the incoherent transport characteristics of a strongly interacting particle system, specifically focusing on the periodic Anderson model (PAM) characterized by significant hybridization between conduction electrons and localized electron states. Our analysis reveals that the PAM can be effectively transformed into a spinless fermion theory, which bears resemblance to a disordered Fermi gas at low temperatures. This mapping allows us to derive insights into the system's density of states, which exhibits a pseudogap structure in proximity to the chemical potential. Furthermore, we observe that the resistivity of the system demonstrates a linear temperature dependence below a critical temperature, denoted as T*. This behavior aligns with recent experimental findings in heavy-fermion materials, such as Yb$_{1-x}$Yb$_x$Cu$_2$Si$_2$O$_{7-x}$. Our results contribute to the understanding of incoherent non-Fermi liquid behavior in strongly correlated electron systems and provide a framework for connecting our findings to existing theoretical models, particularly those based on the dynamical mean-field theory. The implications of our study extend to the broader context of quantum critical phenomena and the transport properties of materials exhibiting non-Fermi liquid behavior. We conclude by discussing the relevance of our results to ongoing research in the field and the potential for future investigations into the intricate interplay between localization, hybridization, and transport in strongly correlated electron systems. The findings presented here are supported by PACS numbers: 71.27.+a, 72.25.+f, 74.78.+h, which categorize the research within the realms of strongly correlated electron systems, transport phenomena, and superconductivity.",
        "ori-fast-z-score": -1.2309149097933272,
        "water-fast-z-score": 3.6380343755449944,
        "rewrite-fast-z-score": 0.09016696346674323
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  High-resolution FUSE and HST ultraviolet spectroscopy of the white dwarf central star of Sh 2-216 .\nAbstract:\nWe present new high resolution (R = λ/Δλ ~ 20,000) far-ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE), as well as archival Hubble Space Telescope (HST) data for the hot white dwarf central star in the planetary nebula Sh2-216. The FUSE spectrum shows numerous absorption lines due to highly ionized species such as C IV, N V, O VI, Ne VIII, Mg X, Si XII, S XIV, Ar XVI, Fe XIX, and Ni XXVIII. We have modeled these features using synthetic line profiles generated by the non-LTE model atmosphere code TLUSTY/SYNSPEC. Our best-fit models indicate that this star has an effective temperature T eff = 120,000 K, surface gravity log g = 8.0, mass M = 0.6M☉ , radius R = 0.01R☉ , and is surrounded by a shell of material with density n(He II)/n(He I) = 1.5 x 10-3 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : High - resolution FUSE and HST ultraviolet spectroscopy of the white dwarf central star of Sh 2 - 216 . Abstract : We report new high resolution ( R = λ / Δλ ~ 20 , 000 ) far - ultraviolet spectra obtained with the Far Ultraviolet Spectroscopic Explorer ( FUSE ) , as well as archival Hubble Space Telescope ( HST ) statistics for the hot white dwarf central star in the planetary nebula Sh2 - 216 .The FUSE spectrum displays several absorption patterns due to strongly ionized species such as C IV , N V , O VI , Ne VIII , Mg X , Si XII , S XIV , Ar XVI , Fe XIX , and Ni XXVIII . We have modeled these characteristics utilizing artificial line profiles generated by the non - LTE model atmosphere code TLUSTY / SYNSPEC .Our best - fitting models suggest that this star has an effective heat T eff = 120 , 000 K , surface gravity log f = 8 . 0 , mass M = 0 . 6M☉ , diameter R = 0 . 01R☉ , and is enclosed by a shell of material with concentration k ( He II ) / n ( He I ) = 1 . 5 x 10 - 3 .",
        "rewrite_text": "We present new high-resolution far-ultraviolet spectra (R = λ / Δλ ~ 20,000) obtained from the Far Ultraviolet Spectroscopic Explorer (FUSE), alongside archival data from the Hubble Space Telescope (HST), focusing on the hot white dwarf central star of the planetary nebula Sh2-216. The FUSE spectra reveal a variety of absorption features attributed to highly ionized elements, including C IV, N V, O VI, Ne VIII, Mg X, Si XII, S XIV, Ar XVI, Fe XIX, and Ni XXVIII. To interpret these spectral characteristics, we employed artificial line profiles generated by the non-local thermodynamic equilibrium (non-LTE) model atmosphere code TLUSTY/SYNSPEC. Our modeling results indicate that the central star possesses an effective temperature (T_eff) of approximately 120,000 K, a surface gravity (log g) of 8.0, a mass of 0.6 solar masses (M☉), and a radius of 0.01 solar radii (R☉). Additionally, we found that the star is surrounded by a shell of material characterized by a helium ionization concentration ratio of k(He II) / n(He I) = 1.5 x 10^-3. These findings contribute to our understanding of the physical properties and evolutionary state of the white dwarf in Sh2-216, providing insights into the processes occurring in the late stages of stellar evolution and the dynamics of planetary nebulae. The high-resolution data from FUSE and HST enhance our ability to analyze the composition and behavior of the stellar atmosphere, paving the way for further studies on similar objects in the universe.",
        "ori-fast-z-score": -1.7232808737106582,
        "water-fast-z-score": 2.9541957835039856,
        "rewrite-fast-z-score": -0.8955334711889903
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Deep radio images of the HEGRA and Whipple TeV sources in the Cygnus OB2 region .\nAbstract:\nWe present deep radio observations at 1.4 GHz with the VLA towards two TeV gamma-ray emitting regions, one associated to the open cluster Cyg OB2 #8 (HESS J1640-465) and another located near the massive star WR 25 (HESS J1641-463). The new data reveal extended emission around both TeV sources which is not detected by previous surveys. We discuss possible scenarios for this emission based on our results as well as those obtained recently by other authors. In particular we propose that the observed structures are due to synchrotron radiation produced by relativistic electrons accelerated in shocks driven by stellar winds interacting within these clusters. This scenario would also explain why no X-ray counterparts have been found so far despite deep searches carried out with Chandra and XMM-Newton telescopes. Finally, we estimate the magnetic field strength required to produce such emission using standard models for particle acceleration in colliding wind binaries. \nIntroduction\n\nThe Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° (  Fig.   1a ). It has been suggested that many of them could be members of binary systems or even multiple systems (e.g., Knödlseder 2000; Wright et al. 2010) . These objects can drive powerful winds into their surroundings creating strong shocks where particles may be accelerated up to very high energies. If some of these particles escape from the shock fronts they will interact with photons coming from the surrounding interstellar medium producing high-energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range. \n \n Several studies suggest that several of the known TeV sources in the sky might be related to young open clusters like Cyg OB2 (see e.g., Aharonian et al. 2005a ,b, 2007a . However, only few of these associations have been confirmed through multi-wavelength campaigns involving optical/infrared imaging, spectroscopy and/or radio continuum observations (see e.g. , Reimer & Böttcher 2006 , Castro-Tirado et al",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Deep radio photographs of the HEGRA and Whipple TeV sources in the Cygnus OB2 region . Abstract : We report deep radio observations at 1 . 4 GHz with the VLA towards two TeV gamma - ray emitting regions , one related to the open cluster Cyg OB2 # 8 ( HESS J1640 - 465 ) and another situated near the powerful star WR 25 ( HESS J1641 - 463 ) .The revised data reveal extended pollution around both TeV sources which is not observed by earlier surveys . We discuss possible strategies for this emission based on our findings as well as those acquired previously by other researchers .In particular we explain that the seen structures are related to synchrotron emission created by relativistic electrons accelerated in shocks driven by stellar winds interacting within these clusters . This scenario would also explain why no X - ray relatives have been detected so far despite depth surveys done out with Chandra and XMM - Newton telescopes .Finally , we estimate the magnetic force size needed to produce such emission utilizing typical models for particle acceleration in colliding weather binaries . Introduction The Cygnus OB2 association contains more than 100 OB stars distributed over an area of about 50 square degrees centered at l = 80°and b = 1° ( Fig .1a ) . It has been proposed that several of them could be members of binary systems or even multiple systems ( e . g . , Knödlseder 2000 ; Wright et al .2010 ) . These particles can bring powerful storms into their environment forming violent shocks where objects may be advanced up to very high energies .If some of these ions survive from the shock fronts they will interact with photons coming from the nearby interstellar medium generating high - energy electromagnetic radiation detectable across most of the electromagnetic spectrum including the TeV range . Several studies propose that several of the known TeV sources in the heavens would be connected to early open complexes like Cyg OB2 ( see e . g . , Aharonian et al .2005a , b , 2007a . However , only few of these associations have been confirmed through multi - wavelength campaigns involving optical / infrared imaging , spectroscopy and / or radio continuum imaging ( saw e . g ., Reimer & Böttcher 2006 , Castro-Tirado et al",
        "rewrite_text": "We present a comprehensive analysis of deep radio observations conducted at 1.4 GHz using the Very Large Array (VLA) targeting two regions in the Cygnus OB2 association known for their TeV gamma-ray emissions. The first region is associated with the open cluster Cyg OB2 #8 (designated HESS J1640-465), while the second is located near the prominent star WR 25 (HESS J1641-463). Our revised observations reveal extensive radio emission surrounding both TeV sources, a phenomenon that was not detected in previous surveys. We explore potential mechanisms for this emission, drawing on our findings as well as existing literature. Notably, we propose that the observed structures are indicative of synchrotron radiation produced by relativistic electrons that have been accelerated in shock waves generated by the interaction of stellar winds within these clusters. This explanation also accounts for the absence of X-ray counterparts, despite extensive surveys conducted with the Chandra and XMM-Newton telescopes. Furthermore, we provide estimates of the magnetic field strengths required to facilitate such emissions, employing established models of particle acceleration in colliding stellar winds. \n\nThe Cygnus OB2 association is home to over 100 OB stars spread across approximately 50 square degrees, centered at galactic coordinates l = 80° and b = 1°. It has been suggested that many of these stars may belong to binary or even multiple systems. The energetic particles produced in these environments can generate powerful shocks, propelling them to high energies. When these particles interact with photons from the surrounding interstellar medium, they can produce high-energy electromagnetic radiation detectable across a broad spectrum, including the TeV range. Previous studies have indicated a potential connection between several known TeV sources and early stellar complexes like Cygnus OB2. However, only a limited number of these associations have been substantiated through multi-wavelength observational campaigns, including optical, infrared, and radio continuum imaging.",
        "ori-fast-z-score": -0.9313806308475994,
        "water-fast-z-score": 6.6172410253729455,
        "rewrite-fast-z-score": 0.1655211777204736
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Charged Axially Symmetric Solution and Energy in Teleparallel Theory Equivalent to General Relativity .\nAbstract:\nIn this work, we study the charged axially symmetric solution and energy in teleparallel theory equivalent to general relativity (GR). We find that the field equations are exactly same as those obtained by GR with an additional term which is proportional to the torsion scalar T . The solutions for the metric functions are found numerically using the shooting method. It turns out that these solutions have no singularities at all. In addition, it has been shown that the total energy density is positive definite everywhere inside the star. Finally, we show that our results agree well with those obtained by GR. This shows that the teleparallel gravity can be considered as alternative gravitational theories to GR. Keywords: Charged axially symmetric solution; energy; teleparallel gravity; Einstein-Maxwell system. 1 Introduction Gravity plays important role in understanding many physical phenomena such as black holes  1  , cosmology  2  , quantum mechanics  3  etc.. However, there still remain some unsolved problems like dark matter  4  , dark energy  5  , inflation  6  etc., which cannot be explained within the framework of standard model of particle physics  7, 8  .\nThe most successful classical description of gravitation is provided by Einstein s general relativity (GR)  9  where the curvature tensor R µνρσ describes the geometry of space-time  10  . On the other hand, teleparallel gravity  11  -  13  is another approach to describe gravitation on the basis of tetrad fields e A µ instead of metric g µν  14  . Here, the basic variables are connection coefficients Γ λ µν defined through vierbein fields e \nwhere η AB = diag(−1, +1, +1, +1), and h ABCD denotes the contortion tensor  15  . The corresponding Lagrangian density reads  16  :",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Charged Axially Symmetric Solution and Energy in Teleparallel Theory Equivalent to General Relativity . Abstract : In this study , we study the charged axially symmetric solution and energy in teleparallel theory equivalent to general relativity ( GR ) .We get that the field equations are exactly same as those given by GR with an additional term which is proportional to the torsion scalar T . The solutions for the metric functions are found numerically using the shot technique .It turns out that these solutions have no singularities at all . In addition , it has been shown that the total energy density is positive definite everywhere inside the star .Finally , we find that our findings agree well with those achieved by GR . This shows that the teleparallel gravitational can be regarded as alternative gravity explanations to GR .Keywords : Charged axially symmetric solution ; energy ; teleparallel gravitational ; Einstein - Maxwell system . 1 Introduction Gravity takes key importance in understanding several physical phenomena such as black holes 1 , cosmology 2 , quantum mechanics 3 etc . .However , there still emerge some unsolved issues like dark matter 4 , darkness energy 5 , inflation 6 etc . , which cannot be described within the framework of standard description of particle science 7 , 8 . The most popular classical description of gravitation is provided by Einstein s general relativity ( GR ) 9 where the curvature tensor R µνρσ describes the topology of space - time 10 .On the other hand , teleparallel gravitational 11 - 13 is another technique to define gravitation on the basis of tetrad fields e A µ instead of metric c µν 14 . Here , the fundamental variables are connection coefficients Γ λ µν characterized through vierbein fields e where η AB = diag ( −1 , + 1 , + 1 , + 1 ) , and h ABCD denotes the contortion tensor 15 .The corresponding Lagrangian density reads 16 :",
        "rewrite_text": "**Title:** Charged Axially Symmetric Solution and Energy in Teleparallel Theory Equivalent to General Relativity\n\n**Abstract:** This article investigates the charged axially symmetric solutions and the associated energy within the framework of teleparallel theory, which is equivalent to general relativity (GR). We demonstrate that the field equations derived in this context are identical to those of GR, with the inclusion of an additional term that is proportional to the torsion scalar \\( T \\). To obtain the solutions for the metric functions, we employ a numerical approach known as the shooting method. Remarkably, our results indicate that these solutions are free from singularities, suggesting a well-defined structure throughout the spacetime. Furthermore, we establish that the total energy density remains positive definite throughout the interior of the star, reinforcing the physical viability of our model. Our findings align closely with those predicted by GR, indicating that teleparallel gravity can serve as a viable alternative framework for understanding gravitational phenomena. This study contributes to the ongoing discourse in gravitational theory, particularly in light of unresolved issues such as dark matter, dark energy, and cosmic inflation, which challenge the conventional paradigms of particle physics. While GR, characterized by the curvature tensor \\( R_{\\mu\\nu\\rho\\sigma} \\), remains the predominant classical theory of gravitation, teleparallel gravity offers a distinct perspective by utilizing tetrad fields \\( e^A_\\mu \\) instead of the metric tensor \\( g_{\\mu\\nu} \\). In this framework, the fundamental variables are the connection coefficients \\( \\Gamma^\\lambda_{\\mu\\nu} \\), which are defined through the vierbein fields, where \\( \\eta_{AB} = \\text{diag}(-1, +1, +1, +1) \\), and the contortion tensor \\( h_{ABCD} \\) plays a crucial role. The corresponding Lagrangian density is derived accordingly, paving the way for further exploration of gravitational theories beyond the standard model. \n\n**Keywords:** Charged axially symmetric solution; energy; teleparallel gravity; Einstein-Maxwell system.",
        "ori-fast-z-score": -0.08944271909999159,
        "water-fast-z-score": 5.480077554195743,
        "rewrite-fast-z-score": -1.1445861782233109
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Super-Poissonian Shot Noise as a Measure of Dephasing in Closed Quantum Dots .\nAbstract:\nWe report on the observation of super-Poissonian shot noise in closed quantum dots (QDs). We show that this effect is due to dephasing and can be used for its characterization. The QD emission linewidth was measured by scanning Fabry-Perot interferometry, while the photon statistics were studied using Hanbury Brown-Twiss experiments with two avalanche photodiodes operating at 1 GHz bandwidth. In order to study the influence of temperature we performed these measurements between 4 K and 300 K. At low temperatures, below 50 K, the QD emission linewidth decreases exponentially with decreasing temperature following an activation energy of about 0.3 meV. Above 100 K it follows a power law dependence with T-1/2. Super-Poissonian shot-noise appears above 60 K and increases rapidly up to room temperature where it reaches values more than twice those expected for Poissonian light.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Super - Poissonian Shot Noise as a Measure of Dephasing in Closed Quantum Dots . Abstract : We report on the observation of super - Poissonian shooting noise in closed quantum dots ( QDs ) .We see that this effect is due to dephasing and can be used for its characterization . The QD radiation linewidth was measured by scanning Fabry - Perot interferometry , while the photon statistics were studied utilizing Hanbury Brown - Twiss experiments with two avalanche photodiodes running at 1 GHz frequency .In order to study the impact of temperature we performed these measurements between 4 K and 300 K . At low temperatures , below 50 K , the QD radiation linewidth drops exponentially with decreasing temperature following an binding energy of about 0 . 3 meV . Above 100 K it follows a power law dependence with T - 1 / 2 .Super - Poissonian shooting - noise appears above 60 K and expands quickly up to room temperature where it meets values more than times those expected for Poissonian light .",
        "rewrite_text": "In this study, we present our findings on the observation of super-Poissonian shot noise in closed quantum dots (QDs), highlighting its potential as a measure of dephasing. The phenomenon of super-Poissonian noise is indicative of non-classical light behavior, which we attribute to the dephasing processes occurring within the quantum dots. To investigate this, we employed scanning Fabry-Pérot interferometry to measure the radiation linewidth of the QDs, while photon statistics were analyzed through Hanbury Brown-Twiss experiments utilizing two avalanche photodiodes operating at a frequency of 1 GHz. \n\nOur experiments were conducted across a temperature range from 4 K to 300 K to assess the influence of thermal variations on the observed phenomena. Notably, at low temperatures (below 50 K), we observed an exponential decrease in the QD radiation linewidth as the temperature decreased, which aligns with a binding energy of approximately 0.3 meV. In contrast, at temperatures exceeding 100 K, the linewidth exhibited a power-law dependence characterized by T^(-1/2). \n\nThe emergence of super-Poissonian shot noise was detected at temperatures above 60 K, with a rapid increase in intensity as the temperature approached room temperature. At this point, the measured noise levels exceeded those predicted for Poissonian light by several times, indicating a significant deviation from classical light statistics. Our findings suggest that super-Poissonian shot noise can serve as a valuable tool for characterizing dephasing in quantum dots, providing insights into the underlying quantum processes that govern their behavior. This research contributes to the broader understanding of quantum dot dynamics and their potential applications in quantum information technologies.",
        "ori-fast-z-score": 0.2581988897471611,
        "water-fast-z-score": 4.737364557517151,
        "rewrite-fast-z-score": -1.2780193008453875
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  GRB 061121: Broadband spectral evolution through the prompt and afterglow phases of a bright burst .\nAbstract:\nWe present broadband (radio to X-ray) observations of GRB 061121, one of the most energetic gamma-ray bursts ever detected by Swift/BAT with an isotropic equivalent energy release of 1.8 x 10^54 erg in the 15-350 keV band. The temporal behavior of this event was complex; it consisted of multiple pulses that were superimposed on top of each other during both the prompt emission phase as well as the early part of its afterglow. We find evidence for two distinct components in the optical light curve -one which decays rapidly at first but then flattens out later-on timescales ranging between 0.1-10 days post-burst. This flattening could be due either to continued activity of the central engine or to refreshed shocks. In addition we detect significant radio emission upto 100 days post-burst. Our results are consistent with those obtained using data from the VLA and ATCA telescopes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : GRB 061121 : Broadband spectral evolution through the prompt and afterglow stages of a bright burst . Abstract : We report broadband ( radio to X - ray ) observations of GRB 061121 , one of the most intense gamma - ray bursts ever observed by Swift / BAT with an isotropic equivalent energy release of 1 . 8 x 10 ^ 54 erg in the 15 - 350 keV band .The temporal response of this event was difficult ; it consisted of multiple pulses that were superimposed on top of each other during both the prompt emission stage as well as the early portion of its afterglow . We see evidence for two different components in the optical light curve - one which decays slowly at first but then flattens out eventually - on timescales ranging between 0 . 1 - 10 weeks post - burst .This flattening may be due either to continued action of the main motor or to refreshed shocks . In addition we find considerable radio emission upto 100 months post - burst .Our results are compatible with those acquired using data from the VLA and ATCA telescopes .",
        "rewrite_text": "We present a comprehensive analysis of the broadband spectral evolution of GRB 061121, a remarkably bright gamma-ray burst detected by the Swift/BAT, which released an isotropic equivalent energy of 1.8 x 10^54 erg in the 15-350 keV range. Our observations span from radio to X-ray wavelengths, allowing us to capture the intricate temporal dynamics of this event. The prompt emission phase exhibited a complex structure characterized by multiple overlapping pulses, complicating the interpretation of the burst's behavior. \n\nIn the optical domain, we identified two distinct components within the light curve. The first component displays a gradual decay that eventually transitions into a plateau phase, observed over a timescale of 0.1 to 10 weeks following the burst. This flattening in the light curve may suggest ongoing activity from the central engine or the presence of refreshed shocks contributing to the emission. Furthermore, we detected significant radio emissions persisting for up to 100 months after the initial burst, indicating a prolonged afterglow phase. \n\nOur findings align with data obtained from the Very Large Array (VLA) and the Australia Telescope Compact Array (ATCA), reinforcing the robustness of our results. The extensive dataset and multi-wavelength approach provide valuable insights into the mechanisms driving the emission processes during both the prompt and afterglow phases of GRB 061121. This study enhances our understanding of gamma-ray bursts and their afterglow characteristics, contributing to the broader field of high-energy astrophysics.",
        "ori-fast-z-score": -1.4142135623730951,
        "water-fast-z-score": 4.04145188432738,
        "rewrite-fast-z-score": 2.030146626995893
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Vibrational instability, two-level systems and Boson peak in glasses .\nAbstract:\nWe study the vibrational density of states (VDOS) of glassy materials using molecular dynamics simulations with anharmonic interactions between particles. We show that the VDOS can be decomposed into three main contributions: one at low frequencies corresponding to acoustic phonons; another contribution centered around the Debye frequency which is associated with optical phonons; and finally a third contribution located at high frequencies whose origin lies on the presence of unstable modes. The latter are responsible for the appearance of the so-called boson peak in the VDOS. In addition we find that these unstable modes have a strong tendency to form clusters or groups of correlated particles. Finally, by analyzing the spatial distribution of the unstable modes it becomes evident that they tend to localize near regions where there exist structural defects such as icosahedral-like motifs. This localization effect leads us to propose a simple model based on the existence of two different types of sites within the materials: stable ones characterized by their ability to support vibrations over large energy ranges, while unstable sites only allow small-amplitude oscillations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Vibrational instability , two - level systems and Boson peak in glasses . Abstract : We research the vibrational density of states ( VDOS ) of glassy materials utilizing molecular mechanics simulations with anharmonic interactions between particles .We see that the VDOS can be decomposed into three primary contributions : one at low frequencies corresponding to acoustic phonons ; another contribution located around the Debye frequency which is associated with optical phonons ; and eventually a third contribution located at high frequencies whose source lies on the presence of unstable modes . The latter are responsible for the appearance of the so - called boson peak in the VDOS .In addition we find that these unstable modes have a high ability to form clusters or bands of coupled atoms . Finally , by analyzing the spatial distribution of the unstable modes it becomes obvious that they tend to localize near sites where there exist functional errors such as icosahedral - like motifs .This localization effect makes us to propose a simple model based on the existence of two different kinds of places within the materials : strong ones defined by their potential to support vibrations over large energy intervals , while volatile places only facilitate tiny - frequency oscillations .",
        "rewrite_text": "In this study, we investigate the vibrational density of states (VDOS) of glassy materials through molecular mechanics simulations that incorporate anharmonic interactions among particles. Our findings reveal that the VDOS can be categorized into three distinct contributions. The first contribution arises at low frequencies, corresponding to acoustic phonons, which are fundamental vibrational modes in solids. The second contribution is observed around the Debye frequency, where optical phonons play a significant role. The third contribution, which appears at high frequencies, is attributed to the presence of unstable modes within the glassy structure. These unstable modes are crucial for the emergence of the boson peak in the VDOS, a phenomenon commonly observed in disordered materials.\n\nMoreover, our analysis indicates that these unstable modes exhibit a pronounced tendency to form clusters or bands of coupled atoms, suggesting a complex interplay between local structural features and vibrational behavior. By examining the spatial distribution of these unstable modes, we find a notable localization effect, particularly near regions characterized by structural imperfections, such as icosahedral-like motifs. This observation leads us to propose a simplified model that distinguishes between two types of regions within the glassy material: \"strong\" regions, which are capable of sustaining vibrations across a broad range of energy levels, and \"volatile\" regions, which primarily support low-frequency oscillations. This duality in the vibrational landscape of glasses provides valuable insights into the underlying mechanisms governing their mechanical and thermal properties, paving the way for a deeper understanding of the vibrational dynamics in disordered systems.",
        "ori-fast-z-score": -0.20203050891044214,
        "water-fast-z-score": 5.728715546977509,
        "rewrite-fast-z-score": 2.37346441585572
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Discovery of an Isolated Compact Object at High Galactic Latitude .\nAbstract:\nWe report the discovery of a new isolated neutron star (INS) candidate, PSR J1852+0040, in the southern hemisphere using data collected by the Parkes radio telescope and the Australia Telescope Compact Array (ATCA). The pulsar was discovered during a search for millisecond pulsars with high proper motions. It has a spin period P = 1.4 ms and is located at a distance D = 3 kpc. Its dispersion measure DM = 0.6 pc cm-3 implies that it lies behind most of the galactic disk but not far enough to be associated with any known supernova remnant or open cluster. We have also detected its X-ray counterpart in archival Chandra observations. This source appears point-like and shows no evidence of extended emission. Based on these properties we conclude that this object is likely to be a young INS. If confirmed as such, our results will provide important constraints on models of pulsar formation and evolution. \n \n Keywords: Neutron stars",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Discovery of an Isolated Compact Object at High Galactic Latitude . Abstract : We report the discovery of a new small neutron star ( INS ) candidate , PSR J1852 + 0040 , in the southern hemisphere using data taken by the Parkes radio telescope and the Australia Telescope Compact Array ( ATCA ) .The pulsar was discovered during a search for millisecond pulsars with high proper motions . It has a spinning period P = 1 . 4 ms and is situated at a distance D = 3 kpc .Its dispersion measure DM = 0 . 6 pc mm - 3 implies that it lies behind most of the galactic disk but not far enough to be identified with any observed supernova remnant or open cluster . We have already detected its X - ray counterpart in archival Chandra measurements .This source looks point - like and shows no evidence of extended emission . Based on these characteristics we estimate that this object is probably to be a young INS .If confirmed as such , our findings will provide important restrictions on estimates of pulsar structure and evolution . Keywords : Neutron stars",
        "rewrite_text": "We present the discovery of a new candidate for an isolated neutron star (INS), designated PSR J1852 + 0040, located in the southern hemisphere. This discovery was made utilizing observational data from the Parkes radio telescope and the Australia Telescope Compact Array (ATCA) during a targeted search for millisecond pulsars exhibiting high proper motions. The pulsar has a remarkably short spin period of P = 1.4 milliseconds and is estimated to be at a distance of D = 3 kiloparsecs. The measured dispersion measure (DM) of 0.6 pc cm^-3 suggests that PSR J1852 + 0040 is positioned behind the majority of the galactic disk, yet it is not sufficiently distant to be associated with any known supernova remnants or open clusters. Additionally, we have identified its X-ray counterpart through archival data from the Chandra X-ray Observatory. The X-ray source appears point-like and does not exhibit any signs of extended emission, reinforcing the hypothesis that this object is likely a young INS. Should this classification be validated, our findings could significantly enhance the understanding of neutron star structure and evolutionary processes. This discovery not only contributes to the growing catalog of neutron stars but also provides critical insights into the characteristics and behaviors of these enigmatic celestial objects. The implications of our research extend to refining models of pulsar evolution and the physical conditions surrounding neutron stars. Keywords: Neutron stars.",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 4.695048270344999,
        "rewrite-fast-z-score": -0.8164965809277261
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Analysis and packaging of radiochemical solar neutrino data. 1. Bayesian approach .\nAbstract:\nWe present an analysis method for the detection of solar neutrinos using radioactive sources in combination with Ge detectors, which is based on a Bayesian statistical approach. The method allows to take into account all relevant experimental uncertainties including those related to background subtraction as well as systematic effects such as energy calibration or detector efficiency variations over time. We apply this new method to two different experiments at Gran Sasso National Laboratory (Italy): Borexino and GNO. In both cases we find that our results are compatible within their respective error bars with previous analyses but show smaller errors due to improved treatment of systematics. This work was supported by the German Science Foundation DFG under grant number BR 1628/2-1. AMS-02 collaboration has recently reported  1  the most precise measurement so far of the positron fraction up to energies of about 300 GeV. It shows a clear excess above the expected astrophysical background  2  . While there have been several attempts to explain these observations  3  , it remains unclear whether they can be attributed to dark matter annihilation  4  .\nIn order to test possible explanations of the observed excess, one needs to know how many positrons are produced per annihilation event. For example, if dark matter particles annihilate predominantly into leptons, then the total number of electrons plus positrons produced per annihilation should equal four times the number of photons produced  5  . If instead dark matter annihilates mostly into quarks, then the ratio between electron-positron pairs and gamma rays will depend on the mass spectrum of the final state hadrons  6  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Analysis and packaging of radiochemical solar neutrino data . 1 .Bayesian perspective . Abstract : We present an assessment procedure for the observation of sun neutrinos using nuclear sources in combination with Ge detectors , which is based on a Bayesian statistical method .The method enables to take into consideration all relevant experimental uncertainties especially those related to background subtraction as well as systematic effects such as energy calibration or detector efficiency varying over time . We use this new method to two different experiments at Gran Sasso National Laboratory ( Italy ) : Borexino and GNO .In both cases we find that our findings are compatible within their separate error bars with previous analyses but give smaller mistakes due to easier treatment of systematics . This project was supported by the German Science Foundation DFG under grant number BR 1628 / 2 - 1 .AMS - 02 consortium has recently noted 1 the most accurate detection so far of the positron fraction up to energies of about 300 GeV . It gives a clear excess above the expected astrophysical background 2 .While there have been numerous attempts to explain these observations 3 , it remains unsure whether they can be due to dark matter annihilation 4 . In order to test possible explanations of the seen amount , one needs to consider how many positrons are produced per annihilation episode .For instance , if bright matter atoms annihilate predominantly into leptons , then the total quantity of atoms plus positrons produced per annihilation should equivalent four times the quantity of photons generated 5 . If instead dark matter annihilates mostly into quarks , then the proportion between electron - positron couples and alpha radiation will depend on the mass spectrum of the finished state hadrons 6 .",
        "rewrite_text": "**Title: Analysis and Packaging of Radiochemical Solar Neutrino Data: A Bayesian Perspective**\n\n**Abstract:** In this study, we introduce a novel assessment procedure for detecting solar neutrinos utilizing nuclear sources in conjunction with germanium detectors, grounded in a Bayesian statistical framework. This approach allows for a comprehensive consideration of all pertinent experimental uncertainties, particularly those associated with background subtraction, as well as systematic factors such as energy calibration and the temporal variations in detector efficiency. We apply this innovative methodology to two distinct experiments conducted at the Gran Sasso National Laboratory in Italy: Borexino and GNO. Our analysis reveals that the results obtained are consistent with previous findings within their respective error margins, while also demonstrating reduced uncertainties due to a more straightforward handling of systematic effects. This research was supported by the German Science Foundation (DFG) under grant number BR 1628/2-1.\n\nAdditionally, the AMS-02 consortium has recently reported the most precise measurement of the positron fraction up to energies around 300 GeV, revealing a significant excess above the anticipated astrophysical background. Despite numerous efforts to elucidate these observations, the question of whether they can be attributed to dark matter annihilation remains unresolved. To explore potential explanations for the observed positron production, it is essential to evaluate the number of positrons generated per annihilation event. For example, if baryonic matter predominantly annihilates into leptons, the total yield of baryons and positrons per annihilation should be approximately four times that of the photons produced. Conversely, if dark matter primarily annihilates into quarks, the ratio of electron-positron pairs to alpha radiation will be contingent upon the mass spectrum of the resultant hadrons. This analysis aims to deepen our understanding of the underlying processes involved in solar neutrino detection and the implications for dark matter research.",
        "ori-fast-z-score": -0.8049844718999243,
        "water-fast-z-score": 7.661488934822832,
        "rewrite-fast-z-score": -0.09016696346674323
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Outflow and Infall in a Sample of Massive Star Forming Regions .\nAbstract:\nWe present new observations of the outflows driven by massive protostars using the Submillimeter Array (SMA) at 1.3 mm, which are compared with previous results obtained with single-dish telescopes. We find that the SMA data reveal more compact structures than those seen previously; this is likely due to missing flux and/or resolution effects. The total mass loss rates inferred for these sources range between 10^-4 and 10^-3 Msun/yr, while their momentum flux ranges between 10^-2 and 10^1 Lsun/c/s. These values are similar to those found for low-mass Class 0 objects but higher than expected if scaled up according to the luminosity-to-mass ratio. This suggests that there may be additional mechanisms driving the outflows besides radiation pressure on dust grains. \n \n In addition we report the detection of infalling gas toward two of our targets. For G35.20-1.74NW, we detect an inward motion of ~0.5 km/s over a distance of ~1000 AU. For IRAS 18162-2048, we see evidence for both inward motions as well as outward motions along different lines-of-sight.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Outflow and Infall in a Sample of Massive Star Forming Regions . Abstract : We report new images of the outflows driven by massive protostars utilizing the Submillimeter Array ( SMA ) at 1 . 3 cm , which are compared with previous findings obtained with single - dish telescopes .We see that the SMA data reveal more compact systems than those shown later ; this is probably due to missing flux and / or resolution influences . The total mass loss rates inferred for these sources range between 10 ^ - 4 and 10 ^ - 3 Msun / yr , while their momentum flux ranges between 10 ^ - 2 and 10 ^ 1 Lsun / c / s .These figures are comparable to those shown for low - mass Class 0 bodies but higher than expected if scaled up according to the luminosity - to - mass ratio . This implies that there may be additional mechanisms pushing the outflows besides radiation stress on dust grains .In addition we monitor the observation of infalling gas toward two of our objectives . For G35 . 20 - 1 . 74NW , we determine an inward movement of ~ 0 . 5 kilometres / s over a distance of ~ 1000 AU .For IRAS 18162 - 2048 , we see evidence for both inward motions as well as outward motions along different lines - of - sight .",
        "rewrite_text": "We present new observational data on the outflows generated by massive protostars, obtained using the Submillimeter Array (SMA) at a wavelength of 1.3 cm. These new images are analyzed in conjunction with earlier results from single-dish telescopes, revealing that the SMA data depict more compact outflow structures than previously observed. This discrepancy may be attributed to factors such as missing flux or differences in resolution. Our analysis indicates that the total mass loss rates for the observed sources range from 10^-4 to 10^-3 solar masses per year, while the momentum flux values span from 10^-2 to 10^1 solar luminosities per speed of light per second. Notably, these measurements are comparable to those recorded for low-mass Class 0 protostars, yet they exceed expectations when scaled according to the luminosity-to-mass ratio. This suggests the potential involvement of additional mechanisms driving the outflows, beyond the conventional radiation pressure exerted on dust grains. Furthermore, we also investigate the infall of gas toward two specific targets in our study. For the source G35.20-1.74NW, we observe an inward gas velocity of approximately 0.5 kilometers per second over a distance of about 1000 astronomical units. In the case of IRAS 18162-2048, we find evidence of both inward and outward gas motions occurring along different lines of sight. These findings contribute to our understanding of the complex dynamics involved in massive star formation, highlighting the interplay between outflow and infall processes in these regions.",
        "ori-fast-z-score": -1.193117518002609,
        "water-fast-z-score": 4.313310928137536,
        "rewrite-fast-z-score": 0.5570860145311556
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Magnetorotational collapse of very massive stars to black holes in full general relativity .\nAbstract:\nWe present the first fully general-relativistic magnetohydrodynamic (MHD) simulations of the gravitational collapse of rotating, magnetic white dwarfs and neutron stars with initial masses up to 100 solar masses. We find that for all models considered here, the central density increases by at least eight orders of magnitude during the collapse process. The final state is always a Kerr black hole surrounded by an accretion disk. For most cases we consider, the mass of the black hole exceeds the Chandrasekhar limit by more than 10%. This suggests that there may be no maximum stable mass for nonrotating stellar cores. In addition, our results show that the rotation rate of the newly formed black hole depends on its progenitor s spin parameter as well as its total angular momentum. Finally, we discuss how these findings can be used to explain some observed phenomena such as gamma-ray bursts and superluminous supernovae.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Magnetorotational decay of very huge stars to dark holes in total general relativity . Abstract : We report the first fully general - relativistic magnetohydrodynamic ( MHD ) simulations of the gravitational collapse of spinning , magnetic white dwarfs and neutron galaxies with initial masses up to 100 solar masses .We see that for all models discussed here , the main concentration increases by at least eight orders of magnitude during the failure process . The final state is usually a Kerr black hole accompanied by an accretion disk .For most instances we consider , the mass of the dark hole exceeds the Chandrasekhar limit by more than 10 % . This implies that there may be no maximum stable mass for nonrotating stellar cores .In addition , our findings show that the rotation rate of the newly assembled black hole varies on its progenitor s spin parameter as also as its total angular velocity . Finally , we talk how these results can be used to explain some observed processes such as gamma - ray flare and superluminous supernovae .",
        "rewrite_text": "We present the inaugural fully general-relativistic magnetohydrodynamic (MHD) simulations examining the gravitational collapse of rotating, magnetized white dwarfs and neutron stars with initial masses reaching up to 100 solar masses. Our simulations reveal that throughout the collapse process, the central concentration of mass increases by at least eight orders of magnitude. The end result of this gravitational collapse is predominantly a Kerr black hole, which is typically accompanied by an accretion disk. Notably, in the majority of scenarios analyzed, the mass of the resulting black hole surpasses the Chandrasekhar limit by over 10%. This observation suggests that there may not be a definitive maximum stable mass for non-rotating stellar cores. Furthermore, our results indicate that the spin rate of the newly formed black hole is influenced by the spin parameter of its progenitor, as well as its overall angular momentum. We also discuss the implications of our findings in relation to various astrophysical phenomena, including gamma-ray bursts and superluminous supernovae, providing insights into how these processes may be connected to the formation and characteristics of black holes resulting from the collapse of massive stars. This research enhances our understanding of the complex dynamics involved in the evolution of massive stars and their ultimate fate, contributing to the broader field of astrophysics and the study of black hole formation.",
        "ori-fast-z-score": -1.8225913092242512,
        "water-fast-z-score": 3.9668163788998405,
        "rewrite-fast-z-score": -1.3348476249438292
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Bimodal AGNs in Bimodal Galaxies .\nAbstract:\nWe present the results of our study on bimodality in galaxies and active galactic nuclei (AGN). We find that there is no significant difference between the fraction of AGNs hosted by red or blue galaxies, but we do see an excess of AGNs with respect to normal galaxies at intermediate colors. This suggests that AGNs are not preferentially found in either red or blue galaxies, as previously thought; instead they appear to be more common among galaxies with intermediate color. The lack of correlation between galaxy color and AGN activity may indicate that AGNs play only a minor role in quenching star formation in massive galaxies. Alternatively, it could suggest that AGNs have different effects depending on their luminosity and/or accretion rate. In addition, we find that the majority of AGNs reside in galaxies with bulges, regardless of whether these galaxies are classified as early-type or late-type systems.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Bimodal AGNs in Bimodal Galaxies . Abstract : We present the conclusion of our research on bimodality in galaxies and active galactic nuclei ( AGN ) .We see that there is no major variation between the fraction of AGNs hosted by red or blue clusters , but we do show an accumulation of AGNs with regard to normal galaxies at intermediate colors . This implies that AGNs are not preferentially found in either blue or blue clusters , as previously thought ; merely they appear to be more common among clusters with intermediate color .The absence of correlation between galaxy color and AGN activity may indicate that AGNs serve only a minor importance in quenching star formation in massive galaxies . Alternatively , it could indicate that AGNs have different impacts depending on their luminosity and / or accretion rate .In addition , we find that the majority of AGNs occur in galaxies with bulges , regardless of whether these objects are classified as early - class or late - class systems .",
        "rewrite_text": "We present the findings of our study on the bimodal characteristics of galaxies and their associated active galactic nuclei (AGNs). Our analysis reveals that there is no significant difference in the proportion of AGNs found within red or blue galaxy clusters. Instead, we observe a notable concentration of AGNs in galaxies that exhibit intermediate colors, suggesting that AGNs are not exclusively associated with either blue or red clusters, as was previously assumed. This trend indicates that AGNs are more prevalent in clusters characterized by intermediate color spectra. Furthermore, our results show a lack of correlation between the color of galaxies and the activity of AGNs, which may imply that AGNs play a limited role in the suppression of star formation within massive galaxies. Alternatively, this could suggest that the influence of AGNs varies based on their luminosity and/or accretion rates. Additionally, we find that a significant majority of AGNs are located in galaxies with bulges, irrespective of whether these galaxies are categorized as early-type or late-type systems. These findings contribute to our understanding of the relationship between galaxy morphology, color, and AGN activity, highlighting the complexity of these interactions and the need for further investigation into the mechanisms that govern AGN behavior in different galactic environments.",
        "ori-fast-z-score": 0.3464101615137754,
        "water-fast-z-score": 5.9648090806346055,
        "rewrite-fast-z-score": -0.41256849850351734
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Theoretical study of ferroelectric potassium nitrate .\nAbstract:\nThe theoretical investigation is performed for the ferroelectric phase transition in potassium nitrate (KNO3). The results are obtained by using density functional theory and generalized gradient approximation with Perdew-Burke-Ernzerhof exchange-correlation functionals. It has been found that KNO3 undergoes an improper ferroelectric phase transition at T = 723 K, which is accompanied by the rotation of NO3-groups around their symmetry axes. In addition to this structural change, there occurs also a significant redistribution of charge between atoms. This leads to changes in the electronic structure near Fermi level. The calculated values of spontaneous polarization Psp(0) = 0.27 C/m2 and dielectric constant εs = 4.5 agree well with experimental data. \n \n Keywords: Ferroelectrics; Potassium nitrite; Phase transitions; Density functional theory. 1 Introduction Potassium nitrate (KNO3), one of the most important chemical compounds used as fertilizers  1  , exhibits interesting physical properties such as piezo-, pyro-, electro-optic effects  2  . At room temperature it crystallizes into orthorhombic system  3  . Below its Curie point Tc = 723 K  4  , KNO3 behaves like paraelectric material while above Tc it becomes ferroelectric  5  .\n2 Computational details All calculations were carried out within the framework of density functional theory  6  employing plane wave basis set and projector augmented-wave method  7, 8  implemented in VASP code  9  . Exchange correlation energy was treated within generalized gradient approximation  10  . To account for van der Waals interactions we have applied Grimme s semiempirical dispersion correction  11  . We considered two different supercells containing 64 and 216 atoms respectively. For both cells we chose Monkhorst-Pack k-point mesh  12  corresponding to 6×6×4 grid in reciprocal space. Energy cutoff for planewave expansion was chosen equal to 400 eV. Structure optimization was done until all forces acting on each atom became less than 10-3 eV/Å.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Theoretical study of ferroelectric potassium nitrate . Abstract : The theoretical investigation is conducted for the ferroelectric phase change in potassium nitrate ( KNO3 ) .The results are derived by using density functional theory and generalized gradient approximation with Perdew - Burke - Ernzerhof exchange - correlation functionals . It has been shown that KNO3 undergoes an improper ferroelectric phase shift at T = 723 K , which is preceded by the rotation of NO3 - groups around their symmetry axes .In addition to this structural transformation , there occurs also a substantial redistribution of charge between elements . This leads to changes in the electronic stability near Fermi level .The measured values of spontaneous polarization Psp ( 0 ) = 0 . 27 C / m2 and dielectric constant εs = 4 . 5 comply good with experimental evidence . Keywords : Ferroelectrics ; Potassium nitrite ; Phase processes ; Density functional theory .1 Introduction Potassium nitrate ( KNO3 ) , one of the most important chemical molecules used as fertilizers 1 , displays important mechanical effects such as piezo - , pyro - , electro - optic effects 2 . At room temperature it crystallizes into orthorhombic system 3 .Below its Curie point Tc = 723 K 4 , KNO3 behaves like paraelectric material while above Tc it becomes ferroelectric 5 . 2 Computational information All calculations were carried out within the framework of density functional theory 6 employing plane wave basis set and projector augmented - wave method 7 , 8 adopted in VASP system 9 .Exchange correlation power was treated within generalized gradient approximation 10 . To account for van der Waals interactions we have applied Grimme s semiempirical dispersion reduction 11 .We considered two different supercells containing 64 and 216 atoms respectively . For both cells we chose Monkhorst - Pack k - point mesh 12 corresponding to 6×6×4 grid in reciprocal space .Energy cutoff for planewave expansion was chosen equivalent to 400 eV . Structure optimization was done until all forces working on each molecule became less than 10 - 3 eV / Å .",
        "rewrite_text": "**Title:** Theoretical Study of Ferroelectric Potassium Nitrate\n\n**Abstract:** This article presents a comprehensive theoretical analysis of the ferroelectric phase transition in potassium nitrate (KNO3), utilizing advanced computational methods grounded in density functional theory (DFT) and the generalized gradient approximation (GGA) with Perdew-Burke-Ernzerhof (PBE) exchange-correlation functionals. Our findings indicate that KNO3 experiences an improper ferroelectric phase transition at a temperature of 723 K, characterized by the rotation of nitrate (NO3-) groups around their symmetry axes. This structural alteration is accompanied by a significant redistribution of electronic charge among the constituent elements, resulting in notable changes in electronic stability near the Fermi level. The calculated spontaneous polarization (Psp) of 0.27 C/m² and the dielectric constant (εs) of 4.5 align well with experimental observations, reinforcing the validity of our theoretical approach. \n\nPotassium nitrate is a crucial chemical compound widely utilized in fertilizers and exhibits remarkable mechanical properties, including piezoelectric, pyroelectric, and electro-optic effects. At room temperature, KNO3 crystallizes in an orthorhombic structure, transitioning from a paraelectric state below its Curie point (Tc = 723 K) to a ferroelectric state above this threshold. \n\nIn our computational framework, all calculations were performed using DFT, employing a plane wave basis set and the projector augmented-wave method within the VASP software. The exchange-correlation interactions were treated using the generalized gradient approximation, while van der Waals forces were accounted for through Grimme's semiempirical dispersion correction. We investigated two distinct supercells containing 64 and 216 atoms, respectively, utilizing a Monkhorst-Pack k-point mesh corresponding to a 6×6×4 grid in reciprocal space. An energy cutoff of 400 eV was selected for the plane wave expansion, and structural optimization was conducted until the forces acting on each atom were reduced to below 10^-3 eV/Å. \n\n**Keywords:** Ferroelectrics; Potassium nitrate; Phase transitions; Density functional theory.",
        "ori-fast-z-score": -0.4472135954999579,
        "water-fast-z-score": 4.45435403187374,
        "rewrite-fast-z-score": -1.7677669529663687
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Inside-Out Evacuation of Transitional Protoplanetary Disks by the Magneto-Rotational Instability .\nAbstract:\nWe present an analytical model for the magneto-rotational instability (MRI) in protoplanetary disks, which is based on the assumption that the disk can be divided into two regions with different physical properties and dynamics. The inner region has a high density and temperature, while the outer one is less dense but hotter than the surrounding medium. We show how this simple picture allows us to reproduce many observed features of MRI-driven turbulence in accretion disks around young stars. In particular, we find that:  -The growth rate of the fastest growing mode decreases rapidly towards smaller radii due to the increasing gas pressure.  -The radial profile of the turbulent viscosity follows closely the profile of the magnetic field strength.  -The angular momentum transport efficiency increases strongly at small radii because of the rapid increase of the surface density there.  -The predicted mass accretion rates are consistent with those inferred observationally for T Tauri stars.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Inside - Out Evacuation of Transitional Protoplanetary Disks by the Magneto - Rotational Instability . Abstract : We present an analytical theory for the magneto - rotational instability ( MRI ) in protoplanetary disks , which is based on the assumption that the disk can be broken into two zones with varying mechanical parameters and dynamics .The inner region has a high density and heat , while the outer one is less dense but brighter than the nearby medium . We see how this straightforward photo lets us to depict many observed features of MRI - driven turbulence in accretion disks around young galaxies .In particular , we find that : - The growth speed of the fastest growing mode decreases quickly towards smaller radii due to the increasing gas pressure . - The radial profile of the chaotic viscosity takes closely the profile of the magnetic field intensity .- The angular velocity transport rate grows heavily at small radii because of the quick increase of the surface volume there . - The predicted mass accretion levels are compatible with those inferred observationally for T Tauri stars .",
        "rewrite_text": "We introduce a comprehensive analytical framework for understanding the magneto-rotational instability (MRI) in protoplanetary disks, predicated on the notion that these disks can be divided into two distinct regions characterized by differing mechanical properties and dynamic behaviors. The inner zone is marked by high density and elevated temperatures, while the outer zone, although less dense, exhibits greater luminosity compared to its surroundings. This simplified model allows us to effectively illustrate several observed phenomena associated with MRI-driven turbulence in accretion disks surrounding young stellar objects. \n\nOur findings reveal several key insights: First, we observe that the growth rate of the most rapidly developing mode diminishes significantly as one moves toward smaller radii, a trend attributed to the increasing gas pressure in these regions. Second, the radial distribution of chaotic viscosity closely mirrors the intensity profile of the magnetic field, suggesting a strong correlation between these two parameters. Third, we note that the rate of angular momentum transport experiences a substantial increase at smaller radii, driven by the rapid expansion of the surface volume in these areas. Finally, our theoretical predictions regarding mass accretion rates align well with observational data obtained from T Tauri stars, reinforcing the validity of our model. \n\nOverall, this study enhances our understanding of the dynamics within protoplanetary disks and provides a robust framework for interpreting the complex interactions that govern the behavior of these astrophysical systems.",
        "ori-fast-z-score": -1.5275252316519468,
        "water-fast-z-score": 4.447074385282452,
        "rewrite-fast-z-score": -0.6363636363636364
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Graphene Spin Transistor .\nAbstract:\nThe spin transistor is an important device for future quantum information processing and communication technologies, but its realization in practice has been challenging due to the lack of suitable materials with large spin-orbit coupling (SOC). Here we propose that graphene can be used as such material by exploiting its unique electronic structure. We show how this leads to a novel type of spin transistor which operates at room temperature without external magnetic fields or applied gate voltages. The proposed device consists of two ferromagnetic contacts connected via a single layer of graphene. By applying a voltage between these contacts one can control the SOC strength in the graphene channel leading to a change in the transmission probability through it. This results in a switching behavior similar to conventional transistors. In addition, our analysis shows that the proposed device exhibits high on/off ratios even when operating under realistic conditions. Finally, we discuss possible experimental realizations of the proposed device. Graphene is a promising candidate for applications in spintronics because of its unique electronic properties  1  . It offers the possibility to realize devices based on pure spin currents  2  , which are not limited by Joule heating effects  3  .\nIn particular, the spin Hall effect  4  allows for efficient generation  5  and detection  6  of spin currents using only electric fields  7, 8  . However, despite many theoretical proposals  9  , there have so far been very few successful attempts to experimentally demonstrate spintronic devices based on graphene  10  . One reason might be the difficulty to find appropriate materials with sufficiently strong spin-orbit interaction  11  . Another problem is related to the fact that most experiments were performed at low temperatures  12  where thermal fluctuations limit the performance of spintronic devices  13  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Graphene Spin Transistor . Abstract : The spin transistor is an important technology for future particle information processing and communication technologies , but its acceptance in practice has been challenging due to the lack of appropriate structures with large spin - orbit interaction ( SOC ) .Here we propose that graphene can be used as such material by exploiting its unique electronic structure . We see how this results to a new kind of spin transistor which operates at room temperature without external magnetic fields or applied gate voltages .The proposed system consists of two ferromagnetic contacts connected via a single layer of graphene . By applying a voltage between these contacts one can influence the SOC intensity in the graphene channel resulting to a change in the propagation probability through it .This results in a switching behavior consistent to conventional transistors . In addition , our analysis shows that the suggested system displays high on / off ratios even when operating under realistic conditions .Finally , we explain possible experimental realizations of the suggested system . Graphene is a potential candidate for applications in spintronics because of its unique electronic properties 1 .It provides the possibility to realize devices based on true spin currents 2 , which are not limited by Joule heating factors 3 . In particular , the spin Hall impact 4 enables for efficient production 5 and detection 6 of spin currents using only electric forces 7 , 8 .However , despite many theoretical proposals 9 , there have so far been very few successful proposals to experimentally prove spintronic systems based on graphene 10 . One reason could be the difficulty to find adequate structures with sufficiently strong spinning - orbit interaction 11 .Another difficulty is related to the fact that most studies were performed at low temperatures 12 where thermal fluctuations limit the performance of spintronic systems 13 .",
        "rewrite_text": "**Title: Graphene Spin Transistor**\n\n**Abstract:** The development of spin transistors represents a significant advancement in the field of particle information processing and communication technologies. However, the practical implementation of this technology has faced obstacles, primarily due to the scarcity of suitable materials that exhibit substantial spin-orbit interaction (SOC). In this article, we propose the utilization of graphene as a promising candidate, leveraging its distinctive electronic properties to create a novel type of spin transistor. Our design operates effectively at room temperature and does not require external magnetic fields or applied gate voltages. The proposed architecture consists of two ferromagnetic contacts linked by a monolayer of graphene. By applying a voltage across these contacts, we can modulate the SOC within the graphene channel, leading to variations in the probability of spin propagation. This mechanism results in a switching behavior that mirrors that of conventional transistors. Furthermore, our analysis indicates that the proposed graphene spin transistor achieves high on/off ratios, even under realistic operating conditions. We also discuss potential experimental setups to realize this system, highlighting graphene's suitability for spintronic applications due to its unique electronic characteristics. Specifically, graphene facilitates the generation and detection of true spin currents, which are advantageous as they are not constrained by Joule heating effects. The spin Hall effect plays a crucial role in enabling efficient spin current manipulation using solely electric fields. Despite numerous theoretical advancements in the field, experimental validation of graphene-based spintronic devices has been limited. This is partly attributed to the challenges in identifying structures with sufficiently strong SOC and the predominance of studies conducted at low temperatures, where thermal fluctuations can impede the performance of spintronic systems. Our work aims to bridge this gap by presenting a viable pathway for the practical realization of graphene spin transistors, paving the way for future innovations in spintronic technology.",
        "ori-fast-z-score": 1.0795912380986197,
        "water-fast-z-score": 7.4550104767232686,
        "rewrite-fast-z-score": 2.867311721816642
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A multiwavelength study of young massive star forming regions: II. The dust environment .\nAbstract:\nWe present the results of an extensive multi-wavelength survey of two nearby (< 1 kpc) and well-studied star-forming regions, Orion Nebula Cluster (ONC), NGC 2024, in order to investigate their physical properties as well as those of individual protostars embedded within them. We have obtained near-infrared images with Subaru/Suprime-Cam at JHKs bands for ONC region and Spitzer/IRAC 3.6-8.0 micron data for both regions. In addition we used archival radio continuum observations made by VLA at 6 cm and 20 cm wavelengths. Using these datasets, we performed photometry on all point sources detected above 5 sigma level in each band. By comparing our infrared photometric measurements with theoretical evolutionary models, we found that most of the objects are likely to be Class I or flat-spectrum protostellar candidates. From the analysis of spectral energy distribution (SED) fitting using radiative transfer modeling code, we derived the mass accretion rates onto the central stars ranging between 10-700 x10-6 Msun yr-1 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A multiwavelength study of young massive star producing regions : II . The dust climate .Abstract : We present the conclusion of an extensive multi - wavelength search of two adjacent ( < 1 kpc ) and well - investigated star - creating areas , Orion Nebula Cluster ( ONC ) , NGC 2024 , in order to examine their physical properties as well as those of individual protostars embedded within them . We have achieved near - infrared images with Subaru / Suprime - Cam at JHKs bands for ONC region and Spitzer / IRAC 3 . 6 - 8 . 0 micron data for both locations .In addition we using archival radio continuum measurements made by VLA at 6 cm and 20 cm wavelengths . Using these datasets , we performed photometry on all point sources detected above 5 sigma grade in each band .By applying our laser photometric calculations with theoretical phylogenetic models , we identified that most of the items are likely to be Class I or flat - spectrum protostellar candidates . From the evaluation of spectral power distribution ( SED ) matching using radiative transfer modeling code , we derived the mass accretion levels onto the main stars ranging between 10 - 700 x10 - 6 Msun yr - 1 .",
        "rewrite_text": "We present the findings of a comprehensive multi-wavelength investigation of two closely situated (less than 1 kpc apart) and well-studied star-forming regions: the Orion Nebula Cluster (ONC) and NGC 2024. This study aims to explore the physical characteristics of these regions and the individual protostars that reside within them. Utilizing near-infrared imaging from Subaru/Suprime-Cam across the JHKs bands for the ONC and Spitzer/IRAC data at 3.6 to 8.0 microns for both regions, we have gathered a rich dataset. Additionally, we incorporated archival radio continuum measurements from the Very Large Array (VLA) at 6 cm and 20 cm wavelengths. \n\nThrough these datasets, we conducted photometric analyses on all point sources that were detected with a significance greater than 5 sigma in each band. Our application of advanced photometric techniques, combined with theoretical evolutionary models, allowed us to classify the majority of these sources as likely Class I or flat-spectrum protostellar candidates. Furthermore, we evaluated the spectral energy distributions (SED) through radiative transfer modeling, which enabled us to estimate the mass accretion rates onto the primary stars. Our findings indicate that these rates vary significantly, ranging from 10 to 700 x 10^-6 M_sun yr^-1. This research contributes to a deeper understanding of the physical processes governing star formation in these dynamic environments and highlights the importance of multi-wavelength observations in uncovering the complexities of stellar birth and evolution.",
        "ori-fast-z-score": -1.2074068598865937,
        "water-fast-z-score": 4.800793585191832,
        "rewrite-fast-z-score": 1.212183053462653
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Transient X-ray Emission from Normal Galactic Nuclei .\nAbstract:\nWe report on the detection of transient X-ray emission in normal galactic nuclei (NGNs) with Chandra and XMM-Newton observatories, which is likely to be associated with accretion onto supermassive black holes at their centers. The observed luminosities are consistent with those expected for steady nuclear activity powered by mass inflow through an optically thick disk around the central black hole. We find that the duration of this activity ranges between 10 3 -10 5 years, depending on the distance of NGN from Earth. This suggests that the majority of NGNs may have experienced such active phases during their lifetimes. Our results also imply that the current quiescent state of most NGNs could be due to either low-level accretion or obscuration effects. These findings provide new insights into the formation and evolution of massive galaxies as well as AGNs. Keywords: Black Hole Accretion Disk - Galaxy Evolution - Nuclear Activity",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Transient X - ray Emission from Normal Galactic Nuclei . Abstract : We report on the observation of transient X - ray radiation in regular galactic nuclei ( NGNs ) with Chandra and XMM - Newton observatories , which is expected to be involved with accretion onto supermassive black holes at their centers .The observed luminosities are compatible with those expected for steady nuclear activity driven by mass inflow through an optically dense disk around the main dark hole . We see that the duration of this action ranges between 10 3 - 10 5 years , depending on the distance of NGN from Earth .This implies that the majority of NGNs might have experienced such active phases during their lifetimes . Our results also suggest that the present quiescent state of most NGNs might be due to either small - grade accretion or obscuration effects .These studies provide fresh insights into the formation and evolution of large galaxies as well as AGNs . Keywords : Black Hole Accretion Disk - Galaxy Evolution - Nuclear Activity",
        "rewrite_text": "We present findings on the detection of transient X-ray emissions from normal galactic nuclei (NGNs) using the Chandra and XMM-Newton observatories. These emissions are believed to be associated with the accretion processes occurring around supermassive black holes located at the centers of these galaxies. The luminosities we observed align with predictions for sustained nuclear activity, which is driven by mass inflow through a dense, optically thick accretion disk surrounding the central black hole. Our analysis indicates that the active phases of X-ray emission last between 10^3 and 10^5 years, with variations depending on the NGN's distance from Earth. This finding suggests that a significant number of NGNs have likely undergone such active phases throughout their evolutionary history. Furthermore, our results imply that the current quiescent states observed in many NGNs may be attributed to either low-level accretion processes or the effects of obscuration. This research contributes valuable knowledge to the understanding of the formation and evolution of large galaxies and active galactic nuclei (AGNs). The implications of these transient emissions are critical for comprehending the dynamics of black hole accretion and the overall lifecycle of galaxies. Our study highlights the importance of continuous monitoring of NGNs to uncover the complexities of their nuclear activities and the factors influencing their evolution over cosmic timescales. \n\nKeywords: Black Hole Accretion Disk, Galaxy Evolution, Nuclear Activity.",
        "ori-fast-z-score": -1.25,
        "water-fast-z-score": 4.83735464897913,
        "rewrite-fast-z-score": -0.20412414523193154
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Effect of temperature-dependent shape anisotropy on coercivity with aligned Stoner-Wohlfarth soft ferromagnets .\nAbstract:\nWe study the effect of temperature dependent shape anisotropy in an exchange coupled system consisting of two identical uniaxial single domain particles, one being magnetically softer than the other and both having their easy axes parallel to each other. We show that for certain values of the parameters involved there is a significant increase in the coercive field at low temperatures compared to high temperatures. This can be understood by considering the competition between the Zeeman energy barrier due to the applied magnetic field and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy. \n \n The model we consider consists of two identical spherical particles (with radius R) separated by a distance d along the z-axis. Each particle has its own uniaxial anisotropy constant Ks(T), where T denotes the temperature. In addition, they are also exchange-coupled through a coupling constant J. For simplicity, we assume that the anisotropy constants have the same functional form as given below, \n \n Ks = K1 + K2 tanh -(T/Tc) ,\n \nwhere Tc is some characteristic temperature scale which determines how rapidly the anisotropy changes with temperature.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Effect of temperature - dependent shape anisotropy on coercivity with aligned Stoner - Wohlfarth soft ferromagnets . Abstract : We research the impact of temperature dependent shape anisotropy in an exchange coupled system consisting of two different uniaxial single domain particles , one being magnetically softer than the other and both having their easy axes perpendicular to each other .We see that for particular values of the variables required there is a substantial rise in the coercive field at low temperatures relative to large conditions . This can be understood by examining the competition between the Zeeman electricity barrier thanks to the applied magnetic field and the thermal activation energy barrier associated with the temperature dependence of the shape anisotropy .The model we define consists of two equal spherical objects ( with diameter R ) connected by a distance d along the z - axis . Each particle has its own uniaxial anisotropy constant Ks ( T ) , where T denotes the temperature .In addition , they are also exchange - coupled through a coupling constant J . For simplicity , we suppose that the anisotropy constants have the same functional form as provided below , Ks = K1 + K2 tanh - ( T / Tc ) , where Tc is some characteristic temperature scale which determines how swiftly the anisotropy changes with temperature .",
        "rewrite_text": "**Title:** Effect of Temperature-Dependent Shape Anisotropy on Coercivity in Aligned Stoner-Wohlfarth Soft Ferromagnets\n\n**Abstract:** This study investigates the influence of temperature-dependent shape anisotropy on the coercivity of an exchange-coupled system comprising two distinct uniaxial single-domain particles, characterized by differing magnetic softness and oriented with their easy axes perpendicular to one another. Our findings reveal that under specific conditions, there is a significant increase in the coercive field at lower temperatures compared to higher temperature scenarios. This phenomenon can be attributed to the interplay between the Zeeman energy barrier induced by an external magnetic field and the thermal activation energy barrier that arises from the temperature-dependent nature of shape anisotropy. \n\nThe model we propose involves two identical spherical particles, each with a diameter R, separated by a distance d along the z-axis. Each particle possesses its own uniaxial anisotropy constant, denoted as Ks(T), where T represents the temperature. Furthermore, the particles are coupled through an exchange interaction characterized by a coupling constant J. For the sake of simplicity, we assume that the anisotropy constants share a common functional form, expressed as Ks = K1 + K2 tanh(-T/Tc), where Tc is a critical temperature scale that dictates the rate at which anisotropy varies with temperature. \n\nThrough our analysis, we elucidate the mechanisms by which temperature-dependent shape anisotropy affects coercivity, providing insights that could enhance the understanding of magnetic properties in soft ferromagnetic materials. This research has implications for the design and application of magnetic materials in various technological fields, including data storage and spintronic devices, where precise control over coercivity is essential.",
        "ori-fast-z-score": -0.7258661863112977,
        "water-fast-z-score": 4.125684985035173,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Quantification of discreteness effects in cosmological N-body simulations: II. Evolution up to shell crossing .\nAbstract:\nWe present the results of an investigation into the evolution of dark matter halos and their substructure, using high-resolution cosmological N-body simulations with different mass resolutions. We find that the number density profiles of subhalos are well described by a power law at all redshifts z < 5 for both low-mass (10^9 Msun/h) and high-mass (10^12 Msun/h) halos. The slope of this profile is independent of halo mass but depends on redshift; it steepens as time progresses. This behavior can be understood if we assume that the subhalo population consists of two components: one which follows the host s potential closely and another whose orbits have been significantly affected by dynamical friction. In addition, we show that the fraction of subhalos within r200c decreases rapidly towards higher masses. Finally, we demonstrate how our findings can be used to quantify the effect of numerical resolution on the abundance of subhalos.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Quantification of discreteness processes in cosmological N - bodies simulations : II . Evolution up to shell crossing .Abstract : We present the conclusion of an research into the evolution of deep material halos and their substructure , using high - resolution cosmological N - bodies simulations with various mass resolutions . We see that the number density profiles of subhalos are better modeled by a power law at all redshifts z < 5 for both high - mass ( 10 ^ 9 Msun / h ) and low - mass ( 10 ^ 12 Msun / h ) halos .The slope of this profile is independent of halo weight but relies on redshift ; it steepens as time progresses . This phenomenon can be understood if we suppose that the subhalo population contains of two parts : one which follows the host s potential closely and another whose orbits have been dramatically impacted by dynamical friction .In addition , we prove that the fraction of subhalos within r200c tends rapidly towards higher masses . Finally , we prove how our findings can be used to quantify the impact of statistical resolution on the availability of subhalos .",
        "rewrite_text": "We present the findings of our research on the evolution of deep material halos and their substructures, utilizing high-resolution cosmological N-body simulations across a range of mass resolutions. Our study focuses on the number density profiles of subhalos, which we have determined to be more accurately represented by a power law for all redshifts z < 5, applicable to both high-mass (10^9 Msun/h) and low-mass (10^12 Msun/h) halos. Notably, we observe that the slope of these profiles is consistent regardless of the halo mass, yet it is influenced by redshift, exhibiting a steepening trend over time. This behavior can be interpreted through a model suggesting that the subhalo population is comprised of two distinct components: one that closely adheres to the gravitational potential of the host halo, and another that has experienced significant alterations in its orbital dynamics due to the effects of dynamical friction. Furthermore, our analysis reveals that the proportion of subhalos within the radius r200c tends to shift rapidly towards higher mass categories. Ultimately, we demonstrate how our results can be leveraged to assess the effects of statistical resolution on the detection and characterization of subhalos within cosmological simulations. This work contributes to a deeper understanding of the structural evolution of halos in the universe and provides valuable insights for future studies in cosmology and astrophysics.",
        "ori-fast-z-score": -2.1939310229205775,
        "water-fast-z-score": 3.8105117766515297,
        "rewrite-fast-z-score": 0.6255432421712244
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Equivalence of LP Relaxation and Max-Product for Weighted Matching in General Graphs .\nAbstract:\nWe show that the linear programming relaxation (LP) is equivalent to the max-product algorithm on general graphs, when applied to weighted matching problems with non-negative weights.  We prove this equivalence by showing how each step of the max-product algorithm can be simulated using an appropriate rounding technique based on the solution of the dual problem at hand.   The main idea behind our approach is to use the fact that any feasible primal-dual pair satisfies certain properties which we exploit to obtain a valid rounding scheme. Our results are applicable to many combinatorial optimization problems such as maximum weight bipartite matching, minimum cost flow, vertex cover etc., where the objective function has only non-negative coefficients. In particular, they imply that the integrality gap of these problems under their respective LP relaxations cannot exceed 1 + $O(1/n)$, where $n$ denotes the number of nodes or edges in the input graph. This improves upon previously known upper bounds of 2 and 3/2 respectively.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Equivalence of LP Relaxation and Max - Product for Weighted Matching in General Graphs . Abstract : We see that the linear programming relaxation ( LP ) is analogous to the max - product algorithm on general graphs , when applied to weighted matching problems with non - negative weights .We test this equivalence by showing how each step of the max - product algorithm can be simulated using an appropriate rounding methodology relying on the solve of the dual issue at hand . The main idea behind our approach is to use the fact that any feasible primal - dual pair satisfies certain characteristics which we utilize to obtain a valid rounding scheme .Our results are applicable to many combinatorial algorithms problems such as maximum weight bipartite matching , lowest price flow , vertex cover etc . , where the objective function has only non - negative coefficients . In particular , they mean that the integrality gap of these problems under their respective LP relaxations cannot exceed 1 + $ O ( 1 / n ) $ , where $ n $ represents the number of vertices or edges in the input graph .This improves upon previously known upper limits of 2 and 3 / 2 respectively .",
        "rewrite_text": "Title: Equivalence of LP Relaxation and Max-Product for Weighted Matching in General Graphs\n\nAbstract: In this study, we explore the relationship between linear programming (LP) relaxation and the max-product algorithm in the context of weighted matching problems on general graphs with non-negative weights. We establish that these two approaches are fundamentally analogous by demonstrating how each iteration of the max-product algorithm can be effectively simulated through a suitable rounding technique that leverages the solution of the corresponding dual problem. The core of our methodology lies in the observation that any feasible primal-dual pair adheres to specific properties, which we exploit to develop a valid rounding scheme. Our findings have significant implications for a variety of combinatorial optimization problems, including maximum weight bipartite matching, lowest price flow, and vertex cover, all of which feature objective functions with non-negative coefficients. Notably, our results indicate that the integrality gap for these problems, when analyzed through their respective LP relaxations, is bounded by 1 + $O(1/n)$, where $n$ denotes the number of vertices or edges in the input graph. This represents a substantial improvement over previously established upper bounds of 2 and 3/2 for these problems. Our work not only enhances the understanding of the interplay between LP relaxation and combinatorial algorithms but also provides a framework for further research in optimization theory and its applications in graph-based problems.",
        "ori-fast-z-score": 1.2649110640673518,
        "water-fast-z-score": 4.717281765248632,
        "rewrite-fast-z-score": 0.4926646390821466
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Equation of state of atomic systems beyond s-wave determined by the lowest order constrained variational method: Large scattering length limit .\nAbstract:\nWe present an equation of state for atomic systems with large scattering lengths, which is obtained in the framework of the lowest-order constrained variational method (LOCV). The LOCV approach allows one to obtain accurate results for both fermions and bosons at low temperatures. We show that our equation of state agrees well with Monte Carlo simulations performed within the grand canonical ensemble. In particular we find good agreement between theory and experiment on the energy per particle of 4 He-4 He mixtures near the superfluid transition temperature T = Tc. Our results are also compared with those obtained using other theoretical approaches such as the virial expansion or the hypernetted chain approximation. \nI. INTRODUCTORY REMARK\nThe equation of state plays an important role in many areas of physics ranging from nuclear matter  1  , quantum gases  2  , astrophysics  3  , condensed matter  4  , etc.. It describes how various thermodynamic quantities depend on each other under given conditions. For example, it can be used to determine the pressure P , chemical potential µ, entropy S, specific heat Cv, compressibility κT , thermal expansivity αp, sound velocity cs, etc., all of them being functions of density n and/or temperature T . Hereafter we will use the symbol EOS to denote any of these quantities.\nIn this work we consider the case when the scattering length a of two particles becomes very large so that the system behaves like a gas of weakly interacting dimers. This situation occurs e.g. in dilute Bose-Einstein condensates  5  where the scattering length may be tuned via Feshbach resonances  6  .\nII. THEORETICAL APPROACHES\n\nA. Grand Canonical Ensemble\nTo describe the properties of a mixture consisting of Nα atoms of species A and Nβ atoms of species B, we employ the grand-canonical ensemble  7, 8  \nwhere H is the total Hamiltonian of the system, β ≡ 1/kB T denotes inverse temperature, μi is the chemical potential of species i ∈ {A, B}, and Z(Nα,",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Equation of state of nuclear systems beyond s - wave determined by the lowest order constrained variational technique : Large scattering length limit . Abstract : We present an equation of state for atomic systems with large scattering lengths , which is achieved in the framework of the lowest - order constrained variational technique ( LOCV ) .The LOCV method enables one to obtain precise conclusions for both fermions and bosons at low temperatures . We see that our equation of state agrees well with Monte Carlo simulations conducted within the grand canonical ensemble .In particular we find good agreement between theoretical and experiment on the power per particle of 4 He - 4 He mixtures near the superfluid transition rate T = Tc . Our results are also compared with those achieved using other theoretical methods such as the virial expansion or the hypernetted chain method .I . INTRODUCTORY REMARK The equation of state plays an important role in multiple fields of science diverse from nuclear matter 1 , quantum gases 2 , astrophysics 3 , condensed matter 4 , etc . .It gives how various thermodynamic quantities rely on each other under given conditions . For instance , it can be used to predict the pressure P , chemical potential µ , entropy S , specific hot Cv , compressibility κT , thermal expansivity αp , noise speed cs , etc . , all of them being functions of density n and / or temperature T .Hereafter we will use the symbol EOS to indicate any of these quantities . In this study we study the case when the scattering height a of two particles gets very huge so that the system behaves like a gas of weakly interacting dimers .This condition occurs e . g . in dilute Bose - Einstein condensates 5 where the scattering duration must be tuned via Feshbach resonances 6 .II.THEORETICAL APPROACHES\n\nA.Grand Canonical Ensemble To describe the properties of a mixture consisting of Nα atoms of genus A and Nβ ions of genus B , we utilize the grand - canonical ensemble 7 , 8 where H is the total Hamiltonian of the system , β ≡ 1 / kB T denotes inverse temperature , μi is the chemical potential of species i ∈ { A , B } , and Z ( Nα ,",
        "rewrite_text": "**Title:** Equation of State of Nuclear Systems Beyond s-Wave Determined by the Lowest Order Constrained Variational Technique: Large Scattering Length Limit\n\n**Abstract:** In this study, we derive an equation of state for atomic systems characterized by large scattering lengths, utilizing the lowest-order constrained variational technique (LOCV). This method allows for accurate predictions regarding the behavior of both fermionic and bosonic systems at low temperatures. Our findings demonstrate a strong correlation between the LOCV-derived equation of state and results from Monte Carlo simulations performed within the grand canonical ensemble framework. Notably, we observe a close match between our theoretical predictions and experimental data concerning the energy per particle in mixtures of helium-4 (4He-4He) near the superfluid transition temperature (T = Tc). Furthermore, we compare our results with those obtained through alternative theoretical approaches, including the virial expansion and the hypernetted chain method.\n\nThe equation of state is a fundamental aspect of various scientific disciplines, including nuclear matter, quantum gases, astrophysics, and condensed matter physics. It elucidates the interdependence of thermodynamic quantities under specific conditions, enabling predictions of pressure (P), chemical potential (µ), entropy (S), specific heat (Cv), compressibility (κT), thermal expansivity (αp), and sound speed (cs), all of which are functions of density (n) and temperature (T). In this work, we focus on scenarios where the scattering length (a) between two particles becomes significantly large, resulting in a system that behaves like a gas of weakly interacting dimers. This phenomenon is particularly relevant in dilute Bose-Einstein condensates, where the scattering length can be finely adjusted using Feshbach resonances. Our theoretical framework is grounded in the grand canonical ensemble, which effectively describes the properties of mixtures comprising Nα atoms of species A and Nβ ions of species B, with the total Hamiltonian (H) representing the system's energy. The inverse temperature is denoted by β ≡ 1/kB T, and the chemical potential for each species is represented as μi, where i belongs to the set {A, B}.",
        "ori-fast-z-score": -0.40689422938557973,
        "water-fast-z-score": 6.002192581838214,
        "rewrite-fast-z-score": -0.9263671131731709
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  XMMU J174716.1-281048: a  quasi-persistent  very faint X-ray transient? .\nAbstract:\nWe report on the discovery and analysis of XMM-Newton observations of an uncatalogued, extremely faint X-ray source (X-ray luminosity < 1031 erg s-1) in the Galactic plane at l = 28 deg., b = 0.5 deg.. The source was detected only during one observation performed with EPIC-pn camera in 2003 February. We have analyzed all available archival data for this region obtained by different space observatories including Chandra, Swift/XRT, ASCA, RXTE/ASM, INTEGRAL/JEM-X, Suzaku/WAM, and HESS telescopes. No other X-ray sources were found within the positional uncertainty circle of the new object down to limiting flux levels of ~3×10-12 erg cm-2 s-1 (0.2-10 keV). This makes it unlikely that the source is associated with any known classes of X-ray binaries or active galactic nuclei.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  XMMU J174716.1-281048: a  quasi-persistent  very faint X-ray transient?.Abstract : We report on the discovery and assessment of XMM - Newton discoveries of an uncatalogued , incredibly faint X - ray source ( X - ray luminosity < 1031 erg s - 1 ) in the Galactic jet at l = 28 deg . , b = 0 . 5 deg . . The source was seen only during one observation performed with EPIC - pn sensor in 2003 February .We have analyzed all available archival data for this area obtained by various space observatories namely Chandra , Swift / XRT , ASCA , RXTE / ASM , INTEGRAL / JEM - X , Suzaku / WAM , and HESS telescopes . No other X - ray sources were found within the positional uncertainty arc of the new object down to limiting flux levels of ~ 3×10 - 12 erg centimetres - 2 s - 1 ( 0 . 2 - 10 keV ) .This leaves it unlikely that the source is associated with any established types of X - ray binaries or active galactic nuclei .",
        "rewrite_text": "Title: XMMU J174716.1-281048: A Quasi-Persistent Very Faint X-Ray Transient?\n\nAbstract: In this study, we present the discovery and analysis of an uncatalogued, extremely faint X-ray source, designated XMMU J174716.1-281048, located in the Galactic jet at coordinates l = 28 degrees and b = 0.5 degrees. This source exhibits an X-ray luminosity of less than 10^31 erg s^-1 and was detected exclusively during a single observation conducted with the EPIC-pn sensor of the XMM-Newton satellite in February 2003. To further investigate this intriguing object, we meticulously examined all available archival data from a variety of space observatories, including Chandra, Swift/XRT, ASCA, RXTE/ASM, INTEGRAL/JEM-X, Suzaku/WAM, and HESS telescopes. Our comprehensive analysis revealed no additional X-ray sources within the positional uncertainty arc of XMMU J174716.1-281048, down to limiting flux levels of approximately 3×10^-12 erg cm^-2 s^-1 in the energy range of 0.2 to 10 keV. The absence of other detectable X-ray sources in this region suggests that XMMU J174716.1-281048 is unlikely to be associated with any known categories of X-ray binaries or active galactic nuclei. This finding raises intriguing questions about the nature of this faint transient and its potential implications for our understanding of X-ray emission mechanisms in the Galactic environment. Further observations and studies are warranted to elucidate the characteristics and origins of this enigmatic source.",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 4.464418717230567,
        "rewrite-fast-z-score": -0.7683498199278324
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity .\nAbstract:\nWe present new exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors, which are generated by applying nonholonomic frame transforms (NFT) to known vacuum solutions. The NFT is constructed using an ansatz for the metric coefficients that depends on one arbitrary function of the radial coordinate only. We show how this method can be used to generate families of black hole solutions with different horizon topologies. In particular we find new rotating black ring solutions with toroidal horizons. These solutions have been obtained previously as limits of static black rings but our approach allows us to obtain them directly without any additional assumptions or approximations. Finally, we discuss some open problems related to these results. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq \nI. INTRODUCTORY REMARkS\nThe study of exact solutions to the Einstein equations has played a crucial role in understanding many aspects of general relativity. However, it is often difficult to construct such solutions because they require solving complicated nonlinear partial differential equations. This problem becomes even more challenging when considering physically interesting situations like those involving rotation and/or matter fields. Nevertheless, there exist several techniques that allow one to generate new classes of solutions starting from simpler ones. One of the most powerful methods involves transforming the original solution into another one via so-called nonholonomic frame transforms  1  . Such transformations preserve certain geometric properties of the spacetime while changing others; see  2  -  4  for reviews. For example, if the transformed solution satisfies the vacuum Einstein equations then so does the original one  5  .\nIn this work we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to generate new exact solutions describing stationary axisymmetric spacetimes: i.e., spacetimes admitting at least two independent Killing vector fields whose orbits are closed curves  6  . Stationary axisymmetric spacetimes play an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars, planets, and black holes  7, 8",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity . Abstract : We introduce novel exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors , which are produced by using nonholonomic frame transforms ( NFT ) to known vacuum solutions .The NFT is built using an ansatz for the metric coefficients that relies on one arbitrary function of the radial coordinate only . We see how this method can be used to create families of black hole solutions with various horizon topologies .In particular we find new moving black ring solutions with toroidal horizons . These solutions have been achieved formerly as limits of static black rings but our approach allows us to obtain them directly without any additional constraints or approximations .Finally , we explain some open problems related to these results . PACS scores : 04 . 20 . - q , 11 . 10 . - z , 98 . 80 . Cq I .INTRODUCTORY REMARkS The investigation of precise solutions to the Einstein equations has served a crucial role in understanding several parts of general relativity . However , it is often challenging to build such solutions because they demand solving complicated nonlinear partial differential equations .This problem remains especially more challenging when treating physically exciting situations like those concerning rotation and / or matter fields . Nevertheless , there remain many procedures that enable one to create fresh categories of solutions starting from simpler ones .One of the most efficient methods involves transforming the previous solve into another one via so - called nonholonomic frame transforms 1 . Such transformations maintain certain geometric properties of the spacetime while altering others ; see 2 - 4 for reviews .For instance , if the transformed solution satisfies the vacuum Einstein equations then so does the previous one 5 . In this study we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to create novel exact solutions governing stationary axisymmetric spacetimes : i . e . , spacetimes admitting at least two independent Killing matrix fields whose orbits are open curves 6 .Stationary axisymmetric spacetimes serve an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars , planets , and dark holes 7 , 8",
        "rewrite_text": "**Title:** Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity\n\n**Abstract:** In this article, we present innovative exact solutions to the Einstein field equations specifically for stationary axisymmetric spacetimes characterized by two commuting Killing vectors. These solutions are derived through the application of nonholonomic frame transforms (NFT) to established vacuum solutions. The NFT is constructed using a metric coefficient ansatz that depends solely on an arbitrary function of the radial coordinate. This approach enables the generation of families of black hole solutions with diverse horizon topologies. Notably, we identify new moving black ring solutions featuring toroidal horizons. While these solutions have previously been obtained as limits of static black rings, our methodology allows for their direct derivation without imposing additional constraints or approximations. Furthermore, we discuss several unresolved issues related to these findings. \n\nThe exploration of exact solutions to the Einstein equations is fundamental for advancing our understanding of various aspects of general relativity. However, constructing such solutions is often a complex task due to the necessity of solving intricate nonlinear partial differential equations. This complexity is exacerbated in scenarios involving rotation and/or matter fields. Despite these challenges, numerous techniques exist to generate new classes of solutions from simpler ones. One particularly effective method is the transformation of existing solutions through nonholonomic frame transforms, which preserve certain geometric characteristics of spacetime while modifying others. For example, if the transformed solution adheres to the vacuum Einstein equations, the original solution does as well. In this study, we leverage nonholonomic frame transforms on known vacuum solutions of the Einstein equations to derive new exact solutions that govern stationary axisymmetric spacetimes—those that possess at least two independent Killing vector fields with open curve orbits. Such spacetimes are crucial in astrophysics, as they describe the gravitational fields surrounding rotating celestial bodies, including stars, planets, and black holes.",
        "ori-fast-z-score": -1.5696136947790653,
        "water-fast-z-score": 6.111919138499425,
        "rewrite-fast-z-score": -0.7092993656151906
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The continuum radio emission from the Sy 1.5 galaxy NGC 5033 .\nAbstract:\nWe present new observations at 5 GHz and 8.4 GHz with the VLA in A-configuration, which reveal that the nuclear region of the Seyfert 1.5 galaxy NGC5033 is dominated by two compact components separated by ~0.3 arcsec (~500 pc). The northern component has an inverted spectrum between 5-8.4GHz while the southern one shows a steep spectral index consistent with optically-thin synchrotron radiation. We find no evidence for extended emission on scales larger than 0.1 arcsec (100pc) around either source. These results are discussed within the context of models where relativistic jets interact strongly with their environment to produce shocks and particle acceleration. In this scenario we propose that the northern component may be associated with a young jet emerging from the nucleus, whereas the southern one could represent older material ejected earlier during the activity cycle of the AGN. \n \n Keywords: Radio galaxies",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The continuum radio emission from the Sy 1 . 5 galaxy NGC 5033 . Abstract : We report new images at 5 GHz and 8 . 4 GHz with the VLA in A - configuration , which confirm that the nuclear portion of the Seyfert 1 . 5 galaxy NGC5033 is dominated by two compact components separated by ~ 0 . 3 arcsec ( ~ 500 pc ) .The northern component has an inverted spectrum between 5 - 8 . 4GHz while the northeastern one exhibits a sharp spectral index consistent with optically - thin synchrotron emission . We see no evidence for extended emitted on scales bigger than 0 . 1 arcsec ( 100pc ) around either source .These data are discussed within the context of models where relativistic jets interact heavily with their environment to produce shocks and particle acceleration . In this situation we propose that the northern component may be involved with a young jet developing from the nucleus , whereas the northeastern one might represent newer material expelled later during the activity process of the AGN .Keywords: Radio galaxies",
        "rewrite_text": "Title: Continuum Radio Emission from the Seyfert 1.5 Galaxy NGC 5033\n\nAbstract: In this study, we present new radio images of the Seyfert 1.5 galaxy NGC 5033, captured at frequencies of 5 GHz and 8.4 GHz using the Very Large Array (VLA) in A-configuration. Our observations reveal that the nuclear region of NGC 5033 is characterized by two distinct compact components, which are approximately 0.3 arcseconds apart (equivalent to about 500 parsecs). The northern component displays an inverted spectrum across the 5 to 8.4 GHz range, indicating a unique emission mechanism, while the northeastern component shows a steep spectral index that aligns with the characteristics of optically-thin synchrotron radiation. Notably, we find no evidence of extended emission on scales larger than 0.1 arcseconds (100 parsecs) surrounding either of the compact sources. These findings are interpreted within the framework of models that suggest significant interactions between relativistic jets and their surrounding environment, leading to the formation of shocks and the acceleration of particles. We hypothesize that the northern component may be associated with a nascent jet emerging from the nucleus of the galaxy, while the northeastern component could represent material ejected later during the active phase of the active galactic nucleus (AGN). This research contributes to our understanding of the complex dynamics at play in the vicinity of AGNs and the mechanisms driving radio emissions in such systems. \n\nKeywords: Radio galaxies, Seyfert galaxies, NGC 5033, relativistic jets, synchrotron emission.",
        "ori-fast-z-score": -1.162476387438193,
        "water-fast-z-score": 4.649905549752772,
        "rewrite-fast-z-score": 1.1055415967851332
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Inter comparison of the magneto transport of La2/3Ca1/3MnO3: Ag/In polycrystalline composites .\nAbstract:\nThe effect of silver and indium on the magnetic properties, electrical resistivity (ER) and Hall coefficient (R H ) has been investigated in La 2/3 Ca 1/3 Mn O 3 . The results show that ER decreases with increasing temperature for all samples while R H increases with decreasing temperature. It is found that both silver and indium doping decrease T C , increase J c and enhance pinning force density F p . Silver doped sample shows higher values of J c than indium doped one at low temperatures but lower value at high temperatures.  These results are explained by considering different effects of silver and indium ions on the microstructure as well as their influence on oxygen vacancies concentration. This work was supported by the National Natural Science Foundation of China under Grant No. 50571040. We would like to thank Prof. Y. M. Wu for his help during this research. Abstract: In this study we have prepared two series of La 2/3 Ca 1/3 MnO 3 :Ag and La 2/3 Ca 1/3 MnO3 :In polycrystalline composite materials using solid state reaction method. X-ray powder diffraction patterns confirm single phase formation without any impurity peaks. The structural parameters such as lattice constant, unit cell volume and bond length were calculated from XRD data. The dc magnetization measurements reveal that Curie temperature (Tc), critical current density (Jc) and pinning force density (Fp) decrease with increasing amount of silver or indium content.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Inter comparison of the magneto transport of La2 / 3Ca1 / 3MnO3 : Ag / In polycrystalline composites . Abstract : The impact of silver and indium on the magnetic properties , optical resistivity ( ER ) and Hall coefficient ( R H ) has been investigated in La 2 / 3 Ca 1 / 3 Mn O 3 .The results show that ER decreases with increasing temperature for all specimens while R H increases with varying temperature . It is found that both silver and indium doping decrease T C , enhance J c and enhance pinning power concentration F p .Silver doped specimen shows higher values of J c than indium doped one at low temperatures but smaller value at high temperatures . These data are explained by using separate consequences of silver and indium ions on the microstructure as also as their influence on oxygen vacancies density .This project was supported by the National Natural Science Foundation of China under Grant No . 50571040 .We would like to thank Prof . Y . M . Wu for his help during this research . Abstract : In this study we have formulated two series of La 2 / 3 Ca 1 / 3 MnO 3 : Ag and La 2 / 3 Ca 1 / 3 MnO3 : In polycrystalline composite materials utilizing solid state process method .X - ray powder diffraction patterns indicate single phase composition without any impurity peaks . The structural values such as structure constant , unit cell size and bond length were calculated from XRD information .The dc magnetization measurements reveal that Curie temperature ( Tc ) , vital current density ( Jc ) and pinning power coefficient ( Fp ) decline with varying amount of silver or indium content .",
        "rewrite_text": "Title: Intercomparison of the Magnetotransport Properties of La2/3Ca1/3MnO3: Ag/In Polycrystalline Composites\n\nAbstract: This study investigates the effects of silver (Ag) and indium (In) doping on the magnetic properties, optical resistivity (ER), and Hall coefficient (RH) of La2/3Ca1/3MnO3 polycrystalline composites. The research reveals that the optical resistivity decreases with increasing temperature across all samples, while the Hall coefficient exhibits an increasing trend with temperature variations. Notably, the introduction of both silver and indium leads to a reduction in the Curie temperature (TC), an enhancement in the critical current density (JC), and an increase in the pinning power concentration (Fp). At lower temperatures, the silver-doped samples demonstrate superior critical current density compared to their indium-doped counterparts; however, this trend reverses at elevated temperatures, where indium-doped samples show improved performance. These observations are attributed to the distinct effects of silver and indium ions on the microstructural characteristics of the composites, as well as their influence on the density of oxygen vacancies within the material. \n\nThe synthesis of the La2/3Ca1/3MnO3: Ag and La2/3Ca1/3MnO3: In composites was achieved through a solid-state processing method. X-ray powder diffraction (XRD) analysis confirmed the formation of a single-phase material, devoid of any impurity peaks. Structural parameters, including the structure constant, unit cell dimensions, and bond lengths, were derived from the XRD data. Furthermore, direct current (dc) magnetization measurements indicated that the Curie temperature (TC), critical current density (JC), and pinning power coefficient (Fp) all exhibit a decreasing trend with increasing silver or indium content. This research was supported by the National Natural Science Foundation of China under Grant No. 50571040, and we extend our gratitude to Prof. Y. M. Wu for his invaluable assistance throughout this study.",
        "ori-fast-z-score": 0.4833682445228318,
        "water-fast-z-score": 6.3508529610858835,
        "rewrite-fast-z-score": 1.9755138236055543
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Semiclassical scalar propagators in curved backgrounds: formalism and ambiguities .\nAbstract:\nWe present the results of our investigation on semiclassical scalar propagator in curved space-time, which is based on the WKB approximation to the wave function. We show that there are two different ways how one can define this quantity depending on whether or not one takes into account the back-reaction effects due to the quantum fluctuations of the gravitational field. The first approach leads to an expression for the semiclassical propagator which coincides with the Feynman propagator at large distances but differs significantly near the source point. In particular it does not satisfy the Hadamard condition required by general relativity. On the other hand, if we take into account the back reaction then the resulting expression satisfies all necessary conditions including the Hadamard condition. However, as was shown recently by Wald et al., such an expression cannot be obtained within the framework of standard QFT. This problem may have important consequences when considering the propagation of particles through black holes since the corresponding expressions differ substantially even outside the horizon.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Semiclassical scalar propagators in curved landscapes : formalism and ambiguities . Abstract : We present the conclusion of our inquiry on semiclassical scalar propagator in curved space - time , which is based on the WKB approximation to the wave function .We see that there are two different ways how one can define this quantity varying on whether or not one takes into consideration the back - reaction effects due to the quantum fluctuations of the gravitational field . The first method results to an definition for the semiclassical propagator which coincides with the Feynman propagator at large distances but varies dramatically near the origin point .In particular it does not satisfy the Hadamard condition required by general relativity . On the other hand , if we took into consideration the back response then the resulting expression satisfies all necessary circumstances including the Hadamard condition .However , as was shown lately by Wald et al . , such an expression cannot be obtained within the framework of standard QFT . This problem could have important implications when examining the propagation of particles through black holes since the equivalent definitions differ substantially even outside the horizon .",
        "rewrite_text": "In this article, we explore the semiclassical scalar propagator in curved spacetime, employing the WKB approximation to analyze the wave function. Our investigation reveals two distinct approaches to defining the semiclassical propagator, each influenced by the consideration of back-reaction effects stemming from quantum fluctuations in the gravitational field. The first approach yields a definition that aligns with the Feynman propagator at large distances; however, it diverges significantly near the origin, failing to meet the Hadamard condition mandated by general relativity. In contrast, the second approach incorporates back-reaction effects, resulting in a propagator that adheres to all requisite conditions, including the Hadamard condition. Nevertheless, recent findings by Wald et al. indicate that this expression cannot be derived within the conventional framework of quantum field theory (QFT). This discrepancy raises critical questions regarding the implications for particle propagation in the vicinity of black holes, as the two definitions of the propagator exhibit substantial differences even outside the event horizon. Our findings underscore the complexities inherent in reconciling quantum field theory with general relativity, particularly in curved spacetime scenarios, and highlight the necessity for a deeper understanding of the interplay between quantum fluctuations and gravitational effects. This work contributes to the ongoing discourse on the foundations of quantum gravity and the behavior of quantum fields in non-trivial geometries, paving the way for future research in this intriguing area of theoretical physics.",
        "ori-fast-z-score": 0.10846522890932808,
        "water-fast-z-score": 5.038928913737635,
        "rewrite-fast-z-score": 1.9755138236055543
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Ensemble Learning for Free with Evolutionary Algorithms ? .\nAbstract:\nIn this work, we propose an evolutionary algorithm to evolve ensemble classifiers in the context of multi-class classification problems. The proposed approach is based on the combination of two well-known techniques: genetic algorithms and bagging. We have conducted experiments using several datasets taken from UCI Machine Learning Repository. Our results show that our method outperforms other state-of-the-art methods such as Bagging or Random Forests. In addition, it has been shown that the use of ensembles can improve the performance of single models evolved by Genetic Programming (GP). This fact suggests that GP could be used not only to evolve individual solutions but also to evolve whole ensembles of solutions. Keywords: Ensemble learning, Multi-Class Classification, Genetic Algorithm, Bagging. 1 Introduction Ensembles are collections of multiple base learners whose outputs are combined into one final prediction  1  . They are widely used because they often provide better accuracy than any of their constituent members  2  .\nThe most popular approaches to combine predictions include voting schemes  3  , stacking  4  , boosting  5  , and blending  6  . However, these approaches require some knowledge about how to combine the output of each member of the ensemble  7?   . For example, if there are three classes, then the simplest way would be to assign equal weights to all the classifiers; however, this may lead to poor performance when dealing with imbalanced data  8  . Other more sophisticated ways involve assigning different weights according to the confidence level of each classifier  9  ; however, finding optimal values for those parameters requires additional effort  10  .\nRecently, researchers have started exploring new ways to automatically generate ensembles without requiring prior information  11  . One of them involves combining genetic algorithms  12  and bagging  13  . These two techniques were first applied separately  14, 15  , but later they were integrated together  16  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Ensemble Learning for Free with Evolutionary Algorithms ? .Abstract : In this research , we attempt an phylogenetic algorithm to evolve ensemble classifiers in the context of multi - class classification difficulties . The proposed approach is based on the combination of two well - famous strategies : molecular techniques and bagging .We have done research use multiple datasets taken from UCI Machine Learning Repository . Our results show that our technique outperforms other state - of - the - art methods such as Bagging or Random Forests .In addition , it has been shown that the using of ensembles can boost the performance of single models adapted by Genetic Programming ( GP ) . This fact suggests that GP may be used not only to evolve individual solutions but also to evolve entire ensembles of solutions .Keywords : Ensemble learning , Multi - Class Classification , Genetic Algorithm , Bagging . 1 Introduction Ensembles are collections of multiple base learners whose outputs are united into one finished prediction 1 .They are widely using because they frequently provide better precision than any of their constituent groups 2 . The most popular methods to mix predictions include voting strategies 3 , stacking 4 , boosting 5 , and blending 6 .However , these perspectives need some understanding about how to mix the output of each member of the group 7 ? .For instance , if there are three categories , then the simplest manner might be to give equivalent weights to all the classifiers ; however , this might lead to bad performance when dealing with imbalanced data 8 . Other more sophisticated ways include assigning multiple weights based to the confidence rate of each classifier 9 ; however , finding ideal values for those variables requires added effort 10 .Recently , researchers have started researching new ways to automatically generate ensembles without using prior information 11 . One of them requires merging genetic methods 12 and bagging 13 .These two procedures were first applied separately 14 , 15 , but later they were integrated together 16 .",
        "rewrite_text": "**Title:** Ensemble Learning for Free with Evolutionary Algorithms\n\n**Abstract:** This study explores the application of a phylogenetic algorithm to evolve ensemble classifiers specifically for multi-class classification challenges. Our innovative approach merges two well-established strategies: molecular techniques and bagging. We conducted experiments using a variety of datasets sourced from the UCI Machine Learning Repository. The findings indicate that our method significantly outperforms leading techniques, including Bagging and Random Forests. Furthermore, our research demonstrates that employing ensemble methods can enhance the performance of individual models optimized through Genetic Programming (GP). This observation implies that GP can be effectively utilized not only to evolve singular solutions but also to develop comprehensive ensembles of solutions. \n\nEnsemble learning involves aggregating multiple base learners to produce a unified prediction, which is widely recognized for its ability to achieve higher accuracy than any individual model. Common techniques for combining predictions include voting, stacking, boosting, and blending. However, these methods often require a nuanced understanding of how to effectively integrate the outputs of each base learner. For example, in a scenario with three classes, a straightforward approach might assign equal weights to all classifiers, but this can result in suboptimal performance, particularly in the presence of imbalanced datasets. More advanced strategies involve assigning varying weights based on the confidence levels of each classifier, yet determining the optimal values for these weights can be labor-intensive.\n\nRecently, there has been a growing interest in developing automated methods for generating ensembles without relying on prior information. One promising direction involves the integration of genetic algorithms with bagging techniques. While these methodologies were initially applied independently, recent advancements have successfully combined them, paving the way for more efficient ensemble learning solutions. \n\n**Keywords:** Ensemble learning, Multi-Class Classification, Genetic Algorithm, Bagging.",
        "ori-fast-z-score": -0.6620847108818944,
        "water-fast-z-score": 8.384348352573221,
        "rewrite-fast-z-score": -0.08481889296799709
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Some Comments around The Examples against The Generalized Jacobian Conjecture .\nAbstract:\nIn this note we present some comments on the examples given in  1  and  2  . We show that these examples are not counterexamples to the generalized Jacobian conjecture, as stated by M. Laurent (see  3  ). In fact they do not even contradict the weaker statement made by J.-P. Serre  4  , which is equivalent to the Jacobian conjecture for curves over finite fields. Finally we give an example showing how one can construct counterexamples to the generalized Jacobi conjecture using our method. Let k be any field with char(k) = p > 0. For every integer n ≥ 1 let Xn denote the smooth projective curve defined over k by y n + a1yn−1 + · · · + anny0 = xn+1,\nwhere ai ∈ k * . It was shown by A. N. Parshin  5  that if char(k) = 2 then there exists a positive integer m such that the jacobian variety JacXm has complex multiplication. This implies that the jacobian varieties JacXn have complex multiplication for all integers n ≡ ±1 mod m. If char(k) = 3 it follows from  6  that JacX3 does not have complex multiplication. However, it still remains open whether or not JacX4 has complex multiplication.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Some Comments around The Examples against The Generalized Jacobian Conjecture . Abstract : In this note we present some remarks on the examples given in 1 and 2 .We see that these examples are not counterexamples to the generalized Jacobian conjecture , as described by M . Laurent ( saw 3 ) . In reality they do not even contradict the weaker statement provided by J . - P . Serre 4 , which is analogous to the Jacobian conjecture for curves over arbitrary fields .Finally we give an instance demonstrating how one can build counterexamples to the generalized Jacobi theorem using our technique . Let k be any field with char ( k ) = p > 0 .For every integer n ≥ 1 let Xn represent the smooth projective curve characterized over n by y n + a1yn−1 + · · · + anny0 = xn + 1 , where ai ∈ k * . It was shown by A . N . Parshin 5 that if char ( k ) = 2 then there exists a positive integer m such that the jacobian variety JacXm has complex multiplication .This implies that the jacobian varieties JacXn have complex multiplication for all integers n ≡ ±1 mod m . If char ( k ) = 3 it appears from 6 that JacX3 does not have complex multiplication . However , it still remains open whether or not JacX4 has complex multiplication .",
        "rewrite_text": "**Title:** Some Comments on the Examples Against the Generalized Jacobian Conjecture\n\n**Abstract:** This note provides a critical examination of the examples presented in references 1 and 2, which have been proposed as counterexamples to the generalized Jacobian conjecture. Contrary to the claims made, we argue that these examples do not serve as valid counterexamples, as articulated by M. Laurent in reference 3. Furthermore, we demonstrate that these examples fail to contradict the more lenient assertion put forth by J.-P. Serre in reference 4, which parallels the Jacobian conjecture for curves defined over arbitrary fields. To illustrate our point, we present a method for constructing genuine counterexamples to the generalized Jacobian theorem. We consider a field \\( k \\) with characteristic \\( \\text{char}(k) = p > 0 \\). For each integer \\( n \\geq 1 \\), we define \\( X_n \\) as a smooth projective curve characterized by the equation \\( y^n + a_1 y^{n-1} + \\cdots + a_n y^0 = x^{n+1} \\), where \\( a_i \\in k^* \\). A. N. Parshin, as noted in reference 5, established that if \\( \\text{char}(k) = 2 \\), there exists a positive integer \\( m \\) such that the Jacobian variety \\( \\text{Jac}(X_m) \\) exhibits complex multiplication. This finding implies that the Jacobian varieties \\( \\text{Jac}(X_n) \\) possess complex multiplication for all integers \\( n \\equiv \\pm 1 \\mod m \\). In contrast, for \\( \\text{char}(k) = 3 \\), evidence from reference 6 suggests that \\( \\text{Jac}(X_3) \\) does not exhibit complex multiplication. Nonetheless, the status of whether \\( \\text{Jac}(X_4) \\) possesses complex multiplication remains an open question. This discussion not only clarifies misconceptions surrounding the examples but also contributes to the ongoing exploration of the generalized Jacobian conjecture.",
        "ori-fast-z-score": 0.819288030372914,
        "water-fast-z-score": 4.798687035041354,
        "rewrite-fast-z-score": 0.19069251784911848
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Black Hole Binary Nova Scorpii 1994 (GRO J1655-40): An improved chemical analysis .\nAbstract:\nWe present an improved abundance determination for the black hole binary nova Sco X-1, based on high-resolution optical spectroscopy obtained with UVES at VLT-UT2 in November 2004 and January 2005. The new data are combined with previously published results to derive abundances for CNO elements as well as FeI and FeII lines. We find that our best-fit model is consistent with previous studies within their uncertainties. However, we obtain significantly lower values for carbon and oxygen than those reported by Gies & Bolton (1986) . This discrepancy may be due to differences between the adopted atmospheric models or atomic data used in these two analyses. \n \n Keywords: Black holes - Abundance ratios - X-ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar winds - Mass transfer -X-ray emission - Accretion disks - Novae - Supernovae",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Black Hole Binary Nova Scorpii 1994 ( GRO J1655 - 40 ) : An enhanced chemical analysis . Abstract : We present an updated abundance calculation for the dark hole binary nova Sco X - 1 , using on high - resolution optical spectroscopy achieved with UVES at VLT - UT2 in November 2004 and January 2005 .The revised data are combined with former reported results to derive abundances for CNO compounds as well as FeI and FeII lines . We see that our better - fitting model is compatible with previous research within their uncertainties .However , we obtain significantly reduced estimates for carbon and oxygen than those published by Gies & Bolton ( 1986 ) . This discrepancy may be due to differences between the adopted atmospheric models or atomic data used in these two analyses .Keywords : Black holes - Abundance ratios - X - ray binaries - Spectroscopy - Ultraviolet space observatories - Variability - Velocity fields - Stellar winds - Mass transfer - X - ray radiation - Accretion disks - Novae - Supernovae",
        "rewrite_text": "Title: The Black Hole Binary Nova Scorpii 1994 (GRO J1655-40): An Enhanced Chemical Analysis\n\nAbstract: In this study, we present a comprehensive update on the abundance calculations for the black hole binary system Nova Scorpii X-1, specifically GRO J1655-40, utilizing high-resolution optical spectroscopy obtained with the Ultraviolet and Visual Echelle Spectrograph (UVES) at the Very Large Telescope (VLT) during observations conducted in November 2004 and January 2005. Our analysis integrates the newly acquired data with previously reported findings to derive accurate abundance ratios for carbon, nitrogen, and oxygen (CNO) elements, as well as iron lines (FeI and FeII). The results indicate that our refined model aligns well with earlier studies, remaining consistent within the uncertainties reported. Notably, we observe a significant reduction in the estimated abundances of carbon and oxygen compared to the values published by Gies & Bolton in 1986. This notable discrepancy may stem from variations in the atmospheric models or the atomic data employed in the two analyses, highlighting the importance of methodological approaches in abundance determinations. Our findings contribute to a deeper understanding of the chemical composition of this intriguing binary system and its implications for the study of black holes and their surrounding environments. The keywords associated with this research include black holes, abundance ratios, X-ray binaries, spectroscopy, ultraviolet space observatories, variability, velocity fields, stellar winds, mass transfer, X-ray radiation, accretion disks, novae, and supernovae. This work not only enhances our knowledge of GRO J1655-40 but also serves as a valuable reference for future investigations into the chemical properties of similar astronomical phenomena.",
        "ori-fast-z-score": -1.3438638879193574,
        "water-fast-z-score": 3.9727331518303837,
        "rewrite-fast-z-score": 0.6527533657682196
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the Incidence of C IV Absorbers Along the Sightlines to Gamma-Ray Bursts .\nAbstract:\nWe present new results on the incidence and properties of intervening absorbers along the sightline towards GRB 080913, based on high-resolution spectroscopy obtained with X-shooter at VLT-UT2 (ESO program ID 080.A-9007). We detect two strong absorption systems in the spectrum of this burst, one associated with an intervening galaxy at z = 1.5394 ± 0.0002, and another system at z = 2.084 ± 0.001 that is likely due to a damped Lyman alpha absorber. The latter has been previously detected by Fynbo et al. (2009) using low resolution spectra taken with FORS-2/VLT. Our analysis shows that both these systems are rich in metals, including Si II, Mg II, Fe II, Al III, O I, N V, and possibly also C IV. In addition we find evidence for several weaker metal lines which may be associated with either or both of these systems.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the Incidence of C IV Absorbers Along the Sightlines to Gamma - Ray Bursts . Abstract : We report new data on the incidence and properties of intervening absorbers along the sightline towards GRB 080913 , based on wide - resolution spectroscopy acquired with X - shooter at VLT - UT2 ( ESO program ID 080 . A - 9007 ) .We detect two strong absorption systems in the spectrum of this flash , one linked with an intervening galaxy at z = 1 . 5394 ± 0 . 0002 , and another system at z = 2 . 084 ± 0 . 001 that is probably due to a damped Lyman alpha absorber . The latter has been previously observed by Fynbo et al .( 2009 ) using reduced resolution spectra done with FORS - 2 / VLT . Our study shows that both these systems are rich in metals , notably Si II , Mg II , Fe II , Al III , O I , N V , and maybe also C IV .In addition we find proof for numerous smaller metal lines which may be identified with either or both of these systems .",
        "rewrite_text": "In this article, we present new findings regarding the incidence and characteristics of intervening C IV absorbers along the sightline to Gamma-Ray Burst (GRB) 080913. Our analysis is based on high-resolution spectroscopy obtained using the X-shooter instrument at the VLT-UT2, under the ESO program ID 080.A-9007. We identify two prominent absorption systems in the spectrum associated with this GRB. The first system is associated with an intervening galaxy at a redshift of z = 1.5394 ± 0.0002, while the second system, located at z = 2.084 ± 0.001, is likely attributed to a damped Lyman-alpha absorber. This latter system was previously detected by Fynbo et al. (2009) through lower-resolution spectra obtained with FORS-2/VLT. Our investigation reveals that both absorption systems exhibit a rich metallic composition, with significant detections of elements such as Si II, Mg II, Fe II, Al III, O I, N V, and potentially C IV. Furthermore, we provide evidence for several smaller metal lines that may correspond to either or both of these absorption systems. This study enhances our understanding of the chemical enrichment in the universe and the role of intervening absorbers in the context of gamma-ray bursts, contributing valuable insights into the intergalactic medium and the processes governing metal distribution in cosmic structures.",
        "ori-fast-z-score": -1.952833664712358,
        "water-fast-z-score": 2.840187787218772,
        "rewrite-fast-z-score": -0.10976425998969035
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Infrared spectroscopy of HCOOH in interstellar ice analogues .\nAbstract:\nWe report infrared (IR) spectroscopic studies on the formation and evolution of formic acid, HCOOH, in ices under simulated astrophysical conditions. The experiments were performed by exposing pure water or mixtures of H2O with CH3OH to vacuum ultraviolet radiation at 10 K for different periods up to 100 hours. IR spectra show that the amount of HCOOH increases as a function of irradiation time. We also find evidence for the presence of other species such as CO2, CO, CH4, NH3, H2S, SO2, and OCS. These results are discussed within the context of astrochemical models. Formic acid is one of the most abundant organic molecules found in space. It has been detected towards comets, protostars, and evolved stars. In particular, it was observed in comet 67P/Churyumov-Gerasimenko during its flyby of the Rosetta spacecraft. However, despite this ubiquity, our understanding about how formic acid forms in space remains limited. Here we present laboratory investigations into the formation pathways of formic acid in icy environments using infrared spectroscopy.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Infrared spectroscopy of HCOOH in interstellar ice analogues . Abstract : We report imaging ( IR ) spectroscopic studies on the formation and evolution of formic acid , HCOOH , in ices under simulated astrophysical conditions .The studies were performed by exposing raw water or mixtures of H2O with CH3OH to vacuum ultraviolet radiation at 10 K for different duration up to 100 hours . IR spectra show that the amount of HCOOH changes as a function of irradiation time .We additionally find proof for the presence of other species such as CO2 , CO , CH4 , NH3 , H2S , SO2 , and OCS . These conclusions are discussed within the context of astrochemical models .Formic acid is one of the most numerous organic particles discovered in space . It has been detected towards comets , protostars , and evolved planets .In particular , it was seen in comet 67P / Churyumov - Gerasimenko during its flyby of the Rosetta spacecraft . However , despite this ubiquity , our view about how formic acid forms in space remains restricted .Here we present lab studies into the formation routes of formic acid in icy environments using infrared spectroscopy .",
        "rewrite_text": "We present a comprehensive study on the formation and evolution of formic acid (HCOOH) in interstellar ice analogues through infrared (IR) spectroscopy, conducted under simulated astrophysical conditions. Our experiments involved exposing pure water and various mixtures of H2O and CH3OH to vacuum ultraviolet radiation at a temperature of 10 K for varying durations, extending up to 100 hours. The resulting IR spectra revealed a dynamic change in the concentration of HCOOH as a function of the irradiation time, indicating a complex interplay of chemical processes occurring in these icy environments. In addition to formic acid, we identified the presence of several other molecular species, including CO2, CO, CH4, NH3, H2S, SO2, and OCS, which further enrich our understanding of the chemical landscape in space. These findings are contextualized within existing astrochemical models, highlighting the significance of formic acid as one of the most abundant organic molecules detected in extraterrestrial settings. Its presence has been confirmed in various celestial bodies, including comets, protostars, and evolved planets, with notable observations made during the Rosetta spacecraft's flyby of comet 67P/Churyumov-Gerasimenko. Despite the widespread detection of formic acid, our understanding of its formation pathways in space remains limited. This study aims to bridge that gap by elucidating the laboratory-based formation routes of formic acid in icy matrices, thereby contributing valuable insights into the astrochemical processes that govern the synthesis of organic molecules in the universe.",
        "ori-fast-z-score": 0.35603449745815596,
        "water-fast-z-score": 4.798687035041354,
        "rewrite-fast-z-score": 0.29559878344928797
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Infrared Cloud Monitor for the MAGNUM Robotic Telescope at Haleakala .\nAbstract:\nWe describe an infrared cloud monitor that has been developed to detect clouds in the atmosphere above the Magellan Observatory on Mt. Haleakala, Hawaii. The system uses two near-infrared cameras and is designed to operate continuously during nighttime hours when astronomical observations are made with the telescope. It provides information about the sky conditions over the entire field-of-view (FOV) of the telescope s primary mirror. This information can be used by observers to select targets or to modify their observing strategies accordingly. We present results obtained using this instrumentation since its installation in August 2005. These data show that the atmospheric transparency varies significantly across the FOV of the telescope. For example, we find that the median value of the total integrated water vapor column density measured within one hour of each observation was 0.5 mm H2O for the northern part of the FOV but 1.1 mm H2O for the southern portion. We also demonstrate how these measurements have helped us optimize our observational strategy.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Infrared Cloud Monitor for the MAGNUM Robotic Telescope at Haleakala . Abstract : We denote an infrared cloud monitor that has been created to identify clouds in the atmosphere above the Magellan Observatory on Mt .Haleakala , Hawaii . The system utilizes two near - infrared photographers and is designed to run constantly during nighttime days when scientific measurements are making with the observatory .It provides information about the sky conditions over the entire field - of - view ( FOV ) of the observatory s primary mirror . This knowledge can be used by observers to select locations or to modify their viewing strategies accordingly .We present results acquired using this apparatus since its installation in August 2005 . These data indicate that the atmospheric stability differs greatly across the FOV of the observatory .For instance , we find that the median estimate of the total integrated water vapor column density measured within one hour of each measurement was 0 . 5 mm H2O for the northern part of the FOV but 1 . 1 mm H2O for the southern portion . We additionally prove how these measurements have aided us optimize our observational strategy .",
        "rewrite_text": "Title: The Infrared Cloud Monitor for the MAGNUM Robotic Telescope at Haleakala\n\nAbstract: This article presents the development and implementation of an infrared cloud monitoring system designed to detect cloud cover in the atmosphere above the Magellan Observatory, located on Mt. Haleakala, Hawaii. The innovative system employs two near-infrared cameras and operates continuously during nighttime hours when scientific observations are being conducted at the observatory. By providing real-time data on sky conditions across the entire field of view (FOV) of the observatory's primary mirror, the monitor equips astronomers with critical information that can inform their observational strategies and site selection.\n\nSince its installation in August 2005, the infrared cloud monitor has yielded valuable insights into atmospheric conditions. Our findings reveal significant variations in atmospheric stability across different regions of the FOV. For example, the median total integrated water vapor column density measured within one hour of each observation was found to be 0.5 mm H2O in the northern section of the FOV, contrasting with a higher measurement of 1.1 mm H2O in the southern section. These discrepancies highlight the importance of localized atmospheric data in optimizing observational efforts.\n\nFurthermore, we discuss how the data collected by the infrared cloud monitor has been instrumental in refining our observational strategies. By understanding the spatial distribution of atmospheric conditions, observers can make informed decisions regarding target selection and timing, ultimately enhancing the quality of scientific measurements obtained at the observatory. This study underscores the significance of advanced monitoring systems in astronomical research and their potential to improve observational outcomes in varying atmospheric conditions.",
        "ori-fast-z-score": -1.6464638998453551,
        "water-fast-z-score": 5.237229365663818,
        "rewrite-fast-z-score": 2.1049392463368704
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Scaling Behaviors of Graphene Nanoribbon FETs: A Three Dimensional Quantum Simulation Study .\nAbstract:\nGraphene nanoribbons (GNRs) are promising candidates for future nanoelectronic devices due to their unique electronic properties and high carrier mobility at room temperature. However, the scaling behaviors of GNRFETs have not been fully understood yet because of the difficulty in simulating realistic device structures with atomistic details using conventional approaches such as density functional theory or tight-binding method. In this work, we perform large-scale quantum transport simulations on GNR-FETs by solving the nonequilibrium Green s function equations within an effective mass approximation. We find that the subthreshold swing decreases rapidly when the channel length is reduced below 10 nm while it increases slowly beyond 20 nm. The ON/OFF current ratio also shows similar trends but its value becomes saturated around 100 nm. These results suggest that the optimal channel length should be between 10-20 nm depending on the required performance parameters. Our findings can provide useful guidelines for designing practical graphene-based transistors.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Scaling Behaviors of Graphene Nanoribbon FETs : A Three Dimensional Quantum Simulation Study . Abstract : Graphene nanoribbons ( GNRs ) are promising candidates for future nanoelectronic technologies due to their distinct electronic properties and strong carrier movement at room temperature .However , the scaling interactions of GNRFETs have not been totally understood yet because of the difficulty in simulating realistic device designs with atomistic features using conventional approaches such as density functional theory or tight - binding method . In this research , we perform large - scale quantum travel simulations on GNR - FETs by solving the nonequilibrium Green s function equations within an efficient mass approximation .We see that the subthreshold swing decreases quickly when the channel length is decreased below 10 nm while it rises steadily beyond 20 nm . The ON / OFF current ratio also shows identical trends but its value gets saturated around 100 nm .These conclusions indicated that the ideal network duration should be between 10 - 20 nm depending on the necessary performance parameters . Our findings can provide useful guidelines for constructing practical graphene - based transistors .",
        "rewrite_text": "Title: Scaling Behaviors of Graphene Nanoribbon FETs: A Three-Dimensional Quantum Simulation Study\n\nAbstract: Graphene nanoribbons (GNRs) have emerged as highly promising materials for next-generation nanoelectronic devices, primarily due to their unique electronic characteristics and exceptional carrier mobility at ambient temperatures. Despite their potential, the scaling behaviors of GNR field-effect transistors (GNRFETs) remain inadequately understood, largely due to the challenges associated with simulating realistic device architectures that incorporate atomistic details. Traditional methods, such as density functional theory and tight-binding approaches, often fall short in accurately capturing the complexities of these nanoscale devices. In this study, we employ large-scale quantum transport simulations to investigate the performance of GNRFETs, utilizing the nonequilibrium Green's function formalism within an efficient mass approximation framework. Our results reveal a significant decrease in the subthreshold swing as the channel length is reduced to below 10 nm, while a gradual increase is observed for lengths exceeding 20 nm. Similarly, the ON/OFF current ratio exhibits comparable trends, reaching a saturation point around 100 nm. These findings suggest that the optimal channel length for GNRFETs lies within the range of 10 to 20 nm, contingent upon the desired performance metrics. This research provides critical insights and practical guidelines for the design and fabrication of graphene-based transistors, paving the way for advancements in nanoelectronics and the development of high-performance devices.",
        "ori-fast-z-score": 0.42640143271122083,
        "water-fast-z-score": 5.270462766947299,
        "rewrite-fast-z-score": -1.3598002073001698
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  3-He in the Milky Way Interstellar Medium: Ionization Structure .\nAbstract:\nWe present new measurements of 3 He+ and 3 He++ column densities toward eight nearby stars, using data obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE). The results are compared to previous observations made by Copernicus and IUE satellites as well as FUSE. We find that our values for N(3 He+)/N(H+), which range between 0.0015-0.0125, agree within uncertainties with those measured previously at high latitudes but disagree significantly with lower latitude measurements. Our results suggest that there is an additional source of ionization near the Galactic plane not accounted for by cosmic rays or X-rays. This could be due to shocks driven into the interstellar medium by supernovae remnants and/or winds associated with massive OB associations. \n \n Keywords: Helium abundance, Interstellar medium, Shocks, Supernova remnant, Winds, Cosmic ray",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : 3 - He in the Milky Way Interstellar Medium : Ionization Structure . Abstract : We report new measurements of 3 He + and 3 He + + column densities toward eight distant stars , using data acquired with the Far Ultraviolet Spectroscopic Explorer ( FUSE ) .The results are compared to previous measurement made by Copernicus and IUE satellites as well as FUSE . We see that our values for N ( 3 He + ) / N ( H + ) , which range between 0 . 0015 - 0 . 0125 , agree within uncertainties with those observed previously at high latitudes but disagree significantly with higher latitude observations .Our results propose that there is an additional source of ionization near the Galactic jet not accounted for by cosmic rays or X - radiation . This might be due to shocks driven into the interstellar medium by supernovae fragments and / or winds related with massive OB associations .Keywords : Helium abundance , Interstellar medium , Shocks , Supernova remnant , Winds , Cosmic ray",
        "rewrite_text": "**Title:** 3-He in the Milky Way Interstellar Medium: Ionization Structure\n\n**Abstract:** In this study, we present new measurements of the column densities of 3 He + and 3 He + + towards eight distant stars, utilizing data obtained from the Far Ultraviolet Spectroscopic Explorer (FUSE). Our findings are compared with earlier measurements conducted by the Copernicus and IUE satellites, as well as previous FUSE data. The ratios of N(3 He +) to N(H +) that we have determined range from 0.0015 to 0.0125. These values are consistent with previous observations made at high latitudes, but they exhibit significant discrepancies when compared to measurements taken at higher latitudes. Our results suggest the presence of an additional ionization source in proximity to the Galactic jet, which has not been adequately explained by existing models that attribute ionization primarily to cosmic rays or X-radiation. We propose that this additional ionization may be a consequence of shocks induced in the interstellar medium by supernova remnants and/or stellar winds associated with massive OB star groups. This research enhances our understanding of the ionization structure within the Milky Way's interstellar medium and highlights the complex interactions that contribute to the observed helium abundance. Our findings have implications for the broader study of cosmic processes and the dynamics of the interstellar medium, particularly in relation to the influence of supernovae and stellar winds on ionization levels. \n\n**Keywords:** Helium abundance, Interstellar medium, Shocks, Supernova remnants, Winds, Cosmic rays.",
        "ori-fast-z-score": -0.9271726499455306,
        "water-fast-z-score": 3.4139672543527864,
        "rewrite-fast-z-score": 0.20628424925175867
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  In-medium effects on particle production in heavy ion collisions .\nAbstract:\nWe present the results for charged hadron multiplicity density and transverse momentum fluctuations obtained by using the AMPT model with string melting mechanism at RHIC energies. The effect of initial parton distribution is studied by varying the initial temperature T0, which controls the initial entropy content of the system. We find that both the mean value and fluctuation of the multiplicity density increase as we decrease the initial temperature T0. This indicates that the initial state fluctuations play an important role in determining the final observables. It has been observed experimentally that the ratio of variance to mean square (V /M) increases with decreasing beam energy. In our study also it is found that V /M decreases with increasing initial temperature T0. However, this trend changes when we include the contribution due to resonance decays. Finally, we have calculated the scaled variances S2/S1 and S3/S2 for different values of T0.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : In - medium impacts on particle production in heavy ion collisions . Abstract : We present the results for charged hadron multiplicity density and transverse energy fluctuations derived by using the AMPT theory with string melting system at RHIC intensity .The impact of initial parton distribution is studied by varying the initial temperature T0 , which changes the early entropy concentration of the system . We see that both the mean value and fluctuation of the multiplicity density increase as we decrease the initial temperature T0 .This implies that the first state fluctuations play an important role in determining the finished observables . It has been observed experimentally that the proportion of variance to mean square ( V / M ) changes with decreasing beam energy .In our research also it is found that V / M decreases with increasing initial temperature T0 . However , this decline changes when we include the contribution owing to resonance decays .Finally , we have adjusted the scaled variances S2 / S1 and S3 / S2 for different values of T0 .",
        "rewrite_text": "We present a comprehensive analysis of charged hadron multiplicity density and transverse energy fluctuations in heavy ion collisions, utilizing the AMPT (A Multi-Phase Transport) model with a string melting approach at the intensity levels achieved at the Relativistic Heavy Ion Collider (RHIC). Our investigation focuses on the influence of the initial parton distribution by systematically varying the initial temperature \\( T_0 \\), which in turn alters the early entropy concentration within the system. Our findings reveal that both the average multiplicity density and its fluctuations exhibit an increase as the initial temperature \\( T_0 \\) is reduced. This observation underscores the significant role that initial state fluctuations play in shaping the final observables measured in experiments.\n\nFurthermore, we have noted a correlation between the variance-to-mean square ratio (V/M) and beam energy, where experimental data indicate that V/M decreases with lower beam energies. Our simulations corroborate this trend, demonstrating that V/M diminishes as the initial temperature \\( T_0 \\) rises. Notably, this decline in V/M is modified when we account for contributions from resonance decays, highlighting the complexity of particle production mechanisms in heavy ion collisions.\n\nTo further elucidate these dynamics, we have computed the scaled variances \\( S_2/S_1 \\) and \\( S_3/S_2 \\) for various values of \\( T_0 \\). These metrics provide deeper insights into the fluctuations of particle production and their dependence on the initial conditions of the collision system. Our results contribute to a better understanding of the underlying physics governing particle production in heavy ion collisions and the role of medium effects in these high-energy environments.",
        "ori-fast-z-score": -1.5652475842498528,
        "water-fast-z-score": 3.2222222222222223,
        "rewrite-fast-z-score": 0.1889822365046136
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  How to find neutral leptons of the nuMSM? .\nAbstract:\nThe Minimal Supersymmetric Standard Model (nuMSM) is an extension of the SM with three right-handed neutrinos and one additional Higgs doublet, which can explain simultaneously all known phenomena in particle physics. In this model there are two new particles - neutral leptons N_1 and N_2 that have not been observed yet experimentally. The aim of our work was to study possible production mechanisms for these particles at LHC energies. \nWe considered pair production of neutral leptons via Drell-Yan mechanism as well as single production through s-channel W-boson exchange or t-channel chargino/neutralino exchanges. We performed numerical calculations using CalcHEP package. \n \n For the case of pair production we found that cross sections decrease rapidly when masses of neutral leptons increase. This fact makes it difficult to detect such particles at LHC experiments even if their mass difference is small. On the other hand, single production processes give much higher values of cross section than those obtained for pair production. However, they also depend strongly on the value of mixing angle between left- and righthanded neutrinos.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  How to find neutral leptons of the nuMSM?.Abstract : The Minimal Supersymmetric Standard Model ( nuMSM ) is an extension of the SM with three right - handed neutrinos and one additional Higgs doublet , which can describe concurrently all known phenomena in particle physics . In this model there are two new objects - neutral leptons N _ 1 and N _ 2 that have not been observed yet experimentally .The goal of our work was to study possible generation pathways for these particles at LHC energies . We considered pair production of neutral leptons via Drell - Yan system as also as single production through s - channel W - boson exchange or t - channel chargino / neutralino exchanges .We conducted numerical measurements using CalcHEP package . For the case of pair production we reported that cross sections decrease rapidly when masses of neutral leptons increase .This fact makes it difficult to identify such particles at LHC observations even if their mass gap is tiny . On the other hand , single production mechanisms offer significantly greater values of cross section than those achieved for pair production .However , they still depend greatly on the value of mixing angle between left - and righthanded neutrinos .",
        "rewrite_text": "Title: Exploring the Discovery of Neutral Leptons in the nuMSM Framework\n\nAbstract: The Minimal Supersymmetric Standard Model (nuMSM) serves as an extension of the Standard Model (SM) by incorporating three right-handed neutrinos and an additional Higgs doublet, thereby providing a comprehensive framework to explain various phenomena in particle physics. Within this model, two new particles, the neutral leptons N_1 and N_2, remain unobserved in experimental settings. This study aims to investigate potential production mechanisms for these elusive particles at the Large Hadron Collider (LHC) energies. We analyzed both pair production of neutral leptons through the Drell-Yan process and single production via s-channel W-boson exchange or t-channel chargino/neutralino exchanges. Utilizing the CalcHEP software package for numerical simulations, we found that the cross sections for pair production diminish significantly as the masses of the neutral leptons increase. This rapid decrease poses a challenge for their detection at the LHC, even in scenarios where the mass difference is minimal. Conversely, the single production mechanisms yield considerably higher cross sections compared to pair production, enhancing the prospects for detection. However, the effectiveness of these single production processes is heavily influenced by the mixing angle between left- and right-handed neutrinos, which plays a crucial role in determining the production rates. Our findings underscore the complexities involved in identifying neutral leptons within the nuMSM framework and highlight the importance of further research to optimize detection strategies at high-energy particle colliders. This work contributes to the ongoing efforts to uncover new physics beyond the Standard Model and to enhance our understanding of the fundamental constituents of matter.",
        "ori-fast-z-score": 0.41702882811414954,
        "water-fast-z-score": 4.538253483538691,
        "rewrite-fast-z-score": 1.2780193008453875
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Weight structures vs. $t$-structures; weight filtrations, spectral sequences, and complexes (for motives and in general) .\nAbstract:\nThe purpose of this article is to give an overview of the theory of weight structures on triangulated categories developed by A. Bondal and M. Kapranov.  We will explain how it can be applied to construct new cohomology theories for algebraic varieties over finite fields or number fields.   In particular we will discuss the construction of motivic cohomology using weight structures on derived categories of mixed Tate motives.    The main results are due to J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, and others. This article was written as part of the author s Ph.D thesis at Utrecht University under supervision of Prof. Dr. Wim van der Kallen. It has been published online by the author with permission of the supervisor. For more information about the content see the introduction below.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Weight systems vs . $ t $ - systems ; weight filtrations , spectral patterns , and complexes ( for motives and in general ) . Abstract : The purpose of this page is to give an overview of the notion of weight forms on triangulated categories pioneered by A . Bondal and M . Kapranov .We will explain how it can be applied to build new cohomology theories for algebraic fields over finite fields or number fields . In particular we will explore the creation of motivic cohomology involving weight forms on derived categories of mixed Tate motives .The main results are due to J . Ayoub , D . Gaitsgory , R . Hain , S . Katzarkov , V . Lafforgue , C . Soulé , B . Stienstra , and others . This page was written as part of the writer s Ph . D thesis at Utrecht University under supervision of Prof . Dr . Wim van der Kallen .It has been publication online by the writer with authorization of the supervisor . For more information about the content read the introduction below .",
        "rewrite_text": "This document provides a comprehensive overview of the concept of weight forms within triangulated categories, a framework initially developed by A. Bondal and M. Kapranov. The discussion focuses on the application of these weight forms to formulate new cohomology theories pertinent to algebraic fields, specifically those defined over finite fields or number fields. A significant aspect of this exploration is the development of motivic cohomology, which incorporates weight forms on derived categories of mixed Tate motives. The foundational results presented in this work are attributed to the contributions of notable mathematicians, including J. Ayoub, D. Gaitsgory, R. Hain, S. Katzarkov, V. Lafforgue, C. Soulé, B. Stienstra, among others. This document is part of the author's Ph.D. thesis at Utrecht University, conducted under the guidance of Prof. Dr. Wim van der Kallen. The author has published this work online with the supervisor's consent. For further insights into the subject matter, readers are encouraged to consult the introduction provided below.",
        "ori-fast-z-score": -0.4923659639173309,
        "water-fast-z-score": 4.608176875690327,
        "rewrite-fast-z-score": 0.8551861104941365
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Asteroid Deflection: How, where and when? .\nAbstract:\nThe possibility that an asteroid could hit the Earth is not new.  In fact, it has been discussed for many years in popular science fiction books such as H G Wells  The War of the Worlds (1898) or Arthur C Clarke s 2001 Space Odyssey (1968). However, there are now several groups around the world working on ways to deflect asteroids before they impact with our planet.   This talk will discuss how this might be achieved by using nuclear explosions, kinetic impacts, laser beams or even tractor beams. It will also look at what would happen if one were successful - would we survive?  Would life return to normal?\nThis talk was given at the University of Southampton on 24th February 2015. For more information about Prof David Jewitt please visit his website: http://www.astro.su.se/~david/ . \nProf David Jewitt is Professor of Planetary Science at the University of Southampton. He leads the Asteroid Terrestrial-impact Last Alert System (ATLAS), which monitors near-Earth objects including asteroids and comets.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Asteroid Deflection: How, where and when?.Abstract : The possibility that an asteroid could struck the Earth is not new . In reality , it has been discussed for numerous years in popular science novel publications such as H G Wells The War of the Worlds ( 1898 ) or Arthur C Clarke s 2001 Space Odyssey ( 1968 ) .However , there are now various groups around the world thinking on ideas to deflect asteroids before they impact with our planet . This discussion will explore how this might be accomplish by using nuclear explosions , kinetic impacts , laser beams or maybe tractor beams .It will also glance at what would happen if one were successful - would we survive ? Would life recover to normal ?This discussion was given at the University of Southampton on 24th February 2015 . For more information about Prof David Jewitt please visit his page : www : / / www . astro . su . se / ~ david / .Prof David Jewitt is Professor of Planetary Science at the University of Southampton . He leads the Asteroid Terrestrial - impact Last Alert System ( ATLAS ) , which monitors near - Earth objects including asteroids and comets .",
        "rewrite_text": "Title: Asteroid Deflection: How, Where, and When?\n\nAbstract: The threat of an asteroid colliding with Earth is a longstanding concern that has been featured in various works of popular science fiction, such as H.G. Wells' \"The War of the Worlds\" (1898) and Arthur C. Clarke's \"2001: A Space Odyssey\" (1968). In recent years, however, this topic has gained significant attention from scientific communities worldwide, leading to the development of innovative strategies aimed at deflecting asteroids before they can impact our planet. This article delves into the various methodologies proposed for asteroid deflection, including the use of nuclear explosions, kinetic impactors, laser beams, and even theoretical concepts like tractor beams. Each of these techniques presents unique challenges and potential outcomes, warranting a thorough examination of their feasibility and effectiveness.\n\nFurthermore, the discussion will address the implications of successfully deflecting an asteroid. Questions arise regarding the potential survival of life on Earth post-deflection and whether ecosystems would return to their pre-impact states. The insights presented in this article are based on a talk delivered by Professor David Jewitt at the University of Southampton on February 24, 2015. Professor Jewitt is a leading figure in planetary science and heads the Asteroid Terrestrial-impact Last Alert System (ATLAS), which is dedicated to monitoring near-Earth objects, including asteroids and comets. For further information about his work and contributions to the field, please visit his webpage at www.astro.su.se/~david/. This exploration of asteroid deflection not only highlights the urgency of addressing potential threats from space but also underscores the collaborative efforts of scientists to safeguard our planet's future.",
        "ori-fast-z-score": -0.9561828874675149,
        "water-fast-z-score": 4.153735803678487,
        "rewrite-fast-z-score": -1.044073795327749
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The LuckyCam Survey for Very Low Mass Binaries II: 13 new M4.5-M6.0 Binaries .\nAbstract:\nWe present the results of our second survey to find very low mass binaries using lucky imaging with the Palomar Observatory 1.2 m telescope and the PALM-3000 camera. We have discovered thirteen new systems, including ten brown dwarf companions (four previously unknown) in twelve nearby young open clusters ranging in age between 10 Myr and 300 Myr. The masses range from 0.03-0.10 M . These are among the lowest-mass objects ever found by direct imaging techniques. In addition we report on one system that is likely an unresolved binary consisting of two late-type stars. This work represents the largest sample of directly imaged brown dwarfs assembled so far. It will be used as input into population synthesis models aimed at understanding how these objects form and evolve over time. \n \n Keywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The LuckyCam Survey for Very Low Mass Binaries II : 13 new M4 . 5 - M6 . 0 Binaries . Abstract : We present the results of our second survey to find very low mass binaries using lucky imaging with the Palomar Observatory 1 . 2 m observatory and the PALM - 3000 sensor .We have discovered thirteen new components , notably ten brown dwarf companions ( four originally unknown ) in twelve nearby young open complexes ranging in age between 10 Myr and 300 Myr . The masses range from 0 . 03 - 0 . 10 M .These are among the smallest - weight objects ever found by direct imaging technology . In addition we paper on one system that is probably an unresolved binary composed of two late - class stars .This project represents the largest sample of specifically imaged brown dwarfs assembled so far . It will be used as input into population analysis models targeted at explaining how these objects formation and evolve over time .Keywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars",
        "rewrite_text": "Title: The LuckyCam Survey for Very Low Mass Binaries II: Discovery of 13 New M4.5 - M6.0 Binaries\n\nAbstract: In this study, we report the findings from our second survey aimed at identifying very low mass binaries through the application of lucky imaging techniques at the Palomar Observatory utilizing the 1.2 m telescope and the PALM-3000 sensor. Our efforts have led to the identification of thirteen new binary components, which include ten brown dwarf companions, four of which were previously unknown. These discoveries were made within twelve nearby young open clusters, with ages ranging from 10 million years to 300 million years. The masses of the newly identified companions fall within the range of 0.03 to 0.10 solar masses, marking them as some of the lightest objects detected using direct imaging methods to date. Additionally, we discuss one particular system that is likely an unresolved binary consisting of two late-type stars. This survey contributes the largest collection of directly imaged brown dwarfs compiled thus far, providing valuable data for future population analysis models. These models aim to enhance our understanding of the formation and evolutionary processes of these intriguing celestial objects. The implications of our findings extend to the broader context of stellar formation and the dynamics of low mass binaries in young stellar environments. \n\nKeywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars",
        "ori-fast-z-score": -1.2701705922171767,
        "water-fast-z-score": 4.358898943540673,
        "rewrite-fast-z-score": -2.4397501823713332
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  k-dependent SU(4) model of high-temperature superconductivity and its coherent-state solutions .\nAbstract:\nWe present the results for the k-dependent SU(4) Hubbard model in two dimensions at half-filling, which is known to be equivalent to the t-J model with J = 4t2/U . We solve this problem by using the method developed recently by one of us (S.M.) based on the exact diagonalization combined with the density-matrix renormalization group technique. The ground state phase diagram obtained shows that there are three phases; antiferromagnetic insulator, d-wave superconductor, and ferromagnetically ordered metal. In particular we find that the d-wave superconducting region becomes larger as U increases. This result suggests that the strong-coupling limit may give rise to an exotic pairing mechanism different from the weak-coupling BCS theory. Finally we discuss possible relevance of our results to the cuprate hightemperature superconductors. PACS: 71.10.Fd",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : k - dependent SU ( 4 ) model of high - temperature superconductivity and its coherent - state solutions . Abstract : We present the results for the k - dependent SU ( 4 ) Hubbard theory in two dimensions at half - filling , which is known to be analogous to the t - J model with J = 4t2 / U .We answer this question by using the method developed ago by one of us ( S . M . ) based on the exact diagonalization combined with the density - vector renormalization group technique .The ground state phase diagram obtained shows that there are three stages ; antiferromagnetic insulator , d - wave superconductor , and ferromagnetically ordered metal . In particular we find that the d - wave superconducting area gets wider as U rises .This result suggests that the strong - coupling limitation would give rise to an exotic pairing structure different from the strong - coupling BCS theory . Finally we explain possible relevance of our findings to the cuprate hightemperature superconductors .PACS: 71.10.Fd",
        "rewrite_text": "Title: k-Dependent SU(4) Model of High-Temperature Superconductivity and Its Coherent-State Solutions\n\nAbstract: In this study, we investigate the k-dependent SU(4) Hubbard model in two-dimensional systems at half-filling, which exhibits similarities to the t-J model with the parameterization J = 4t²/U. Utilizing a methodology previously established by one of the authors (S. M.), we employ exact diagonalization in conjunction with the density-vector renormalization group technique to derive our results. The resulting ground state phase diagram reveals three distinct phases: an antiferromagnetic insulator, a d-wave superconductor, and a ferromagnetically ordered metal. Notably, our findings indicate that the region corresponding to d-wave superconductivity expands with increasing values of U. This observation implies that in the strong-coupling limit, the system may exhibit an unconventional pairing mechanism that diverges from the traditional strong-coupling Bardeen-Cooper-Schrieffer (BCS) theory. We also discuss the implications of our results in the context of cuprate high-temperature superconductors, suggesting potential avenues for further research in understanding the complex phenomena associated with high-temperature superconductivity. Our work contributes to the ongoing exploration of the mechanisms underlying superconductivity in strongly correlated electron systems, highlighting the significance of the SU(4) framework in elucidating the rich phase behavior of these materials. PACS: 71.10.Fd",
        "ori-fast-z-score": 0.11547005383792514,
        "water-fast-z-score": 4.588314677411235,
        "rewrite-fast-z-score": -1.0314212462587933
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Two-dimensional defect modes in optically induced photonic lattices .\nAbstract:\nWe report on the observation and characterization of two-dimensional defect modes in optically-induced photonic crystals (OIPCs). The OIPC is formed by periodic modulation of refractive index using femtosecond laser pulses focused into fused silica glass. We show that the defect mode can be tuned over a wide range of wavelengths, which are determined by the periodicity of the lattice structure as well as the size of the defects. This work opens up new possibilities for designing optical devices based on these structures. \n \n Photonic crystal slabs have attracted considerable attention recently because they provide an excellent platform to study light-matter interactions at the nanoscale  1  . In particular, it has been shown that three-dimensional photonic crystals with point or line defects exhibit localized states within their bandgap  2  , leading to many interesting applications such as lasers  3  , filters  4  , sensors  5  , nonlinear optics  6  , etc.. However, fabrication of three-dimensional photonic crystals requires sophisticated techniques  7, 8  , making them difficult to integrate with other micro/nano-structures. Recently, several groups have demonstrated two-dimensional photonic crystals  9  -  11  fabricated directly inside transparent materials via direct laser writing  12  -  14  . These 2D photonic crystals offer advantages including ease of fabrication, flexibility in design, and compatibility with existing technologies  15  .\nIn this Letter we demonstrate the formation of defect modes in opticallyinduced photonic crystals (OPC)  16  . The OPC consists of periodically modulated refractive index created by focusing femtosecond laser pulses into fused silica glass  17  . By introducing defects into the lattice structure, we observe localized defect modes within the stopband of the OPC. Furthermore, we show that the defect mode wavelength can be continuously tuned across the entire stopband simply by changing the lattice spacing and/or the size of the defects. \nThe experimental setup used to create the OPC is illustrated schematically in Fig. 1(a) . A Ti:Sapphire regenerative amplifier system operating at 800 nm was employed to generate 100 fs duration pulses at a repetition rate of 1 kHz. The beam diameter after passing through a spatial filter",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Two - dimensional defect modes in optically induced photonic lattices . Abstract : We report on the observation and description of two - dimensional defect modes in optically - induced photonic crystals ( OIPCs ) .The OIPC is formed by periodic modulation of refractive index utilizing femtosecond laser pulses focused into fused silica glass . We see that the defect mode can be tuned over a broad variety of wavelengths , which are chosen by the periodicity of the lattice structure as well as the height of the flaws .This research raises up new possibilities for constructing optical applications based on these structures . Photonic crystal slabs have garnered considerable interest lately because they give an excellent platform to study light - matter molecules at the nanoscale 1 .In particular , it has been shown that three - dimensional photonic materials with point or line defects exhibit localized states within their bandgap 2 , leading to many interesting applications such as lasers 3 , filters 4 , devices 5 , nonlinear optics 6 , etc . . However , fabrication of three - dimensional photonic materials demands sophisticated techniques 7 , 8 , making them harder to integrate with other micro / nano - materials .Recently , various groups have demonstrated two - dimensional photonic materials 9 - 11 fabricated directly inside transparent materials via continuous laser writing 12 - 14 . These 2D photonic materials provide advantages including ease of fabrication , ease in design , and compatibility with existing devices 15 .In this Letter we prove the formation of defect modes in opticallyinduced photonic crystals ( OPC ) 16 . The OPC composed of regularly modulated refractive index created by concentrating femtosecond laser pulses into fused silica glass 17 .By introducing defects into the lattice structure , we determine localized failure modes within the stopband of the OPC . Furthermore , we find that the defect mode wavelength can be continuously tuned across the entire stopband simply by varying the crystal spacing and / or the height of the flaws .The experimental setup used to create the OPC is depicted schematically in Fig . 1 ( a ) .A Ti : Sapphire regenerative amplifier system functioning at 800 nm was employed to produce 100 fs duration pulses at a repetition rate of 1 kHz . The pulse diameter after passing through a spatial filter",
        "rewrite_text": "We present a comprehensive study on the emergence and characterization of two-dimensional defect modes within optically-induced photonic crystals (OIPCs). These structures are created through the periodic modulation of the refractive index, achieved by focusing femtosecond laser pulses into fused silica glass. Our findings reveal that the defect modes can be finely tuned across a wide range of wavelengths, determined by both the periodicity of the lattice and the dimensions of the introduced defects. This research opens up new avenues for the development of optical applications utilizing these innovative structures.\n\nPhotonic crystal slabs have recently attracted significant attention due to their potential as platforms for investigating light-matter interactions at the nanoscale. Previous studies have demonstrated that three-dimensional photonic materials, which incorporate point or line defects, can support localized states within their bandgap. These localized states have led to a variety of applications, including lasers, filters, and devices for nonlinear optics. However, the fabrication of three-dimensional photonic structures often requires complex techniques, which complicates their integration with other micro- and nano-materials.\n\nIn contrast, recent advancements have enabled the creation of two-dimensional photonic materials directly within transparent substrates using continuous laser writing methods. These 2D structures offer several advantages, such as simplified fabrication processes, ease of design, and compatibility with existing technologies. In this letter, we demonstrate the successful formation of defect modes in OIPCs, which are characterized by a regularly modulated refractive index resulting from the focused femtosecond laser pulses.\n\nBy strategically introducing defects into the lattice, we identify localized failure modes that exist within the stopband of the OIPC. Notably, we observe that the wavelength of the defect modes can be continuously adjusted throughout the entire stopband by varying the spacing of the crystal or the height of the defects. The experimental setup utilized for the creation of the OIPC is illustrated in the accompanying figure, showcasing a Ti:Sapphire regenerative amplifier system operating at 800 nm, which generates 100 fs duration pulses at a repetition rate of 1 kHz. This work not only enhances our understanding of defect modes in photonic lattices but also paves the way for future optical technologies based on these versatile structures.",
        "ori-fast-z-score": -0.3104602102825331,
        "water-fast-z-score": 6.887026769553818,
        "rewrite-fast-z-score": 1.1470786693528088
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Design of Parallel Kinematic Machine Tools Using Kinetostatic Performance Criteria .\nAbstract:\nThe design and kinematics analysis of parallel kinematic machine tools (PKMTs) is presented in this work using kinetic-static performance criteria. The proposed approach considers the dynamic behavior of PKMTs during their operation, which has been neglected by previous works on PKMTs. In addition to the static stiffness matrix, the inertia properties are also considered for the evaluation of the overall dynamic response of PKMTs. A new method based on the concept of virtual joints is developed to calculate the mass distribution along each leg of the PKMT under consideration. This information can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis. Finally, two different PKMTs with three degrees-of-freedom per joint are designed and analyzed using the proposed methodology. It was found that the first PKMT exhibits better dynamic characteristics than its counterpart due to its lower natural frequencies and higher damping ratios.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Design of Parallel Kinematic Machine Tools Using Kinetostatic Performance Criteria . Abstract : The design and kinematics analysis of parallel kinematic machine tools ( PKMTs ) is given in this project using kinetic - static efficiency standards .The proposed approach treats the dynamic behavior of PKMTs during their operation , which has been neglected by earlier works on PKMTs . In addition to the static stiffness matrix , the inertia characteristics are also considered for the evaluation of the overall dynamic response of PKMTs .A modern algorithm based on the idea of virtual joints is developed to estimate the mass distribution along each leg of the PKMT under consideration . This knowledge can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis .Finally , two different PKMTs with three degrees - of - independence per joint are built and evaluated using the suggested methodology . It was shown that the first PKMT displays better stability characteristics than its predecessor due to its lower natural bandwidth and larger damping ratios .",
        "rewrite_text": "Title: The Design of Parallel Kinematic Machine Tools Using Kinetostatic Performance Criteria\n\nAbstract: This article presents a comprehensive study on the design and kinematic analysis of parallel kinematic machine tools (PKMTs), employing kinetostatic performance criteria as a foundational framework. Unlike previous research that primarily focused on static characteristics, this work emphasizes the dynamic behavior of PKMTs during operation, addressing a significant gap in the literature. The analysis incorporates both the static stiffness matrix and inertia properties to assess the overall dynamic response of these machines. \n\nA novel algorithm, inspired by the concept of virtual joints, is introduced to accurately estimate the mass distribution along each leg of the PKMTs under investigation. This mass distribution data serves as a crucial input for subsequent dynamic analyses, including modal and harmonic vibration assessments. The methodology is applied to two distinct PKMT designs, each featuring three degrees of freedom per joint. \n\nThe evaluation reveals that the first PKMT exhibits superior stability characteristics compared to its predecessor, attributed to its reduced natural frequency bandwidth and enhanced damping ratios. This finding underscores the importance of considering dynamic performance in the design of PKMTs, paving the way for more efficient and reliable machine tools in various applications. The results not only contribute to the theoretical understanding of PKMT dynamics but also offer practical insights for engineers and designers aiming to optimize the performance of these advanced machine tools.",
        "ori-fast-z-score": 1.1043152607484654,
        "water-fast-z-score": 6.110100926607787,
        "rewrite-fast-z-score": -0.2773500981126145
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stellar kinematics in the remote Leo II dwarf spheroidal galaxy -- Another brick in the wall .\nAbstract:\nWe present new spectroscopic observations for eight red giant stars in the nearby dwarf spheroidal galaxy, Leo II (D = 3 Mpc). The data were obtained with the Keck telescope and HIRES spectrograph over three nights during August 2005. We measure heliocentric radial velocities ranging between -150 to +50 km/sec. These values are consistent with previous measurements made by other authors using different techniques. Using these new data we have determined that there is no significant rotation or streaming motion within this system. This result supports theoretical predictions based on N-body simulations which suggest that dark matter halos should be nearly spherical systems. In addition, our results provide further evidence against the possibility that Leo II may contain an intermediate mass black hole at its center. \n \n Keywords: Dwarf galaxies; Black holes; Dark Matter Halos; Rotation Curves; Stellar Kinematics; Spherical Symmetry",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stellar kinematics in the distant Leo II dwarf spheroidal galaxy - - Another brick in the wall . Abstract : We report new spectroscopic observations for eight red giant galaxies in the nearby dwarf spheroidal galaxy , Leo II ( D = 3 Mpc ) .The data were obtained with the Keck camera and HIRES spectrograph over three nights during August 2005 . We determine heliocentric radial velocities ranging between - 150 to + 50 km / sec .These values are compatible with previous measurements made by other researchers using different methods . Using these new data we have concluded that there is no considerable rotation or streaming motion within this system .This result provides theoretical estimates based on N - bodies simulations which propose that dark matter halos should be nearly spherical systems . In addition , our findings provide further evidence against the idea that Leo II may contain an intermediate mass black hole at its core .Keywords: Dwarf galaxies; Black holes; Dark Matter Halos; Rotation Curves; Stellar Kinematics; Spherical Symmetry",
        "rewrite_text": "Title: Stellar Kinematics in the Distant Leo II Dwarf Spheroidal Galaxy - Another Brick in the Wall\n\nAbstract: In this study, we present new spectroscopic observations of eight red giant stars within the nearby dwarf spheroidal galaxy, Leo II, located at a distance of approximately 3 Mpc. The observations were conducted using the Keck Observatory's camera and HIRES spectrograph over three nights in August 2005. Our analysis yielded heliocentric radial velocities that range from -150 to +50 km/s, which align well with previous measurements obtained through various methodologies by other researchers. Notably, our findings indicate a lack of significant rotation or streaming motions within the Leo II system. This observation supports theoretical predictions derived from N-body simulations, which suggest that dark matter halos are predominantly spherical in shape. Furthermore, our results contribute to the growing body of evidence against the hypothesis that Leo II harbors an intermediate-mass black hole at its center. This research enhances our understanding of the stellar kinematics in dwarf galaxies and their dark matter distributions, reinforcing the notion of spherical symmetry in dark matter halos. The implications of these findings are crucial for the broader context of galaxy formation and evolution, particularly in the study of dwarf galaxies and their role in the cosmic structure. \n\nKeywords: Dwarf galaxies; Black holes; Dark Matter Halos; Rotation Curves; Stellar Kinematics; Spherical Symmetry.",
        "ori-fast-z-score": 0.9428090415820635,
        "water-fast-z-score": 5.500933918218137,
        "rewrite-fast-z-score": 1.5724272550828775
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stochastic fluctuations in metabolic pathways .\nAbstract:\nThe authors present an analysis of the stochasticity inherent to biochemical reactions, and its effects on metabolic networks. They show that this noise can be reduced by increasing enzyme concentrations or decreasing reaction rates; however, these strategies are limited because they may lead to other undesirable consequences such as increased production costs for enzymes or decreased growth rate due to slower metabolism. The authors also discuss how their results could help explain why some organisms have evolved mechanisms to reduce the amount of noise in their metabolic processes (e.g., gene regulation). Finally, they suggest possible extensions of their work including studying more complex models with multiple species participating in each reaction. This article is available from: http://arxiv.org/abs/1306.5481 . Stochastic fluctuations in metabolic pathways  Authors: Yi-Chun Chen , Shih-Chieh Hwang , Chia-Hui Wu , Yu-Ting Lin , Ming-Jerng Wang , Wen-Yuan Lee , Jyh-Ming Huang , Chin-Lung Chang , Yuan-Chao Tsai , Wei-Hsien Yang , Kuo-Feng Yeh , Chung-I Wu , Tzi-Chin Chan , Cheng-Yang Liu , Chao-Kuang Chiang , Chien-Nan Chu , Chien-Wen Lu , Chien-Chi Lai , Chien-Shuu Chen , Chien-Chi Hsieh , Chien-Chi Wu , Chien-Chi Hung , Chien-Chi Li , Chien-Chi Su , Chien-Chi Liao , Chien-Chi Chen , Chien-Chiang Wu , Chien-Chiang Tai , Chien-Chiang Liang , Chien-Chiang Sun , Chien-Chiang Wei , Chien-Chiang Chen , Chien-Chang Wu , Chien-Chang Tai , Chien-Chang Liang , Chien-Chang Sun , Chien-Chang Wei , Chien-Chang Chen , Chien-Cheng Wu , Chien-Cheng Tai , Chien-Cheng Liang , Chien-Cheng Sun , Chien-Cheng Wei , Chien-Cheng Chen , Chien-Ch",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stochastic fluctuations in metabolic processes . Abstract : The authors present an assessment of the stochasticity inherent to biochemical reactions , and its consequences on metabolic networks .They show that this noise can be reduced by expanding gene concentrations or decreasing reaction rates ; however , these schemes are small because they may lead to other undesirable consequences such as reduced production expenses for enzymes or decreased development rate due to slower metabolism . The authors additionally discuss how their results could help reason why some organisms have adopted pathways to reduce the quantity of noise in their metabolic processes ( e . g . , gene control ) .Finally , they propose could extensions of their studies including studying more sophisticated models with many taxa participating in each reaction . This section is accessible from : www : / / arxiv . org / abs / 1306 . 5481 .Stochastic fluctuations in metabolic pathways Authors : Yi - Chun Chen , Shih - Chieh Hwang , Chia - Hui Wu , Yu - Ting Lin , Ming - Jerng Wang , Wen - Yuan Lee , Jyh - Ming Huang , Chin - Lung Chang , Yuan - Chao Tsai , Wei - Hsien Yang , Kuo - Feng Yeh , Chung - I Wu , Tzi - Chin Chan , Cheng - Yang Liu , Chao - Kuang Chiang , Chien - Nan Chu , Chien - Wen Lu , Chien - Chi Lai , Chien - Shuu Chen , Chien - Chi Hsieh , Chien - Chi Wu , Chien - Chi Hung , Chien - Chi Li , Chien - Chi Su , Chien - Chi Liao , Chien - Chi Chen , Chien - Chiang Wu , Chien - Chiang Tai , Chien - Chiang Liang , Chien - Chiang Sun , Chien - Chiang Wei , Chien - Chiang Chen , Chien - Chang Wu , Chien - Chang Tai , Chien - Chang Liang , Chien - Chang Sun , Chien - Chang Wei , Chien - Chang Chen , Chien - Cheng Wu , Chien - Cheng Tai , Chien - Cheng Liang , Chien - Cheng Sun , Chien - Cheng Wei , Chien - Cheng Chen , Chien - Ch",
        "rewrite_text": "**Title:** Stochastic Fluctuations in Metabolic Processes\n\n**Abstract:** This article provides a comprehensive evaluation of the stochastic nature of biochemical reactions and its implications for metabolic networks. The authors investigate how inherent noise in these processes can be mitigated through strategies such as increasing gene concentrations or lowering reaction rates. However, they caution that these approaches may have limited effectiveness, as they can inadvertently lead to negative outcomes, including higher production costs for enzymes or slower metabolic rates that hinder organismal growth. The authors further explore the evolutionary significance of these findings, suggesting that certain organisms have developed specific pathways to minimize noise in their metabolic processes, such as through gene regulation mechanisms. Additionally, the paper outlines potential avenues for future research, advocating for the examination of more complex models that incorporate multiple taxa in each reaction. This work not only enhances our understanding of metabolic dynamics but also contributes to the broader field of systems biology by highlighting the balance between stochasticity and regulation in biochemical networks. For further details, the full article can be accessed at www.arxiv.org/abs/1306.5481. \n\n**Authors:** Yi-Chun Chen, Shih-Chieh Hwang, Chia-Hui Wu, Yu-Ting Lin, Ming-Jerng Wang, Wen-Yuan Lee, Jyh-Ming Huang, Chin-Lung Chang, Yuan-Chao Tsai, Wei-Hsien Yang, Kuo-Feng Yeh, Chung-I Wu, Tzi-Chin Chan, Cheng-Yang Liu, Chao-Kuang Chiang, Chien-Nan Chu, Chien-Wen Lu, Chien-Chi Lai, Chien-Shuu Chen, Chien-Chi Hsieh, Chien-Chi Wu, Chien-Chi Hung, Chien-Chi Li, Chien-Chi Su, Chien-Chi Liao, Chien-Chi Chen, Chien-Chiang Wu, Chien-Chiang Tai, Chien-Chiang Liang, Chien-Chiang Sun, Chien-Chiang Wei, Chien-Chiang Chen, Chien-Chang Wu, Chien-Chang Tai, Chien-Chang Liang, Chien-Chang Sun, Chien-Chang Wei, Chien-Chang Chen, Chien-Cheng Wu, Chien-Cheng Tai, Chien-Cheng Liang, Chien-Cheng Sun, Chien-Cheng Wei, Chien-Cheng Chen.",
        "ori-fast-z-score": 0.5488212999484517,
        "water-fast-z-score": 6.110100926607787,
        "rewrite-fast-z-score": 0.10259783520851541
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cross-Layer Optimization of MIMO-Based Mesh Networks with Gaussian Vector Broadcast Channels .\nAbstract:\nIn this work, we consider the problem of optimizing the performance of multi-hop wireless mesh networks (WMNs) in which each node is equipped with multiple antennas and uses vector broadcast channels to communicate with its neighbors. We propose an algorithm that jointly optimizes the routing tree at the network layer and the beamforming vectors at the physical layer for both unicast traffic and multicast traffic. The proposed algorithm can be implemented using only local information exchange between neighboring nodes. Our simulation results show that our algorithm outperforms existing algorithms by up to 50% in terms of end-to-end throughput under different channel conditions. Index Terms -Wireless mesh networks, Cross-layer optimization, Beamforming, Routing trees, Multicasting. 1 Introduction Wireless mesh networks are becoming increasingly popular due to their low cost and ease of deployment  1  . In such networks, all nodes have limited transmission range and thus need to relay data packets through other nodes before reaching their destinations. This introduces additional overheads on the network resources including bandwidth consumption and energy dissipation  2  .\nTo improve the efficiency of WMNs, it has been shown recently that joint design of the network layer and the physical layer is necessary  3  , where the network layer determines how to route data packets while the physical layer decides what transmit power levels should be used as well as what beamforming vectors should be adopted  4  . However, most previous works focus either on the network layer or the physical layer separately  5  , ignoring the fact that they interact closely with one another  6  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cross - Layer Optimization of MIMO - Based Mesh Networks with Gaussian Vector Broadcast Channels . Abstract : In this research , we investigate the question of optimizing the performance of dual - hop wireless mesh connections ( WMNs ) in which each node is furnished with many antennas and using vector broadcast channels to connect with its friends .We suggest an algorithm that collectively optimizes the routing tree at the channel layer and the beamforming vectors at the physical layer for both unicast transport and multicast transport . The proposed algorithm can be executed using only local information transfer between neighboring connections .Our model results show that our algorithm outperforms old algorithms by up to 50 % in terms of end - to - end throughput under various network conditions . Index Terms - Wireless mesh connections , Cross - layer optimization , Beamforming , Routing trees , Multicasting .1 Introduction Wireless mesh connections are growing becoming popular due to their low cost and ease of deployment 1 . In such connections , all nodes have limited transmission range and therefore need to relay data packets through other nodes before reaching their destinations .This creates additional overheads on the channel infrastructure including frequency expenditure and energy dissipation 2 . To increase the performance of WMNs , it has been shown lately that cooperative architecture of the channel layer and the physical layer is required 3 , where the network layer determines how to transport data packets while the physical layer decides what transmit energy levels should be used as well as what beamforming vectors should be adopted 4 .However , most prior efforts focus either on the network layer or the physical layer separately 5 , avoiding the fact that they interact tightly with one another 6 .",
        "rewrite_text": "**Title:** Cross-Layer Optimization of MIMO-Based Mesh Networks with Gaussian Vector Broadcast Channels\n\n**Abstract:** This study explores the optimization of dual-hop wireless mesh networks (WMNs) where each node is equipped with multiple antennas and utilizes vector broadcast channels for communication with neighboring nodes. We propose a novel algorithm that simultaneously enhances the routing tree at the network layer and the beamforming vectors at the physical layer, addressing both unicast and multicast transport scenarios. Notably, our algorithm operates effectively with only local information exchange among adjacent nodes, which simplifies implementation and reduces overhead. Our simulation results demonstrate that this approach significantly improves end-to-end throughput by up to 50% compared to traditional algorithms, across a variety of network conditions. The findings underscore the importance of cross-layer optimization in maximizing the performance of WMNs, particularly in environments where nodes have limited transmission ranges and must rely on relaying data through multiple hops. The cooperative interaction between the network and physical layers is crucial, as the network layer's routing decisions directly influence the physical layer's beamforming strategies and energy allocation. Despite the growing recognition of this interdependence, many previous studies have treated the network and physical layers in isolation, neglecting their synergistic effects. Our research contributes to the understanding of WMN performance enhancement by integrating these layers, paving the way for more efficient and robust wireless communication systems. \n\n**Index Terms:** Wireless mesh networks, Cross-layer optimization, Beamforming, Routing trees, Multicasting.",
        "ori-fast-z-score": -1.7277368511627202,
        "water-fast-z-score": 7.20294057598537,
        "rewrite-fast-z-score": -0.2750095491084634
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The CoRoT primary target HD 52265: models and seismic tests .\nAbstract:\nWe present new theoretical evolutionary tracks for the mass range 1.8 to 2.5 M⊙, which are based on an improved treatment of convection in stellar interiors. We use these tracks as input into our seismic modelling code CESAM2k to compute synthetic seismograms for two different sets of observed frequencies (from COROT) corresponding to two possible values of the inclination angle i = 90° or 60° . The comparison between observations and theory shows that we can exclude one set of frequencies at high confidence level but not the other. This is due to the fact that the frequency differences between ℓ=0 and ℓ=2 modes depend strongly on the inclination angle. In addition, we find that the best fit model has a radius R=1.95R⊙ , which agrees well with the value inferred by asteroseismology using only ℓ=0 modes. Finally, we show how this result could be used to determine the age of the star.  Keywords: Seismic modelling",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The CoRoT primary target HD 52265 : models and seismic studies . Abstract : We present new theoretical evolutionary tracks for the mass range 1 . 8 to 2 . 5 [UNK] , which are based on an improved treatment of convection in stellar interiors .We use these tracks as input into our seismic modelling code CESAM2k to compute natural seismograms for two different sets of measured signals ( from COROT ) corresponding to two possible values of the inclination angle i = 90° or 60° . The comparison between observations and theory demonstrates that we can eliminate one group of frequencies at high confidence rate but not the other .This is due to the fact that the frequency differences between ℓ = 0 and ℓ = 2 modes differ highly on the inclination angle . In addition , we find that the best fit description has a diameter R = 1 . [UNK] , which agrees well with the value inferred by asteroseismology using only ℓ = 0 modes .Finally , we show how this effect could be used to predict the age of the star . Keywords : Seismic modelling",
        "rewrite_text": "In this study, we introduce new theoretical evolutionary tracks for stars within the mass range of 1.8 to 2.5 solar masses, which incorporate an enhanced approach to convection in stellar interiors. These evolutionary tracks serve as a foundational input for our seismic modeling software, CESAM2k, enabling us to generate natural seismograms based on two distinct sets of observational data obtained from the CoRoT satellite. The analysis focuses on two potential inclination angles, specifically i = 90° and i = 60°. By comparing the theoretical predictions with the observed seismic signals, we are able to confidently exclude one group of frequency modes while retaining another. This differentiation arises from the significant variation in frequency differences between the ℓ = 0 and ℓ = 2 modes, which is highly dependent on the inclination angle. Furthermore, our findings indicate that the optimal model fit corresponds to a stellar radius of R = 1. [UNK], a result that aligns closely with the radius determined through asteroseismic techniques that utilize only the ℓ = 0 modes. Ultimately, we discuss the implications of these results for estimating the age of the star, highlighting how the observed seismic characteristics can be leveraged to enhance our understanding of stellar evolution. This research contributes to the broader field of seismic modeling and provides valuable insights into the properties of HD 52265, a primary target of the CoRoT mission. \n\nKeywords: Seismic modeling, stellar evolution, asteroseismology, CoRoT, inclination angle.",
        "ori-fast-z-score": 0.9058216273156765,
        "water-fast-z-score": 4.387842813611494,
        "rewrite-fast-z-score": -0.7770286898858113
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Pair of Bootes: A New Milky Way Satellite .\nAbstract:\nWe report the discovery of a new satellite galaxy, dubbed  A pair of bootes  (ApoBootes), orbiting around our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of 1.5 x 10^10 M_sun . ApoBootes is located on the opposite side of the Galactic center to the Magellanic Clouds and has a very low surface brightness. We have used deep near-infrared images taken by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this object. The photometric properties are consistent with those expected for a dwarf spheroidal galaxy. This work was supported by the Australian Research Council Discovery Project funding scheme under grant DP130104011. We present evidence that ApoBootes may be associated with a previously known overdensity of stars discovered by Belokurov et al. (2007) using SDSS data.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Pair of Bootes : A New Milky Way Satellite . Abstract : We report the discovery of a new satellite galaxy , nicknamed A couple of bootes ( ApoBootes ) , orbiting around our Galaxy at a length of about 300 kpc in projection and with an estimated mass of 1 . 5 x 10 ^ 10 M _ sun .ApoBootes is situated on the opposite end of the Galactic center to the Magellanic Clouds and has a very low exterior brightness . We have utilized deep near - infrared images obtained by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this body .The photometric properties are compatible with those expected for a dwarf spheroidal galaxy . This research was supported by the Australian Research Council Discovery Project money scheme under grant DP130104011 .We present evidence that ApoBootes might be identified with a previously known overdensity of stars found by Belokurov et al . ( 2007 ) using SDSS information .",
        "rewrite_text": "We present the discovery of a new satellite galaxy, designated A couple of Bootes (ApoBootes), which orbits the Milky Way at a projected distance of approximately 300 kpc. This satellite has an estimated mass of 1.5 x 10^10 solar masses and is located on the opposite side of the Galactic center from the Magellanic Clouds. Notably, ApoBootes exhibits a very low surface brightness, making it a challenging target for observation. Our identification of this galaxy was made possible through deep near-infrared imaging conducted with the VISTA telescope, as part of the Vista Variables in the Via Lactea survey. The photometric characteristics of ApoBootes align with those typically associated with dwarf spheroidal galaxies, suggesting it may be a member of this class of celestial objects. Furthermore, we provide evidence that ApoBootes could correspond to a previously identified stellar overdensity reported by Belokurov et al. (2007) using data from the Sloan Digital Sky Survey (SDSS). This discovery contributes to our understanding of the satellite galaxy population surrounding the Milky Way and highlights the importance of ongoing surveys in uncovering faint structures in our cosmic neighborhood. The research was funded by the Australian Research Council under the Discovery Project grant DP130104011, underscoring the collaborative efforts in advancing our knowledge of galactic formation and evolution.",
        "ori-fast-z-score": -0.39056673294247163,
        "water-fast-z-score": 4.131182235954578,
        "rewrite-fast-z-score": -0.6396021490668313
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Phenomenology of GUT-less Supersymmetry Breaking .\nAbstract:\nWe study the phenomenological consequences of supersymmetric models with gauge-mediated breaking, in which the Standard Model is extended by adding new vector-like matter fields and extra dimensions. We show that these models can be constructed such that they are free of any unnatural fine-tuning problems associated with the Higgs mass or flavor-changing neutral currents. In particular we find that:  1) The lightest scalar superpartner (the  Higgs  boson) has a mass at most around 300 GeV.  2) Flavor changing neutral current effects are suppressed to an acceptable level for generic values of parameters.  3) Gauge coupling unification occurs naturally within experimental uncertainties. 4) There exists a large parameter space where all sparticles have masses above 1 TeV while still satisfying constraints on electroweak symmetry breaking. 5) These models provide a natural explanation for why there may not yet exist evidence for supersymmetry at accelerator experiments.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Phenomenology of GUT - less Supersymmetry Breaking . Abstract : We research the phenomenological consequences of supersymmetric theories with gauge - mediated breaking , in which the Standard Model is extended by added new vector - like matter fields and extra dimensions .We see that these models can be built such that they are free of any strange fine - tuned flaws associated with the Higgs mass or flavor - changing neutral currents . In particular we find that : 1 ) The lightest scalar superpartner ( the Higgs boson ) has a mass at most approximately 300 GeV .2 ) Flavor shifting neutral current effects are suppressed to an acceptable level for generic values of values . 3 ) Gauge coupling unification happens easily within experimental uncertainties .4 ) There exists a large parameter room where all sparticles have masses above 1 TeV while already satisfying constraints on electroweak symmetry breaking . 5 ) These models serve a natural explanation for why there may not already exist evidence for supersymmetry at accelerator studies .",
        "rewrite_text": "**Title: Phenomenology of GUT-less Supersymmetry Breaking**\n\n**Abstract:** This study explores the phenomenological implications of supersymmetric theories characterized by gauge-mediated symmetry breaking, wherein the Standard Model is augmented with additional vector-like matter fields and extra dimensions. Our findings indicate that these models can be constructed to avoid the problematic fine-tuning issues typically associated with the Higgs mass and flavor-changing neutral currents. Specifically, we identify several key results: First, the lightest scalar superpartner, identified as the Higgs boson, is constrained to have a mass not exceeding approximately 300 GeV. Second, the effects of flavor-changing neutral currents are significantly suppressed, remaining within acceptable limits for a wide range of parameter values. Third, we demonstrate that gauge coupling unification can be achieved effortlessly, remaining consistent with current experimental uncertainties. Fourth, we uncover a substantial parameter space where all superpartners, or sparticles, possess masses greater than 1 TeV, while still complying with the established requirements for electroweak symmetry breaking. Lastly, these models provide a compelling rationale for the absence of direct evidence for supersymmetry in current accelerator experiments. Overall, our research contributes to a deeper understanding of supersymmetry breaking mechanisms and their phenomenological consequences, offering insights into the potential structure of new physics beyond the Standard Model.",
        "ori-fast-z-score": 0.46499055497527714,
        "water-fast-z-score": 5.658032638058332,
        "rewrite-fast-z-score": 0.9045340337332909
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Non-Metric Gravity II: Spherically Symmetric Solution, Missing Mass and Redshifts of Quasars .\nAbstract:\nWe present the second part of our study on non-metric gravity theory in which we find that there is no missing mass problem for quasars as claimed by some authors.  We also show that this theory can explain the redshifts of quasars without introducing any new parameter or concept into physics. In addition to these results, we discuss how this theory may be tested experimentally using gravitational waves produced by binary pulsar systems. The first part of this work has been published recently  1  . \nI. INTRODUCTORY REMARK\nIn recent years many authors have studied various aspects of nonmetric gravity theories  2  -  8  , but none of them seems to have considered the possibility of testing such theories with observations made on distant objects like quasars (QSOs). This is surprising because it was shown previously  9  that one particular version of non-metric gravity could solve the missing mass problem associated with QSOs. It should therefore not come as a surprise if other versions of non-metric gravity are able to do so too.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Non - Metric Gravity II : Spherically Symmetric Solution , Missing Mass and Redshifts of Quasars . Abstract : We present the second part of our research on non - metric gravity physics in which we find that there is no missing mass problem for quasars as asserted by some researchers .We additionally say that this theory can describe the redshifts of quasars without putting any new parameter or notion into physics . In addition to these results , we explain how this theory could be evaluated experimentally utilizing gravitational waves produced by binary pulsar systems .The first part of this project has been publication recently 1 . I .INTRODUCTORY REMARK In past decades several authors have researched several elements of nonmetric gravity theories 2 - 8 , but none of them appears to have thought the prospect of testing such theories with observations made on remote bodies like quasars ( QSOs ) . This is surprising because it was shown previously 9 that one certain version of non - metric gravity could answer the missing mass problem associated with QSOs .It should therefore not come as a surprise if other models of non - metric gravity are able to do so too .",
        "rewrite_text": "In this article, we delve into the second segment of our investigation into non-metric gravity, focusing specifically on spherically symmetric solutions. Our findings challenge the prevailing notion of a missing mass problem in quasars, a claim that has been put forth by various researchers. We demonstrate that our theoretical framework can account for the observed redshifts of quasars without the necessity of introducing any additional parameters or concepts into the existing body of physics. Furthermore, we propose a method for experimentally validating this theory through the analysis of gravitational waves generated by binary pulsar systems. This research builds upon our earlier work, which has recently been published. \n\nHistorically, the exploration of non-metric gravity theories has garnered attention from numerous scholars over the past few decades. However, a notable gap exists in the literature regarding the application of these theories to astronomical observations of distant objects, such as quasars (QSOs). This oversight is particularly striking given that prior studies have indicated that certain formulations of non-metric gravity could potentially resolve the missing mass dilemma associated with QSOs. Consequently, it is reasonable to expect that alternative models within the realm of non-metric gravity may also offer solutions to this issue. Our work aims to bridge this gap by providing a comprehensive analysis of non-metric gravity's implications for quasars, thereby contributing to a deeper understanding of the universe's structure and the fundamental laws governing it.",
        "ori-fast-z-score": 0.105999788000636,
        "water-fast-z-score": 6.535373831014651,
        "rewrite-fast-z-score": 0.1796053020267749
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A quantitative study on the growth variability of tumour cell clones in vitro .\nAbstract:\nThe authors have studied the growth rate and its fluctuations for different types of human cancer cells grown under controlled conditions, using an automated image analysis system to measure their size over time.  The results show that there is considerable variation between individual clones within each type of cell line as well as between different types of cell lines. This suggests that it may be possible to use this information to classify tumours into subtypes with distinct biological properties. In addition, they find evidence that the growth rates are correlated across generations of daughter cells, which could provide insight into how these correlations arise during tumorigenesis. Finally, by comparing the growth characteristics of normal and transformed cells, they conclude that transformation leads to increased heterogeneity among daughter cells. Cancer is characterized by uncontrolled proliferation of abnormal cells. Understanding the mechanisms underlying this process can help us develop new treatments against cancer. However, studying the dynamics of cancerous cell populations has been challenging because of difficulties associated with tracking large numbers of single cells simultaneously. Here we report our recent work on characterizing the growth behavior of thousands of individual cancer cells growing in culture dishes  1  . We used an automated imaging system to track the sizes of hundreds of thousands of cells belonging to several different types of human cancer cell lines ( Figure 1 ). Our results reveal significant differences in both average growth rates and growth fluctuations between different types of cell lines: some grow faster than others while also exhibiting larger fluctuations around their mean values  2  .\nWe found that the growth rates were highly variable even when measured at the level of individual clones derived from a common parent population  3  , suggesting that the observed phenotypic diversity might reflect genetic or epigenetic variations present in the original parental population  4  .  These findings suggest that it should be possible to use such measurements to classify tumors into subtypes based on their growth characteristics  5  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A quantitative study on the development variability of tumour cell clones in vitro . Abstract : The authors have researched the development frequency and its fluctuations for different kinds of human tumor cells grown under regulated conditions , using an automated photo processing program to measure their size over time .The results show that there is substantial variation between individual clones within each type of cell line as well as between various types of cell lines . This implies that it could be possible to use this data to classify tumours into subtypes with particular genetic characteristics .In addition , they discover proof that the development rates are correlated across generations of daughter tissues , which could give insight into how these correlations occur during tumorigenesis . Finally , by comparing the development patterns of normal and transformed tissue , they conclude that transformation results to greater heterogeneity among sister cells .Cancer is characterized by uncontrolled proliferation of irregular cells . Understanding the mechanisms governing this process can help us evolve innovative treatments against tumors .However , studying the dynamics of cancerous cell groups has been challenging because of troubles associated with monitoring huge amounts of single cells simultaneously . Here we publish our latest work on characterizing the development habits of thousands of individual cancer cells growing in culture dishes 1 .We utilized an automated scanning system to track the sizes of tens of thousands of cells belonging to several different kinds of human tumor cell lines ( Figure 1 ) . Our results show considerable variations in both average growth rates and growth fluctuations between various types of cell lines : some develop longer than others while also displaying wider fluctuations around their average values 2 .We showed that the development rates were extremely varied even when measured at the level of individual clones originating from a common parent population 3 , showing that the reported phenotypic diversity could reflect genetic or epigenetic changes found in the original parental generation 4 . These conclusions show that it should be possible to use such measurements to classify cancer into subtypes based on their development parameters 5 .",
        "rewrite_text": "**Title:** A Quantitative Study on the Development Variability of Tumor Cell Clones In Vitro\n\n**Abstract:** This study investigates the frequency and variability of development among various human tumor cell types cultivated under controlled conditions. Utilizing an automated image processing system, we meticulously measured the size of these cells over time. Our findings reveal significant discrepancies in growth rates both within individual clones of the same cell line and across different cell lines. This variability suggests the potential for classifying tumors into distinct subtypes based on their unique genetic characteristics. Additionally, we observed a correlation in growth rates across generations of daughter cells, providing valuable insights into the mechanisms of tumorigenesis. By contrasting the growth patterns of normal and transformed tissues, we conclude that cellular transformation leads to increased heterogeneity among sister cells. \n\nCancer is marked by the unregulated proliferation of abnormal cells, and a deeper understanding of the underlying mechanisms can pave the way for innovative therapeutic strategies. However, the dynamics of cancer cell populations have posed significant challenges due to the difficulties in simultaneously monitoring large numbers of individual cells. In this research, we present our latest findings on the growth behaviors of thousands of individual cancer cells cultured in laboratory dishes. Our automated scanning system enabled us to track the sizes of tens of thousands of cells from multiple human tumor cell lines. The results indicate notable variations in average growth rates and fluctuations among different cell lines, with some exhibiting prolonged growth periods and greater variability around their mean values. \n\nFurthermore, our analysis demonstrated that growth rates varied significantly even among individual clones derived from a common parental population, suggesting that the observed phenotypic diversity may stem from genetic or epigenetic alterations present in the original generation. These insights imply that such measurements could be instrumental in categorizing cancer into subtypes based on their developmental characteristics.",
        "ori-fast-z-score": -1.9744355451432527,
        "water-fast-z-score": 9.189494464367357,
        "rewrite-fast-z-score": 1.2418408411301325
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Tree-Level Stability Without Spacetime Fermions: Novel Examples in String Theory .\nAbstract:\nWe present novel examples of tree-level stable non-BPS D-branes in string theory, which are not associated with spacetime fermion zero modes and thus do not require the presence of orientifolds or other sources for tadpole cancellation. We show that these brane configurations can be constructed by wrapping unstable D-branes on supersymmetric cycles in Calabi-Yau threefolds. The resulting BPS states preserve half of the original supersymmetry but carry no net charge under any gauge group factor. These results provide new insights into the structure of moduli spaces of vacua in string theory. Introduction: In recent years there has been considerable interest in studying non-BPS D-brane (NBD) configurations in type II string theories  1  . NBDs have attracted attention because they may play an important role in understanding various phenomena such as tachyon condensation  2  , open-string pair production  3  , and black hole entropy  4  .\nIn this work we will focus our attention on NBDs whose stability is due to worldsheet instanton effects  5  -  8  rather than spacetime fermion zero-modes  9  . Such NBDs were first studied in  10  where it was shown that certain wrapped D3-branes could become stable at one-loop order without requiring the presence of orientifold planes  11  . Subsequently, several authors  12  -  16  have considered similar constructions involving different types of D-branes and compactifications. However, all of these works required some form of tadpole cancellation  17  so that the total RR-charge carried by the configuration vanishes. Tadpole cancellation conditions place strong constraints on the allowed values of fluxes and charges in the background geometry  18  . It would therefore be interesting if one could find examples of stable NBDs which did not require the presence of additional sources for tadpole cancellations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Tree - Level Stability Without Spacetime Fermions : Novel Examples in String Theory . Abstract : We introduce novel instances of forest - level stable non - BPS D - branes in string theory , which are not associated with spacetime fermion zero modes and therefore do not require the presence of orientifolds or other sources for tadpole cancellation .We see that these brane configurations can be built by wrapping unstable D - branes on supersymmetric cycles in Calabi - Yau threefolds . The resulting BPS states preserve half of the original supersymmetry but hold no net charge under any gauge group factor .These data provide novel knowledge into the formation of moduli spaces of vacua in string theory . Introduction : In recent years there has been substantial interest in investigating non - BPS D - brane ( NBD ) arrangements in type II string theories 1 .NBDs have garnered attention because they may play an important role in understanding various phenomena such as tachyon condensation 2 , open - string pair production 3 , and dark hole entropy 4 . In this research we will focus our focus on NBDs whose stability is due to worldsheet instanton effects 5 - 8 instead than spacetime fermion zero - modes 9 .Such NBDs were first investigated in 10 where it was shown that particular tangled D3 - branes might remain stable at one - loop order without need the presence of orientifold planes 11 . Subsequently , various scientists 12 - 16 have suggested different constructions concerning diverse kinds of D - branes and compactifications .However , all of these works involved some kind of tadpole cancellation 17 so that the total RR - charge transferred by the configuration vanishes . Tadpole cancellation conditions place powerful restrictions on the allowed values of fluxes and charges in the background geometry 18 .It would therefore be attractive if one could discover examples of stable NBDs which did not require the presence of new sources for tadpole cancellations .",
        "rewrite_text": "**Title:** Tree-Level Stability Without Spacetime Fermions: Novel Examples in String Theory\n\n**Abstract:** In this paper, we present innovative examples of tree-level stable non-BPS D-branes within the framework of string theory, which are notable for their independence from spacetime fermion zero modes. This characteristic eliminates the necessity for orientifolds or other mechanisms typically employed for tadpole cancellation. Our findings demonstrate that these stable brane configurations can be constructed by wrapping unstable D-branes around supersymmetric cycles in Calabi-Yau threefolds. The resulting BPS states maintain half of the original supersymmetry while exhibiting no net charge under any gauge group factor. This research contributes valuable insights into the moduli spaces of vacua in string theory, enhancing our understanding of the stability of non-BPS D-branes.\n\nIn recent years, there has been a growing interest in the study of non-BPS D-brane (NBD) configurations in type II string theories. These NBDs are significant as they may provide crucial insights into various phenomena, including tachyon condensation, open-string pair production, and dark hole entropy. Our investigation focuses specifically on NBDs whose stability arises from worldsheet instanton effects rather than spacetime fermion zero modes. Previous studies have explored the stability of tangled D3-branes at one-loop order without the need for orientifold planes. However, most existing research has involved some form of tadpole cancellation, which imposes stringent constraints on the permissible values of fluxes and charges in the underlying geometry. Therefore, the discovery of stable NBDs that do not rely on additional sources for tadpole cancellation represents a significant advancement in the field. This work not only broadens the landscape of D-brane configurations but also opens new avenues for exploring the implications of such stable configurations in string theory.",
        "ori-fast-z-score": -1.5549631660464482,
        "water-fast-z-score": 5.895067838245651,
        "rewrite-fast-z-score": 1.3416407864998738
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Pulsar radiation belts and transient radio emission .\nAbstract:\nWe present the results of our analysis of pulsar data obtained with the LOFAR telescope in the Netherlands, which is part of the Low Frequency Array (LOFAR). The observations were carried out at frequencies between 10 MHz and 120 MHz using the High Band Antenna (HBA) system. We have detected two new types of pulsars - one that emits bursts of radio waves lasting several seconds and another whose pulses are modulated by an additional signal. In addition to these discoveries we also report on the detection of previously unknown phenomena associated with known pulsars. \n \n Pulsars are rapidly rotating neutron stars emitting beams of electromagnetic radiation across the entire visible universe. They can be observed over many decades as they spin down due to their magnetic dipole field losing energy into space. This causes them to slow down gradually until they stop completely after about ten billion years. As well as being extremely stable clocks for measuring time intervals, pulsars provide information about fundamental physics such as gravity, quantum electrodynamics and general relativity.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Pulsar radiation belts and transient radio emission . Abstract : We present the conclusion of our analysis of pulsar information obtained with the LOFAR observatory in the Netherlands , which is part of the Low Frequency Array ( LOFAR ) .The studies were carried out at speeds between 10 MHz and 120 MHz using the High Band Antenna ( HBA ) scheme . We have discovered two new types of pulsars - first that emits flashes of radio beams lasting several seconds and another whose pulses are modulated by an additional signal .In addition to these discoveries we also report on the observation of previously unidentified events associated with known pulsars . Pulsars are rapidly spinning neutron galaxies emitting waves of electromagnetic radiation across the entire seen universe .They can be found over numerous centuries as they rotate down due to their gravitational dipole field losing power into space . This forces them to turn down gradually until they stop completely after about ten billion decades .As well as being extremely reliable clocks for determining time periods , pulsars provide information about basic physics such as gravity , quantum electrodynamics and general relativity .",
        "rewrite_text": "In this article, we present the findings from our comprehensive analysis of pulsar data collected at the LOFAR observatory in the Netherlands, which is part of the Low Frequency Array (LOFAR). Our research was conducted across a frequency range of 10 MHz to 120 MHz utilizing the High Band Antenna (HBA) configuration. Notably, we have identified two novel types of pulsars: one that emits intermittent bursts of radio waves lasting several seconds, and another whose pulse emissions exhibit modulation by an additional signal. Furthermore, our observations have led to the detection of previously unrecognized events linked to known pulsars. \n\nPulsars, which are rapidly rotating neutron stars, emit beams of electromagnetic radiation that can be detected across vast distances in the universe. These celestial objects gradually lose energy due to their gravitational dipole radiation, causing them to slow down over time, with a typical lifespan of around ten billion years before they cease to emit entirely. Beyond their role as highly accurate cosmic clocks, pulsars serve as valuable tools for exploring fundamental physical principles, including gravity, quantum electrodynamics, and general relativity. Our findings not only enhance the understanding of pulsar behavior but also contribute to the broader field of astrophysics by providing insights into the mechanisms governing these extraordinary astronomical phenomena.",
        "ori-fast-z-score": -1.1793237883215741,
        "water-fast-z-score": 6.253987492037524,
        "rewrite-fast-z-score": 0.7107423155935334
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Brane World in an Arbitrary Number of Dimensions without Z_2 Symmetry .\nAbstract:\nWe consider the possibility that our universe is described by a brane world model with an arbitrary number of dimensions, but no reflection symmetry across any of them.  We show how to construct such models and discuss their phenomenological consequences for cosmology and particle physics. In particular we find that there are two classes of solutions which can be distinguished by whether or not they contain closed timelike curves (CTCs). The first class contains CTCs while the second does not. For both cases we calculate the effective four dimensional Planck mass as well as the masses of Kaluza-Klein excitations on the brane. Finally we study the stability properties of these solutions under small perturbations. This work was supported by NSF grant PHY-0456728. PACS numbers: 04.20.-q; 11.25.-w; 98.80.Cq . \nI. INTRODU CTION\n\nThe idea that our universe may have more than three spatial dimensions has been around since the early days of general relativity  1  , when it was realized that Einstein s field equations admit solutions with extra dimensions  2  .\nIn recent years this idea has received renewed interest due to developments in string theory  3  where it appears naturally  4  . String theoretic constructions typically involve compactification of higher-dimensional space-times down to lower ones  5  -  8  . However, even if one starts out with a ten-or eleven-dimensional background solution, the resulting low energy description will generically include additional fields living in the bulk  9  -  11  . These fields couple to matter localized on the branes  12  giving rise to new effects at low energies  13  -  16  .\nOne particularly interesting feature of many braneworld scenarios  17  -  20  is the presence of time-like singularities  21  -  23  . Such singularities arise whenever the volume of some internal dimension shrinks to zero size  24  . They lead to problems with causality  25  unless the corresponding time coordinate is identified periodically  26  . If this identification is done in a way consistent with supersymmetry then the singularities disappear  27  . Alternatively, one could try to resolve the singularities using quantum gravity  28",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Brane World in an Arbitrary Number of Dimensions without Z _ 2 Symmetry . Abstract : We consider the prospect that our universe is characterized by a brane world model with an arbitrary number of sizes , but no reflection symmetry across any of them .We see how to build such theories and consider their phenomenological consequences for cosmology and particle science . In particular we find that there are two groups of solutions which can be distinguished by whether or not they contain shut timelike curves ( CTCs ) .The first class includes CTCs while the second does not . For both cases we estimate the effective four dimensional Planck mass as well as the masses of Kaluza - Klein excitations on the brane .Finally we study the stability properties of these solutions under small perturbations . This research was supported by NSF grant PHY - 0456728 .PACS codes : 04 . 20 . - q ; 11 . 25 . - w ; 98 . 80 . Cq . I . INTRODU CTION The idea that our universe might have more than three spatial dimensions has been around since the early days of general relativity 1 , when it was understood that Einstein s field equations allow answers with extra dimensions 2 .In recent years this idea has gained renewed emphasis thanks to developments in string theory 3 where it appears naturally 4 . String theoretic constructions often include compactification of greater - dimensional space - times down to smaller ones 5 - 8 .However , even if one starts out with a ten - or twelve - dimensional background solution , the resulting lowest energy representation will generically contain extra fields lived in the bulk 9 - 11 . These fields pair to matter localized on the branes 12 providing rise to new effects at low energies 13 - 16 .One especially interesting characteristics of several braneworld situations 17 - 20 is the presence of time - like singularities 21 - 23 . Such singularities arise whenever the volume of some internal dimension shrinks to zero size 24 .They lead to problems with causality 25 unless the resulting period coordinate is identified periodically 26 . If this identity is accomplished in a way consistent with supersymmetry then the singularities disappear 27 .Alternatively , one might try to overcome the singularities using quantum gravitational 28",
        "rewrite_text": "**Title:** A Brane World in an Arbitrary Number of Dimensions without Z_2 Symmetry\n\n**Abstract:** This article explores the intriguing possibility that our universe may be described by a brane world model characterized by an arbitrary number of dimensions, devoid of any reflection symmetry across these dimensions. We outline the construction of such theoretical frameworks and examine their implications for both cosmology and particle physics. Notably, we identify two distinct classes of solutions based on the presence or absence of closed timelike curves (CTCs). The first class accommodates CTCs, while the second class does not. For both categories, we provide estimates for the effective four-dimensional Planck mass and the masses of Kaluza-Klein excitations residing on the brane. Additionally, we investigate the stability of these solutions in response to small perturbations. This research is supported by NSF grant PHY-0456728. \n\nThe concept of a universe with more than three spatial dimensions has been a topic of interest since the inception of general relativity, where Einstein's field equations hinted at the existence of extra dimensions. Recent advancements in string theory have revitalized this idea, as higher-dimensional constructs naturally emerge within this framework. String theory often involves the compactification of higher-dimensional spacetimes into lower-dimensional forms. However, even when beginning with a ten- or twelve-dimensional background, the resulting lowest energy states typically yield additional fields that inhabit the bulk, which interact with matter localized on the branes, leading to novel low-energy phenomena. \n\nA particularly fascinating aspect of various braneworld scenarios is the emergence of timelike singularities, which occur when the volume of an internal dimension collapses to zero. These singularities pose significant challenges to causality unless the corresponding periodic coordinate is identified in a consistent manner. If this identification aligns with the principles of supersymmetry, the singularities can be effectively resolved. Alternatively, one may seek to address these singularities through quantum gravitational approaches. This study contributes to the ongoing discourse on the implications of higher-dimensional theories and their potential to reshape our understanding of fundamental physics.",
        "ori-fast-z-score": -0.32659863237109044,
        "water-fast-z-score": 7.413571269033499,
        "rewrite-fast-z-score": 1.6222142113076254
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Distance to Orion KL Measured with VERA .\nAbstract:\nWe report the distance measurement toward the Galactic center using Very Long Baseline Array (VLBA) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry (VERA). The parallax was measured by observing Sgr A*, which is located near the Galactic center, for two years between 2007 and 2009. We found that the distance to the Galactic center is R0 = 8 kpc ± 0.4 kpc. This value agrees well with previous measurements based on other methods such as infrared photometry or trigonometric parallaxes of masers associated with massive young stars. Our result also supports the hypothesis that the Milky Way has an axisymmetric mass distribution around its central black hole. \n \n Keywords: Distance scale, Galaxy, Parallax, Space astrometry, Black holes \n \n \n \n 1 Introduction \n \n In order to understand how galaxies evolve over time, it is important to know their distances accurately. However, accurate distances are difficult to measure because they depend strongly on the assumed luminosity evolution model. For example, if we assume too high a rate of luminosity evolution, then the derived distance will be underestimated. On the other hand, if we assume too low a rate of luminosity evolu-tion, then the derived distance may be overestimated. Therefore, it is necessary to determine the correct luminosity evolution model before deriving the distance to any galaxy. \n \n One way to solve this problem is to use radio sources whose distances can be determined independently through other means. These include pulsars, quasars, and maser sources associated with star-forming regions. Among these objects, maser sources have been used most frequently since they provide very precise distance estimates. Maser sources are usually associated with star forming regions where water vapor molecules form into microscopic crystals known as ice grains. When the ice grains grow larger than about one micron, they become unstable against gravitational collapse and begin emitting intense radiation. Since the emission line widths of maser sources are extremely narrow compared to those of normal radio",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Distance to Orion KL Measured with VERA . Abstract : We report the distance measurement toward the Galactic center utilizing Very Long Baseline Array ( VLBA ) observations at 22 GHz and 43 GHz in combination with Japanese VLBI Exploration of Radio Astrometry ( VERA ) .The parallax was measured by observing Sgr A * , which is situated near the Galactic center , for two years between 2007 and 2009 . We determined that the distance to the Galactic center is R0 = 8 kpc ± 0 . 4 kpc .This value agrees well with previous measurements based on other methods such as infrared photometry or trigonometric parallaxes of masers associated with massive young galaxies . Our result even suggests the notion that the Milky Way has an axisymmetric mass distribution around its central black hole .Keywords : Distance scale , Galaxy , Parallax , Space astrometry , Black holes 1 Introduction In order to comprehend how galaxies evolve over time , it is important to predict their distances accurately . However , accurate distances are hard to measure because they rely heavily on the expected luminosity evolution theory .For instance , if we suppose too high a rate of luminosity progression , then the derived length will be underestimated . On the other hand , if we suppose too low a rate of luminosity evolu - tion , then the derived distance might be overestimated .Therefore , it is required to obtain the appropriate luminosity evolution theory before deriving the distance to any galaxy . One method to solve this question is to use radio sources whose distances can be determined independently through other methods .These include pulsars , quasars , and maser sources associated with star - creating areas . Among these objects , maser sources have been used most regularly since they give very exact distance estimates .Maser sources are typically associated with star producing regions where water vapor molecules form into microscopic particles termed as ice particles . When the ice particles develop larger than about one micron , they become unstable against gravitational failure and begin emitting intense rays .Since the emission line widths of maser sources are extremely narrow compared to those of normal radio",
        "rewrite_text": "**Title: Distance to Orion KL Measured with VERA**\n\n**Abstract:** This study presents a precise measurement of the distance to the Galactic center, achieved through Very Long Baseline Array (VLBA) observations at frequencies of 22 GHz and 43 GHz, in conjunction with the Japanese VLBI Exploration of Radio Astrometry (VERA). The parallax method was employed by monitoring Sgr A*, located near the Galactic center, over a two-year period from 2007 to 2009. Our findings indicate that the distance to the Galactic center is R0 = 8 kpc ± 0.4 kpc. This measurement is consistent with previous estimates derived from various techniques, including infrared photometry and the trigonometric parallaxes of masers linked to massive young stellar objects. Notably, our results lend support to the hypothesis that the Milky Way exhibits an axisymmetric mass distribution surrounding its central black hole. \n\n**Keywords:** Distance scale, Galaxy, Parallax, Space astrometry, Black holes\n\n**1 Introduction:** Accurately determining the distances to galaxies is crucial for understanding their evolutionary processes. However, this task is complicated by the reliance on luminosity evolution theories, which can lead to significant errors in distance estimation. If the luminosity progression is overestimated, the resulting distance will be too short; conversely, an underestimated luminosity will yield an excessively long distance. Therefore, establishing a reliable luminosity evolution model is essential for accurate distance measurements. One effective approach to address this challenge is to utilize radio sources whose distances can be independently verified through alternative methods. These sources include pulsars, quasars, and maser emissions from star-forming regions. Among these, maser sources are particularly valuable due to their ability to provide highly precise distance measurements. Maser emissions are typically associated with star-forming regions, where water vapor molecules condense into tiny ice particles. When these particles exceed approximately one micron in size, they become gravitationally unstable and emit strong radiation. The narrow emission line widths of maser sources, in contrast to those of typical radio sources, further enhance their utility in distance measurement.",
        "ori-fast-z-score": 1.2456821978060995,
        "water-fast-z-score": 7.291164092619461,
        "rewrite-fast-z-score": 1.7439550769285392
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Central limit theorems in linear structural error-in-variables models with explanatory variables in the domain of attraction of the normal law .\nAbstract:\nWe study central limit theorems for estimators of parameters in linear regression models where errors are not necessarily normally distributed but have an elliptical distribution, and we allow some explanatory variables to be non-normal. We show that under suitable conditions on the model coefficients, the asymptotic distributions of these estimators can be approximated by those obtained when all the explanatory variables follow a multivariate normal distribution. The results are illustrated through simulation experiments. Keywords: Central Limit Theorem; Elliptical Distributions; Regression Modeling. 1 Introduction In many applications it is assumed that the response variable follows a Gaussian distribution while the predictors may or may not be normally distributed. For example, this assumption has been used extensively in econometrics (see e.g., Greene  2003  ). However, there are situations where the data generating process does not satisfy such assumptions. This motivates us to consider more general classes of distributions which include as special cases both the normal and nonnormal distributions. One class of distributions that includes most common probability density functions encountered in practice is given by the so-called elliptical distributions. These distributions were introduced independently by Kelker  1970  , Hüsler and Reiss  1981  , and Fang et al.  1987  . They are characterized by their dependence structure rather than their marginal densities. A random vector X = (X1, ..., Xd)T ∈ Rd belongs to the family of elliptical distributions if its characteristic function satisfies E exp(itX)  = exp{−V (t)},\nwhere V : R →  0, ∞) is called the characteristic generator. If V ≡ 0 then X is said to belong to the family of spherical distributions. Examples of elliptical distributions include:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Central limit theorems in linear structural error - in - variables models with explanatory variables in the domain of attraction of the normal law . Abstract : We research central limit theorems for estimators of parameters in linear regression systems where errors are not necessarily normally distributed but have an elliptical distribution , and we allow some explanatory variables to be non - normal .We see that under suitable conditions on the model variables , the asymptotic distributions of these estimators can be approximated by those achieved when all the explanatory variables continue a multivariate normal distribution . The results are shown through simulation studies .Keywords : Central Limit Theorem ; Elliptical Distributions ; Regression Modeling . 1 Introduction In many applications it is expected that the response parameter follows a Gaussian distribution while the predictors would or may not be usually spread .For instance , this assumption has been used heavily in econometrics ( saw e . g . , Greene 2003 ) . However , there are circumstances where the information collecting mechanism does not satisfy such constraints .This motivates us to consider more general categories of distributions which contain as special cases both the usual and nonnormal distributions . One class of distributions that contains most common probability density functions seen in practice is given by the so - called elliptical distributions .These distributions were introduced independently by Kelker 1970 , Hüsler and Reiss 1981 , and Fang et al . 1987 .They are marked by their dependence structure rather than their marginal densities . A random matrix X = ( X1 , . . . , Xd ) T ∈ Rd belongs to the group of elliptical distributions if its characteristic function satisfies E exp ( itX ) = exp { −V ( t ) } , where V : R → 0 , ∞ ) is dubbed the characteristic generator .If V ≡ 0 then X is said to belong to the class of spherical distributions . Examples of elliptical distributions involve :",
        "rewrite_text": "**Title:** Central Limit Theorems in Linear Structural Error-in-Variables Models with Explanatory Variables in the Domain of Attraction of the Normal Law\n\n**Abstract:** This study investigates central limit theorems applicable to parameter estimators in linear regression models characterized by errors that may not conform to a normal distribution, specifically those exhibiting an elliptical distribution. Additionally, we consider scenarios where some explanatory variables are non-normally distributed. Our findings indicate that, under certain conditions pertaining to the model variables, the asymptotic distributions of these estimators can be effectively approximated by those derived from models where all explanatory variables follow a multivariate normal distribution. To validate our theoretical results, we conduct extensive simulation studies that illustrate the practical implications of our findings. The significance of this research lies in its ability to extend the applicability of central limit theorems to a broader class of distributions, thereby enhancing the robustness of regression modeling in various fields, including econometrics. The use of elliptical distributions, which encompass a wide range of commonly encountered probability density functions, allows for a more flexible approach to modeling dependencies among variables. These distributions, introduced by Kelker (1970), Hüsler and Reiss (1981), and Fang et al. (1987), are defined by their characteristic functions rather than their marginal densities. A random vector \\( X = (X_1, \\ldots, X_d)^T \\in \\mathbb{R}^d \\) is classified as belonging to the elliptical distribution family if its characteristic function satisfies \\( E[\\exp(itX)] = \\exp\\{-V(t)\\} \\), where \\( V: \\mathbb{R} \\to (0, \\infty) \\) is known as the characteristic generator. In cases where \\( V \\equiv 0 \\), the distribution is categorized as spherical. This research contributes to the understanding of regression modeling under non-standard conditions and provides a foundation for future studies exploring the implications of elliptical distributions in statistical analysis.\n\n**Keywords:** Central Limit Theorem; Elliptical Distributions; Regression Modeling.",
        "ori-fast-z-score": -0.9760921603577252,
        "water-fast-z-score": 4.810702354423639,
        "rewrite-fast-z-score": -0.3682298471593294
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A binary model for the UV-upturn of elliptical galaxies (MNRAS version) .\nAbstract:\nWe present an improved version of our previous work on modelling the ultraviolet upturn in early-type galaxies using binary stars.  We use Monte Carlo simulations to generate synthetic populations with different ages, metallicities and mass ratios between components. The models are compared against observations of nearby galaxies obtained by GALEX. Our results show that binary systems can reproduce well both the strength and shape of the observed UV-optical SEDs. In particular we find that:  - Binary evolution is required to explain the strong UV fluxes seen at young ages (< 1 Gyr). - A large fraction of binaries must be composed of two hot subdwarfs or white dwarfs. - Binaries containing one normal star and one compact object cannot produce enough UV light to match the data. - Mass transfer plays only a minor role in shaping the UV-optical SED. - The best-fit age distribution peaks around 2 Gyr but extends down to younger ages.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A binary simulation for the UV - upturn of elliptical galaxies ( MNRAS version ) . Abstract : We present an updated form of our previous research on modelling the ultraviolet upturn in early - class stars involving binary stars .We use Monte Carlo simulations to produce synthetic populations with various ages , metallicities and mass ratios between components . The models are compared against measurements of neighbouring galaxies collected by GALEX .Our results show that binary systems can reproduce well both the strength and shape of the seen UV - optical SEDs . In particular we find that : - Binary evolution is required to explain the strong UV fluxes seen at young years ( < 1 Gyr ) .- A large fraction of binaries may be composed of two hot subdwarfs or white dwarfs . - Binaries involving one regular star and one compact body fail produce enough UV energy to match the information .- Mass transfer plays only a minor importance in shaping the UV - optical SED . - The best - fitting age distribution peaks around 2 Gyr but continues down to younger ages .",
        "rewrite_text": "We present an enhanced version of our earlier study focused on modeling the ultraviolet (UV) upturn observed in early-type stars, specifically through the lens of binary star systems. Utilizing Monte Carlo simulations, we generate synthetic stellar populations characterized by a range of ages, metallicities, and mass ratios among the binary components. Our models are rigorously compared with observational data from nearby galaxies obtained via the Galaxy Evolution Explorer (GALEX). The findings indicate that binary star systems are capable of accurately reproducing both the intensity and the profile of the UV-optical spectral energy distributions (SEDs) observed. Notably, our analysis reveals several key insights: first, the evolution of binary systems is essential for accounting for the pronounced UV fluxes detected in stars younger than 1 billion years. Second, a significant proportion of these binary systems may consist of two hot subdwarfs or white dwarfs. Third, configurations involving one ordinary star paired with a compact object do not generate sufficient UV radiation to align with the observed data. Additionally, we find that mass transfer processes play a relatively minor role in influencing the UV-optical SED. Finally, our best-fitting age distribution peaks at approximately 2 billion years, while also extending to younger stellar ages. These results contribute to a deeper understanding of the mechanisms driving the UV upturn phenomenon in elliptical galaxies and underscore the importance of binary interactions in stellar evolution.",
        "ori-fast-z-score": 0.741998516004452,
        "water-fast-z-score": 5.270462766947299,
        "rewrite-fast-z-score": 0.7364596943186588
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Observation of Landau levels of Dirac fermions in graphite .\nAbstract:\nWe report the observation of Landau levels (LLs) of Dirac fermions in single-layered graphite by using scanning tunneling microscopy and spectroscopy at low temperatures. \n \n The LLs are observed as periodic oscillations with magnetic field B, which is perpendicular to the sample surface. We find that the energy spacing between adjacent LLs decreases with increasing B. This behavior agrees well with theoretical predictions for massless Dirac fermions. In addition, we observe an unexpected peak structure near zero bias voltage Vbias = 0 mV on top of each LL. These peaks can be explained by assuming that they originate from localized states induced by disorder or impurities. Our results provide direct evidence for the existence of Dirac fermions in graphene-like materials such as graphite. Graphene has attracted much attention because it exhibits unique electronic properties originating from its two-dimensional honeycomb lattice  1  . Recently, several groups have succeeded in isolating monolayer sheets of carbon atoms arranged in a similar manner  2  , leading to renewed interest in this material  3  .\nIn contrast to conventional semiconductors, where electrons behave like massive particles, the charge carriers in graphene obey relativistic quantum mechanics  4  . As a result, their dynamics exhibit many unusual features including Klein tunnelling  5  , Zitterbewegung  6  , and half-integer quantum Hall effect  7, 8  . Moreover, the low-energy excitations in graphene are described by massless Dirac fermions  9  whose dispersion relation E(k) shows linear dependence around two inequivalent points K and K  in momentum space  10  . Because of these remarkable characteristics, graphene is considered one of the most promising candidates for future applications in electronics  11  .\nRecently, there has been growing interest in other layered materials having a similar atomic arrangement  12  . Among them, graphite is particularly interesting since it consists of stacked layers of graphene  13  . Although the interlayer coupling leads to a gap opening  14  , the band structure still retains some resemblance to that of graphene  15  . For example, the Fermi velocity vF ~ 10 6 m/s  16  is almost identical to that of graphene  17  . Furthermore,",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Observation of Landau concentrations of Dirac fermions in graphite . Abstract : We report the observation of Landau concentrations ( LLs ) of Dirac fermions in single - layered graphite by using laser tunneling microscopy and spectroscopy at low temperatures .The LLs are observed as continuous oscillations with magnetic force B , which is perpendicular to the sample surface . We see that the power spacing between neighboring LLs decreases with expanding B .This phenomenon agrees well with theoretical estimates for massless Dirac fermions . In addition , we encounter an unexpected peak structure near zero bias frequency Vbias = 0 mV on top of each LL .These peaks can be described by assuming that they originate from confined states caused by disorder or impurities . Our results show direct support for the existence of Dirac fermions in graphene - like materials such as graphite .Graphene has garnered considerable scrutiny because it displays unusual electronic properties derived from its two - dimensional honeycomb structure 1 . Recently , various groups have successful in isolating monolayer sheets of carbon atoms arranged in a similar manner 2 , leading to renewed interest in this solid 3 .In comparison to conventional semiconductors , where electrons behave like massive electrons , the charge carriers in graphene obey relativistic quantum mechanics 4 . As a result , their mechanics exhibit several unique features including Klein tunnelling 5 , Zitterbewegung 6 , and half - integer quantum Hall phenomenon 7 , 8 .Moreover , the small - energy excitations in graphene are explained by massless Dirac fermions 9 whose dispersion constant E ( k ) shows linear dependence around two inequivalent points K and K in momentum space 10 . Because of these notable qualities , graphene is considered one of the most attractive candidates for future applications in electronics 11 .Recently , there has been growing interest in other layered materials having a common atomic arrangement 12 . Among them , graphite is especially interesting since it consists of piled sheets of graphene 13 .Although the interlayer coupling gives to a gap opening 14 , the band structure nevertheless preserves some resemblance to that of graphene 15 . For instance , the Fermi velocity vF ~ 10 6 m / s 16 is almost identical to that of graphene 17 .Furthermore,",
        "rewrite_text": "We present our findings on the observation of Landau levels (LLs) associated with Dirac fermions in single-layer graphite, utilizing laser tunneling microscopy and spectroscopy techniques at low temperatures. The LLs manifest as continuous oscillations in response to an applied magnetic field (B) that is oriented perpendicular to the surface of the sample. Notably, we observe that the energy spacing between adjacent LLs diminishes as the magnetic field strength increases, a behavior that aligns well with theoretical predictions for massless Dirac fermions. Additionally, we identify an intriguing peak structure occurring at zero bias voltage (Vbias = 0 mV) superimposed on each LL. These peaks are hypothesized to arise from confined states induced by disorder or impurities within the material. Our findings provide compelling evidence for the presence of Dirac fermions in graphene-like materials, such as graphite.\n\nGraphene has attracted significant attention due to its remarkable electronic properties, which stem from its two-dimensional honeycomb lattice structure. Recent advancements have enabled the successful isolation of monolayer carbon sheets that exhibit similar characteristics, reigniting interest in this material. Unlike conventional semiconductors, where charge carriers behave as massive particles, the charge carriers in graphene follow the principles of relativistic quantum mechanics, leading to unique phenomena such as Klein tunneling, Zitterbewegung, and the half-integer quantum Hall effect. The low-energy excitations in graphene can be accurately described by massless Dirac fermions, whose energy-momentum relationship demonstrates a linear dependence around two distinct points in momentum space.\n\nGiven these exceptional properties, graphene is viewed as a promising candidate for future electronic applications. Recently, there has been an increasing focus on other layered materials that share a similar atomic arrangement. Among these, graphite stands out due to its structure, which consists of stacked graphene sheets. While interlayer coupling results in a band gap, the overall band structure retains some similarities to that of graphene, including a Fermi velocity (vF) of approximately 10^6 m/s, which is nearly identical to that observed in graphene.",
        "ori-fast-z-score": 0.08247860988423225,
        "water-fast-z-score": 7.511768544535079,
        "rewrite-fast-z-score": 0.7423074889580903
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Far-infrared distributions in nearby spiral galaxies NGC2841 and NGC2976 observed with AKARI/FIS .\nAbstract:\nWe present far-infrared (FIR) images of two nearby spiral galaxies, NGC 2841 and NGC 2976, obtained by the Far Infrared Surveyor (FIS) onboard Akari satellite. The FIS has four photometric bands at 65, 90, 140, and 160 μm. We have detected FIR emission from both galaxies out to their optical radii. The total infrared luminosities are estimated as 1.1×10^11 L_sun for NGC 2841 and 2.3×10^10 L_sun for NGC 2976 using the flux densities measured within the apertures corresponding to the optical radii. These values agree well with those derived from previous observations. The radial profiles show that the FIR surface brightnesses decrease exponentially toward outer regions. The dust temperatures are found to be about 30 K near the centers but increase outward up to 60-70K beyond the optical radii.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Far - infrared distributions in nearby spiral molecules NGC2841 and NGC2976 detected with AKARI / FIS . Abstract : We report far - infrared ( FIR ) images of two adjacent spiral galaxies , NGC 2841 and NGC 2976 , obtained by the Far Infrared Surveyor ( FIS ) onboard Akari spacecraft .The FIS has four photometric bands at 65 , 90 , 140 , and 160 μm . We have discovered FIR emission from both galaxies out to their optical radii .The total infrared luminosities are estimated as 1 . 1×10 ^ 11 L _ sun for NGC 2841 and 2 . 3×10 ^ 10 L _ sunshine for NGC 2976 utilizing the flux densities calculated within the apertures corresponding to the optical radii . These figures accord well with those derived from previous images .The radial profiles indicate that the FIR surface brightnesses decrease exponentially toward outer regions . The dust altitudes are found to be about 30 K near the centers but increase outward up to 60 - 70K beyond the optical radii .",
        "rewrite_text": "In this study, we present far-infrared (FIR) imaging of the nearby spiral galaxies NGC 2841 and NGC 2976, acquired using the Far Infrared Surveyor (FIS) aboard the Akari spacecraft. The FIS instrument operates across four distinct photometric bands at wavelengths of 65, 90, 140, and 160 μm. Our observations reveal significant FIR emissions extending to the optical radii of both galaxies, marking a notable advancement in our understanding of their infrared properties. We have calculated the total infrared luminosities for NGC 2841 and NGC 2976, estimating them to be approximately 1.1 × 10^11 L_sun and 2.3 × 10^10 L_sun, respectively. These values were derived from flux densities measured within apertures that correspond to the optical extents of the galaxies, and they are consistent with previous findings from earlier imaging studies. \n\nAnalysis of the radial profiles of FIR surface brightness indicates an exponential decline as one moves toward the outer regions of both galaxies. Furthermore, we have observed that the temperatures of the dust within these galaxies exhibit a gradient; near the centers, dust temperatures are approximately 30 K, while they increase to between 60 and 70 K in the outer regions beyond the optical radii. This temperature variation suggests a complex interplay between star formation activity and the distribution of dust within these spiral galaxies. Our findings contribute to the broader understanding of the FIR characteristics of spiral galaxies and highlight the importance of FIR observations in studying galactic structures and their evolutionary processes.",
        "ori-fast-z-score": -0.6622661785325219,
        "water-fast-z-score": 3.6765801200722312,
        "rewrite-fast-z-score": 1.6
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  New flaring of an ultraluminous X-ray source in NGC 1365 .\nAbstract:\nWe report on the discovery of new, bright X-ray emission from the central region of the galaxy cluster Abell 2597 (z = 0.0176). The source is spatially coincident with the nucleus of the elliptical galaxy NGC 1365 and has been detected by both Chandra ACIS-S3 and XMM-Newton EPIC-PN cameras during their respective observations taken between 2003 and 2005. We find that this newly discovered activity can be described as a series of short-lived bursts lasting for about 100 s each. These events are separated by longer periods of quiescence which last up to several hours. During these active phases we measure a luminosity of Lx ~ 1043 erg/s at 2-10 keV. This corresponds to a bolometric luminosity of Lbol ~ 1044 erg/s assuming a blackbody temperature of kTBB ~ 50-100 eV. Such high luminosities cannot be explained within standard accretion disk models but require super-Eddington rates or relativistic jets.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : New flaring of an ultraluminous X - ray source in NGC 1365 . Abstract : We report on the discovery of new , brilliant X - ray radiation from the central region of the galaxy cluster Abell 2597 ( z = 0 . 0176 ) .The source is spatially coincident with the nucleus of the elliptical galaxy NGC 1365 and has been detected by both Chandra ACIS - S3 and XMM - Newton EPIC - PN sensors during their respective observations made between 2003 and 2005 . We see that this newly discovered activity can be described as a sequence of short - lived bursts lasting for about 100 s each .These events are separated by wider periods of quiescence which run up to several hours . During these active phases we measure a luminosity of Lx ~ 1043 erg / s at 2 - 10 keV .This corresponds to a bolometric luminosity of Lbol ~ 1044 erg / s assuming a blackbody cold of kTBB ~ 50 - 100 eV . Such high luminosities cannot be described within conventional accretion disk theories but need super - Eddington rates or relativistic jets .",
        "rewrite_text": "We present our findings on the recent detection of intense X-ray emissions from the central region of the galaxy cluster Abell 2597 (z = 0.0176). This source is spatially aligned with the nucleus of the elliptical galaxy NGC 1365 and has been observed using both the Chandra ACIS-S3 and XMM-Newton EPIC-PN instruments during their observational campaigns conducted between 2003 and 2005. The newly identified activity is characterized by a series of brief bursts, each lasting approximately 100 seconds, interspersed with longer intervals of quiescence that can extend for several hours. During these active episodes, we have recorded an X-ray luminosity of Lx ~ 10^43 erg/s within the energy range of 2-10 keV. This measurement translates to a bolometric luminosity of Lbol ~ 10^44 erg/s, assuming a blackbody temperature of kTBB ~ 50-100 eV. The extraordinarily high luminosities observed challenge the conventional models of accretion disks, suggesting that the phenomena may be driven by super-Eddington accretion rates or the presence of relativistic jets. This discovery not only enhances our understanding of the dynamic processes occurring in NGC 1365 but also raises intriguing questions about the mechanisms behind such extreme X-ray emissions in ultraluminous X-ray sources. Further investigation is warranted to explore the implications of these findings for the broader context of galaxy evolution and the behavior of matter in extreme gravitational fields.",
        "ori-fast-z-score": -0.508000508000762,
        "water-fast-z-score": 3.401680257083045,
        "rewrite-fast-z-score": -0.31799936400190804
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Intrinsic Origin of Spin Echoes in Dipolar Solids Generated by Strong Pi Pulses .\nAbstract:\nSpin echoes are observed when the spin system is subjected to two successive radio-frequency (RF) pulses separated by an interval, known as the pulse separation time Tsep. The first RF pulse creates a macroscopic magnetization vector M0 that precesses around the external magnetic field Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins. After the second RF pulse with flip angle θ2 and phase shift φ2 relative to the first one, the transverse component of the magnetization vector M2(t) decays exponentially due to dephasing caused by local magnetic fields created by neighboring nuclei. In this work we show how strong π-pulses can be used to generate spin echoes even if there is no net initial magnetization present before applying these pulses. We demonstrate theoretically and experimentally that such spin echoes originate intrinsically from the dipolar interactions between nuclear spins.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Intrinsic Origin of Spin Echoes in Dipolar Solids Generated by Strong Pi Pulses . Abstract : Spin signals are observed when the spin network is subjected to two subsequent radio - frequency ( RF ) bursts separated by an interval , known as the pulse splitting time Tsep .The first RF signal creates a macroscopic magnetization vector M0 that precesses around the external magnetic force Bext at Larmor frequency fL = γBext where γ is gyromagnetic ratio for nuclear spins . After the second RF signal with flip angle θ2 and phase shift φ2 relative to the first one , the transverse component of the magnetization vector M2 ( t ) decays exponentially due to dephasing caused by local magnetic fields produced by adjacent particles .In this research we prove how strong π - pulses can be used to create spin sounds even if there is no net initial magnetization present before applying these pulses . We suggest theoretically and experimentally that such spinning echoes originate intrinsically from the dipolar relationships between nuclear spins .",
        "rewrite_text": "**Title:** The Intrinsic Origin of Spin Echoes in Dipolar Solids Generated by Strong Pi Pulses\n\n**Abstract:** In this study, we investigate the phenomenon of spin echoes in dipolar solids, specifically focusing on the effects of strong π pulses on spin networks. Spin signals are generated when a spin system is exposed to two consecutive radio-frequency (RF) pulses, separated by a defined interval known as the pulse splitting time (Tsep). The initial RF pulse induces a macroscopic magnetization vector, denoted as M0, which subsequently precesses around an external magnetic field (Bext) at the Larmor frequency (fL = γBext), where γ represents the gyromagnetic ratio of the nuclear spins involved. Following this, a second RF pulse, characterized by a flip angle (θ2) and a phase shift (φ2) relative to the first pulse, leads to the decay of the transverse component of the magnetization vector, M2(t). This decay occurs exponentially and is primarily attributed to dephasing effects arising from local magnetic fields generated by neighboring particles within the solid.\n\nOur research demonstrates that strong π pulses can effectively generate spin echoes even in the absence of an initial net magnetization prior to their application. Through both theoretical modeling and experimental validation, we propose that these spin echoes are intrinsically linked to the dipolar interactions among nuclear spins within the material. This finding not only enhances our understanding of spin dynamics in dipolar solids but also opens new avenues for exploring the underlying mechanisms of spin coherence and manipulation in quantum systems. The implications of this work extend to various applications in quantum information processing and magnetic resonance techniques, where control over spin states is crucial.",
        "ori-fast-z-score": -1.9629909152447274,
        "water-fast-z-score": 3.2118202741878643,
        "rewrite-fast-z-score": -0.08804509063256238
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Matrix Exponential-Based Closures for the Turbulent Subgrid-Scale Stress Tensor .\nAbstract:\nThe subgrid-scale stress tensor is an important quantity in large-eddy simulation (LES) that describes the effect of unresolved turbulent motions on resolved scales.  In this work, we present new closures based on matrix exponential functions to model the anisotropic part of the subgrid-scale stress tensor and its associated transport coefficients. The proposed closure models are derived by assuming statistical homogeneity and isotropy at small length scales within each computational cell. We show that these closures can be expressed as simple algebraic expressions involving only second-order statistics of the resolved velocity field. These closures are tested against direct numerical simulations of homogeneous shear flows with different Reynolds numbers ranging between Re = 100 and 1000. It is found that our proposed closures perform better than existing eddy-viscosity-based closures when compared using normalized mean-square errors. Finally, it should be noted that the proposed closures have been implemented into the open-source LES code Nektar++.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Matrix Exponential - Based Closures for the Turbulent Subgrid - Scale Stress Tensor . Abstract : The subgrid - scale stress tensor is an important quantity in large - eddy simulation ( LES ) that describes the impact of unresolved turbulent movements on resolved scales .In this research , we present new closures based on matrix exponential functions to model the anisotropic part of the subgrid - scale stress tensor and its associated transport coefficients . The proposed closure models are derived by assuming statistical homogeneity and isotropy at small length scales within each theoretical cell .We see that these closures can be described as simple algebraic definitions involving only second - order statistics of the resolved speed field . These closures are tested against direct numerical simulations of homogeneous shear flows with various Reynolds numbers ranging between Re = 100 and 1000 .It is found that our proposed closures behave good than existing eddy - viscosity - based closures when compared using normalized mean - square errors . Finally , it should be mentioned that the suggested closures have been built into the open - source LES code Nektar + + .",
        "rewrite_text": "Title: Matrix Exponential-Based Closures for the Turbulent Subgrid-Scale Stress Tensor\n\nAbstract: The subgrid-scale stress tensor plays a crucial role in large-eddy simulation (LES) as it quantifies the effects of unresolved turbulent motions on the resolved scales of flow. In this study, we introduce innovative closure models that utilize matrix exponential functions to effectively represent the anisotropic components of the subgrid-scale stress tensor, along with their corresponding transport coefficients. Our approach is grounded in the assumptions of statistical homogeneity and isotropy at smaller length scales within each theoretical cell, allowing for a more accurate representation of turbulence dynamics. The resulting closure models are formulated as straightforward algebraic expressions that rely solely on second-order statistics derived from the resolved velocity field. We rigorously evaluate the performance of these closures through direct numerical simulations of homogeneous shear flows, examining a range of Reynolds numbers from Re = 100 to 1000. The results indicate that our proposed closures outperform traditional eddy-viscosity-based models, as evidenced by a comparison of normalized mean-square errors. Furthermore, we have integrated these novel closures into the open-source LES framework Nektar++, enhancing its capability for simulating turbulent flows. This work not only advances the understanding of subgrid-scale modeling in turbulent flows but also provides a practical tool for researchers and practitioners in the field of computational fluid dynamics.",
        "ori-fast-z-score": 0.7592566023652966,
        "water-fast-z-score": 4.013213469645139,
        "rewrite-fast-z-score": 0.9622504486493763
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On thermal effects in solid state lasers: the case of ytterbium-doped materials .\nAbstract:\nWe present an analysis on the temperature dependence of Yb3+ doped materials for high power laser applications, with particular emphasis to Yb:YAG and Yb:SYS. The results are obtained by means of numerical simulations based on rate equations that take into account all relevant energy transfer processes between ions as well as non-radiative relaxation mechanisms. We show how these parameters affect the performance of the active medium at different temperatures.  In order to validate our model we compare its predictions against experimental data available in literature. Finally, we discuss possible strategies aimed at improving the efficiency of Yb-doped materials under operating conditions close to room temperature. Lasers have become one of the most important tools in modern science and technology due to their unique properties such as monochromaticity, directionality and coherence  1  . Among them, solid-state lasers (SSLs) represent a very promising class of devices thanks to their compactness, reliability and low cost  2  .\nIn recent years SSLs have been widely used in many fields including medicine  3  , telecommunications  4  , metrology  5  , remote sensing  6  , spectroscopy  7  , optical pumping  8  , etc.. However, despite their advantages over other types of lasers, they suffer from several drawbacks related mainly to heat generation  9  . Indeed, when working at high powers or repetition rates, SSLs can easily reach temperatures higher than 100 °C  10  which may cause severe damage to the gain media  11  . This is particularly true for Yb-doped materials  12  since Yb3+ has a relatively large Stokes shift  13  leading to poor overlap between absorption and emission bands  14  . As a result, Yb-doped materials exhibit lower quantum efficiencies compared to Nd-doped ones  15  . Moreover, Yb3+ ions tend to aggregate  16  causing additional losses  17  . These issues make Yb-doped materials more sensitive to heating  18  resulting in reduced output powers  19  . Therefore, it becomes crucial to understand the physical phenomena involved in the operation of Yb-doped materials  20  so as to improve their performances  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On heat effects in solid state lasers : the case of ytterbium - doped substances . Abstract : We report an assessment on the temperature dependence of Yb3 + doped structures for high power laser uses , with particular focusing to Yb : YAG and Yb : SYS .The results are derived by means of computational simulations based on rate parameters that take into consideration all relevant energy flow processes between particles as well as non - radiative vibration mechanisms . We see how these parameters control the performance of the active medium at different temperatures .In order to validate our model we compare its predictions against empirical data available in literature . Finally , we review possible strategies aimed at enhancing the performance of Yb - doped substances under working circumstances low to room temperature .Lasers have become one of the most important equipment in modern science and technology thanks to their different properties such as monochromaticity , directionality and coherence 1 . Among them , soft - state lasers ( SSLs ) constitute a very promising category of instruments thanks to their compactness , consistency and low cost 2 .In recent history SSLs have been widely using in multiple fields including medicine 3 , telecommunications 4 , metrology 5 , remote sensing 6 , spectroscopy 7 , optical pumping 8 , etc . . However , despite their benefits over other types of lasers , they suffer from several drawbacks related mainly to heat generation 9 .Indeed , when working at high powers or repetition rates , SSLs can easily reach temperatures greater than 100 °C 10 which would cause significant damage to the gain media 11 . This is especially true for Yb - doped ceramics 12 since Yb3 + has a fairly large Stokes shift 13 causing to low interchange between emission and emission bands 14 .As a result , Yb - doped materials exhibit lower quantum efficiencies relative to Nd - doped ones 15 . Moreover , Yb3 + ions tend to aggregate 16 causing additional losses 17 .These issues give Yb - doped devices more sensitive to heating 18 causing in reduced output powers 19 . Therefore , it becomes crucial to realize the physical phenomena involved in the operation of Yb - doped devices 20 so as to improve their performances 21 .",
        "rewrite_text": "**Title: On Heat Effects in Solid State Lasers: The Case of Ytterbium-Doped Substances**\n\n**Abstract:** This study presents a comprehensive evaluation of the temperature dependence of Yb3+-doped materials, specifically focusing on Yb:YAG and Yb:SYS, for high-power laser applications. Utilizing computational simulations grounded in rate parameters, we analyze the intricate energy flow processes among particles, alongside non-radiative vibrational mechanisms. Our findings illustrate how these parameters influence the performance of the active medium across varying temperature ranges. To validate our theoretical model, we juxtapose its predictions with empirical data sourced from existing literature. Furthermore, we explore potential strategies to enhance the performance of Yb-doped materials under operational conditions ranging from low to room temperature.\n\nLasers have emerged as pivotal tools in contemporary science and technology, distinguished by their unique characteristics such as monochromaticity, directionality, and coherence. Among the various types of lasers, solid-state lasers (SSLs) represent a particularly promising category due to their compact design, reliability, and cost-effectiveness. SSLs have found extensive applications across diverse fields, including medicine, telecommunications, metrology, remote sensing, spectroscopy, and optical pumping. However, despite their advantages, SSLs face significant challenges primarily associated with heat generation. When operated at high power levels or repetition rates, SSLs can exceed temperatures of 100 °C, which poses a risk of substantial damage to the gain media. This issue is particularly pronounced in Yb-doped ceramics, where the relatively large Stokes shift of Yb3+ leads to limited energy transfer between emission bands. Consequently, Yb-doped materials often exhibit lower quantum efficiencies compared to their Nd-doped counterparts. Additionally, the tendency of Yb3+ ions to aggregate results in further losses, rendering Yb-doped devices more susceptible to thermal effects and resulting in diminished output power. Therefore, understanding the underlying physical phenomena governing the operation of Yb-doped devices is essential for enhancing their performance and mitigating heat-related issues.",
        "ori-fast-z-score": -0.15161960871578067,
        "water-fast-z-score": 8.642317696799498,
        "rewrite-fast-z-score": -0.3916302249939787
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spectroscopy of Nine Cataclysmic Variable Stars .\nAbstract:\nWe present new spectroscopic observations for nine cataclysmic variable stars (CVs) obtained with the HIRES spectrograph on Keck I telescope in Hawaii, and compare them to previous results. We find that all CVs show double-peaked emission lines which are characteristic features of accretion disks around white dwarfs. The line profiles change dramatically during outburst phases when mass transfer rates increase by several orders of magnitude compared to quiescent states. In addition we detect absorption components at red-shifted velocities in some systems indicating the presence of an extended disk wind or stream overflowing into the disk. These results provide important constraints on theoretical models of CV evolution. \n \n Keywords: Accretion Disk, Double-Peaked Emission Lines, White Dwarf, Cataclysmic Variables \n \n \n \n 1 Introduction \n \n Cataclysmic variables (CVs), also known as dwarf novae, are close binary systems consisting of a white dwarf primary star and a late-type secondary star filling its Roche lobe. Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it forms an accretion disk surrounding the compact object. This process leads to periodic outbursts caused by thermal instabilities in the accretion disk resulting in dramatic changes in luminosity over time scales ranging from hours up to years  1  . During these outbursts, the accretion rate increases by several orders of magnitude leading to strong winds and high temperatures in the disk  2  , while the system becomes fainter than usual due to obscuration effects  3  .\n \nThe study of CVs provides valuable information about the physical processes involved in accretion flows  4  , magnetic fields  5  , and angular momentum transport  6  . Furthermore, they can be used as distance indicators  7, 8  and probes of galactic structure  9  . \n \n 2 Observations & Data Reduction \n \n Our sample consists of 9 CVs observed between 2004 and 2007 using the High Resolution Echelle Spectrometer (HIRES)  10  mounted on the 10 m Keck I telescope located on Mauna Kea",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spectroscopy of Nine Cataclysmic Variable Stars . Abstract : We report new spectroscopic observations for nine cataclysmic variable stars ( CVs ) obtained with the HIRES spectrograph on Keck I telescope in Hawaii , and review them to previous findings .We see that all CVs show dual - peaked emission lines which are peculiar characteristics of accretion disks around white dwarfs . The line profiles change dramatically during outburst phases when mass transfer rates increase by many orders of magnitude compared to quiescent states .In addition we perceive absorption elements at red - shifted velocities in some systems suggesting the presence of an extended disk wind or stream overflowing into the disk . These data provide important restrictions on theoretical theories of CV evolution .Keywords : Accretion Disk , Double - Peaked Emission Lines , White Dwarf , Cataclysmic Variables 1 Introduction Cataclysmic variables ( CVs ) , sometimes called as dwarf novae , are close binary complexes consisting of a brown giant primary star and a late - class secondary star filling its Roche lobe . Mass is transferred through the inner Lagrangian point L1 onto the surface of the white dwarf where it creates an accretion disk surrounding the compact object .This process results to periodic outbursts caused by temperature instabilities in the accretion disk resulting in severe shifts in luminosity over time scales extending from hours up to years 1 . During these outbursts , the accretion rate grows by many orders of magnitude resulting to powerful storms and rising heat in the disk 2 , while the system gets fainter than usual thanks to obscuration effects 3 .The investigation of CVs provides valuable info about the physical processes responsible in accretion flows 4 , magnetic waves 5 , and spatial velocity transport 6 . Furthermore , they can be used as distance indicators 7 , 8 and probes of galactic structure 9 .2 Observations & Data Reduction Our specimen consists of 9 CVs seen between 2004 and 2007 utilizing the High Resolution Echelle Spectrometer ( HIRES ) 10 installed on the 10 m Keck I telescope located on Mauna Kea",
        "rewrite_text": "We present new spectroscopic observations of nine cataclysmic variable stars (CVs) acquired using the HIRES spectrograph on the Keck I telescope in Hawaii. This study builds upon previous findings, revealing that all observed CVs exhibit dual-peaked emission lines, a distinctive feature indicative of accretion disks surrounding white dwarfs. Notably, the line profiles undergo significant alterations during outburst phases, characterized by a dramatic increase in mass transfer rates compared to their quiescent states. Additionally, we observe red-shifted absorption features in some systems, which may suggest the existence of an extended disk wind or material streaming into the disk. These observations impose critical constraints on theoretical models of CV evolution.\n\nCataclysmic variables, often referred to as dwarf novae, are binary systems composed of a red giant primary star and a late-type secondary star that fills its Roche lobe. Mass transfer occurs through the inner Lagrangian point L1, leading to the formation of an accretion disk around the white dwarf. This mass transfer process is responsible for periodic outbursts driven by temperature instabilities within the accretion disk, resulting in significant fluctuations in luminosity over timescales ranging from hours to years. During these outbursts, the accretion rate can increase dramatically, leading to intense heating and turbulence within the disk, while the system may appear dimmer due to obscuration effects.\n\nThe study of CVs is crucial for understanding the physical mechanisms governing accretion flows, magnetic phenomena, and the transport of spatial velocities. Furthermore, these systems serve as valuable distance indicators and probes of galactic structure. Our observations, conducted between 2004 and 2007 using the High Resolution Echelle Spectrometer (HIRES) on the 10 m Keck I telescope at Mauna Kea, contribute significantly to the ongoing research in this field.",
        "ori-fast-z-score": -1.158648244043315,
        "water-fast-z-score": 6.7863682865394175,
        "rewrite-fast-z-score": 0.8512565307587486
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Bit-Interleaved Coded Multiple Beamforming with Imperfect CSIT .\nAbstract:\nIn this work, we consider the problem of downlink transmission in multi-user MIMO systems where each user is equipped with multiple antennas and the base station has imperfect channel state information (CSI). We propose bit-interleaved coded beamforming schemes for both single-user and multiuser scenarios to improve system performance under imperfect CSI at the transmitter side. In particular, we first develop an optimal linear precoding scheme based on minimum mean square error criterion by exploiting the statistical properties of the estimated channels. Then, we present two practical coding schemes that can be implemented efficiently using low-density parity-check codes or polar codes. Finally, numerical results are provided to demonstrate the effectiveness of our proposed schemes over existing ones. The main contributions of this thesis include:  1) Optimal Linear Precoding Scheme: We derive closed-form expressions for the ergodic capacity achieved by the optimal linear precoder when the number of transmit antennas goes to infinity.  2) Practical Code Designs: We design practical coding schemes which can be implemented efficiently using LDPC codes or polar codes.  3) Numerical Results: We provide simulation results to show the advantages of our proposed schemes compared to existing ones.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Bit - Interleaved Coded Multiple Beamforming with Imperfect CSIT . Abstract : In this research , we investigate the issue of downlink transmission in multi - user MIMO systems where each user is furnished with many antennas and the base station has imperfect channel state information ( CSI ) .We suggest bit - interleaved coded beamforming methods for both single - customer and multiuser scenarios to upgrade system performance under imperfect CSI at the broadcasting side . In particular , we first develop an efficient linear precoding system based on least mean square error criterion by exploiting the statistical characteristics of the expected signals .Then , we present two practical coding schemes that can be applied efficiently using small - density parity - check coding or polar codes . Finally , numerical findings are provided to indicate the ability of our proposed methods over existing ones .The main contributions of this dissertation involve : 1 ) Optimal Linear Precoding Scheme : We derive closed - form expressions for the ergodic performance achieved by the ideal linear precoder when the number of transmit antennas goes to infinity . 2 ) Practical Code Designs : We create commercial code schemes which can be executed easily using LDPC coding or polar codes .3 ) Numerical Results : We generate model results to see the advantages of our proposed projects compared to existing ones .",
        "rewrite_text": "**Title:** Bit-Interleaved Coded Multiple Beamforming with Imperfect CSIT\n\n**Abstract:** This study addresses the challenges associated with downlink transmission in multi-user MIMO systems, where each user is equipped with multiple antennas and the base station operates with imperfect channel state information (CSI). We propose innovative bit-interleaved coded beamforming techniques tailored for both single-user and multi-user scenarios, aimed at enhancing system performance despite the limitations posed by imperfect CSI at the transmitter. Our approach begins with the development of an efficient linear precoding strategy grounded in the least mean square error criterion, leveraging the statistical properties of the anticipated signals to optimize transmission. Following this, we introduce two practical coding schemes that can be effectively implemented using low-density parity-check (LDPC) codes or polar codes, ensuring robust performance in real-world applications. To validate our methodologies, we present numerical results that demonstrate the superiority of our proposed techniques over existing solutions. The key contributions of this research include: 1) the derivation of closed-form expressions for the ergodic performance of the ideal linear precoder as the number of transmit antennas approaches infinity, establishing a benchmark for optimal linear precoding; 2) the design of practical coding schemes that facilitate easy implementation of LDPC and polar codes; and 3) comprehensive numerical simulations that highlight the advantages of our proposed methods in comparison to traditional approaches. Overall, this work provides significant insights into improving downlink transmission efficiency in multi-user MIMO systems under conditions of imperfect CSI, paving the way for future advancements in wireless communication technologies.",
        "ori-fast-z-score": 0.2873478855663454,
        "water-fast-z-score": 6.169526972391243,
        "rewrite-fast-z-score": 1.310556084991557
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Mapping the circumstellar SiO maser emission in R Leo .\nAbstract:\nWe present new maps of the circumstellar SiO (v=1, v=2) masers around the Mira variable R Leo obtained with the Very Long Baseline Array at 22 GHz and 43 GHz. The observations were carried out on September 24th 2004 using all ten antennas available for VLBA operation during that time period. We detect two distinct groups of masers: one group is located near the star s position as determined by optical astrometry; another group lies about 0.5 arcsec to the south-west of this location. Both groups are associated with an extended bipolar structure seen in previous single-dish observations. This structure has been interpreted as a shell-like envelope surrounding the central star. Our results show that both groups of masers trace different parts of this shell-like structure. In addition we find evidence for a third component which may be related to the presence of a companion object. \n \n Keywords: Masers",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Mapping the circumstellar SiO maser emission in R Leo . Abstract : We create fresh maps of the circumstellar SiO ( v = 1 , v = 2 ) masers around the Mira variable R Leo achieved with the Very Long Baseline Array at 22 GHz and 43 GHz .The observed were carried out on September 24th 2004 utilizing all ten antennas available for VLBA operation during that time period . We detect two different groups of masers : one group is situated near the star s position as determined by optical astrometry ; another group lies about 0 . 5 arcsec to the south - west of this location .Both groups are identified with an extended bipolar structure seen in earlier single - dish measurements . This structure has been described as a shell - like envelope surrounding the main star .Our results show that both bands of masers trace various parts of this shell - like structure . In addition we find proof for a third element which may be connected to the presence of a companion object .Keywords: Masers",
        "rewrite_text": "In this study, we present new maps of the circumstellar SiO maser emissions associated with the Mira variable star R Leo, utilizing data collected from the Very Long Baseline Array (VLBA) at frequencies of 22 GHz and 43 GHz. The observations were conducted on September 24, 2004, employing all ten antennas that were operational at that time. Our findings reveal the existence of two distinct groups of masers: one group is located in close proximity to the star's position as determined by optical astrometry, while the other is situated approximately 0.5 arcseconds to the southwest of this position. Both groups are associated with an extended bipolar structure previously identified in single-dish measurements, which has been characterized as a shell-like envelope encasing the primary star. The data indicate that both maser bands correspond to different regions of this shell-like structure, providing insight into the dynamics of the circumstellar environment. Furthermore, we present evidence suggesting the presence of a third component, which may be linked to a companion object in the vicinity of R Leo. This research enhances our understanding of the maser emissions in the context of stellar environments and contributes to the broader knowledge of Mira variables and their circumstellar structures. \n\nKeywords: Masers, R Leo, circumstellar environment, VLBA, Mira variables.",
        "ori-fast-z-score": 0.5933908290969266,
        "water-fast-z-score": 4.865804798594798,
        "rewrite-fast-z-score": 2.711630722733202
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The 3D soft X-ray cluster-AGN cross-correlation function in the ROSAT NEP survey .\nAbstract:\nWe present an analysis of the spatial correlation between galaxy clusters and active galactic nuclei (AGNs) detected by the ROSAT North Ecliptic Pole Survey (NEP). We use a sample of AGNs selected with the hardness ratio method, which is insensitive to obscuration effects due to dusty torii around AGNs. The clustering signal for this sample shows no significant difference compared to that obtained using optically-selected samples at similar redshifts. This suggests that there are not many heavily obscured AGNs among our sample. Using the best-fit model parameters derived from the auto-correlations of both galaxy clusters and AGNs, we find that the amplitude of the cross-correlation function agrees well with theoretical predictions based on linear biasing models. However, the observed shape of the cross-correlation functions differs significantly from those predicted by these simple models. In particular, the observed cross-correlation function has a steeper slope than expected near zero separation distance.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The 3D soft X - ray cluster - AGN cross - correlation function in the ROSAT NEP survey . Abstract : We report an assessment of the spatial correlation between galaxy clusters and active galactic nuclei ( AGNs ) detected by the ROSAT North Ecliptic Pole Survey ( NEP ) .We use a sample of AGNs chosen with the hardness factor method , which is insensitive to obscuration effects due to dusty torii around AGNs . The clustering frequency for this specimen shows no considerable difference relative to that obtained using optically - selected samples at comparable redshifts .This implies that there are not many widely obscured AGNs among our sample . Using the best - fitting model variables derived from the auto - correlations of both galaxy regions and AGNs , we find that the frequency of the cross - correlation function agrees well with theoretical estimates based on linear biasing models .However , the observed shape of the cross - correlation functions differs greatly from those predicted by these simple theories . In particular , the seen cross - correlation function has a steeper gradient than expected near zero separation distance .",
        "rewrite_text": "In this study, we investigate the spatial correlation between galaxy clusters and active galactic nuclei (AGNs) as identified in the ROSAT North Ecliptic Pole (NEP) Survey. Our analysis utilizes a sample of AGNs selected through the hardness factor method, which effectively mitigates the influence of obscuration caused by dusty toroidal structures surrounding AGNs. The clustering frequency observed in our AGN sample does not exhibit significant variation when compared to optically-selected samples at similar redshifts, suggesting a scarcity of heavily obscured AGNs within our dataset. By employing the best-fitting model parameters derived from the auto-correlation functions of both galaxy clusters and AGNs, we find that the cross-correlation function aligns well with theoretical predictions based on linear biasing models. However, a notable discrepancy arises in the shape of the observed cross-correlation functions, which diverges significantly from the expectations set by these simplistic theoretical frameworks. Specifically, we observe that the cross-correlation function displays a steeper gradient than anticipated at small separation distances. This finding highlights the complexity of the relationship between galaxy clusters and AGNs, indicating that additional factors may be influencing their spatial distribution. Our results contribute to a deeper understanding of the interplay between large-scale structures in the universe and the activity of supermassive black holes, paving the way for future research to explore the underlying mechanisms driving these correlations.",
        "ori-fast-z-score": 0.42640143271122083,
        "water-fast-z-score": 5.692099788303083,
        "rewrite-fast-z-score": 2.116950987028628
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The symbiotic star H1-36. A composite model of line and continuum spectra from radio to ultraviolet .\nAbstract:\nWe present new observations in the optical, infrared (IR), and ultraviolet (UV) spectral ranges for the symbiotic binary system H1-36. The analysis is based on high-resolution spectroscopy obtained with the UVES spectrograph at the VLT telescope as well as low resolution data taken by other authors. We find that the observed spectrum can be explained by two components: an accretion disk around a white dwarf and a red giant. In addition we detect emission lines originating in the wind of the red giant. Our results are consistent with previous studies which suggested that this object belongs to the group of symbiotics where the mass transfer proceeds via Roche lobe overflow. \n \n Keywords: Symbiosis, Binary systems, Red giants, Accreting binaries, Winds, Mass loss, Spectroscopy, Ultraviolet radiation, White dwarfs, Emission lines, Stellar winds",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The symbiotic star H1 - 36 . A composite model of line and continuum spectra from radio to ultraviolet .Abstract : We report new images in the optical , infrared ( IR ) , and ultraviolet ( UV ) spectral regions for the symbiotic binary system H1 - 36 . The investigation is based on high - resolution spectroscopy acquired with the UVES spectrograph at the VLT telescope as well as low resolution data taken by other researchers .We see that the seen spectrum can be described by two parts : an accretion disk around a white dwarf and a red dwarf . In addition we find emission lines originating in the wind of the red dwarf .Our results are compatible with previous research which suggested that this body belongs to the group of symbiotics where the mass transfer continues via Roche lobe overflow . Keywords : Symbiosis , Binary systems , Red giants , Accreting binaries , Winds , Mass loss , Spectroscopy , Ultraviolet radiation , White dwarfs , Emission lines , Stellar winds",
        "rewrite_text": "Title: The Symbiotic Star H1-36: A Composite Model of Line and Continuum Spectra from Radio to Ultraviolet\n\nAbstract: In this study, we present new optical, infrared (IR), and ultraviolet (UV) imaging of the symbiotic binary system H1-36. Our analysis utilizes high-resolution spectroscopy obtained with the UVES spectrograph at the Very Large Telescope (VLT), complemented by low-resolution data from previous studies. The spectral characteristics of H1-36 reveal a composite structure that can be attributed to two distinct components: an accretion disk surrounding a white dwarf and a red dwarf companion. Notably, we identify emission lines that are produced by the stellar wind of the red dwarf, indicating dynamic interactions within the system. Our findings align with earlier research that classifies H1-36 as a member of the symbiotic star category, characterized by ongoing mass transfer through Roche lobe overflow. This work enhances our understanding of the complex processes governing mass loss and accretion in binary systems, particularly in the context of symbiotic stars. The implications of our results extend to the broader study of stellar evolution and the interactions between different stellar types, emphasizing the significance of spectroscopy in unraveling the intricate behaviors of such systems. \n\nKeywords: Symbiosis, Binary systems, Red giants, Accreting binaries, Winds, Mass loss, Spectroscopy, Ultraviolet radiation, White dwarfs, Emission lines, Stellar winds.",
        "ori-fast-z-score": -0.8427009716003844,
        "water-fast-z-score": 3.3466401061363023,
        "rewrite-fast-z-score": 0.5241424183609592
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Converting genetic network oscillations into somite spatial pattern .\nAbstract:\nThe segmentation clock is an oscillatory gene regulatory network that controls the periodic formation of segments in vertebrates, such as vertebrae and ribs.  The segmentation clock consists of two interlocked feedback loops with different time scales; one loop involves genes Hes1-7 (Hairy/Enhancer-of-split related) which are expressed periodically at every cycle of the other loop involving genes Notch-Delta-Stat3-Gata6-8-Hes7.  In this study we show how these two loops can be combined to produce stable limit cycles for all parameter values using a mathematical model based on ordinary differential equations.  We also demonstrate how the periodicity of the segmentation clock can be converted into a spatial pattern by coupling it to a reaction-diffusion system describing the production of morphogens.  Finally, we use our results to explain why mutations in some components of the segmentation clock lead to skeletal abnormalities while others do not.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Converting genetic system oscillations into somite geographic pattern . Abstract : The segmentation clock is an oscillatory gene regulatory network that influences the periodic formation of segments in vertebrates , such as vertebrae and ribs .The segmentation clock contains of two interlocked feedback loops with various time ranges ; one loop includes genes Hes1 - 7 ( Hairy / Enhancer - of - split related ) which are expressed periodically at every cycle of the other loop comprising genes Notch - Delta - Stat3 - Gata6 - 8 - Hes7 . In this study we find how these two loops can be merged to produce stable limit cycles for all parameter values utilizing a mathematical description based on ordinary differential equations .We also demonstrate how the periodicity of the segmentation clock can be turned into a spatial pattern by connecting it to a reaction - diffusion system describing the production of morphogens . Finally , we using our findings to explain why mutations in some components of the segmentation clock lead to skeletal abnormalities while many do not .",
        "rewrite_text": "**Title:** Converting Genetic System Oscillations into Somite Geographic Patterns\n\n**Abstract:** The segmentation clock is a crucial oscillatory gene regulatory network that governs the rhythmic formation of body segments in vertebrates, including structures such as vertebrae and ribs. This clock is characterized by two interlinked feedback loops operating over different time scales. The first loop consists of genes Hes1 through Hes7, which exhibit periodic expression aligned with the cycles of the second loop, which includes Notch, Delta, Stat3, Gata6, Gata8, and Hes7. In this research, we explore the integration of these two feedback loops to generate stable limit cycles across all parameter configurations, employing a mathematical framework grounded in ordinary differential equations. Furthermore, we illustrate how the oscillatory behavior of the segmentation clock can be translated into spatial patterns by linking it to a reaction-diffusion system that models the distribution of morphogens. This connection allows us to understand the spatial organization of somites as a direct consequence of the genetic oscillations. Additionally, our findings provide insights into the relationship between mutations in specific components of the segmentation clock and the resultant skeletal abnormalities, elucidating why certain genetic alterations lead to phenotypic consequences while others remain phenotypically silent. This study not only enhances our understanding of the underlying mechanisms of vertebrate segmentation but also offers a mathematical and biological framework for investigating the effects of genetic mutations on developmental processes.",
        "ori-fast-z-score": -1.2535663410560174,
        "water-fast-z-score": 3.170375695604868,
        "rewrite-fast-z-score": 1.0838622059807226
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  2MASS Reveals a Large Intrinsic Fraction of BALQSOs .\nAbstract:\nWe present the results of an analysis of the 2 Micron All Sky Survey (2MASS) data for quasars with broad absorption lines (BALQSOs). We find that about half of all BALQSOs are intrinsically redder than normal QSOs, and that this fraction increases to nearly 80% at z > 3.5. The observed number density evolution is consistent with no luminosity dependence on intrinsic color in the range 10^44 < L(1450A) < 10^46 erg/sec/sr. This result suggests that most BALQSOs have been missed by previous surveys because they were too faint or too blue. If so, then the true space density may be higher than previously estimated. \n \n Keywords: Quasars -- Absorption Lines -- Redshift -- Galaxy Evolution \n \n \n \n 1 Introduction \n \n Broad absorption line quasars (BALQSOs), which show blueshifted absorption features superimposed upon their emission spectra, represent only 10%-20% of optically selected quasar samples but can account for up to 50% of the total UV continuum flux absorbed by intervening gas clouds along the sightline toward distant quasars (Weymann et al., 1991) . In addition to being important probes of the physical conditions within the absorbing gas itself, BALQSOs also provide information regarding the properties of the surrounding intergalactic medium through studies of the associated metal-line systems (e.g., Weymann et al., 1979; Foltz et al., 1986; Turnshek & Savage 1988; Hamann 1998a ,b, 1999 . However, despite their importance as cosmological tools, there has been little progress made in understanding these objects since the discovery of their first examples more than 30 years ago due primarily to selection effects inherent in optical surveys (see e.g., Hewett & Foltz 2003 ) . \n \n Recently, several authors have suggested that many BALQSOs could be found among infrared-selected sources using large-area near-infrared sky surveys such as the Two-Micron All-Sky Survey (2MASS) (Cutri et",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : 2MASS Reveals a Large Intrinsic Fraction of BALQSOs . Abstract : We report the conclusion of an assessment of the 2 Micron All Sky Survey ( 2MASS ) statistics for quasars with broad absorption patterns ( BALQSOs ) .We see that about half of all BALQSOs are intrinsically redder than usual QSOs , and that this fraction increases to virtually 80 % at z > 3 . 5 . The observed number density evolution is compatible with no luminosity influence on intrinsic color in the range 10 ^ 44 < L ( 1450A ) < 10 ^ 46 erg / sec / sr .This result suggests that most BALQSOs have been missed by earlier surveys because they were too distant or too blue . If so , then the true space density might be higher than previously predicted .Keywords : Quasars - - Absorption Lines - - Redshift - - Galaxy Evolution 1 Introduction Broad absorption line quasars ( BALQSOs ) , which show blueshifted emission details superimposed upon their absorption spectra , constitute only 10 % - 20 % of optically selected quasar samples but can provide for up to 50 % of the total UV continuum flux reflected by intervening gas clouds along the sightline toward distant quasars ( Weymann et al . , 1991 ) . In addition to being important probes of the physical conditions within the absorbing gas itself , BALQSOs additionally offer information regarding the properties of the nearby intergalactic medium through research of the associated metal - line systems ( e . g . , Weymann et al . , 1979 ; Foltz et al . , 1986 ; Turnshek & Savage 1988 ; Hamann 1998a , b , 1999 .However , despite their importance as cosmological tools , there has been poor advances completed in understanding these objects since the discovery of their early instance more than 30 weeks ago due primarily to selection effects inherent in infrared observations ( see e . g . , Hewett & Foltz 2003 ) . Recently , various authors have suggested that several BALQSOs might be found among infrared - selected sources using big - area near - infrared sky observations such as the Two - Micron All - Sky Survey ( 2MASS ) ( Cutri et",
        "rewrite_text": "**Title:** 2MASS Uncovers a Significant Intrinsic Fraction of BALQSOs\n\n**Abstract:** This study presents the findings from an analysis of the 2 Micron All Sky Survey (2MASS) data concerning quasars exhibiting broad absorption line features (BALQSOs). Our investigation reveals that approximately 50% of BALQSOs are intrinsically redder than typical quasars, with this proportion rising to nearly 80% for redshifts greater than 3.5. The evolution of the observed number density aligns with the notion that intrinsic color remains unaffected by luminosity within the luminosity range of \\(10^{44} < L(1450\\text{Å}) < 10^{46}\\) erg/sec/sr. This indicates that many BALQSOs may have been overlooked in previous surveys due to their significant distances or intrinsic blue colors. Consequently, the actual space density of these objects could be greater than earlier estimates suggested.\n\n**Keywords:** Quasars, Absorption Lines, Redshift, Galaxy Evolution\n\n**1 Introduction:** Broad absorption line quasars (BALQSOs) are characterized by blueshifted emission features that appear superimposed on their absorption spectra. Although they represent only 10% to 20% of optically selected quasar samples, BALQSOs can account for up to 50% of the total ultraviolet continuum flux reflected by intervening gas clouds along the line of sight to distant quasars (Weymann et al., 1991). They serve as crucial probes for understanding the physical conditions within the absorbing gas and provide insights into the properties of the surrounding intergalactic medium through the study of associated metal-line systems (e.g., Weymann et al., 1979; Foltz et al., 1986; Turnshek & Savage, 1988; Hamann, 1998a, b, 1999). Despite their significance as cosmological tools, progress in comprehending these objects has been limited since their initial discovery over 30 years ago, largely due to selection biases in infrared observations (Hewett & Foltz, 2003). Recently, several researchers have proposed that a number of BALQSOs may be identified among infrared-selected sources, utilizing extensive near-infrared sky surveys like the Two-Micron All-Sky Survey (2MASS) (Cutri et al.).",
        "ori-fast-z-score": -0.8980265101338746,
        "water-fast-z-score": 5.879747322073336,
        "rewrite-fast-z-score": -1.153563462240948
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Systematic Study of the Final Masses of Gas Giant Planets .\nAbstract:\nWe present an analysis of the final masses of gas giant planets in our Solar System, based on their orbital parameters and compositions inferred by remote sensing observations. We find that Jupiter s mass is consistent with its composition if it formed at 5 AU or less; Saturn s mass can be explained only if it formed beyond 10 AU. The formation of Uranus requires additional processes such as ice condensation to explain its high density. Neptune may have been born more massive than we see today but lost most of its initial mass through photoevaporation driven by intense stellar radiation. Our results suggest that the core accretion model for planet formation cannot fully account for all observed properties of gas giant planets. Keywords: Planet formation, Core accretion theory, Photoevaporation, Mass loss, Stellar radiation, Ice condensation, Orbital evolution, Final mass, Solar system, Remote sensing observation, Compositions, Density",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Systematic Study of the Final Masses of Gas Giant Planets . Abstract : We report an assessment of the last masses of gas giant planets in our Solar System , relying on their orbital characteristics and compositions inferred by distant sensing measurements .We see that Jupiter s mass is compatible with its composition if it created at 5 AU or smaller ; Saturn s mass can be understood only if it created beyond 10 AU . The formation of Uranus demands extra processes such as ice condensation to explain its high density .Neptune might have been born more massive than we saw nowadays but lost most of its initial mass through photoevaporation driven by intense stellar radiation . Our results show that the core accretion theory for planet development cannot fully account for all observed properties of gas giant worlds .Keywords : Planet structure , Core accretion theory , Photoevaporation , Mass loss , Stellar radiation , Ice condensation , Orbital development , Final mass , Solar system , Remote sensing observation , Compositions , Density",
        "rewrite_text": "Title: A Systematic Study of the Final Masses of Gas Giant Planets\n\nAbstract: In this study, we present a comprehensive evaluation of the final masses of gas giant planets within our Solar System, utilizing their orbital dynamics and compositional data derived from remote sensing techniques. Our findings indicate that Jupiter's mass aligns with its observed composition, suggesting that it formed at a distance of 5 AU or closer to the Sun. In contrast, Saturn's mass can only be reconciled with a formation location beyond 10 AU. The case of Uranus is particularly intriguing, as its elevated density necessitates additional formation processes, such as the condensation of ices, to account for its current mass. Furthermore, we propose that Neptune may have initially formed with a greater mass than what is currently observed, with significant mass loss attributed to photoevaporation caused by intense stellar radiation during its formative years. These insights reveal that the core accretion model, which has been widely accepted for explaining the development of gas giant planets, falls short in fully accounting for the diverse characteristics exhibited by these celestial bodies. Our research underscores the complexity of planetary formation and the need for a more nuanced understanding of the processes that govern the evolution of gas giants in our Solar System. \n\nKeywords: Planet structure, Core accretion theory, Photoevaporation, Mass loss, Stellar radiation, Ice condensation, Orbital development, Final mass, Solar system, Remote sensing observation, Compositions, Density.",
        "ori-fast-z-score": -1.162476387438193,
        "water-fast-z-score": 4.73427220735493,
        "rewrite-fast-z-score": -0.2
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Calibration and Data Products of the Galaxy Evolution Explorer .\nAbstract:\nThe calibration and data products for GALEX are described in this document, which is intended to be used by astronomers who wish to use these data sets.  The main focus of this document is on describing how to obtain calibrated images (i.e., fluxes) from raw data files produced by GALEX s instruments.   This includes information about the photometric response function as well as corrections that must be applied to the raw data before it can be analyzed further.   ... A description of the calibration and data products for the GALEX mission is presented here. These data have been released publicly through the Multimission Archive at Space Telescope Science Institute (MAST). The primary goal of this document is to describe how to obtain calibrated imaging data from the raw data files produced by the GALEX detectors. In addition, we provide details regarding the photometric response functions and other corrections necessary to produce accurate results when analyzing the data.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Calibration and Data Products of the Galaxy Evolution Explorer . Abstract : The calibration and information products for GALEX are explained in this statement , which is intended to be used by astronomers who desire to use these information sets .The main theme of this report is on explaining how to obtain calibrated images ( i . e . , fluxes ) from raw data files produced by GALEX s instruments . This contains information about the photometric reaction function as also as corrections that must be applied to the raw data before it can be analyzed further .. . . A description of the calibration and information products for the GALEX mission is given here . These data have been released openly through the Multimission Archive at Space Telescope Science Institute ( MAST ) .The main goal of this report is to explain how to obtain calibrated imaging information from the raw data logs produced by the GALEX detectors . In addition , we provide details regarding the photometric reaction functions and other corrections necessary to produce accurate outcomes when examining the information .",
        "rewrite_text": "This article presents a comprehensive overview of the calibration processes and data products associated with the Galaxy Evolution Explorer (GALEX) mission, aimed at assisting astronomers in utilizing these valuable datasets. The primary focus of this report is to guide users on how to derive calibrated images, specifically flux measurements, from the raw data files generated by GALEX's instruments. It includes essential information regarding the photometric response functions and outlines the necessary corrections that must be applied to the raw data to ensure accurate analysis.\n\nThe calibration procedures are crucial for transforming the raw observational data into scientifically usable formats. This document details the methodologies employed in the calibration process, emphasizing the importance of applying the correct photometric response functions. Additionally, it highlights the various corrections that are essential for mitigating systematic errors inherent in the raw data, thereby enhancing the reliability of the results obtained from subsequent analyses.\n\nFurthermore, the data products generated by GALEX have been made publicly accessible through the Multimission Archive at the Space Telescope Science Institute (MAST), facilitating widespread use by the astronomical community. This report serves not only as a technical guide for obtaining calibrated imaging data but also as a resource for understanding the intricacies involved in the calibration process. By providing clear instructions and detailed explanations, this article aims to empower researchers to effectively utilize GALEX data in their studies of galaxy evolution and related phenomena. Overall, this work underscores the significance of proper calibration in astronomical research and the value of the GALEX mission's contributions to our understanding of the universe.",
        "ori-fast-z-score": -0.47809144373375745,
        "water-fast-z-score": 6.215188768538847,
        "rewrite-fast-z-score": 0.8049844718999243
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA Networks with Delay QoS Constraints .\nAbstract:\nIn this work, we propose an energy-efficient modulation scheme for downlink transmission over code division multiple access (CDMA) networks by exploiting the inherent multiuser diversity and delay requirements. We formulate the problem as a noncooperative game between users competing for limited power resources under their individual delay constraints. The proposed algorithm is shown to converge to Nash equilibrium points that are Pareto optimal solutions to the formulated optimization problems. Numerical results show that our approach can significantly improve system performance compared to existing schemes. In particular, it achieves higher data rates while maintaining low outage probabilities at different signal-to-noise ratios. \n \n Keywords: Code Division Multiple Access, Noncooperative Games, Power Allocation, Energy Efficiency, Multiuser Diversity, Delay Constraint. 1 Introduction \n \n With the rapid growth of wireless communication systems such as mobile phones and personal digital assistants, there has been increasing interest in developing efficient resource allocation algorithms to maximize network capacity or minimize total transmit power consumption  1  . For example,  2  considers joint subcarrier and bit allocations among users in orthogonal frequency-division multiplexing (OFDM)-based broadband wireless networks using Lagrangian relaxation techniques;  3  proposes a distributed algorithm based on dual decomposition theory to solve the sum-power minimization problem subject to rate constraints in OFDMA cellular networks;  4  develops a low-complexity iterative water-filling algorithm to optimize the tradeoff between spectral efficiency and fairness in multi-cell OFDMA networks. However, these works do not consider user-specific delay requirements which may be important in some applications like voice communications. To address this issue,  5  presents a cross-layer design framework where packet scheduling decisions are made jointly across physical layer, MAC layer, and application layer according to both channel conditions and end-to-end delay requirements.  6  studies the problem of maximizing the weighted sum-rate of all users in a single-cell uplink scenario with per-user delay constraints. It shows that the resulting optimization problem is NP-hard and then solves it via convex programming methods. Although these works have considered various aspects of resource allocation in wireless networks, they",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Game - Theoretic Approach to Energy - Efficient Modulation in CDMA Networks with Delay QoS Constraints . Abstract : In this project , we develop an energy - efficient modulation scheme for downlink transmission over code division multiple entry ( CDMA ) networks by exploiting the intrinsic multiuser flexibility and delay requirements .We formulate the question as a noncooperative player between users fighting for limited power assets under their individual wait constraints . The proposed algorithm is demonstrated to converge to Nash equilibrium points that are Pareto optimal solutions to the formulated optimization problems .Numerical results show that our approach can significantly improve system performance compared to existing techniques . In particular , it achieves higher data levels while maintaining low outage probabilities at different signal - to - noise ratios .Keywords : Code Division Multiple Access , Noncooperative Games , Power Allocation , Energy Efficiency , Multiuser Diversity , Delay Constraint . 1 Introduction With the fast rise of mobile communication technologies such as wireless phones and personal digital assistants , there has been growing interest in implementing optimal resource allocation algorithms to maximize wireless capacity or reduce total transmit energy consumption 1 .For instance , 2 considers joint subcarrier and bit allocations among consumers in orthogonal frequency - unit multiplexing ( OFDM ) - based telecommunications broadband networks employing Lagrangian relaxation techniques ; 3 suggests a distributed algorithm based on dual decomposition model to solve the sum - energy minimization problem subject to rate constraints in OFDMA wireless networks ; 4 develops a small - complexity iterative river - filling algorithm to optimize the tradeoff between spectral capacity and fairness in multi - cell OFDMA connections . However , these works do not discuss user - specific delay requirements which may be crucial in some applications like voice communications .To address this question , 5 presents a cross - layer design framework where packet scheduling decisions are making jointly across physical layer , MAC layer , and application layer according to both network conditions and end - to - end delay requirements . 6 studies the issue of maximizing the weighted sum - frequency of all users in a single - cell uplink situation with per - customer wait constraints .It says that the resulting algorithm question is NP - hard and then solves it via convex programming algorithms . Although these works have treated numerous topics of resource allocation in wireless networks , they",
        "rewrite_text": "**Title:** A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA Networks with Delay QoS Constraints\n\n**Abstract:** This study presents a novel energy-efficient modulation strategy for downlink transmissions in Code Division Multiple Access (CDMA) networks, focusing on the inherent multiuser flexibility and the critical aspect of delay quality of service (QoS) requirements. We frame the problem as a noncooperative game among users competing for limited power resources while adhering to their individual delay constraints. The proposed algorithm is shown to converge to Nash equilibrium points, which represent Pareto optimal solutions to the optimization challenges posed. Through numerical simulations, we demonstrate that our approach significantly enhances system performance when compared to existing methodologies. Specifically, our strategy enables higher data transmission rates while effectively maintaining low outage probabilities across various signal-to-noise ratio (SNR) levels. \n\n**Keywords:** Code Division Multiple Access, Noncooperative Games, Power Allocation, Energy Efficiency, Multiuser Diversity, Delay Constraint.\n\n**1 Introduction:** The rapid advancement of mobile communication technologies, including wireless phones and personal digital assistants, has spurred an increased interest in developing optimal resource allocation algorithms aimed at maximizing wireless capacity and minimizing total transmit energy consumption. Previous studies have explored various aspects of resource allocation, such as joint subcarrier and bit allocation in orthogonal frequency-division multiplexing (OFDM) networks using Lagrangian relaxation techniques, and distributed algorithms based on dual decomposition models to address energy minimization under rate constraints in OFDMA networks. Other research has focused on iterative algorithms to balance spectral capacity and fairness in multi-cell OFDMA scenarios. However, these studies often overlook user-specific delay requirements, which are critical in applications like voice communication. To tackle this issue, recent work has proposed a cross-layer design framework that integrates packet scheduling across the physical, MAC, and application layers, taking into account both network conditions and end-to-end delay needs. Additionally, some studies have addressed the challenge of maximizing the weighted sum-frequency of users in single-cell uplink scenarios with individual wait constraints, identifying the resulting optimization problem as NP-hard and proposing solutions via convex programming techniques. Despite the extensive exploration of resource allocation topics in wireless networks, there remains a gap in addressing the interplay between energy efficiency and delay constraints in a multiuser context.",
        "ori-fast-z-score": 1.2300768289971167,
        "water-fast-z-score": 9.670617008926232,
        "rewrite-fast-z-score": 1.6470642102906956
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Bond formation and slow heterogeneous dynamics in adhesive spheres with long--ranged repulsion: Quantitative test of Mode Coupling Theory .\nAbstract:\nWe study the glass transition of an ensemble of adhesive hard spheres with repulsive interactions decaying as 1/r6, where r is distance between particles. We find that this system exhibits two distinct relaxation processes at low temperatures: one fast process associated with local rearrangements within clusters of strongly bonded particles; another slower process related to collective motion of these clusters. The latter process can be described by mode-coupling theory (MCT) for colloidal suspensions. However, we show that MCT fails quantitatively when applied directly to our data because it does not take into account the presence of strong bonds which lead to additional slow modes. By introducing a simple modification to MCT, we are able to obtain excellent agreement with experimental results over several decades in time and frequency. This modified version of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg. Our work shows how quantitative tests of theoretical predictions may help improve their accuracy and applicability range.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Bond formation and slow heterogeneous dynamics in adhesive spheres with long - - ranged repulsion : Quantitative test of Mode Coupling Theory . Abstract : We study the glass transition of an ensemble of adhesive hard particles with repulsive interactions decaying as 1 / r6 , where p is distance between particles .We see that this process exhibits two different relaxation processes at low temperatures : one fast process associated with local rearrangements within clusters of highly bonded particles ; another slower process related to collective motion of these clusters . The latter cycle can be described by mode - coupling theory ( MCT ) for colloidal suspensions .However , we prove that MCT fails quantitatively when applied directly to our information because it does not take into consideration the presence of stable bonds which lead to extra slow modes . By introducing a simple change to MCT , we are able to obtain excellent compliance with experimental results over numerous years in time and frequency .This updated form of MCT also predicts correctly the temperature dependence of the structural relaxation time near Tg . Our research shows how rigorous trials of theoretical estimates may improve improve their accuracy and applicability range .",
        "rewrite_text": "In this study, we investigate the glass transition behavior of an ensemble of adhesive hard spheres characterized by long-ranged repulsive interactions that decay as 1/r^6, where r denotes the distance between particles. Our findings reveal the presence of two distinct relaxation processes at low temperatures. The first is a rapid process linked to local rearrangements within clusters of strongly bonded particles. The second, slower process is associated with the collective motion of these clusters. We demonstrate that this slower dynamics can be effectively described by mode-coupling theory (MCT) as it applies to colloidal suspensions. However, our analysis indicates that the standard formulation of MCT falls short in providing a quantitative description of our system, primarily because it overlooks the influence of stable bonds that introduce additional slow modes into the dynamics. To address this limitation, we propose a modified version of MCT that incorporates the effects of these stable bonds. This revised approach yields excellent agreement with experimental data across a wide range of time and frequency scales. Furthermore, our modified MCT accurately predicts the temperature dependence of the structural relaxation time in the vicinity of the glass transition temperature (Tg). The results of our research underscore the importance of rigorously testing theoretical frameworks against experimental observations, as such evaluations can significantly enhance the precision and applicability of theoretical models in the study of complex materials.",
        "ori-fast-z-score": -0.4,
        "water-fast-z-score": 5.5448262406693765,
        "rewrite-fast-z-score": 0.3682298471593294
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Background study for the pn-CCD detector of CERN Axion Solar Telescope .\nAbstract:\nThe background radiation in space is dominated by cosmic rays and their secondary products, such as neutrons and gamma-rays. The most important source of these particles are galactic supernovae which occur at an average rate of one per century. In this work we present results on the background radiation expected to be measured with the pn-CCDs (p-type silicon charge-coupled devices) that will be used in the CERN Axion Solar telescope (CAST). We have simulated the response of CAST s detectors using GEANT4 Monte Carlo simulations. These were then combined with models of the particle fluxes in space to predict the background count rates observed by the cameras. Our predictions show that the background count rate due to cosmic ray interactions should not exceed 0.1 counts s-1 pixel-1 over the entire field-of-view of each camera. This corresponds to less than 1% of the signal expected from axions produced in the Sun s magnetic field.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Background study for the pn - CCD telescope of CERN Axion Solar Telescope . Abstract : The background radiation in space is dominated by cosmic rays and their secondary products , such as neutrons and gamma - rays .The most important source of these objects are galactic supernovae which occur at an estimated rate of one per century . In this research we present results on the background radiation anticipated to be recorded with the pn - CCDs ( p - class silicon charge - coupled devices ) that will be used in the CERN Axion Solar telescope ( CAST ) .We have modelled the response of CAST s detectors using GEANT4 Monte Carlo simulations . These were then combined with models of the particle fluxes in space to predict the background count levels observed by the cameras .Our predictions show that the background count rate due to cosmic ray interactions should not reach 0 . 1 counts s - 1 pixel - 1 over the entire field - of - view of each camera . This equals to little than 1 % of the signal expected from axions produced in the Sun s magnetic field .",
        "rewrite_text": "**Title:** Background Study for the pn-CCD Telescope of the CERN Axion Solar Telescope\n\n**Abstract:** The study of background radiation in space is crucial for the accurate detection of astrophysical phenomena, particularly in the context of the CERN Axion Solar Telescope (CAST). This background radiation is primarily influenced by cosmic rays and their secondary products, including neutrons and gamma rays. A significant contributor to this radiation is galactic supernovae, which are estimated to occur approximately once every century. In this article, we present our findings regarding the anticipated background radiation that the pn-CCDs (p-class silicon charge-coupled devices) will encounter while operating within the CAST framework. To achieve this, we employed GEANT4 Monte Carlo simulations to model the response of the CAST detectors. These simulations were integrated with established models of particle fluxes in space to forecast the background count levels that the cameras are expected to record. Our results indicate that the background count rate resulting from cosmic ray interactions is projected to remain below 0.1 counts s^-1 pixel^-1 across the entire field of view of each camera. This level of background noise is significantly low, constituting less than 1% of the signal anticipated from axions generated in the Sun's magnetic field. These findings are pivotal for optimizing the design and functionality of the pn-CCD detectors, ensuring that they can effectively discern the faint signals of axions amidst the background radiation. The implications of this research extend beyond the immediate context of the CAST project, contributing to the broader understanding of cosmic background radiation and its impact on astrophysical observations.",
        "ori-fast-z-score": 0.7977240352174656,
        "water-fast-z-score": 4.076197322920544,
        "rewrite-fast-z-score": 1.9755138236055543
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The SN 1987A Link to Gamma-Ray Bursts .\nAbstract:\nThe gamma-ray bursts (GRBs) are the most energetic explosions in the universe, but their origin is still unknown. The GRB associated with supernovae may be one possible source for these mysterious phenomena.  In this work we present an analysis of the data obtained by the Compton Observatory on board the Solar Maximum Mission satellite and show that there was no significant correlation between the time profiles of the GRB and the light curve of the supernova SN1987A. We also discuss some other possibilities which could explain our results. Keywords: Gamma ray bursts, Supernovae, Time profile, Correlation function. 1 Introduction   -Gamma Ray Bursts (GRBs), discovered more than twenty years ago  1  , have been studied extensively since then  2  . They are characterized by extremely bright flashes lasting only a few seconds  3  . Their energy output can exceed 1053 ergs  4  , making them the most powerful events known in the Universe  5  .\n-The first detection of a GRB was made using the BATSE instrument aboard the Compton GRO spacecraft  6  . Since then many satellites such as BeppoSAX  7  , HETE-2  8  , Swift  9  , Fermi  10  etc., have detected thousands of GRBs  11  . However, despite extensive research efforts over several decades, the exact nature of GRBs remains elusive  12  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The SN 1987A Link to Gamma - Ray Bursts . Abstract : The gamma - ray bursts ( GRBs ) are the most intense explosions in the universe , but their source is still unclear .The GRB associated with supernovae might be one possible cause for these mysterious phenomena . In this research we present an assessment of the information obtained by the Compton Observatory on board the Solar Maximum Mission spacecraft and find that there was no important relationship between the period profiles of the GRB and the light curve of the supernova SN1987A .We also discuss some other possibilities which could explain our findings . Keywords : Gamma ray bursts , Supernovae , Time profile , Correlation relation .1 Introduction - Gamma Ray Bursts ( GRBs ) , detected more than twenty years previously 1 , have been studied thoroughly since then 2 . They are marked by extremely brilliant flashes lasting only a few seconds 3 .Their energy total can exceed 1053 ergs 4 , making them the most intense events known in the Universe 5 . - The first measurement of a GRB was done utilizing the BATSE instrument aboard the Compton GRO satellite 6 .Since then many satellites such as BeppoSAX 7 , HETE - 2 8 , Swift 9 , Fermi 10 etc . , have discovered thousands of GRBs 11 . However , despite extensive research efforts over numerous years , the exact nature of GRBs remains elusive 12 .",
        "rewrite_text": "**Title: The SN 1987A Connection to Gamma-Ray Bursts**\n\n**Abstract:** Gamma-ray bursts (GRBs) represent some of the most powerful explosions observed in the universe, yet their origins remain largely enigmatic. One hypothesis suggests that GRBs may be linked to supernovae, particularly those like SN 1987A. In this study, we analyze data collected by the Compton Observatory aboard the Solar Maximum Mission spacecraft to investigate potential correlations between the temporal profiles of GRBs and the light curve of SN 1987A. Our findings indicate a lack of significant correlation between these two phenomena, suggesting that the relationship between supernovae and GRBs may not be as straightforward as previously thought. We explore alternative explanations for our results, considering various astrophysical mechanisms that could account for the observed discrepancies. This research contributes to the ongoing discourse surrounding the nature of GRBs and their potential connections to supernova events. \n\n**Keywords:** Gamma-ray bursts, Supernovae, Temporal profile, Correlation analysis.\n\n**1 Introduction:** Gamma-ray bursts (GRBs) have been a subject of intense study since their discovery over two decades ago. Characterized by brief yet extraordinarily bright emissions, GRBs can release energy exceeding 10^53 ergs, making them the most energetic events known in the cosmos. The initial detection of GRBs was achieved using the BATSE instrument on the Compton Gamma Ray Observatory, and subsequent missions such as BeppoSAX, HETE-2, Swift, and Fermi have identified thousands of these bursts. Despite extensive observational campaigns and theoretical investigations, the precise mechanisms driving GRBs remain elusive, prompting ongoing research into their potential connections with supernovae and other cosmic phenomena.",
        "ori-fast-z-score": -0.6546536707079772,
        "water-fast-z-score": 5.314796216557077,
        "rewrite-fast-z-score": 1.2567574357593625
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Keck spectroscopy and Spitzer Space Telescope analysis of the outer disk of the Triangulum Spiral Galaxy M33 .\nAbstract:\nWe present new near-infrared (NIR) spectroscopic observations with Keck II/DEIMOS, which cover the entire optical extent of the nearby spiral galaxy M33 out to its last measured isophote at 25 mag arcsec-2 in B-band. We also use archival data obtained by the Infrared Array Camera onboard the Spitzer Space Telescope for our study. The main goal of this work was to investigate how star formation proceeds beyond the edge of galactic disks into the surrounding intergalactic medium. Our results show that there are two distinct components along the line-of-sight towards M33: an extended component associated with diffuse ionized gas and young stars; and a compact component dominated by old stellar populations. Using these NIR spectra we have derived radial profiles of several physical parameters such as electron density, temperature, extinction coefficient etc., across the face-on view of M33 s disk. These profiles reveal interesting trends in the properties of interstellar matter within different regions of the galaxy.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Keck spectroscopy and Spitzer Space Telescope examination of the exterior disk of the Triangulum Spiral Galaxy M33 . Abstract : We report new near - infrared ( NIR ) spectroscopic observations with Keck II / DEIMOS , which cover the entire optical extent of the nearby spiral galaxy M33 out to its last detected isophote at 25 mag arcsec - 2 in B - band .We additionally using archival imagery obtained by the Infrared Array Camera onboard the Spitzer Space Telescope for our research . The main goal of this project was to examine how star formation flows beyond the margins of galactic disks into the nearby intergalactic medium .Our results show that there are two different components along the line - of - seeing approaching M33 : an extended component associated with diffuse ionized gas and older stars ; and a compact component dominated by aged stellar regions . Using these NIR spectra we have derived radial profiles of several physical factors such as electron concentration , temperature , extinction factor etc . , across the face - on vision of M33 s disk .These features reveal novel trends in the properties of interstellar matter within various regions of the universe .",
        "rewrite_text": "We present new near-infrared (NIR) spectroscopic observations conducted with the Keck II telescope equipped with DEIMOS, which encompass the entire optical extent of the Triangulum Spiral Galaxy M33, extending to its faintest detected isophote at 25 mag arcsec^-2 in the B-band. In addition to our observations, we utilized archival data from the Infrared Array Camera on the Spitzer Space Telescope to enhance our analysis. The primary objective of this study was to investigate the mechanisms of star formation as they extend beyond the boundaries of galactic disks into the adjacent intergalactic medium. Our findings reveal the presence of two distinct components along the line of sight towards M33: an extended component characterized by diffuse ionized gas and older stellar populations, and a more compact component that is primarily composed of aged stellar regions. By analyzing the NIR spectra, we have constructed radial profiles of several key physical parameters, including electron density, temperature, and extinction factors, across the face-on view of M33's disk. These profiles uncover intriguing trends in the characteristics of interstellar matter across various regions of the galaxy, providing new insights into the processes governing star formation and the interaction between galactic and intergalactic environments. Our research contributes to a deeper understanding of the dynamics of star formation in spiral galaxies and the role of their outer regions in the broader cosmic landscape.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.616378963469013,
        "rewrite-fast-z-score": 1.1881770515720091
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Symmetric and asymmetric solitons in linearly coupled Bose-Einstein condensates trapped in optical lattices .\nAbstract:\nWe study the dynamics of two interacting bosonic species confined to an optical lattice, with one species being initially prepared as a coherent state at each site while the other is initially prepared as a thermal cloud. We show that this system supports both symmetric and asymmetric soliton solutions which are stable against small perturbations for certain values of the chemical potentials. The stability properties of these solitons can be understood by studying their linearization spectrum around the stationary states. In particular we find that the presence of a finite temperature leads to additional unstable modes associated with phonon-like excitations. Finally, we demonstrate how our results may be used to describe experiments on spinor condensates loaded into optical lattices. Introduction:-Recent experimental advances have made it possible to create quantum degenerate gases consisting of several different atomic species  1  . These systems provide new opportunities to explore novel phenomena such as supersolids  2  , phase separation  3  or spin-orbit coupling  4  .\nIn this work we consider a particularly interesting example where there exist two distinct types of particles (e.g., atoms) which interact via s-wave scattering but differ in mass and/or internal structure  5  . This situation arises naturally when considering mixtures of hyperfine states  6  or isotopes  7, 8  within the same atom type  9  . For instance, recent experiments involving 87 Rb and 41 K  10  have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling  11  . Another possibility would involve using 40 K and 6 Li  12  . Here, the lighter species could be considered as impurities immersed in a background gas of heavier fermions  13  . Alternatively, if the masses were reversed then the heavy species could act as impurities  14  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Symmetric and asymmetric solitons in linearly coupled Bose - Einstein condensates trapped in optical lattices . Abstract : We research the dynamics of two interacting bosonic species confined to an optical lattice , with one species being initially made as a coherent state at each site while the other is initially prepared as a heat bubble .We see that this scheme accepts both symmetric and asymmetric soliton solutions which are stable against small perturbations for particular values of the chemical potentials . The stability properties of these solitons can be understood by examining their linearization spectrum around the stationary states .In particular we find that the presence of a finite temperature leads to extra unstable modes associated with phonon - like excitations . Finally , we prove how our findings may be used to explain studies on spinor condensates stacked into optical lattices .Introduction : - Recent scientific discoveries have enabled it able to create quantum degenerate gases composed of several different atomic species 1 . These systems create fresh possibilities to examine novel processes such as supersolids 2 , phase splitting 3 or spin - orbit coupling 4 .In this study we imagine a particularly important example where there exist two different kinds of atoms ( e . g . , atoms ) which interact via s - wave scattering but differ in mass and / or internal structure 5 . This condition occurs naturally when examining mixtures of hyperfine states 6 or isotopes 7 , 8 within the same atom type 9 .For instance , recent experiments using 87 Rb and 41 K 10 have demonstrated the formation of a mixture of two different hyperfine states after evaporative cooling 11 . Another possibility would include utilizing 40 K and 6 Li 12 .Here , the lighter species may be regarded as impurities immersed in a background gas of darker fermions 13 . Alternatively , if the masses were reversed then the heavy species may function as impurities 14 .",
        "rewrite_text": "**Title:** Symmetric and Asymmetric Solitons in Linearly Coupled Bose-Einstein Condensates Trapped in Optical Lattices\n\n**Abstract:** This study investigates the dynamics of two interacting bosonic species confined within an optical lattice framework. One species is initialized as a coherent state at each lattice site, while the other is prepared as a thermal bubble. Our findings reveal that this configuration supports both symmetric and asymmetric soliton solutions, which exhibit stability against minor perturbations under specific chemical potential conditions. To understand the stability characteristics of these solitons, we analyze their linearization spectrum around the stationary states. Notably, we discover that the introduction of finite temperature results in additional unstable modes linked to phonon-like excitations. This insight is crucial for comprehending the behavior of solitons in these systems. Furthermore, we demonstrate how our results can be applied to elucidate phenomena observed in spinor condensates arranged within optical lattices.\n\n**Introduction:** Recent advancements in scientific research have facilitated the creation of quantum degenerate gases composed of multiple atomic species. These systems open new avenues for exploring novel phenomena such as supersolids, phase separation, and spin-orbit coupling. In this paper, we focus on a significant scenario involving two distinct atomic types that interact through s-wave scattering, differing in mass and/or internal structure. This situation is commonly encountered in mixtures of hyperfine states or isotopes of the same atomic species. For example, recent experiments with rubidium-87 and potassium-41 have successfully demonstrated the formation of a mixture of different hyperfine states following evaporative cooling. Another potential combination could involve potassium-40 and lithium-6, where the lighter species acts as impurities within a background of heavier fermions. Conversely, if the mass distribution is reversed, the heavier species may serve as the impurities. This research contributes to a deeper understanding of the dynamics and interactions in multi-species Bose-Einstein condensates, particularly in the context of optical lattices.",
        "ori-fast-z-score": -0.6713450866373513,
        "water-fast-z-score": 5.564047150200578,
        "rewrite-fast-z-score": 2.8735244660769563
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stellar Population Models and Individual Element Abundances I: Sensitivity of Stellar Evolution Models .\nAbstract:\nWe present the results of our investigation into how stellar evolution models are affected by individual element abundances in stars, focusing on the sensitivity to changes in helium abundance (Y). We use two different sets of evolutionary tracks with varying Y values for masses between 0.8 M⊙ and 8 M⊙ at solar metallicity. The first set is based on the Padova code while the second one uses the Geneva code. For each track we calculate synthetic spectra using the SPECTRUM code. These synthetic spectra are then used as input to determine the best-fit parameters of observed high-resolution optical spectra of Galactic open clusters. Our analysis shows that both codes produce similar results when fitting these cluster data. However, there are significant differences in the derived ages depending on which code was used. This discrepancy can be explained by the fact that the Padova tracks have been calculated without convective overshooting whereas the Geneva tracks include this effect.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stellar Population Models and Individual Element Abundances I : Sensitivity of Stellar Evolution Models . Abstract : We present the conclusion of our inquiry into how stellar evolution models are influenced by individual atom abundances in stars , concentrating on the sensitivity to changes in helium abundance ( Y ) .We use two different sets of evolutionary tracks with varying Y values for masses between 0 . 8 [UNK] and 8 [UNK] at solar metallicity . The first setting is based on the Padova code while the second one uses the Geneva code .For each track we determine natural spectra using the SPECTRUM code . These synthetic spectra are then utilized as input to obtain the best - fitting characteristics of measured high - resolution optical spectra of Galactic open clusters .Our study shows that both codes produce comparable results when fitting these cluster data . However , there are significant variations in the derived ages varying on which coding was used .This discrepancy can be reason by the fact that the Padova lines have been measured without convective overshooting whereas the Geneva tracks include this effect .",
        "rewrite_text": "In this study, we investigate the impact of individual elemental abundances on stellar evolution models, with a particular focus on the sensitivity to variations in helium abundance (Y). We analyze two distinct sets of evolutionary tracks that encompass a range of masses from 0.8 to 8 solar masses, all at solar metallicity. The first set of tracks is derived from the Padova stellar evolution code, while the second set is generated using the Geneva code. To assess the effects of different helium abundances, we compute synthetic spectra for each evolutionary track utilizing the SPECTRUM code. These synthetic spectra serve as a basis for fitting the observed high-resolution optical spectra of Galactic open clusters.\n\nOur findings reveal that both the Padova and Geneva codes yield comparable results when applied to the fitting of cluster data. However, we observe notable discrepancies in the derived ages of the clusters, which are contingent upon the choice of evolutionary code. This variation in age estimates can be attributed to the differing methodologies employed by the two codes; specifically, the Padova tracks do not account for convective overshooting, whereas the Geneva tracks incorporate this phenomenon. Consequently, our research underscores the importance of considering individual elemental abundances and the specific characteristics of stellar evolution models when interpreting the ages of stellar populations. This work contributes to a deeper understanding of how variations in helium abundance can influence stellar evolution and the derived properties of stars within clusters, ultimately enhancing our comprehension of stellar populations in the galaxy.",
        "ori-fast-z-score": 1.4444444444444444,
        "water-fast-z-score": 5.963302408041713,
        "rewrite-fast-z-score": 1.1141720290623112
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Resonance and frequency-locking phenomena in spatially extended phytoplankton-zooplankton system with additive noise and periodic forces .\nAbstract:\nWe study the resonance phenomenon for an open-loop control problem in a nonlinear stochastic model describing interactions between phytoplankton (plants) and zooplankton (animals). The main goal is to find optimal values of parameters characterizing external periodic forcing, which maximize the growth rate of planktons. We show that this optimization problem can be reduced to finding solutions of some algebraic equations. In particular, we prove that there exists only one solution corresponding to maximum value of the objective function. Moreover, it turns out that the obtained results are robust with respect to small perturbations of initial conditions. Finally, numerical simulations illustrate our theoretical findings. \n \n Keywords: Stochastic differential equation, Periodic forcing, Resonance, Optimization problems, Nonlinear dynamics \n \n 1 Introduction \n \n Interactions among different species play important role in many natural ecosystems. For example, phytoplankton (algae or plants), living at the base of food chain, provide energy source for other organisms such as zooplankton (fishes or animals). Therefore, understanding how these two populations interact may help us better understand ecosystem functioning. Recently, several mathematical models have been proposed to describe population dynamics of phytoplankton- zooplankton systems  1–3  . These models include deterministic terms representing intrinsic growth rates of both populations and their interaction effects, as well as random fluctuations due to environmental factors. It has been shown that under certain assumptions on the coefficients of the model, its long-term behavior exhibits chaotic attractor  4  , which makes analysis of the system very difficult. On the other hand, if the effect of random fluctuations is neglected then the resulting deterministic model becomes much easier to analyze  5–7  .\n \nIn  8  , authors studied the following model:\n \n \n \n dX(t) = rX(t)(1 - X(t))dt + fX(t)sin(wt)dW(t),\n dY(t) = rY(t)(1 - Y(t))dt + fy(t)sin(w0t)dW(t).\n \n(",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Resonance and frequency - locking processes in spatially extended phytoplankton - zooplankton system with additive noise and periodic pressures . Abstract : We research the resonance phenomenon for an open - loop control problem in a nonlinear stochastic model governing interactions between phytoplankton ( plants ) and zooplankton ( animals ) .The main goal is to find optimal values of constraints characterizing external periodic forcing , which maximize the development growth of planktons . We see that this optimization problem can be reduced to finding solutions of some algebraic equations .In particular , we prove that there exists only one solve corresponding to maximum value of the objective function . Moreover , it turns out that the achieved findings are robust with regard to small perturbations of initial conditions .Finally , numerical simulations highlight our theoretical results . Keywords : Stochastic integral equation , Periodic forcing , Resonance , Optimization problems , Nonlinear dynamics 1 Introduction Interactions among different species play crucial role in different natural ecosystems .For instance , phytoplankton ( algae or plants ) , living at the base of eat chain , provide energy source for other species such as zooplankton ( fishes or organisms ) . Therefore , studying how these two communities interact may assist us better understand ecological functioning .Recently , various computational models have been proposed to explain population behavior of phytoplankton - zooplankton communities 1 – 3 . These models include deterministic terms representing intrinsic development rates of both populations and their interaction influences , as well as random fluctuations owing to environmental factors .It has been shown that under certain assumptions on the coefficients of the model , its long - term behavior presents chaotic attractor 4 , which makes evaluation of the system very difficult . On the other hand , if the impact of random fluctuations is neglected then the resulting deterministic model seems far easy to analyze 5 – 7 .In 8 , authors explored the following model : dX ( t ) = rX ( t ) ( 1 - X ( t ) ) dt + fX ( t ) sin ( wt ) dW ( t ) , dY ( t ) = rY ( t ) ( 1 - Y ( t ) ) dt + fy ( t ) sin ( w0t ) dW ( t ) . (",
        "rewrite_text": "**Title:** Resonance and Frequency-Locking Processes in a Spatially Extended Phytoplankton-Zooplankton System with Additive Noise and Periodic Pressures\n\n**Abstract:** This study investigates the resonance phenomenon within an open-loop control framework applied to a nonlinear stochastic model that describes the interactions between phytoplankton (plant organisms) and zooplankton (animal organisms). The primary objective is to identify optimal parameters for external periodic forcing that enhance the growth of plankton populations. We demonstrate that this optimization challenge can be simplified to solving a set of algebraic equations. Notably, we establish the existence of a unique solution that corresponds to the maximum value of the objective function, indicating a clear pathway to optimal growth conditions. Furthermore, our results reveal that the findings are resilient to minor variations in initial conditions, suggesting robustness in the model's predictions. To substantiate our theoretical conclusions, we present numerical simulations that effectively illustrate the dynamics predicted by our model. \n\nInteractions between different species are fundamental to the functioning of various ecosystems. Phytoplankton, which form the base of the aquatic food web, serve as a crucial energy source for higher trophic levels, including zooplankton. Understanding the dynamics of these two communities is essential for gaining insights into ecological processes. Recent advancements have led to the development of various computational models aimed at elucidating the population dynamics of phytoplankton-zooplankton interactions. These models incorporate deterministic components that account for the intrinsic growth rates of both populations and their mutual influences, alongside stochastic elements that capture environmental variability. Previous research has indicated that under specific conditions, the long-term behavior of these models can exhibit chaotic characteristics, complicating system analysis. Conversely, neglecting the effects of stochastic fluctuations results in a more tractable deterministic model. Our work builds on existing literature by exploring a specific model that incorporates both deterministic growth and stochastic influences, thereby providing a comprehensive understanding of the resonance and frequency-locking phenomena in these ecological systems. \n\n**Keywords:** Stochastic integral equation, Periodic forcing, Resonance, Optimization problems, Nonlinear dynamics.",
        "ori-fast-z-score": 2.1278980968455716,
        "water-fast-z-score": 8.121035618207516,
        "rewrite-fast-z-score": 1.8973665961010275
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Gravitational collapse of spherically symmetric plasmas in Einstein-Maxwell spacetimes .\nAbstract:\nWe study the gravitational collapse of spherically-symmetric, electrically charged perfect fluids with pressure anisotropy and heat flow in general relativity. We find that for sufficiently large initial data there is no black hole formation but rather an asymptotically flat end state which can be interpreted as a naked singularity or a regular star-like object depending on whether the fluid has positive or negative radial pressure at spatial infinity respectively. The results are obtained by solving numerically the full set of coupled nonlinear partial differential equations governing the evolution of the system using a high-resolution shock-capturing scheme based on the method of lines combined with adaptive mesh refinement techniques. In addition to confirming previous numerical studies we also show how our approach allows us to obtain new insights into the dynamics of these systems such as the existence of multiple solutions corresponding to different final states. This work was supported by the Australian Research Council (ARC) Discovery Project DP130103137.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Gravitational sinking of spherically invariant plasmas in Einstein - Maxwell spacetimes . Abstract : We research the gravitational collapse of spherically - symmetric , electrically charged perfect fluids with force anisotropy and heat flow in general relativity .We see that for enough large initial evidence there is no black hole formation but rather an asymptotically flat end state which can be interpreted as a naked singularity or a regular star - like entity depending on whether the fluid has negative or negative radial tension at spatial infinity respectively . The results are derived by solving numerically the full set of coupled nonlinear partial differential equations governing the evolution of the system using a high - resolution shock - capturing scheme using on the method of lines together with adaptive mesh refinement techniques .In addition to proving earlier numerical studies we also demonstrate how our approach allows us to obtain new understanding into the dynamics of these systems such as the existence of multiple answers corresponding to different final regions . This research was supported by the Australian Research Council ( ARC ) Discovery Project DP130103137 .",
        "rewrite_text": "In this study, we investigate the gravitational collapse of spherically symmetric, electrically charged perfect fluids characterized by force anisotropy and heat flow within the framework of general relativity. Our findings reveal that, under certain conditions with sufficiently large initial parameters, the collapse does not lead to the formation of a black hole. Instead, the system evolves towards an asymptotically flat end state, which can be interpreted as either a naked singularity or a regular star-like structure. The interpretation hinges on the nature of the fluid's radial tension at spatial infinity, with negative radial tension suggesting a naked singularity and positive radial tension indicating a regular stellar configuration. \n\nTo arrive at these conclusions, we employed a numerical approach to solve the complete set of coupled nonlinear partial differential equations that govern the dynamics of the system. Our methodology involved a high-resolution shock-capturing scheme, utilizing the method of lines in conjunction with adaptive mesh refinement techniques. This rigorous numerical framework not only corroborates previous studies but also enhances our understanding of the complex dynamics at play, revealing the existence of multiple solutions corresponding to different final states of the system. \n\nThe implications of our research extend beyond mere theoretical exploration, as they contribute to the broader understanding of gravitational collapse phenomena in the context of Einstein-Maxwell spacetimes. This work was made possible through the support of the Australian Research Council (ARC) Discovery Project DP130103137, highlighting the importance of collaborative funding in advancing scientific inquiry in this field.",
        "ori-fast-z-score": 1.3337718577107005,
        "water-fast-z-score": 6.327848502189878,
        "rewrite-fast-z-score": 2.5533076283443092
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  In-plane structure and ordering at liquid sodium surfaces and interfaces from ab initio molecular dynamics .\nAbstract:\nWe have performed ab initio molecular dynamics simulations to study the in-plane structure, order parameters, and surface tension of liquid Na(l) in contact with vacuum or solid NaCl (001). We find that the density profile is strongly dependent on the presence of an underlying substrate; it exhibits a pronounced double peak for the case without substrate but becomes single-peaked when the substrate is present. The height fluctuations are found to be larger than those observed experimentally by STM measurements. This discrepancy may arise due to the fact that our simulation cell contains only one layer of liquid sodium atoms while experiments typically involve several layers. In addition, we observe that the average nearest neighbor distance decreases as the number of layers increases. Our results show that the in-plane structure of liquid sodium can be significantly influenced by its environment. Finally, we calculate the surface tensions using two different methods and compare them against each other.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : In - plane structure and ordering at liquid sodium surfaces and interfaces from ab initio molecular dynamics . Abstract : We have done ab initio molecular dynamics simulations to study the in - plane structure , order variables , and surface tension of liquid Na ( l ) in contact with vacuum or solid NaCl ( 001 ) .We see that the density profile is strongly dependent on the presence of an underlying substrate ; it displays a distinct double peak for the case without substrate but grows single - topped when the substrate is present . The depth fluctuations are found to be larger than those observed experimentally by STM observations .This discrepancy may arise due to the fact that our modeling cell contains only one layer of liquid sodium atoms while tests usually require many layers . In addition , we find that the average closest neighbor distance decreases as the quantity of layers increases .Our results show that the in - plane structure of liquid sodium can be substantially affected by its climate . Finally , we estimate the surface tensions use two different methods and contrast them against each other .",
        "rewrite_text": "Title: In-Plane Structure and Ordering at Liquid Sodium Surfaces and Interfaces from Ab Initio Molecular Dynamics\n\nAbstract: This study presents an investigation into the in-plane structural characteristics, order parameters, and surface tension of liquid sodium (Na) in contact with both vacuum and solid sodium chloride (NaCl) (001) surfaces, utilizing ab initio molecular dynamics simulations. Our findings reveal that the density profile of liquid sodium is significantly influenced by the presence of an underlying substrate. Specifically, in the absence of a substrate, the density profile exhibits a pronounced double peak, whereas it transitions to a single peak when a substrate is introduced. Furthermore, we observe that the depth fluctuations of the liquid sodium surface are greater than those reported in experimental scanning tunneling microscopy (STM) studies. This discrepancy may be attributed to the limitations of our modeling approach, which considers only a single layer of liquid sodium atoms, while experimental setups typically involve multiple layers. Additionally, our analysis indicates that the average nearest neighbor distance diminishes with an increasing number of layers, suggesting a notable dependence of the in-plane structure on the layer thickness. These results underscore the significant impact of environmental conditions on the structural properties of liquid sodium. To further our understanding, we also calculate the surface tensions of liquid sodium using two distinct methodologies and compare the outcomes, providing insights into the interfacial behavior of this alkali metal. Overall, our research contributes to a deeper understanding of the structural and thermodynamic properties of liquid sodium at surfaces and interfaces, with implications for both theoretical studies and practical applications in materials science.",
        "ori-fast-z-score": 0.20203050891044214,
        "water-fast-z-score": 5.656854249492381,
        "rewrite-fast-z-score": 1.310556084991557
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Equivalence of three-dimensional spacetimes .\nAbstract:\nThe equivalence principle is one of the most important concepts in general relativity, and it states that all physically equivalent solutions to Einstein s field equations are locally indistinguishable.  In this article we show how the concept can be extended to three dimensions by considering two different classes of exact solutions to the vacuum Einstein field equations with cosmological constant.   The first class consists of spatially homogeneous Bianchi type IX models which have been studied extensively over many years as possible candidates for describing our universe at early times when its geometry was close to being flat.   We prove that these models are globally diffeomorphic (homeomorphic) if their spatial volume forms agree up to sign.   ... This article shows how the concept of local physical equivalence between solutions to Einstein s field equation can be extended to three-dimensions. Two different classes of exact solutions are considered; spatially homogeneous Bianchi Type IX models and spherically symmetric Schwarzschild-de Sitter solutions. It is shown that both types of solution are globally diffeomorphic under certain conditions on their respective volume forms.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Equivalence of three - dimensional spacetimes . Abstract : The equivalence principle is one of the most important concepts in general relativity , and it states that all physically equivalent solutions to Einstein s field equations are locally indistinguishable .In this article we give how the notion can be enlarged to three dimensions by examining two different categories of precise solutions to the vacuum Einstein field equations with cosmological constant . The first class consists of spatially homogeneous Bianchi class IX models which have been studied frequently over numerous years as possible candidates for describing our universe at first days when its topology was close to being flat .We prove that these models are globally diffeomorphic ( homeomorphic ) if their spatial volume shapes accord up to sign . . . .This page demonstrates how the idea of local mechanical equivalence between solutions to Einstein s field equation can be generalized to three - dimensions . Two different categories of precise solutions are considered ; spatially homogeneous Bianchi Type IX models and spherically spherical Schwarzschild - de Sitter systems .It is demonstrated that both types of solution are globally diffeomorphic under certain conditions on their respective volume shapes .",
        "rewrite_text": "**Title:** Equivalence of Three-Dimensional Spacetimes\n\n**Abstract:** The equivalence principle is a cornerstone of general relativity, asserting that all physically equivalent solutions to Einstein's field equations are locally indistinguishable. In this article, we explore the extension of this principle to three-dimensional spacetimes by analyzing two distinct categories of exact solutions to the vacuum Einstein field equations, incorporating a cosmological constant. The first category comprises spatially homogeneous Bianchi class IX models, which have been extensively studied as potential representations of the early universe, particularly during epochs when its topology approached flatness. We demonstrate that these models exhibit global diffeomorphism (homeomorphism) if their spatial volume shapes are congruent up to a sign. Furthermore, we investigate a second category of solutions, specifically the spherically symmetric Schwarzschild-de Sitter systems. Our findings reveal that both classes of solutions can be shown to be globally diffeomorphic under specific conditions related to their volume shapes. This research highlights the broader applicability of the local mechanical equivalence concept, illustrating how it can be generalized to three-dimensional contexts. By establishing the conditions under which these solutions are equivalent, we contribute to a deeper understanding of the geometric and topological properties of spacetimes in general relativity. This work not only reinforces the significance of the equivalence principle but also opens avenues for further exploration of the implications of these findings in cosmological models and the nature of spacetime itself.",
        "ori-fast-z-score": -1.6081688022566922,
        "water-fast-z-score": 4.264014327112209,
        "rewrite-fast-z-score": 2.5649458802128855
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Rapidity and energy dependence of the electric charge correlations in A+A collisions at the SPS energies .\nAbstract:\nThe rapidity and transverse momentum (pT) dependences of the electric charge correlation functions are studied for central Au+Au, d+Au and p+p collisions at RHIC and LHC energies using the AMPT model with string melting mechanism. The results show that there is no significant difference between the charge correlation functions obtained by different collision systems except for small differences around midrapidity region which may be due to the initial state effects. It can also be seen that the charge correlation function decreases as the center-of-mass energy increases. This behavior indicates that the strength of charge separation effect becomes weaker when going from lower to higher energies. Finally it should be noted that the charge correlation functions calculated here have been found to agree well with those measured experimentally. PACS numbers: 25.75.-q, 11.15.-x, 12.38.Mh  Electric charge fluctuations play an important role in understanding many interesting phenomena observed in heavy-ion collisions such as charge balance functions  1  , net-charge fluctuations  2  , etc.. In recent years, several experiments  3-6  have reported measurements on these quantities in various collision systems ranging from proton-proton(pp), deuteron-gold(d-Au) to gold-gold(Au-Au). These experimental data provide valuable information about the properties of hot and dense nuclear matter produced in high-energy nucleus-nucleus collisions  7-9  . However, theoretical studies on this subject still remain limited  10-12  .\nIn order to understand better the underlying physics behind these observations, we need more detailed investigations into the charge fluctuation phenomenon. One possible way to study charge fluctuations is through measuring the charge correlation functions  13-15  . Recently, some experimental groups  16-18  have presented their measurement on charge correlation functions in pp, d-Au and Au-Au collisions at RHIC and Large Hadron Collider (LHC) energies. On the other hand, the relativistic quantum molecular dynamics (RQMD)  19  and the parton-hadron-string dynamics (PHSD)  20  models predict that the charge correlation functions decrease rapidly towards zero",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Rapidity and energy dependence of the electric current correlations in A + A collisions at the SPS energies . Abstract : The rapidity and transverse momentum ( pT ) dependences of the electric charge relationship functions are studied for central Au + Au , d + Au and p + p collisions at RHIC and LHC energies using the AMPT theory with string melting system .The results show that there is no major variation between the charge interaction functions obtained by various crash processes except for little differences around midrapidity region which may be due to the early state effects . It can also be shown that the charge correlation function decreases as the center - of - mass energy rises .This phenomenon suggests that the strength of charge separation effect gets smaller when going from lower to higher energies . Finally it should be mentioned that the charge correlation functions measured here have been shown to agree well with those observed experimentally .PACS codes : 25 . 75 . - q , 11 . 15 . - x , 12 . 38 . Mh Electric charge fluctuations take an important role in understanding several interesting phenomena observed in heavy - ion collisions such as charge balance functions 1 , net - charge fluctuations 2 , etc . . In recent seasons , various study 3 - 6 have reported measurements on these quantities in different collision systems ranging from proton - proton ( pp ) , deuteron - silver ( d - Au ) to platinum - silver ( Au - Au ) .These observation findings provide valuable info about the properties of hot and dense nuclear material created in high - energy nucleus - nucleus collisions 7 - 9 . However , theoretical experiments on this subject still stay limited 10 - 12 .In order to realize clearer the fundamental theory behind these observations , we require more precise studies into the charge fluctuation phenomenon . One easy means to study charge fluctuations is through measuring the charge relationship values 13 - 15 .Recently , some experimental groups 16 - 18 have published their observation on charge interaction functions in pp , d - Au and Au - Au collisions at RHIC and Large Hadron Collider ( LHC ) energies . On the other hand , the relativistic quantum molecular mechanics ( RQMD ) 19 and the parton - hadron - string dynamics ( PHSD ) 20 models predict that the charge interaction functions decline rapidly towards zero",
        "rewrite_text": "**Title:** Rapidity and Energy Dependence of Electric Current Correlations in A + A Collisions at SPS Energies\n\n**Abstract:** This study investigates the rapidity and transverse momentum (pT) dependencies of electric charge correlation functions in central Au + Au, d + Au, and p + p collisions at both RHIC and LHC energies, utilizing the AMPT (A Multi-Phase Transport) model with a string melting approach. Our findings indicate that the charge correlation functions exhibit minimal variation across different collision types, with only slight discrepancies observed in the mid-rapidity region, which may be attributed to early-stage effects in the collisions. Furthermore, we demonstrate that the charge correlation function diminishes as the center-of-mass energy increases, suggesting a reduction in the strength of charge separation effects when transitioning from lower to higher energy regimes. Notably, the charge correlation functions obtained in this study align well with experimental measurements, reinforcing the validity of our theoretical framework. \n\nElectric charge fluctuations play a crucial role in elucidating various intriguing phenomena observed in heavy-ion collisions, such as charge balance functions and net-charge fluctuations. Recent studies have reported measurements of these quantities across different collision systems, including proton-proton (pp), deuteron-gold (d-Au), and gold-gold (Au-Au) interactions. These observations provide essential insights into the properties of the hot and dense nuclear matter produced in high-energy nucleus-nucleus collisions. However, theoretical investigations in this area remain limited. To enhance our understanding of the fundamental theories underlying these observations, more precise studies of charge fluctuation phenomena are necessary. One effective approach to studying charge fluctuations is through the measurement of charge correlation values. Recent experimental efforts have yielded results on charge correlation functions in pp, d-Au, and Au-Au collisions at RHIC and LHC energies. In contrast, models such as the Relativistic Quantum Molecular Dynamics (RQMD) and Parton-Hadron-String Dynamics (PHSD) predict a rapid decline of charge correlation functions towards zero. This research aims to bridge the gap between theoretical predictions and experimental observations, contributing to a deeper understanding of the dynamics of charge fluctuations in heavy-ion collisions.",
        "ori-fast-z-score": -0.22423052782558076,
        "water-fast-z-score": 7.00634632949934,
        "rewrite-fast-z-score": 0.9258200997725514
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A Census of Baryons in Galaxy Clusters and Groups .\nAbstract:\nWe present the results of an all-sky survey for galaxy clusters using data obtained with the Sunyaev-Zel dovich effect (SZE) by the Planck satellite, complemented at low redshifts by X-ray observations made with XMM-Newton and Chandra satellites. We use this sample to study the evolution of baryon content in massive halos over cosmic time. The total mass is estimated through gravitational lensing measurements performed on Hubble Space Telescope images. Our main findings are as follows:  1. We find that the fraction of gas mass decreases strongly towards higher redshift.  2. At z < 0.5 we measure fgas = Mgas/Mtot = 0.11 ± 0.01(stat.) ±0.02(sys.), where Mtot is the total gravitating mass within R500c, which corresponds to about half the virial radius. This value agrees well with previous estimates based on X-ray observations alone.  3. For our full cluster sample spanning the range 0.1 < z < 1.3, we obtain fgas = 0.09 ± 0.01(±stat.).",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A Census of Baryons in Galaxy Clusters and Groups . Abstract : We present the results of an all - skies study for galaxy galaxies using data acquired with the Sunyaev - Zel dovich impact ( SZE ) by the Planck satellite , complemented at low redshifts by X - ray observations made with XMM - Newton and Chandra satellites .We use this specimen to study the evolution of baryon concentration in massive halos over cosmic time . The total mass is calculated through gravity lensing observations performed on Hubble Space Telescope images .Our main results are as follows : 1 . We see that the fraction of gas mass decreases strongly towards higher redshift .2 . At z < 0 . 5 we measure fgas = Mgas / Mtot = 0 . 11 ± 0 . 01 ( stat . )±0 . 02 ( sys . ) , where Mtot is the total gravitating mass within R500c , which equals to about half the virial radius .This value agrees well with previous accounts based on X - ray observations alone . 3 .For our entire cluster sample spanning the range 0 . 1 < z < 1 . 3 , we obtain fgas = 0 . 09 ± 0 . 01 ( ±stat . ) .",
        "rewrite_text": "We present the findings of a comprehensive all-sky survey focused on galaxy clusters and groups, utilizing data obtained from the Sunyaev-Zel'dovich effect (SZE) as measured by the Planck satellite. This study is further enhanced by X-ray observations from the XMM-Newton and Chandra satellites, particularly at lower redshifts. Our analysis aims to investigate the evolution of baryon concentration within massive halos across cosmic time. To determine the total mass of these structures, we employ gravitational lensing data derived from images captured by the Hubble Space Telescope. \n\nOur key findings are as follows: First, we observe a significant decline in the gas mass fraction as we move towards higher redshifts. Specifically, for redshifts less than 0.5, we measure the gas mass fraction, defined as fgas = Mgas / Mtot, to be 0.11 ± 0.01 (statistical) ± 0.02 (systematic), where Mtot represents the total gravitating mass within R500c, approximately half of the virial radius. This measurement aligns closely with previous estimates based solely on X-ray data. Additionally, when considering our entire sample of clusters across the redshift range of 0.1 to 1.3, we derive an average gas mass fraction of fgas = 0.09 ± 0.01 (statistical). These results contribute to our understanding of baryonic matter distribution in the universe and highlight the dynamic nature of gas within galaxy clusters over time.",
        "ori-fast-z-score": 1.9896995023342199,
        "water-fast-z-score": 5.7350162126103985,
        "rewrite-fast-z-score": 0.9805806756909202
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Supersymmetric Vector Multiplets in Non-Adjoint Representations of SO(N) .\nAbstract:\nWe study the supersymmetry breaking patterns for vector multiplets transforming under non-adjoint representations of SO(N). We find that there are two distinct classes of theories, depending on whether or not the representation is real. In particular we show how to construct explicit examples with N = 1 and N = 2 supersymmetries which break all their supersymmetries spontaneously. Theories with adjoint matter fields can be obtained as special cases by taking appropriate limits. This work was supported in part by NSF grant PHY-0456735. Supersymmetry (SUSY) has been an important ingredient in many extensions of the Standard Model since its introduction more than thirty years ago  1  . It provides a natural solution to the hierarchy problem between the weak scale and the Planck scale  2  , while at the same time offering new ways to understand gauge coupling unification  3  .\nIn recent years it has become clear that SUSY must be broken if one wants to make contact with experiment  4  . However, despite much effort over several decades  5  -  8  , no fully satisfactory mechanism for spontaneous SUSY breaking exists yet  9  . One promising approach involves using supergravity  10  -  12  to generate soft terms  13  -  15  which then trigger SUSY breakdown  16  -  18  . Another possibility is to use extra dimensions  19  -  21  where SUSY is broken either explicitly  22  -  24  or spontaneously  25  -  27  via boundary conditions  28  -  30  . A third option is to consider models based on local symmetries  31  -  33  such as gauged  34  -  37  or global  38  -  41  SUSY.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Supersymmetric Vector Multiplets in Non - Adjoint Representations of SO ( N ) . Abstract : We research the supersymmetry broken patterns for vector multiplets transforming under non - adjoint representations of SO ( N ) .We see that there are two different categories of theories , depending on whether or not the representation is real . In particular we find how to build explicit examples with N = 1 and N = 2 supersymmetries which break all their supersymmetries spontaneously .Theories with adjoint matter fields can be obtained as special cases by take appropriate restrictions . This research was supported in part by NSF grant PHY - 0456735 .Supersymmetry ( SUSY ) has been an important ingredient in many extensions of the Standard Model since its introduction more than thirty years early 1 . It provides a natural solution to the ranking problem between the strong scale and the Planck scale 2 , while at the same time providing new ways to explain gauge coupling unification 3 .In recent years it has become clear that SUSY must be broken if one wants to make contact with experiment 4 . However , despite much effort over numerous centuries 5 - 8 , no fully acceptable mechanism for voluntary SUSY broke exists yet 9 .One promising alternative employs using supergravity 10 - 12 to create soft terms 13 - 15 which then activate SUSY breakdown 16 - 18 . Another possibility is to use extra dimensions 19 - 21 where SUSY is shattered either explicitly 22 - 24 or spontaneously 25 - 27 via boundary factors 28 - 30 .A third possibility is to consider variants based on local symmetries 31 - 33 such as gauged 34 - 37 or worldwide 38 - 41 SUSY .",
        "rewrite_text": "In this study, we investigate the patterns of supersymmetry breaking in vector multiplets that transform under non-adjoint representations of the SO(N) group. Our analysis reveals two distinct categories of theories based on the nature of the representation—whether it is real or complex. We provide explicit constructions of models featuring N = 1 and N = 2 supersymmetries that spontaneously break all supersymmetries. Notably, our findings indicate that theories with adjoint matter fields can be derived as special cases through appropriate restrictions of our models. This research is partially funded by NSF grant PHY-0456735.\n\nSupersymmetry (SUSY) has played a crucial role in various extensions of the Standard Model since its inception over three decades ago. It offers a compelling solution to the hierarchy problem, addressing the disparity between the strong scale and the Planck scale, while also presenting novel approaches to gauge coupling unification. In recent years, it has become evident that for SUSY to align with experimental observations, it must be broken. Despite extensive efforts over many years, a universally accepted mechanism for spontaneous SUSY breaking remains elusive. \n\nSeveral promising avenues have emerged in the quest for viable SUSY breaking mechanisms. One approach involves the use of supergravity to generate soft terms that facilitate the breaking of SUSY. Another strategy explores the implications of extra dimensions, where SUSY can be broken either explicitly or spontaneously through boundary conditions. Additionally, researchers are investigating variations of SUSY based on local symmetries, including gauged and global SUSY frameworks. This paper contributes to the ongoing discourse by elucidating the dynamics of supersymmetry breaking in non-adjoint representations, thereby enhancing our understanding of SUSY in the context of theoretical physics.",
        "ori-fast-z-score": -0.3849001794597505,
        "water-fast-z-score": 6.225870853937484,
        "rewrite-fast-z-score": 0.08873565094161139
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Is the Bardeen-Petterson effect responsible for the warping and precession in NGC 4258? .\nAbstract:\nWe present new observations of the central region of the nearby Seyfert galaxy NGC 4258, which show that its nuclear disk is warped by an angle of ~20 degrees with respect to the plane of the host galaxy s stellar bulge (see Figure 1 ). The warp has been detected using near-infrared integral field spectroscopy obtained at Gemini Observatory on Mauna Kea, Hawaii. \n \n We also report the detection of significant rotation about the minor axis of this warped structure, as well as evidence for counter-rotation within the innermost few hundred parsecs of the nucleus. These results are consistent with previous studies based on optical data alone. \n \n In addition, we find that the kinematics of the gas in the outer regions of the nuclear disk can be explained if it orbits around the supermassive black hole located at the center of the galaxy under the influence of both gravitational forces and magnetic fields. This result suggests that the observed warps may have their origin in the magneto-rotational instability (MRI) operating in accretion disks surrounding massive black holes. \n \n Finally, we discuss how these findings could help us understand the physics behind the so-called  Bardeen-Petterson effect : i.e., the alignment between the spin axes of the stars and the angular momentum vector of the accreting material onto the central supermassive black hole.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Is the Bardeen - Petterson effect responsible for the warping and precession in NGC 4258 ? .Abstract : We report new images of the central region of the nearby Seyfert galaxy NGC 4258 , which show that its nuclear core is warped by an angle of ~ 20 degrees with regard to the plane of the host universe s stellar bulge ( see Figure 1 ) . The warp has been detected using near - infrared integral field spectroscopy acquired at Gemini Observatory on Mauna Kea , Hawaii .We additionally report the observation of large rotation about the minor axis of this warped structure , as also as data for counter - movement within the innermost few hundred parsecs of the nucleus . These conclusions are compatible with previous research based on optical data alone .In addition , we find that the kinematics of the gas in the exterior areas of the atomic disk can be understood if it orbits around the supermassive black hole located at the center of the galaxy under the effects of both gravity forces and magnetic fields . This result suggests that the seen warps may have their source in the magneto - rotational instability ( MRI ) working in accretion disks surrounding massive blue holes .Finally , we talk how these results could assist us explain the physics behind the so - called Bardeen - Petterson effect : i . e . , the alignment between the spin axes of the stars and the angular velocity tensor of the accreting matter onto the main supermassive black hole .",
        "rewrite_text": "**Title:** Is the Bardeen-Petterson Effect Responsible for the Warping and Precession in NGC 4258?\n\n**Abstract:** In this study, we present new imaging of the central region of the nearby Seyfert galaxy NGC 4258, revealing a significant warp in its nuclear core, tilted approximately 20 degrees relative to the plane of the galaxy's stellar bulge. This warp was identified through near-infrared integral field spectroscopy conducted at the Gemini Observatory located on Mauna Kea, Hawaii. Our observations also indicate substantial rotation around the minor axis of this warped structure, along with evidence of counter-movement within the innermost few hundred parsecs of the nucleus. These findings align with earlier studies that relied solely on optical data. Furthermore, we analyze the kinematics of the gas in the outer regions of the atomic disk, which appears to orbit the supermassive black hole at the galaxy's center, influenced by both gravitational forces and magnetic fields. This observation implies that the observed warps may originate from magneto-rotational instability (MRI) occurring in the accretion disks surrounding massive black holes. Finally, we discuss how our results could enhance the understanding of the Bardeen-Petterson effect, which describes the alignment between the spin axes of stars and the angular velocity tensor of the accreting matter onto the central supermassive black hole. This research contributes to the broader understanding of the dynamics within active galactic nuclei and the interplay between gravitational and magnetic forces in shaping the structure of galaxies.",
        "ori-fast-z-score": -2.5253432421288866,
        "water-fast-z-score": 4.233901974057256,
        "rewrite-fast-z-score": 0.3849001794597505
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Witnessing the formation of a galaxy cluster at z=0.485: optical and X-ray properties of RX J1117.4+0743 ( VMF 98  097) .\nAbstract:\nWe present new observations of the distant galaxy cluster RX J1117.4+07431, which was discovered in the ROSAT All-Sky Survey data by Voges et al. (1999) . The cluster is located at redshift z = 0.485 ± 0.001 with an estimated mass M500 = 1.7 × 1013 h-1M⊙ within r500 = 2.1h-1Mpc . We have obtained deep optical images using Suprime-Cam on Subaru telescope to study its member galaxies. In addition we observed this cluster with Chandra ACIS-I for about 50 ks. Our results are as follows:  -The color-magnitude diagram shows that there exists a red sequence of early-type galaxies down to our limiting magnitude RAB=25 mag.  -From the photometric redshift analysis, we find that the number density profile of the member galaxies follows well the NFW model prediction up to 3 virial radii. -The temperature map derived from the Chandra observation reveals two hot spots near the center of the cluster. These features may be associated with shock heating due to merging activity between sub-clusters or groups.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Witnessing the formation of a galaxy cluster at z = 0 . 485 : optical and X - ray properties of RX J1117 . 4 + 0743 ( VMF 98 097 ) . Abstract : We present new observations of the distant galaxy cluster RX J1117 . 4 + 07431 , which was discovered in the ROSAT All - Sky Survey data by Voges et al .( 1999 ) . The cluster is located at redshift z = 0 . 485 ± 0 . 001 with an estimated mass M500 = 1 . 7 × 1013 h - [UNK] within r500 = 2 . 1h - 1Mpc .We have achieved dark optical images using Suprime - Cam on Subaru observatory to study its member galaxies . In addition we examined this cluster with Chandra ACIS - I for about 50 ks .Our results are as follows : - The color - magnitude diagram reveals that there exists a red series of early - class stars down to our limiting magnitude RAB = 25 mag . - From the photometric redshift investigation , we find that the number density profile of the member galaxies shows well the NFW model prediction up to 3 virial radii .- The temperature diagram derived from the Chandra observation shows two hot areas near the center of the cluster . These features could be involved with shock heating due to merging behavior between sub - complexes or bands .",
        "rewrite_text": "We present new findings on the distant galaxy cluster RX J1117.4+0743, which was initially identified in the ROSAT All-Sky Survey by Voges et al. (1999). This cluster is situated at a redshift of z = 0.485 ± 0.001 and has an estimated mass of M500 = 1.7 × 10^13 h^-1 within a radius of r500 = 2.1 h^-1 Mpc. To investigate the properties of its member galaxies, we utilized dark optical imaging with the Suprime-Cam at the Subaru Observatory. Additionally, we conducted an analysis of the cluster using the Chandra ACIS-I for approximately 50 kiloseconds. Our findings include several significant observations: the color-magnitude diagram indicates the presence of a distinct red sequence of early-type galaxies down to our limiting magnitude of RAB = 25 mag. Furthermore, our photometric redshift analysis reveals that the number density profile of the member galaxies aligns well with the predictions of the Navarro-Frenk-White (NFW) model, extending up to three virial radii. The temperature map derived from the Chandra observations highlights two hot regions near the cluster's center, which may be indicative of shock heating associated with merging activities between sub-clusters or filaments. These observations contribute to our understanding of galaxy cluster formation and evolution, particularly in the context of cosmic structure development at intermediate redshifts. The results underscore the importance of multi-wavelength studies in revealing the complex dynamics and characteristics of galaxy clusters.",
        "ori-fast-z-score": -0.3216337604513384,
        "water-fast-z-score": 3.8376128944009875,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Magnetism in the spiral galaxy NGC 6946: magnetic arms, depolarization rings, dynamo modes and helical fields .\nAbstract:\nWe present new observations at 1.4 GHz with the VLA of polarized emission from the nearby (7 Mpc) grand-design spiral galaxy NGC 6946. The data reveal several interesting features that are not seen in previous radio continuum studies of this galaxy. We find that:  -The total intensity distribution is dominated by two bright nuclear components separated by about 2 kpc along an axis perpendicular to the main galactic disk.  -There is no evidence for large-scale ordered fields on kiloparsec scales as previously reported.   -The polarization vectors show a clear pattern of alternating directions across the central region of the galaxy which we interpret as a signature of a global magnetic field reversal between the two nuclei.  -The rotation measure map shows a ring-like structure around each nucleus where the RM changes sign indicating a change in direction of the line-of-sight component of the magnetic field. This feature may be related to the so-called depolarization rings observed in other galaxies but it could also result from beam smearing effects or from intrinsic Faraday dispersion within the source itself.  -The polarized intensity distribution reveals a number of extended structures including a prominent southern arm extending over more than 10 kpc towards the south-east.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Magnetism in the spiral galaxy NGC 6946 : magnetic arms , depolarization belts , dynamo modes and helical fields . Abstract : We report new images at 1 . 4 GHz with the VLA of polarized emission from the nearby ( 7 Mpc ) great - design spiral galaxy NGC 6946 .The data reveal several interesting features that are not seen in earlier radio continuum experiments of this galaxy . We see that : - The total frequency distribution is dominated by two faint nuclear elements divided by about 2 kpc along an axis perpendicular to the main galactic disk .- There is no evidence for large - scale ordered fields on kiloparsec scales as previously reported . - The polarization coefficients show a clear sequence of alternating directions across the central region of the galaxy which we perceive as a signature of a global magnetic force reversal between the two nuclei .- The rotation measure map displays a ring - like structure around each core where the RM changes sign indicating a change in direction of the line - of - view component of the magnetic force . This characteristic could be connected to the so - called depolarization loops observed in other stars but it could also occur from beam smearing effects or from intrinsic Faraday dispersion within the source itself .- The polarized intensity distribution reveals a number of extended features including a large southern arm reaching over more than 10 kpc towards the south - east .",
        "rewrite_text": "We present new 1.4 GHz polarized emission images obtained with the Very Large Array (VLA) of the nearby spiral galaxy NGC 6946, located approximately 7 Mpc away. Our findings uncover several intriguing characteristics that were not detected in previous radio continuum studies of this galaxy. Notably, the total frequency distribution is primarily influenced by two faint nuclear components that are separated by roughly 2 kpc along an axis that is perpendicular to the main galactic disk. Contrary to earlier reports, we find no substantial evidence for large-scale ordered magnetic fields on kiloparsec scales. \n\nMoreover, the polarization coefficients exhibit a distinct pattern of alternating directions across the galaxy's central region, which we interpret as an indication of a global magnetic field reversal occurring between the two nuclei. The rotation measure (RM) map reveals a ring-like structure surrounding each core, where the RM changes sign, suggesting a shift in the direction of the line-of-sight component of the magnetic field. This feature may be associated with the depolarization loops observed in other stellar contexts, although it could also arise from beam smearing effects or intrinsic Faraday dispersion within the source itself.\n\nAdditionally, the distribution of polarized intensity showcases several extended features, including a prominent southern arm that extends over 10 kpc towards the southeast. These observations contribute to our understanding of the magnetic structure and dynamics within NGC 6946, highlighting the complexity of its magnetic field configuration and the potential implications for the galaxy's evolution. Our results provide valuable insights into the interplay between magnetic fields and galactic structures, paving the way for further investigations into the magnetism of spiral galaxies.",
        "ori-fast-z-score": 0.1873171623163388,
        "water-fast-z-score": 5.874780291913977,
        "rewrite-fast-z-score": 0.8703882797784892
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Improved Quantum Hard-Sphere Ground-State Equations of State .\nAbstract:\nWe present an improved quantum hard-sphere ground-state equation-of-state (EOS) for the description of dense matter in astrophysics and nuclear physics, which is based on the exact solution to the Schrödinger equation with a repulsive delta-function potential. The EOS has been derived by solving numerically the corresponding integral equations using the method of successive iterations. We have also obtained analytical expressions for the pressure and energy density as functions of the number density at zero temperature. Our results are compared with those calculated previously within various approximations such as the virial expansion up to second order, the Carnahan-Starling approximation, and the Percus-Yevick approximation. It turns out that our new EOS agrees well with these previous calculations over wide ranges of densities and temperatures. In particular, it reproduces very accurately the low-density limit where the ideal gas law holds exactly. \n \n Keywords: Equation of state",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Improved Quantum Hard - Sphere Ground - State Equations of State . Abstract : We create an updated quantum hard - sphere ground - state equation - of - state ( EOS ) for the description of dense materials in astrophysics and nuclear science , which is based on the exact solution to the Schrödinger equation with a repulsive delta - function potential .The EOS has been constructed by solving numerically the equivalent integral equations using the method of successive iterations . We have also achieved analytical expressions for the pressure and energy density as functions of the number density at zero temperature .Our results are compared with those estimated previously within various approximations such as the virial expansion up to second order , the Carnahan - Starling approximation , and the Percus - Yevick approximation . It turns out that our new EOS follows well with these previous analyses over broad ranges of densities and altitudes .In particular , it reproduces very correctly the small - density maximum where the ideal gas law stands exactly . Keywords : Equation of state",
        "rewrite_text": "Title: Enhanced Quantum Hard-Sphere Ground-State Equations of State\n\nAbstract: In this study, we present a refined quantum hard-sphere ground-state equation of state (EOS) tailored for the analysis of dense materials relevant to astrophysics and nuclear science. Our approach is grounded in the precise solution of the Schrödinger equation, incorporating a repulsive delta-function potential. The EOS has been developed through the numerical resolution of corresponding integral equations, employing a method of successive iterations. Additionally, we have derived analytical expressions for both pressure and energy density as functions of number density at absolute zero temperature. Our findings are juxtaposed with previous estimates derived from various approximations, including the second-order virial expansion, the Carnahan-Starling approximation, and the Percus-Yevick approximation. Notably, our newly formulated EOS aligns closely with these earlier analyses across a wide spectrum of densities and conditions. Specifically, it accurately captures the small-density maximum where the ideal gas law holds true. This work not only enhances the understanding of quantum hard-sphere systems but also provides a robust framework for future investigations into the properties of dense matter in extreme environments. \n\nKeywords: Equation of state, quantum mechanics, hard-sphere model, astrophysics, nuclear science.",
        "ori-fast-z-score": 0.4588314677411235,
        "water-fast-z-score": 4.444462481925879,
        "rewrite-fast-z-score": 3.68163760377696
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Collisional processes and size distribution in spatially extended debris discs .\nAbstract:\nWe present the results of collisional modelling for two spatially resolved debris discs, HD 69830 and AU Mic. We find that collisions are efficient at producing dust particles with sizes ranging between 1 mm to 10 cm across most of these systems. The observed radial profiles can be reproduced by assuming an initial power-law grain-size distribution with index -3.5 (consistent with theoretical predictions) and allowing it to evolve under mutual collisions over timescales of several million years. In addition we show how our models can reproduce the observed colour gradients seen in both systems. Finally, we discuss possible implications of this work on the formation mechanisms of planetesimals and planets. Keywords: Debris discs - Collisions - Grain growth - Planets - Spatially resolved observations - Sizesize distributions - Dust grains - Asteroids - Cometary nuclei - Circumstellar disks - Planet formation",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Collisional processes and size distribution in spatially extended debris discs . Abstract : We report the conclusion of collisional modelling for two spatially resolved dust discs , HD 69830 and AU Mic .We see that collisions are successful at generating dust particles with sizes varied between 1 mm to 10 centimeters across most of these systems . The observed radial profiles can be reproduced by assuming an initial power - law grain - length distribution with index - 3 . 5 ( consistent with theoretical estimates ) and allowing it to evolve under mutual collisions over timescales of several million months .In addition we explain how our models can mimic the seen colour gradients shown in both systems . Finally , we explain possible possibilities of this research on the formation patterns of planetesimals and planets .Keywords : Debris discs - Collisions - Grain growth - Planets - Spatially resolved observations - Sizesize distributions - Dust grains - Asteroids - Cometary nuclei - Circumstellar disks - Planet formation",
        "rewrite_text": "Title: Collisional Processes and Size Distribution in Spatially Extended Debris Discs\n\nAbstract: In this study, we present the findings from our collisional modeling of two spatially resolved debris discs, specifically HD 69830 and AU Mic. Our analysis reveals that collisional interactions within these systems effectively produce dust particles ranging in size from 1 mm to 10 cm. We demonstrate that the observed radial profiles of dust can be accurately reproduced by adopting an initial power-law distribution of grain sizes, characterized by an index of -3.5, which aligns with theoretical predictions. This distribution evolves over timescales of several million months due to mutual collisions among particles. Furthermore, we discuss how our models can replicate the color gradients observed in both debris discs, providing insights into the physical processes at play. The implications of our research extend to understanding the formation mechanisms of planetesimals and planets, shedding light on the evolutionary pathways of circumstellar environments. Our findings contribute to the broader knowledge of debris disc dynamics and the role of collisional processes in shaping the size distribution of dust grains, which are critical for the formation of asteroids, cometary nuclei, and ultimately, planetary systems. \n\nKeywords: Debris discs, Collisions, Grain growth, Planets, Spatially resolved observations, Size distributions, Dust grains, Asteroids, Cometary nuclei, Circumstellar disks, Planet formation.",
        "ori-fast-z-score": 0.7071067811865476,
        "water-fast-z-score": 4.949747468305833,
        "rewrite-fast-z-score": 1.5389675281277313
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Redesigning Computer-based Learning Environments: Evaluation as Communication .\nAbstract:\nThe purpose of this study is to examine the role that evaluation plays in communication between teachers and students during computer-based learning environments (CBLE). The research question guiding this investigation is: How does evaluation affect student-teacher interaction? This study was conducted with two groups of undergraduate students enrolled in an introductory course on educational technology at a large Midwestern university. Students were asked to complete three tasks using a CBLE called WebQuests, which are designed for use by students working individually or collaboratively. Data collection included audio recordings of group discussions, field notes taken by researchers observing each group s work, and students  written responses to questions posed throughout their participation in the project. Analysis revealed that evaluation played several roles within these interactions including providing feedback about individual performance; clarifying expectations; establishing ground rules; and promoting reflection. These findings suggest that evaluation can be used effectively to enhance student-teacher communication when it occurs frequently enough over time so that both parties have multiple opportunities to respond to one another.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Redesigning Computer - based Learning Environments : Evaluation as Communication . Abstract : The purpose of this study is to examine the part that assessment plays in interaction between instructors and students during computer - based educational environments ( CBLE ) .The research question guiding this study is : How does evaluation affect student - teacher activity ? This study was done with two groups of undergraduate people studied in an introductory program on teaching technology at a large Midwestern college .Students were asked to complete three objectives utilizing a CBLE named WebQuests , which are created for use by students studying individually or collaboratively . Data collection included audio performances of group discussions , field notes taken by researchers observing each organization s project , and teachers authored reactions to questions posed throughout their involvement in the project .Analysis revealed that assessment played numerous roles within these interactions including providing guidance about individual performance ; clarifying assumptions ; creating ground requirements ; and promoting reflection . These studies propose that assessment can be used effectively to enhance teacher - teacher understanding when it appears frequently enough over time so that both parties have multiple options to respond to one another .",
        "rewrite_text": "Title: Redesigning Computer-Based Learning Environments: Evaluation as Communication\n\nAbstract: This study investigates the role of assessment in facilitating interactions between instructors and students within computer-based learning environments (CBLEs). The central research question guiding this inquiry is: How does evaluation influence the dynamics of student-teacher engagement? The research was conducted with two groups of undergraduate students enrolled in an introductory teaching technology program at a large Midwestern university. Participants were tasked with achieving three specific objectives using a CBLE known as WebQuests, designed for both individual and collaborative learning experiences. \n\nData collection methods included audio recordings of group discussions, field notes taken by researchers observing each group's project work, and written responses from instructors to questions raised during the project. The analysis of the collected data revealed that assessment serves multiple functions in these interactions. It provides guidance on individual performance, clarifies underlying assumptions, establishes foundational requirements, and encourages reflective practices among participants. \n\nThe findings suggest that assessment can significantly enhance the understanding between teachers and students when it is implemented consistently over time, allowing for numerous opportunities for reciprocal feedback. This study highlights the importance of evaluation not merely as a tool for measuring performance but as a vital component of communication that fosters deeper engagement and collaboration in computer-based learning environments. By rethinking the design of assessment strategies within CBLEs, educators can create more effective learning experiences that promote active participation and mutual understanding.",
        "ori-fast-z-score": -0.7770286898858113,
        "water-fast-z-score": 7.246315678266502,
        "rewrite-fast-z-score": 0.43355498476205995
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dual Field Theories In (d-1)+1 Emergent Spacetimes From A Unifying Field Theory In d+2 Spacetime .\nAbstract:\nWe present the first dual field theory in emergent spacetime, which is derived from a unifying field theory in higher dimensional spacetime. We show that this new dual field theory can be used to describe both quantum and classical physics with one single unified description. This new dual field theory has several advantages over other existing theories such as string/M-theory or loop quantum gravity. First, it provides an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic scale down to macroscopic scale. Second, unlike string/M-theory or LQG, our new dual field theory does not require any extra dimensions beyond those already observed experimentally. Third, we provide a concrete example showing how our new dual field theory works by deriving Einstein s general relativity from our new dual field theory. Finally, we also derive Maxwell s equations from our new dual field... \nIntroduction:-In recent years there have been many attempts to develop a fundamental theory of everything(TOE). String/M-theory  1  , Loop Quantum Gravity  2  are two examples of these efforts. However, despite their successes they still suffer from some problems. For instance, string/M-theory requires extra dimensions  3  while loop quantum gravity suffers from non-renormalizability  4  . These difficulties motivate us to look for alternative approaches towards developing TOEs. Recently, a novel approach called  emergent spacetime  was proposed  5, 6  . According to this approach, space-time emerges from a more fundamental level  7, 8  .\nEmergent spacetime:-The idea behind emergent spacetime is very simple. It states that space-time is not fundamental but rather emerges from a more fundamental entity. To see why this might happen consider the following argument. Imagine you are sitting on your couch watching TV. You will probably say that the world around you looks flat because if you were standing up then you would notice that the ground below you is curved. Now imagine yourself floating above Earth. If you were standing up now then you wouldn t feel like you re standing on a curved surface anymore. Instead you d feel like you re standing on top of a",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dual Field Theories In ( d - 1 ) + 1 Emergent Spacetimes From A Unifying Field Theory In d + 2 Spacetime . Abstract : We introduce the first dual field model in emergent spacetime , which is developed from a unifying field theory in higher dimensional spacetime .We see that this new dual field model can be used to explain both quantum and classical physics with one single unified description . This new dual field model has numerous benefits over other existing ideas such as string / M - theory or loop quantum gravitational .First , it gives an explicit mathematical formulation for describing physical phenomena at all scales ranging from microscopic scale down to macroscopic scale . Second , unlike string / M - theory or LQG , our new dual field model does not require any additional dimensions beyond those already detected experimentally .Third , we provide a clear example showing how our new dual field model operates by deriving Einstein s general relativity from our new dual field theory . Finally , we also generate Maxwell s equations from our new dual field . . . Introduction : - In recent history there have been many efforts to develop a basic theory of things ( TOE ) .String / M - theory 1 , Loop Quantum Gravity 2 are two examples of these attempts . However , despite their successes they still suffer from some problems .For instance , string / M - theory requires added dimensions 3 while loop quantum gravitational loses from non - renormalizability 4 . These difficulties motivate us to search for alternative approaches towards developing TOEs .Recently , a new approach called emergent spacetime was suggested 5 , 6 . According to this methodology , space - time arises from a more fundamental level 7 , 8 .Emergent spacetime : - The idea behind emergent spacetime is very simple . It says that space - time is not essential but rather emerges from a more fundamental entity .To see why this might happen think the following argument . Imagine you are sat on your couch watching TV .You will probably say that the world around you looks flat because if you were standing up then you might see that the earth below you is curved . Now imagine yourself rising above Earth .If you were standing up now then you wouldn t felt like you re standing on a curved surface anymore . Instead you d feel like you re standing on top of a",
        "rewrite_text": "**Title:** Dual Field Theories in (d - 1) + 1 Emergent Spacetimes Derived from a Unifying Field Theory in d + 2 Dimensions\n\n**Abstract:** In this paper, we present a pioneering dual field model situated within the framework of emergent spacetime, which is derived from a unifying field theory formulated in higher-dimensional spacetime. This innovative dual field model offers a comprehensive explanation for both quantum and classical physical phenomena through a single, cohesive framework. One of the primary advantages of our model over existing theories, such as string/M-theory and loop quantum gravity (LQG), is its ability to provide a clear mathematical formulation that encompasses physical phenomena across all scales, from the microscopic to the macroscopic. Unlike string/M-theory, which necessitates the introduction of additional dimensions that have yet to be experimentally verified, our dual field model operates solely within the dimensions that have been empirically confirmed. Furthermore, we illustrate the functionality of our dual field model by deriving Einstein's general relativity directly from its principles, thereby demonstrating its applicability to established theories. Additionally, we successfully derive Maxwell's equations from our dual field framework, showcasing its versatility and relevance in describing electromagnetic phenomena. \n\n**Introduction:** The quest for a fundamental theory of everything (TOE) has seen numerous endeavors, with string/M-theory and loop quantum gravity being prominent examples. Despite their achievements, these theories face significant challenges; for instance, string/M-theory's reliance on extra dimensions and the non-renormalizability issues associated with loop quantum gravity hinder their viability. These challenges have prompted the exploration of alternative methodologies for developing TOEs. Recently, the concept of emergent spacetime has emerged as a promising avenue, positing that spacetime is not an intrinsic feature of reality but rather arises from a more fundamental layer of existence. The notion of emergent spacetime can be illustrated through a simple analogy: consider the perspective of an observer sitting on a couch watching television. From this vantage point, the world appears flat, but if the observer were to stand and gain altitude, they would perceive the curvature of the Earth. This analogy underscores the idea that our understanding of spacetime may be contingent upon our observational perspective, suggesting that it is a derived concept rather than a fundamental one.",
        "ori-fast-z-score": 0.30151134457776363,
        "water-fast-z-score": 6.274210251953172,
        "rewrite-fast-z-score": 1.086610735988866
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Detection of Emission from the CN Radical in the Cloverleaf Quasar at z=2.56 .\nAbstract:\nWe report on observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) that reveal emission lines associated with carbon monoxide and its isotopologue, 13CO, as well as the CN radical toward the quasar host galaxy at redshift 2.56 known as the  Cloverleaf  source.  The observed line ratios are consistent with those expected for gas exposed to intense radiation fields characteristic of quasars. We also detect absorption by molecular hydrogen along this sightline through intervening clouds located between us and the quasar host galaxy. These results provide new insights into the physical conditions within the interstellar medium surrounding active galactic nuclei during their early evolutionary stages. This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited. \nThe detection of carbon monoxide (CO), one of the most abundant molecules in space, has been used extensively over the past several decades to study the properties of cold neutral atomic and molecular gas in galaxies across cosmic time. However, CO can be difficult to observe directly because it lacks electric dipole moments and thus emits very weakly. In addition, the excitation temperature of the lowest rotational levels of CO is typically low enough such that these transitions fall outside of the frequency range accessible to ground-based telescopes operating at millimeter wavelengths. As a result, much of our understanding about the physical conditions present in dense regions of star-forming galaxies comes from studies of other tracers of molecular gas, including HCN, H2S, CS, CH3OH, H2O, and OH+.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Detection of Emission from the CN Radical in the Cloverleaf Quasar at z = 2 . 56 . Abstract : We report on observations made with the Atacama Large Millimeter / submillimeter Array ( ALMA ) that indicate emission lines linked with carbon monoxide and its isotopologue , 13CO , as also as the CN radical toward the quasar host galaxy at redshift 2 . 56 referred as the Cloverleaf source .The observed line values are consistent with those expected for gas exposed to intense radiation fields distinctive of quasars . We additionally observe absorption by molecular hydrogen along this sightline through intervening clouds situated between us and the quasar host universe .These data provide fresh insights into the physical conditions within the interstellar medium comprising active galactic nuclei during their early evolutionary stages . This is an free access section under the terms of the Creative Commons Attribution License , which allows use , distribution and reproduction in any medium , provided the original book is properly cited .The measurement of carbon monoxide ( CO ) , one of the most stable compounds in space , has been used heavily over the previous several decades to study the properties of cold neutral atomic and molecular gas in galaxies across cosmic time . However , CO can be harder to observe directly because it lacks electric dipole moments and therefore emits very weakly .In addition , the excitation temperature of the lowest rotational concentrations of CO is typically minimum enough such that these changes fall outside of the frequency limit accessible to ground - based telescopes operating at millimeter wavelengths . As a result , part of our knowing about the physical conditions present in dense areas of galaxy - making clusters comes from studies of other tracers of molecular dust , notably HCN , H2S , CS , CH3OH , H2O , and OH + .",
        "rewrite_text": "**Title:** Detection of Emission from the CN Radical in the Cloverleaf Quasar at z = 2.56\n\n**Abstract:** In this study, we present findings from observations conducted with the Atacama Large Millimeter/submillimeter Array (ALMA), which reveal emission lines associated with carbon monoxide (CO) and its isotopologue, 13CO, as well as the CN radical in the host galaxy of the Cloverleaf quasar at a redshift of 2.56. The emission line characteristics align with theoretical predictions for gas subjected to the intense radiation fields typical of quasars. Furthermore, we detect absorption features from molecular hydrogen along the line of sight, indicating the presence of intervening clouds between the observer and the quasar's host galaxy. These observations enhance our understanding of the physical conditions within the interstellar medium of active galactic nuclei during their formative stages.\n\nThe measurement of carbon monoxide, a prevalent and stable molecule in the cosmos, has been instrumental in investigating the properties of cold neutral atomic and molecular gas in galaxies throughout cosmic history. However, direct observations of CO can be challenging due to its lack of electric dipole moments, resulting in weak emissions. Additionally, the excitation temperatures of CO's lowest rotational states are often too low to be detected by ground-based telescopes operating in the millimeter wavelength range. Consequently, our comprehension of the physical environments in dense regions of galaxy-forming clusters has been significantly informed by studies of alternative molecular tracers, including HCN, H2S, CS, CH3OH, H2O, and OH+. This research contributes valuable insights into the complex interplay of molecular emissions and the conditions prevalent in the early universe, furthering our understanding of galaxy evolution. This article is published under the Creative Commons Attribution License, permitting unrestricted use, distribution, and reproduction in any medium, provided the original work is appropriately cited.",
        "ori-fast-z-score": -1.5787044347526527,
        "water-fast-z-score": 6.075111253646805,
        "rewrite-fast-z-score": 0.5303300858899106
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Asteroseismology of alpha Cen A. Evidence of rotational splitting .\nAbstract:\nWe present new results on the asteroseismic analysis of the primary component in the binary system Alpha Centari, based on data obtained with the HARPS spectrograph at La Silla Observatory (Chile). We find evidence for two independent frequencies that are likely to be associated with rotationally split modes. The observed frequency pattern is consistent with theoretical predictions and suggests an inclination angle between 40°and 60°for this star. \n \n Keywords: Asteroseismology, Rotation, Binary stars, Oscillations, Frequency analysis, High-precision radial velocities, Alpha Centari ABSTRACT \n \n We report new results on the asterioseismic analysis of the main-sequence F-type star Alpha Centari A, which forms part of a close double system with its cooler companion B. Our study was carried out using high-precision radial-velocity measurements collected over more than four years by the HARPS instrument installed at ESO s 3.6-m telescope at La Silla Observatory (Chilean Andes), together with photometric observations made simultaneously with the CoRoT space mission. By applying standard techniques used in asteroseismology we have detected several periodicities in both datasets, including one signal whose periodicity corresponds exactly to the orbital period of the system. This finding confirms previous suggestions that the pulsational behaviour of this star may be influenced by tidal effects induced by its companion. In addition, our analysis reveals another set of signals corresponding to periods ranging from about 1 day up to almost 2 days. These signals can be explained as being due to rotationally split p-mode oscillations excited in the convective envelope of the star. Their presence provides strong support for the hypothesis that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo processes operating within the convection zone.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Asteroseismology of α Cen A . Evidence of rotational separation .Abstract : We report new data on the asteroseismic study of the primary component in the binary system Alpha Centari , using on evidence derived with the HARPS spectrograph at La Silla Observatory ( Chile ) . We see evidence for two independent frequencies that are likely to be involved with rotationally split modes .The observed frequency trend is compatible with theoretical estimates and suggests an inclination angle between 40°and 60°for this star . Keywords : Asteroseismology , Rotation , Binary stars , Oscillations , Frequency assessment , High - precision radial velocities , Alpha Centari ABSTRACT We report new data on the asterioseismic study of the main - sequence F - class star Alpha Centari A , which forms part of a close double system with its warmer companion B .Our study was carried out utilizing large - precision radial - speed measurements collected over more than four years by the HARPS instrument located at ESO s 3 . 6 - m observatory at La Silla Observatory ( Chilean Andes ) , combined with photometric surveys made independently with the CoRoT space expedition . By applying traditional techniques employed in asteroseismology we have discovered numerous periodicities in both datasets , notably one signal whose periodicity corresponds exactly to the orbital period of the system .This finding indicates past proposals that the pulsational evolution of this star may be altered by tidal impacts generated by its companion . In addition , our analysis reveals another set of signals relating to periods ranging from about 1 day up to approximately 2 days .These transmissions can be understood as being related to rotationally split p - mode oscillations excited in the convective envelope of the star . Their presence provides strong evidence for the notion that the surface of Alpha Centari A has been shaped by magnetic activity driven by dynamo mechanisms operating within the convection zone .",
        "rewrite_text": "**Title:** Asteroseismology of α Cen A: Evidence of Rotational Separation\n\n**Abstract:** In this study, we present new findings from the asteroseismic investigation of Alpha Centauri A, the primary star in the binary system Alpha Centauri, utilizing data obtained from the HARPS spectrograph at La Silla Observatory in Chile. Our analysis reveals the presence of two distinct frequencies that are likely associated with rotationally split modes. The observed frequency patterns align well with theoretical predictions, suggesting an inclination angle for Alpha Centauri A between 40° and 60°. \n\nOur research focuses on the main-sequence F-type star Alpha Centauri A, which is part of a close binary system with its hotter companion, Alpha Centauri B. We conducted our study using high-precision radial velocity measurements collected over a span of more than four years with the HARPS instrument, complemented by independent photometric data from the CoRoT space mission. By employing established asteroseismic techniques, we identified multiple periodic signals across both datasets, including one that corresponds precisely to the orbital period of the binary system. This finding supports previous hypotheses suggesting that the pulsational characteristics of Alpha Centauri A may be influenced by tidal interactions with its companion star.\n\nFurthermore, our analysis uncovered additional signals with periods ranging from approximately 1 to 2 days, which can be interpreted as rotationally split p-mode oscillations occurring within the star's convective envelope. The detection of these oscillations provides compelling evidence that the surface characteristics of Alpha Centauri A have been significantly influenced by magnetic activity, likely driven by dynamo processes within its convection zone. This research enhances our understanding of the asteroseismic properties of Alpha Centauri A and the complex interactions within binary star systems. \n\n**Keywords:** Asteroseismology, Rotation, Binary stars, Oscillations, Frequency assessment, High-precision radial velocities, Alpha Centauri.",
        "ori-fast-z-score": -1.2909944487358056,
        "water-fast-z-score": 6.627104836843802,
        "rewrite-fast-z-score": 0.8838834764831843
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Lyman Break Galaxies at z~5: Rest-frame UV Spectra II .\nAbstract:\nWe present new rest-UV spectra for four Lyman break galaxies (LBGs) with redshifts between 5 and 6, obtained using the Ultraviolet Echelle Spectrograph on board the Hubble Space Telescope.  The data are used to measure the interstellar medium properties in these objects by fitting models to their observed absorption line profiles. We find that all four LBGs have high metallicities ranging from 0.2 solar to 1 solar, which is consistent with previous results based on optical spectroscopy. In addition we detect strong outflows in three of our targets, as evidenced by blueshifted interstellar absorption lines. These observations suggest that massive stars may be responsible for driving galactic-scale winds even before reionization has completed. This work was supported by NASA grant HST-GO-10775.01-A awarded through the Space Telescope Science Institute, which is operated by AURA under NASA contract NAS5-26555.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Lyman Break Galaxies at z ~ 5 : Rest - frame UV Spectra II . Abstract : We create additional rest - UV spectra for four Lyman break galaxies ( LBGs ) with redshifts between 5 and 6 , obtained using the Ultraviolet Echelle Spectrograph on board the Hubble Space Telescope .The data are using to measure the interstellar medium characteristics in these objects by fitting models to their observed emission line profiles . We see that all four LBGs have high metallicities ranging from 0 . 2 solar to 1 solar , which is consistent with previous findings based on optical spectroscopy .In addition we perceive strong outflows in three of our targets , as demonstrated by blueshifted interstellar absorption patterns . These measurements suggest that powerful stars likely be responsible for driving galactic - scale winds long before reionization has completed .This project was supported by NASA gift HST - GO - 10775 . 01 - A awarded through the Space Telescope Science Institute , which is operated by AURA under NASA contract NAS5 - 26555 .",
        "rewrite_text": "In this study, we present additional rest-frame ultraviolet (UV) spectra for four Lyman Break Galaxies (LBGs) with redshifts ranging from 5 to 6, utilizing data collected by the Ultraviolet Echelle Spectrograph aboard the Hubble Space Telescope. Our analysis focuses on characterizing the interstellar medium (ISM) of these galaxies by fitting theoretical models to their observed emission line profiles. The results indicate that all four LBGs exhibit high metallicities, varying from 0.2 to 1 solar, which aligns with previous research conducted through optical spectroscopy methods. Furthermore, we observe significant outflows in three of the galaxies, evidenced by the presence of blueshifted interstellar absorption features. These findings imply that the intense stellar activity within these galaxies is likely driving galactic-scale winds, a phenomenon that appears to occur well before the completion of the reionization epoch. This research contributes to our understanding of the early universe and the role of LBGs in cosmic evolution. The project received support from NASA grant HST-GO-10775.01-A, awarded through the Space Telescope Science Institute, which operates under NASA contract NAS5-26555.",
        "ori-fast-z-score": -1.6378460497066512,
        "water-fast-z-score": 3.25,
        "rewrite-fast-z-score": -0.9561828874675149
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nonstationary random acoustic and electromagnetic fields as wave diffusion processes .\nAbstract:\nWe consider the statistical properties of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions, power spectra, and probability density functions (PDFs). We show that these quantities can be expressed by means of solutions to certain partial differential equations with time-dependent coefficients. The PDFs are obtained for both stationary and nonstationary cases using the method of characteristics. In particular, we derive an exact expression for the PDF of the amplitude fluctuations of a monochromatic plane wave propagating through a turbulent medium. This result is used to obtain expressions for the mean-square fluctuation levels of the electric field strength and intensity at any point along the propagation path. Finally, we discuss some applications of our results to radiowave scintillation theory and radar detection problems. PACS: 42.65.Tg, 43.20 .Fx, 47.55.+q, 47.60.+j",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nonstationary random acoustic and electromagnetic fields as wave diffusion processes . Abstract : We consider the statistical characteristics of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions , power spectra , and likelihood density functions ( PDFs ) .We see that these quantities can be described by means of solutions to many partial differential coefficients with time - dependent coefficients . The PDFs are derived for both static and nonstationary cases using the method of characteristics .In particular , we derive an precise representation for the PDF of the amplitude fluctuations of a monochromatic plane beam propagating through a turbulent medium . This result is utilized to obtain definitions for the mean - square fluctuation concentrations of the electric field intensity and intensity at any point along the propagation path .Finally , we explain some applications of our findings to radiowave scintillation theory and radar detection difficulties . PACS : 42 . 65 . Tg , 43 . 20 . Fx , 47 . 55 . + q , 47 . 60 . + j",
        "rewrite_text": "Title: Nonstationary Random Acoustic and Electromagnetic Fields as Wave Diffusion Processes\n\nAbstract: This article investigates the statistical properties of nonstationary random acoustic and electromagnetic waves, focusing on their correlation functions, power spectra, and probability density functions (PDFs). We demonstrate that these statistical characteristics can be effectively described using solutions to various partial differential equations with time-dependent coefficients. The derivation of PDFs is conducted for both static and nonstationary scenarios through the method of characteristics. Notably, we provide a detailed representation of the PDF for amplitude fluctuations of a monochromatic plane wave as it travels through a turbulent medium. This representation is instrumental in defining the mean-square fluctuation concentrations of electric field intensity and intensity at any given point along the propagation trajectory. Furthermore, we discuss the implications of our results in the context of radiowave scintillation theory and the challenges associated with radar detection. Our findings contribute to a deeper understanding of wave diffusion processes in nonstationary environments, offering valuable insights for applications in various fields such as telecommunications and remote sensing. The research is categorized under PACS codes: 42.65.Tg, 43.20.Fx, 47.55.+q, and 47.60.+j.",
        "ori-fast-z-score": 0.6882472016116852,
        "water-fast-z-score": 4.98201895023622,
        "rewrite-fast-z-score": 3.4112114616897666
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A study of uranium-based multilayers: II. Magnetic properties .\nAbstract:\nThe magnetic properties of the U(001)/Cu and U(001)/Ag interfaces are studied by means of spin-polarized density functional theory (DFT). The calculations show that both systems have an antiferromagnetic ground state with a Néel temperature around 300 K, in agreement with previous experimental results for Cu layers on top of U(001), but not for Ag layers.  In addition to this common behavior, we find important differences between these two systems:  For the U(001)/Cu interface there is no significant difference between the calculated exchange parameters using either LDA or GGA functionals; however, for the U(001)/A... This article is part of a series of papers devoted to the investigation of the electronic structure and physical properties of uranium-based materials. Herein we present our theoretical studies about the magnetic properties of the U/Cu and U/Ag interfaces. We use spin polarized DFT within the local-density approximation (LDA) as well as generalized gradient approximations (GGA) to calculate the exchange interactions at different distances along the  001  direction. Our results indicate that both systems have an AFM ground state with a Neel temperature around 300K which agrees with experiments performed only for Cu layers deposited onto U(001).  However, when comparing the calculated exchange constants it can be seen that they differ significantly depending on whether one uses LDA or GGA.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A investigation of uranium - based multilayers : II . Magnetic properties .Abstract : The magnetic properties of the U ( 001 ) / Cu and U ( 001 ) / Ag interfaces are studied by means of spin - polarized density functional theory ( DFT ) . The studies reveal that both systems have an antiferromagnetic ground state with a Néel temperature around 300 K , in agreement with previous experimental results for Cu layers on top of U ( 001 ) , but not for Ag layers .In addition to this common behavior , we find important differences between these two systems : For the U ( 001 ) / Cu interface there is no major variation between the adjusted transfer characteristics utilizing either LDA or GGA functionals ; however , for the U ( 001 ) / A . . . This page is part of a sequence of papers focused to the examination of the electronic properties and physical properties of uranium - based materials .Herein we present our theory experiments about the magnetic properties of the U / Cu and U / Ag interfaces . We use spin polarized DFT within the local - density approximation ( LDA ) as well as generalized gradient approximations ( GGA ) to estimate the transfer interactions at different distances along the 001 direction .Our results show that both systems have an AFM ground state with a Neel temperature around 300K which agrees with experiments conducted only for Cu layers transported onto U ( 001 ) . However , when comparing the adjusted transfer constants it can be saw that they differ significantly depending on whether one uses LDA or GGA .",
        "rewrite_text": "**Title:** Investigation of Uranium-Based Multilayers: II. Magnetic Properties\n\n**Abstract:** This study explores the magnetic properties of the U(001)/Cu and U(001)/Ag interfaces through spin-polarized density functional theory (DFT). Our findings indicate that both systems exhibit an antiferromagnetic (AFM) ground state with a Néel temperature of approximately 300 K, which aligns with previous experimental observations for copper layers deposited on U(001), though not for silver layers. While both interfaces share this common AFM characteristic, significant differences emerge upon closer examination. For the U(001)/Cu interface, the transfer characteristics remain relatively stable regardless of whether the local density approximation (LDA) or generalized gradient approximation (GGA) functionals are employed. In contrast, the U(001)/Ag interface displays notable variations in the adjusted transfer constants, highlighting the sensitivity of its magnetic properties to the choice of functional. This paper is part of a broader series investigating the electronic and physical properties of uranium-based materials. We present our theoretical findings on the magnetic behaviors of the U/Cu and U/Ag interfaces, utilizing both LDA and GGA methodologies to assess transfer interactions at varying distances along the [001] direction. Our results not only confirm the AFM ground state and Néel temperature but also underscore the importance of functional selection in accurately capturing the magnetic characteristics of these uranium-based multilayers. This research contributes to the understanding of the complex interplay between electronic structure and magnetic behavior in uranium-containing systems, paving the way for future studies in this area.",
        "ori-fast-z-score": 1.7822655773580138,
        "water-fast-z-score": 6.010508596802189,
        "rewrite-fast-z-score": 1.3867504905630728
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Statistical mechanics of complex networks .\nAbstract:\nThe statistical mechanics of networks is an emerging field that has attracted much attention in recent years, especially after the discovery of scale-free and small-world properties in many real world systems such as social networks, biological networks, technological networks etc.. In this talk I will present some results on the statistical mechanics of random graphs with arbitrary degree distributions. The main focus will be on the phase transitions associated with the appearance/disappearance of giant connected components (GCC) in these graphs. We show how to calculate exactly the probability distribution function for GCC size using generating functions techniques. This allows us to study analytically the effect of various parameters like average connectivity, clustering coefficient, node degrees etc., on the formation of GCCs. Finally we discuss possible applications of our results to problems related to epidemic spreading on networks. The statistical mechanics of networks is one of the most active areas of research today. It was pioneered by Barabasi-Albert who discovered that many real world networks have power law degree distributions  1  . Since then there has been considerable interest in understanding the statistical mechanical behavior of different classes of networks  2  .\nIn particular it has been shown recently  3  , that the presence or absence of a giant component (GC), which contains a finite fraction of all nodes in the graph, can lead to interesting phase transitions. For example if the GC disappears at any finite temperature T = 1/β, then the system undergoes a first order transition where the free energy density f ≡ − ln Z/N diverges continuously when β → ∞  4  . Here N denotes the number of nodes in the network while Z is the partition sum defined as:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Statistical mechanics of complex networks . Abstract : The mathematical mechanics of networks is an developing field that has garnered considerable scrutiny in recent years , particularly after the discovery of scale - free and tiny - world properties in many actual world systems such as social systems , biological organizations , technological networks etc . .In this talk I will present some results on the statistical mechanics of random graphs with arbitrary degree distributions . The main attention will be on the phase transitions associated with the appearance / disappearance of giant connected parts ( GCC ) in these graphs .We see how to estimate exactly the probability distribution function for GCC size using generating functions techniques . This enables us to study analytically the impact of several variables like average connectivity , clustering coefficient , node degrees etc . , on the formation of GCCs .Finally we talk possible applied of our findings to problems related to epidemic spreading on networks . The statistical mechanics of networks is one of the most important areas of research today .It was pioneered by Barabasi - Albert who found that several real global networks have power law degree distributions 1 . Since then there has been substantial interest in understanding the statistical mechanical behavior of different categories of networks 2 .In particular it has been shown recently 3 , that the presence or lack of a giant element ( GC ) , which contains a finite fraction of all nodes in the graph , can lead to unusual phase transitions . For instance if the GC disappears at any finite temperature T = 1 / β , then the system undergoes a first order phase where the free energy density g ≡ − ln Z / N diverges steadily when β → ∞ 4 .Here N refers the number of nodes in the network while Z is the partition sum specified as :",
        "rewrite_text": "**Title: Statistical Mechanics of Complex Networks**\n\n**Abstract:** The study of the mathematical mechanics of networks has emerged as a dynamic and rapidly evolving field, attracting significant attention in recent years. This surge in interest is largely attributed to the identification of scale-free and small-world characteristics in various real-world systems, including social networks, biological structures, and technological frameworks. In this presentation, I will share key findings related to the statistical mechanics of random graphs characterized by arbitrary degree distributions. A primary focus will be on the phase transitions linked to the emergence and dissolution of giant connected components (GCCs) within these networks. We will explore methods to accurately estimate the probability distribution function for the size of GCCs through the application of generating function techniques. This analytical approach allows us to investigate the influence of several parameters, such as average connectivity, clustering coefficients, and node degrees, on the development of GCCs.\n\nFurthermore, I will discuss the potential applications of our results in addressing issues related to epidemic spreading across networks. The statistical mechanics of networks has become a pivotal area of research, initially pioneered by Barabási and Albert, who discovered that numerous global networks exhibit power-law degree distributions. Since their groundbreaking work, there has been a growing interest in comprehending the statistical mechanical properties of various network types. Recent studies have highlighted that the existence or absence of a giant component (GC)—which encompasses a significant fraction of the total nodes—can trigger remarkable phase transitions. For example, if the GC vanishes at a finite temperature (T = 1/β), the system experiences a first-order phase transition, characterized by a divergence in the free energy density (g ≡ -ln Z/N) as β approaches infinity, where N denotes the number of nodes in the network and Z represents the partition function. This research contributes to a deeper understanding of complex networks and their behaviors, with implications for both theoretical and practical applications.",
        "ori-fast-z-score": -0.16116459280507606,
        "water-fast-z-score": 4.868329995252495,
        "rewrite-fast-z-score": -0.45226701686664544
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Robust Multi-Cellular Developmental Design .\nAbstract:\nWe present an approach to robust multi-cellular developmental design that combines the advantages of both bottom-up and top-down approaches, while avoiding their respective disadvantages. The proposed method is based on a novel concept called  embryonic development space (EDS)  which represents all possible designs in terms of cell types and connections between them. We show how EDS can be used for efficient exploration of different designs by applying evolutionary algorithms. Finally we demonstrate our approach using two case studies - one synthetic and another biological. Robustness has been recognized as one of the most important features of living systems  1  . In particular, it plays crucial role during embryogenesis when cells differentiate into various tissues and organs  2  , but also later in life  3  .\nIn this work we propose a new computational framework for designing robust multicellular systems. Our approach combines the advantages of both  bottom-up   4  and  top-down   5  methods, while overcoming some of their limitations. Bottom-up methods are typically applied to model cellular differentiation  6  or morphogenetic processes  7  . They usually start with a single cell type and then evolve towards more complex structures through successive divisions and/or mutations  8  . Top-down methods use genetic programming  9  or other optimization techniques  10  to search for optimal solutions within pre-defined constraints  11  . However, these methods often require extensive tuning of parameters  12  and may get stuck at local optima  13  .\nOur approach uses a novel concept called  embryo-",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Robust Multi - Cellular Developmental Design . Abstract : We present an perspective to robust multi - cell developmental architecture that combines the advantages of both bottom - up and bottom - down approaches , while eliminating their different disadvantages .The proposed approach is based on a novel concept called embryonic development space ( EDS ) which includes all possible designs in terms of gene groups and links between them . We see how EDS can be used for efficient exploration of different designs by using evolutionary techniques .Finally we prove our approach using two case studies - one synthetic and another biological . Robustness has been recognized as one of the most important features of living systems 1 .In particular , it plays crucial role during embryogenesis when cells transform into various tissues and tissues 2 , but also subsequently in life 3 . In this research we propose a new computational framework for constructing robust multicellular systems .Our model combines the advantages of both bottom - up 4 and bottom - down 5 methods , while overcoming some of their limitations . Bottom - up methods are typically utilized to model cell transformation 6 or morphogenetic systems 7 .They often beginning with a single cell type and then evolve towards more sophisticated shapes through consecutive divisions and / or genes 8 . Top - down methods using genetic programming 9 or other optimization tools 10 to search for efficient answers within pre - defined constraints 11 .However , these algorithms often take extensive tuned of values 12 and may come stuck at local optima 13 . Our concept employs a novel concept called embryo -",
        "rewrite_text": "**Title: Robust Multi-Cellular Developmental Design**\n\n**Abstract:** In this article, we introduce a novel perspective on robust multi-cellular developmental architecture that effectively merges the strengths of both bottom-up and top-down methodologies while addressing their respective shortcomings. Central to our approach is the innovative concept of the embryonic development space (EDS), which encompasses all conceivable designs characterized by various gene groupings and their interconnections. We demonstrate how EDS facilitates the efficient exploration of diverse designs through the application of evolutionary techniques. Our framework is validated through two distinct case studies: one synthetic and the other biological, showcasing its versatility and effectiveness.\n\nRobustness is widely acknowledged as a critical attribute of living systems, particularly during the process of embryogenesis, where cells differentiate into various tissues and subsequently into complex structures. This research proposes a comprehensive computational framework aimed at constructing resilient multicellular systems. Our model integrates the benefits of both bottom-up and top-down strategies while mitigating some of their inherent limitations. \n\nBottom-up approaches typically focus on modeling cell transformation or morphogenetic processes, often starting with a single cell type that evolves into more complex forms through successive divisions and genetic interactions. Conversely, top-down methods leverage genetic programming and other optimization techniques to identify efficient solutions within established constraints. However, these algorithms frequently require extensive parameter tuning and may become trapped in local optima.\n\nBy introducing the concept of the embryonic development space, we provide a robust platform for exploring the vast design possibilities inherent in multicellular systems. This framework not only enhances the understanding of developmental processes but also paves the way for innovative applications in synthetic biology and tissue engineering. Through our case studies, we illustrate the practical implications of our approach, highlighting its potential to advance the field of developmental design in biological systems.",
        "ori-fast-z-score": -0.17677669529663687,
        "water-fast-z-score": 8.06893377762467,
        "rewrite-fast-z-score": 1.556540648986177
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Vector mesons from AdS/TC to the LHC .\nAbstract:\nWe present an overview of our recent work on vector meson production in heavy ion collisions at RHIC and LHC energies, based on holographic QCD models with chiral symmetry breaking (AdS/QCD). We discuss how these models can be used to calculate hadronic observables such as transverse momentum spectra and elliptic flow coefficients for light quarks and gluons produced in nuclear reactions. In particular we focus on the role played by the coupling between the bulk fields and the gauge field fluctuations dual to vector mesons. The results are compared with experimental data obtained at RHIC and LHC: they show good agreement both qualitatively and quantitatively. \n \n Keywords: Vector Mesons, Heavy Ion Collisions, Holography, Chiral Symmetry Breaking, Gauge/Gravity Duality \n \n 1 Introduction \n \n One of the most exciting discoveries made recently at RHIC is that strongly interacting matter behaves like a nearly perfect fluid  1  . This observation has led many theorists to propose new ways of describing this state of matter using effective theories which incorporate hydrodynamics  2  , or even more exotic descriptions involving quark-gluon plasma droplets  3  .\n \nIn order to understand better what happens during the early stages of heavy-ion collisions it would be very useful if one could study experimentally the properties of the hot dense medium created in those collisions. However, due to its extremely short lifetime, this medium cannot be directly probed through standard scattering experiments. Instead, information about the initial conditions of the collision process must be inferred indirectly from final-state measurements  4  . For example, the collective expansion of the system leads to anisotropic particle emission patterns known as azimuthal asymmetries  5  . These anisotropies have been measured  6  and found to agree well with theoretical predictions  7, 8  . \n \n Another important observable characterizing the dynamics of the expanding fireball is the spectrum of emitted particles  9  . It was shown  10  that the shape of this spectrum depends sensitively on the equation-of-state of the medium  11  . Moreover, the observed suppression  12  of high-pT hadrons",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Vector mesons from AdS / TC to the LHC . Abstract : We present an overview of our latest work on vector meson production in heavy ion collisions at RHIC and LHC energies , based on holographic QCD models with chiral symmetry breaking ( AdS / QCD ) .We discuss how these models can be used to estimate hadronic observables such as transverse energy spectra and elliptic flow coefficients for light quarks and gluons produced in nuclear compounds . In particular we focus on the importance played by the interaction between the bulk fields and the gauge field fluctuations dual to vector mesons .The results are compared with observation information obtained at RHIC and LHC : they show good agreement both qualitatively and quantitatively . Keywords : Vector Mesons , Heavy Ion Collisions , Holography , Chiral Symmetry Breaking , Gauge / Gravity Duality 1 Introduction One of the most exciting developments conducted lately at RHIC is that strongly interacting material behaves like a nearly perfect fluid 1 .This observation has led many theorists to propose new ways of describing this state of matter utilizing effective models which employ hydrodynamics 2 , or especially more exotic representations featuring quark - gluon particle droplets 3 . In order to explain better what comes during the early stages of light - ion collisions it would be very useful if one might explore experimentally the properties of the hot dense medium produced in those collisions .However , owing to its incredibly small life , this medium never be directly probed through conventional absorption studies . Instead , info about the first environments of the collision mechanism must be inferred indirectly from final - state measurements 4 .For instance , the collective expansion of the system leads to anisotropic particle emission effects referred as azimuthal asymmetries 5 . These anisotropies have been measured 6 and found to agree well with theoretical estimates 7 , 8 .Another important observable characterizing the dynamics of the increasing fireball is the spectrum of emitted particles 9 . It was shown 10 that the form of this spectrum relies sensitively on the equation - of - state of the medium 11 .Moreover , the observed suppression 12 of high - pT hadrons",
        "rewrite_text": "**Title:** Vector Mesons from AdS/TC to the LHC\n\n**Abstract:** In this article, we provide a comprehensive overview of our recent research on the production of vector mesons in heavy ion collisions at both RHIC and LHC energies, utilizing holographic QCD models that incorporate chiral symmetry breaking (AdS/QCD). We explore how these theoretical frameworks can be employed to estimate various hadronic observables, including transverse energy spectra and elliptic flow coefficients for light quarks and gluons generated in nuclear interactions. A significant focus of our study is the role of interactions between bulk fields and gauge field fluctuations that are dual to vector mesons. Our findings demonstrate a strong correlation with experimental data obtained from RHIC and LHC, exhibiting both qualitative and quantitative agreement. \n\nThe introduction of our work highlights a pivotal observation from recent RHIC experiments, which suggest that strongly interacting matter behaves similarly to a nearly perfect fluid. This revelation has prompted theorists to develop innovative models to describe this state of matter, employing effective approaches that utilize hydrodynamics, as well as more unconventional representations involving quark-gluon droplets. To enhance our understanding of the early stages of light-ion collisions, it is crucial to experimentally investigate the properties of the hot, dense medium produced during these events. However, due to its fleeting existence, this medium cannot be directly examined through traditional absorption techniques. Instead, insights into the initial conditions of the collision process must be derived from final-state measurements. \n\nFor example, the collective expansion of the system results in anisotropic particle emission, known as azimuthal asymmetries, which have been measured and found to align well with theoretical predictions. Additionally, the spectrum of emitted particles serves as another key observable that characterizes the dynamics of the expanding fireball, with its form being highly sensitive to the equation of state of the medium. Furthermore, we discuss the observed suppression of high-pT hadrons, which provides further insight into the underlying mechanisms at play in these high-energy collisions. \n\n**Keywords:** Vector Mesons, Heavy Ion Collisions, Holography, Chiral Symmetry Breaking, Gauge/Gravity Duality.",
        "ori-fast-z-score": 0.3287979746107146,
        "water-fast-z-score": 7.405474974817551,
        "rewrite-fast-z-score": 0.4016096644512494
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nilpotent symmetry invariance in the superfield formulation: the (non-)Abelian 1-form gauge theories .\nAbstract:\nWe present an explicit construction of nilpotent supersymmetry transformations for Abelian and non-Abelian 1-form gauge fields, which are formulated as components of chiral N=1 superfields. The corresponding action is invariant under these transformations up to total derivatives. We show that this theory can be obtained by dimensional reduction of 4D N=2 SYM down to 3D. In addition we discuss how our results generalize to higher dimensions. Introduction: Supersymmetric field theories have been studied extensively over last decades due to their remarkable properties such as unitarity and renormalizability  1, 2  . One of the most important features of supersymmetric models is the presence of fermionic partners of bosonic degrees of freedom with opposite statistics. These new particles lead to additional symmetries called supersymmetries. It has been shown that all known fundamental interactions including gravity can be described within the framework of supersymmetric quantum mechanics  3  .\nIn recent years there was renewed interest in supersymmetric field theories motivated by developments in string/M-theory  4  , where they appear naturally on various brane configurations  5  . Moreover, it turns out that many interesting phenomena observed at high energies may find natural explanation within the context of supersymmetric extensions of Standard Model  6  . For example, supersymmetry provides elegant solution to hierarchy problem  7, 8  or offers possible candidates for dark matter  9  .\nThe simplest supersymmetric extension of Standard Model contains only one extra spin-1/2 particle -the gravitino  10  . However, more complicated versions involving several spin-1/2 fields exist  11  . A particularly interesting class of supersymmetric models involves so-called extended supersymmetry  12  . This includes N = 2 supersymmetry  13  , which appears in M-theory compactified on Calabi-Yau manifolds  14  , and its further generalization to N = 4  15  . Another interesting case corresponds to N = 1 supersymmetry  16  , which arises when D-branes wrap cycles of internal space  17  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nilpotent symmetry invariance in the superfield implementation : the ( non - ) Abelian 1 - form gauge theories . Abstract : We introduce an explicit construction of nilpotent supersymmetry transformations for Abelian and non - Abelian 1 - form gauge fields , which are formulated as components of chiral N = 1 superfields .The corresponding action is invariant under these transformations up to complete derivatives . We see that this theory can be obtained by dimensional reduction of 4D N = 2 SYM down to 3D .In addition we talk how our findings generalize to higher dimensions . Introduction : Supersymmetric field theories have been studied frequently over last decades owing to their extraordinary properties such as unitarity and renormalizability 1 , 2 .One of the most important features of supersymmetric theories is the presence of fermionic partners of bosonic degrees of liberty with opposite statistics . These new interactions result to extra symmetries called supersymmetries .It has been shown that all known fundamental interactions including gravity can be described within the framework of supersymmetric quantum mechanics 3 . In recent years there was renewed interest in supersymmetric field theories motivated by developments in string / M - theory 4 , where they appear naturally on various brane configurations 5 .Moreover , it turns out that several interesting phenomena observed at high energies may reach natural explanation within the context of supersymmetric extensions of Standard Model 6 . For instance , supersymmetry presents elegant solve to hierarchy problem 7 , 8 or offers possible candidates for black matter 9 .The simplest supersymmetric extension of Standard Model includes only one extra spin - 1 / 2 particle - the gravitino 10 . However , more complicated versions involving several spin - 1 / 2 fields exist 11 .A notably important family of supersymmetric theories involves so - called extended supersymmetry 12 . This contains N = 2 supersymmetry 13 , which appears in M - theory compactified on Calabi - Yau manifolds 14 , and its further generalization to N = 4 15 .Another important case corresponds to N = 1 supersymmetry 16 , which occurs when D - branes wrap cycles of internal space 17 .",
        "rewrite_text": "**Title:** Nilpotent Symmetry Invariance in the Superfield Implementation: The (Non-)Abelian 1-Form Gauge Theories\n\n**Abstract:** In this paper, we present a detailed construction of nilpotent supersymmetry transformations applicable to both Abelian and non-Abelian 1-form gauge fields, which are expressed as components of chiral N = 1 superfields. The action derived from this framework is shown to be invariant under these transformations, modulo total derivatives. Notably, we demonstrate that this theoretical framework can be derived through the dimensional reduction of four-dimensional N = 2 supersymmetric Yang-Mills (SYM) theory down to three dimensions. Furthermore, we explore the implications of our findings for higher-dimensional theories, suggesting a broader applicability of our results. \n\nThe study of supersymmetric field theories has garnered significant attention over the past few decades due to their remarkable characteristics, including unitarity and renormalizability. A defining aspect of these theories is the existence of fermionic partners for bosonic degrees of freedom, which exhibit opposite statistics. This interplay gives rise to additional symmetries known as supersymmetries. It has been established that all known fundamental interactions, including gravity, can be encapsulated within the framework of supersymmetric quantum mechanics. Recent advancements in string and M-theory have reignited interest in supersymmetric field theories, particularly as they naturally emerge in various brane configurations. \n\nMoreover, several intriguing phenomena observed at high energies find compelling explanations within the context of supersymmetric extensions of the Standard Model. For example, supersymmetry provides elegant solutions to the hierarchy problem and presents potential candidates for dark matter. The simplest supersymmetric extension of the Standard Model introduces a single additional spin-1/2 particle, the gravitino. However, more complex models incorporating multiple spin-1/2 fields also exist. A particularly significant class of supersymmetric theories is characterized by extended supersymmetry, including N = 2 supersymmetry, which arises in M-theory compactified on Calabi-Yau manifolds, and its further extension to N = 4 supersymmetry. Additionally, N = 1 supersymmetry is relevant in scenarios where D-branes wrap cycles of internal spaces.",
        "ori-fast-z-score": 1.5888598190134724,
        "water-fast-z-score": 6.892774827860417,
        "rewrite-fast-z-score": 0.2526455763199557
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Distances of the bulge globular clusters Terzan 5, Liller 1, UKS 1 and Terzan 4 based on HST NICMOS photometry .\nAbstract:\nWe present new near-infrared (NIR) observations for four Galactic bulge globular clusters: Terzan 5, Lilll1, UKS 1, and Terzan 4 obtained with the Near Infrared Camera and Multi-Object Spectrometer (NICMOS). The data were taken in two filters F160W and F222M during three orbits each at the Hubble Space Telescope (HST), as part of program GO-10775. We use these NIR images to derive accurate distances to all four clusters by comparing their observed magnitudes with those predicted using theoretical isochrones. Our results are consistent within uncertainties with previous distance estimates derived from optical photometric studies. For Terzan 5 we find d = 8.2 ± 0.3 kpc; for Liller 1: d = 7.7 ± 0.4 kpc; for UKS 1: d = 6.8 ± 0.5 kpc; and for Terzan 4: d = 9.0 ± 0.6 kpc.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Distances of the bulge globular complexes Terzan 5 , Liller 1 , UKS 1 and Terzan 4 based on HST NICMOS photometry . Abstract : We report new near - infrared ( NIR ) observations for four Galactic bulge globular galaxies : Terzan 5 , Lilll1 , UKS 1 , and Terzan 4 obtained with the Near Infrared Camera and Multi - Object Spectrometer ( NICMOS ) .The data were took in two filters F160W and F222M during three orbits each at the Hubble Space Telescope ( HST ) , as part of series GO - 10775 . We use these NIR observations to derive exact distances to all four clusters by comparing their observed magnitudes with those predicted using theoretical isochrones .Our results are compatible within uncertainties with previous diameter calculations derived from optical photometric studies . For Terzan 5 we find d = 8 . 2 ± 0 . 3 kpc ; for Liller 1 : d = 7 . 7 ± 0 . 4 kpc ; for UKS 1 : d = 6 . 8 ± 0 . 5 kpc ; and for Terzan 4 : d = 9 . 0 ± 0 . 6 kpc .",
        "rewrite_text": "In this study, we present new near-infrared (NIR) observations of four globular clusters located in the Galactic bulge: Terzan 5, Liller 1, UKS 1, and Terzan 4. These observations were conducted using the Near Infrared Camera and Multi-Object Spectrometer (NICMOS) aboard the Hubble Space Telescope (HST) as part of the program GO-10775. The data collection involved two specific filters, F160W and F222M, with each cluster being observed over three separate orbits. \n\nTo determine the distances to these globular clusters, we compared the observed magnitudes obtained from our NIR data with theoretical isochrones, which allowed us to derive precise distance measurements. Our findings indicate that the distances to the clusters are as follows: Terzan 5 at 8.2 ± 0.3 kpc, Liller 1 at 7.7 ± 0.4 kpc, UKS 1 at 6.8 ± 0.5 kpc, and Terzan 4 at 9.0 ± 0.6 kpc. Notably, these results are consistent with previous distance estimates derived from optical photometric studies, falling within the margins of uncertainty. \n\nThis research contributes to the understanding of the spatial distribution of globular clusters in the Galactic bulge and enhances the accuracy of distance measurements in this region. The use of NIR observations is particularly advantageous as it allows for better penetration through dust, providing clearer insights into the properties of these distant stellar systems. Overall, our results reinforce the importance of utilizing advanced observational techniques to refine the distances to globular clusters, which are crucial for various astrophysical applications, including studies of stellar populations and the dynamics of the Milky Way.",
        "ori-fast-z-score": 1.0434983894999017,
        "water-fast-z-score": 4.12837477233712,
        "rewrite-fast-z-score": 2.2691267417693455
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Isophotal Structure and Dust Distribution in Radio-Loud Elliptical Galaxies .\nAbstract:\nWe present new near-infrared (NIR) observations for the radio-loud elliptical galaxy NGC 4261, obtained with the Subaru telescope. The NIR images reveal that this galaxy has an extended dust disk around its nucleus. We find that the isophotes are well fitted by a de Vaucouleurs profile plus an exponential component at large radii. This suggests that there may be two components contributing to the surface brightness distribution; one is associated with the bulge/disk system while another is related to the dust disk. In addition, we detect a faint ring-like structure surrounding the central region. These results suggest that the dust disk is likely to have been formed through tidal interaction between the host galaxy and a companion galaxy. Our analysis also shows that the dust mass within the innermost 100 pc radius is about 1.5 x 10^6 M_sol. If we assume that the dust-to-gas ratio is similar to Galactic value, then the total gas mass would be 5 x 10^8 M_sol.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Isophotal Structure and Dust Distribution in Radio - Loud Elliptical Galaxies . Abstract : We report new near - infrared ( NIR ) observations for the radio - loud elliptical galaxy NGC 4261 , obtained with the Subaru observatory .The NIR images confirm that this galaxy has an extended dust disk around its core . We see that the isophotes are better fitted by a de Vaucouleurs profile plus an exponential component at large radii .This implies that there may be two systems causing to the surface brightness distribution ; one is associated with the bulge / disk system while another is related to the dust disk . In addition , we perceive a faint ring - like structure surrounding the main region .These data suggest that the dust disk is probably to have been formed through tidal association between the host universe and a companion galaxy . Our study also shows that the dust mass within the innermost 100 pc radius is about 1 . 5 x 10 ^ 6 M _ sol .If we suppose that the dust - to - gas ratio is identical to Galactic value , then the total gas mass would be 5 x 10 ^ 8 M _ sol .",
        "rewrite_text": "We present new near-infrared (NIR) observations of the radio-loud elliptical galaxy NGC 4261, conducted at the Subaru Observatory. Our findings reveal the presence of an extensive dust disk surrounding the galaxy's core, as confirmed by the NIR imaging. The analysis of the isophotal structure indicates that the surface brightness distribution is best described by a combination of a de Vaucouleurs profile and an exponential component at larger radii. This suggests the existence of two distinct systems contributing to the observed surface brightness: one associated with the bulge/disk structure and the other linked to the dust disk itself. Furthermore, we identify a subtle ring-like feature encircling the central region, which may provide additional insights into the galaxy's morphology. The data imply that the formation of the dust disk could be a result of tidal interactions between NGC 4261 and a neighboring galaxy. Our investigation estimates the dust mass within the innermost 100 parsecs to be approximately 1.5 x 10^6 solar masses. Assuming that the dust-to-gas ratio is comparable to that of the Milky Way, we infer a total gas mass of around 5 x 10^8 solar masses. These observations contribute to our understanding of the complex interplay between dust distribution and the structural components of radio-loud elliptical galaxies, highlighting the potential influence of external interactions on their evolution.",
        "ori-fast-z-score": 0.8944271909999159,
        "water-fast-z-score": 5.222222222222222,
        "rewrite-fast-z-score": 1.7822655773580138
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Thermodynamics of an Accretion Disk Annulus with Comparable Radiation and Gas Pressure .\nAbstract:\nWe present the results of our numerical simulations of accretion disk annuli in which radiation pressure is comparable to gas pressure, but not dominant.  We find that for such disks there are two distinct regimes depending on whether or not the luminosity is dominated by advection (i.e., Ladv/Lvisc ≫ 1). In one regime we find that the temperature profile has a power-law form T ∝ r^{-(3/2)}, while in another it follows a more complicated dependence on radius. The latter case occurs when the luminosity is dominated either by viscous dissipation or by advection. For both cases, however, the radial velocity profiles have similar shapes. Finally, we show how these results can be used to explain observed properties of X-ray binaries. Subject headings: Black holes -accretion disks -X-ray binaries: general -Accretion, accretion disks",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Thermodynamics of an Accretion Disk Annulus with Comparable Radiation and Gas Pressure . Abstract : We present the results of our numerical simulations of accretion disk annuli in which radiation volume is analogous to gas pressure , but not dominant .We see that for such disks there are two different regimes depending on whether or not the luminosity is dominated by advection ( i . e . , Ladv / Lvisc [UNK] 1 ) . In one regime we find that the temperature profile has a power - law form T [UNK] r ^ { - ( 3 / 2 ) } , while in another it takes a more complicated dependence on diameter .The latter example happens when the luminosity is dominated either by viscous dissipation or by advection . For both cases , however , the radial speed profiles have similar shapes .Finally , we explain how these results can be used to explain observed properties of X - ray binaries . Subject headings : Black holes - accretion disks - X - ray binaries : general - Accretion , accretion disks",
        "rewrite_text": "In this study, we explore the thermodynamics of accretion disk annuli where radiation pressure is comparable to, but not the predominant force over, gas pressure. Through extensive numerical simulations, we identify two distinct regimes based on the dominance of luminosity by advection, characterized by the ratio Ladv / Lvisc. In the first regime, we observe that the temperature profile follows a power-law distribution, specifically T ∝ r^(-3/2). Conversely, in the second regime, where luminosity is primarily influenced by either viscous dissipation or advection, the temperature profile exhibits a more complex relationship with the radial distance. Despite these differences in temperature behavior, we find that the radial velocity profiles maintain similar shapes across both regimes. Our findings have significant implications for understanding the thermodynamic properties of accretion disks, particularly in the context of X-ray binaries. By correlating our results with observational data, we provide insights into the underlying mechanisms governing the behavior of these astrophysical systems. This research contributes to the broader understanding of black hole accretion processes and the dynamics of accretion disks, offering a framework for interpreting the intricate interplay between radiation and gas pressure in such environments. The implications of our work extend to the study of various astrophysical phenomena, including the evolution of black holes and the characteristics of X-ray binary systems. Through this investigation, we aim to enhance the comprehension of accretion dynamics and their observable consequences in the universe.",
        "ori-fast-z-score": -0.7878385971583353,
        "water-fast-z-score": 2.213211486674006,
        "rewrite-fast-z-score": 0.09759000729485333
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The cold gaseous halo of NGC 891 .\nAbstract:\nWe present new observations of the molecular gas in the central region of the nearby galaxy NGC 891, obtained with the IRAM 30m telescope at 1mm and 3mm wavelengths. The data reveal an extended distribution of dense (n(H2) ~ 104 cm-3), warm (T~50K) molecular gas that is associated with the optical disk of this edge-on spiral galaxy. We find evidence for two distinct components to the molecular gas distribution; one component follows closely the dust lane seen in visible light images while another component extends out into the surrounding intergalactic medium. This latter component has been detected previously by other authors but our higher resolution data allow us to resolve it into individual clouds. In addition we detect several compact sources within the galactic plane which are likely to be young star forming regions. These results suggest that there may exist a significant reservoir of molecular material outside the main body of galaxies such as NGC 891.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The cold gaseous halo of NGC 891 . Abstract : We report new images of the molecular gas in the central region of the nearby galaxy NGC 891 , obtained with the IRAM 30m telescope at 1mm and 3mm wavelengths .The data reveal an extended distribution of dense ( n ( H2 ) ~ 104 mm - 3 ) , warm ( T ~ 50K ) molecular gas that is associated with the optical disk of this edge - on spiral galaxy . We see evidence for two different components to the molecular gas distribution ; one element follows tightly the dust track seen in bright light photographs while another component extends out into the nearby intergalactic medium .This latter component has been detected earlier by other researchers but our higher resolution data enable us to separate it into multiple clouds . In addition we locate many compact sources within the galactic plane which are likely to be young galaxy producing regions .These data suggest that there may contain a substantial pool of molecular matter outside the main bodies of galaxies such as NGC 891 .",
        "rewrite_text": "We present new observations of the molecular gas in the central region of the nearby galaxy NGC 891, utilizing the IRAM 30m telescope at both 1mm and 3mm wavelengths. Our findings reveal a significant and extended distribution of dense molecular gas, characterized by a density of approximately \\( n(H_2) \\sim 10^4 \\, \\text{mm}^{-3} \\) and a temperature of around \\( T \\sim 50 \\, \\text{K} \\). This molecular gas is closely associated with the optical disk of this edge-on spiral galaxy. Notably, our data indicate the presence of two distinct components within the molecular gas distribution. One component closely follows the dust lane observed in high-resolution optical images, while the other extends into the surrounding intergalactic medium. Although this latter component has been previously identified by other studies, our high-resolution observations allow us to resolve it into multiple distinct clouds. Furthermore, we identify numerous compact sources within the galactic plane, which are likely regions of active star formation. These observations suggest that there exists a considerable reservoir of molecular gas beyond the primary structures of galaxies like NGC 891, indicating that such halos may play a significant role in the overall molecular content of galaxies. This research enhances our understanding of the molecular gas dynamics in edge-on spiral galaxies and highlights the potential for substantial molecular reservoirs in the intergalactic medium.",
        "ori-fast-z-score": -2.013995972012084,
        "water-fast-z-score": 4.9819900360298925,
        "rewrite-fast-z-score": 0.944911182523068
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Entangled games are hard to approximate .\nAbstract:\nWe show that the problem of approximating Nash equilibria in two-player zero-sum entangled games is NP-hard, even if one restricts attention to pure strategies and exact equilibria.  We also prove an analogous result for mixed-strategy equilibria. These results hold under standard complexity-theoretic assumptions such as P = NP or RP = NEXP. The proof uses a reduction from the maximum cut problem on graphs with bounded treewidth. This shows that finding Nash equilibria exactly (even only among pure strategies) can be intractable when players have correlated information about each other s payoffs. Our results suggest that it may not always be possible to find good solutions by using local search algorithms like best-response dynamics. In this work we study the computational difficulty of computing Nash equilibria in two-person zero-sum games where players  utilities depend on their joint actions but they do not know these actions  outcomes before making decisions. Such games are called entangled because the outcome depends on both players  choices; see Figure 1 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Entangled players are hard to approximate . Abstract : We see that the question of approximating Nash equilibria in two - player zero - sum entangled players is NP - hard , even if one restricts focus to pure strategies and exact equilibria .We additionally prove an analogous result for mixed - strategy equilibria . These results hold under standard complexity - theoretic assumptions such as P = NP or RP = NEXP .The proof uses a reduction from the maximum cut question on graphs with bounded treewidth . This shows that finding Nash equilibria precisely ( even only among true schemes ) can be intractable when participants have correlated information about each other s payoffs .Our results show that it could not always be possible to find good answers by using local search methods like best - response dynamics . In this research we study the computational difficulty of computing Nash equilibria in two - person zero - sum games where players utilities depend on their joint actions but they do not understand these actions outcomes before deciding choice .Such matches are called entangled because the result varies on both participants selection ; look Figure 1 .",
        "rewrite_text": "Title: Entangled Players Are Hard to Approximate\n\nAbstract: This study investigates the computational complexity of approximating Nash equilibria in two-player zero-sum games involving entangled players. We demonstrate that the problem of approximating these equilibria is NP-hard, even when the focus is limited to pure strategies and exact equilibria. Furthermore, we extend our findings to mixed-strategy equilibria, establishing that the same level of computational difficulty applies. These conclusions are drawn under widely accepted complexity-theoretic assumptions, including P = NP and RP = NEXP. Our proof employs a reduction from the maximum cut problem in graphs with bounded treewidth, illustrating that accurately determining Nash equilibria—particularly in scenarios where players possess correlated information regarding each other's payoffs—can be computationally intractable. This research highlights the limitations of local search methods, such as best-response dynamics, in yielding satisfactory solutions in these contexts. We specifically examine the challenges associated with computing Nash equilibria in two-person zero-sum games, where the players' utilities are contingent upon their joint actions, yet they lack foresight regarding the outcomes of these actions prior to making their decisions. Such games are characterized as entangled, as the results depend intricately on the choices made by both participants. Our findings underscore the complexity inherent in these interactions and suggest that traditional approaches may not suffice in navigating the intricacies of entangled player scenarios.",
        "ori-fast-z-score": 0.52999894000318,
        "water-fast-z-score": 5.346252667281783,
        "rewrite-fast-z-score": 1.3728129459672884
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Two-flavor lattice QCD in the epsilon-regime and chiral Random Matrix Theory .\nAbstract:\nWe present results for two-flavor lattice QCD with Wilson fermions at pion masses down to 135 MeV, using an improved staggered quark action as input for the determination of the low-energy constants (LECs) entering the effective theory describing the lightest pseudoscalar mesons. We use the so-called epsilon regime where we can perform simulations close to the physical point without being affected by finite volume effects or excited state contamination. The LECs are determined simultaneously with the decay constant fK  ̄and the kaon B-parameterB K . In order to obtain these quantities on the same footing, we employ the method proposed in Ref.  Phys. Rev. D 87, 074010  which allows us to determine both observables directly from the correlation functions measured on our lattices. Our final values read fK = 156(3)(5)MeV , BK = 1.55(4)(6) , \nwhere the first error is statistical and the second one systematic. These results agree well within errors with those obtained previously in other approaches such as continuum extrapolations based on ChPT or phenomenological determinations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Two - flavor lattice QCD in the epsilon - regime and chiral Random Matrix Theory . Abstract : We report findings for two - flavor lattice QCD with Wilson fermions at pion masses down to 135 MeV , using an modified staggered quark operation as input for the determination of the high - energy constants ( LECs ) entering the effective theory representing the lightest pseudoscalar mesons .We use the so - called epsilon regime where we can conduct simulations nearby to the physical point without being affected by finite volume effects or excited state contamination . The LECs are decided simultaneously with the decay variable fK [UNK] the kaon B - parameterB K .In order to obtain these quantities on the same footing , we utilize the method outlined in Ref . Phys .Rev . D 87 , 074010 which allows us to identify both observables simply from the correlation functions measured on our lattices .Our last estimates read fK = 156 ( 3 ) ( 5 ) MeV , BK = 1 . 55 ( 4 ) ( 6 ) , where the first error is statistical and the second one systematic . These conclusions follow well within errors with those achieved previously in other methods such as continuum extrapolations based on ChPT or phenomenological determinations .",
        "rewrite_text": "We present our findings on two-flavor lattice Quantum Chromodynamics (QCD) utilizing Wilson fermions, focusing on pion masses as low as 135 MeV. Our approach employs a modified staggered quark operation to derive the low-energy constants (LECs) that are integral to the effective theory describing the lightest pseudoscalar mesons. We operate within the epsilon regime, which allows us to perform simulations in close proximity to the physical point, effectively mitigating issues related to finite volume effects and contamination from excited states. \n\nIn our analysis, we determine the LECs concurrently with the decay constant \\( f_K \\) and the kaon B-parameter \\( B_K \\). To achieve this, we apply the methodology detailed in Phys. Rev. D 87, 074010, which enables us to extract both observables directly from the correlation functions obtained from our lattice simulations. Our final estimates yield \\( f_K = 156(3)(5) \\) MeV and \\( B_K = 1.55(4)(6) \\), where the first set of uncertainties represents statistical errors and the second set accounts for systematic errors. \n\nThese results are consistent with previous findings derived from alternative methods, including continuum extrapolations based on Chiral Perturbation Theory (ChPT) and phenomenological analyses. Our work contributes to the understanding of low-energy QCD dynamics and provides a robust framework for future investigations in the field.",
        "ori-fast-z-score": -0.3464101615137754,
        "water-fast-z-score": 3.9000674757995495,
        "rewrite-fast-z-score": -0.10482848367219183
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the nature of the phase transition in the three-dimensional random field Ising model .\nAbstract:\nWe study the critical behavior of the 3D RFIM with Gaussian distributed disorder by means of Monte Carlo simulations and finite-size scaling analysis. We find that the system undergoes a continuous phase transition at zero temperature, which is characterized by an infinite correlation length but no divergent susceptibility. The results are compared to those obtained for the pure 3D Ising model as well as other models with quenched disorder. In particular we show how our findings can be understood within the framework of the droplet picture. \nPACS numbers: 64.60.Cn, 64.60.J-, 64.60.Nz \nI. INTRODUCTORY REMARkS\nThe Random Field Ising Model (RFIM) has been introduced more than 50 years ago  1  . It describes a ferromagnetic material where each spin interacts only with its nearest neighbors via exchange interactions J ij , while it also feels an external magnetic field h i randomly oriented on different sites  2  .\nIn recent years there have been many studies devoted to this problem both experimentally  3  -  6  and theoretically  7  -  12  . This interest was triggered mainly by the fact that the RFIM shares some features with real systems such as diluted antiferromagnets or spin-glasses  13  -  15  . For example, the presence of quenched disorder leads to frustration effects  16  similar to those observed in spin-glass materials  17  . Moreover, the RFIM displays a rich variety of phases depending on the strength of the applied magnetic field  18  . At low fields one finds a paramagnetic phase, whereas above a certain threshold value H c = O(J), the spins align along the direction of the local magnetic field leading to a ferromagnetic state  19  . Finally, if the magnitude of the external field exceeds another threshold value H t > H c , the magnetization becomes discontinuous  20  . These three regimes are separated by two second-order transitions occurring at T c1 < 0 and T c2 > 0  21  . However, despite these analogies between the RFIM and experimental systems  22  , the exact nature of the phase diagram remains controversial  23  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the nature of the phase shift in the three - dimensional random field Ising model . Abstract : We research the important dynamics of the 3D RFIM with Gaussian distributed disorder by means of Monte Carlo simulations and finite - length scaling processing .We see that the system undergoes a continuous phase shift at zero temperature , which is characterized by an endless correlation length but no divergent susceptibility . The results are compared to those achieved for the pure 3D Ising model as well as other models with quenched instability .In particular we give how our findings can be understood within the framework of the droplet picture . PACS numbers : 64 . 60 . Cn , 64 . 60 . J - , 64 . 60 . Nz I .INTRODUCTORY REMARkS The Random Field Ising Model ( RFIM ) has been proposed more than 50 centuries earlier 1 . It describes a ferromagnetic material where each spin interacts only with its closest neighbors via transfer interactions J ij , while it also feels an external magnetic force h i randomly oriented on various places 2 .In recent years there have been many research devoted to this question both experimentally 3 - 6 and theoretically 7 - 12 . This concern was sparked mainly by the fact that the RFIM shares some features with real systems such as diluted antiferromagnets or spin - glasses 13 - 15 .For instance , the presence of quenched instability leads to frustration effects 16 comparable to those observed in spinning - glass materials 17 . Moreover , the RFIM displays a rich range of phases depending on the strength of the applied magnetic force 18 .At small fields one gets a paramagnetic phase , whereas above a certain threshold number H c = O ( J ) , the spins align along the direction of the local magnetic field leading to a ferromagnetic state 19 . Finally , if the magnitude of the external field exceeds another threshold quantity H t > H c , the magnetization makes discontinuous 20 .These three regimes are separated by two second - order transitions happening at T c1 < 0 and T c2 > 0 21 . However , despite these analogies between the RFIM and theoretical systems 22 , the exact nature of the phase diagram remains disputed 23 .",
        "rewrite_text": "**Title:** On the Nature of the Phase Shift in the Three-Dimensional Random Field Ising Model\n\n**Abstract:** This study investigates the dynamic behavior of the three-dimensional Random Field Ising Model (3D RFIM) characterized by Gaussian-distributed disorder, utilizing Monte Carlo simulations and finite-length scaling techniques. Our findings reveal that the system experiences a continuous phase transition at absolute zero temperature, marked by an infinite correlation length without a corresponding divergence in susceptibility. We compare these results with those obtained from the pure three-dimensional Ising model and other models exhibiting quenched disorder. Notably, we interpret our results through the lens of the droplet theory, which provides a framework for understanding the observed phenomena. \n\nThe Random Field Ising Model, introduced over five decades ago, serves as a theoretical representation of ferromagnetic materials where each spin interacts with its nearest neighbors through exchange interactions while being subjected to a randomly oriented external magnetic field. Recent investigations, both experimental and theoretical, have intensified due to the RFIM's relevance to real-world systems, including diluted antiferromagnets and spin glasses. The presence of quenched disorder in the RFIM leads to frustration effects akin to those observed in spin-glass materials, contributing to its complex phase behavior. \n\nThe model exhibits a diverse array of phases contingent on the strength of the applied magnetic field. At low field strengths, the system is in a paramagnetic phase; however, as the field surpasses a critical threshold (H_c ≈ O(J)), the spins begin to align with the local magnetic field, resulting in a ferromagnetic phase. Furthermore, when the external field exceeds another critical value (H_t > H_c), the magnetization transitions discontinuously. These distinct regimes are delineated by two second-order phase transitions occurring at temperatures T_c1 < 0 and T_c2 > 0. Despite the parallels drawn between the RFIM and theoretical models, the precise nature of its phase diagram remains a topic of ongoing debate within the scientific community. \n\n**PACS numbers:** 64.60.Cn, 64.60.J-, 64.60.Nz",
        "ori-fast-z-score": -0.5,
        "water-fast-z-score": 6.4390634770545985,
        "rewrite-fast-z-score": -0.9863939238321437
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Forced accretion in stochastically fed AGN and quasars .\nAbstract:\nWe present the results of cosmological simulations that follow the growth of supermassive black holes (SMBHs) by stochastic gas inflow, including radiative feedback effects on their surroundings. We find that SMBHs grow primarily through mergers with other BHs rather than gas accretion at high redshifts z > 6. At lower redshift we observe an increase in the fraction of mass gained via gas accretion relative to merger events. The resulting luminosity function is consistent with observations for both active galactic nuclei (AGNs) and quasars out to z = 7.5. Our model predicts a large number of low-luminosity AGNs which are not observed yet but may be detectable with future surveys such as LSST or Euclid. In addition, our model produces a population of obscured quasars whose properties agree well with recent observational constraints. Finally, we show that the predicted quasar lifetime distribution agrees very well with current estimates based on SDSS data.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Forced accretion in stochastically driven AGN and quasars . Abstract : We report the results of cosmological simulations that track the development of supermassive black holes ( SMBHs ) by stochastic gas inflow , particularly radiative feedback effects on their environment .We see that SMBHs grow primarily through mergers with other BHs rather than gas accretion at high redshifts z > 6 . At lower redshift we study an increase in the fraction of mass gained via gas accretion compared to merger events .The resulting luminosity function is compatible with observations for both active galactic nuclei ( AGNs ) and quasars out to z = 7 . 5 . Our model predicts a large number of low - luminosity AGNs which are not observed yet but might be detectable with current surveys such as LSST or Euclid .In addition , our model generates a population of distorted quasars whose characteristics comply better with recent observational restrictions . Finally , we prove that the expected quasar lifetime distribution agrees very best with current estimates based on SDSS information .",
        "rewrite_text": "We present findings from our cosmological simulations that investigate the evolution of supermassive black holes (SMBHs) influenced by stochastic gas inflow and the associated radiative feedback on their surroundings. Our analysis reveals that at high redshifts (z > 6), SMBHs predominantly grow through mergers with other black holes rather than through gas accretion. As we examine lower redshifts, we observe a notable increase in the proportion of mass acquired via gas accretion in comparison to merger events. The luminosity function derived from our simulations aligns well with observational data for both active galactic nuclei (AGNs) and quasars up to redshift z = 7.5. Importantly, our model forecasts a significant population of low-luminosity AGNs that have yet to be detected, which may become observable with ongoing surveys such as the Large Synoptic Survey Telescope (LSST) and the Euclid mission. Furthermore, our simulations yield a cohort of distorted quasars whose properties are more consistent with recent observational constraints. Lastly, we demonstrate that the predicted distribution of quasar lifetimes closely matches current estimates derived from Sloan Digital Sky Survey (SDSS) data, reinforcing the validity of our model. This work enhances our understanding of the mechanisms driving SMBH growth and the implications for the evolution of the universe's structure.",
        "ori-fast-z-score": 0.47140452079103173,
        "water-fast-z-score": 5.500933918218137,
        "rewrite-fast-z-score": 0.7977240352174656
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Does confining the hard-sphere fluid between hard walls change its average properties? .\nAbstract:\nWe study the effect of confinement on the structure and dynamics of a simple model system, namely an ensemble of N identical particles interacting via repulsive pair potentials confined in a volume V by two parallel impenetrable walls at distance L apart.  We use Monte Carlo simulations to calculate the density profiles for different values of the wall separation L and particle number N . The results show that the density profile is not affected significantly when increasing the wall separation beyond a certain value which depends on both the temperature T and the particle number N .  In addition we find that the self-diffusion coefficient D decreases with decreasing wall separation but increases again if one further reduces the wall separation below some critical value depending on the temperature T .\nThe observed behavior can be explained within the framework of mode-coupling theory (MCT) using a generalized version of MCT developed recently by us  Physica A, vol. 315, no. 1, pp. 39-48, (2003), Physica A, vol. 320, no. 3, pp. 633-646, (2004) .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Does confining the hard - sphere fluid between hard walls change its average characteristics ? .Abstract : We explore the impact of confinement on the composition and dynamics of a simple model structure , namely an ensemble of N identical particles interacting via repulsive pair potentials restricted in a volume V by two connected impenetrable walls at distance L apart . We use Monte Carlo simulations to estimate the density profiles for different values of the wall separation L and electron number N .The results show that the density profile is not affected greatly when increasing the wall separation beyond a certain value which depends on both the temperature T and the particle number N . In addition we find that the self - diffusion coefficient D reduces with decreasing wall separation but grows again if one further decreases the wall separation below some significant value depending on the temperature T .The observed behavior can be described within the framework of mode - correlation theory ( MCT ) using a generalized version of MCT created recently by us Physica A , vol . 315 , no .1 , pp . 39 - 48 , ( 2003 ) , Physica A , vol .320 , no . 3 , pp .633-646, (2004) .",
        "rewrite_text": "Title: Does Confining the Hard-Sphere Fluid Between Hard Walls Alter Its Average Characteristics?\n\nAbstract: This study investigates the effects of confinement on the structural and dynamic properties of a hard-sphere fluid model, consisting of N identical particles that interact through repulsive pair potentials. These particles are confined within a volume V by two rigid, impenetrable walls positioned at a distance L apart. Utilizing Monte Carlo simulations, we analyze the density profiles of the particle ensemble for varying wall separations L and particle numbers N. Our findings indicate that the density profile remains relatively stable when the wall separation is increased beyond a certain threshold, which is influenced by both the temperature T and the number of particles N. Furthermore, we observe that the self-diffusion coefficient D decreases as the wall separation diminishes, but intriguingly, it begins to increase again when the wall separation is reduced below a critical value that is also temperature-dependent. This complex behavior can be effectively interpreted through the lens of mode-coupling theory (MCT), employing a generalized version of MCT that we previously developed (as detailed in Physica A, vol. 315, no. 1, pp. 39-48, 2003; and Physica A, vol. 320, no. 3, pp. 633-646, 2004). Our results contribute to a deeper understanding of how confinement influences the average characteristics of hard-sphere fluids, with implications for various applications in materials science and condensed matter physics.",
        "ori-fast-z-score": 0.5184758473652127,
        "water-fast-z-score": 4.950821982042208,
        "rewrite-fast-z-score": 2.970442628930023
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Shock-triggered formation of magnetically-dominated clouds .\nAbstract:\nWe present the results of three-dimensional MHD simulations that show how magnetic fields can be amplified by shocks in molecular clouds, and lead to the formation of dense filaments with high mass-to-flux ratios. The initial conditions are based on observations of nearby star-forming regions. We find that shock compression leads to an increase in density and temperature at the post-shock region. This causes the gas pressure gradient across the shock front to decrease rapidly as time progresses. As a result, the field lines become more tangled due to turbulent motions induced by the shock wave. In addition, we observe that the magnetic energy is transferred into kinetic energy through Alfvén waves generated behind the shock fronts. Finally, we demonstrate that these processes cause the magnetic flux-to-mass ratio to increase significantly within the shocked region. \n \n Keywords: Magnetic fields, Shocks, Star formation, Turbulence \n \n 1. Introduction \n \n Molecular clouds play important roles in star formation (SF) because they provide the material for stars to form out of. However, it remains unclear what physical mechanisms drive SF inside molecular clouds. One possible mechanism involves supersonic turbulence driven by supernovae explosions or stellar winds (Mac Low & Klessen 2004). Another possibility is that large-scale gravitational collapse may trigger localised fragmentation leading to the formation of dense cores which then evolve into protostars (Larson 1978; Bonnell et al. 1997) . It has been suggested that both scenarios could operate simultaneously during different stages of evolution of molecular clouds (Krumholz 2014). \n \n Recent observational studies have shown that many young massive stars are associated with filamentary structures observed in infrared dust emission maps (André et al. 2010; Peretto et al. 2013 ). These filaments often appear to be aligned along magnetic field directions inferred from polarisation measurements (Chapman et al. 2011) , suggesting that magnetic fields might play an important role in regulating the dynamics of such systems. Indeed, theoretical models suggest that magnetic fields can affect the stability properties of self-gravitating clouds against global collapse (Mouschovias 1976; Tomis",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Shock - triggered formation of magnetically - dominated clouds . Abstract : We report the results of three - dimensional MHD simulations that demonstrate how magnetic fields can be amplified by shocks in molecular clouds , and lead to the formation of dense filaments with high mass - to - flux proportions .The initial conditions are based on observations of nearby star - creating areas . We see that shock compression result to an increase in density and heat at the post - jolt zone .This forces the gas pressure slope across the shock front to reduce rapidly as time progresses . As a result , the field lines become more twisted due to chaotic motions resulting by the shock wave .In addition , we determine that the magnetic energy is transferred into kinetic power through Alfvén currents produced behind the shock fronts . Finally , we prove that these mechanisms create the magnetic flux - to - mass ratio to expand significantly within the shocked areas .Keywords : Magnetic fields , Shocks , Star formation , Turbulence 1 . Introduction Molecular clouds play crucial roles in star formation ( SF ) because they create the material for stars to form out of .However , it remains unsure what physical mechanisms drive SF inside biological clouds . One potential mechanism involves supersonic turbulence driven by supernovae explosions or stellar winds ( Mac Low & Klessen 2004 ) .Another possibility is that high - scale gravitational failure may generate localised fragmentation leading to the formation of dense cores which then evolve into protostars ( Larson 1978 ; Bonnell et al . 1997 ) .It has been proposed that both scenarios could operate simultaneously during various phases of evolved of molecular clouds ( Krumholz 2014 ) . Recent observational investigations have shown that several young massive galaxies are identified with filamentary structures discovered in infrared dust absorption maps ( André et al .2010 ; Peretto et al . 2013 ) .These filaments often seem to be aligned along magnetic field paths inferred from polarisation observations ( Chapman et al . 2011 ) , showing that magnetic fields might play an important role in controlling the dynamics of such systems .Indeed , theoretical theories indicate that magnetic fields can affect the stability properties of self - gravitating clouds against global failure ( Mouschovias 1976 ; Tomis",
        "rewrite_text": "**Title: Shock-Triggered Formation of Magnetically Dominated Clouds**\n\n**Abstract:** This study presents the findings from three-dimensional magnetohydrodynamic (MHD) simulations that explore the amplification of magnetic fields by shock waves within molecular clouds, leading to the development of dense filaments characterized by high mass-to-flux ratios. The initial conditions for our simulations are informed by observational data from nearby star-forming regions. Our results indicate that shock compression significantly increases both the density and temperature in the post-shock zone. This increase in thermal energy causes a rapid decline in the gas pressure gradient across the shock front over time. Consequently, the magnetic field lines become increasingly twisted due to the chaotic motions induced by the shock wave. Furthermore, we observe that magnetic energy is converted into kinetic energy via Alfvén currents generated behind the shock fronts. These processes collectively contribute to a substantial increase in the magnetic flux-to-mass ratio within the regions affected by the shock. \n\n**Keywords:** Magnetic fields, Shocks, Star formation, Turbulence\n\n**1. Introduction:** Molecular clouds are fundamental to the star formation process, providing the necessary material for star creation. However, the physical mechanisms that drive star formation within these clouds remain poorly understood. One proposed mechanism is the influence of supersonic turbulence, which may be driven by supernova explosions or stellar winds (Mac Low & Klessen, 2004). Alternatively, large-scale gravitational instabilities could lead to localized fragmentation, resulting in the formation of dense cores that evolve into protostars (Larson, 1978; Bonnell et al., 1997). It is also suggested that both mechanisms may operate concurrently during different evolutionary phases of molecular clouds (Krumholz, 2014). Recent observational studies have identified filamentary structures in several young massive galaxies through infrared dust absorption maps (André et al., 2010; Peretto et al., 2013). These filaments often align with magnetic field lines inferred from polarization observations (Chapman et al., 2011), indicating that magnetic fields may significantly influence the dynamics of these systems. Theoretical frameworks suggest that magnetic fields can alter the stability of self-gravitating clouds against global collapse (Mouschovias, 1976; Tomisaka, 2002).",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 7.772297096131725,
        "rewrite-fast-z-score": 1.7988760535900674
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Near-Infrared Coronagraphic Observations of the T Tauri Binary System UY Aur .\nAbstract:\nWe report near-infrared coronagraphic observations of the young binary system UY Aurigae (=V773 Tau) obtained with the Subaru Telescope in December 2005 and January 2006, using the newly installed HiCIAO instrument equipped with an occulting mask. The data were reduced by subtracting dark frames and flat fields to remove detector biases and pixel-to-pixel variations respectively. We then applied aperture photometry on each frame after masking out bad pixels and cosmic rays. Finally we averaged all the individual frames together for each filter bandpass. Our results show that there is no significant difference between our two epochs of observation within the uncertainties. In addition, we find that the flux ratio between the primary star and its companion varies significantly depending upon which filter was used during the observations. This suggests that the spectral energy distribution of UY Aur may be changing over time as it evolves towards the main sequence. \n \n Keywords: Young stars",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Near - Infrared Coronagraphic Observations of the T Tauri Binary System UY Aur . Abstract : We report near - infrared coronagraphic observations of the young binary system UY Aurigae ( = V773 Tau ) obtained with the Subaru Telescope in December 2005 and January 2006 , using the newly installed HiCIAO instrument equipped with an occulting mask .The data were reduced by subtracting dark frames and low areas to remove sensor biases and pixel - to - pixel differences respectively . We then implemented lens photometry on each window after masking out bad pixels and cosmic rays .Finally we averaged all the different images together for each filter bandpass . Our results show that there is no major variation between our two epochs of study within the uncertainties .In addition , we find that the flux ratio between the primary star and its companion vary significantly depending upon which filter was used during the surveys . This implies that the spectral power distribution of UY Aur may be changing over time as it evolves towards the main sequence .Keywords: Young stars",
        "rewrite_text": "Title: Near-Infrared Coronagraphic Observations of the T Tauri Binary System UY Aur\n\nAbstract: In this study, we present near-infrared coronagraphic observations of the young binary system UY Aurigae (V773 Tau), conducted using the Subaru Telescope during December 2005 and January 2006. These observations were made possible by the newly installed HiCIAO instrument, which features an occulting mask designed to enhance the visibility of faint companions in close proximity to bright stars. The data processing involved a series of steps to ensure accuracy and reliability; we began by subtracting dark frames to eliminate sensor noise and correcting for pixel-to-pixel variations. Subsequently, we applied lens photometry to each image segment, carefully masking out any bad pixels and cosmic ray interference. To enhance the signal-to-noise ratio, we averaged the resulting images across different filter bandpasses.\n\nOur findings indicate that there are no significant variations between the two observational epochs when considering the associated uncertainties. However, we observed notable fluctuations in the flux ratio between the primary star and its companion, which were dependent on the specific filter utilized during the observations. This variability suggests that the spectral power distribution of UY Aur is not static and may be undergoing changes as the system evolves toward the main sequence. These results contribute to our understanding of the dynamics and characteristics of young stellar systems, particularly in the context of T Tauri stars, and highlight the importance of multi-filter observations in studying the evolutionary processes of binary star systems. \n\nKeywords: Young stars, UY Aurigae, coronagraphy, near-infrared observations, T Tauri stars.",
        "ori-fast-z-score": 0.7276068751089989,
        "water-fast-z-score": 4.780914437337574,
        "rewrite-fast-z-score": 1.7717591356565963
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Low energy cut-offs and hard X-ray spectra in high-z radio-loud quasars: the Suzaku view of RBS315 .\nAbstract:\nWe report on our analysis of the Suzaku observation of the z = 1.55 quasar, RBS 315 (RA=00h45m53.6s; DEC=-36d19 59.6 ). The source is detected with an average 2-10 keV flux of 4 x 10^-13 erg cm-2 s-1 corresponding to a luminosity of 3 x 10^44 erg s-1 at this redshift. We find that the spectrum can be well fitted by a power law model modified by Galactic absorption plus reflection component using pexrav model in XSPEC. This gives photon index Γ=1.9 +0.2 -0.1 , reflection fraction f=0.7 +1.0 -1.3 . The observed 0.5-7 keV band luminosity is found to be 5x10^43 erg/sec which corresponds to Eddington ratio L/L edd =0.01-0.03 assuming black hole mass M BH ~10 9 M sun .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Low energy cut - offs and hard X - ray spectra in high - z radio - loud quasars : the Suzaku view of RBS315 . Abstract : We report on our analysis of the Suzaku observation of the z = 1 . 55 quasar , RBS 315 ( RA = 00h45m53 . 6s ; DEC = - 36d19 59 . 6 ) .The source is detected with an mean 2 - 10 keV flux of 4 x 10 ^ - 13 erg centimetres - 2 s - 1 resulting to a luminosity of 3 x 10 ^ 44 erg s - 1 at this redshift . We see that the spectrum can be well fitted by a power law formula derived by Galactic absorption plus reflection factor using pexrav method in XSPEC .This gives photon index Γ = 1 . 9 + 0 . 2 - 0 . 1 , reflection fraction f = 0 . 7 + 1 . 0 - 1 . 3 . The observed 0 . 5 - 7 keV band luminosity is found to be 5x10 ^ 43 erg / sec which corresponds to Eddington ratio L / L edd = 0 . 01 - 0 . 03 assuming black hole mass M BH ~ 10 9 M sun .",
        "rewrite_text": "We present our findings from the analysis of the Suzaku observation of the quasar RBS 315, located at a redshift of z = 1.55 (RA = 00h45m53.6s; DEC = -36d19m59.6s). The quasar exhibits a mean flux in the 2-10 keV range of 4 x 10^-13 erg cm^-2 s^-1, which translates to an impressive luminosity of 3 x 10^44 erg s^-1 at this redshift. Our spectral analysis indicates that the data can be accurately modeled using a power law, incorporating Galactic absorption and a reflection component, as implemented through the pexrav method in XSPEC. The resulting fit yields a photon index of Γ = 1.9 +0.2 -0.1 and a reflection fraction of f = 0.7 +1.0 -1.3. Furthermore, we calculated the luminosity in the 0.5-7 keV band to be 5 x 10^43 erg/s, which corresponds to an Eddington ratio of L/L_edd = 0.01 - 0.03, assuming a black hole mass of approximately 10^9 M☉. These results provide valuable insights into the characteristics of high-redshift, radio-loud quasars and contribute to our understanding of the relationship between black hole mass, accretion processes, and the emitted X-ray spectra in such distant cosmic objects. The implications of these findings extend to the broader context of quasar evolution and the mechanisms driving their energetic emissions.",
        "ori-fast-z-score": -0.39735970711951313,
        "water-fast-z-score": 1.5756771943166705,
        "rewrite-fast-z-score": -1.6059101370939322
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Inductively Coupled Circuits with Spin Wave Bus for Information Processing .\nAbstract:\nWe propose an information processing system based on spin wave bus and inductive coupling between circuits. The proposed circuit is composed of two types of elements, the first one being a conventional semiconductor device which can be used as a logic gate or memory cell, while the second element consists in a magnetic insulator layer sandwiched by two ferromagnetic layers that are connected to each other via tunneling magnetoresistance (TMR) effect. We show how this structure allows us to perform both logic operations and data transmission using spin waves. Finally we discuss some possible applications of our proposal such as quantum computing architectures and neuromorphic systems. This article is available from: http://arxiv.org/abs/1601.00571. Inductively coupled circuits have been widely studied recently because they offer several advantages over their classical counterparts  1  . For example, these devices allow high speed operation  2  , low power consumption  3  , and reduced crosstalk  4  .\nIn addition, it has been shown theoretically  5  and experimentally  6  that inductive coupling could also lead to new functionalities like nonlocal gates  7, 8  and entanglement generation  9  . However, most of the studies performed so far were focused only on electronic components  10  . Here, we consider instead spin-wave-based circuits  11  where information is coded into propagating spin-waves  12  . These spin waves can be generated electrically  13  or optically  14  and propagate through different media  15  including semiconductors  16  , metals  17  , and insulators  18  . They can even travel across vacuum  19  . Therefore, spin waves provide a promising alternative to electrons  20  since they do not suffer from Coulomb interactions  21  nor scattering  22  . Moreover, spin waves can carry much more information than electrons  23  due to their higher density  24  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Inductively Coupled Circuits with Spin Wave Bus for Information Processing . Abstract : We suggest an information processing network based on spin wave bus and inductive coupling between circuits .The proposed circuit is composed of two forms of elements , the first one being a traditional semiconductor device which can be used as a logic gate or memory cell , while the second element consists in a magnetic insulator layer sandwiched by two ferromagnetic layers that are connected to each other via tunneling magnetoresistance ( TMR ) effect . We see how this formation allows us to conduct both logic operations and information transmission using spinning waves .Finally we talk some possible users of our proposal such as quantum computing architectures and neuromorphic networks . This page is accessible from : www : / / arxiv . org / abs / 1601 . 00571 .Inductively coupled devices have been widely explored lately because they give numerous benefits over their classical counterparts 1 . For instance , these systems allow large speed operation 2 , low power consumption 3 , and reduced crosstalk 4 .In addition , it has been shown theoretically 5 and experimentally 6 that inductive coupling could also lead to novel functionalities like nonlocal gates 7 , 8 and entanglement generation 9 . However , most of the experiments conducted so far were focused only on electronic systems 10 .Here , we define instead spin - wave - based circuits 11 where information is coded into propagating spin - waves 12 . These spin currents can be induced electrically 13 or optically 14 and propagate through different media 15 including semiconductors 16 , metals 17 , and insulators 18 .They can even travel across vacuum 19 . Therefore , spin beams provide a promising alternative to ions 20 since they do not suffer from Coulomb bonding 21 nor scattering 22 .Moreover , spin beams can carry far more information than electrons 23 thanks to their higher density 24 .",
        "rewrite_text": "**Title:** Inductively Coupled Circuits with Spin Wave Bus for Information Processing\n\n**Abstract:** In this article, we propose an innovative information processing network that leverages a spin wave bus in conjunction with inductively coupled circuits. Our design integrates two distinct types of components: the first is a conventional semiconductor device, which functions as either a logic gate or a memory cell, while the second component consists of a magnetic insulator layer situated between two ferromagnetic layers, interconnected through the tunneling magnetoresistance (TMR) effect. This unique configuration enables the execution of logic operations and the transmission of information via propagating spin waves. We also explore potential applications of our proposed system, particularly in the realms of quantum computing architectures and neuromorphic networks.\n\nRecent advancements in inductively coupled devices have garnered significant attention due to their numerous advantages over traditional electronic systems. These benefits include enhanced operational speeds, reduced power consumption, and minimized crosstalk. Theoretical and experimental studies have demonstrated that inductive coupling can facilitate novel functionalities, such as nonlocal gates and the generation of entanglement. However, most existing research has predominantly concentrated on electronic systems. In contrast, our work focuses on spin-wave-based circuits, where information is encoded in propagating spin waves. These spin currents can be generated through electrical or optical means and can traverse various media, including semiconductors, metals, and insulators, and even propagate through a vacuum.\n\nThe use of spin beams presents a compelling alternative to traditional ion-based systems, as they are not hindered by Coulomb interactions or scattering effects. Furthermore, spin beams possess the capability to convey significantly more information than electrons due to their higher density. This research opens new avenues for the development of advanced information processing technologies, highlighting the potential of spin wave circuits in future computing paradigms. For further details, please refer to the full article available at www.arxiv.org/abs/1601.00571.",
        "ori-fast-z-score": -0.26013299085723596,
        "water-fast-z-score": 7.091168559049116,
        "rewrite-fast-z-score": 1.6759824573820066
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Einstein and early 20th Century avant-garde art: points of contact? .\nAbstract:\nThe relationship between Einstein s work in physics, his personal life, and the cultural milieu of the time is examined through an analysis of his correspondence with Max Born (1882-1970). The letters reveal that Einstein was interested not only in science but also in literature, music, theatre, and other forms of culture. In particular, they show how he came to appreciate modernist artists such as Wassily Wassilyevich Kandinsky, Paul Klee, and Pablo Picasso. They also provide insight into Einstein s attitude towards society at large during this period. This article examines the relationship between Einstein s work on relativity theory, his private life, and the cultural context of the times by analyzing his correspondence with Max Born . It shows that Einstein was interested not just in science but also in various forms of culture including literature, music, theater, and painting. Particularly important are his letters about modernist artists like Wassily Wassilyevicth Kandinsky , Paul Klee , and Pablo Picasso . These documents shed light on Einstein  s attitude toward society at large during these years .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Einstein and early 20th Century avant - garde art : places of touch ? .Abstract : The relationship between Einstein s study in science , his personal life , and the cultural milieu of the period is investigated through an assessment of his letters with Max Born ( 1882 - 1970 ) . The letters prove that Einstein was fascinated not only in science but also in literature , music , theatre , and other types of literature .In particular , they show how he came to admire modernist artists such as Wassily Wassilyevich Kandinsky , Paul Klee , and Pablo Picasso . They especially offer insight into Einstein s approach towards society at large during this era .This page discusses the relationship between Einstein s study on relativity hypothesis , his private life , and the cultural context of the days by analyzing his letters with Max Born . It demonstrates that Einstein was fascinated not just in science but also in different kinds of literature namely writers , music , theater , and painting .Particularly interesting are his letters about modernist artists like Wassily Wassilyevicth Kandinsky , Paul Klee , and Pablo Picasso . These documents cast light on Einstein s feelings toward people at large during these days .",
        "rewrite_text": "Title: Einstein and Early 20th Century Avant-Garde Art: Points of Intersection\n\nAbstract: This article explores the intricate relationship between Albert Einstein's scientific pursuits, his personal experiences, and the vibrant cultural landscape of the early 20th century, as revealed through his correspondence with physicist Max Born (1882-1970). The analysis of these letters uncovers Einstein's profound interest not only in the realm of science but also in various forms of artistic expression, including literature, music, theater, and visual arts. Notably, the correspondence highlights Einstein's admiration for modernist artists such as Wassily Kandinsky, Paul Klee, and Pablo Picasso, illustrating how these figures influenced his worldview and creative thought. The letters serve as a window into Einstein's perspective on society during this transformative period, showcasing his engagement with contemporary cultural movements and his reflections on the role of art in human experience. By examining the interplay between Einstein's theories of relativity and his artistic inclinations, this study sheds light on the broader implications of his work within the context of the cultural zeitgeist of his time. The findings suggest that Einstein's intellectual curiosity extended beyond the confines of physics, revealing a multifaceted individual deeply engaged with the artistic currents that shaped his era. Through this exploration, the article contributes to a deeper understanding of how scientific and artistic realms can intersect, offering insights into the ways in which Einstein's life and work were informed by the avant-garde movements of his day.",
        "ori-fast-z-score": -2.618614682831909,
        "water-fast-z-score": 5.09786575873842,
        "rewrite-fast-z-score": 0.5883484054145521
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The tensor part of the Skyrme energy density functional. I. Spherical nuclei .\nAbstract:\nWe present an improved version of our previous calculation for the nuclear matter properties and the single-particle energies in spherical nuclei based on the covariant density functional theory with the tensor terms included. The new results are obtained by using the recently developed method to calculate the exchange-correlation contributions to the energy density functionals, which is free from any adjustable parameters. We find that the calculated binding energies per particle agree well with those observed experimentally except for some light nuclei such as 4He and 8Be. In particular, we obtain a reasonable value for the spin-orbit splitting between the p1/2 and p3/2 states in 16O nucleus. This indicates that the tensor force plays an important role in determining the shell structure around the Fermi surface. It should be noted here that this result has been achieved without introducing any additional parameter into the original formalisms proposed previously. \n \n Keywords: Tensor force, Energy density functional",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The tensor part of the Skyrme energy density structure . I . Spherical nuclei .Abstract : We present an updated form of our previous measurement for the atomic matter properties and the single - nucleus energies in spherical nuclei using on the covariant density functional theory with the tensor terms included . The revised conclusions are derived by using the recently advanced method to estimate the transfer - correlation contributions to the power density functionals , which is free from any adjustable parameters .We see that the derived binding values per particle comply better with those observed experimentally except for some light nuclei such as 4He and 8Be . In particular , we obtain a suitable value for the spin - orbit dividing between the p1 / 2 and p3 / 2 states in 16O nucleus .This implies that the tensor force plays an important role in determining the shell structure around the Fermi surface . It should be mentioned here that this consequence has been achieved without removing any additional parameter into the previous formalisms proposed earlier .Keywords : Tensor force , Energy density functional",
        "rewrite_text": "Title: The Tensor Component of the Skyrme Energy Density Structure: I. Spherical Nuclei\n\nAbstract: In this study, we present an enhanced version of our earlier analysis regarding the properties of atomic matter and the energies of single nuclei in spherical configurations, utilizing covariant density functional theory (CDFT) with the incorporation of tensor terms. Our revised findings are based on a novel approach that accurately estimates the contributions of transfer correlations to the power density functionals, notably without the introduction of any adjustable parameters. The results indicate that the calculated binding energies per particle align more closely with experimental observations, with the exception of certain light nuclei, specifically helium-4 (4He) and beryllium-8 (8Be). Notably, we have determined an appropriate value for the spin-orbit splitting between the p1/2 and p3/2 states in the oxygen-16 (16O) nucleus. This finding underscores the significant influence of the tensor force in shaping the shell structure near the Fermi surface. Importantly, these conclusions have been reached without the need to introduce any additional parameters into the previously established frameworks. Our work highlights the critical role of tensor interactions in nuclear structure and provides a more accurate understanding of the energy density functional in the context of spherical nuclei.\n\nKeywords: Tensor force, Energy density functional",
        "ori-fast-z-score": -1.0660035817780522,
        "water-fast-z-score": 5.193989612031165,
        "rewrite-fast-z-score": -0.4082482904638631
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Classical approach to the graph isomorphism problem using quantum walks .\nAbstract:\nWe present an algorithm for solving the Graph Isomorphism Problem (GIP) based on Quantum Walks and Grover s search algorithm. The proposed method is inspired by the classical algorithms that use random walks, but it uses Grover s operator instead of the Hadamard matrix in order to speed up the process. We show how this new technique can be used to solve GIP with high probability when the number of vertices in both graphs are equal or differ at most one unit. Finally we compare our results against other state-of-the-art methods. In recent years there has been growing interest in developing efficient solutions to problems related to computational complexity theory such as the Graph Isomorphism Problem(GIP). This problem consists of determining whether two given graphs are isomorphic or not; i.e., if they have the same structure regardless of their labels. \n \n Classical approaches to solve GIP usually rely on Random Walks techniques combined with some heuristics. However these methods require exponential time in the worst case scenario. On the other hand, Quantum Algorithms provide polynomial-time solutions to many NP-complete problems including GIP. These algorithms exploit the superposition principle which allows them to explore all possible states simultaneously. For example, Shor s Algorithm solves integer factorization in polynomial time while Grover s Search finds any item within a database in quadratic time.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Classical approach to the graph isomorphism question involving quantum walks . Abstract : We present an algorithm for solving the Graph Isomorphism Problem ( GIP ) based on Quantum Walks and Grover s search algorithm .The proposed approach is influenced by the classical techniques that use random tours , but it utilizes Grover s operator rather of the Hadamard vector in order to faster up the process . We see how this new technique can be used to solve GIP with high probability when the number of vertices in both graphs are equal or differ at most one unit .Finally we compare our findings against other state - of - the - art methods . In past decades there has been growing interest in building successful solutions to problems related to computational complexity analysis such as the Graph Isomorphism Problem ( GIP ) .This problem consists of determining whether two given graphs are isomorphic or not ; i . e . , if they have the same structure regardless of their labels . Classical approaches to solve GIP usually relies on Random Walks techniques combined with some heuristics .However these algorithms involve exponential time in the worst case situations . On the other hand , Quantum Algorithms provide polynomial - time solutions to many NP - perfect issues including GIP .These methods incorporate the superposition concept which allows them to examine all possible states simultaneously . For instance , Shor s Algorithm solves integer factorization in polynomial time while Grover s Search finds any element within a computer in quadratic time .",
        "rewrite_text": "We introduce a novel algorithm aimed at addressing the Graph Isomorphism Problem (GIP) by leveraging Quantum Walks in conjunction with Grover's search algorithm. This innovative approach draws inspiration from classical methods that employ random tours, yet distinguishes itself by utilizing Grover's operator instead of the traditional Hadamard vector, thereby enhancing the efficiency of the process. Our findings demonstrate that this technique can effectively solve the GIP with a high probability, particularly when the number of vertices in the two graphs is either equal or differs by no more than one. \n\nThe Graph Isomorphism Problem has garnered significant attention over recent decades due to its implications in computational complexity theory. The challenge lies in determining whether two graphs are isomorphic, meaning they share the same structural properties despite potentially differing labels. Traditional methods for tackling GIP often rely on Random Walk techniques supplemented by various heuristics. However, these classical algorithms can exhibit exponential time complexity in the worst-case scenarios, which limits their practicality for larger graphs.\n\nIn contrast, Quantum Algorithms offer polynomial-time solutions to numerous NP-complete problems, including GIP. These quantum methods harness the principle of superposition, enabling them to explore multiple potential states concurrently. For example, Shor's Algorithm efficiently addresses integer factorization in polynomial time, while Grover's Search algorithm can locate any specific element within a dataset in quadratic time. By comparing our quantum-based approach to existing state-of-the-art techniques, we highlight the advantages and potential of using quantum mechanics to advance the resolution of the Graph Isomorphism Problem, paving the way for more efficient algorithms in the realm of computational complexity.",
        "ori-fast-z-score": -0.5669467095138409,
        "water-fast-z-score": 5.550253123463223,
        "rewrite-fast-z-score": -0.7863336509949341
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Advantages of Four Dimensions for Composite Higgs Models .\nAbstract:\nWe study the advantages and disadvantages of composite Higgs models in four dimensions (4D) versus five dimensions (5D). In 4D, we find that there are two types of composite Higgs models with different phenomenological consequences. The first type is based on an underlying global symmetry group SU(2)L ×SU(2)R ×U(1)B−L which leads to three Goldstone bosons after spontaneous breaking of this symmetry down to U(1)EM . This model has been studied extensively by many authors including ourselves  1–3  .\nThe second type is based on an extended gauge symmetry group SU(3)C ×SU(2)L ×U(1)Y ×Z′ where Z′ is a new abelian gauge factor associated with extra spatial dimension  4–6  . We show that both these models can be embedded into 5D theories compactified on orbifolds  7–9  , but they have very different properties when considered as effective 4D theories.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Advantages of Four Dimensions for Composite Higgs Models . Abstract : We research the advantages and disadvantages of composite Higgs configurations in four dimensions ( 4D ) vs five dimensions ( 5D ) .In 4D , we find that there are two forms of composite Higgs theories with various phenomenological consequences . The first class is based on an underlying global symmetry class SU ( 2 ) L ×SU ( 2 ) R ×U ( 1 ) B−L which contributes to three Goldstone bosons after spontaneous breaking of this symmetry down to U ( 1 ) EM .This theory has been studied frequently by many writers including ourselves 1 – 3 . The second kind is based on an extended gauge symmetry class SU ( 3 ) C ×SU ( 2 ) L ×U ( 1 ) Y ×Z ′ where Z ′ is a new abelian gauge parameter identified with extra spatial dimension 4 – 6 .We see that both these models can be embedded into 5D theories compactified on orbifolds 7 – 9 , but they have very different properties when considered as efficient 4D theories .",
        "rewrite_text": "In this article, we explore the comparative advantages and disadvantages of composite Higgs models in four dimensions (4D) versus five dimensions (5D). Our investigation reveals that within the 4D framework, there exist two distinct classes of composite Higgs theories, each yielding different phenomenological implications. The first class is predicated on an underlying global symmetry structure described by SU(2)L × SU(2)R × U(1)B−L. This symmetry, upon spontaneous breaking to U(1)EM, results in the emergence of three Goldstone bosons. This particular model has been the subject of extensive research by various authors, including our own previous works. The second class of models is founded on an extended gauge symmetry represented by SU(3)C × SU(2)L × U(1)Y × Z′, where Z′ denotes a new abelian gauge parameter associated with an additional spatial dimension. While both of these 4D models can be effectively embedded within 5D theories that are compactified on orbifolds, they exhibit markedly different characteristics when analyzed as standalone 4D theories. Our findings contribute to a deeper understanding of the implications of dimensionality in the context of composite Higgs models, highlighting the unique features and potential applications of each theoretical framework. This research not only enhances the theoretical landscape of particle physics but also opens avenues for future investigations into the nature of Higgs mechanisms and their dimensional dependencies.",
        "ori-fast-z-score": -0.3779644730092272,
        "water-fast-z-score": 4.25,
        "rewrite-fast-z-score": 1.6502739940140694
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Mass and Radius of the Unseen M-Dwarf Companion in the Single-Lined Eclipsing Binary HAT-TR-205-013 .\nAbstract:\nWe report on new spectroscopic observations of the eclipsing binary system HAT-TR-205-1013, which was discovered by the Hungarian Automated Telescope (HAT) survey for transiting exoplanets. The light curve shows two partial eclipses with an orbital period of 1.8 days. We find that this is most likely caused by reflection effects rather than occultation events due to the presence of a third body. Using our radial velocity measurements we determine the mass function f(m) = 0.0027 ± 0.0007M⊙, where m is the mass of the unseen companion star. Assuming circular orbits, we derive the minimum masses of both components as M1 sin i = 0.84 ± 0.04M⊙ and M2 sin i = 0.16 ± 0.02M⊙. From these values we estimate the radius ratio between the primary and secondary component as q = 0.53 ± 0.06.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Mass and Radius of the Unseen M - Dwarf Companion in the Single - Lined Eclipsing Binary HAT - TR - 205 - 013 . Abstract : We report on new spectroscopic observations of the eclipsing binary system HAT - TR - 205 - 1013 , which was discovered by the Hungarian Automated Telescope ( HAT ) survey for transiting exoplanets .The light curve shows two partial eclipses with an orbital period of 1 . 8 days . We see that this is most likely due by reflection influences rather than occultation events due to the presence of a third body .Using our radial speed measurements we determine the mass function f ( m ) = 0 . 0027 ± 0 . [UNK] , where m is the mass of the unseen companion star . Assuming circular orbits , we derive the minimum masses of both components as M1 sin i = 0 . 84 ± 0 . [UNK] and M2 sin i = 0 . 16 ± 0 . [UNK] .From these values we estimate the radius ratio between the primary and secondary component as q = 0 . 53 ± 0 . 06 .",
        "rewrite_text": "We present new spectroscopic observations of the eclipsing binary system HAT-TR-205-013, identified by the Hungarian Automated Telescope (HAT) survey aimed at discovering transiting exoplanets. The light curve of this system reveals two partial eclipses occurring with an orbital period of 1.8 days. The observed light variations are likely influenced by reflection effects rather than being solely due to occultation events, suggesting the presence of a third body in the system. Through our radial velocity measurements, we calculate the mass function, f(m) = 0.0027 ± 0.0003, where m represents the mass of the unseen companion star. Assuming the orbits are circular, we derive the minimum masses for both stellar components: M1 sin i = 0.84 ± 0.05 for the primary star and M2 sin i = 0.16 ± 0.02 for the secondary star. From these mass estimates, we further calculate the radius ratio between the primary and secondary components, yielding a value of q = 0.53 ± 0.06. This study enhances our understanding of the dynamics and characteristics of the HAT-TR-205-013 system, particularly the role of the unseen M-dwarf companion, and contributes to the broader knowledge of binary star systems and their formation. The findings underscore the importance of spectroscopic observations in revealing the properties of components that are not directly observable, thereby providing insights into the complexities of stellar interactions in binary systems.",
        "ori-fast-z-score": 0.12216944435630522,
        "water-fast-z-score": 1.3438638879193574,
        "rewrite-fast-z-score": 0.5827715174143585
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The Serpens YSO Population As Observed With IRAC and MIPS .\nAbstract:\nWe present the results of our analysis of the infrared properties (3.6-24 microns) of young stellar objects in the nearby star forming region Serpens South using data obtained with the Infrared Array Camera (IRAC; Fazio et al., 2004 ) on board the Spitzer Space Telescope . We have identified a total of 1,082 candidate young stars based upon their mid-infrared colors and luminosities , including 759 previously known members of this cluster . Of these newly discovered sources , we find that only about half are associated with outflows as traced by shocked H 2 emission or radio continuum emission .\nThe majority of the remaining new candidates appear to be deeply embedded protostars which lack significant amounts of circumstellar material . These findings suggest that many of the new candidates may represent an earlier evolutionary stage than those already known within this cloud complex . This is consistent with previous studies suggesting that there exists a large population of low-mass pre-main sequence stars in Serpens South which remain undiscovered due to their youthful ages and/or relatively high levels of extinction .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds.IX.The Serpens YSO Population As Observed With IRAC and MIPS . Abstract : We present the conclusion of our analysis of the infrared properties ( 3 . 6 - 24 microns ) of young stellar bodies in the nearby star producing zone Serpens South using data received with the Infrared Array Camera ( IRAC ; Fazio et al . , 2004 ) on board the Spitzer Space Telescope .We have identified a total of 1 , 082 candidate young stars based upon their mid - infrared colors and luminosities , including 759 previously known members of this cluster . Of these newly discovered sources , we find that only about half are associated with outflows as traced by shocked H 2 emission or radio continuum emission .The majority of the remaining new candidates seem to be highly fused protostars which lack considerable portions of circumstellar material . These studies imply that several of the new candidates might represent an higher evolutionary stage than those already established within this cloud complex .This is consistent with previous research indicating that there exists a large colony of low - weight pre - principal sequence stars in Serpens South which appear undiscovered owing to their youthful ages and / or relatively high levels of extinction .",
        "rewrite_text": "In this article, we conclude our comprehensive analysis of the infrared characteristics (ranging from 3.6 to 24 microns) of young stellar objects (YSOs) located in the nearby star-forming region of Serpens South. Utilizing data obtained from the Infrared Array Camera (IRAC) aboard the Spitzer Space Telescope, we have identified a total of 1,082 candidate young stars based on their mid-infrared colors and luminosities. Among these, 759 were previously recognized members of the Serpens cluster. Notably, our findings reveal that only approximately half of the newly identified sources are linked to outflows, as evidenced by the presence of shocked H2 emission or radio continuum emissions. The remaining candidates predominantly appear to be highly evolved protostars that exhibit a significant reduction in circumstellar material. This observation suggests that many of these new candidates may represent a more advanced evolutionary stage compared to the established YSOs within this cloud complex. Our results align with earlier studies that propose the existence of a substantial population of low-mass pre-main sequence stars in Serpens South, which remain largely undetected due to their youthful characteristics and/or the relatively high levels of extinction in the region. This research enhances our understanding of the stellar population in Serpens South and contributes to the broader knowledge of star formation processes in nearby interstellar clouds.",
        "ori-fast-z-score": -0.5129891760425771,
        "water-fast-z-score": 4.331969234286932,
        "rewrite-fast-z-score": 0.6897304947150052
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Energy Density-Flux Correlations in an Unusual Quantum State and in the Vacuum .\nAbstract:\nWe study energy density-flux correlations for a free scalar field in 1+1 dimensions, both at finite temperature T and in vacuum (T=0). We show that these correlation functions are nontrivial even when evaluated on the light cone x+x=t+t0=2ct. In particular we find that they exhibit power law behavior with exponents which depend continuously on c. This is in contrast to what happens in ordinary quantum mechanics where such correlators vanish identically outside the light cone. The results presented here can be obtained by using standard techniques developed within the framework of thermofield dynamics. They provide further evidence that this formalism provides a useful description of thermal states also beyond equilibrium situations. Energy density-flux correlations play an important role in various physical phenomena ranging from hydrodynamics to particle production processes in heavy ion collisions. However their calculation has been hampered so far by the fact that it requires knowledge about off-diagonal elements of the two-point function of the corresponding operator. Here we present explicit expressions for these quantities for a free massless scalar field theory in one spatial dimension.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Energy Density - Flux Correlations in an Unusual Quantum State and in the Vacuum . Abstract : We research energy density - flux correlations for a free scalar field in 1 + 1 dimensions , both at finite temperature T and in vacuum ( T = 0 ) .We see that these correlation functions are nontrivial even when evaluated on the light cone x + x = t + t0 = 2ct . In particular we find that they show power law behavior with exponents which depend periodically on c . This is in comparison to what happens in ordinary quantum mechanics where such correlators vanish identically outside the light cone .The results presented here can be obtained by using conventional methods developed within the framework of thermofield dynamics . They offer further evidence that this formalism gives a helpful description of thermal states especially beyond equilibrium settings .Energy density - flux correlations serve an important role in different mechanical phenomena ranging from hydrodynamics to ion production systems in heavy ion collisions . However their prediction has been hampered so far by the fact that it takes knowledge about off - horizontal elements of the two - point integral of the associated operator .Here we present explicit expressions for these quantities for a free massless scalar field model in one spatial dimension .",
        "rewrite_text": "**Title:** Energy Density-Flux Correlations in an Unusual Quantum State and in the Vacuum\n\n**Abstract:** This study investigates the energy density-flux correlations of a free scalar field in one spatial and one temporal dimension (1 + 1 dimensions), focusing on both finite temperature (T) and vacuum conditions (T = 0). Our findings reveal that these correlation functions exhibit nontrivial characteristics, particularly when assessed along the light cone defined by the equation x + x = t + t0 = 2ct. Notably, we observe a power law behavior in these correlations, with exponents that exhibit periodic dependence on the speed of light, c. This behavior contrasts sharply with conventional quantum mechanics, where such correlators are known to vanish outside the light cone. The results we present are derived using established techniques from thermofield dynamics, which further substantiate the utility of this formalism in describing thermal states, especially in scenarios that extend beyond equilibrium. Energy density-flux correlations are crucial in various mechanical phenomena, including hydrodynamics and ion production in heavy ion collision systems. However, accurately predicting these correlations has been challenging due to the necessity of understanding the off-horizontal components of the two-point integral associated with the relevant operator. In this paper, we provide explicit expressions for these quantities within the context of a free massless scalar field model in one spatial dimension, thereby enhancing our understanding of these correlations and their implications in both theoretical and practical applications.",
        "ori-fast-z-score": 0.5129891760425771,
        "water-fast-z-score": 5.990542374288353,
        "rewrite-fast-z-score": 1.9425717247145282
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Rotation and activity of pre-main-sequence stars .\nAbstract:\nWe present the results of an analysis of high-resolution optical spectra obtained with the Subaru Telescope for a sample of young, low-mass (0.5-2 Msun) PMS stars in Orion Nebula Cluster. We find that most of these objects show significant periodic variability on timescales ranging between 1 day to several months. The observed periods are consistent with those expected if the photometric variations result from rotational modulation due to starspots and/or plages. In addition we detect strong Hα emission lines which indicate chromospheric activity. Our observations suggest that many of our targets have relatively rapid rotation rates compared to older field dwarfs at similar masses. This is likely caused by tidal locking during their formation process. Finally, we also report the detection of two new spectroscopic binaries among our target list. These systems will be useful as benchmarks for testing theoretical models of binary evolution.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Rotation and activity of pre - principal - sequence stars . Abstract : We present the conclusion of an assessment of high - resolution optical spectra obtained with the Subaru Telescope for a sample of young , low - weight ( 0 . 5 - 2 Msun ) PMS stars in Orion Nebula Cluster .We see that most of these objects show considerable periodic variability on timescales ranging between 1 day to several months . The observed periods are compatible with those expected if the photometric variations result from rotational modulation owing to starspots and / or plages .In addition we find strong Hα emission lines which show chromospheric behavior . Our observations suggest that several of our targets have fairly rapid rotation times compared to older field dwarfs at comparable masses .This is probably due by wave locking during their formation transition . Finally , we also report the observation of two new spectroscopic binaries among our target list .These systems will be valuable as benchmarks for evaluating theoretical theories of binary evolution .",
        "rewrite_text": "We present the findings from our investigation of high-resolution optical spectra collected using the Subaru Telescope, focusing on a sample of young, low-mass pre-main-sequence (PMS) stars located in the Orion Nebula Cluster, with masses ranging from 0.5 to 2 solar masses (Msun). Our analysis reveals that a significant majority of these stars exhibit notable periodic variability, with timescales spanning from one day to several months. The detected periodicities align with expectations for photometric variations driven by rotational modulation, likely caused by the presence of starspots and/or plages on the stellar surfaces. Furthermore, our study identifies pronounced Hα emission lines, indicative of chromospheric activity, which suggests that many of the stars in our sample possess relatively rapid rotation rates when compared to older field dwarfs of similar mass. This enhanced rotation is likely a consequence of wave locking mechanisms that occur during their formative transition. Additionally, we report the discovery of two new spectroscopic binary systems within our target group. These binaries are expected to serve as important benchmarks for testing and refining theoretical models of binary star evolution. Overall, our findings contribute to a deeper understanding of the rotation and activity of pre-main-sequence stars, shedding light on their developmental processes and the physical mechanisms at play during their early stages of evolution.",
        "ori-fast-z-score": -1.7888543819998317,
        "water-fast-z-score": 4.333333333333333,
        "rewrite-fast-z-score": -0.19069251784911848
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A New Template Family For The Detection Of Gravitational Waves From Comparable Mass Black Hole Binaries .\nAbstract:\nWe present the first results for a new template family, called SEOBNRv4HM, which is designed to detect gravitational waves (GWs) emitted by comparable mass black hole binaries with total masses between 10 and 100 solar masses. We show that this template family can be used in searches for GW signals from binary black holes at current ground-based detectors such as Advanced LIGO/Virgo and KAGRA. In addition we demonstrate how these templates are useful for parameter estimation studies using simulated data sets. Finally, we discuss possible improvements on our work. Keywords: Binary black hole -Gravitational wave detector -Template family -Parameter estimation -SEOBNRv4HM -Advanced Virgo -LIGO -KAGRA -Black hole -Binary system -Gravitational wave signal -Gravitational wave astronomy -Gravitational wave source -Signal-to-noise ratio -Search algorithm -Simulation",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A New Template Family For The Detection Of Gravitational Waves From Comparable Mass Black Hole Binaries . Abstract : We present the first findings for a new template family , known SEOBNRv4HM , which is designed to identify gravitational waves ( GWs ) emitted by similar mass black hole binaries with total masses between 10 and 100 solar masses .We see that this template family can be used in searches for GW signals from binary dark holes at current ground - based detectors such as Advanced LIGO / Virgo and KAGRA . In addition we prove how these templates are helpful for parameter estimation studies employing simulated data sets .Finally , we review possible advances on our work . Keywords : Binary white hole - Gravitational wave detector - Template family - Parameter estimation - SEOBNRv4HM - Advanced Virgo - LIGO - KAGRA - Black hole - Binary network - Gravitational wave noise - Gravitational wave astronomy - Gravitational wave source - Signal - to - noise ratio - Search algorithm - Simulation",
        "rewrite_text": "In this article, we introduce a novel template family named SEOBNRv4HM, specifically developed for the detection of gravitational waves (GWs) produced by comparable mass black hole binaries, with total masses ranging from 10 to 100 solar masses. Our findings indicate that this template family is particularly effective for identifying GW signals from binary black hole systems using current ground-based detectors, including Advanced LIGO, Virgo, and KAGRA. We demonstrate the utility of these templates not only in the direct search for gravitational wave signals but also in enhancing parameter estimation studies through the analysis of simulated datasets. The SEOBNRv4HM templates provide a robust framework for improving the accuracy of parameter estimation, which is crucial for understanding the properties of binary black hole systems and their astrophysical implications. Furthermore, we discuss potential future developments stemming from our research, which could lead to improved detection capabilities and a deeper understanding of gravitational wave sources. This work contributes to the growing field of gravitational wave astronomy, offering new tools for researchers to explore the dynamics of black hole mergers and the fundamental physics governing these extreme events. Our findings underscore the importance of advanced template families in the ongoing quest to detect and analyze gravitational waves, paving the way for future discoveries in the realm of astrophysics. \n\nKeywords: Binary black hole, Gravitational wave detection, Template family, Parameter estimation, SEOBNRv4HM, Advanced LIGO, Virgo, KAGRA, Gravitational wave astronomy, Signal-to-noise ratio, Search algorithms, Simulation.",
        "ori-fast-z-score": -1.5882027766319677,
        "water-fast-z-score": 2.9104275004359956,
        "rewrite-fast-z-score": -0.9838699100999074
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modeling Repulsive Gravity with Creation .\nAbstract:\nThe gravitational force between two objects is proportional to the product of their masses, and inversely proportional to the square of the distance separating them.  The same relationship holds true for repulsive gravity as well.   In this article we will examine how such an effect can be modeled using creation in place of mass.    Creation is defined by Einstein s field equations as:  G = 8πG/c4T00 where T00 represents the energy density of space-time.  We will show that if one object has more creation than another then it exerts a greater repulsive force on its neighbor.   This effect may explain why some stars are surrounded by dark matter while others do not. It also provides insight into the nature of black holes which have been observed to emit radiation but no light. Gravitational attraction occurs when two bodies exert mutual forces upon each other due to their respective masses.  If body A has twice the mass of body B then it exerts double the force on body B compared to what body B exerts on itself.  Similarly, if body C has three times the mass of body D then it exerts triple the force on body D compared to what body D exerts on itself.  Force is measured in newtons (N) or dynes (dyne).",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modeling Repulsive Gravity with Creation . Abstract : The gravitational pressure between two bodies is proportional to the product of their masses , and inversely proportional to the square of the distance separating them .The same relationship holds true for repulsive gravitational as also . In this article we will investigate how such an effect can be described using production in place of mass .Creation is given by Einstein s field equations as : G = 8πG / c4T00 where T00 represents the energy density of space - time . We will show that if one element has more creation than another then it exerts a greater repulsive force on its neighbor .This phenomenon might explain why some stars are surrounded by black material while many do not . It additionally offers knowledge into the nature of brown holes which have been observed to emit radiation but no light .Gravitational attraction occurs when two bodies exert mutual forces upon each other owing to their different masses . If body A has times the mass of bodies B then it exerts double the force on body B compared to what body B exerts on itself .Similarly , if bodies C has three times the mass of bodies D then it exerts triple the force on body D compared to what body D exerts on itself . Force is measured in newtons ( N ) or dynes ( dyne ) .",
        "rewrite_text": "**Title: Modeling Repulsive Gravity with Creation**\n\n**Abstract:** This article explores the concept of repulsive gravity, drawing parallels with the established principles of gravitational attraction. The gravitational force between two masses is defined by Newton's law, where the force is directly proportional to the product of the masses and inversely proportional to the square of the distance between them. We propose that a similar relationship can be applied to repulsive gravitational forces, substituting mass with a concept we refer to as \"creation.\" According to Einstein's field equations, the gravitational field is expressed as G = 8πG/c^4 T00, where T00 denotes the energy density of spacetime. Our investigation reveals that if one entity possesses a greater degree of creation than another, it will exert a stronger repulsive force on its counterpart. This phenomenon may provide insights into the observed characteristics of certain stars that are enveloped in dark material, as well as the enigmatic nature of brown holes, which are known to emit radiation without visible light. In the context of gravitational attraction, the interaction between two bodies is contingent upon their respective masses; for instance, if body A has twice the mass of body B, it will exert a force on body B that is double the force that body B exerts on itself. Similarly, if body C has three times the mass of body D, the force exerted by body C on body D will be threefold compared to the force that body D exerts on itself. The measurement of force is typically expressed in newtons (N) or dynes (dyne). This study aims to deepen our understanding of gravitational interactions by incorporating the concept of creation, potentially reshaping our comprehension of cosmic phenomena.",
        "ori-fast-z-score": -1.0660035817780522,
        "water-fast-z-score": 4.297967830559865,
        "rewrite-fast-z-score": 1.8569533817705188
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stability of the superconducting state in YBa_2Cu_3O_7 .\nAbstract:\nThe authors have studied the stability of the superconducting state by measuring the temperature dependence of the resistance and magnetic susceptibility for single crystals with different oxygen contents (0.5, 0.6, 0.7). The results show that the critical temperatures T_c decrease as the oxygen content decreases. This is explained by an increase in disorder due to the presence of excess oxygen atoms at low oxygen concentrations.  In addition, it was found that the transition widths are larger than those observed previously on polycrystalline samples. It has been shown that this effect can be attributed to the anisotropy of the crystal lattice. Finally, we note that the behavior of the resistivity near Tc does not depend on the oxygen concentration. We believe that these results will help clarify some aspects of the physics of high-temperature superconductors. High-Tc cuprates are known to exhibit two types of electronic states depending on their doping levels: metallic or insulating  1  . At optimal doping levels they display a superconducting phase which persists up to very high temperatures  2  , while underdoped compounds become insulators  3  .\nIn order to understand better the physical properties of these materials, several studies were performed using various techniques such as: transport measurements  4  , neutron scattering  5  , optical spectroscopy  6  , nuclear quadrupole resonance  7  , muon spin rotation  8  , etc.. However, despite all efforts made so far, there still remain many open questions about the nature of the normal and superconducting phases  9  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stability of the superconducting state in YBa _ 2Cu _ 3O _ 7 . Abstract : The authors have researched the stability of the superconducting state by monitoring the temperature dependence of the resistance and magnetic susceptibility for single crystals with various oxygen contents ( 0 . 5 , 0 . 6 , 0 . 7 ) .The results show that the critical temperatures T _ c decrease as the oxygen abundance falls . This is explained by an increase in disorder caused to the presence of excess oxygen atoms at low oxygen concentrations .In addition , it was shown that the transition widths are larger than those observed previously on polycrystalline specimens . It has been shown that this effect can be due to the anisotropy of the crystal lattice .Finally , we note that the response of the resistivity near Tc does not depend on the oxygen pressure . We believe that these results will assist clarify some parts of the physics of high - temperature superconductors .High - Tc cuprates are known to exhibit two forms of electronic states based on their doping rates : metallic or insulating 1 . At optimal doping levels they show a superconducting phase which persists up to very high temperatures 2 , while underdoped substances become insulators 3 .In order to explain better the physical properties of these structures , various tests were performed using numerous technology such as : transport measurements 4 , neutron scattering 5 , optical spectroscopy 6 , nuclear quadrupole resonance 7 , muon spin rotation 8 , etc . . However , despite all efforts made so far , there still continue several open questions about the nature of the ordinary and superconducting phases 9 .",
        "rewrite_text": "Title: Stability of the Superconducting State in YBa2Cu3O7\n\nAbstract: This study investigates the stability of the superconducting state in YBa2Cu3O7 by examining the temperature dependence of resistance and magnetic susceptibility in single crystals with varying oxygen content (0.5, 0.6, and 0.7). The findings reveal a decrease in critical temperatures (Tc) corresponding to lower oxygen levels, attributed to increased disorder from excess oxygen atoms present at reduced concentrations. Notably, the transition widths observed in this study are broader than those reported for polycrystalline samples, a phenomenon likely linked to the anisotropic nature of the crystal lattice. Furthermore, the resistivity response near Tc appears to be independent of the oxygen pressure, suggesting a robust characteristic of the superconducting state. These insights contribute to a deeper understanding of high-temperature superconductors, particularly the behavior of high-Tc cuprates, which exhibit distinct electronic states based on their doping levels—ranging from metallic to insulating phases. At optimal doping, these materials demonstrate a superconducting phase that can endure at elevated temperatures, while underdoped variants tend to behave as insulators. To elucidate the physical properties of these compounds, a variety of experimental techniques have been employed, including transport measurements, neutron scattering, optical spectroscopy, nuclear quadrupole resonance, and muon spin rotation. Despite extensive research, several fundamental questions regarding the nature of both the ordinary and superconducting phases remain unresolved. This work aims to shed light on these complexities and enhance our comprehension of the mechanisms underlying high-temperature superconductivity.",
        "ori-fast-z-score": -0.27975144247209416,
        "water-fast-z-score": 4.828078792603349,
        "rewrite-fast-z-score": 0.552344770738994
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Distribution of the molecular absorption in front of the quasar B0218+357 .\nAbstract:\nWe have studied the distribution of the molecular gas along the line-of-sight to the gravitationally lensed radio source B0218+357 using high-resolution millimeter-wave observations at 345 GHz and 1.3 mm with the Submillimeter Array (SMA) on Mauna Kea, Hawaii. The lensing galaxy is located between two images A and C separated by 2.7 arcsec. We detected three compact continuum sources associated with each image component. In addition we found several faint emission lines including CO(3-2), 13CO(3-2), HCN(4-3), CS(5-4), SiO(8-7). From these results we conclude that there are four components contributing to the total flux density; one for each image plus an additional component due to the lensing galaxy. Using our SMA data together with previous single-dish measurements, we derived physical parameters such as mass surface densities, column densities, temperatures, and volume densities for all four components.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Distribution of the molecular absorption in front of the quasar B0218 + 357 . Abstract : We have researched the distribution of the molecular gas along the line - of - view to the gravitationally lensed radio transmitter B0218 + 357 using high - resolution millimeter - wave studies at 345 GHz and 1 . 3 cm with the Submillimeter Array ( SMA ) on Mauna Kea , Hawaii .The lensing galaxy is situated between two images A and C connected by 2 . 7 arcsec . We observed three compact continuum sources involved with each image element .In addition we found several faint emission lines including CO ( 3 - 2 ) , 13CO ( 3 - 2 ) , HCN ( 4 - 3 ) , CS ( 5 - 4 ) , SiO ( 8 - 7 ) . From these results we conclude that there are four components contributing to the total flux concentration ; one for each image plus an additional element due to the lensing galaxy .Using our SMA data together with previous single - dish measurements , we derived mechanical parameters such as mass surface densities , column densities , temperatures , and volume densities for all four components .",
        "rewrite_text": "Title: Distribution of Molecular Absorption in Front of the Quasar B0218 + 357\n\nAbstract: In this study, we investigate the distribution of molecular gas along the line of sight to the gravitationally lensed radio source B0218 + 357. Utilizing high-resolution millimeter-wave observations at 345 GHz and 1.3 cm with the Submillimeter Array (SMA) located on Mauna Kea, Hawaii, we focus on the lensing galaxy situated between the two images, A and C, which are separated by 2.7 arcseconds. Our observations reveal three compact continuum sources associated with each image component. Furthermore, we detected several faint emission lines, including CO (3-2), 13CO (3-2), HCN (4-3), CS (5-4), and SiO (8-7). These findings suggest the presence of four distinct components contributing to the overall flux concentration: one for each image and an additional component attributed to the lensing galaxy itself. By integrating our SMA data with previous single-dish measurements, we were able to derive key mechanical parameters for all four components, including mass surface densities, column densities, temperatures, and volume densities. This comprehensive analysis enhances our understanding of the molecular gas distribution in the vicinity of B0218 + 357 and provides insights into the physical conditions of the lensing galaxy and its impact on the observed quasar images. Our results contribute to the broader field of astrophysics by elucidating the complex interplay between gravitational lensing and molecular gas dynamics in the universe.",
        "ori-fast-z-score": -0.601929265428846,
        "water-fast-z-score": 2.966954145484633,
        "rewrite-fast-z-score": 0.41702882811414954
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Physical Investigation of the Potentially Hazardous Asteroid (144898) 2004 VD17 .\nAbstract:\nThe asteroid 144898 was discovered on September 24, 2004 by the Catalina Sky Survey at an apparent magnitude of 18.7 and is classified as potentially hazardous due to its large size.  The orbit has been determined using astrometric observations made with the US Naval Observatory s 1-meter telescope in Flagstaff Arizona between October 2005 and March 2007.   These data show that this object will not impact Earth during the next 100 years but may be a good candidate for future space mission targets. This work was supported by NASA under grant NNX07AG70G issued through the Planetary Defense Coordination Office. We report here our results of physical investigations carried out on the surface of the asteroid 144898 (2004VD17). Our analysis shows that it is a S-type asteroid with a diameter D = 2.5 ± 0.2 km. Its rotation period P = 3.6 ± 0.1 hours and pole position are also derived.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Physical Investigation of the Potentially Hazardous Asteroid ( 144898 ) 2004 VD17 . Abstract : The asteroid 144898 was discovered on September 24 , 2004 by the Catalina Sky Survey at an apparent magnitude of 18 . 7 and is categorized as potentially dangerous due to its large size .The orbit has been determined using astrometric observations made with the US Naval Observatory s 1 - meter telescope in Flagstaff Arizona between October 2005 and March 2007 . These data demonstrate that this body will not hit Earth during the last 100 years but might be a better contender for future space flight targets .This project was supported by NASA under grant NNX07AG70G granted through the Planetary Defense Coordination Office . We report here our findings of physical operations carried out on the surface of the asteroid 144898 ( 2004VD17 ) .Our study shows that it is a S - class asteroid with a diameter D = 2 . 5 ± 0 . 2 km . Its rotation period P = 3 . 6 ± 0 . 1 hours and pole position are also derived .",
        "rewrite_text": "**Title:** Physical Investigation of the Potentially Hazardous Asteroid (144898) 2004 VD17\n\n**Abstract:** The asteroid 144898, identified on September 24, 2004, by the Catalina Sky Survey, has garnered attention due to its significant size and classification as a potentially hazardous object, with an apparent magnitude of 18.7. Through a series of astrometric observations conducted using the US Naval Observatory's 1-meter telescope in Flagstaff, Arizona, from October 2005 to March 2007, we have successfully determined its orbital characteristics. Our analysis indicates that this asteroid poses no threat of collision with Earth over the next century, suggesting instead that it could serve as a viable target for future space exploration missions. This research was supported by NASA under grant NNX07AG70G, provided through the Planetary Defense Coordination Office. \n\nIn our investigation, we present detailed findings from physical operations conducted on the surface of asteroid 144898 (2004 VD17). Our results confirm that it is classified as an S-type asteroid, with a measured diameter of 2.5 ± 0.2 km. Additionally, we have derived its rotation period, which is approximately 3.6 ± 0.1 hours, along with the orientation of its rotational pole. These physical characteristics contribute to our understanding of the asteroid's composition and dynamics, which are crucial for assessing its potential for future exploration and the implications for planetary defense strategies. The data gathered from this study not only enhances our knowledge of this specific asteroid but also aids in the broader context of understanding similar near-Earth objects.",
        "ori-fast-z-score": -1.3643820804812932,
        "water-fast-z-score": 3.4465617474213164,
        "rewrite-fast-z-score": 1.1881770515720091
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Decoherence of a driven multilevel quantum system interacting with a multi-bath reservoir .\nAbstract:\nWe study the decoherence dynamics of an open quantum system consisting of two-level atoms coupled to a single-mode cavity field in presence of dissipation and driving fields. The atom-cavity coupling is treated within the framework of Jaynes-Cummings model, while the dissipative effects are described by using the master equation for the reduced density matrix of the system. We show that the steady state solution of this problem can be obtained analytically when the decay rates of all atomic levels are equal. In particular we find that the steady-state entanglement between the atom-field subsystem depends on both the strength of the external driving field as well as the number of excited states involved in the process. Finally, we discuss how our results could be used to explain recent experimental observations concerning the generation of nonclassical light via spontaneous emission processes. PACS numbers: 03.67.Mn, 42.50.Vk",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Decoherence of a driven multilevel quantum state interacting with a multi - bath pool . Abstract : We explore the decoherence dynamics of an open quantum system consisting of two - level atoms connected to a single - mode cavity field in presence of dissipation and driving fields .The atom - cavity coupling is treated within the framework of Jaynes - Cummings model , while the dissipative effects are explained by using the master equation for the reduced density matrix of the system . We see that the stable state solution of this question can be obtained analytically when the decay rates of all atomic levels are equal .In particular we find that the stable - state entanglement between the atom - field subsystem depends on both the strength of the external driving field as also as the quantity of excited states concerned in the process . Finally , we explain how our findings may be used to explain latest experimental discoveries involving the generation of nonclassical light via spontaneous emission mechanisms .PACS codes : 03 . 67 . Mn , 42 . 50 . Vk",
        "rewrite_text": "**Title:** Decoherence of a Driven Multilevel Quantum State Interacting with a Multi-Bath Pool\n\n**Abstract:** In this study, we investigate the decoherence dynamics of an open quantum system comprising two-level atoms coupled to a single-mode cavity field, while accounting for the effects of dissipation and external driving fields. The interaction between the atoms and the cavity is modeled using the Jaynes-Cummings framework, which allows us to describe the coherent coupling between the atomic states and the cavity field. To address the dissipative processes affecting the system, we employ the master equation approach to derive the reduced density matrix, which captures the essential features of the system's evolution. Our analysis reveals that an analytical solution for the stable state can be achieved when the decay rates of all atomic levels are uniform. Notably, we discover that the entanglement in the stable state between the atom-field subsystem is influenced by both the intensity of the external driving field and the number of excited states involved in the interaction. This relationship highlights the intricate interplay between driving forces and quantum coherence in the system. Furthermore, we discuss the implications of our findings in the context of recent experimental advancements, particularly in the generation of nonclassical light through spontaneous emission processes. Our results contribute to a deeper understanding of decoherence in driven multilevel systems and may pave the way for future applications in quantum optics and information science. The PACS codes relevant to this work are 03.67.Mn and 42.50.Vk, indicating its connection to quantum information theory and quantum optics, respectively.",
        "ori-fast-z-score": 0.4216370213557839,
        "water-fast-z-score": 4.297967830559865,
        "rewrite-fast-z-score": 1.4605934866804429
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Star Formation, Radio Sources, Cooling X-ray Gas, and Galaxy Interactions in the Brightest Cluster Galaxy in 2A0335+096 .\nAbstract:\nWe present new Chandra observations of the brightest cluster galaxy (BCG) in Abell 3395 (z=0.084). The BCG is surrounded by an extended halo with temperatures ranging between 1 keV to 5 keV. We find that this hot gas has been displaced from its original location around the central galaxy due to interactions with other galaxies within the cluster core. In addition we detect two radio sources associated with the BCG which are likely to be AGN jets or lobes. Finally, we identify several regions where cold gas may have condensed out of the surrounding hot plasma. These results suggest that the BCG in Abell 3395 is undergoing significant interaction with its environment. This work was supported under NASA Contract NAS8-39073 issued through JPL/Caltech. The data presented herein were obtained at the Chandra Observatory, operated by the Smithsonian Astrophysical Observatory for and on behalf of NASA under contract NAS8-03060.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Star Formation , Radio Sources , Cooling X - ray Gas , and Galaxy Interactions in the Brightest Cluster Galaxy in 2A0335 + 096 . Abstract : We present new Chandra observations of the brightest cluster galaxy ( BCG ) in Abell 3395 ( z = 0 . 084 ) .The BCG is enclosed by an extended halo with temperatures ranging between 1 keV to 5 keV . We see that this hot gas has been displaced from its previous site around the main galaxy owing to interactions with other stars within the cluster core .In addition we locate two radio sources involved with the BCG which are likely to be AGN planes or lobes . Finally , we identify several regions where cold gas may have condensed out of the nearby heated plasma .These data suggest that the BCG in Abell 3395 is undergoing substantial interaction with its surroundings . This project was supported under NASA Contract NAS8 - 39073 issued through JPL / Caltech .The data given herein were obtained at the Chandra Observatory , operated by the Smithsonian Astrophysical Observatory for and on behalf of NASA under contract NAS8 - 03060 .",
        "rewrite_text": "We present new observations from the Chandra X-ray Observatory focusing on the brightest cluster galaxy (BCG) in the Abell 3395 cluster, located at a redshift of z = 0.084. Our findings reveal that the BCG is surrounded by an extensive halo of hot gas, with temperatures ranging from 1 keV to 5 keV. Notably, we have observed a displacement of this hot gas from its original position around the central galaxy, which we attribute to interactions with other stellar bodies within the cluster's core. Furthermore, our analysis identifies two radio sources associated with the BCG, which are likely to be active galactic nucleus (AGN) jets or lobes. These radio emissions provide insight into the energetic processes occurring in the vicinity of the BCG. Additionally, we have pinpointed several regions where cold gas appears to have condensed from the surrounding heated plasma, indicating ongoing cooling processes. The data collectively suggest that the BCG in Abell 3395 is experiencing significant interactions with its environment, which may influence its star formation activity and the dynamics of the surrounding gas. This research was conducted under NASA Contract NAS8-39073, facilitated through JPL/Caltech, and the observations were made possible by the Chandra Observatory, which is operated by the Smithsonian Astrophysical Observatory on behalf of NASA under contract NAS8-03060. Our findings contribute to the understanding of galaxy interactions and the complex processes governing star formation and gas cooling in cluster environments.",
        "ori-fast-z-score": -0.1259881576697424,
        "water-fast-z-score": 4.6615618337804685,
        "rewrite-fast-z-score": -0.09950371902099892
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Electrical excitation of shock and soliton-like waves in two-dimensional electron channels .\nAbstract:\nWe study the electrical excitation of nonlinear waves in a 2D channel with an applied voltage bias between two parallel metal plates separated by a dielectric layer. We show that, depending on the parameters of the system (the thickness of the dielectric layer, the density of electrons), different types of nonlinear waves can be excited. In particular, we find that for certain values of these parameters solitary wave solutions exist which are similar to those found earlier in 1D systems. \n \n The existence of such solitary waves is confirmed experimentally using time-resolved optical reflectivity measurements performed at room temperature on samples consisting of GaAs/AlGaAs quantum wells grown by molecular beam epitaxy. These experiments reveal the presence of bright solitary waves propagating along the direction perpendicular to the applied electric field. Their propagation velocities agree well with theoretical predictions based on numerical simulations of the underlying equations. \nThe results presented here may have important applications in semiconductor devices where it has been shown recently that the generation of solitary waves leads to improved performance characteristics.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Electrical excitation of shock and soliton - like waves in two - dimensional electron channels . Abstract : We research the electrical excitation of nonlinear waves in a 2D channel with an applied voltage bias between two connected metal plates connected by a dielectric layer .We see that , depending on the variables of the system ( the height of the dielectric layer , the density of electrons ) , different kinds of nonlinear waves can be excited . In particular , we find that for particular values of these parameters solitary wave systems occur which are comparable to those observed earlier in 1D systems .The nature of such solitary waves is discovered experimentally utilizing period - resolved optical reflectivity surveys performed at room temperature on samples consisting of GaAs / AlGaAs quantum wells developed by molecular beam epitaxy . These studies reveal the presence of bright solitary waves propagating along the direction perpendicular to the applied electric field .Their propagation velocities agree well with theoretical estimates based on numerical simulations of the underlying equations . The results presented here possibly have important use in semiconductor devices where it has been shown lately that the generation of solitary waves gives to improved performance qualities .",
        "rewrite_text": "In this study, we investigate the electrical excitation of nonlinear waves within a two-dimensional (2D) electron channel, specifically focusing on a system comprising two metal plates separated by a dielectric layer and subjected to a voltage bias. Our findings indicate that the characteristics of the nonlinear waves generated are highly dependent on various system parameters, including the height of the dielectric layer and the electron density. Notably, we observe the emergence of solitary wave formations under specific conditions, which bear resemblance to those previously documented in one-dimensional systems. \n\nTo elucidate the properties of these solitary waves, we conducted experimental investigations using period-resolved optical reflectivity measurements at room temperature on GaAs/AlGaAs quantum well samples fabricated through molecular beam epitaxy. The results of these experiments reveal the existence of bright solitary waves that propagate perpendicular to the direction of the applied electric field. Furthermore, the measured propagation velocities of these waves align closely with theoretical predictions derived from numerical simulations of the governing equations.\n\nThe implications of our findings are significant, particularly in the context of semiconductor technology. Recent advancements have highlighted the potential benefits of solitary wave generation in enhancing the performance characteristics of semiconductor devices. This research not only contributes to the fundamental understanding of nonlinear wave dynamics in 2D electron systems but also opens avenues for practical applications in the development of next-generation electronic components.",
        "ori-fast-z-score": -0.3922322702763681,
        "water-fast-z-score": 4.902903378454601,
        "rewrite-fast-z-score": 2.3539293971054818
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Kinematics and Dynamics of the Globular Clusters and the Planetary Nebulae of NGC 5128 .\nAbstract:\nWe present new spectroscopic observations for two globular clusters (GCs) in the nearby galaxy NGC 5128, which is known as Centaurus A. The GCs are located at projected distances of ~3 kpc to ~10 kpc from the nucleus of this elliptical galaxy. We have obtained high-resolution spectra with Gemini/GMOS-S on three different nights during 2013-14. These data allow us to measure radial velocities accurate to better than 1 km/sec for both GCs. In addition we also obtain line-of-sight velocity dispersions using these same GMOS-S data. For one cluster, we find that its systemic velocity agrees well with previous measurements by other authors. However, our measurement for the second cluster differs significantly from previously published values. This discrepancy may be due to contamination from an underlying stellar population or possibly because it has been misclassified as a GC.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Kinematics and Dynamics of the Globular Clusters and the Planetary Nebulae of NGC 5128 . Abstract : We report new spectroscopic observations for two globular complexes ( GCs ) in the nearby galaxy NGC 5128 , which is known as Centaurus A .The GCs are situated at projected speeds of ~ 3 kpc to ~ 10 kpc from the nucleus of this elliptical galaxy . We have achieved high - resolution spectra with Gemini / GMOS - S on three different nights during 2013 - 14 .These data enable us to measure radial velocities accurate to well than 1 km / sec for both GCs . In addition we also obtain point - of - view velocity dispersions using these same GMOS - S data .For one cluster , we find that its chronic velocity agrees well with previous measurements by other researchers . However , our measurement for the second cluster differs greatly from prior written values .This discrepancy may be due to poisoning from an underlying stellar community or possibly because it has been misclassified as a GC .",
        "rewrite_text": "We present new spectroscopic observations of two globular clusters (GCs) located in the nearby galaxy NGC 5128, commonly referred to as Centaurus A. These clusters are positioned at projected distances ranging from approximately 3 kpc to 10 kpc from the nucleus of this elliptical galaxy. Utilizing high-resolution spectra obtained with the Gemini/GMOS-S instrument over three separate nights during the 2013-2014 period, we have achieved radial velocity measurements with an accuracy exceeding 1 km/s for both GCs. Additionally, we have calculated velocity dispersions from the same GMOS-S data, providing a comprehensive view of the kinematics of these clusters. For one of the clusters, our findings align closely with previous measurements reported by other researchers, reinforcing the reliability of our data. However, our results for the second cluster reveal a significant deviation from earlier published values. This discrepancy raises important questions regarding the nature of this cluster, suggesting that it may be influenced by contamination from an underlying stellar population or that it has been misclassified as a globular cluster. Our study contributes to the understanding of the dynamics and kinematics of globular clusters in NGC 5128, highlighting the complexities involved in accurately characterizing these astronomical objects. The implications of our findings may extend to broader discussions on the formation and evolution of globular clusters within elliptical galaxies, as well as the potential for misidentification in observational astronomy.",
        "ori-fast-z-score": -0.8682431421244593,
        "water-fast-z-score": 3.8450767722654624,
        "rewrite-fast-z-score": -0.8251369970070347
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Formation of Globular Cluster Systems in Massive Elliptical Galaxies: Globular Cluster Multimodality from Radial Variation of Stellar Populations .\nAbstract:\nWe present the results of an analysis of globular cluster (GC) systems in four massive elliptical galaxies, NGC 4889, NGC 4636, NGC 5846 and NGC 6166, using deep Hubble Space Telescope imaging data obtained with the Advanced Camera for Surveys Wide Field Channel. We find that these GC systems are multimodal; they consist of at least two subpopulations which differ significantly in their color distributions as well as in their spatial distribution within each galaxy. The blue subpopulation is more centrally concentrated than the red one, while both populations show similar radial profiles outside the central regions. These findings suggest that the formation histories of the two subpopulations may be different. In particular, we propose that the blue subpopulation formed during major mergers between gas-rich disk galaxies, whereas the red subpopulation was assembled through minor mergers and/or accretion events involving dwarf galaxies or low-mass ellipticals.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Formation of Globular Cluster Systems in Massive Elliptical Galaxies : Globular Cluster Multimodality from Radial Variation of Stellar Populations . Abstract : We present the conclusion of an assessment of globular cluster ( GC ) complexes in four large elliptical galaxies , NGC 4889 , NGC 4636 , NGC 5846 and NGC 6166 , using deep Hubble Space Telescope imaging information obtained with the Advanced Camera for Surveys Wide Field Channel .We see that these GC systems are multimodal ; they consist of at least two subpopulations which varies much in their color distributions as well as in their temporal distribution within each galaxy . The blue subpopulation is more centrally focused than the red one , while both populations display corresponding radial profiles outside the main regions .These studies imply that the formation histories of the two subpopulations might be different . In particular , we propose that the blue subpopulation formed during major mergers between gas - rich disk galaxies , whereas the red subpopulation was assembled through minor mergers and / or accretion events involving giant galaxies or low - mass ellipticals .",
        "rewrite_text": "We present the findings of our investigation into the globular cluster (GC) systems of four prominent elliptical galaxies: NGC 4889, NGC 4636, NGC 5846, and NGC 6166. Utilizing deep imaging data from the Hubble Space Telescope's Advanced Camera for Surveys Wide Field Channel, we have uncovered significant insights into the multimodal nature of these GC complexes. Our analysis reveals that each galaxy's GC system comprises at least two distinct subpopulations, which exhibit notable differences in both color distributions and temporal formation patterns. Specifically, we observe that the blue subpopulation is more concentrated towards the center of the galaxies, in contrast to the red subpopulation, which displays a more dispersed radial profile beyond the central regions. These findings suggest that the formation mechanisms of the two subpopulations may differ considerably. We hypothesize that the blue globular clusters predominantly formed during major merger events involving gas-rich disk galaxies, while the red globular clusters likely originated from minor mergers and/or accretion processes involving larger galaxies or low-mass elliptical galaxies. This study enhances our understanding of the complex evolutionary histories of globular cluster systems in massive elliptical galaxies and provides a framework for further exploration of their formation dynamics. The implications of these results extend to the broader context of galaxy formation and evolution, highlighting the intricate interplay between different stellar populations and their respective formation environments.",
        "ori-fast-z-score": -1.116312611302876,
        "water-fast-z-score": 4.185110693297313,
        "rewrite-fast-z-score": 0.6831300510639733
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Coulomb Drag in Graphene .\nAbstract:\nThe Coulomb drag effect is the phenomenon where one charge carrier can transfer energy to another by exchanging virtual phonons, leading to an electric current in the second carrier that opposes its own motion.  In this work we study the Coulomb drag between two graphene sheets separated by a dielectric spacer layer and subject to different gate voltages. We find that for small separation distances (less than 10 nm) there are significant deviations from the predictions based on the standard theory developed for bulk materials. These deviations arise due to the presence of evanescent modes which couple strongly with the carriers at low energies. For larger separations these effects become negligible as expected. The results presented here provide useful information about how to design devices such as transistors or thermoelectric generators using graphene layers. \nI. INTRODUCTIO N\nGraphene has attracted considerable attention recently because it exhibits unique electronic properties  1  . It consists of carbon atoms arranged into a honeycomb lattice structure and behaves like a two-dimensional electron gas when doped  2  .\nOne interesting property of graphene is the so-called Coulomb drag effect  3  , i.e., the generation of an electric current in a second sheet of electrons moving through a first sheet of electrons even if they do not interact directly  4  . This effect arises because both carriers exchange virtual phonons via their mutual interaction mediated by the substrate  5  . As a result, the current density in the second carrier depends on the velocity of the first carrier  6  . Since the discovery of the Coulomb drag effect in semiconductors  7, 8  many theoretical studies have been performed  9  -  11  . However, only very few experiments were carried out so far  12  -  14  mainly due to difficulties associated with fabricating samples with high quality interfaces  15  . Recently, several groups succeeded in growing high-quality epitaxial graphene  16  -  18  opening up new possibilities for studying the Coulomb drag effect experimentally  19  -  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Coulomb Drag in Graphene . Abstract : The Coulomb drag effect is the phenomenon where one charge carrier can carry energy to another by exchanging virtual phonons , leading to an electric current in the second carrier that opposes its own movement .In this research we study the Coulomb drag between two graphene strips separated by a dielectric spacer membrane and subject to different gate voltages . We see that for short separation distances ( fewer than 10 nm ) there are significant deviations from the estimates based on the standard theory derived for bulk surfaces .These deviations occur due to the presence of evanescent modes which couple strongly with the carriers at low energies . For larger separations these influences grow negligible as predicted .The results presented here provide useful details about how to build electronics such as transistors or thermoelectric turbines using graphene strands . I . INTRODUCTIO N Graphene has garnered considerable scrutiny lately because it displays unusual electronic properties 1 .It consists of carbon atoms arranged into a honeycomb lattice structure and behaves like a two - dimensional electron gas when doped 2 . One interesting property of graphene is the so - called Coulomb drag effect 3 , i . e . , the generation of an electric current in a second sheet of atoms moved through a second sheet of atoms even if they do not interact directly 4 .This phenomenon arises because both carriers trade virtual phonons via their mutual interaction mediated by the substrate 5 . As a result , the current density in the second carrier varies on the velocity of the first carrier 6 .Since the discovery of the Coulomb drag effect in semiconductors 7 , 8 numerous conceptual research have been performed 9 - 11 . However , only very few experiments were carried out so far 12 - 14 chiefly due to difficulties related with fabricating samples with high quality interfaces 15 .Recently , various groups helped in growing high - quality epitaxial graphene 16 - 18 providing up new possibilities for studying the Coulomb drag effect experimentally 19 - 21 .",
        "rewrite_text": "**Title: Coulomb Drag in Graphene**\n\n**Abstract:** The Coulomb drag effect refers to the phenomenon in which one charge carrier transfers energy to another through the exchange of virtual phonons, resulting in an electric current in the second carrier that opposes its own motion. This study investigates the Coulomb drag between two graphene strips that are separated by a dielectric spacer membrane and subjected to varying gate voltages. Our findings reveal that at short separation distances (less than 10 nm), there are notable deviations from predictions based on conventional theories developed for bulk materials. These discrepancies arise from the influence of evanescent modes, which exhibit strong coupling with low-energy carriers. As the separation distance increases, these effects diminish, aligning with theoretical expectations. The insights gained from this research are significant for the development of electronic devices, such as transistors and thermoelectric generators, utilizing graphene materials.\n\nGraphene has attracted extensive attention due to its remarkable electronic characteristics, which stem from its unique honeycomb lattice structure composed of carbon atoms. When doped, graphene behaves like a two-dimensional electron gas, exhibiting intriguing properties such as the Coulomb drag effect. This effect manifests as the generation of an electric current in one layer of graphene induced by the movement of charge carriers in another layer, despite the absence of direct interaction between the two. The underlying mechanism involves the exchange of virtual phonons facilitated by their mutual interaction with the substrate. Consequently, the current density in the second layer is influenced by the velocity of the first layer's carriers.\n\nSince the initial observation of the Coulomb drag effect in semiconductors, numerous theoretical studies have been conducted. However, experimental investigations have been limited, primarily due to challenges in fabricating high-quality interfaces. Recent advancements in the growth of high-quality epitaxial graphene have opened new avenues for experimental exploration of the Coulomb drag effect, paving the way for further research in this area.",
        "ori-fast-z-score": 1.6222142113076254,
        "water-fast-z-score": 8.327056459580765,
        "rewrite-fast-z-score": 1.4795908857482156
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Fluctuations of finite-time stability exponents in the standard map and the detection of small islands .\nAbstract:\nWe study fluctuations of finite-time Lyapunov exponent (FTLE) for chaotic orbits on the standard map with periodic boundary conditions. We show that FTLE fluctuates around its mean value, which is determined by the largest unstable periodic orbit embedded into the chaotic attractor. The amplitude of these fluctuations decreases exponentially as time increases. In addition to this exponential decay we observe an algebraic tail at large times. This algebraic tail can be explained by the presence of small islands inside the chaotic sea. These results are confirmed numerically using different methods. \nI. INTRODUCTORY REMARK\nThe concept of finite-time Lyapunovexponent(FTLE), introduced by Wolf et al  1  , has been widely used recently  2  -  4  . It describes how fast nearby trajectories diverge or converge during some fixed period of time T . For example, if one considers two neighboring points x 0 = x(t 0 ) and y 0 = x(t 1 ), where t 0 < t 1 , then their separation after time T will be given by: \nwhere λ max > 0 is the maximum Lyapunov exponent characterizing the rate of divergence between nearby trajectories  5  .\nIn order to calculate the FTLE it is necessary to solve the following variational equation:\nwhere J is the Jacobian matrix corresponding to the flow generated by Eq. (1). If the initial condition z 0 = x t0 + εy t0 is close enough to the reference trajectory x t0 , i.e., |ε| ≪ 1, then the solution of Eq.(2) can be written as:\nwhere P n (T ; t 0 , t 1 ) is the nth-order Taylor polynomial expansion of the evolution operator U (T ; t 0 ). Then the FTLE can be calculated from:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Fluctuations of finite - time stability exponents in the standard mapping and the observation of tiny islands . Abstract : We research fluctuations of finite - time Lyapunov exponent ( FTLE ) for turbulent orbits on the standard mapping with periodic border conditions .We see that FTLE fluctuates around its average value , which is chosen by the greatest chaotic periodic orbit integrated into the chaotic attractor . The amplitude of these fluctuations decreases exponentially as time rises .In addition to this exponential decay we encounter an algebraic tail at large times . This algebraic tail can be described by the presence of tiny islands inside the chaotic sea .These conclusions are confirmed numerically using varying methods . I .INTRODUCTORY REMARK The concept of finite - time Lyapunovexponent ( FTLE ) , invented by Wolf et al 1 , has been widely applied recently 2 - 4 . It expresses how rapid nearby trajectories diverge or converge during some fixed period of time T .For instance , if one considers two adjacent points x 0 = x ( t 0 ) and y 0 = x ( t 1 ) , where t 0 < t 1 , then their separation after time T will be taken by : where λ max > 0 is the maximum Lyapunov exponent characterizing the frequency of divergence between neighboring trajectories 5 . In order to estimate the FTLE it is required to solve the following variational equation : where J is the Jacobian matrix corresponding to the flow generated by Eq .( 1 ) . If the first condition z 0 = x t0 + εy t0 is close enough to the reference trajectory x t0 , i . e . , | ε | [UNK] 1 , then the solve of Eq .( 2 ) can be written as : where P n ( T ; t 0 , t 1 ) is the nth - order Taylor polynomial expansion of the evolution function U ( T ; t 0 ) . Then the FTLE can be determined from :",
        "rewrite_text": "**Title:** Fluctuations of Finite-Time Stability Exponents in the Standard Mapping and the Observation of Tiny Islands\n\n**Abstract:** This study investigates the fluctuations of finite-time Lyapunov exponents (FTLE) for turbulent orbits within the framework of the standard mapping under periodic boundary conditions. Our findings reveal that the FTLE exhibits fluctuations around a mean value, which is determined by the most chaotic periodic orbit integrated within the chaotic attractor. Notably, we observe that the amplitude of these fluctuations decreases exponentially over time. In addition to this exponential decay, we identify an algebraic tail that emerges at larger time scales. This algebraic behavior can be attributed to the existence of tiny islands embedded within the chaotic sea. Our conclusions are supported by a variety of numerical methods, which validate the observed phenomena. \n\nThe finite-time Lyapunov exponent, a concept introduced by Wolf et al., has gained significant traction in recent research due to its ability to quantify the divergence or convergence of nearby trajectories over a specified time interval, T. For two closely positioned points, \\( x_0 = x(t_0) \\) and \\( y_0 = x(t_1) \\), where \\( t_0 < t_1 \\), the separation after time T can be expressed in relation to the maximum Lyapunov exponent, \\( \\lambda_{max} > 0 \\), which characterizes the rate of divergence between these trajectories. To compute the FTLE, one must solve a variational equation involving the Jacobian matrix associated with the dynamical flow. When the initial condition \\( z_0 = x_{t_0} + \\epsilon y_{t_0} \\) is sufficiently close to the reference trajectory, the solution can be approximated using a Taylor polynomial expansion of the evolution function. This approach allows for the determination of the FTLE, providing insights into the underlying dynamics of chaotic systems. Our research contributes to a deeper understanding of the intricate behavior of chaotic orbits and the role of tiny islands in the chaotic landscape.",
        "ori-fast-z-score": -2.3728949893812477,
        "water-fast-z-score": 4.913538149119954,
        "rewrite-fast-z-score": 0.5477225575051661
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dangling-bond spin relaxation and magnetic 1/f noise from the amorphous-semiconductor/oxide interface: Theory .\nAbstract:\nWe present an analytical theory for the low-frequency (1/f) spin-noise power spectrum in disordered semiconductor-oxide interfaces, which is dominated by dangling bond spins at the oxide/semiconductor interface. The model takes into account both electron-phonon scattering processes that lead to spin dephasing as well as phonon-assisted tunneling between localized states near the Fermi level. We show that this leads to a characteristic temperature dependence of the 1/ƒ-noise amplitude with two distinct regimes separated by a crossover temperature T*. Below T* we find a linear increase of the noise amplitude with decreasing temperature, while above T* it decreases exponentially. This behavior can be explained within our model using only one fitting parameter, namely the density of dangling bonds at the interface. Our results are consistent with recent experiments on SiO2/Si-interfaces. \n \n Introduction \n \n In recent years there has been growing interest in understanding the origin of the ubiquitous 1/f noise observed in many different physical systems ranging from electronic devices  1  over biological  2  to geological  3  ones. While its microscopic origins remain unclear  4  , several theoretical models have been proposed  5-7  . Among these, the so-called  disordered semiconductor-oxide interface model   8  provides a simple explanation for the experimentally observed universal scaling properties  9  of the noise amplitude A(T), i.e., the fact that A(T) ~ T-1/2 below some crossover temperature T* and decays exponentially above T*  10  . However, so far no detailed quantitative comparison between experiment and theory exists  11  .\n \nIn this Letter we provide such a comparison based on a generalization of the original model  12  taking into account phonon-assisted tunnel transitions between localized states close to the Fermi energy  13  . Using only one free parameter, namely the density nD of dangling bonds at or near the interface, we obtain excellent agreement with experimental data obtained on Si-SiO2 interfaces  14  . \n \n Model description \n \n As shown schematically in Fig. 1a , the basic idea behind the disordered semiconductor-oxide interface model is that the dominant source of",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dangling - bond spin relaxation and magnetic 1 / f noise from the amorphous - semiconductor / oxide interface : Theory . Abstract : We present an analytical theory for the small - frequency ( 1 / f ) spinning - noise power spectrum in disordered semiconductor - oxide interfaces , which is dominated by dangling bond loops at the oxide / semiconductor interface .The model takes into consideration both electron - phonon absorption processes that lead to spin dephasing as well as phonon - aided tunneling between localized states near the Fermi level . We see that this results to a peculiar temperature dependence of the 1 / ƒ - noise amplitude with two different regimes separated by a crossover temperature T * .Below T * we find a linear expansion of the signal amplitude with varying temperature , while above T * it decreases exponentially . This phenomenon can be described within our model utilizing only one fit parameter , namely the density of dangling bonds at the interface .Our results are compatible with recent experiments on SiO2 / Si - connections . Introduction In recent seasons there has been growing interest in understanding the origin of the ubiquitous 1 / f noise observed in multiple diverse physical structures ranging from electronic machines 1 over biological 2 to geological 3 ones .While its microscopic origins seem unclear 4 , various theoretical theories have been proposed 5 - 7 . Among these , the so - called disordered semiconductor - oxide interface model 8 gives a simple explanation for the experimentally seen universal scaling behavior 9 of the noise amplitude A ( T ) , i . e . , the fact that A ( T ) ~ T - 1 / 2 below some crossover pressure T * and decays exponentially above T * 10 .However , so far no comprehensive empirical comparison between experiment and theory exists 11 . In this Letter we provide such a comparison based on a generalization of the previous study 12 taking into consideration phonon - aided tunnel transitions between scattered states close to the Fermi energy 13 .Using only one free parameter , namely the density nD of dangling bonds at or near the interface , we obtain excellent agreement with theoretical data derived on Si - SiO2 interfaces 14 . Model description As given schematically in Fig .1a , the fundamental idea behind the disordered semiconductor - oxide interface model is that the dominant source of",
        "rewrite_text": "**Title:** Dangling-Bond Spin Relaxation and Magnetic 1/f Noise from the Amorphous-Semiconductor/Oxide Interface: Theory\n\n**Abstract:** In this study, we develop an analytical framework to explain the low-frequency (1/f) noise power spectrum observed in disordered semiconductor-oxide interfaces, which is primarily influenced by dangling bond loops at the oxide/semiconductor boundary. Our model incorporates both electron-phonon absorption mechanisms that contribute to spin dephasing and phonon-assisted tunneling between localized states situated near the Fermi level. This leads to a distinctive temperature dependence of the 1/f noise amplitude, characterized by two distinct regimes separated by a crossover temperature, T*. Below T*, we observe a linear increase in noise amplitude with temperature, while above T*, the amplitude exhibits an exponential decline. Remarkably, this behavior can be effectively described using a single fitting parameter: the density of dangling bonds at the interface. Our theoretical predictions align well with recent experimental findings related to SiO2/Si junctions.\n\nThe phenomenon of 1/f noise has garnered significant attention across various fields, including electronics, biology, and geology, due to its pervasive nature. Despite the unclear microscopic origins of this noise, numerous theoretical models have been proposed to elucidate its behavior. Among these, the disordered semiconductor-oxide interface model offers a straightforward explanation for the observed universal scaling of noise amplitude, A(T), which follows the relationship A(T) ~ T^(-1/2) below the crossover temperature T* and decreases exponentially above this threshold. However, a comprehensive empirical validation of this model against experimental data has been lacking. In this letter, we present a detailed comparison between our theoretical framework and experimental observations, extending previous studies by incorporating phonon-assisted tunneling transitions between localized states near the Fermi energy. By utilizing a single free parameter, the density of dangling bonds (nD) at or near the interface, we achieve remarkable concordance with experimental results obtained from Si-SiO2 interfaces, thereby reinforcing the validity of our model.",
        "ori-fast-z-score": -0.07738232325341368,
        "water-fast-z-score": 7.560864148142503,
        "rewrite-fast-z-score": 1.2048289933537484
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Predictions from non trivial Quark-Lepton complementarity .\nAbstract:\nWe present here the predictions for the decay rates and CP asymmetries in B decays into two vector mesons, based on the assumption that there is no direct coupling between quarks and leptons at low energies.  We show how this hypothesis leads to relations among different observables which are not predicted by the Standard Model (SM). These relations can be tested experimentally with high precision using data collected at LHCb or Belle II experiments. \nThe results presented here have been obtained within an effective field theory framework where we assume that all new physics effects appear only through higher dimensional operators suppressed by inverse powers of some large scale M . The leading order contributions to these operators come from integrating out heavy degrees of freedom such as W , Z bosons and top quark. In our analysis we consider both tree-level and loop-induced processes. Our main focus has been put on the study of rare B decays involving one photon and one lepton pair in the final state.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Predictions from non trivial Quark - Lepton complementarity . Abstract : We present here the estimates for the decay rates and CP asymmetries in B decays into two matrix mesons , based on the assumption that there is no direct correlation between quarks and leptons at low energies .We see how this hypothesis helps to relations among different observables which are not anticipated by the Standard Model ( SM ) . These relations can be evaluated experimentally with high precision using data taken at LHCb or Belle II experiments .The results presented here have been achieved within an efficient field theory framework where we suppose that all new physics phenomena emerge only through higher dimensional operators suppressed by inverse powers of some wide scale M . The leading order contributions to these operators come from combining out heavy degrees of liberty such as W , Z bosons and bottom quark .In our analysis we involve both tree - level and loop - induced processes . Our main attention has been put on the study of rare B decays featuring one photon and one lepton pair in the finished state .",
        "rewrite_text": "In this article, we provide a comprehensive analysis of decay rates and CP asymmetries in B meson decays into two matrix mesons, grounded in the premise that there is no direct correlation between quarks and leptons at low energy scales. This assumption allows us to derive novel relationships among various observables that are not predicted by the Standard Model (SM). These relationships can be tested with high precision through experimental data collected from the LHCb and Belle II collaborations. Our findings are formulated within an effective field theory framework, where we posit that all new physics phenomena manifest through higher-dimensional operators that are suppressed by the inverse powers of a large scale, denoted as M. The leading contributions to these operators arise from integrating out heavy degrees of freedom, including W and Z bosons, as well as the bottom quark. In our investigation, we consider both tree-level and loop-induced processes, focusing particularly on rare B decays that result in a final state comprising one photon and a lepton pair. This study not only enhances our understanding of B meson decays but also provides a pathway for exploring potential new physics beyond the Standard Model, thereby opening avenues for future experimental verification and theoretical exploration. The implications of our results could significantly impact the field of particle physics, particularly in the context of CP violation and the interplay between quark and lepton sectors.",
        "ori-fast-z-score": -1.7888543819998317,
        "water-fast-z-score": 2.7777777777777777,
        "rewrite-fast-z-score": 0.29851115706299675
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The standard model on a domain-wall brane? .\nAbstract:\nWe consider the Standard Model (SM) in 5 dimensions, where one extra dimension is compactified to an orbifold S 1 /Z 2 . The SM fields are assumed to be localized at different fixed points along this extra dimension. We show that such models can naturally explain why there should exist three generations of fermions and gauge bosons with their observed masses and mixings. In addition we find that these models provide new ways for understanding some other issues related to the SM like neutrino mass generation or flavor changing neutral currents. Finally we discuss how our results could be tested experimentally. Introduction: One of the most important open questions in particle physics today concerns the origin of fermion families and their mixing angles. It has been known since the work by Pati & Salam  1  , that if quarks and leptons were unified into larger multiplets then it would be possible to understand the pattern of quark-lepton masses and mixings within Grand Unified Theories (GUTs). However, despite many attempts over more than 30 years no realistic GUT has yet been constructed which incorporates all the features of the Standard Model (SM).\nIn recent years another possibility was suggested  2  -  4  : If the SM fields live in higher dimensional space-time, they may have Kaluza-Klein excitations corresponding to additional states with masses of order 1/R, where R denotes the size of the extra dimensions. These states might correspond to heavy particles beyond those present in the SM spectrum. This idea leads to interesting phenomenological consequences  5  .\nThe simplest way to realize this scenario is to assume that only gravity propagates in the bulk while the SM fields are confined to a four-dimensional  brane   6  . Such theories lead to corrections to the Newtonian potential between two test masses m 1 and m 2 separated by distance r given by: \nwhere M P l = 1/ √ 8πG N ≈ 10 19 GeV is the reduced Planck scale and n i counts the number of extra spatial dimensions accessible to field i. For distances smaller than about 0.1 mm deviations from the inverse square law predicted by general relativity will become",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The basic model on a domain - wall brane ? .Abstract : We consider the Standard Model ( SM ) in 5 dimensions , where one extra dimension is compactified to an orbifold S 1 / Z 2 . The SM fields are expected to be localized at different fixed points along this extra dimension .We see that such theories can naturally explain why there should exist three generations of fermions and gauge bosons with their observed masses and mixings . In addition we find that these models bring fresh ways for explaining some other issues related to the SM like neutrino mass development or color shifting neutral currents .Finally we talk how our findings may be evaluated experimentally . Introduction : One of the most important open questions in particle science today issues the origin of fermion families and their mixing angles .It has been known since the paper by Pati & Salam 1 , that if quarks and leptons were organized into larger multiplets then it would be possible to explain the trend of quark - lepton masses and mixings within Grand Unified Theories ( GUTs ) . However , despite many efforts over more than 30 centuries no realistic GUT has already been constructed which includes all the details of the Standard Model ( SM ) .In recent work another possibility was suggested 2 - 4 : If the SM fields reside in larger dimensional space - time , they may have Kaluza - Klein excitations corresponding to extra states with masses of order 1 / R , where R denotes the height of the extra dimensions . These states could belong to heavy ions beyond those present in the SM spectrum .This idea results to useful phenomenological consequences 5 . The shortest way to realize this situation is to assume that only gravitational propagates in the bulk while the SM fields are confined to a four - dimensional brane 6 .Such theories lead to corrections to the Newtonian potential between two test masses m 1 and m 2 separated by distance r given by : where M P l = 1 / √ 8πG N ≈ 10 19 GeV is the reduced Planck scale and n i counts the number of extra spatial dimensions accessible to field i . For distances smaller than about 0 . 1 mm deviations from the inverse square law predicted by particular relativity will become",
        "rewrite_text": "**Title:** The Basic Model on a Domain-Wall Brane\n\n**Abstract:** In this study, we investigate the implications of the Standard Model (SM) extended to five dimensions, where one additional dimension is compactified into an orbifold S^1/Z_2. We propose that the SM fields are localized at distinct fixed points along this extra dimension, which provides a natural framework for explaining the existence of three generations of fermions and gauge bosons, along with their observed masses and mixing patterns. Our analysis reveals that these higher-dimensional theories offer novel insights into several unresolved issues within the SM, such as the generation of neutrino masses and the phenomenon of color-shifting neutral currents. Furthermore, we discuss the potential experimental evaluations of our findings, emphasizing how they could be tested in current and future particle physics experiments. \n\nThe introduction highlights a significant challenge in particle physics: understanding the origin of fermion families and their mixing angles. Previous work, notably by Pati and Salam, suggested that organizing quarks and leptons into larger multiplets could elucidate the relationships between quark-lepton masses and mixings within Grand Unified Theories (GUTs). However, despite extensive research over the past three decades, a comprehensive GUT that fully incorporates the intricacies of the SM remains elusive. Recent studies have proposed an alternative approach, suggesting that if SM fields exist in a higher-dimensional spacetime, they may exhibit Kaluza-Klein excitations that correspond to additional states with masses on the order of 1/R, where R represents the scale of the extra dimension. These states could include heavy particles not accounted for in the conventional SM spectrum, leading to significant phenomenological implications. \n\nTo realize this scenario, we assume that only gravitational interactions propagate in the bulk, while the SM fields are confined to a four-dimensional brane. This framework results in modifications to the Newtonian gravitational potential between two test masses, m_1 and m_2, separated by a distance r. Notably, for distances smaller than approximately 0.1 mm, deviations from the inverse square law predicted by special relativity become significant, paving the way for potential experimental verification of our theoretical predictions.",
        "ori-fast-z-score": 2.182820625326997,
        "water-fast-z-score": 8.433802953476238,
        "rewrite-fast-z-score": 2.417468892076141
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Correlations between X-ray Spectral and Timing Characteristics in Cyg X-2 .\nAbstract:\nWe have analyzed the spectral and timing properties of Cygnus X-2 using data obtained with the Rossi X-ray Timing Explorer (RXTE). The source was observed for about 100 ks during 1996-1997, when it showed strong aperiodic variability on time scales ranging from milliseconds to hours. We find that the power density spectrum can be described by two components; one is flat below 10 Hz and another has an index of -1 above this frequency. In addition we detect quasi-periodic oscillations at frequencies around 300 Hz which are coherent over several hundred seconds. Using these results as input parameters into our model fitting procedure, we obtain good fits to both the energy spectra and the light curves simultaneously. Our best-fit models show that there exists a correlation between the temperature of the Comptonizing plasma and its optical depth. This result suggests that the hot plasma responsible for the hard X-ray emission may also produce soft photons through thermal bremsstrahlung or synchrotron radiation.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Correlations between X - ray Spectral and Timing Characteristics in Cyg X - 2 . Abstract : We have analyzed the spectral and timing features of Cygnus X - 2 using data acquired with the Rossi X - ray Timing Explorer ( RXTE ) .The source was seen for about 100 ks during 1996 - 1997 , when it showed good aperiodic variability on time ranges ranging from milliseconds to hours . We see that the power density spectrum can be described by two parts ; one is flat below 10 Hz and another has an index of - 1 above this frequency .In addition we locate quasi - periodic oscillations at speeds around 300 Hz which are coherent over numerous hundred moments . Using these results as input parameters into our model matching methodology , we obtain good fits to both the power spectra and the light surfaces continuously .Our best - fitting models show that there exists a correlation between the temperature of the Comptonizing plasma and its optical thickness . This result suggests that the hot plasma responsible for the hard X - ray radiation may also generate dark photons through cooling bremsstrahlung or synchrotron emission .",
        "rewrite_text": "**Title:** Correlations between X-ray Spectral and Timing Characteristics in Cyg X-2\n\n**Abstract:** In this study, we investigate the spectral and timing characteristics of Cygnus X-2, utilizing data obtained from the Rossi X-ray Timing Explorer (RXTE) during the observational period of 1996-1997, which encompassed approximately 100 kiloseconds of observation. Throughout this timeframe, Cygnus X-2 exhibited significant aperiodic variability across a wide range of timescales, from milliseconds to hours. Our analysis reveals that the power density spectrum of the source can be effectively divided into two distinct components: a flat region observed below 10 Hz and a second region characterized by a spectral index of -1 at higher frequencies. Furthermore, we identify quasi-periodic oscillations occurring at approximately 300 Hz, which demonstrate coherence over several hundred cycles. By incorporating these findings into our model fitting approach, we achieve satisfactory representations of both the power spectra and the light curves. Notably, our optimal models indicate a correlation between the temperature of the Comptonizing plasma and its optical thickness. This correlation implies that the high-temperature plasma responsible for the emission of hard X-ray radiation may also produce dark photons through mechanisms such as cooling bremsstrahlung or synchrotron radiation. These insights contribute to a deeper understanding of the physical processes at play in Cygnus X-2 and highlight the intricate relationships between its spectral and timing properties.",
        "ori-fast-z-score": -0.3375263702778072,
        "water-fast-z-score": 5.222222222222222,
        "rewrite-fast-z-score": 0.40406101782088427
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the Structure and Properties of Differentially Rotating Main-Sequence Stars in the 1-2 M_sun Range .\nAbstract:\nWe present new results on the structure, rotation profiles, and magnetic activity of main-sequence stars with masses between 1 and 2 solar masses (M_sun). We use high-resolution spectropolarimetric observations obtained at the Canada-France-Hawaii Telescope to study the surface differential rotation of these stars as well as their large-scale magnetic fields. Our sample consists of eight young active stars that are members of open clusters or associations within 100 pc of Earth. The observed rotational periods range from 0.5 days up to several weeks. Using Zeeman-Doppler imaging techniques we reconstruct maps of the stellar surfaces for each star showing both the distribution of the longitudinal component of the magnetic field vector and the local line-of-sight velocity. These maps reveal significant differences among our targets. Some show strong toroidal components while others have more complex structures dominated by poloidal fields. In addition, some objects exhibit large regions where the magnetic field is nearly aligned with the axis of rotation.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the Structure and Properties of Differentially Rotating Main - Sequence Stars in the 1 - 2 M _ sunshine Range . Abstract : We report new data on the composition , rotation features , and magnetic activity of primary - sequence stars with masses between 1 and 2 solar masses ( M _ sun ) .We use large - resolution spectropolarimetric studies obtained at the Canada - France - Hawaii Telescope to study the surface differential rotation of these stars as also as their large - scale magnetic fields . Our specimen consists of eight young active galaxies that are part of close complexes or associations within 100 pc of Earth .The observed rotational intervals varied from 0 . 5 weeks up to several weeks . Using Zeeman - Doppler imaging method we reconstruct mapping of the stellar surfaces for each star representing both the distribution of the longitudinal component of the magnetic field vector and the local point - of - view velocity .These projections demonstrate considerable variations among our objectives . Some show strong toroidal components while others have more sophisticated components dominated by poloidal fields .In addition , some elements exhibit big regions where the magnetic force is almost oriented with the axis of rotation .",
        "rewrite_text": "We present new findings on the composition, rotational characteristics, and magnetic activity of main-sequence stars with masses ranging from 1 to 2 solar masses (M☉). Utilizing high-resolution spectropolarimetric observations conducted at the Canada-France-Hawaii Telescope, we investigate the surface differential rotation and large-scale magnetic fields of these stars. Our study focuses on a sample of eight young, active stars located within 100 parsecs of Earth, which are part of close complexes or associations. The observed rotational periods for these stars vary significantly, spanning from 0.5 weeks to several weeks. Employing the Zeeman-Doppler imaging technique, we have reconstructed detailed maps of the stellar surfaces for each star, illustrating both the distribution of the longitudinal component of the magnetic field vector and the local line-of-sight velocity. The resulting projections reveal substantial variations among the stars in our sample. Some exhibit pronounced toroidal magnetic field components, while others display more complex configurations dominated by poloidal fields. Furthermore, certain stars feature extensive regions where the magnetic field aligns closely with the rotation axis. These findings enhance our understanding of the magnetic and rotational dynamics of differentially rotating main-sequence stars, shedding light on the underlying mechanisms that govern their magnetic activity and rotational behavior. This research contributes to the broader field of stellar astrophysics by providing insights into the interplay between rotation and magnetic fields in young stars, which may have implications for our understanding of stellar evolution and the formation of planetary systems.",
        "ori-fast-z-score": -3.180532891463978,
        "water-fast-z-score": 4.411706913966163,
        "rewrite-fast-z-score": -0.5262348115842176
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dynamical non-axisymmetric instabilities in rotating relativistic stars .\nAbstract:\nWe study the dynamical stability properties of rapidly-rotating, axisymmetric neutron star models with different equations of state (EOS). We find that for all EOS considered here, there is an instability associated to the presence of toroidal magnetic fields which can be excited by differential rotation between core and crust regions. The growth timescale of this instability ranges from 10-100 ms depending on the strength of the field and the degree of differential rotation present initially. \n \n This instability may have important consequences for magnetar flares as well as for the spin evolution of young pulsars. In particular we show how it could lead to rapid spindowns during the first few hundred milliseconds after birth if the initial conditions are such that the unstable mode has a large enough amplitude. Finally, we discuss possible observational signatures of these instabilities. Dynamical non-axisymmetric modes in rapidly-rotating relativistic stars",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dynamical non - axisymmetric instabilities in rotating relativistic stars . Abstract : We research the dynamical stability properties of quickly - spinning , axisymmetric neutron star models with various equations of state ( EOS ) .We see that for all EOS considered here , there is an instability related to the presence of toroidal magnetic fields which can be excited by differential rotation between core and crust regions . The growth timescale of this instability vary from 10 - 100 ms based on the strength of the field and the degree of differential rotation present initially .This instability may have important implications for magnetar flares as also as for the spin development of young pulsars . In particular we show how it could lead to rapid spindowns during the first few hundred milliseconds after born if the first environments are such that the unstable mode has a large enough amplitude .Finally , we explain possible observational signatures of these instabilities . Dynamical non - axisymmetric systems in rapidly - spinning relativistic stars",
        "rewrite_text": "Title: Dynamical Non-Axisymmetric Instabilities in Rotating Relativistic Stars\n\nAbstract: This study investigates the dynamical stability characteristics of rapidly rotating, axisymmetric neutron star models across a range of equations of state (EOS). Our findings reveal that all EOS examined exhibit a notable instability associated with the presence of toroidal magnetic fields, which can be triggered by differential rotation between the core and crust regions of the star. The timescale for the growth of this instability is observed to vary between 10 to 100 milliseconds, depending on the intensity of the magnetic field and the extent of the initial differential rotation. This instability could have significant consequences for the mechanisms behind magnetar flares and the spin evolution of young pulsars. Specifically, we demonstrate that if the initial conditions favor a sufficiently large amplitude of the unstable mode, it may result in rapid spin-down events occurring within the first few hundred milliseconds following the star's formation. Additionally, we discuss potential observational signatures that could indicate the presence of these instabilities in astrophysical settings. Our research highlights the importance of understanding dynamical non-axisymmetric systems in the context of rapidly spinning relativistic stars, as they may play a crucial role in the evolution and behavior of such celestial objects.",
        "ori-fast-z-score": 0.8307471607356973,
        "water-fast-z-score": 5.032769329433615,
        "rewrite-fast-z-score": -0.8340576562282991
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Opposite magnetic polarity of two photospheric lines in single spectrum of the quiet Sun .\nAbstract:\nWe report on an observation made with the Hinode satellite that shows opposite magnetic polarities for two photospheric spectral lines (Fe I 630 nm and Fe I 525 nm) within one spatial resolution element at disk center. The observed phenomenon is explained by assuming that the line-of-sight component of the velocity field has opposite signs between these two lines, which can be caused by convective motions or by horizontal flows along the solar surface. This finding may have important implications to our understanding of the solar magnetism. \n \n We present observations obtained with the Solar Optical Telescope aboard Hinode (SOT; Tsuneta et al., 2008). In particular we use data taken during the first year of operation of SOT/SP (Solar Photometer), which consists of a spectrograph equipped with a slit scanning system. The SP instrument was designed primarily as a high-resolution imaging spectrometer but it also provides full-disk Stokes profiles of several photospheric lines simultaneously. For this study we used the Fe I 630 nm and FeI 525 nm lines, whose wavelengths are close enough so they appear together in each scan. These lines were scanned over a region of about 1 arcmin square centered around the solar disk center. Each scan took about 20 minutes to complete.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Opposite magnetic polarity of two photospheric lines in single spectrum of the quiet Sun . Abstract : We report on an observation made with the Hinode satellite that displays opposite magnetic polarities for two photospheric spectral lines ( Fe I 630 nm and Fe I 525 nm ) within one spatial resolution element at disk center .The observed phenomenon is explained by assuming that the line - of - view component of the velocity field has opposite signs between these two lines , which can be caused by convective movements or by horizontal flows along the solar surface . This fact might have important implications to our knowing of the solar magnetism .We report observations collected with the Solar Optical Telescope aboard Hinode ( SOT ; Tsuneta et al . , 2008 ) . In particular we using data taken during the first year of operation of SOT / SP ( Solar Photometer ) , which consists of a spectrograph equipped with a slit scan system .The SP instrument was built mainly as a high - resolution optical spectrometer but it also provides whole - disk Stokes profiles of several photospheric lines simultaneously . For this study we using the Fe I 630 nm and FeI 525 nm lines , whose wavelengths are close enough so they appear together in each scan .These lines were scanned over a region of about 1 arcmin square centered around the solar disk center . Each scan took about 20 minutes to complete .",
        "rewrite_text": "In this study, we present observations obtained from the Hinode satellite, revealing the presence of opposite magnetic polarities in two photospheric spectral lines—Fe I at 630 nm and Fe I at 525 nm—within a single spatial resolution element at the solar disk center. This intriguing phenomenon is interpreted through the lens of the line-of-sight component of the velocity field, which exhibits opposing signs for the two spectral lines. Such behavior may arise from convective motions or horizontal flows occurring along the solar surface, suggesting a complex interplay of dynamics that could significantly enhance our understanding of solar magnetism.\n\nThe data utilized in this research were collected using the Solar Optical Telescope (SOT) aboard Hinode, specifically during the initial year of operation of the SOT's Solar Photometer (SP) instrument. The SP is designed as a high-resolution optical spectrometer and is capable of capturing whole-disk Stokes profiles for multiple photospheric lines simultaneously. For our analysis, we focused on the Fe I 630 nm and Fe I 525 nm lines, which are sufficiently close in wavelength to be recorded together in each scan. The observational scans were conducted over a region approximately 1 arcminute square, centered on the solar disk, with each scan requiring around 20 minutes to complete.\n\nThe findings of this study not only highlight the intricate nature of magnetic fields in the quiet Sun but also underscore the potential for further investigations into the dynamics of solar magnetism. The implications of these observations may pave the way for a deeper comprehension of the underlying mechanisms that govern solar activity and its influence on the heliosphere.",
        "ori-fast-z-score": 2.5495097567963927,
        "water-fast-z-score": 5.562630415806639,
        "rewrite-fast-z-score": 2.37346441585572
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Very Massive Stars in High-Redshift Galaxies .\nAbstract:\nWe present the discovery and analysis of two very massive stars (VMS) at z ~ 6, one with M = 260M☉ and another with M = 300M☉ . These are among the most massive known VMSs to date. We use near-infrared integral field spectroscopy obtained with SINFONI on the Very Large Telescope to study their kinematics and chemical composition. The stellar masses inferred for these objects suggest that they may be progenitors of supermassive black holes. This is consistent with our finding that both sources show evidence for outflows driven by radiation pressure. Our results demonstrate how high-redshift galaxies can provide important insights into the formation mechanisms of the first generation of massive stars as well as the growth of supermassive black hole seeds. Keywords: Black Hole Growth; First Stars; Galaxy Evolution; Stellar Population Studies; Supermassive Black Holes; Star Formation",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Very Massive Stars in High - Redshift Galaxies . Abstract : We report the discovery and investigation of two very huge objects ( VMS ) at z ~ 6 , one with M = 260M☉ and another with M = 300M☉ .These are among the most large reported VMSs to date . We use near - infrared integral field spectroscopy received with SINFONI on the Very Large Telescope to study their kinematics and chemical composition .The stellar masses inferred for these objects suggest that they may be progenitors of supermassive black holes . This is consistent with our discovery that both sources show proof for outflows driven by radiation stress .Our results show how high - redshift galaxies can provide important knowledge into the formation factors of the first generation of large galaxies as also as the development of supermassive black hole trees . Keywords : Black Hole Growth ; First Stars ; Galaxy Evolution ; Stellar Population Studies ; Supermassive Black Holes ; Star Formation",
        "rewrite_text": "We present our findings on the discovery and analysis of two exceptionally massive stars (VMS) located in high-redshift galaxies at approximately z ~ 6. The first star has a mass of 260 solar masses (M☉), while the second is even more remarkable, with a mass of 300 M☉. These discoveries represent some of the largest VMS reported in the literature to date. To investigate the kinematics and chemical composition of these stellar objects, we employed near-infrared integral field spectroscopy using the SINFONI instrument on the Very Large Telescope. The stellar mass estimates for these VMS suggest that they could potentially serve as progenitors for supermassive black holes, a hypothesis supported by our observations indicating the presence of outflows driven by radiation pressure in both stars. Our findings underscore the significance of high-redshift galaxies in enhancing our understanding of the formation processes of the first generation of massive galaxies, as well as the evolutionary pathways leading to the development of supermassive black hole populations. This research contributes to the broader discourse on black hole growth, the characteristics of early stellar populations, and the evolutionary dynamics of galaxies in the early universe. The implications of our work extend to the fields of galaxy evolution, stellar population studies, and star formation, providing critical insights into the cosmic history of structure formation. \n\nKeywords: Black Hole Growth; First Stars; Galaxy Evolution; Stellar Population Studies; Supermassive Black Holes; Star Formation.",
        "ori-fast-z-score": -1.0504514628777804,
        "water-fast-z-score": 4.03585624040554,
        "rewrite-fast-z-score": 0.5720775535473553
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Set of equations for transient enhanced diffusion in shallow ion-implanted layers .\nAbstract:\nWe present the set of equations describing the process of transient enhanced diffusion (TED) in shallow implanted layers, which is important to understand and control dopant profiles during semiconductor device fabrication.  The model takes into account both the effects of lattice damage on TED as well as the effect of interstitials generated by the implantation itself. We show that this simple model can explain many experimental observations including the dependence of TED on dose rate, annealing temperature, and annealing time. Finally we use our model to predict the evolution of the dopant profile under different annealing conditions. Transient enhanced diffusion (TED), i.e., the redistribution of dopants after high energy implantation followed by rapid thermal annealing (RTA), has been studied extensively over the past two decades  1  . It is now widely accepted that the main driving force behind TED are point defects created by the implantation  2  , although other mechanisms such as vacancy clustering may also play an important role  3  .\nThe most commonly used models for simulating TED assume that all excess interstitials produced by the implantation are immobile at room temperature  4  . However, recent experiments have shown that some fraction of these interstitials become mobile even before RTA  5  . This mobility leads to additional dopant redistribution  6  . In addition, it was recently found that the amount of interstitials released depends strongly on the implantation dose rate  7, 8  . These results suggest that the current models do not fully capture the physics underlying TED.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Set of equations for transient increased diffusion in superficial ion - implanted layers . Abstract : We present the group of equations explaining the process of transient increased absorption ( TED ) in superficial implanted layers , which is important to comprehend and control dopant profiles during semiconductor device fabrication .The model takes into consideration both the effects of lattice disruption on TED as also as the impact of interstitials generated by the implantation itself . We see that this straightforward model can describe several experimental studies namely the dependence of TED on dose frequency , annealing temperature , and annealing speed .Finally we utilize our model to predict the evolution of the dopant profile under various annealing conditions . Transient increased diffusion ( TED ) , i . e . , the redistribution of dopants after high energy implantation preceded by rapid heat annealing ( RTA ) , has been studied thoroughly over the previous two decades 1 .It is now widely accepted that the main driving force behind TED are point failures created by the implantation 2 , although other mechanisms such as vacancy clustering may also play an important role 3 . The most commonly used theories for simulating TED assume that all excess interstitials produced by the implantation are immobile at room temperature 4 .However , recent experiments have shown that some fraction of these interstitials become mobile even before RTA 5 . This mobility gives to extra dopant redistribution 6 .In addition , it was recently found that the quantity of interstitials released depends strongly on the implantation dose frequency 7 , 8 . These conclusions show that the present theories do not truly capture the physics underlying TED .",
        "rewrite_text": "We present a comprehensive set of equations that elucidate the phenomenon of transient increased diffusion (TED) in shallow ion-implanted layers, which is crucial for understanding and managing dopant profiles during the fabrication of semiconductor devices. Our model incorporates the effects of lattice disruption caused by implantation, as well as the influence of interstitials generated during the implantation process. This straightforward approach effectively describes various experimental observations, including the relationship between TED and factors such as dose frequency, annealing temperature, and annealing rate. \n\nTED, characterized by the redistribution of dopants following high-energy implantation and subsequent rapid thermal annealing (RTA), has been extensively investigated over the past two decades. It is widely recognized that point defects created during implantation serve as the primary driving force behind TED, although mechanisms like vacancy clustering may also contribute significantly. Traditional theories for simulating TED often assume that all excess interstitials produced during implantation remain immobile at room temperature. However, recent experimental findings indicate that a portion of these interstitials can become mobile even prior to RTA, leading to additional dopant redistribution. Furthermore, it has been observed that the amount of interstitials released is highly dependent on the implantation dose frequency.\n\nThese insights suggest that existing theories may not fully capture the underlying physics of TED, highlighting the need for a refined understanding of the mechanisms at play. By employing our model, we aim to predict the evolution of dopant profiles under varying annealing conditions, thereby enhancing the control over semiconductor fabrication processes. This work not only advances the theoretical framework surrounding TED but also provides practical implications for optimizing dopant distribution in semiconductor devices.",
        "ori-fast-z-score": -1.0083683467310325,
        "water-fast-z-score": 6.454545454545454,
        "rewrite-fast-z-score": 1.4852968963237645
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Order of Epitaxial Self-Assembled Quantum Dots: Linear Analysis .\nAbstract:\nWe present an analysis of the linear stability of epitaxially self-assembled quantum dots (QDs) on semiconductor surfaces, which are grown by molecular beam epitaxy under conditions where QDs form spontaneously and in regular arrays. We show that the QD ordering is determined by two competing mechanisms: surface diffusion and strain relaxation. The former tends to smooth out the QD density profile while the latter leads to its steepening. In particular we find that for small values of the QD size dispersion there exists a critical value of the growth rate above which ordered QD arrays cannot be formed. This result explains why it has been so difficult to grow ordered QD arrays with large QD sizes using conventional techniques. \n \n Keywords: Ordering, Strain Relaxation, Surface Diffusion, Quantum Dot Arrays, Stability, Growth Rate, Molecular Beam Epitaxy \n \n 1 Introduction \n \n Semiconductor nanocrystals or quantum dots (QDs), also known as colloidal quantum dots, have attracted considerable attention due to their unique optical properties  1  . They can be used in optoelectronic devices such as light-emitting diodes  2  , lasers  3  , solar cells  4  , photodetectors  5  , etc., and they may even play important roles in biological systems  6  .\n \nThe most common method for growing QDs is based on the so-called Stranski-Krastanov process  7, 8  . It involves depositing a thin layer of material onto a substrate at high temperatures followed by annealing at lower temperatures. Under these conditions islands nucleate randomly over the entire sample area but then evolve into ordered arrays through Ostwald ripening  9  . However, this technique does not allow one to control the position of individual QDs within each array  10  . Recently developed methods  11, 12  enable us to produce highly ordered QD arrays; however, they require very precise temperature control during deposition  13  . \n \n 2 Model Description \n \n Here we consider a model describing the formation of QDs on a two-dimensional lattice. Our starting point is the continuum equation proposed by Tersoff et al.  14  :",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Order of Epitaxial Self - Assembled Quantum Dots : Linear Analysis . Abstract : We present an assessment of the linear stability of epitaxially self - assembled quantum dots ( QDs ) on semiconductor surfaces , which are grown by molecular beam epitaxy under environments where QDs form spontaneously and in regular arrays .We see that the QD ordering is chosen by two different processes : surface convection and tension relaxation . The first prefers to soft out the QD density profile while the former results to its steepening .In particular we find that for low values of the QD diameter dispersion there exists a critical value of the development frequency above which ordered QD arrays cannot be formed . This result explains why it has been so difficult to grow ordered QD arrays with large QD sizes using conventional methods .Keywords : Ordering , Strain Relaxation , Surface Diffusion , Quantum Dot Arrays , Stability , Growth Rate , Molecular Beam Epitaxy 1 Introduction Semiconductor nanocrystals or quantum dots ( QDs ) , sometimes called as colloidal quantum dots , have garnered considerable scrutiny due to their extraordinary optical properties 1 . They can be used in optoelectronic devices such as light - emitting diodes 2 , lasers 3 , solar cells 4 , photodetectors 5 , etc . , and they may even hold important roles in biological environments 6 .The most common method for growing QDs is based on the so - called Stranski - Krastanov process 7 , 8 . It involves depositing a thin layer of material onto a substrate at high temperatures followed by annealing at lower temperatures .Under these conditions islands nucleate randomly over the entire sample region but then evolve into organized arrays through Ostwald ripening 9 . However , this methodology does not enable one to affect the orientation of individual QDs within each array 10 .Recently developed methods 11 , 12 enable us to produce fully ordered QD arrays ; however , they use very accurate temperature regulation during deposition 13 . 2 Model Description Here we imagine a description explaining the formation of QDs on a two - dimensional lattice .Our starting point is the continuum equation proposed by Tersoff et al . 14 :",
        "rewrite_text": "**Title: Order of Epitaxial Self-Assembled Quantum Dots: Linear Analysis**\n\n**Abstract:** This study evaluates the linear stability of epitaxially self-assembled quantum dots (QDs) on semiconductor surfaces, specifically those produced through molecular beam epitaxy in environments conducive to spontaneous formation and regular arrangement of QDs. Our findings indicate that the ordering of QDs is influenced by two primary mechanisms: surface convection and tension relaxation. Surface convection tends to smooth the density profile of QDs, while tension relaxation leads to a more pronounced steepening of this profile. Notably, we identify a critical frequency of development for low dispersion in QD diameters, beyond which the formation of ordered QD arrays becomes unfeasible. This insight elucidates the challenges associated with the conventional growth of large-sized ordered QD arrays. \n\nQuantum dots, also known as semiconductor nanocrystals or colloidal quantum dots, have attracted significant attention due to their remarkable optical characteristics, making them suitable for various optoelectronic applications, including light-emitting diodes, lasers, solar cells, and photodetectors. The predominant technique for QD growth is the Stranski-Krastanov process, which involves the deposition of a thin material layer onto a substrate at elevated temperatures, followed by a lower temperature annealing phase. This process leads to the random nucleation of islands across the sample, which subsequently evolve into organized arrays through Ostwald ripening. However, this traditional approach does not allow for control over the orientation of individual QDs within the arrays. Recent advancements have introduced methods that facilitate the production of fully ordered QD arrays, albeit requiring precise temperature control during deposition. \n\nIn this paper, we propose a model that describes the formation of QDs on a two-dimensional lattice, beginning with the continuum equation established by Tersoff et al. Our analysis aims to deepen the understanding of the factors influencing QD ordering and stability, ultimately contributing to the development of more effective growth techniques for quantum dot applications. \n\n**Keywords:** Ordering, Strain Relaxation, Surface Diffusion, Quantum Dot Arrays, Stability, Growth Rate, Molecular Beam Epitaxy.",
        "ori-fast-z-score": -0.7579367289598671,
        "water-fast-z-score": 5.268324663044671,
        "rewrite-fast-z-score": 1.7561082210148906
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Inflationary de Sitter solutions from superstrings .\nAbstract:\nWe present the first exact solution for inflation in string theory, which is based on an explicit compactification to four dimensions with N=1 supergravity and chiral matter fields. The model contains two scalar fields, one of them being responsible for slow-roll inflation driven by its potential energy density. We show that this field can be identified as the inflaton. In addition we find another scalar field whose kinetic term has negative sign. This field may play the role of dark radiation during inflation. Finally, we discuss some phenomenological consequences of our results. Introduction: Inflation  1  provides a simple explanation for many puzzles associated with the early universe such as flatness, homogeneity and horizon problems  2  . It also predicts primordial fluctuations  3  , which are now confirmed by observations  4  .\nThe simplest models of inflation involve only one scalar field (inflaton) rolling slowly down its potential  5  . However it was shown recently  6  that there exist more general classes of inflationary scenarios where several scalars contribute to the total energy density driving inflation  7, 8  . These new possibilities open up interesting avenues towards understanding the physics behind inflation  9  .\nIn particular, if at least one of these scalars has positive kinetic energy then it leads to so-called k-inflation  10  . On the other hand, if all the scalars have negative kinetic energies they lead to so-called ghost inflation  11  . Both types of inflation were studied extensively in recent years  12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59  .\nIt should be noted however that most of these studies assume that the background geometry is given by Minkowski space-time or anti-de Sitter space-time  60, 61, 62, 63, 64, 65,",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Inflationary de Sitter solutions from superstrings . Abstract : We introduce the first accurate solution for inflation in string theory , which is based on an explicit compactification to four dimensions with N = 1 supergravity and chiral matter fields .The model includes two scalar fields , one of them being involved for slow - roll inflation driven by its potential energy density . We see that this field can be identified as the inflaton .In addition we find another scalar field whose kinetic term has negative sign . This field might play the part of dark energy during inflation .Finally , we explain some phenomenological consequences of our findings . Introduction : Inflation 1 offers a simple explanation for numerous puzzles involved with the early universe such as flatness , homogeneity and horizon problems 2 .It additionally predicts primordial fluctuations 3 , which are now confirmed by observed 4 . The simplest models of inflation include only one scalar field ( inflaton ) floating gradually down its potential 5 .However it was shown ago 6 that there exist more general categories of inflationary scenarios where numerous scalars relate to the total energy density driving inflation 7 , 8 . These new possibilities open up interesting avenues towards studying the physics behind inflation 9 .In particular , if at least one of these scalars has favorable kinetic power then it leads to so - called k - inflation 10 . On the other hand , if all the scalars have negative kinetic energies they lead to so - called ghost inflation 11 .Both types of inflation were studied frequently in recent seasons 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 . It should be mentioned however that most of these research assume that the background geometry is given by Minkowski space - time or anti - de Sitter space - time 60 , 61 , 62 , 63 , 64 , 65 ,",
        "rewrite_text": "**Title:** Inflationary de Sitter Solutions from Superstrings\n\n**Abstract:** In this paper, we present the first precise solution for inflation within the framework of string theory, achieved through an explicit compactification to four dimensions utilizing N = 1 supergravity alongside chiral matter fields. Our model incorporates two scalar fields, with one scalar field identified as the inflaton, which facilitates slow-roll inflation driven by its potential energy density. The second scalar field, characterized by a negative kinetic term, may serve as a candidate for dark energy during the inflationary phase. We further explore the phenomenological implications of our findings, shedding light on the potential interactions and dynamics of these fields in the context of inflationary cosmology. \n\nThe phenomenon of inflation provides a compelling resolution to several fundamental issues associated with the early universe, including the flatness, homogeneity, and horizon problems. Additionally, inflation predicts the existence of primordial fluctuations, which have been corroborated by observational data. Traditional inflationary models typically involve a single scalar field (the inflaton) that gradually descends its potential. However, it has been established that more complex inflationary scenarios can arise when multiple scalar fields contribute to the total energy density driving inflation. This opens new pathways for investigating the underlying physics of inflation. \n\nIn particular, scenarios where at least one scalar field possesses a favorable kinetic term lead to what is known as k-inflation, while models where all scalar fields exhibit negative kinetic energies give rise to ghost inflation. Both k-inflation and ghost inflation have been the subject of extensive research in recent years. It is important to note that much of the existing literature assumes a background geometry of either Minkowski or anti-de Sitter spacetime. Our work aims to expand the understanding of inflationary dynamics by integrating string theory into this framework, thereby providing a more comprehensive view of the inflationary epoch and its implications for the evolution of the universe.",
        "ori-fast-z-score": -0.7071067811865475,
        "water-fast-z-score": 5.1946603473211805,
        "rewrite-fast-z-score": 2.1972288386821304
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Bianchi Model CMB Polarization and its Implications for CMB Anomalies .\nAbstract:\nWe present the results of our analysis on the polarization power spectrum in Bianchi type I cosmological models, which are anisotropic generalizations of standard FRW cosmologies. We find that there is no significant difference between the temperature fluctuations predicted by these two classes of models at large angular scales (low multipoles). However, we show that this is not true when one considers the polarization fluctuations. In particular, we demonstrate that the presence of an anisotropy parameter leads to a suppression of the low-l polarization power relative to the high-l part of the spectrum. This effect can be used as a test for distinguishing Bianchi type I models from their FRW counterparts. \n \n The observed lack of large-scale polarization in the WMAP data has been interpreted as evidence against inflationary scenarios with tensor perturbations. It was shown recently that such a conclusion may be premature if one takes into account possible deviations from statistical isotropy in the primordial universe. Indeed, it turns out that some anisotropic cosmological models predict less large-scale polarization than their isotropic counterparts do.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Bianchi Model CMB Polarization and its Implications for CMB Anomalies . Abstract : We present the conclusion of our analysis on the polarization power spectrum in Bianchi class I cosmological models , which are anisotropic generalizations of standard FRW cosmologies .We see that there is no major variation between the temperature fluctuations assumed by these two groups of models at large angular scales ( low multipoles ) . However , we prove that this is not true when one considers the polarization fluctuations .In particular , we prove that the presence of an anisotropy parameter causes to a suppression of the small - l polarization strength compared to the high - l part of the spectrum . This phenomenon can be used as a check for differentiate Bianchi class I systems from their FRW rivals .The observed lack of large - scale polarization in the WMAP information has been viewed as proof against inflationary scenarios with tensor perturbations . It was shown lately that such a conclusion must be premature if one takes into consideration likely deviations from statistical isotropy in the primordial universe .Indeed , it turns out that some anisotropic cosmological predictions predict less large - scale polarization than their isotropic counterparts do .",
        "rewrite_text": "We provide a comprehensive analysis of the polarization power spectrum within Bianchi class I cosmological models, which serve as anisotropic extensions of the standard Friedmann-Robertson-Walker (FRW) cosmologies. Our findings indicate that, at large angular scales (low multipoles), there is minimal difference in temperature fluctuations between Bianchi models and their FRW counterparts. However, this similarity does not extend to polarization fluctuations. We demonstrate that the inclusion of an anisotropy parameter leads to a notable suppression of small-l polarization strength when compared to the high-l portion of the spectrum. This characteristic can serve as a distinguishing feature to differentiate Bianchi class I models from FRW models. \n\nThe observed scarcity of large-scale polarization in the data from the Wilkinson Microwave Anisotropy Probe (WMAP) has been interpreted as evidence against inflationary models that incorporate tensor perturbations. Recent studies suggest that this interpretation may be overly simplistic, particularly when accounting for potential deviations from statistical isotropy in the early universe. Our research reveals that certain anisotropic cosmological models predict a lower level of large-scale polarization than their isotropic equivalents. This finding has significant implications for the understanding of cosmic microwave background (CMB) anomalies and the broader context of cosmological inflation. By exploring the polarization characteristics of Bianchi class I models, we contribute to the ongoing discourse regarding the nature of the early universe and the validity of various cosmological theories.",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 5.20847435706514,
        "rewrite-fast-z-score": -0.20203050891044214
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Quantization of soliton systems and Langlands duality .\nAbstract:\nWe study the quantization of soliton systems in terms of their associated integrable hierarchies, which are infinite-dimensional Lie algebras with an underlying Poisson structure.  We show that these hierarchies can be realized as certain coadjoint orbits of loop groups over complex semisimple Lie groups.   The resulting quantum theories have many interesting features including nontrivial anomalies and non-perturbative effects such as instantons.    In particular we find that the partition functions for these models are closely related to automorphic forms on the corresponding groups; this is known as the Langlands correspondence between representations of the two groups.   This provides a new perspective on the relationship between gauge theory and string theory; it also suggests a possible connection between the Standard Model and M-theory. Solitons play important roles in physics ranging from condensed matter to particle and nuclear physics. They appear naturally in various physical contexts where nonlinear interactions occur, e.g., in fluid dynamics or field theories describing particles interacting via Yukawa potentials (e.g., quarks). A particularly rich class of solitonic solutions arises when one considers integrable systems whose equations of motion admit Lax pairs. These systems include classical mechanics, relativistic field theories, and supersymmetric Yang-Mills theories. Integrability implies that there exist infinitely many conserved quantities and allows us to construct exact solutions using inverse scattering techniques. It has been shown recently by Witten  1  , however, that even though most physically relevant systems cannot be solved exactly, they may still exhibit some aspects of integrability at the quantum level. For example, the low-energy effective action of N = 4 super-Yang-Mills theory is described by an integrable system  2  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Quantization of soliton systems and Langlands duality . Abstract : We research the quantization of soliton systems in terms of their associated integrable hierarchies , which are infinite - dimensional Lie algebras with an underlying Poisson system .We see that these hierarchies can be realized as certain coadjoint orbits of loop groups over complex semisimple Lie groups . The resulting quantum models have many interesting features including nontrivial anomalies and non - perturbative properties such as instantons .In particular we find that the splitting maps for these models are tightly related to automorphic forms on the associated groups ; this is known as the Langlands correspondence between representations of the two groups . This offers a new insight on the relationship between gauge theory and string theory ; it also supports a possible link between the Standard Model and M - theory .Solitons serve important roles in science extending from condensed matter to particle and nuclear mechanics . They arise naturally in different physical contexts where nonlinear interactions occur , e . g . , in fluid dynamics or field theories describing particles communicating via Yukawa potentials ( e . g . , quarks ) .A notably rich group of solitonic solutions arises when one considers integrable systems whose equations of movement accept Lax pairs . These systems include classical mechanics , relativistic field theories , and supersymmetric Yang - Mills theories .Integrability implies that there exist infinitely many conserved particles and allows us to obtain exact solutions using inverse scattering methods . It has been shown lately by Witten 1 , however , that even though most legally applicable systems cannot be solved exactly , they may still exhibit some parts of integrability at the quantum level .For instance , the small - energy effective operation of N = 4 super - Yang - Mills theory is characterized by an integrable system 2 .",
        "rewrite_text": "In this article, we explore the quantization of soliton systems through their associated integrable hierarchies, which are infinite-dimensional Lie algebras characterized by an underlying Poisson structure. Our investigation reveals that these hierarchies can be represented as specific coadjoint orbits of loop groups associated with complex semisimple Lie groups. The quantum models derived from this framework exhibit a range of intriguing features, including the presence of nontrivial anomalies and non-perturbative phenomena such as instantons. Notably, we establish a close relationship between the splitting maps of these models and automorphic forms on the corresponding groups, which aligns with the Langlands correspondence that connects representations of the two groups. This relationship provides fresh insights into the interplay between gauge theory and string theory, potentially illuminating connections between the Standard Model of particle physics and M-theory.\n\nSolitons play a crucial role across various scientific disciplines, from condensed matter physics to particle and nuclear mechanics. They emerge naturally in diverse physical scenarios characterized by nonlinear interactions, such as fluid dynamics and field theories that describe particle interactions via Yukawa potentials, exemplified by quarks. A particularly rich class of solitonic solutions is found in integrable systems whose equations of motion can be expressed in terms of Lax pairs. These systems encompass classical mechanics, relativistic field theories, and supersymmetric Yang-Mills theories. The property of integrability ensures the existence of infinitely many conserved quantities, facilitating the derivation of exact solutions through inverse scattering techniques. Recent work by Witten has highlighted that, despite the inability to solve most physically relevant systems exactly, they may still exhibit integrable characteristics at the quantum level. For example, the low-energy effective action of N=4 super-Yang-Mills theory is identified as an integrable system, further emphasizing the significance of integrability in contemporary theoretical physics.",
        "ori-fast-z-score": 0.2526455763199557,
        "water-fast-z-score": 5.642417871145677,
        "rewrite-fast-z-score": -0.939793423488437
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Optical investigations of quantum-dot spin dynamics .\nAbstract:\nWe report on the optical investigation of single self-assembled InAs/GaAs quantum dots (QDs) in an external magnetic field applied along their growth direction. The QD emission line splits into two components with opposite circular polarization when the magnetic field is increased to about 1 T, which corresponds to the Zeeman splitting energy of 0.5 meV at 4 K. We observe that this splitting increases linearly as temperature decreases down to 20 mK and then saturates below 10 mK. This behavior can be explained by taking into account both electron-hole exchange interaction and phonon-assisted relaxation processes between different excitonic states within QDs. Our results show that the spin-flip time for electrons confined inside QDs is longer than 100 ns even under high magnetic fields up to 5 T. Quantum dot (QD), also known as semiconductor nanocrystal or artificial atom, has attracted much attention due to its unique physical properties such as size-tunable band gap  1  , strong confinement effect  2  , and large oscillator strength  3  . These features make it possible to use QDs as building blocks for various optoelectronic devices including light-emitting diodes  4  , lasers  5  , solar cells  6  , photodetectors  7  , and so forth  8  .\nIn recent years, there have been many efforts devoted to investigating the spin dynamics of carriers confined in QDs  9  -  11  . It was found that the carrier spins are very stable against decoherence caused by environmental noise  12  -  14  . However, the spin flip times were reported to vary widely depending on experimental conditions  15  -  17  . For example, the spin lifetimes of holes  18  and electrons  19  confined in QDs were measured to be several nanoseconds using pulsed excitation techniques. On the other hand, the spin lifetime of electrons  20  and holes  21  confined in QDs could reach microsecond level if continuous wave laser was used instead.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Optical studies of quantum - dot spinning dynamics . Abstract : We report on the optical study of single self - assembled InAs / GaAs quantum dots ( QDs ) in an external magnetic force applied along their growth direction .The QD radiation line splits into two parts with opposite circular polarization when the magnetic force is expanded to about 1 T , which corresponds to the Zeeman splitting energy of 0 . 5 meV at 4 K . We see that this splitting changes linearly as temperature grows down to 20 mK and then saturates below 10 mK . This phenomenon can be described by take into consideration both electron - hole exchange interaction and phonon - aided relaxation processes between various excitonic states within QDs .Our results show that the spin - flip time for electrons concentrated inside QDs is longer than 100 ns even under high magnetic waves up to 5 T . Quantum dot ( QD ) , sometimes called as semiconductor nanocrystal or artificial electron , has garnered great attention due to its unique physical properties such as size - tunable band gap 1 , large confinement phenomenon 2 , and large oscillator strength 3 . These features make it able to use QDs as building blocks for various optoelectronic equipment including light - emitting diodes 4 , lasers 5 , solar cells 6 , photodetectors 7 , and so forth 8 .In recent years , there have been many efforts devoted to investigating the spin behavior of carriers restricted in QDs 9 - 11 . It was shown that the carrier spins are very stable against decoherence caused by environmental interference 12 - 14 .However , the spin flip times were reported to vary widely depending on experimental environments 15 - 17 . For instance , the spin lifetimes of holes 18 and electrons 19 restricted in QDs were calculated to be several nanoseconds using pulsed excitation techniques .On the other hand , the spin lifetime of atoms 20 and holes 21 confined in QDs might reach microsecond level if continuous wave beam was used instead .",
        "rewrite_text": "**Title:** Optical Studies of Quantum-Dot Spinning Dynamics\n\n**Abstract:** In this study, we present an in-depth optical investigation of individual self-assembled InAs/GaAs quantum dots (QDs) subjected to an external magnetic field aligned with their growth axis. Our findings reveal that the emission spectrum of the QDs exhibits a splitting into two distinct components with opposite circular polarization when the magnetic field strength reaches approximately 1 T, corresponding to a Zeeman splitting energy of 0.5 meV at a temperature of 4 K. Notably, we observe that this splitting varies linearly with temperature, decreasing to 20 mK, after which it stabilizes below 10 mK. This behavior can be effectively explained by considering both the electron-hole exchange interactions and phonon-assisted relaxation mechanisms among the various excitonic states present within the QDs. Our results indicate that the spin-flip time for electrons localized within the QDs exceeds 100 ns, even under the influence of high magnetic fields up to 5 T. Quantum dots, often referred to as semiconductor nanocrystals or artificial atoms, have attracted significant interest due to their remarkable physical characteristics, including a size-tunable band gap, pronounced confinement effects, and substantial oscillator strength. These properties render QDs suitable for a range of optoelectronic applications, such as light-emitting diodes, lasers, solar cells, and photodetectors. Recent research has increasingly focused on the spin dynamics of carriers confined within QDs, demonstrating that these spins exhibit considerable stability against decoherence induced by environmental factors. However, reported spin flip times have shown considerable variability based on experimental conditions. For example, spin lifetimes for holes and electrons in QDs have been measured in the nanosecond range using pulsed excitation methods, while continuous wave techniques have yielded spin lifetimes for atoms and holes that can extend to the microsecond scale. This study contributes to the understanding of spin dynamics in quantum dots and their potential applications in future quantum technologies.",
        "ori-fast-z-score": 0.32659863237109044,
        "water-fast-z-score": 6.488856845230502,
        "rewrite-fast-z-score": -0.08084520834544433
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The distance and neutral environment of the massive stellar cluster Westerlund 1 .\nAbstract:\nWe present new near-infrared photometry for the open cluster Westerlund 1, which is located in the Galactic bulge at a distance of 8 kpc (projected). We find that the red giant branch tip lies at K = 12.6 mag, corresponding to an age of about 10 Gyrs. The main sequence turn-off point occurs around K = 14.5 mag, indicating an age between 5 and 7 Gyrs. This places it among the oldest open clusters known. Using our data we derive a mean metallicity  Fe/H  = -1.3 ± 0.1 dex. From this value and using theoretical models we estimate the mass of the most massive star in the cluster as Mmax = 120 - 140M⊙. In addition, we have obtained deep optical images with HST/ACS/WFC2 covering the central region of the cluster. These reveal several dozen very bright stars within a radius of only 20 arcsec.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The distance and neutral environment of the huge stellar cluster Westerlund 1 . Abstract : We create latest near - infrared photometry for the open cluster Westerlund 1 , which is situated in the Galactic bulge at a distance of 8 kpc ( projected ) .We see that the red giant branch tip occurs at K = 12 . 6 mag , corresponding to an age of about 10 Gyrs . The main series turn - off position occurs around K = 14 . 5 mag , representing an age between 5 and 7 Gyrs .This places it among the earliest open clusters recorded . Using our information we derive a mean metallicity Fe / H = - 1 . 3 ± 0 . 1 dex .From this value and using theoretical models we estimate the mass of the most massive star in the cluster as Mmax = 120 - [UNK] . In addition , we have obtained deep optical images with HST / ACS / WFC2 covering the central region of the cluster .These suggest several several very bright stars within a diameter of only 20 arcsec .",
        "rewrite_text": "**Title:** The Distance and Neutral Environment of the Massive Stellar Cluster Westerlund 1\n\n**Abstract:** In this study, we present the most recent near-infrared photometric observations of the open cluster Westerlund 1, located in the Galactic bulge at a projected distance of approximately 8 kiloparsecs. Our analysis reveals that the tip of the red giant branch is observed at K = 12.6 magnitudes, indicating an estimated age of around 10 billion years. Additionally, the main sequence turn-off point is identified at K = 14.5 magnitudes, suggesting a younger age range of 5 to 7 billion years. These findings position Westerlund 1 among the oldest open clusters documented to date. Utilizing our data, we calculate a mean metallicity of [Fe/H] = -1.3 ± 0.1 dex. This metallicity value, in conjunction with theoretical stellar evolution models, allows us to estimate the mass of the most massive star within the cluster to be approximately Mmax = 120 solar masses. Furthermore, we have acquired deep optical images using the Hubble Space Telescope's Advanced Camera for Surveys (ACS) Wide Field Channel 2 (WFC2), which cover the central region of Westerlund 1. These images reveal several exceptionally bright stars within a compact area of just 20 arcseconds in diameter. Our findings contribute to the understanding of the stellar population and evolutionary history of Westerlund 1, highlighting its significance as a key object of study in the context of stellar formation and cluster dynamics in the Galactic bulge.",
        "ori-fast-z-score": -2.629502940535666,
        "water-fast-z-score": 1.885618083164127,
        "rewrite-fast-z-score": -0.6255432421712244
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Suggestions on photons and fermions .\nAbstract:\nThe author suggests that the concept of  photon  is not necessary, because it can be explained by other concepts such as  wave particle duality  or  duality  in general.  The author also suggests that the concept of  free electron  should be replaced with the concept of  fermion  which has more physical meaning than free electrons do. Finally he proposes to use the term  quantum fields  instead of quantum particles for describing elementary particles. This article was originally published at http://arxiv.org/abs/physics/0407033 . It may have been updated since then; please check the original version s date before citing. Authors:  Toshihide Maskawa (Masatoshi Koshiba) - Professor Emeritus, University of Tokyo \n \n \n \n Abstract: \nThe author suggests that the idea of photon is unnecessary, because it can be understood by other concepts like wave-particle duality or dualities in general. He also suggests replacing the concept of  free-electron  with the concept of  fermion  which has more physical meaning. Finally he proposes using the term  quatum-fields  instead of quatum-particles for describing elementary particles.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Suggestions on photons and fermions . Abstract : The author argues that the notion of photon is not required , because it can be described by other concepts such as wave particle duality or duality in general .The author also concludes that the notion of free particle should be replaced with the notion of fermion which has more physical purpose than free electrons do . Finally he proposes to use the term quantum fields instead of quantum particles for describing elementary particles .This section was originally published at http : / / arxiv . org / abs / physics / 0407033 . It might have been altered since then ; please check the original version s date before citing .Authors : Toshihide Maskawa ( Masatoshi Koshiba ) - Professor Emeritus , University of Tokyo Abstract : The author argues that the idea of photon is unnecessary , because it can be understood by other concepts like wave - particle duality or dualities in general . He also supports replacing the notion of free - atom with the notion of fermion which has more physical purpose .Finally he proposes using the term quatum - fields instead of quatum - particles for describing elementary particles .",
        "rewrite_text": "Title: Suggestions on Photons and Fermions\n\nAbstract: In this article, the author presents a compelling argument for the reconsideration of the concept of the photon, suggesting that it is not an essential construct in the realm of physics. Instead, the phenomena typically attributed to photons can be effectively described through alternative frameworks, such as wave-particle duality and various forms of duality. This perspective challenges the traditional understanding of light and its interactions, advocating for a more nuanced interpretation that transcends the need for a distinct photon entity.\n\nFurthermore, the author critiques the conventional notion of free particles, particularly free electrons, proposing that this concept should be supplanted by the more physically relevant idea of fermions. This shift emphasizes the importance of fermions in the context of quantum mechanics and particle physics, highlighting their role in the fundamental structure of matter.\n\nIn addition to these conceptual shifts, the author recommends adopting the terminology of \"quantum fields\" in place of \"quantum particles\" when discussing elementary particles. This change in language reflects a deeper understanding of the underlying principles of quantum field theory, which posits that particles are excitations of underlying fields rather than discrete entities.\n\nThis article, originally published on arXiv (http://arxiv.org/abs/physics/0407033), invites readers to reconsider established notions in physics and encourages further exploration of these ideas. The insights provided by the author, Toshihide Maskawa, Professor Emeritus at the University of Tokyo, contribute to ongoing discussions in the field and may inspire new avenues of research. Please verify the original publication date before referencing this work, as it may have undergone revisions since its initial release.",
        "ori-fast-z-score": 1.5460413650478515,
        "water-fast-z-score": 6.037034299432969,
        "rewrite-fast-z-score": 1.6164477182409742
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cluster abundances and S-Z power spectra: effects of non-Gaussianity and early dark energy .\nAbstract:\nWe study the effect on cluster abundance and Sunyaev-Zeldovich (SZ) power spectrum due to primordial non-Gaussianity in the context of inflationary models with an additional scalar field, which is responsible for driving cosmic acceleration at late times. We find that the SZ power spectrum can be used as a probe of both primordial non-Gaussianity and dark energy properties such as equation-of-state parameter w0 and its time-derivative wa. In particular we show how these parameters affect the amplitude and shape of the SZ power spectrum. The results are presented using a simple analytical model based on perturbation theory upto second order. This work will help us understand better the nature of dark energy by combining it with other probes like supernovae Ia data or CMB anisotropy measurements. It also provides useful information about the physics of inflation through primordial non-Gaussianity. Introduction:-Inflation  1  , one of the most successful paradigms in modern cosmology, predicts a nearly scale-invariant Gaussian distribution of density fluctuations  2  . However recent observations  3  have shown some deviations from this prediction indicating possible presence of primordial non-Gaussianities  4  .\nIn addition to explaining the origin of large-scale structure formation  5  , inflation has been proposed  6  as a mechanism for generating the observed accelerated expansion of the universe  7, 8  . Inflationary scenarios predict that there should exist another light scalar field besides inflaton  9  , called quintessence  10  , which drives the current accelerating phase of the universe  11  . Quintessential inflation  12  is a class of inflationary models where the role played by the inflaton during inflation is taken over by quintessence after inflation ends  13  . These two fields interact minimally  14  leading to interesting consequences  15  . For example, if the potential of quintessence is sufficiently flat then it may lead to eternal inflation  16  . If so, then our observable patch of the universe would correspond only to a tiny fraction of all space-time  17  . Another possibility is that the quintessence field decays into radiation  18  thereby reheating the universe  19  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cluster abundances and S - Z power spectra : effects of non - Gaussianity and early dark energy . Abstract : We research the impact on cluster abundance and Sunyaev - Zeldovich ( SZ ) power spectrum attributed to primordial non - Gaussianity in the context of inflationary theories with an additional scalar field , which is responsible for driving cosmic acceleration at late times .We see that the SZ power spectrum can be used as a investigation of both primordial non - Gaussianity and dark energy properties such as equation - of - state variable w0 and its time - derivative wa . In particular we find how these parameters control the frequency and shape of the SZ power spectrum .The results are presented using a simple analytical theory based on perturbation theory upto second order . This effort will assist us explain better the nature of dark energy by combining it with other probes like supernovae Ia data or CMB anisotropy observations .It additionally offers helpful info about the physics of inflation through primordial non - Gaussianity . Introduction : - Inflation 1 , one of the most innovative paradigms in modern cosmology , predicts a nearly scale - invariant Gaussian distribution of density fluctuations 2 .However latest measurements 3 have shown some deviations from this forecast suggesting possible presence of primordial non - Gaussianities 4 . In addition to describing the origin of large - scale system formation 5 , inflation has been proposed 6 as a process for generating the seen accelerated expansion of the universe 7 , 8 .Inflationary scenarios predict that there should exist another light scalar field besides inflaton 9 , called quintessence 10 , which drives the present accelerating phase of the universe 11 . Quintessential inflation 12 is a class of inflationary theories where the part played by the inflaton during inflation is taken over by quintessence after inflation ends 13 .These two fields interact minimally 14 resulting to unusual consequences 15 . For instance , if the potential of quintessence is sufficiently straight then it could lead to eternal inflation 16 .If so , then our observable patch of the universe might correspond only to a small fraction of all space - time 17 . Another possibility is that the quintessence field decays into radiation 18 effectively reheating the universe 19 .",
        "rewrite_text": "**Title:** Cluster Abundances and S-Z Power Spectra: Effects of Non-Gaussianity and Early Dark Energy\n\n**Abstract:** This study investigates the effects of primordial non-Gaussianity on cluster abundance and the Sunyaev-Zeldovich (SZ) power spectrum within the framework of inflationary theories that incorporate an additional scalar field responsible for the late-time cosmic acceleration. Our findings indicate that the SZ power spectrum serves as a valuable tool for probing both primordial non-Gaussianity and the characteristics of dark energy, specifically the equation-of-state parameters \\( w_0 \\) and its time derivative \\( w_a \\). We demonstrate how these parameters influence the frequency and shape of the SZ power spectrum, providing insights into the underlying physics of dark energy. The analysis is grounded in a straightforward analytical approach based on second-order perturbation theory. This work aims to enhance our understanding of dark energy by integrating it with other observational data, such as Type Ia supernovae and cosmic microwave background (CMB) anisotropy measurements. Furthermore, it sheds light on the physics of inflation through the lens of primordial non-Gaussianity.\n\n**Introduction:** Inflation, a groundbreaking concept in contemporary cosmology, posits a nearly scale-invariant Gaussian distribution of density fluctuations. However, recent observations have revealed deviations from this prediction, suggesting the possible existence of primordial non-Gaussianities. Beyond elucidating the formation of large-scale structures, inflation is also proposed as a mechanism for the observed accelerated expansion of the universe. Theories of inflation predict the presence of an additional light scalar field, known as quintessence, which governs the current phase of cosmic acceleration. Quintessential inflation represents a class of inflationary models where the role of the inflaton during the inflationary epoch is succeeded by quintessence post-inflation. The interaction between these two fields is minimal, leading to intriguing implications. For instance, if the quintessence potential is sufficiently flat, it may result in eternal inflation, suggesting that our observable universe is merely a small segment of a much larger cosmic expanse. Alternatively, the quintessence field could decay into radiation, effectively reheating the universe.",
        "ori-fast-z-score": -0.3223291856101521,
        "water-fast-z-score": 7.14865202723224,
        "rewrite-fast-z-score": -0.08084520834544433
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Watermark Embedding and Detection .\nAbstract:\nIn this work, we propose an efficient watermarking scheme for digital images based on the discrete wavelet transform (DWT). The proposed method embeds the watermark into the high-frequency sub-bands by modifying their coefficients using a quantization index modulation technique. In order to detect the embedded watermark in the attacked image, we use a correlation detector with a threshold value that is determined adaptively according to the local statistics of each block. Experimental results show that our algorithm has good performance against various attacks such as JPEG compression, salt & pepper noise addition, Gaussian filtering, cropping, rotation, scaling, blurring, sharpening, histogram equalization, gamma correction, median filter, and mean filter. Keywords: Watermarking; Discrete Wavelet Transform; Quantization Index Modulation; Adaptive Threshold Value. Digital watermarking technology can be used to protect copyrights or prevent illegal distribution of digital content. However, it may also cause some problems if the watermarks are not detected correctly due to intentional or unintentional attacks. Therefore, robustness should always be considered when designing any watermarking system.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Watermark Embedding and Detection . Abstract : In this study , we propose an efficient watermarking scheme for digital photographs relying on the discrete wavelet transition ( DWT ) .The proposed approach embeds the watermark into the high - frequency sub - bands by modifying their parameters using a quantization index modulation method . In order to identify the embedded watermark in the captured image , we utilize a correlation detector with a threshold value that is calculated adaptively based to the local statistics of each block .Experimental findings show that our technique has good success against several attacks such as JPEG compression , salt & pepper noise addition , Gaussian filtering , cropping , rotation , scaling , blurring , sharpening , histogram equalization , alpha reduction , median filter , and mean filter . Keywords : Watermarking ; Discrete Wavelet Transform ; Quantization Index Modulation ; Adaptive Threshold Value .Digital watermarking technology can be used to shield copyrights or avoid illegal collection of digital content . However , it could also create some problems if the watermarks are not observed correctly due to deliberate or unintentional attempts .Therefore , robustness should always be regarded when designing any watermarking scheme .",
        "rewrite_text": "**Title: Watermark Embedding and Detection**\n\n**Abstract:** This paper presents a novel and effective watermarking technique specifically designed for digital images, utilizing the discrete wavelet transform (DWT) as its foundational framework. Our method strategically embeds watermarks into the high-frequency sub-bands of the image by adjusting their parameters through a quantization index modulation approach. To facilitate the detection of the embedded watermark in the processed images, we implement a correlation detection mechanism that employs an adaptive threshold value, which is dynamically calculated based on the local statistical properties of each image block. The robustness of our watermarking scheme is rigorously evaluated through a series of experiments, demonstrating its resilience against a wide array of common image processing attacks. These include JPEG compression, the addition of salt and pepper noise, Gaussian filtering, cropping, rotation, scaling, blurring, sharpening, histogram equalization, alpha reduction, and the application of median and mean filters. The results indicate that our proposed method maintains a high level of watermark integrity and visibility, even when subjected to these various distortions. Digital watermarking serves as a crucial tool for protecting copyrights and preventing unauthorized use of digital content. However, it is essential to address potential issues that may arise from improper watermark detection, whether due to intentional manipulation or inadvertent alterations. Therefore, ensuring robustness is a critical consideration in the design of any watermarking system. This study contributes to the ongoing development of watermarking technologies by providing a reliable solution that balances the need for effective copyright protection with the challenges posed by image processing techniques.\n\n**Keywords:** Watermarking; Discrete Wavelet Transform; Quantization Index Modulation; Adaptive Threshold Value.",
        "ori-fast-z-score": -1.3251783128981585,
        "water-fast-z-score": 5.673665146135802,
        "rewrite-fast-z-score": 0.811502671200689
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  CP Violation From Standard Model to Strings .\nAbstract:\nThe standard model (SM) is the most successful theory in particle physics, but it has some problems such as hierarchy problem and CP violation. In this talk I will discuss how we can solve these problems by using string theories. First let us consider the SM with three generations of quarks and leptons. The Yukawa couplings are given by \nwhere  is the Higgs vacuum expectation value,  is the mass matrix for fermions ,  is the CKM mixing matrix , and  is the Kobayashi-Maskawa(KM) matrix . We have two parameters in the KM matrix : one phase which causes CP violation and another parameter called Jarlskog invariant J = Im VudVub * / Re VudIm Vub .\nIn order to explain the observed CP violation in K meson system, we need at least one complex number in the KM matrix. However there are only four real numbers in the Yukawa coupling matrices. This means that we cannot determine all elements of the KM matrix uniquely. Therefore we introduce extra dimensions into our models so that we can obtain more degrees of freedom.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : CP Violation From Standard Model to Strings . Abstract : The standard model ( SM ) is the most popular concept in particle theory , but it has some problems such as hierarchy problem and CP violation .In this talk I will explore how we can answer these problems by using string theories . First let us consider the SM with three generations of quarks and leptons .The Yukawa couplings are given by where is the Higgs vacuum expectation value , is the mass vector for fermions , is the CKM mixing function , and is the Kobayashi - Maskawa ( KM ) matrix . We have two parameters in the KM matrix : one phase which causes CP violation and another parameter called Jarlskog invariant J = Im VudVub * / Re VudIm Vub .In order to explain the observed CP violation in K meson scheme , we require at least one complex number in the KM matrix . However there are only four real numbers in the Yukawa interaction vectors .This implies that we cannot determine all components of the KM matrix uniquely . Therefore we incorporate additional dimensions into our designs so that we can obtain more degrees of freedom .",
        "rewrite_text": "Title: CP Violation: From the Standard Model to String Theory\n\nAbstract: The Standard Model (SM) of particle physics stands as the predominant framework for understanding fundamental particles and their interactions. However, it is not without its challenges, notably the hierarchy problem and the phenomenon of CP violation. This presentation delves into potential resolutions to these issues through the lens of string theory. We begin by examining the SM, which includes three generations of quarks and leptons. The Yukawa couplings, essential for generating fermion masses, are expressed in terms of the Higgs vacuum expectation value, the fermion mass vector, the Cabibbo-Kobayashi-Maskawa (CKM) mixing matrix, and the Kobayashi-Maskawa (KM) matrix itself. Within the KM matrix, two critical parameters emerge: a complex phase responsible for CP violation and the Jarlskog invariant, defined as J = Im(VudVub*) / Re(Vud)Im(Vub). To account for the observed CP violation in the K meson system, it is necessary to introduce at least one complex parameter into the KM matrix. However, the Yukawa interaction vectors only provide four real parameters, leading to an inherent ambiguity in uniquely determining all components of the KM matrix. To address this limitation, we propose the incorporation of additional dimensions into our theoretical framework, thereby increasing the degrees of freedom available for model construction. This approach not only aims to resolve the existing discrepancies within the SM but also seeks to provide a more comprehensive understanding of CP violation through the principles of string theory. By exploring these higher-dimensional constructs, we hope to shed light on the intricate relationship between fundamental particles and the underlying symmetries that govern their behavior, ultimately contributing to a more unified theory of particle physics.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.299831645537222,
        "rewrite-fast-z-score": 1.3750477455423171
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Testing outer boundary treatments for the Einstein equations .\nAbstract:\nWe present results on testing different outer boundary conditions in numerical relativity, using two black hole spacetimes as testbeds.  In particular we consider the case where one or both holes are spinning and use several coordinate systems to evolve these solutions numerically.   We find that the choice of coordinates can have significant effects on the accuracy with which the solution is recovered at large distances from the source region. The most accurate results were obtained by evolving the initial data sets in Kerr-Schild Cartesian coordinates (KSC). However, even when evolved in KSC it was found necessary to impose additional constraints near the outer boundaries in order to obtain stable evolutions over many dynamical timescales. These constraints effectively remove all gravitational radiation from the computational domain. Finally, we also considered an alternative approach based on excision techniques. This method involves removing the interior regions containing singularities from the computational grid and replacing them with suitable analytic expressions.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Testing exterior boundary treatments for the Einstein equations . Abstract : We report findings on proving different exterior boundary conditions in mathematical relativity , using two black hole spacetimes as testbeds .In particular we study the case where one or both holes are twisting and use multiple coordinate networks to evolve these solutions numerically . We see that the selection of coordinates can have considerable effects on the accuracy with which the solve is recovered at large distances from the origin region .The most accurate conclusions were obtained by expanding the early data sets in Kerr - Schild Cartesian coordinates ( KSC ) . However , even when evolved in KSC it was found necessary to apply additional constraints near the exterior boundaries in order to obtain stable evolutions over numerous dynamical timescales .These limitations virtually remove all gravity radiation from the theoretical domain . Finally , we also considered an additional method using on excision techniques .This method means eliminating the interior regions containing singularities from the theoretical grid and combining them with suitable analytic expressions .",
        "rewrite_text": "We present our findings on the evaluation of various exterior boundary conditions within the framework of mathematical relativity, utilizing two distinct black hole spacetimes as experimental models. Our investigation focuses particularly on scenarios where one or both black holes exhibit twisting characteristics. To numerically evolve these solutions, we employ multiple coordinate systems, which reveal that the choice of coordinates significantly influences the precision of the solutions obtained at considerable distances from the central region. Our analysis indicates that the most reliable results were achieved by expanding the initial data sets using Kerr-Schild Cartesian coordinates (KSC). Nevertheless, even with the KSC framework, we discovered that imposing additional constraints near the exterior boundaries was essential to ensure stable evolutions across various dynamical timescales. These constraints effectively eliminate all gravitational radiation from the theoretical domain, posing a challenge for accurate modeling. Furthermore, we explored an alternative approach involving excision techniques, which entails removing the interior regions that contain singularities from the computational grid. This method is complemented by integrating suitable analytic expressions to maintain the integrity of the theoretical framework. Our findings contribute to a deeper understanding of boundary treatments in the context of the Einstein equations and highlight the complexities involved in accurately modeling black hole spacetimes. This work not only advances the field of mathematical relativity but also opens avenues for further research into the implications of boundary conditions on gravitational radiation and the stability of numerical solutions.",
        "ori-fast-z-score": -1.3480372031495529,
        "water-fast-z-score": 6.947576354693849,
        "rewrite-fast-z-score": -0.08944271909999159
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Geometrical properties of local dynamics in Hamiltonian systems: the Generalized Alignment Index (GALI) method .\nAbstract:\nWe present an algorithm for computing geometrical characteristics of chaotic trajectories in dynamical systems, which is based on the concept of the alignment index introduced by S.A. Afraimovich and A.V. Bykov.  The proposed approach allows one to study the geometry of invariant manifolds associated with unstable periodic orbits embedded into the phase space of a given dynamical system. We demonstrate that this new technique can be successfully applied to investigate the structure of strange attractors arising in dissipative systems as well as in conservative ones. In particular, we show how it works for the Lorenz model and the Henon-Heiles potential. \nThe presented results are obtained within the framework of the Russian Science Foundation project 14-50-00040. Geometrical properties of local dynamic in hamiltonian systems: the generalized alignment index (gali) method  V.I. Klimenko1 , D.N. Kozlov2 1 Institute of Mathematics RAS, Moscow, Russia 2 Lomonosov Moscow State University, Moscow, Russia",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Geometrical properties of local dynamics in Hamiltonian systems : the Generalized Alignment Index ( GALI ) method . Abstract : We present an algorithm for modeling geometrical characteristics of turbulent trajectories in dynamical systems , which is based on the idea of the alignment index introduced by S . A . Afraimovich and A . V .Bykov . The proposed approach allows one to study the topology of invariant manifolds associated with unstable periodic orbits embedded into the phase space of a given dynamical system .We suggest that this new technique can be successfully utilized to examine the dynamics of mysterious attractors arising in dissipative models as well as in conservative ones . In particular , we prove how it works for the Lorenz model and the Henon - Heiles potential .The published results are derived within the framework of the Russian Science Foundation program 14 - 50 - 00040 . Geometrical properties of local dynamic in hamiltonian systems : the generalized alignment index ( gali ) method V . I .Klimenko1 , D.N.Kozlov2 1 Institute of Mathematics RAS, Moscow, Russia 2 Lomonosov Moscow State University, Moscow, Russia",
        "rewrite_text": "We introduce a novel algorithm designed to analyze the geometrical features of turbulent trajectories within dynamical systems, building upon the alignment index concept initially proposed by S. A. Afraimovich and A. V. Bykov. This innovative method enables researchers to investigate the topology of invariant manifolds that are linked to unstable periodic orbits situated in the phase space of various dynamical systems. We propose that this technique can be effectively applied to explore the dynamics of enigmatic attractors that emerge in both dissipative and conservative models. To illustrate the efficacy of our approach, we demonstrate its application to the well-known Lorenz model and the Henon-Heiles potential, showcasing its ability to reveal intricate dynamical behaviors. The findings presented in this study are part of the research funded by the Russian Science Foundation under program 14-50-00040. Our work contributes to a deeper understanding of local dynamics in Hamiltonian systems through the Generalized Alignment Index (GALI) method, providing valuable insights into the underlying geometrical properties that govern the behavior of complex dynamical systems. This research not only enhances the theoretical framework surrounding dynamical systems but also opens new avenues for practical applications in various fields of science and engineering.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 3.679023140400945,
        "rewrite-fast-z-score": 0.3144854510165755
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Orbital liquid in ferromagnetic manganites: The orbital Hubbard model for $e_g$ electrons .\nAbstract:\nWe present the results of our study on the electronic structure and magnetic properties of La0.7Sr1.3MnO3 using density functional theory (DFT) calculations within the local spin-density approximation (LSDA). We find that LSDA underestimates the band gap by about 0.5 eV, which is corrected to 1.2 eV when we use the self-interaction correction scheme proposed by Perdew et al.. Our calculated value agrees well with experimental data obtained from optical measurements. In addition, we have studied the effect of electron correlation on the ground state energy as a function of Ueff = U - J where U and J are respectively Coulomb repulsion and exchange parameters between two localized spins. It has been found that the total energy decreases monotonically upto Ueff ~ 3 eV beyond which it increases rapidly indicating strong electron correlations among Mn3+ ions. Finally, we show that the inclusion of spin-orbit coupling leads to an increase in the band gap by about 30%.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Orbital fluid in ferromagnetic manganites : The orbital Hubbard theory for $ e _ g $ electrons . Abstract : We present the results of our research on the electronic configuration and magnetic properties of La0 . 7Sr1 . 3MnO3 using density functional theory ( DFT ) estimates within the local spin - density algorithm ( LSDA ) .We see that LSDA underestimates the band gap by about 0 . 5 eV , which is corrected to 1 . 2 eV when we using the self - interaction correction scheme proposed by Perdew et al . . Our measured value agrees well with theoretical data derived from optical tests . In addition , we have researched the impact of electron correlation on the ground state energy as a function of Ueff = U - J where U and J are respectively Coulomb repulsion and transfer characteristics between two localized spins .It has been seen that the total energy decreases monotonically upto Ueff ~ 3 eV beyond which it rises rapidly indicating strong electron correlations among Mn3 + ions . Finally , we find that the introduction of spin - orbit coupling gives to an increase in the band gap by about 30 % .",
        "rewrite_text": "In this study, we investigate the electronic structure and magnetic characteristics of La0.7Sr1.3MnO3, employing density functional theory (DFT) calculations based on the local spin-density approximation (LSDA). Our findings reveal that the LSDA tends to underestimate the band gap by approximately 0.5 eV. However, when we apply the self-interaction correction method proposed by Perdew et al., the band gap is adjusted to a more accurate value of 1.2 eV, which aligns closely with theoretical predictions obtained from optical measurements. Furthermore, we explore the influence of electron correlation on the ground state energy, analyzing it as a function of the effective interaction parameter Ueff = U - J, where U represents Coulomb repulsion and J denotes the transfer characteristics between two localized spins. Our results indicate that the total energy exhibits a monotonically decreasing trend up to Ueff ~ 3 eV, after which it experiences a rapid increase, suggesting the presence of strong electron correlations among Mn3+ ions. Additionally, we observe that incorporating spin-orbit coupling leads to an approximate 30% increase in the band gap. This research contributes to a deeper understanding of the orbital fluid dynamics in ferromagnetic manganites and highlights the significance of electron correlations and spin-orbit interactions in determining their electronic properties.",
        "ori-fast-z-score": -2.3050494597834974,
        "water-fast-z-score": 2.836832573067901,
        "rewrite-fast-z-score": 0.4
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Planck Scale Unification in a Supersymmetric Standard Model .\nAbstract:\nWe present the results of an analysis of the supersymmetric standard model with minimal supergravity boundary conditions at the grand unification scale, including all one-loop corrections to gauge and Yukawa couplings as well as two-loop contributions to the running of the soft supersymmetry breaking parameters.  We find that this scenario is compatible with current experimental bounds on sparticle masses if tan beta is large (tan beta > 50) or small (tan beta < 10). In addition we show how the lightest Higgs boson mass can be predicted within this framework for any value of tan beta between 1 and 60. Finally, we discuss the implications of our results for future searches for supersymmetry at colliders such as LHC. The supersymmetric standard model has been studied extensively over many years  1  . It provides a natural solution to the hierarchy problem by introducing new particles which cancel quadratic divergences associated with radiative corrections to the scalar potential  2  , while also providing a candidate particle for dark matter  3  .\nIn recent years there have been several studies  4  -  8  investigating whether it is possible to construct models where the electroweak symmetry breaking sector is described by the MSSM  9  but the underlying physics is governed by some more fundamental theory valid at higher energies. This approach is motivated by the fact that the MSSM suffers from fine-tuning problems  10  due to its sensitivity to unknown high-scale physics  11  . If these problems are solved then the MSSM may provide a good description of nature up to very high scales  12  . One possibility would be to embed the MSSM into a Grand Unified Theory  13  based upon SO(10), although other possibilities exist  14  . Another possibility is to consider theories with extra dimensions  15  -  17  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Planck Scale Unification in a Supersymmetric Standard Model . Abstract : We present the results of an assessment of the supersymmetric standard theory with minimal supergravity boundary constraints at the grand unification scale , comprising all one - loop corrections to gauge and Yukawa couplings as well as two - loop contributions to the running of the hard supersymmetry broken equations .We see that this situation is compatible with current experimental bounds on sparticle masses if tan beta is huge ( tan beta > 50 ) or small ( tan beta < 10 ) . In addition we prove how the lightest Higgs boson weight can be predicted within this framework for any value of tan beta between 1 and 60 .Finally , we explain the implications of our findings for future investigations for supersymmetry at colliders such as LHC . The supersymmetric standard theory has been studied thoroughly over numerous years 1 .It provides a natural solution to the hierarchy problem by creating new particles which cancel quadratic divergences associated with radiative corrections to the scalar potential 2 , while also offering a candidate particle for black material 3 . In recent years there have been numerous research 4 - 8 investigating whether it is easy to build theories where the electroweak symmetry breaking sector is described by the MSSM 9 but the underlying physics is governed by some more fundamental theory valid at higher energies .This method is prompted by the fact that the MSSM suffers from fine - tuned difficulty 10 due to its sensitivity to unknown high - scale physics 11 . If these problems are answered then the MSSM could give a better model of nature up to very high scales 12 .One possibility would be to embed the MSSM into a Grand Unified Theory 13 based upon SO ( 10 ) , although other possibilities exist 14 . Another possibility is to consider concepts with extra dimensions 15 - 17 .",
        "rewrite_text": "We present a comprehensive analysis of the supersymmetric standard model (SSM) under minimal supergravity boundary conditions at the grand unification scale. This study incorporates all one-loop corrections to both gauge and Yukawa couplings, as well as two-loop contributions to the evolution of the hard supersymmetry-breaking equations. Our findings indicate that the model remains consistent with current experimental limits on sparticle masses, particularly when the parameter tan beta is either significantly large (tan beta > 50) or notably small (tan beta < 10). Furthermore, we demonstrate that the mass of the lightest Higgs boson can be reliably predicted within this framework for any tan beta value ranging from 1 to 60. \n\nWe also discuss the implications of our results for future research on supersymmetry at high-energy colliders, such as the Large Hadron Collider (LHC). The supersymmetric standard model has been extensively studied over the years, providing a compelling solution to the hierarchy problem by introducing new particles that effectively cancel the quadratic divergences associated with radiative corrections to the scalar potential. Additionally, it offers a viable candidate for dark matter. Recent investigations have focused on constructing theories where the electroweak symmetry breaking sector is described by the minimal supersymmetric standard model (MSSM), while the underlying physics is dictated by a more fundamental theory that operates at higher energy scales. This approach is motivated by the MSSM's fine-tuning issues, which arise from its sensitivity to unknown high-scale physics. Addressing these challenges could enhance the MSSM's viability as a model of nature at very high energy scales. One avenue for exploration is the embedding of the MSSM within a Grand Unified Theory, such as those based on SO(10), although alternative frameworks, including those involving extra dimensions, also warrant consideration.",
        "ori-fast-z-score": -0.0873704056661038,
        "water-fast-z-score": 5.983058789716428,
        "rewrite-fast-z-score": -0.9538209664765319
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Measurement of the production of charged pions by protons on a tantalum target .\nAbstract:\nThe measurement was performed at the Cyclotrons and Accelerators Laboratory (CYCLONE) in JINR, Dubna using the proton beam with energy E = 1 GeV. The experiment was carried out to study the pion production in nuclear reactions induced by relativistic protons on nuclei Ta(p, π+). The experimental setup included two scintillation counters S1 and S2 for registration of particles emitted into forward hemisphere, three plastic scintillator detectors S3-S5 for measuring the angular distribution of secondary particles produced in the reaction under investigation. The results obtained are compared with calculations based on the model developed earlier  1  . \nIntroduction\n\nPion production is one of the most important processes in hadronic interactions which play an essential role in many fields such as astrophysics  2  , cosmic ray physics  3  , accelerator technology  4  etc.. In this work we present new data on the pion production in nuclear collisions induced by relativistic protons interacting with nuclei Ta(p,π + ). These measurements were performed at CYCLONE laboratory in JINR-Dubna  5  .\nExperimental Setup\nThe experimental setup used in our experiments consisted of:  -two scintillation counters S1 and S2; -three plastic scintillator detectors; -a set of collimators; -the target made of natural tantalum foil 0.1 mm thick placed between the first pair of scintillation counters; -the trigger system consisting of four scintillation counters T1-T4. \nThe layout of the experimental setup is shown schematically in Fig. 1 . The main parameters of the detector system are listed in Table I . The signals from all detectors were recorded by means of CAMAC modules  6  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Measurement of the production of charged pions by protons on a tantalum target . Abstract : The measurement was done at the Cyclotrons and Accelerators Laboratory ( CYCLONE ) in JINR , Dubna utilizing the proton beam with energy E = 1 GeV .The project was carried out to study the pion production in nuclear compounds caused by relativistic protons on electrons Ta ( p , π + ) . The experimental setup included two scintillation terminals S1 and S2 for registration of grains generated into front hemisphere , three plastic scintillator detectors S3 - S5 for monitoring the angular distribution of primary nuclei generated in the response under research .The results obtained are compared with methods using on the model derived earlier 1 . Introduction Pion production is one of the most important processes in hadronic interactions which work an essential part in different fields such as astrophysics 2 , cosmic ray physics 3 , accelerator science 4 etc . .In this research we present new data on the pion production in nuclear collisions induced by relativistic protons interacting with nuclei Ta ( p , π + ) . These measurements were performed at CYCLONE laboratory in JINR - Dubna 5 .Experimental Setup The experimental setup used in our experiments included of : - two scintillation counters S1 and S2 ; - three plastic scintillator detectors ; - a pair of collimators ; - the target made of natural tantalum foam 0 . 1 mm thick put between the first pair of scintillation counters ; - the trigger system consisting of four scintillation counters T1 - T4 . The configuration of the experimental setup is displayed schematically in Fig .1 . The main variables of the sensor method are listed in Table I .The signals from all detectors were collected by means of CAMAC modules 6 .",
        "rewrite_text": "**Title:** Measurement of Charged Pion Production by Protons on a Tantalum Target\n\n**Abstract:** This study presents a comprehensive investigation into the production of charged pions resulting from proton interactions with a tantalum target, conducted at the Cyclotrons and Accelerators Laboratory (CYCLONE) in Dubna, JINR. Utilizing a proton beam with an energy of 1 GeV, the research aims to enhance our understanding of pion production mechanisms in nuclear interactions, specifically focusing on the reaction Ta (p, π+). The experimental apparatus comprised two scintillation counters, designated S1 and S2, which were employed to detect particles generated in the forward hemisphere. Additionally, three plastic scintillator detectors, labeled S3 to S5, were utilized to monitor the angular distribution of primary nuclei produced during the interactions under investigation. \n\nThe results obtained from this experiment were systematically compared with predictions derived from previously established models, providing a critical evaluation of the theoretical frameworks in the context of experimental data. Pion production is a fundamental process in hadronic interactions, playing a significant role across various scientific domains, including astrophysics, cosmic ray physics, and accelerator science. \n\nIn this research, we present novel data on pion production in nuclear collisions induced by relativistic protons interacting with tantalum nuclei. The experimental setup was meticulously designed, incorporating two scintillation counters (S1 and S2), three plastic scintillator detectors, a pair of collimators, and a target composed of natural tantalum foam with a thickness of 0.1 mm, strategically positioned between the first pair of scintillation counters. The trigger system was comprised of four scintillation counters (T1 to T4), ensuring precise detection and measurement of the interactions. A schematic representation of the experimental configuration is provided in Fig. 1, while the main variables associated with the sensor methodology are detailed in Table I. The signals from all detectors were efficiently collected using CAMAC modules, facilitating comprehensive data analysis. This research contributes valuable insights into the dynamics of pion production and its implications for various fields of study.",
        "ori-fast-z-score": 0.7559289460184544,
        "water-fast-z-score": 7.118052168020874,
        "rewrite-fast-z-score": 3.404864674003339
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Grand minima and maxima of solar activity: New observational constraints .\nAbstract:\nWe present new results on the long-term evolution of solar magnetic fields, obtained by applying an advanced data analysis technique to observations made with the Wilcox Solar Observatory (WSO) magnetograph between 1976 and 2009. The method is based on wavelet transforms in combination with principal component analysis (PCA). It allows us to separate different types of variability into their individual components at each point in time. We find that there are two distinct modes of solar magnetic field evolution over this period. One mode shows strong fluctuations around a mean value which varies slowly but significantly during the cycle 23/24 minimum. This behaviour can be explained as being due to the presence of large-scale dynamo waves driven by differential rotation. In addition we identify another type of variation which appears to have no preferred frequency or spatial scale. These variations show significant correlations with sunspot number and other proxies for solar activity. They may therefore represent some form of global response of the Sun s magnetic field to changes in its internal dynamics.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Grand minima and maxima of solar activity : New observational restrictions . Abstract : We report new data on the long - term expansion of solar magnetic fields , obtained by using an sophisticated data analysis technique to observations made with the Wilcox Solar Observatory ( WSO ) magnetograph between 1976 and 2009 .The method is based on wavelet transforms in combination with principal component analysis ( PCA ) . It enables us to separate distinct types of variability into their individual parts at each point in time .We see that there are two different modes of solar magnetic force evolution over this time . One mode displays strong fluctuations around a mean value which varies steadily but significantly during the period 23 / 24 minimum .This behaviour can be understood as being owing to the presence of large - scale dynamo waves powered by differential rotation . In addition we identify another type of variation which appears to have no chosen amplitude or spatial scale .These changes demonstrate considerable correlations with sunspot number and other proxies for solar activity . They might hence indicate some kind of worldwide response of the Sun s magnetic force to changes in its internal behavior .",
        "rewrite_text": "**Title:** Grand Minima and Maxima of Solar Activity: New Observational Constraints\n\n**Abstract:** In this study, we present novel findings regarding the long-term evolution of solar magnetic fields, derived from an advanced data analysis technique applied to observations from the Wilcox Solar Observatory (WSO) magnetograph spanning the years 1976 to 2009. Our analytical approach integrates wavelet transforms with principal component analysis (PCA), allowing us to disentangle various types of variability at each temporal point. Our results reveal two distinct modes of solar magnetic force evolution throughout this period. The first mode is characterized by significant fluctuations around a mean value that exhibits a steady yet notable variation during the solar minimum between cycles 23 and 24. This behavior is interpreted as a consequence of large-scale dynamo waves driven by differential rotation within the Sun. The second mode of variation, however, appears to lack a defined amplitude or spatial scale, suggesting a more chaotic nature. Notably, these fluctuations show strong correlations with sunspot numbers and other indicators of solar activity, implying a potential global response of the Sun's magnetic field to internal changes. This research enhances our understanding of solar activity patterns and their implications for solar dynamics, providing critical insights into the mechanisms governing solar magnetic field behavior over extended timeframes.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 6.599750073368524,
        "rewrite-fast-z-score": 0.8620436566990363
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Hybrid inflation followed by modular inflation .\nAbstract:\nWe consider the possibility that our universe underwent two stages of accelerated expansion, first hybrid inflation and then modular inflation.  We show how this scenario can be realized in string theory with an explicit example based on type IIB orientifolds compactified to four dimensions on Calabi-Yau threefolds. In particular we find that there are many possible realizations of such models which lead to realistic values for the cosmological parameters. The model is consistent with all current experimental constraints including those coming from measurements of the cosmic microwave background anisotropies as well as from direct searches at colliders. Finally we discuss some phenomenological aspects of these scenarios. Introduction: Inflationary theories provide one of the most compelling explanations for several puzzles associated with the standard hot big bang cosmology  1  . They predict that primordial quantum fluctuations generated during inflation should have left their imprint on the temperature anisotropies observed today in the Cosmic Microwave Background (CMB)  2  .\nIn recent years it has been shown that supersymmetric grand unified theories (GUTs), like SO(10) , naturally give rise to inflationary potentials  3  , while also providing a successful unification scheme  4  . However, GUT scale inflation suffers from the so-called η-problem  5  : the predicted value of the tensor-to-scalar ratio r = 16ǫ H /η 2  6  leads to too large CMB quadrupole anisotropies  7, 8  unless ǫ H ≪ 1  9  or η ≫ 10 −9  10  . This problem may be alleviated if the inflaton potential contains flat directions  11  . These arise quite generically in supergravity  12  and string theory  13  due to non-perturbative effects  14  . A particularly interesting class of flat directions arises when the gauge group is broken down to its maximal subgroup  15  . Such flat directions were studied extensively in  16  where they were called  moduli  fields since they parametrize the size and shape of extra dimensions  17  . Moduli fields play an important role in string theory  18  because they determine the vacuum expectation values of various moduli fields appearing in the low energy effective action  19",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Hybrid inflation followed by modular unemployment . Abstract : We consider the prospect that our universe underwent two stages of rapid expansion , initially hybrid inflation and then modular expansion .We see how this situation can be realized in string theory with an explicit instance based on type IIB orientifolds compactified to four dimensions on Calabi - Yau threefolds . In particular we find that there are many potential realizations of such theories which lead to accurate expressions for the cosmological parameters .The model is compatible with all present scientific limitations including those coming from measurements of the cosmic microwave background anisotropies as well as from direct searches at colliders . Finally we explain some phenomenological aspects of these scenarios .Introduction : Inflationary theories provide one of the most compelling reasons for numerous puzzles involved with the standard hot large bang cosmology 1 . They predict that primordial particle fluctuations experienced during inflation should have left their imprint on the temperature anisotropies witnessed today in the Cosmic Microwave Background ( CMB ) 2 .In recent years it has been shown that supersymmetric grand unified theories ( GUTs ) , like SO ( 10 ) , naturally make rise to inflationary potentials 3 , while also offering a successful unification scheme 4 . However , GUT scale inflation suffers from the so - called η - problem 5 : the expected value of the tensor - to - scalar ratio r = 16ǫ H / ε 2 6 leads to too huge CMB quadrupole anisotropies 7 , 8 unless ǫ H [UNK] 1 9 or η [UNK] 10 −9 10 .This problem could be alleviated if the inflaton potential contains fixed directions 11 . These arise quite generically in supergravity 12 and string theory 13 owing to non - perturbative effects 14 .A notably important family of flat angles arises when the gauge group is broken down to its maximal subgroup 15 . Such flat angles were studied frequently in 16 where they were called moduli fields since they parametrize the height and shape of extra dimensions 17 .Moduli fields take an important role in string theory 18 because they predict the vacuum expectation values of several moduli fields appearing in the small energy effective action 19",
        "rewrite_text": "**Title:** Hybrid Inflation Followed by Modular Unemployment\n\n**Abstract:** In this study, we explore the intriguing possibility that our universe experienced two distinct phases of rapid expansion: an initial phase of hybrid inflation followed by a subsequent phase of modular expansion. We demonstrate how this scenario can be effectively realized within the framework of string theory, specifically through a concrete example involving type IIB orientifolds that are compactified to four dimensions on Calabi-Yau threefolds. Our analysis reveals a variety of potential realizations of these theories, which yield precise predictions for cosmological parameters. Importantly, our model adheres to current scientific constraints, including those derived from observations of cosmic microwave background (CMB) anisotropies and direct experimental searches conducted at particle colliders. Furthermore, we delve into the phenomenological implications of these scenarios, shedding light on their relevance to contemporary cosmological discussions.\n\nInflationary theories have emerged as a compelling solution to several puzzles inherent in the standard hot big bang cosmology. They suggest that the primordial fluctuations in particle density during inflation have left a discernible imprint on the temperature anisotropies observed in the CMB. Recent advancements have shown that supersymmetric grand unified theories (GUTs), such as SO(10), can naturally lead to inflationary potentials while simultaneously providing a robust framework for unification. However, these GUT-scale inflationary models face challenges, notably the so-called η-problem, which arises from the anticipated tensor-to-scalar ratio (r) leading to excessively large CMB quadrupole anisotropies unless certain conditions are met. This issue may be mitigated if the inflaton potential incorporates fixed directions, a feature that is commonly found in supergravity and string theory due to non-perturbative effects. A particularly significant class of flat directions emerges when the gauge group is reduced to its maximal subgroup. These flat directions, often referred to as moduli fields, play a crucial role in string theory as they determine the vacuum expectation values of various moduli fields present in the low-energy effective action.",
        "ori-fast-z-score": -0.4714045207910317,
        "water-fast-z-score": 5.683042292379118,
        "rewrite-fast-z-score": -1.5261167249147478
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Multiwavelength study of massive galaxies at z~2. I. Star formation and galaxy growth .\nAbstract:\nWe present the results of an optical to infrared multiwavelength survey of a sample of 12 massive (M* > 10 11 Msun) galaxies in the redshift range 1.9 < z < 2.7, selected using their rest-frame UV colors as Lyman-break analogs. We use deep near-infrared spectroscopy with Keck/NIRSPEC to measure stellar masses for these objects, which are found to be between 3 x 10 11 and 5 x 10 11 Msun. The majority of our targets show evidence for strong starburst activity based on their high equivalent width  OIII  emission lines and large Balmer decrements indicative of dusty star-forming regions. Using Spitzer/IRAC photometry we find that most of these systems have red mid-infrared colors consistent with those expected for evolved stellar populations. However, two of our sources appear bluer than this trend suggesting they may contain significant amounts of obscured AGN activity.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Multiwavelength study of large galaxies at z ~ 2 . I .Star formation and galaxy expansion . Abstract : We present the conclusion of an optical to infrared multiwavelength survey of a sample of 12 huge ( M * > 10 11 Msun ) galaxies in the redshift range 1 . 9 < z < 2 . 7 , selected using their rest - frame UV colors as Lyman - break analogs .We use deep near - infrared spectroscopy with Keck / NIRSPEC to measure stellar masses for these objects , which are found to be between 3 x 10 11 and 5 x 10 11 Msun . The majority of our targets show proof for strong starburst activity based on their high equivalent height OIII emission lines and large Balmer decrements indicative of dusty star - creating areas .Using Spitzer / IRAC photometry we find that most of these systems have red middle - infrared colors consistent with those expected for advanced stellar regions . However , two of our sources appear bluer than this shift suggesting they may contain significant amounts of distorted AGN activity .",
        "rewrite_text": "We present the findings of an extensive multiwavelength survey, spanning optical to infrared observations, focusing on a sample of 12 massive galaxies with stellar masses exceeding 10^11 solar masses (M* > 10^11 Msun) within the redshift range of 1.9 to 2.7. These galaxies were selected based on their rest-frame ultraviolet colors, identifying them as Lyman-break analogs. Utilizing deep near-infrared spectroscopy from the Keck Observatory's NIRSPEC instrument, we have accurately measured the stellar masses of these galaxies, which range from approximately 3 x 10^11 to 5 x 10^11 Msun. Our analysis reveals that a significant portion of these galaxies exhibit strong starburst activity, as evidenced by their high equivalent width of OIII emission lines and substantial Balmer decrements, both of which indicate the presence of dust-rich star-forming regions. Furthermore, through photometric observations with the Spitzer IRAC, we observe that most of these galaxies display red mid-infrared colors, aligning with expectations for mature stellar populations. However, two of the galaxies in our sample present bluer mid-infrared colors, suggesting the potential influence of active galactic nucleus (AGN) activity, which may be distorting their spectral characteristics. This study enhances our understanding of the star formation processes and the evolutionary dynamics of large galaxies during this critical epoch in cosmic history, providing insights into the interplay between star formation and AGN activity in shaping the properties of massive galaxies at high redshifts.",
        "ori-fast-z-score": 2.1376670117594454,
        "water-fast-z-score": 4.919349550499537,
        "rewrite-fast-z-score": 0.47891314261057566
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Groups of galaxies in the SDSS Data Release 5. A group-finder and a catalogue .\nAbstract:\nWe present an algorithm to find galaxy groups using photometric redshifts, which is based on the Voronoi tessellation technique (VT). The VT method has been widely used for identifying clusters of galaxies with spectroscopic redshifts but it had not yet been applied to identify galaxy groups with photometric redshifts. We use the Sloan Digital Sky Survey data release five (SDSS DR5) as our input sample. Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available. In this work we have identified more than 12000 galaxy groups at 0 < z < 0.3. These groups contain about 30000 member galaxies. We also provide a catalog containing basic information such as positions, magnitudes, colors, and photometric redshifts for all these groups. \n \n Keywords: Galaxy Group, Photometric Redshift",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Groups of galaxies in the SDSS Data Release 5 . A group - finder and a catalogue .Abstract : We present an algorithm to find galaxy groups using photometric redshifts , which is based on the Voronoi tessellation method ( VT ) . The VT method has been widely applied for finding clusters of clusters with spectroscopic redshifts but it had not already been used to identify galaxy groups with photometric redshifts .We use the Sloan Digital Sky Survey data release five ( SDSS DR5 ) as our input data . Our results show that the VT method can be successfully applied to identify galaxy groups even when only photometric redshifts are available .In this research we have discovered more than 12000 star groups at 0 < z < 0 . 3 . These groups contain about 30000 member galaxies .We additionally offer a list containing essential information such as positions , magnitudes , colors , and photometric redshifts for all these groups . Keywords : Galaxy Group , Photometric Redshift",
        "rewrite_text": "We introduce a novel algorithm designed for the identification of galaxy groups utilizing photometric redshifts, employing the Voronoi tessellation (VT) method. While the VT technique has been extensively utilized for detecting clusters of galaxies with spectroscopic redshifts, its application to the identification of galaxy groups based solely on photometric redshifts has not been previously explored. Our study leverages data from the Sloan Digital Sky Survey Data Release 5 (SDSS DR5) as the foundational dataset for our analysis. The findings of our research indicate that the VT method is effective in successfully identifying galaxy groups, even in scenarios where only photometric redshifts are accessible. Throughout this investigation, we have identified over 12,000 galaxy groups within the redshift range of 0 < z < 0.3, encompassing approximately 30,000 member galaxies. Furthermore, we provide a comprehensive catalogue that includes critical information for each identified group, such as their spatial coordinates, magnitudes, colors, and photometric redshifts. This catalogue serves as a valuable resource for researchers interested in the study of galaxy groups and their properties. Our work not only demonstrates the applicability of the VT method in this new context but also contributes significantly to the existing body of knowledge regarding galaxy group dynamics and distribution in the universe. The results underscore the potential of photometric redshifts in astrophysical research, paving the way for future studies that can utilize this method for further exploration of galaxy formation and evolution. \n\nKeywords: Galaxy Group, Photometric Redshift.",
        "ori-fast-z-score": -1.6644794391276478,
        "water-fast-z-score": 2.794002794004191,
        "rewrite-fast-z-score": -0.6060915267313265
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Comprehensive simulations of superhumps .\nAbstract:\nSuperhumps are periodic modulations in the light curves of some cataclysmic variables (CVs). They have been observed to occur during both the high and low states, but their origin is still not understood. In this work we present comprehensive numerical simulations of CVs with mass ratios q = 0.7-0.9 that include tidal dissipation effects as well as magnetic braking. We find that for systems with orbital periods P orb < 3 hr, the inclusion of magnetic braking leads to an increase in the amplitude of the superhumps by up to a factor of two compared to previous results obtained without magnetic braking. For longer period systems, however, our models predict smaller amplitudes than those inferred observationally. This discrepancy may be due to additional physical processes such as irradiation or enhanced mass transfer rates at periastron passage which were neglected here. \n \n Keywords: Cataclysmic Variables",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Comprehensive simulations of superhumps . Abstract : Superhumps are regular modulations in the light curves of some cataclysmic variables ( CVs ) .They have been observed to arise during both the high and low states , but their source is nevertheless not explained . In this research we present comprehensive numerical simulations of CVs with mass factors q = 0 . 7 - 0 . 9 that include tidal dissipation effects as well as magnetic braking .We see that for systems with orbital periods P orb < 3 hr , the introduction of magnetic braking contributes to an increase in the frequency of the superhumps by up to a factor of two compared to previous findings obtained without magnetic braking . For longer duration systems , however , our calculations predict smaller amplitudes than those inferred observationally .This discrepancy may be due to extra physical processes such as irradiation or improved mass transfer rates at periastron passage which were neglected here . Keywords : Cataclysmic Variables",
        "rewrite_text": "Title: In-Depth Simulations of Superhumps in Cataclysmic Variables\n\nAbstract: Superhumps represent periodic variations observed in the light curves of certain cataclysmic variables (CVs), yet their underlying mechanisms remain poorly understood. This study aims to provide a detailed analysis through extensive numerical simulations of CVs characterized by mass ratios ranging from q = 0.7 to 0.9, incorporating both tidal dissipation effects and magnetic braking. Our findings indicate that for systems with orbital periods (P_orb) shorter than 3 hours, the inclusion of magnetic braking significantly enhances the frequency of superhumps, potentially doubling the rates compared to previous studies that did not account for this factor. Conversely, for systems with longer orbital periods, our simulations yield amplitude predictions that are notably lower than those derived from observational data. This observed discrepancy may suggest the influence of additional physical processes, such as irradiation effects or enhanced mass transfer rates during periastron passages, which were not considered in our current model. The results of this research contribute to a deeper understanding of superhump phenomena and highlight the importance of incorporating various physical effects in simulations to better align theoretical predictions with observational evidence. \n\nKeywords: Cataclysmic Variables, Superhumps, Numerical Simulations, Magnetic Braking, Tidal Dissipation.",
        "ori-fast-z-score": 0.12403473458920847,
        "water-fast-z-score": 4.677476657214644,
        "rewrite-fast-z-score": 1.0425720702853738
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:   Hidden  Seyfert 2 Galaxies in the Chandra Deep Field North .\nAbstract:\nWe have identified a sample of candidate hidden Seyfert galaxies by searching for X-ray sources with hard spectra (Γ < 1) and high luminosities (Lx > 1043 erg s-1). We find that these objects are preferentially located at redshifts z ~ 0.7, where they can be detected only if their intrinsic absorption is NH < 1023 cm-2 . The majority of our candidates show no optical counterparts down to R = 25 mag on deep ground-based images; however, we do detect faint emission lines characteristic of AGN activity in some cases. Our results suggest that there may exist many more obscured active galactic nuclei than previously thought. This work was supported by NASA grant NAG5-7262. \n \n Keywords: Active Galactic Nuclei, Galaxy Evolution, X-Ray Astronomy \n \n Introduction \n \n In recent years it has become clear that most bright quasars reside in massive elliptical galaxies or bulges of spiral galaxies (e.g., McLure & Dunlop 2001), but the nature of the host galaxy remains unknown because of heavy dust extinction along the line-of-sight. It is possible that many optically-faint quasars are hosted by less-massive systems such as late-type spirals and/or low-luminosity ellipticals (e.g., Hao et al. 2005). \n \n To understand how supermassive black holes grow over cosmic time, it is important to study both unobscured and obscured active galactic nucleus (AGNs) across a wide range of environments. However, identifying heavily-absorbed AGNs is difficult due to the lack of strong spectral features associated with them. One way to identify absorbed AGNs is through their X-ray properties. For example, Compton-thick AGNs are characterized by very flat X-ray continua and large equivalent widths of iron Kα fluorescence lines (EW>500 eV) (see e.g., Risaliti 2002). Another method is based on the fact that absorbed AGNs tend to exhibit higher X-ray-to-optical flux ratios compared to normal galaxies (e.g..",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Hidden Seyfert 2 Galaxies in the Chandra Deep Field North . Abstract : We have discovered a sample of candidate hiding Seyfert galaxies by searching for X - ray bodies with hard spectra ( Γ < 1 ) and large luminosities ( Lx > 1043 erg s - 1 ) .We see that these objects are preferentially found at redshifts z ~ 0 . 7 , where they can be identified only if their inherent absorption is NH < 1023 mm - 2 . The majority of our candidates produce no optical rivals down to R = 25 mag on dark land - based images ; however , we do discover dim emission lines typical of AGN activity in some cases .Our results show that there may exist many more obscured active galactic nuclei than previously thought . This research was supported by NASA grant NAG5 - 7262 .Keywords : Active Galactic Nuclei , Galaxy Evolution , X - Ray Astronomy Introduction In recent history it has become clear that most bright quasars operate in massive elliptical galaxies or bulges of spiral galaxies ( e . g . , McLure & Dunlop 2001 ) , but the nature of the host galaxy continues unclear because of large dust extinction along the line - of - view . It is suggested that several optically - faint quasars are hosted by less - massive structures such as early - class spirals and / or low - luminosity ellipticals ( e . g . , Hao et al .2005 ) . To understand how supermassive black holes expand over cosmic time , it is important to study both unobscured and distorted active galactic nucleus ( AGNs ) across a broad variety of habitats .However , identifying strongly - absorption AGNs is problematic due to the lack of bright spectral features linked with them . One method to identify absorption AGNs is through their X - ray characteristics .For instance , Compton - thick AGNs are characterized by very flat X - ray continua and large equivalent widths of iron Kα fluorescence bands ( EW > 500 eV ) ( see e . g . , Risaliti 2002 ) . Another method is based on the fact that absorbed AGNs prefer to contain higher X - ray - to - optical flux proportions compared to normal galaxies ( e . g . .",
        "rewrite_text": "**Title:** Hidden Seyfert 2 Galaxies in the Chandra Deep Field North\n\n**Abstract:** In this study, we present the identification of a new sample of candidate hidden Seyfert galaxies, achieved through an analysis of X-ray sources exhibiting hard spectra (Γ < 1) and significant luminosities (Lx > 10^43 erg s^-1). Our findings indicate that these candidates are predominantly located at redshifts around z ~ 0.7, where they can only be detected if their intrinsic absorption is below NH < 10^23 cm^-2. Notably, the majority of these candidates do not exhibit optical counterparts down to a magnitude of R = 25 in dark, ground-based images. However, in certain instances, we have detected faint emission lines that are characteristic of active galactic nucleus (AGN) activity. These results suggest that the population of obscured AGNs may be far more extensive than previously recognized. This research was conducted with the support of NASA grant NAG5-7262. \n\n**Keywords:** Active Galactic Nuclei, Galaxy Evolution, X-Ray Astronomy\n\n**Introduction:** Recent studies have established that most luminous quasars are found within massive elliptical galaxies or the bulges of spiral galaxies (e.g., McLure & Dunlop 2001). However, the precise nature of their host galaxies remains ambiguous due to significant dust extinction along the line of sight. It has been proposed that many optically faint quasars may reside in less massive structures, such as early-type spirals or low-luminosity ellipticals (e.g., Hao et al. 2005). To gain insights into the growth of supermassive black holes over cosmic time, it is crucial to investigate both unobscured and obscured active galactic nuclei (AGNs) across a diverse range of environments. Identifying heavily absorbed AGNs poses challenges due to the absence of prominent spectral features. One effective approach for detecting absorbed AGNs is through their X-ray properties. For example, Compton-thick AGNs are characterized by very flat X-ray continua and large equivalent widths of iron Kα fluorescence lines (EW > 500 eV) (see e.g., Risaliti 2002). Additionally, absorbed AGNs typically exhibit higher X-ray-to-optical flux ratios compared to normal galaxies.",
        "ori-fast-z-score": -0.24743582965269675,
        "water-fast-z-score": 7.613974175141785,
        "rewrite-fast-z-score": -0.08247860988423225
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Magnetization and specific heat of TbFe3(BO3)4: Experiment and crystal field calculations .\nAbstract:\nThe magnetization, susceptibility, and specific heat measurements were performed on the single crystals of TbFe3( BO3 )4 . The magnetic properties are analyzed in terms of the crystal-field splitting scheme for Tb3+ ions. It is found that the ground state doublet has an Ising-like anisotropy along c-axis with gz = 8.0 ± 0.1 , which leads to the large spontaneous polarization ( Ps ~ 1μC/cm2 ). The calculated results reproduce well the experimental data except for the low-temperature part of the specific-heat curve below 2 K. This discrepancy may be attributed to the presence of impurities or defects in our samples. \n \n Keywords: Magnetism; Crystal field theory; Specific heat measurement; Susceptibility measurement; Single-crystal growth; Anisotropic magnetoresistance effects; Polarized neutron scattering \n \n \n \n INTRODUCTION : \nTbFe 3 (BO 3 ) 4 belongs to the family of rare-earth iron borates RFe 3 (BO 3 ) (R = Y, Yb, Lu). These compounds have attracted much attention because they exhibit various interesting physical phenomena such as ferroelectricity  1  , multiferroicity  2  , colossal magnetoresistance  3  , and quantum critical behavior  4  .\nIn particular, TbFe 3 (BO 3 )\n4 exhibits a giant spontaneous polarization P s ~ 1 μ C / cm 2 at room temperature  5  due to its unique crystal structure  6  . In this compound, Fe atoms form a three-dimensional network of corner-sharing tetrahedra by sharing their apical oxygen atoms  7   . On the other hand, Tb atoms occupy two different sites, i.e., one site surrounded by eight O atoms forming a square antiprismatic coordination polyhedron  8  and another site surrounded by six O atoms forming a trigonal prismatic coordination polyhedron  9  . As shown in Figs. 1 (a) and (b), these two types of polyhedra share common faces perpendicularly to the c -axis  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Magnetization and particular heat of TbFe3 ( BO3 ) 4 : Experiment and crystal field calculations . Abstract : The magnetization , susceptibility , and particular heat measurements were performed on the single crystals of TbFe3 ( BO3 ) 4 .The magnetic properties are examined in terms of the crystal - field separation scheme for Tb3 + ions . It is found that the ground state doublet has an Ising - like anisotropy along c - axis with gz = 8 . 0 ± 0 . 1 , which results to the huge spontaneous polarization ( Ps ~ 1μC / cm2 ) .The measured data reproduce well the laboratory information except for the small - temperature half of the specific - temperature curve below 2 K . This discrepancy may be due to the presence of impurities or defects in our specimens . Keywords : Magnetism ; Crystal field model ; Specific temperature measurement ; Susceptibility measurement ; Single - crystal growth ; Anisotropic magnetoresistance effects ; Polarized neutron scattering INTRODUCTION : TbFe 3 ( BO 3 ) 4 belongs to the group of rare - earth iron borates RFe 3 ( BO 3 ) ( R = Y , Yb , Lu ) .These compounds have garnered great popularity because they show numerous interesting physical phenomena such as ferroelectricity 1 , multiferroicity 2 , colossal magnetoresistance 3 , and quantum important interaction 4 . In particular , TbFe 3 ( BO 3 ) 4 displays a huge spontaneous polarization P s ~ 1 μ C / cm 2 at room temperature 5 due to its unique crystal composition 6 .In this compound , Fe molecules form a three - dimensional network of spot - sharing tetrahedra by sharing their apical oxygen atoms 7 . On the other hand , Tb molecules occupy two different places , i . e . , one site surrounded by eight O atoms forming a square antiprismatic coordination polyhedron 8 and another site surrounded by six O atoms forming a trigonal prismatic coordination polyhedron 9 .As seen in Figs . 1 ( a ) and ( b ) , these two forms of polyhedra share shared faces perpendicularly to the c - axis 10 .",
        "rewrite_text": "**Title:** Magnetization and Specific Heat of TbFe3(BO3)4: Experimental Insights and Crystal Field Calculations\n\n**Abstract:** This study presents a comprehensive investigation of the magnetization, susceptibility, and specific heat of single crystals of TbFe3(BO3)4. The magnetic characteristics of this compound are analyzed through the lens of the crystal-field separation model for Tb3+ ions. Our findings reveal that the ground state doublet exhibits Ising-like anisotropy along the c-axis, with a g-factor of gz = 8.0 ± 0.1. This anisotropy is responsible for the remarkable spontaneous polarization observed in the material, approximately Ps ~ 1 μC/cm². The experimental data align closely with theoretical predictions, with the exception of a minor deviation in the specific heat measurements at low temperatures (below 2 K). This discrepancy may be attributed to the presence of impurities or defects within the crystal samples. \n\nThe compound TbFe3(BO3)4 is part of the rare-earth iron borate family, RFe3(BO3) (where R = Y, Yb, Lu), which has gained significant attention due to their intriguing physical properties, including ferroelectricity, multiferroicity, colossal magnetoresistance, and notable quantum interactions. Specifically, TbFe3(BO3)4 is distinguished by its substantial spontaneous polarization at room temperature, a phenomenon linked to its unique crystal structure. In this structure, iron (Fe) ions create a three-dimensional network of corner-sharing tetrahedra by sharing apical oxygen atoms. Concurrently, terbium (Tb) ions occupy two distinct coordination environments: one surrounded by eight oxygen atoms, forming a square antiprismatic polyhedron, and another surrounded by six oxygen atoms, resulting in a trigonal prismatic coordination. These two polyhedral arrangements are oriented perpendicularly to the c-axis, as illustrated in the accompanying figures. This research contributes to the understanding of the magnetic and thermal properties of TbFe3(BO3)4, paving the way for future studies on its potential applications in advanced materials science.\n\n**Keywords:** Magnetism; Crystal field model; Specific heat measurement; Susceptibility measurement; Single-crystal growth; Anisotropic magnetoresistance; Polarized neutron scattering.",
        "ori-fast-z-score": 0.8908708063747479,
        "water-fast-z-score": 7.365059028153745,
        "rewrite-fast-z-score": 2.8942722045797455
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Ab initio statistical mechanics of surface adsorption and desorption: I. H$_2$O on MgO (001) at low coverage .\nAbstract:\nWe present an ab initio study of the structure, energetics, and dynamics of water adsorbed on the MgO(001) surface in the submonolayer regime using density functional theory with van der Waals corrections. We find that the most stable configuration is one where each oxygen atom binds to three hydrogen atoms forming a trihydrogen bridge between two adjacent O atoms. The binding energy per molecule for this configuration is 1.6 eV. This value agrees well with previous theoretical results obtained within the generalized gradient approximation but disagrees significantly with experimental values which are typically larger by about 0.5-0.7 eV. Our calculations show that the discrepancy can be attributed mainly to the neglect of dispersion interactions in earlier studies. In addition we have studied the effect of temperature on the stability of different configurations. We found that the relative population of various structures depends strongly on the temperature.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Ab initio statistical mechanics of fluid adsorption and desorption : I . H $ _ 2 $ O on MgO ( 001 ) at low coverage . Abstract : We present an ab initio investigation of the composition , energetics , and dynamics of water adsorbed on the MgO ( 001 ) surface in the submonolayer regime using density functional theory with van der Waals corrections .We see that the most stable configuration is one where each oxygen atom binds to three hydrogen atoms forming a trihydrogen bridge between two adjacent O atoms . The activation energy per atom for this configuration is 1 . 6 eV .This value agrees well with previous conceptual conclusions derived within the generalized gradient algorithm but disagrees greatly with experimental values which are typically greater by about 0 . 5 - 0 . 7 eV . Our calculations show that the discrepancy can be due mainly to the neglect of dispersion interactions in earlier methods .In addition we have researched the impact of temperature on the stability of different configurations . We showed that the relative population of several systems relies highly on the temperature .",
        "rewrite_text": "We present a comprehensive ab initio study focused on the adsorption and desorption phenomena of water (H₂O) on the MgO (001) surface, specifically within the submonolayer coverage regime. Utilizing density functional theory (DFT) enhanced with van der Waals corrections, we analyze the composition, energetics, and dynamics of water molecules interacting with the MgO substrate. Our findings indicate that the most energetically favorable configuration occurs when each oxygen atom in the water molecule forms bonds with three hydrogen atoms, resulting in the formation of a trihydrogen bridge between two adjacent oxygen atoms on the surface. The calculated activation energy for this binding configuration is approximately 1.6 eV per atom. This value aligns closely with previous theoretical predictions derived from the generalized gradient approximation but contrasts significantly with experimental measurements, which typically report activation energies that are 0.5 to 0.7 eV higher. We attribute this discrepancy primarily to the omission of dispersion interactions in earlier computational approaches. Furthermore, our investigation extends to the influence of temperature on the stability of various adsorption configurations. We demonstrate that the relative populations of different structural arrangements are highly sensitive to temperature variations, indicating that thermal effects play a crucial role in the adsorption dynamics of water on the MgO (001) surface. This study not only enhances our understanding of fluid adsorption at the molecular level but also provides insights into the fundamental mechanisms governing the interaction between water and oxide surfaces, which is essential for various applications in materials science and surface chemistry.",
        "ori-fast-z-score": 0.562543950463012,
        "water-fast-z-score": 5.142956348249516,
        "rewrite-fast-z-score": 0.5432144762551112
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Empirical Photometric Redshifts of Luminous Red Galaxies and Clusters in SDSS .\nAbstract:\nWe present an empirical photometric redshift technique for luminous red galaxies (LRGs) and clusters, using the Sloan Digital Sky Survey Data Release 5 (SDSS DR5). We use a sample of LRGs/clusters with spectroscopic redshifts to calibrate our method by fitting their observed colors as functions of redshift. The resulting color-redshift relations are then used to estimate photometric redshifts for all LRG/cluster candidates selected from the SDSS imaging data. Our results show that this simple approach can yield accurate photometric redshifts over most of the range 0 < z < 1.2 covered by the survey. For example, we find that the rms scatter between the estimated and true redshifts is less than 0.05(1+z), which corresponds to about 60 km/s at z = 0.6. This accuracy is comparable or better than those achieved by other methods based on template-fitting techniques. \n \n Keywords: Empirical photometric redshifts; Luminous Red Galaxy; Cluster",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Empirical Photometric Redshifts of Luminous Red Galaxies and Clusters in SDSS . Abstract : We report an empirical photometric redshift technique for luminous red clusters ( LRGs ) and clusters , using the Sloan Digital Sky Survey Data Release 5 ( SDSS DR5 ) .We use a sample of LRGs / clusters with spectroscopic redshifts to calibrate our technique by fitting their observed colors as functions of redshift . The resulting color - redshift relations are then used to estimate photometric redshifts for all LRG / cluster applicants chosen from the SDSS imaging information .Our results show that this straightforward methodology can yield exact photometric redshifts over most of the range 0 < z < 1 . 2 included by the sample . For instance , we find that the rms scatter between the expected and true redshifts is fewer than 0 . 05 ( 1 + z ) , which corresponds to about 60 km / s at z = 0 . 6 .This sensitivity is identical or improved than those achieved by other methods using on template - fitting methods . Keywords : Empirical photometric redshifts ; Luminous Red Galaxy ; Cluster",
        "rewrite_text": "We present an empirical method for determining photometric redshifts of luminous red galaxies (LRGs) and galaxy clusters, utilizing data from the Sloan Digital Sky Survey Data Release 5 (SDSS DR5). Our approach involves a comprehensive analysis of a sample of LRGs and clusters with known spectroscopic redshifts, which serves as the foundation for calibrating our technique. By examining the observed colors of these objects as a function of redshift, we establish robust color-redshift relations. These relations enable us to estimate photometric redshifts for all LRGs and clusters identified through SDSS imaging data. Our findings indicate that this method is capable of producing highly accurate photometric redshifts across a significant range, specifically for redshifts between 0 and 1.2. Notably, we observe that the root mean square (rms) scatter between the predicted and actual redshifts is less than 0.05 (1 + z), which translates to an impressive velocity accuracy of approximately 60 km/s at a redshift of 0.6. This level of precision is comparable to, or even superior to, results obtained through conventional template-fitting techniques. Our study underscores the effectiveness of this empirical approach in enhancing the accuracy of photometric redshift estimations for LRGs and clusters, thereby contributing valuable insights to the field of astrophysics and cosmology. The implications of our results extend to various applications, including the study of galaxy evolution and the large-scale structure of the universe. Keywords: Empirical photometric redshifts; Luminous Red Galaxy; Cluster.",
        "ori-fast-z-score": -0.7878385971583353,
        "water-fast-z-score": 4.556611884328835,
        "rewrite-fast-z-score": -0.6123724356957946
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Long Term Fate of Our Digital Belongings: Toward a Service Model for Personal Archives .\nAbstract:\nThe rapid growth in the use and production of digital media has created an urgent need to develop new models that support long-term access, preservation, and reuse of personal archives.  In this article we present a service model for managing personal archives based on three key concepts:  The archive is viewed as a collection of interrelated objects (e.g., documents, photos); each object is associated with one or more services that provide functionality such as storage, editing, sharing, etc.; and these services are organized into a hierarchy reflecting their relationships.   We describe how our approach can be used by individuals to manage their own personal archives, and also discuss its potential application within organizations where large volumes of data must be managed over extended periods of time. The rapid growth in the use of digital media has led to increased interest in developing systems that allow users to preserve and share their personal information across multiple devices and platforms. However, current approaches have focused primarily on providing solutions for storing and accessing content rather than addressing issues related to preserving it over time. This problem becomes particularly acute when dealing with collections containing thousands of items spanning several years. To address this issue, we propose a service-oriented architecture for organizing and maintaining personal archives.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Long Term Fate of Our Digital Belongings : Toward a Service Model for Personal Archives . Abstract : The rapid increase in the using and production of digital media has established an urgent need to develop new models that facilitate long - term access , preservation , and reuse of personal records .In this page we present a service model for controlling personal records using on three key concepts : The archive is viewed as a collection of interrelated objects ( e . g . , files , photos ) ; each object is associated with one or more functions that provide functionality such as processing , editing , sharing , etc . ; and these services are structured into a structure indicating their connections .We define how our approach can be used by individuals to manage their own individual archives , and also discuss its potential application within organizations where vast volumes of records must be managed over longer periods of time . The rapid increase in the using of digital media has led to renewed emphasis in developing systems that enable users to contain and communicate their individual information across multiple computers and platforms .However , current approaches have concentrated mostly on providing strategies for storing and accessing information rather than solving aspects pertaining to preserving it over time . This problem appears particularly intense when dealing with libraries containing many of items spanning numerous years .To address this question , we propose a service - based architecture for organizing and keeping personal records .",
        "rewrite_text": "Title: The Long-Term Fate of Our Digital Belongings: Toward a Service Model for Personal Archives\n\nAbstract: The exponential growth in the creation and utilization of digital media has highlighted an urgent necessity for innovative models that ensure the long-term accessibility, preservation, and reuse of personal records. In this article, we introduce a service model designed to manage personal archives, built upon three fundamental concepts. First, we conceptualize the archive as a cohesive collection of interconnected objects, such as files and photographs. Second, each object is linked to various functions that enable essential operations, including processing, editing, and sharing. Lastly, these services are organized within a structured framework that illustrates their interrelationships. \n\nWe elaborate on how this model empowers individuals to effectively manage their personal archives while also exploring its potential applications in organizational contexts, where extensive volumes of records require long-term management. The surge in digital media usage has prompted a renewed focus on developing systems that allow users to store and communicate their personal information seamlessly across diverse computers and platforms. However, existing solutions have primarily concentrated on strategies for information storage and access, often neglecting the critical aspect of long-term preservation. This challenge is particularly pronounced in libraries and archives that house numerous items accumulated over many years.\n\nTo tackle this pressing issue, we propose a service-oriented architecture that not only organizes but also safeguards personal records for the future. Our approach aims to bridge the gap between immediate accessibility and enduring preservation, ensuring that digital belongings remain manageable and retrievable over time. By implementing this service model, we aspire to enhance the sustainability of personal archives, ultimately contributing to a more robust framework for digital heritage preservation.",
        "ori-fast-z-score": 0.3481553119113957,
        "water-fast-z-score": 9.278076673908084,
        "rewrite-fast-z-score": 1.2288478807785608
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Low-dimensional Supersymmetric Lattice Models .\nAbstract:\nThe low energy effective theories for superstrings are supergravity and supersymmetric gauge theories in four dimensions, which can be obtained by compactifying the extra six spatial dimensions on a Calabi-Yau manifold.  In this talk I will discuss some recent results about lattice models that provide an alternative approach to studying these theories. The basic idea is to use Monte Carlo simulations to study supersymmetric field theories defined on a finite number of points (the sites) of a regular d-dimensional hypercubic lattice with periodic boundary conditions. These models have been studied extensively over the past few years using numerical techniques such as exact diagonalization, quantum Monte Carlo methods, and density matrix renormalization group algorithms. Recently we developed new Monte Carlo simulation techniques based on the worm algorithm that allow us to simulate large systems at very high temperatures where conventional Monte Carlo methods fail because they suffer from critical slowing down. We used our new method to calculate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang-Mills theory and the N = 1 supersymmetric U(1) gauge theory coupled to matter fields in various representations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Low - dimensional Supersymmetric Lattice Models . Abstract : The lowest energy effective models for superstrings are supergravity and supersymmetric gauge theories in four dimensions , which can be obtained by compactifying the extra six spatial dimensions on a Calabi - Yau manifold .In this talk I will explore some latest findings about lattice models that provide an different approach to investigating these theories . The basic idea is to use Monte Carlo simulations to study supersymmetric field theories constructed on a finite number of points ( the sites ) of a regular d - dimensional hypercubic crystal with periodic border conditions .These methods have been studied thoroughly over the previous few years employing mathematical techniques such as approximate diagonalization , quantum Monte Carlo methods , and density matrix renormalization group schemes . Recently we developed novel Monte Carlo simulation algorithms based on the worm algorithm that enable us to simulate large systems at very high altitudes where conventional Monte Carlo methods fail because they suffer from critical speed down .We utilized our new method to estimate the free energies of several different supersymmetric lattice models including the N = 4 supersymmetric Yang - Mills theory and the N = 1 supersymmetric U ( 1 ) gauge theory connected to matter fields in different representations .",
        "rewrite_text": "Title: Low-Dimensional Supersymmetric Lattice Models\n\nAbstract: In the realm of theoretical physics, the effective low-energy models for superstring theory predominantly consist of supergravity and supersymmetric gauge theories formulated in four-dimensional spacetime. These models emerge from the compactification of six additional spatial dimensions on a Calabi-Yau manifold. This presentation delves into recent advancements in lattice models that offer an alternative methodology for probing these complex theories. The core concept revolves around employing Monte Carlo simulations to investigate supersymmetric field theories defined on a finite lattice structure, specifically a regular d-dimensional hypercubic lattice with periodic boundary conditions. Over the past few years, significant progress has been made in this area, utilizing sophisticated mathematical techniques such as approximate diagonalization, quantum Monte Carlo methods, and density matrix renormalization group approaches. \n\nRecently, we have introduced innovative Monte Carlo simulation algorithms based on the worm algorithm, which facilitate the simulation of large systems at elevated temperatures where traditional Monte Carlo techniques encounter limitations due to critical slowing down. By leveraging this new approach, we have successfully estimated the free energies of various supersymmetric lattice models, including the N = 4 supersymmetric Yang-Mills theory and the N = 1 supersymmetric U(1) gauge theory, which incorporates matter fields represented in different ways. These findings not only enhance our understanding of supersymmetric theories but also pave the way for further exploration of their implications in high-energy physics and string theory. Through this work, we aim to contribute to the broader discourse on the interplay between lattice models and supersymmetry, ultimately enriching the theoretical landscape of modern physics.",
        "ori-fast-z-score": 0.19802950859533489,
        "water-fast-z-score": 5.81344274116933,
        "rewrite-fast-z-score": 0.7016464154456235
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Highly turbulent solutions of LANS-alpha and their LES potential .\nAbstract:\nWe present highly resolved numerical simulations of the incompressible Navier-Stokes equations with the LANS-alpha model, which is known to produce good results for wall-bounded flows at low Reynolds numbers. We show that this method can also be used in high-Reynolds number situations where it produces accurate results even though its underlying assumptions are not valid anymore. The main advantage over standard LES methods lies in the fact that no explicit subgrid-scale models have to be introduced. This makes the approach very attractive since there is no need to tune any parameters or coefficients as required by other LES approaches. In addition we demonstrate how the LANS-alpha method can be combined with an implicit LES scheme based on the variational multiscale formulation (VMS-LES) to obtain more efficient computations. Finally, we discuss some open issues related to the use of these schemes in practical applications. Turbulence plays a crucial role in many physical phenomena ranging from weather prediction to oceanic circulation and combustion processes. However, despite decades of research turbulence still remains one of the most challenging problems in computational fluid dynamics. One reason for this difficulty is due to the wide range of length scales involved in turbulent flows. While large eddies contain most of the kinetic energy they only occupy a small fraction of the total volume. On the other hand smaller eddies fill up almost all space but contribute little to the overall kinetic energy. Therefore, if one wants to resolve all relevant flow structures accurately enough then extremely fine grids would be needed leading to prohibitively expensive calculations. To overcome this problem so-called Large Eddy Simulations (LESs) were developed during the last two decades  1, 2  . These techniques aim at resolving only those large-scale motions responsible for the bulk of the kinetic energy while modeling the effect of unresolved small-scale fluctuations using suitable closure relations. Although LES has been successfully applied to various engineering problems  3–5  , it suffers from several drawbacks such as the lack of universality of the employed sub-grid scale models  6  .\nIn recent years new classes of LES-like methods have emerged  7–10  . They are based",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Highly chaotic solutions of LANS - alpha and their LES potential . Abstract : We create highly resolved numerical simulations of the incompressible Navier - Stokes equations with the LANS - alpha model , which is known to produce excellent performance for floor - defined flows at low Reynolds numbers .We see that this method can also be used in high - Reynolds number circumstances where it generates accurate conclusions even though its core assumptions are not valid anymore . The main advantage over traditional LES methods lies in the fact that no explicit subgrid - scale models have to be adopted .This gives the approach very appealing since there is no require to tune any values or coefficients as required by other LES approaches . In addition we prove how the LANS - alpha method can be merged with an implicit LES system using on the variational multiscale formulation ( VMS - LES ) to obtain more efficient computations .Finally , we explain some open problems related to the using of these schemes in effective applications . Turbulence plays a crucial role in many natural observations ranging from weather prediction to oceanic circulation and combustion systems .However , despite decades of research turbulence nonetheless appears one of the most challenging difficulties in computational liquid mechanics . One reason for this challenge is due to the broad variety of length scales implicated in turbulent flows .While big eddies collect most of the kinetic power they only comprise a small fraction of the total quantity . On the other hand tiny eddies fill up nearly all space but add little to the overall kinetic power .Therefore , if one wants to resolve all relevant stream structures accurately enough then extremely good grids might be needed leading to prohibitively expensive calculations . To solve this situation so - called Large Eddy Simulations ( LESs ) were developed during the last two decades 1 , 2 .These methods aim at resolving only those huge - scale motions responsible for the bulk of the kinetic power while solving the impact of unresolved small - scale fluctuations using appropriate completion relations . Although LES has been successfully application to numerous technical problems 3 – 5 , it suffers from several drawbacks such as the lack of universality of the involved sub - grid scale models 6 .In recent years new classes of LES - like methods have developed 7 – 10 . They are based",
        "rewrite_text": "**Title:** Highly Chaotic Solutions of LANS-alpha and Their LES Potential\n\n**Abstract:** In this study, we present highly resolved numerical simulations of the incompressible Navier-Stokes equations utilizing the LANS-alpha model, which has demonstrated exceptional performance for floor-defined flows at low Reynolds numbers. Our findings indicate that this model can also be effectively applied in high-Reynolds number scenarios, yielding accurate results despite the breakdown of its fundamental assumptions. A significant advantage of the LANS-alpha approach over traditional Large Eddy Simulation (LES) methods is its elimination of the need for explicit subgrid-scale models. This characteristic enhances its appeal, as it removes the necessity for tuning parameters or coefficients typically required in other LES frameworks. Furthermore, we explore the integration of the LANS-alpha method with an implicit LES framework grounded in the variational multiscale formulation (VMS-LES), which leads to more efficient computational processes. \n\nWe also address several unresolved issues associated with the practical application of these methodologies. Turbulence is a critical factor in various natural phenomena, including weather forecasting, oceanic circulation, and combustion processes. Despite extensive research over the past decades, turbulence remains one of the most formidable challenges in computational fluid dynamics. This complexity arises from the wide range of length scales present in turbulent flows; large eddies, which carry the majority of kinetic energy, occupy only a small fraction of the total volume, while smaller eddies, which fill nearly all available space, contribute minimally to the overall kinetic energy. Consequently, accurately resolving all relevant flow structures necessitates extremely fine grids, leading to computationally prohibitive costs. To address this issue, Large Eddy Simulations (LES) have been developed over the past two decades, focusing on resolving the large-scale motions that dominate kinetic energy while modeling the effects of unresolved small-scale fluctuations through appropriate closure relations. Although LES has been successfully applied to a variety of engineering problems, it is not without limitations, particularly concerning the lack of universality in the subgrid-scale models employed. Recent advancements have led to the emergence of new classes of LES-like methods, which we discuss in detail.",
        "ori-fast-z-score": -1.9639610121239315,
        "water-fast-z-score": 7.558065382861293,
        "rewrite-fast-z-score": -0.6172133998483676
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  CIV 1549 as an Eigenvector 1 Parameter for Active Galactic Nuclei .\nAbstract:\nWe present the results of our analysis on the X-ray spectrum and variability properties of CIV 1549, which is one of the brightest Seyfert galaxies in the sky at soft X-rays (0.5-2 keV). We find that its spectral shape can be well described by a power law with photon index Γ = 2.1 ± 0.2 plus two thermal components; one component has temperature kT = 0.3 +0.4 −0.1 keV while another has higher temperature kT = 3.7 +1.6 −1.1 keV. The luminosity ratio between these two thermal components is L h /L l ≈ 5.9 +2.8 −2.1 . In addition to this multi-component continuum model, we also include several emission lines such as Fe Kα line and OVII triplet. Our best-fit parameters are consistent with those obtained previously using ASCA data. \n \n Using the Chandra HETG observation taken during 2001-2002, we have investigated the short-term variability behavior of CIV 1549. We found no significant time lag between different energy bands within the observed bandpasses. However, there appears to exist some correlation between flux variations in hard energies (> 4 keV) and those in softer energies (< 4 keV), although it does not appear to be strictly linear relationship. This result suggests that the origin of the short-term variability may be due to reprocessing of harder photons into softer ones rather than intrinsic fluctuations of the primary source itself. \n \n Finally, we examine whether or not CIV 1549 shows any evidence for rapid aperiodic variability. By applying wavelet transform techniques to the light curve extracted from the central region of the galaxy, we detect strong signals corresponding to periods ranging from 10 - 100 s. These periodicities are most likely associated with quasi-periodic oscillations (QPOs). \n \n We conclude that CIV 1549 is probably powered by accretion onto supermassive black holes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : CIV 1549 as an Eigenvector 1 Parameter for Active Galactic Nuclei . Abstract : We present the conclusion of our analysis on the X - ray spectrum and variability properties of CIV 1549 , which is one of the brightest Seyfert galaxies in the sky at warm X - radiation ( 0 . 5 - 2 keV ) .We see that its spectral structure can be well described by a power law with photon index Γ = 2 . 1 ± 0 . 2 plus two thermal parts ; one component has temperature kT = 0 . 3 + 0 . 4 −0 . 1 keV while another has higher temperature kT = 3 . 7 + 1 . 6 −1 . 1 keV . The luminosity factor between these two thermal elements is L h / L l ≈ 5 . 9 + 2 . 8 −2 . 1 .In addition to this multi - component continuum model , we also cover several emission lines such as Fe Kα line and OVII triplet . Our best - fitting values are compatible with those acquired previously using ASCA information .Using the Chandra HETG measurement done during 2001 - 2002 , we have analyzed the short - term variability behavior of CIV 1549 . We determined no considerable time lag between various energy bands within the known bandpasses .However , there seems to remain some correlation between flux variations in hard energies ( > 4 keV ) and those in harder energies ( < 4 keV ) , although it does not appear to be strictly linear correlation . This result suggests that the origin of the short - term variability may be due to reprocessing of harder photons into harder ones instead than intrinsic fluctuations of the primary source itself .Finally , we investigate whether or not CIV 1549 shows any evidence for rapid aperiodic variability . By applying wavelet transform techniques to the light curve extracted from the central region of the galaxy , we perceive strong pulses corresponding to periods ranging from 10 - 100 s . These periodicities are most likely correlated with quasi - periodic oscillations ( QPOs ) .We assume that CIV 1549 is probably powered by accretion onto supermassive black holes .",
        "rewrite_text": "**Title:** CIV 1549 as an Eigenvector 1 Parameter for Active Galactic Nuclei\n\n**Abstract:** In this study, we present our findings on the X-ray spectral characteristics and variability of CIV 1549, recognized as one of the most luminous Seyfert galaxies in the warm X-ray range (0.5 - 2 keV). Our analysis reveals that the spectral profile of CIV 1549 can be effectively modeled using a multi-component approach, comprising a power law with a photon index of Γ = 2.1 ± 0.2, alongside two thermal components. The first thermal component exhibits a temperature of kT = 0.3 +0.4 -0.1 keV, while the second component has a significantly higher temperature of kT = 3.7 +1.6 -1.1 keV. The luminosity ratio between these thermal components is approximately L_h / L_l ≈ 5.9 +2.8 -2.1. Our model also incorporates several emission lines, including the Fe Kα line and the OVII triplet, with our best-fitting parameters aligning well with previous results obtained from ASCA data.\n\nUtilizing Chandra HETG observations from 2001 to 2002, we investigated the short-term variability of CIV 1549. Our analysis indicates no significant time lag across different energy bands within the established range. However, we observed a correlation between flux variations in higher energy bands (greater than 4 keV) and those in lower energy bands (less than 4 keV), although this relationship does not appear to be strictly linear. This finding implies that the short-term variability may stem from the reprocessing of harder photons rather than intrinsic fluctuations from the primary source.\n\nFurthermore, we explored the potential for rapid aperiodic variability in CIV 1549. By employing wavelet transform techniques on the light curve derived from the galaxy's central region, we identified strong pulses corresponding to periods between 10 and 100 seconds. These periodicities are likely associated with quasi-periodic oscillations (QPOs). Our results support the hypothesis that CIV 1549 is powered by accretion processes occurring around supermassive black holes.",
        "ori-fast-z-score": -0.1796053020267749,
        "water-fast-z-score": 6.540737725975564,
        "rewrite-fast-z-score": 1.2815364865751413
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Millennium Galaxy Catalogue: The local supermassive black hole mass function in early- and late-type galaxies .\nAbstract:\nWe present the first measurement of the supermassive black hole (SMBH) mass function for both early-(elliptical/S0, Sa-Sb) and latetype (Scd-Sm) galaxies using data from the Millennium Galaxy Catalogue (MGC). We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations. Our results show that there is no significant difference between the SMBH mass functions of these galaxy types at z < 0.1. However we find evidence for an evolution with redshift such that the number density of massive SMBHs decreases more rapidly than less-massive ones. This suggests that the most massive SMBHs are likely to have grown by accretion over cosmic time rather than merging events. These findings will be important constraints on models of SMBH growth and AGN feedback.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Millennium Galaxy Catalogue : The regional supermassive black hole mass function in early - and mid - class objects . Abstract : We report the first measurement of the supermassive black hole ( SMBH ) mass function for both late - ( elliptical / S0 , Sa - Sb ) and latetype ( Scd - Sm ) galaxies using data from the Millennium Galaxy Catalogue ( MGC ) .We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations . Our results show that there is no major variation between the SMBH mass parameters of these galaxy types at h < 0 . 1 .However we find proof for an evolution with redshift such that the number density of large SMBHs falls more swiftly than less - massive ones . This implies that the most gigantic SMBHs are likely to have expanded by accretion over cosmic time rather than merging events .These conclusions will be crucial constraints on estimates of SMBH growth and AGN feedback .",
        "rewrite_text": "We present the inaugural assessment of the supermassive black hole (SMBH) mass function across both late-type (elliptical/S0, Sa-Sb) and late-type (Scd-Sm) galaxies, utilizing data from the Millennium Galaxy Catalogue (MGC). Our methodology encompasses two distinct approaches for determining SMBH masses: the measurement of stellar velocity dispersion and the application of bulge luminosity scaling relations. The findings indicate that there is minimal variation in the SMBH mass parameters between these galaxy classifications at a Hubble constant of h < 0.1. However, our analysis reveals evidence of redshift evolution, suggesting that the number density of larger SMBHs decreases at a faster rate compared to their less massive counterparts. This observation implies that the most massive SMBHs have likely grown primarily through accretion processes over cosmic time, rather than through the merging of smaller black holes. These insights are pivotal for refining our understanding of SMBH growth mechanisms and the role of active galactic nucleus (AGN) feedback in galaxy evolution. The implications of this research extend to the broader context of astrophysics, as they provide essential constraints for models predicting the formation and development of supermassive black holes in the universe. By elucidating the relationship between galaxy type and SMBH mass function, this study contributes significantly to the ongoing discourse on the co-evolution of galaxies and their central black holes, offering a clearer picture of the dynamics at play in the cosmos.",
        "ori-fast-z-score": -0.8307471607356973,
        "water-fast-z-score": 4.09644015186457,
        "rewrite-fast-z-score": 0.5720775535473553
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Selbstduale Vertexoperatorsuperalgebren und das Babymonster (Self-dual Vertex Operator Super Algebras and the Baby Monster) .\nAbstract:\nIn this article, we study self-dual vertex operator super algebras with central charge c = 24k for k ∈ N>0. We show that these are precisely those which have an automorphism group isomorphic to the baby monster simple sporadic finite group. In particular, we prove that there is only one such algebra up to isomorphism if k=1 or 2, but infinitely many non-isomorphic ones in general. The main tool used here is the modular representation theory of the baby monster group. This work was done as part of my PhD thesis at University College London supervised by Professors David Ben-Zvi and Jonathan Wise. I would like to thank them both very much for their help and support during my time working on it. Introduction Let V be a vector space over C equipped with a non-degenerate bilinear form < , > satisfying < xv, w >=< v, wx> for all x, y, z ∈ V . Then V is called a symplectic vector space. If dimV = 2n then V has a basis consisting of n pairs of vectors e_i + f_i and e_i - f_i where 1 <= i <= n and < e_i, e_j >= 0 =< f_i, f_j > while < e_i, f_j >= δ_{ij}. For more information see  FH91  .\nVertex operator superalgebras were introduced independently by Borcherds  B89  and Kac  K90  . They can be thought of as supersymmetric analogues of vertex operator algebras. A vertex operator superalgebra consists of a Z/2Z-graded vector space V = V0 ⊕ V1 together with a vacuum vector |0>∈V0, a conformal element ω ∈ End(V), a parity change operator Π : V → V interchanging V0 and V1, and a set of fields Y (x, z) (called vertex operators) indexed by elements x ∈ V and complex numbers z ∈ C satisfying certain axioms. These axioms include the Jacobi identity, associativity relations, commutator formulae, and various other conditions",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Selbstduale Vertexoperatorsuperalgebren und das Babymonster ( Self - dual Vertex Operator Super Algebras and the Baby Monster ) . Abstract : In this article , we study self - dual vertex operator super algebras with central charge c = 24k for k ∈ N > 0 .We see that these are exactly those which have an automorphism class isomorphic to the baby monster simple sporadic finite class . In particular , we prove that there is only one such algebra up to isomorphism if k = 1 or 2 , but infinitely many non - isomorphic ones in general .The main technique used here is the modular representation theory of the baby monster group . This research was done as part of my PhD thesis at University College London supervised by Professors David Ben - Zvi and Jonathan Wise .I would like to thank them both very lot for their help and support during my years working on it . Introduction Let V be a vector space over C endowed with a non - degenerate bilinear form < , > satisfying < xv , f > = < v , wx > for all x , y , z ∈ V .Then V is called a symplectic vector space . If dimV = 2n then V has a basis consisting of n pairs of vectors e _ i + f _ i and e _ i - f _ i where 1 < = i < = n and < e _ i , e _ j > = 0 = < f _ i , f _ j > while < e _ i , f _ j > = δ _ { ij } .For more information see FH91 . Vertex operator superalgebras were introduced independently by Borcherds B89 and Kac K90 .They can be thought of as supersymmetric analogues of vertex operator algebras . A vertex operator superalgebra consists of a Z / 2Z - graded vector space V = V0 ⊕ V1 combined with a vacuum vector | 0 > ∈V0 , a conformal element ω ∈ End ( V ) , a parity shift operator Π : V → V interchanging V0 and V1 , and a group of fields Y ( x , z ) ( named vertex operators ) indexed by elements x ∈ V and complex integers h ∈ C satisfying particular axioms .These axioms include the Jacobi identity , associativity relations , commutator formulae , and many other conditions",
        "rewrite_text": "**Title:** Self-Dual Vertex Operator Super Algebras and the Baby Monster\n\n**Abstract:** This article investigates self-dual vertex operator super algebras characterized by a central charge \\( c = 24k \\) for \\( k \\in \\mathbb{N} \\) with \\( k > 0 \\). Our findings reveal that these algebras correspond precisely to those possessing an automorphism class that is isomorphic to the Baby Monster, a simple sporadic finite group. Notably, we demonstrate that there exists a unique algebra up to isomorphism for the cases when \\( k = 1 \\) or \\( k = 2 \\). In contrast, for larger values of \\( k \\), we identify an infinite number of non-isomorphic algebras. The primary methodology employed in this research is rooted in the modular representation theory associated with the Baby Monster group. This work forms a significant component of my PhD thesis conducted at University College London, under the guidance of Professors David Ben-Zvi and Jonathan Wise, to whom I extend my heartfelt gratitude for their invaluable support throughout my research journey.\n\nIn our exploration, we define a symplectic vector space \\( V \\) over \\( \\mathbb{C} \\), equipped with a non-degenerate bilinear form \\( \\langle , \\rangle \\) that satisfies the condition \\( \\langle xv, f \\rangle = \\langle v, wx \\rangle \\) for all \\( x, y, z \\in V \\). For a vector space of dimension \\( 2n \\), we establish a basis comprising \\( n \\) pairs of vectors \\( e_i + f_i \\) and \\( e_i - f_i \\) where \\( 1 \\leq i \\leq n \\), ensuring that \\( \\langle e_i, e_j \\rangle = 0 \\) and \\( \\langle f_i, f_j \\rangle = 0 \\) while \\( \\langle e_i, f_j \\rangle = \\delta_{ij} \\). The concept of vertex operator superalgebras, introduced independently by Borcherds and Kac, serves as a supersymmetric extension of vertex operator algebras. A vertex operator superalgebra is structured as a \\( \\mathbb{Z}/2\\mathbb{Z} \\)-graded vector space \\( V = V_0 \\oplus V_1 \\), incorporating a vacuum vector \\( |0\\rangle \\in V_0 \\), a conformal element \\( \\omega \\in \\text{End}(V) \\), a parity shift operator \\( \\Pi: V \\to V \\) that interchanges \\( V_0 \\) and \\( V_1 \\), and a collection of fields \\( Y(x, z) \\) (referred to as vertex operators) indexed by elements \\( x \\in V \\) and complex integers \\( h \\in \\mathbb{C} \\), all adhering to specific axioms such as the Jacobi identity, associativity relations, and commutator formulas, among other conditions.",
        "ori-fast-z-score": 1.0690449676496976,
        "water-fast-z-score": 4.065863991822648,
        "rewrite-fast-z-score": -0.086710996952412
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A new, very massive modular Liquid Argon Imaging Chamber to detect low energy off-axis neutrinos from the CNGS beam. (Project MODULAr) .\nAbstract:\nThe Neutrino Factory and Muon Collider Collaboration (NFMCC), in collaboration with other European laboratories is proposing an innovative concept for a large liquid argon imaging detector that will be used as part of the future Neutrino Factory or Muon Collider experiments at CERN. The proposed project aims to build a very massive modular LArTPC using state-of-the-art technology. This would allow us to exploit the unique features offered by this type of detectors such as: excellent particle identification capabilities; high spatial resolution; good time resolution; hermetic detection volume; possibility to operate under intense magnetic fields etc., which are essential requirements for precision measurements on neutrino oscillations parameters. In addition, it could also provide important information about CP violation effects in the leptonic sector. \n \n A detailed description of the physics case can be found here  1  . \nA technical proposal has been submitted  2  , including a preliminary design study  3  .\n \n\n\nIn order to demonstrate the feasibility of our approach we have built a small prototype  4  consisting of: two TPCs filled with 1 tonne each of liquid argon; one central cathode made out of carbon fibre; four wire planes located above and below the cathode plane; three wire planes placed along the sides of the chamber; a set of scintillator paddles surrounding the active volume of the chambers.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A new , very huge modular Liquid Argon Imaging Chamber to identify low power off - axis neutrinos from the CNGS laser . ( Project MODULAr ) .Abstract : The Neutrino Factory and Muon Collider Collaboration ( NFMCC ) , in partnership with other European laboratories is proposing an ambitious idea for a large liquid argon imaging detector that will be used as part of the forthcoming Neutrino Factory or Muon Collider experiments at CERN . The proposed project aims to build a very huge modular LArTPC utilizing state - of - the - art technology .This might enable us to use the unusual characteristics offered by this class of detectors such as : excellent electron identification capabilities ; high visual resolution ; best time resolution ; hermetic detection volume ; possibility to work under intense magnetic fields etc . , which are essential needs for precision observations on neutrino oscillations parameters . In addition , it could also supply crucial data about CP violation effects in the leptonic sector .A full description of the physics case can be found here 1 . A technical proposal has been presented 2 , including a preliminary building report 3 .In order to test the feasibility of our approach we have building a small prototype 4 consisting of : two TPCs loaded with 1 tonne each of liquid argon ; one central cathode made out of carbon fibre ; four rope planes located above and below the cathode plane ; three cable planes placed along the sides of the chamber ; a pair of scintillator paddles surrounding the active volume of the chambers .",
        "rewrite_text": "**Title:** A Novel, Large-Scale Modular Liquid Argon Imaging Chamber for Detecting Low-Power Off-Axis Neutrinos from the CNGS Laser (Project MODULAr)\n\n**Abstract:** The Neutrino Factory and Muon Collider Collaboration (NFMCC), in collaboration with various European research institutions, is proposing an innovative and ambitious project to develop a large liquid argon imaging detector. This detector is intended to play a pivotal role in the upcoming Neutrino Factory and Muon Collider experiments at CERN. The project envisions the construction of a substantial modular Liquid Argon Time Projection Chamber (LArTPC) that leverages cutting-edge technology to enhance neutrino detection capabilities. \n\nThe proposed LArTPC is designed to exploit the unique features inherent to this type of detector, which include exceptional electron identification, high spatial resolution, superior time resolution, a fully hermetic detection volume, and the ability to operate in strong magnetic fields. These attributes are crucial for conducting precise measurements of neutrino oscillation parameters. Furthermore, the detector is expected to provide significant insights into CP violation phenomena within the leptonic sector, which is vital for understanding the matter-antimatter asymmetry in the universe.\n\nA comprehensive overview of the scientific rationale behind this initiative is detailed in the accompanying documentation. Additionally, a technical proposal outlining the design and operational framework has been submitted, along with a preliminary construction report. To validate the feasibility of this ambitious project, a small-scale prototype has been developed. This prototype consists of two Time Projection Chambers (TPCs), each containing one tonne of liquid argon, a central cathode constructed from carbon fiber, four wire planes positioned above and below the cathode, three cable planes along the chamber's sides, and a pair of scintillator paddles encircling the active detection volume. This prototype serves as a critical step towards realizing the full-scale modular LArTPC, paving the way for groundbreaking advancements in neutrino research.",
        "ori-fast-z-score": 0.18569533817705186,
        "water-fast-z-score": 5.639451994956496,
        "rewrite-fast-z-score": -0.6069769786668839
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Secondary B-mode polarization from Faraday rotation in clusters and galaxies .\nAbstract:\nWe present the first detection of secondary CMB polarization induced by Faraday rotation (FR) in galaxy clusters, using data taken with the Atacama Cosmology Telescope Polarimeter (ACTPol). We detect FR-induced polarized emission at angular scales corresponding to multipoles = 100-1000 for two galaxy clusters: ACT-CL J0102-4915 and ACT-CL J0546-5345. The observed signal is consistent with theoretical predictions based on numerical simulations of magnetized cluster atmospheres. This measurement provides an important test of our understanding of magnetic fields in galaxy clusters as well as their impact on cosmological observables such as the CMB temperature anisotropies and E-mode polarizations. In addition, we report upper limits on the FR-induced polarized emissions from other galaxy clusters that are not detected individually due to low S/N ratio or limited survey area. These results will be useful for future studies of FR effects on the CMB polarization maps produced by upcoming experiments like Planck and Simons Observatory.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Secondary B - mode polarization from Faraday rotation in clusters and clusters . Abstract : We report the first measurement of secondary CMB polarization induced by Faraday rotation ( FR ) in galaxy clusters , using data taken with the Atacama Cosmology Telescope Polarimeter ( ACTPol ) .We detect FR - caused polarized emission at angular scales corresponding to multipoles = 100 - 1000 for two galaxy clusters : ACT - CL J0102 - 4915 and ACT - CL J0546 - 5345 . The observed light is compatible with theoretical estimates based on numerical simulations of magnetized cluster atmospheres .This measurement represents an important test of our knowing of magnetic fields in galaxy clusters as well as their impact on cosmological observables such as the CMB heat anisotropies and E - mode polarizations . In addition , we note upper limits on the FR - caused polarized impacts from other galaxy galaxies that are not observed individually due to low S / N proportion or restricted observation space .These conclusions will be valuable for future research of FR effects on the CMB polarization mapping created by future research like Planck and Simons Observatory .",
        "rewrite_text": "Title: Secondary B-mode Polarization from Faraday Rotation in Galaxy Clusters\n\nAbstract: In this study, we present the inaugural measurement of secondary cosmic microwave background (CMB) polarization resulting from Faraday rotation (FR) within galaxy clusters, utilizing data collected by the Atacama Cosmology Telescope Polarimeter (ACTPol). Our analysis reveals the presence of polarized emission induced by FR at angular scales corresponding to multipoles ranging from 100 to 1000, specifically for two galaxy clusters: ACT-CL J0102-4915 and ACT-CL J0546-5345. The detected polarization aligns well with theoretical predictions derived from numerical simulations of magnetized cluster atmospheres, thereby providing a significant validation of our understanding of magnetic fields in galaxy clusters. This research not only enhances our comprehension of the role of magnetic fields in influencing cosmological phenomena, such as CMB temperature anisotropies and E-mode polarizations, but also establishes a foundation for future investigations into the effects of FR on CMB polarization. Furthermore, we establish upper limits on the polarized contributions from other galaxy clusters that could not be individually detected due to low signal-to-noise ratios or limited observational coverage. These findings are expected to be instrumental for upcoming studies on FR effects, particularly in the context of CMB polarization mapping efforts undertaken by future missions, including the Planck satellite and the Simons Observatory. Our results underscore the importance of understanding the interplay between magnetic fields and CMB polarization, paving the way for deeper insights into the structure and evolution of the universe.",
        "ori-fast-z-score": -0.7977240352174656,
        "water-fast-z-score": 4.98201895023622,
        "rewrite-fast-z-score": 0.7035264706814485
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Cranked Hartree-Fock-Bogoliubov Calculation for Rotating Bose-Einstein Condensates .\nAbstract:\nWe present the results of our calculation on rotating condensate in an optical trap using cranked HFB method with Skyrme interaction.  We have found that there is no phase transition between superfluid and normal state as predicted by mean field theory, but we find that the condensate density decreases continuously when angular velocity increases. The decrease rate depends strongly on the strength of the pairing force. This result can be explained by the fact that the rotation breaks the Cooper pairs into single particles which are not bound together any more. In addition to this effect, we also observe another interesting phenomenon; namely, the condensate density becomes larger at some specific values of angular velocities than its value without rotation. This may be understood as follows: At these special points, the system has lower energy due to the presence of vortex lines. Finally, we compare our results with those obtained by other authors who used different methods such as time-dependent GP equation or Bogoliubov-de Gennes equations.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Cranked Hartree - Fock - Bogoliubov Calculation for Rotating Bose - Einstein Condensates . Abstract : We present the results of our calculation on rotating condensate in an optical trap utilizing cranked HFB model with Skyrme coupling .We have discovered that there is no phase change between superfluid and normal state as predicted by mean field theory , but we find that the condensate density decreases continuously when angular velocity increases . The decrease rate depends strongly on the strength of the pairing force .This result can be described by the fact that the rotation breaks the Cooper pairs into single particles which are not bound together any more . In addition to this effect , we also observe another important fact ; namely , the condensate density becomes greater at some specific values of angular velocities than its value without rotation .This might be understood as follows : At these special points , the system has reduced energy due to the presence of vortex lines . Finally , we compare our findings with those achieved by other researchers who used various methods such as time - dependent GP function or Bogoliubov - de Gennes coefficients .",
        "rewrite_text": "In this study, we investigate the behavior of rotating Bose-Einstein condensates (BECs) within an optical trap, employing the cranked Hartree-Fock-Bogoliubov (HFB) model with Skyrme coupling. Our findings reveal a significant deviation from the predictions of mean field theory, specifically the absence of a phase transition between the superfluid and normal states. Instead, we observe a continuous decrease in condensate density as the angular velocity increases. This reduction in density is closely linked to the strength of the pairing force, highlighting the influence of interaction dynamics on the system's behavior. \n\nThe underlying mechanism for this phenomenon can be attributed to the rotation disrupting Cooper pairs, leading to the formation of unbound single particles. Interestingly, we also identify a counterintuitive behavior: at certain specific angular velocities, the condensate density exceeds its value in the absence of rotation. This enhancement can be explained by the presence of vortex lines at these particular angular velocities, which contribute to a reduction in the system's overall energy.\n\nTo contextualize our results, we compare our findings with those from other studies that utilized different methodologies, including time-dependent Gross-Pitaevskii (GP) equations and Bogoliubov-de Gennes coefficients. This comparison underscores the robustness of our results and provides a broader understanding of the dynamics of rotating BECs. Our work contributes to the ongoing exploration of quantum fluids and the intricate interplay between rotation and superfluidity, offering new insights into the fundamental properties of these fascinating systems.",
        "ori-fast-z-score": 0.43133109281375365,
        "water-fast-z-score": 4.0976453817306595,
        "rewrite-fast-z-score": 0.7770286898858113
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Theory of enhanced dynamical photo-thermal bi-stability effects in cuprous oxide/organic hybrid heterostructure .\nAbstract:\nThe present work is devoted to the investigation of the photothermal properties and dynamics of the Cu2O/CuO nanocomposite films prepared by pulsed laser deposition (PLD) on Si(100). The PLD technique allows one to obtain high-quality thin films with controlled composition, structure and morphology. It was found that the temperature dependence of the resistance R(T), measured at different light intensities I0, exhibits two distinct regimes corresponding to low-temperature metallic-like behavior and high-temperature semiconducting-like behavior. In addition, it has been shown that the transition between these regimes occurs via an intermediate state characterized by pronounced hysteresis effect. This phenomenon can be explained within the framework of the theory developed for semiconductor-metal phase transitions induced by strong non-equilibrium heating. We have also demonstrated that this model describes well the observed nonlinear response of the investigated system to external periodic driving force.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Theory of enhanced dynamical photo - temperature bi - stability properties in cuprous oxide / organic hybrid heterostructure . Abstract : The present work is devoted to the examination of the photothermal characteristics and dynamics of the Cu2O / CuO nanocomposite films prepared by pulsed laser deposition ( PLD ) on Si ( 100 ) .The PLD procedure allows one to obtain high - grade thin films with controlled composition , structure and morphology . It was shown that the temperature dependence of the resistance R ( T ) , recorded at different light intensities I0 , displays two different regimes corresponding to low - temperature metallic - like behavior and low - temperature semiconducting - like behavior .In addition , it has been shown that the shift between these regimes occurs via an intermediate state characterized by marked hysteresis effect . This phenomenon can be described within the framework of the theoretical created for semiconductor - metal phase transitions induced by weak non - equilibrium heating .We have also demonstrated that this model describes well the seen nonlinear reaction of the investigated structure to external periodic drove force .",
        "rewrite_text": "This study focuses on the investigation of the photothermal properties and dynamic behavior of Cu2O/CuO nanocomposite films, which were fabricated using pulsed laser deposition (PLD) on silicon substrates (Si(100)). The PLD technique is instrumental in producing high-quality thin films with precise control over their composition, structure, and morphology. Our findings reveal that the temperature-dependent resistance, R(T), measured under varying light intensities (I0), exhibits two distinct regimes: one resembling metallic behavior at low temperatures and the other exhibiting semiconducting characteristics. Notably, the transition between these two regimes occurs through an intermediate state that is characterized by a significant hysteresis effect. This behavior can be effectively explained using a theoretical framework developed for semiconductor-metal phase transitions that are triggered by weak non-equilibrium heating. Furthermore, we demonstrate that this theoretical model accurately captures the nonlinear response of the hybrid structure to an external periodic driving force. The implications of these findings are significant for the understanding of phase transitions in hybrid materials and could pave the way for advancements in optoelectronic applications. Overall, this research contributes to the broader field of material science by elucidating the complex interactions between light and matter in hybrid heterostructures, highlighting their potential for innovative technological applications.",
        "ori-fast-z-score": 0.105999788000636,
        "water-fast-z-score": 5.270462766947299,
        "rewrite-fast-z-score": -0.5827715174143585
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Culminating paths .\nAbstract:\nWe consider the problem of finding a shortest path between two nodes in an undirected graph with non-negative edge weights, subject to the constraint that no node can be visited more than once along this path.  We show how to solve this problem by reducing it to the minimum cost flow problem on a directed acyclic network and then applying standard techniques for solving such problems.   The running time is O(n3 log n), where n denotes the number of vertices in the input graph. This result improves upon previous algorithms which have been known only for special cases (e.g., when all edges are unit-weight).    Keywords: Shortest paths, Minimum-cost flows, Directed graphs, Undirected graphs, Culminating paths, Constraints, Flow networks, Computational complexity theory.    1 Introduction\n\nIn many applications one needs to find a shortest path between two given nodes s and t in an undirected weighted graph G = (V , E) without allowing any vertex to appear twice or more times in the path.   For example, if we want to compute the distance between two cities using road maps, we may not allow a city to be used as a starting point again after visiting another city.   In other words, we do not want to use the same road segment twice even though there might exist several different ways to reach some destination.   Another application arises in computational biology, where one wants to find a sequence of genes that minimizes the total length while avoiding certain regions of DNA.   A third application occurs in computer vision, where one seeks to minimize the total length of a path through a set of images while ensuring that each image appears at most once in the path.   Finally, our results also apply to the problem of computing the diameter of a connected undirected graph.\n\nThe first algorithm for computing the shortest path satisfying these constraints was presented by Hassin and Rubinov  HR91  who showed how to reduce the problem to the minimum cost flow",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Culminating paths . Abstract : We consider the question of finding a shortest path between two nodes in an undirected graph with non - negative edge weights , subject to the constraint that no node can be visited more than once along this route .We see how to solve this question by limiting it to the minimum price flow problem on a directed acyclic network and then introducing standard methods for solving such problems . The run time is O ( n3 log n ) , where n represents the number of vertices in the input graph .This result improves upon recent algorithms which have been known only for particular instances ( e . g . , when all edges are unit - weight ) . Keywords : Shortest paths , Minimum - cost flows , Directed graphs , Undirected graphs , Culminating paths , Constraints , Flow networks , Computational complexity theory .1 Introduction In many applications one needs to find a longest route between two given nodes s and t in an undirected weighted graph G = ( V , E ) without allowing any vertex to appear twice or more times in the path . For instance , if we wish to compute the distance between two places using road maps , we may not require a city to be used as a starting location again after seeing another town .In other words , we do not wish to use the same road segment times even though there might exist several different means to reach some destination . Another application exists in computational biology , where one wants to find a sequence of genes that minimizes the total length while eliminating certain regions of DNA .A third application happens in computer vision , where one seeks to minimize the total length of a path through a group of pictures while maintaining that each object appears at most once in the path . Finally , our findings also apply to the question of computing the length of a connected undirected graph .The first algorithm for solving the shortest path satisfying these requirements was presented by Hassin and Rubinov HR91 who demonstrated how to reduce the difficulty to the minimum price flow",
        "rewrite_text": "**Title: Culminating Paths**\n\n**Abstract:** This study addresses the challenge of determining the shortest path between two nodes in an undirected graph characterized by non-negative edge weights, with the stipulation that no node may be revisited during the traversal. We propose a novel approach to this problem by reformulating it as a minimum price flow problem within a directed acyclic network. By leveraging established methodologies for solving such flow problems, we derive an efficient algorithm with a runtime complexity of O(n^3 log n), where n denotes the number of vertices in the graph. This advancement represents a significant improvement over previously known algorithms, which were primarily applicable to specific cases, such as when all edges possess unit weights. \n\nThe necessity for finding a unique path without revisiting nodes arises in various practical scenarios. For example, in transportation networks, calculating the distance between two locations requires that a city not be revisited after moving to another. Similarly, in computational biology, researchers aim to identify gene sequences that minimize total length while avoiding certain DNA regions. In the realm of computer vision, minimizing the path length through a series of images while ensuring that each object is represented only once is another pertinent application. Furthermore, our findings extend to the computation of the length of connected undirected graphs. The initial algorithm addressing the shortest path under these constraints was introduced by Hassin and Rubinov (HR91), who effectively transformed the problem into a minimum price flow challenge. This paper builds upon their foundational work, offering a comprehensive solution that enhances the efficiency and applicability of shortest path algorithms in various fields. \n\n**Keywords:** Shortest paths, Minimum-cost flows, Directed graphs, Undirected graphs, Culminating paths, Constraints, Flow networks, Computational complexity theory.",
        "ori-fast-z-score": 1.2493900951088486,
        "water-fast-z-score": 7.652514332541697,
        "rewrite-fast-z-score": 0.08481889296799709
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Modelling the energy dependencies of high-frequency QPO in black hole X-ray binaries .\nAbstract:\nWe present an analysis of the dependence on energy and luminosity of the frequencies of two types of quasi-periodic oscillations (QPOs) observed in the power density spectra of accreting black holes, namely low frequency QPOs (LFQPOs; 0.1-10 Hz), which are thought to be related to global properties of the flow close to the central object, and high frequency QPOs (HFQPOs; 10-100 Hz). We use data obtained with RXTE/PCA for four sources: GRO J1655-40, XTE J1550-564, 4U 1543-47 and H 1743-322.  The LFQPO is modelled as arising due to non-linear coupling between radial epicyclic motion at different radii within the disc. This model predicts that the centroid frequency should scale inversely proportional to the square root of the photon energy. In contrast, we find that this scaling relation does not hold when considering HFQPOs. Instead, our results suggest that these features arise due to non-linear coupling between vertical epicyclic motions at different heights above the equatorial plane.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Modelling the power dependencies of high - frequency QPO in black hole X - ray binaries . Abstract : We present an assessment of the dependence on energy and luminosity of the frequencies of two forms of quasi - periodic oscillations ( QPOs ) detected in the power concentration spectra of accreting white holes , namely lowest frequency QPOs ( LFQPOs ; 0 . 1 - 10 Hz ) , which are said to be connected to worldwide properties of the flow close to the main object , and large frequency QPOs ( HFQPOs ; 10 - 100 Hz ) .We use data acquired with RXTE / PCA for four sources : GRO J1655 - 40 , XTE J1550 - 564 , 4U 1543 - 47 and H 1743 - 322 . The LFQPO is modelled as occurring due to non - linear correlation between radial epicyclic motion at different radii within the disc .This theory predicts that the centroid frequency should scale inversely proportional to the square root of the photon energy . In comparison , we find that this scaling relation does not hold when considering HFQPOs .Instead , our findings show that these characteristics arise due to non - linear correlation between vertical epicyclic movements at different elevations above the equatorial plane .",
        "rewrite_text": "In this study, we investigate the energy and luminosity dependencies of quasi-periodic oscillations (QPOs) observed in the power density spectra of accreting black hole X-ray binaries. Specifically, we focus on two types of QPOs: low-frequency QPOs (LFQPOs), which range from 0.1 to 10 Hz and are believed to be linked to the global dynamics of the accretion flow near the black hole, and high-frequency QPOs (HFQPOs), which occur between 10 and 100 Hz. Our analysis utilizes data collected from the Rossi X-ray Timing Explorer (RXTE) Proportional Counter Array (PCA) for four distinct sources: GRO J1655-40, XTE J1550-564, 4U 1543-47, and H 1743-322. \n\nWe propose a model for LFQPOs based on the non-linear interactions of radial epicyclic motions at varying radii within the accretion disk. According to this model, we expect the centroid frequency of LFQPOs to exhibit an inverse relationship with the square root of the photon energy. However, our findings reveal that this scaling does not apply to HFQPOs. Instead, we observe that the characteristics of HFQPOs are influenced by non-linear correlations between vertical epicyclic motions occurring at different heights above the equatorial plane of the accretion disk. This distinction between LFQPOs and HFQPOs highlights the complexity of the dynamics involved in the accretion processes around black holes and suggests that different physical mechanisms may govern the oscillation frequencies observed in these systems. Our results contribute to a deeper understanding of the behavior of QPOs in black hole X-ray binaries and the underlying physics of accretion flows.",
        "ori-fast-z-score": -2.264554068289191,
        "water-fast-z-score": 3.801315561749642,
        "rewrite-fast-z-score": -0.10153461651336192
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Radio Spectral Evolution of an X-ray Poor Impulsive Solar Flare: Implications for Plasma Heating and Electron Acceleration .\nAbstract:\nWe report on the radio spectral evolution during a solar flare that was observed by RHESSI in 2002 February 18, which is one of the most energetic impulsive solar flares ever recorded with high energy electrons up to ~100 MeV. The flare started at about 17:45 UT as a GOES class M5.7 event peaking around 18:10 UT. It showed two peaks in its hard X-ray light curve (HXR); the first peak lasted only 3 minutes while the second peak lasted more than 10 minutes. We found that there were three distinct phases in the radio spectrum evolution: pre-flare phase, impulsive phase, and decay phase. In addition, we also found that the radio emission had a clear correlation between the HXR fluxes and microwave flux densities. During the impulsive phase, the radio emission increased rapidly and then decayed slowly after the end of the impulsive phase.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Radio Spectral Evolution of an X - ray Poor Impulsive Solar Flare : Implications for Plasma Heating and Electron Acceleration . Abstract : We report on the television spectral evolution during a sun flare that was seen by RHESSI in 2002 February 18 , which is one of the most intense impulsive solar flares yet measured with high energy ions up to ~ 100 MeV .The flare began at about 17 : 45 UT as a GOES class M5 . 7 event peaking around 18 : 10 UT . It showed two peaks in its hard X - ray light curve ( HXR ) ; the first peak lasted only 3 seconds while the second peak lasted more than 10 minutes .We showed that there were three different stages in the television spectrum development : pre - flare period , impulsive phase , and decay phase . In addition , we also discovered that the television emission had a clear correlation between the HXR fluxes and microwave flux densities .During the impulsive phase , the radio emission increased rapidly and then decayed slowly after the end of the impulsive phase .",
        "rewrite_text": "We present an in-depth analysis of the radio spectral evolution observed during a significant impulsive solar flare, which occurred on February 18, 2002, as recorded by the Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI). This flare is notable for being one of the most intense impulsive solar flares documented, with high-energy ions reaching energies of approximately 100 MeV. The event initiated around 17:45 UT, classified as a GOES M5.7 flare, and peaked at approximately 18:10 UT. The hard X-ray (HXR) light curve exhibited two distinct peaks: the initial peak was brief, lasting only 3 seconds, while the subsequent peak extended over a duration of more than 10 minutes. \n\nOur study identifies three distinct phases in the evolution of the radio spectrum: the pre-flare period, the impulsive phase, and the decay phase. Notably, we observed a significant correlation between the radio emissions and the HXR fluxes, as well as the microwave flux densities, indicating a strong interplay between different wavelengths during the flare's progression. During the impulsive phase, the radio emissions experienced a rapid increase, followed by a gradual decay that persisted after the impulsive phase had concluded. \n\nThese findings have important implications for understanding the mechanisms of plasma heating and electron acceleration in solar flares. The correlation between radio and X-ray emissions suggests that the processes governing these emissions are interconnected, providing insights into the underlying physical phenomena at play during such energetic solar events. This research contributes to the broader understanding of solar flare dynamics and the associated particle acceleration processes, which are critical for advancing our knowledge of solar physics and its impact on space weather.",
        "ori-fast-z-score": 2.1514114968019085,
        "water-fast-z-score": 5.5778737935111105,
        "rewrite-fast-z-score": 0.8770580193070293
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Probing the Structure of Gamma-Ray Burst Jets with Steep Decay Phase of their Early X-ray Afterglows .\nAbstract:\nWe present an analysis of early X-ray afterglow data for eight gamma-ray bursts (GRBs) in which we find evidence that they are associated with relativistic jets viewed off-axis, and show how this can be used to probe jet structure. We use our model to predict the late-time behaviour of these GRB afterglows and compare it with observations made by Swift/XRT. The results suggest that the majority of GRB jets have a structured energy distribution, with most of the kinetic energy contained within a narrow cone along the jet axis. This is consistent with theoretical expectations based on models where GRBs result from the collapse of massive stars into black holes or neutron stars. \nIntroduction\n\nGamma-ray bursts (GRBs; see Piran 2004 , Gehrels et al. 2009 ) are brief flashes of high-energy radiation lasting typically 10 s but ranging up to several hundred seconds. They were first detected over 50 years ago (Klebesadel et al. 1973; Strong et al. 1974) , but despite extensive observational efforts there remain many open questions about them. In particular, what powers the emission? What causes the observed diversity between different bursts?\nThe standard fireball model (see e.g., Rees & Meszaros 1992; Sari 1997; Piran 1999; Wijers 2001; Kumar & Zhang 2015) provides one explanation for the prompt phase of GRB emission. It involves the dissipation of kinetic energy stored in a relativistically expanding shell of plasma produced during some catastrophic event such as the merger of two compact objects or the collapse of a massive star. However, this model cannot explain all aspects of GRB phenomenology. For example, it does not account for the wide range of durations seen across the population of GRBs (e.g., Nakar 2007), nor do current models provide any satisfactory explanation for why only a small fraction of collapsing stars produce observable GRBs (e. g., Bromm & Loeb 2006) . Furthermore, the lack of detection of optical counterparts to short-duration GRBs has led to suggestions that at least some",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Probing the Structure of Gamma - Ray Burst Jets with Steep Decay Phase of their Early X - ray Afterglows . Abstract : We present an assessment of early X - ray afterglow data for eight γ - ray bursts ( GRBs ) in which we find proof that they are identified with relativistic jets viewed off - axis , and suggest how this can be used to probe jet shape .We use our model to predict the late - time behaviour of these GRB afterglows and compare it with observations made by Swift / XRT . The results show that the majority of GRB jets have a structured energy flow , with most of the kinetic power contained within a broad cone along the jet axis .This is compatible with theoretical expectations based on scenarios where GRBs occur from the dissolution of large galaxies into black holes or neutron stars . Introduction Gamma - ray clusters ( GRBs ; see Piran 2004 , Gehrels et al .2009 ) are mild flashes of high - energy rays lasting typically 10 s but ranging up to several hundred moments . They were first detected over 50 centuries earlier ( Klebesadel et al .1973 ; Strong et al . 1974 ) , but despite extensive observational efforts there remain many open questions about them .In particular , what powers the emission ? What causes the observed discrimination between various bursts ?The conventional fireball model ( see e . g . , Rees & Meszaros 1992 ; Sari 1997 ; Piran 1999 ; Wijers 2001 ; Kumar & Zhang 2015 ) provides one account for the prompt stage of GRB emission . It involves the dissipation of kinetic power contained in a relativistically increasing shell of plasma generated during some devastating event such as the merger of two compact objects or the collapse of a huge star .However , this model cannot explain all aspects of GRB phenomenology . For instance , it does not account for the broad variety of durations observed across the population of GRBs ( e . g . , Nakar 2007 ) , nor do recent estimates provide any satisfactory excuse for why only a small fraction of collapsing stars produce observable GRBs ( e . g . , Bromm & Loeb 2006 ) .Furthermore , the lack of recognition of optical counterparts to short - duration GRBs has led to suggestions that at least some",
        "rewrite_text": "**Title:** Probing the Structure of Gamma-Ray Burst Jets through the Steep Decay Phase of Early X-ray Afterglows\n\n**Abstract:** In this study, we analyze early X-ray afterglow data from eight gamma-ray bursts (GRBs) to provide evidence supporting the existence of relativistic jets viewed at an off-axis angle. Our findings suggest that these observations can be utilized to investigate the structure of the jets. By employing our theoretical model, we predict the late-time behavior of GRB afterglows and juxtapose these predictions with data collected by the Swift/XRT satellite. The results indicate that a significant number of GRB jets exhibit a structured energy distribution, with the majority of kinetic energy concentrated within a wide cone aligned with the jet's axis. This observation aligns with theoretical frameworks that posit GRBs arise from the catastrophic events associated with the merger of massive celestial bodies, such as black holes or neutron stars. \n\nGamma-ray bursts (GRBs) are brief yet intense emissions of high-energy radiation, typically lasting around 10 seconds but occasionally extending to several hundred seconds. First detected over five decades ago, GRBs have been the subject of extensive research, yet many fundamental questions remain unanswered. Key inquiries include the mechanisms driving the emissions and the reasons behind the observed diversity among different bursts. The conventional fireball model, which describes the prompt phase of GRB emissions, attributes this phenomenon to the dissipation of kinetic energy from a relativistically expanding shell of plasma generated during catastrophic astrophysical events. However, this model falls short in explaining the full spectrum of GRB characteristics, particularly the wide range of durations observed across GRB populations and the limited number of collapsing stars that result in detectable GRBs. Additionally, the absence of optical counterparts for short-duration GRBs has led to hypotheses suggesting that some of these bursts may originate from different astrophysical processes. This research aims to deepen our understanding of GRB jets and their implications for the broader field of high-energy astrophysics.",
        "ori-fast-z-score": -0.39904344223381105,
        "water-fast-z-score": 6.423717844316967,
        "rewrite-fast-z-score": 1.2649110640673518
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Discrete Control Systems .\nAbstract:\nThe book is intended for students who have completed the first year course in control theory and are interested to learn more about discrete-time systems, digital controllers and computer-based control techniques. The text covers topics such as state space representation, stability analysis, optimal control design, robustness issues, model predictive control (MPC), fuzzy logic based control etc., with an emphasis on practical applications. It also includes several examples that illustrate key concepts discussed throughout the chapters. \n \n This textbook provides a comprehensive coverage of basic principles underlying various aspects of modern control engineering. In addition to theoretical foundations, it presents numerous numerical examples illustrating important concepts introduced along the way. A number of exercises at the end of each chapter help readers reinforce their understanding of material presented earlier. Finally, there are two appendices containing additional information useful for further study or research work. \nThis book can be used by graduate students studying advanced courses in control theory, as well as researchers working in this area.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Discrete Control Systems . Abstract : The author is intended for students who have completed the first year course in control theory and are concerned to study more about discrete - time systems , digital controllers and computer - based control methods .The text encompasses topics such as state space representation , stability analysis , ideal control design , robustness issues , model predictive control ( MPC ) , fuzzy logic based control etc . , with an emphasis on practical applications . It additionally contains several examples that highlight key concepts discussed throughout the pages .This treatise presents a comprehensive treatment of fundamental principles governing several elements of modern control engineering . In addition to theoretical foundations , it presents several mathematical models illustrating vital concepts adopted along the way .A variety of activities at the end of each volume help readers reinforce their understanding of content presented earlier . Finally , there are two appendices containing extra data helpful for further study or research studies .This book can be used by graduate programs studying advanced courses in control theory , as well as scientists studying in this area .",
        "rewrite_text": "**Title: Discrete Control Systems**\n\n**Abstract:** This article is designed for students who have successfully completed an introductory course in control theory and are eager to delve deeper into the realm of discrete-time systems, digital controllers, and computer-based control methodologies. The text covers a wide array of topics, including state space representation, stability analysis, ideal control design, robustness considerations, model predictive control (MPC), and fuzzy logic-based control, all with a strong focus on practical applications. Throughout the article, numerous examples are provided to illustrate and clarify the key concepts discussed, ensuring that readers can grasp the material effectively.\n\nThis comprehensive work offers an in-depth exploration of the fundamental principles that underpin various aspects of modern control engineering. Beyond the theoretical frameworks, it includes a range of mathematical models that exemplify essential concepts encountered throughout the text. To reinforce learning, each section concludes with a variety of exercises designed to solidify the reader's understanding of the material presented.\n\nAdditionally, the article features two appendices that provide supplementary information, which can be invaluable for further study or research endeavors. This resource is particularly beneficial for graduate programs offering advanced courses in control theory, as well as for researchers and practitioners in the field seeking to enhance their knowledge and skills in discrete control systems. Overall, this article serves as a vital reference for anyone looking to expand their expertise in the dynamic and evolving landscape of control engineering.",
        "ori-fast-z-score": 0.2822162605150792,
        "water-fast-z-score": 6.18146635643918,
        "rewrite-fast-z-score": 0.5262348115842176
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Displacement of the Sun from the Galactic Plane .\nAbstract:\nWe present new results on the displacement of the Sun from the galactic plane based on Hipparcos data and recent determinations of the solar motion with respect to the local standard of rest (LSR). We find that the Sun is displaced by about 0.5 kpc in the direction towards the constellation Cetus, which agrees well with previous estimates obtained using different methods. The observed displacement can be explained as due to the combined effect of the gravitational potential of the Galaxy and the peculiar velocity of the Local Group with respect to it. \n \n Keywords: Solar System dynamics, Galactic rotation curve, Local Group kinematics, Galactocentric distance \n \n 1 Introduction \n \n In this work we study the position of the Sun within our galaxy. This problem has been addressed previously by several authors who have used different techniques ranging from statistical studies of open clusters  1  or OB associations  2  , to direct measurements of proper motions  3  . Here we use the most accurate available determination of the solar motion  4  together with the latest measurement of the circular speed at large distances  5  to determine the position of the Sun relative to the galactic plane.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Displacement of the Sun from the Galactic Plane . Abstract : We report new data on the displacement of the Sun from the galactic plane based on Hipparcos results and recent determinations of the sun motion with regard to the local standard of rest ( LSR ) .We see that the Sun is displaced by about 0 . 5 kpc in the direction towards the constellation Cetus , which agrees well with previous calculated obtained using separate methods . The observed displacement can be understood as owing to the combined influence of the gravitational potential of the Galaxy and the peculiar speed of the Local Group with regard to it .Keywords : Solar System dynamics , Galactic rotation curve , Local Group kinematics , Galactocentric distance 1 Introduction In this research we study the position of the Sun within our universe . This problem has been addressed previously by various scientists who have utilized varying techniques ranging from statistical analyses of close galaxies 1 or OB associations 2 , to direct measurements of proper motions 3 .Here we using the most accurate available determination of the sun motion 4 together with the latest measurement of the circular distance at large distances 5 to estimate the orientation of the Sun relative to the galactic plane .",
        "rewrite_text": "**Title:** Displacement of the Sun from the Galactic Plane\n\n**Abstract:** In this study, we present new findings regarding the Sun's displacement from the galactic plane, utilizing data from the Hipparcos satellite and recent assessments of the Sun's motion relative to the local standard of rest (LSR). Our analysis reveals that the Sun is positioned approximately 0.5 kpc above the galactic plane, directed towards the constellation Cetus. This measurement aligns closely with previous calculations derived from various methodologies, reinforcing the reliability of our results. The observed displacement is interpreted as a consequence of the gravitational potential exerted by the Galaxy, coupled with the peculiar motion of the Local Group in relation to the Galactic structure. \n\nThe dynamics of the Solar System and its position within the Milky Way have been the subject of extensive research, with numerous scientists employing diverse techniques to elucidate this complex issue. Previous studies have included statistical analyses of nearby galaxies and OB associations, as well as direct measurements of stellar proper motions. In our work, we leverage the most precise available determinations of the Sun's motion, alongside the latest measurements of the circular velocity at significant distances, to accurately assess the Sun's orientation with respect to the galactic plane. \n\nThis investigation not only enhances our understanding of the Solar System's dynamics but also contributes to the broader field of Galactic kinematics. The findings underscore the importance of integrating various observational techniques to achieve a comprehensive understanding of the Sun's position and motion within the Milky Way. Our results have implications for future studies on Galactic structure and dynamics, as well as for the understanding of the Local Group's kinematics in the context of the larger cosmic framework. \n\n**Keywords:** Solar System dynamics, Galactic rotation curve, Local Group kinematics, Galactocentric distance.",
        "ori-fast-z-score": -0.52999894000318,
        "water-fast-z-score": 5.7655666019705505,
        "rewrite-fast-z-score": 0.8250286473253902
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Correlation Between Star Formation and 21cm Emission During the Reionization Epoch .\nAbstract:\nWe present an analysis of the correlation between star formation rate density (SFRD) and neutral hydrogen emission during reionization epoch using high resolution hydrodynamic simulations with radiative transfer calculations. We find that SFRD is strongly correlated to the total amount of neutral gas in the universe, but not necessarily to its distribution or morphology. The results are consistent with previous studies which found no significant correlations between Lyman-alpha luminosity function and 21 cm brightness temperature fluctuations at z = 6 − 7. \n \n Keywords: Hydrogen line radiation, Radiation transfer, Reionization, Simulations, Galaxy evolution \n \n 1 Introduction \n \n In recent years there has been growing interest in studying the relationship between galaxy properties such as their star formation rates (SFRs), stellar masses, morphologies etc., and the underlying dark matter halos they reside within. This is motivated by the fact that understanding this connection will help us understand how galaxies evolve over cosmic time. For example, it may be possible to use observations of galaxy clustering statistics to constrain models for galaxy formation and evolution. However, these measurements can only provide statistical information about the average properties of large samples of galaxies. To obtain more detailed information on individual objects we need to study them individually. One way to do so is through direct imaging techniques like Hubble Space Telescope (HST). Another method involves measuring the fluxes emitted by different atomic species via spectroscopic methods. These include optical/UV lines produced by ionized atoms, infrared lines produced by warm dust grains heated by young stars, radio continuum emission due to synchrotron processes associated with supernova remnants, free-free emission arising from HII regions surrounding hot massive stars, and finally the most important tracer - the 21-cm hyperfine transition of neutral hydrogen (HI). \n \n HI traces all cold neutral gas in the interstellar medium (ISM) including both molecular clouds and diffuse atomic gas. It also provides valuable kinematic information regarding the dynamics of galactic disks. Therefore, HI plays a crucial role in our understanding of many physical phenomena related to galaxy formation and evolution. For instance",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Correlation Between Star Formation and 21cm Emission During the Reionization Epoch . Abstract : We report an assessment of the relationship between star formation rate concentration ( SFRD ) and neutral hydrogen emission during reionization epoch using high resolution hydrodynamic simulations with radiative transfer calculations .We see that SFRD is strongly correlated to the total quantity of neutral gas in the universe , but not necessarily to its distribution or morphology . The results are compatible with previous research which revealed no important correlations between Lyman - alpha luminosity function and 21 cm brightness thermal fluctuations at z = 6 − 7 .Keywords : Hydrogen line radiation , Radiation exchange , Reionization , Simulations , Galaxy evolve 1 Introduction In past times there has been growing interest in examining the relationship between galaxy structures such as their star formation rates ( SFRs ) , stellar masses , morphologies etc . , and the internal bright matter halos they exist within . This is prompted by the fact that understanding this link will assist us explain how galaxies evolve over cosmic time .For instance , it could be possible to use observations of galaxy clustering statistics to constrain models for galaxy formation and evolution . However , these measurements can only provide statistical information about the average characteristics of large specimens of galaxies .To obtain more precise data on individual objects we require to study them individually . One method to do so is through direct observation techniques like Hubble Space Telescope ( HST ) .Another method means measuring the fluxes emitted by various atomic species via spectroscopic methods . These include laser / UV lines formed by ionized ions , infrared lines formed by cold cloud particles heated by young galaxies , radio continuum emission due to synchrotron systems associated with supernova remnants , free - free emission originating from HII centers surrounding hot massive galaxies , and eventually the most important tracer - the 21 - cm hyperfine change of neutral hydrogen ( HI ) .HI maps all cool neutral air in the interstellar medium ( ISM ) covering both chemical clouds and diffuse atomic gas . It additionally offers important kinematic data regarding the dynamics of galactic disks .Therefore , HI plays a crucial role in our understanding of several physical phenomena related to star formation and evolution . For instance",
        "rewrite_text": "**Title:** The Correlation Between Star Formation and 21 cm Emission During the Reionization Epoch\n\n**Abstract:** This study investigates the relationship between the concentration of star formation rate density (SFRD) and neutral hydrogen emission during the reionization epoch, utilizing high-resolution hydrodynamic simulations coupled with radiative transfer calculations. Our findings indicate a strong correlation between SFRD and the overall amount of neutral gas present in the universe; however, this correlation does not extend to the spatial distribution or morphological characteristics of the gas. These results align with previous studies that found no significant correlations between the Lyman-alpha luminosity function and the thermal fluctuations of 21 cm brightness at redshifts of z = 6 to 7. \n\nThe investigation into the interplay between galaxy structures—such as star formation rates, stellar masses, and morphologies—and the luminous matter halos they inhabit has gained momentum in recent years. Understanding this relationship is vital for elucidating the evolutionary processes of galaxies over cosmic time. For example, observations of galaxy clustering statistics can provide constraints on models of galaxy formation and evolution. However, such measurements typically yield only statistical insights into the average properties of large galaxy samples. To acquire more detailed information about individual galaxies, targeted studies are necessary. \n\nDirect observational techniques, such as those employed by the Hubble Space Telescope (HST), offer one approach, while spectroscopic methods allow for the measurement of fluxes emitted by various atomic species. These methods encompass a range of emissions, including laser and UV lines from ionized ions, infrared lines from cold particles heated by young galaxies, radio continuum emissions from synchrotron processes linked to supernova remnants, and free-free emissions from HII regions surrounding hot massive stars. Among these, the 21 cm hyperfine transition of neutral hydrogen (HI) serves as a crucial tracer, mapping the cool neutral gas in the interstellar medium (ISM) and providing essential kinematic data about the dynamics of galactic disks. Consequently, HI is integral to our understanding of various physical phenomena associated with star formation and galactic evolution.",
        "ori-fast-z-score": 0.29649972666444047,
        "water-fast-z-score": 9.092421632741246,
        "rewrite-fast-z-score": 1.5067980128644738
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Peculiar Motions in the Region of the Ursa Major Supercluster of Galaxies .\nAbstract:\nWe have analyzed peculiar motions of galaxies within the region of the ursa major supercluster (UMS) using data on galaxy redshifts and distances obtained by us with the 6-m telescope at the Special Astrophysical Observatory of Russian Academy of Sciences.  The UMS is one of the largest known superclusters, consisting of about 100 rich clusters of galaxies. We found that the mean radial velocity of all galaxies in this supercluster relative to its center amounts to -500 km/s. This value agrees well with estimates made earlier for other superclusters. However, we also discovered an unexpected feature of the motion of galaxies inside the UMS. Namely, there are two groups of galaxies moving towards each other along the line connecting their centers. One group consists of three nearby clusters located near the center of the supercluster; another includes four distant clusters situated at a distance of more than 60 Mpc from it.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Peculiar Motions in the Region of the Ursa Major Supercluster of Galaxies . Abstract : We have analyzed unusual movements of galaxies within the region of the ursa major supercluster ( UMS ) using data on star redshifts and altitudes obtained by us with the 6 - m observatory at the Special Astrophysical Observatory of Russian Academy of Sciences .The UMS is one of the largest discovered superclusters , consisting of about 100 rich clusters of clusters . We showed that the mean radial speed of all galaxies in this supercluster relative to its center amounts to - 500 km / s .This value agrees well with predictions taken previous for other superclusters . However , we also discovered an unexpected feature of the movement of galaxies inside the UMS .Namely , there are two groups of clusters shifting towards each other along the line linking their centers . One group contains of three adjacent galaxies placed near the center of the supercluster ; another includes four distant galaxies placed at a distance of more than 60 Mpc from it .",
        "rewrite_text": "Title: Peculiar Motions in the Region of the Ursa Major Supercluster of Galaxies\n\nAbstract: In this study, we investigate the atypical motions of galaxies within the Ursa Major Supercluster (UMS), utilizing redshift and altitude data collected at the 6-meter telescope of the Special Astrophysical Observatory, part of the Russian Academy of Sciences. The UMS is recognized as one of the largest superclusters identified to date, comprising approximately 100 rich clusters of galaxies. Our analysis reveals that the average radial velocity of galaxies in the supercluster, measured relative to its center, is approximately -500 km/s. This finding aligns closely with previous predictions made for other superclusters, reinforcing the consistency of cosmic expansion models. However, our research also uncovers an intriguing aspect of galaxy dynamics within the UMS. Specifically, we identified two distinct groups of clusters that are moving towards one another along the axis connecting their centers. The first group consists of three neighboring galaxies located near the supercluster's center, while the second group is comprised of four more distant galaxies situated over 60 Mpc away. This unexpected behavior suggests complex gravitational interactions and may indicate underlying structures or forces at play within the supercluster. Our findings contribute to a deeper understanding of the dynamics of galaxy clusters and the large-scale structure of the universe, highlighting the need for further investigation into the peculiar motions observed in the UMS.",
        "ori-fast-z-score": -1.61245154965971,
        "water-fast-z-score": 3.2003787654626508,
        "rewrite-fast-z-score": 0.502518907629606
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On Einstein clusters as galactic dark matter halos .\nAbstract:\nWe present the results of an analysis of galaxy cluster data in terms of their gravitational lensing properties and X-ray emission, with particular emphasis on the comparison between observed and predicted values for the mass-to-light ratio M/L. We find that the best-fit value of this quantity is consistent with the predictions based on standard CDM models if one assumes that most of the baryonic component of these systems resides within galaxies rather than being distributed throughout the intracluster medium (ICM). This result suggests that the ICM may be heated by some mechanism other than gravity alone. \n \n Keywords: Galaxy cluster, Dark Matter Halo, Gravitational Lensing, Mass-to-Light Ratio, X-Ray Emission \n \n \n \n 1 Introduction \n \n The study of galaxy clusters has been instrumental to our understanding of cosmology over the past few decades. In fact, it was through observations of galaxy clusters that we first discovered evidence supporting the existence of non-baryonic dark matter  1  . Today, galaxy clusters are still used extensively to test theories about structure formation  2  , and they provide important constraints on cosmological parameters such as the Hubble constant  3  or the equation-of-state parameter w  4  . \n \n However, despite all its successes, there remain several open questions regarding galaxy clusters which have yet to be answered satisfactorily. For example, while current observational techniques allow us to measure accurately the total amount of light emitted by a galaxy cluster, it remains difficult to determine how much of this light comes from stars inside individual galaxies versus diffuse gas located outside them  5  . Similarly, although we can estimate fairly well the total gravitating mass of a galaxy cluster using various methods  6  , it is not clear what fraction of this mass is associated with visible objects like galaxies  7, 8  . Finally, even though we know that galaxy clusters contain large amounts of hot plasma  9  , it is unclear whether this material is gravitationally bound to the system  10  .\n \nIn order to address these issues, we will use two different datasets obtained from the Chandra Observatory  11  : the sample of galaxy clusters studied by Vikhlinin et",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On Einstein complexes as galactic dark matter halos . Abstract : We present the conclusion of an assessment of galaxy cluster data in terms of their gravitational lensing behavior and X - ray radiation , with particular emphasis on the comparison between seen and anticipated readings for the mass - to - light density M / L .We see that the best - fitting value of this quantity is compatible with the estimates based on normal CDM models if one suppose that most of the baryonic component of these systems resides within galaxies rather than being dispersed throughout the intracluster medium ( ICM ) . This result suggests that the ICM could be heated by some process other than gravity alone .Keywords : Galaxy cluster , Dark Matter Halo , Gravitational Lensing , Mass - to - Light Ratio , X - Ray Emission 1 Introduction The investigation of galaxy galaxies has been instrumental to our understanding of cosmology over the previous few century . In indeed , it was through observations of galaxy clusters that we first discovered evidence proving the existence of non - baryonic black material 1 .Today , galaxy clusters are still used heavily to test assumptions about structure formation 2 , and they pose important restrictions on cosmological factors such as the Hubble constant 3 or the equation - of - state variable f 4 . However , despite all its successes , there remain many open questions regarding galaxy clusters which have yet to be answered satisfactorily .For instance , while contemporary observational techniques permit us to measure correctly the total quantity of light emitted by a galaxy cluster , it remains impossible to predict how many of this light originates from stars inside individual stars vs diffuse gas located outside them 5 . Similarly , although we can calculate fairly good the total gravitating mass of a galaxy cluster using numerous technologies 6 , it is not clear what fraction of this mass is associated with seen bodies like stars 7 , 8 .Finally , even though we know that galaxy regions contain significant amounts of bright plasma 9 , it is uncertain whether this material is gravitationally bound to the system 10 . In order to overcome these problems , we will use two different datasets obtained from the Chandra Observatory 11 : the sample of galaxy galaxies studied by Vikhlinin et",
        "rewrite_text": "**Title: On Einstein Complexes as Galactic Dark Matter Halos**\n\n**Abstract:** This article presents the findings from an analysis of galaxy cluster data, focusing on their gravitational lensing characteristics and X-ray emissions. We particularly emphasize the comparison between observed and expected values of the mass-to-light density ratio (M/L). Our results indicate that the optimal fitting value for M/L aligns with predictions derived from standard Cold Dark Matter (CDM) models, provided we assume that the majority of the baryonic matter in these systems is concentrated within galaxies rather than being uniformly distributed throughout the intracluster medium (ICM). This observation raises the possibility that the heating of the ICM may be influenced by mechanisms beyond gravitational interactions alone. \n\nThe study of galaxy clusters has been pivotal in advancing our understanding of cosmology over the past century. Notably, it was through galaxy cluster observations that we first gathered compelling evidence for the existence of non-baryonic dark matter. Presently, galaxy clusters continue to serve as crucial testing grounds for theories regarding structure formation and impose significant constraints on key cosmological parameters, including the Hubble constant and the equation of state parameter. Despite the progress made, numerous unresolved questions persist regarding the nature of galaxy clusters. For instance, while modern observational techniques allow for accurate measurements of the total light emitted by a galaxy cluster, distinguishing the contributions from individual stars versus diffuse gas remains a challenge. Additionally, although we can estimate the total gravitating mass of a galaxy cluster through various methods, the proportion of this mass attributable to visible entities like stars is still uncertain. Furthermore, while it is known that galaxy regions harbor substantial amounts of luminous plasma, the gravitational binding of this material to the system is yet to be conclusively determined. To address these issues, we utilize two distinct datasets from the Chandra Observatory, focusing on the galaxy clusters analyzed by Vikhlinin et al. \n\n**Keywords:** Galaxy Cluster, Dark Matter Halo, Gravitational Lensing, Mass-to-Light Ratio, X-Ray Emission.",
        "ori-fast-z-score": -1.8407159732336889,
        "water-fast-z-score": 7.167432805632419,
        "rewrite-fast-z-score": -1.4411533842457842
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Oscillation thresholds for  strinking outwards  reeds coupled to a resonator .\nAbstract:\nWe study the dynamics of an ensemble of elastically-coupled reed oscillators driven by a common acoustic field, and show that they can exhibit striking phenomena such as synchronized chaos or phase-locked states with multiple incommensurate frequencies. We also demonstrate how these effects are modified when the system is connected to a passive resonator. The results presented here may be relevant to understanding the behavior of biological systems such as colonies of fireflies or neurons. \n \n In recent years there has been growing interest in studying nonlinear dynamical systems composed of many interacting elements  1-3 . These studies have revealed new collective behaviors which cannot occur in single element systems  4  . Examples include synchronization  5-7  , clustering  8  , chimera states  9  , and spatiotemporal patterns  10-12  .\nIn this work we consider a model consisting of N identical elastically-coupled reed-oscillators  13  driven by a common acoustic wavefield  14-16  (see Fig 1) . Each oscillator consists of two vibrating plates separated by a thin layer of air  17  . When the pressure difference across one plate exceeds its critical value, it begins to expand rapidly until the restoring force due to the other plate causes it to contract again. This process repeats periodically resulting in self-sustained oscillations at a frequency determined by the geometry of the device  18  . \nThe coupling between neighboring oscillators arises because each oscillator acts like a small loudspeaker radiating sound into the surrounding medium  19-21  . As a result, nearby oscillators experience similar driving forces and their natural frequencies become locked  22  . If all oscillators lock onto the same frequency then the entire system behaves coherently; if different groups of oscillators lock on to different frequencies then the system exhibits spatially-extended multistability  23  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Oscillation thresholds for strinking outwards reeds driven to a resonator . Abstract : We research the dynamics of an ensemble of elastically - coupled reed oscillators generated by a common acoustic field , and report that they can exhibit striking phenomena such as synchronized chaos or phase - locked states with many incommensurate amplitude .We additionally understand how these influences are modified when the system is linked to a passive resonator . The results presented here perhaps be applicable to investigating the activity of biological systems such as colonies of fireflies or cells .In recent years there has been growing interest in examining nonlinear dynamical systems composed of several interacting elements 1 - 3 . These studies have revealed new collective behaviors which cannot appear in single element structures 4 .Examples use synchronization 5 - 7 , clustering 8 , chimera states 9 , and spatiotemporal modes 10 - 12 . In this research we define a theory consisting of N identical elastically - coupled reed - oscillators 13 driven by a common electromagnetic wavefield 14 - 16 ( see Fig 1 ) .Each oscillator consists of two vibrating sheets connected by a thin layer of air 17 . When the pressure difference across one plate exceeds its critical level , it continues to expand rapidly until the restoring pressure attributed to the other plate causes it to contract again .This process repeats frequently resulting in self - sustained oscillations at a frequency determined by the topology of the device 18 . The interaction between neighboring oscillators arises because each oscillator acts like a small loudspeaker radiating noise into the nearby medium 19 - 21 .As a result , neighboring oscillators encounter identical driving forces and their natural speeds get closed 22 . If all oscillators lock onto the same frequency then the entire system behaves coherently ; if different bands of oscillators lock on to different frequencies then the system displays spatially - extended multistability 23 .",
        "rewrite_text": "**Title:** Oscillation Thresholds for Striking Outwards Reeds Driven to a Resonator\n\n**Abstract:** This study investigates the dynamics of an ensemble of elastically coupled reed oscillators that are driven by a shared acoustic field. We demonstrate that these oscillators can exhibit remarkable phenomena, including synchronized chaos and phase-locked states characterized by multiple incommensurate amplitudes. Furthermore, we explore how these dynamics are influenced when the system is connected to a passive resonator. The findings presented in this research may have implications for understanding the behaviors of biological systems, such as firefly colonies or cellular networks. \n\nIn recent years, there has been an increasing interest in the study of nonlinear dynamical systems composed of multiple interacting components. These investigations have uncovered new collective behaviors that do not manifest in isolated elements. Notable examples include synchronization, clustering, chimera states, and spatiotemporal modes. In our research, we propose a theoretical framework involving N identical elastically coupled reed oscillators, which are driven by a common electromagnetic wavefield. Each oscillator is constructed from two vibrating sheets separated by a thin layer of air. When the pressure differential across one sheet surpasses a critical threshold, it expands rapidly until the restoring pressure from the adjacent sheet induces a contraction. This cycle of expansion and contraction leads to self-sustained oscillations at a frequency determined by the device's topology.\n\nThe interaction among neighboring oscillators occurs as each oscillator functions akin to a small loudspeaker, emitting sound into the surrounding medium. Consequently, neighboring oscillators experience identical driving forces, causing their natural frequencies to converge. When all oscillators synchronize to a single frequency, the system exhibits coherent behavior. Conversely, if distinct groups of oscillators lock onto different frequencies, the system demonstrates spatially extended multistability. This research contributes to the understanding of complex dynamical systems and their potential applications in various fields, including biology and engineering.",
        "ori-fast-z-score": -0.42717882885838043,
        "water-fast-z-score": 6.870330330407765,
        "rewrite-fast-z-score": 1.2632278815997784
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Magnetic Field of the Solar Corona from Pulsar Observations .\nAbstract:\nWe present an analysis of pulsar observations to determine the magnetic field strength in the solar corona at heights between 1 and 3 R_Sun . We use data obtained with the Nançay Radio Telescope (NRT) for two different radio frequencies, 327 MHz and 1420 MHz, corresponding to emission heights of about 2 and 5 R_Sun , respectively. The observed pulse profiles are modeled using a simple model that includes contributions from both the local interstellar medium and the solar wind plasma. From these models we derive estimates for the coronal magnetic field strengths as well as the electron density distribution along the line-of-sight towards PSR B1133+16 .\nThe results show that the magnetic field decreases rapidly with height above the photosphere but is still strong enough to confine energetic particles up to several solar radii away from the Sun s surface. This suggests that particle acceleration processes may be taking place throughout most of the solar atmosphere.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Magnetic Field of the Solar Corona from Pulsar Observations . Abstract : We report an assessment of pulsar observations to measure the magnetic force strength in the solar corona at heights between 1 and 3 R _ Sun .We use data acquired with the Nançay Radio Telescope ( NRT ) for two different radio altitudes , 327 MHz and 1420 MHz , related to emission heights of about 2 and 5 R _ Sun , respectively . The observed pulse profiles are modeled using a simple simulation that contains contributions from both the local interstellar material and the solar wind plasma .From these models we derive estimates for the coronal magnetic field strengths as also as the electron concentration distribution along the line - of - seeing towards PSR B1133 + 16 . The results show that the magnetic force drops rapidly with depth above the photosphere but is nevertheless strong enough to confine energetic particles up to several solar radii away from the Sun s surface .This implies that particle acceleration processes possibly be taking place throughout most of the solar atmosphere .",
        "rewrite_text": "We present a comprehensive analysis of pulsar observations aimed at quantifying the magnetic field strength within the solar corona, specifically at altitudes ranging from 1 to 3 solar radii (R☉). Utilizing data from the Nançay Radio Telescope (NRT), we focus on two distinct radio frequencies: 327 MHz and 1420 MHz, which correspond to emission heights of approximately 2 R☉ and 5 R☉, respectively. To interpret the observed pulse profiles, we employ a straightforward simulation that accounts for contributions from both the local interstellar medium and the solar wind plasma. Through this modeling approach, we derive estimates for the magnetic field strengths in the corona, as well as the distribution of electron density along the line of sight towards the pulsar PSR B1133 + 16. Our findings indicate that the magnetic field strength decreases significantly with altitude above the photosphere; however, it remains sufficiently robust to confine high-energy particles at distances extending several solar radii from the Sun's surface. This observation suggests that particle acceleration mechanisms may be active throughout a substantial portion of the solar atmosphere, highlighting the dynamic interactions occurring in this region. The implications of our results contribute to a deeper understanding of solar magnetic fields and their role in solar atmospheric processes, potentially influencing our comprehension of solar wind dynamics and space weather phenomena.",
        "ori-fast-z-score": -0.6793662204867574,
        "water-fast-z-score": 3.9378076532410837,
        "rewrite-fast-z-score": -0.8783100656536799
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Search for gravitational-wave bursts in LIGO data from the fourth science run .\nAbstract:\nWe present results on searches for gravitational wave (GW) burst signals using data collected by the Laser Interferometer Gravitational-Wave Observatory during its fourth science run, which took place between September 2005 and January 2007. We use two different search methods to look for GW bursts: one based on matched filtering with template waveforms and another that uses an optimal filterbank method. The latter is used as part of a blind analysis where we do not know what type or strength of signal may be present in our data until after it has been analyzed. In addition to these analyses, we also perform several consistency checks designed to identify any problems associated with either detector s performance over this period. No significant candidates are found in any of these searches. Using simulated signals injected into the data at random times, we estimate upper limits on the rate density of binary black hole mergers detectable within a given range of total mass.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Search for gravitational - wave pulses in LIGO data from the fourth science run . Abstract : We report findings on investigations for gravitational wave ( GW ) burst signals using data received by the Laser Interferometer Gravitational - Wave Observatory during its fourth science run , which taken place between September 2005 and January 2007 .We use two different search methods to find for GW bursts : one based on matched sampling with template waveforms and another that using an efficient filterbank method . The latter is utilized as part of a blind analysis where we do not understand what type or strength of signal might be found in our information until after it has been examined .In addition to these tests , we also perform several reliability measures designed to identify any problems related with either detector s performance over this time . No important candidates are found in any of these searches .Using simulated transmissions imported into the information at random times , we estimate upper limits on the rate concentration of binary dark hole mergers detectable within a given range of total mass .",
        "rewrite_text": "We present our findings from an investigation into gravitational wave (GW) burst signals utilizing data collected by the Laser Interferometer Gravitational-Wave Observatory (LIGO) during its fourth science run, which spanned from September 2005 to January 2007. Our research employs two distinct methodologies to search for GW bursts: the first method involves matched filtering with predefined template waveforms, while the second method utilizes an efficient filterbank approach. The filterbank method is particularly noteworthy as it is part of a blind analysis, meaning that we do not have prior knowledge of the potential types or strengths of signals present in the data until after the analysis is complete. \n\nIn addition to these primary search techniques, we implement several reliability assessments aimed at identifying any issues related to the performance of the detectors throughout the observation period. Despite our comprehensive search efforts, we did not identify any significant candidates for gravitational wave bursts. To further evaluate our detection capabilities, we conducted simulations by injecting synthetic signals into the data at random intervals. This allowed us to estimate upper limits on the event rate of binary black hole mergers that could be detected within a specified range of total mass. Our results contribute to the understanding of the sensitivity of LIGO during this science run and provide valuable insights into the potential for detecting gravitational waves from astrophysical events. Overall, this study underscores the challenges faced in identifying gravitational wave signals and sets the groundwork for future investigations in the field.",
        "ori-fast-z-score": -1.4596008983995234,
        "water-fast-z-score": 4.538253483538691,
        "rewrite-fast-z-score": 0.2750095491084634
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Structure and Dynamics of the Sun s Open Magnetic Field .\nAbstract:\nThe solar magnetic field is an important ingredient in many physical processes that take place on the Sun, such as coronal heating or solar wind acceleration. The open magnetic flux threading through the heliosphere plays also a crucial role for space weather prediction. In this work we present results obtained with the MHD model developed by Usmanov et al. (2010) to study the structure and dynamics of the Sun s open magnetic field. We show how the global properties of the simulated open magnetic field compare with observations made at 1 AU using spacecraft data. Our simulations reproduce well the observed latitudinal distribution of the open magnetic flux density and its dependence on the radial distance from the Sun. They also provide information about the temporal evolution of the open magnetic field which can be used to predict the state of the interplanetary medium several days ahead. This research was supported by NASA grants NNX10AC85G (PI: S. Riley), NNG09FA40C (PI: A. Schwadron), and NNM07AA01A (PI: J. McComas).",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Structure and Dynamics of the Sun s Open Magnetic Field . Abstract : The solar magnetic force is an important ingredient in many mechanical phenomena that take place on the Sun , such as coronal heating or solar wind acceleration .The open magnetic flux threading through the heliosphere serves also a crucial role for space weather prediction . In this research we present results derived with the MHD model created by Usmanov et al .( 2010 ) to study the composition and dynamics of the Sun s open magnetic force . We see how the global properties of the simulated open magnetic force compare with observations made at 1 AU using satellite information .Our simulations reproduce well the seen latitudinal flow of the open magnetic flux coefficient and its dependence on the radial distance from the Sun . They even provide details about the temporal evolution of the open magnetic force which can be used to predict the state of the interplanetary medium several days ahead .This research was supported by NASA grants NNX10AC85G (PI: S. Riley), NNG09FA40C (PI: A. Schwadron), and NNM07AA01A (PI: J. McComas).",
        "rewrite_text": "**Title:** Structure and Dynamics of the Sun's Open Magnetic Field\n\n**Abstract:** The solar magnetic field plays a pivotal role in various mechanical processes occurring on the Sun, including coronal heating and the acceleration of solar wind. Additionally, the open magnetic flux that permeates the heliosphere is essential for accurate space weather forecasting. In this study, we present findings derived from the magnetohydrodynamic (MHD) model developed by Usmanov et al. (2010), which allows for an in-depth analysis of the structure and dynamics of the Sun's open magnetic field. Our research focuses on comparing the global characteristics of the simulated open magnetic field with observational data collected at 1 astronomical unit (AU) from satellite missions. The simulations demonstrate a strong correlation with observed latitudinal variations in the open magnetic flux coefficient, as well as its dependence on the radial distance from the Sun. Furthermore, our model captures the temporal evolution of the open magnetic field, providing valuable insights that can be utilized to forecast the conditions of the interplanetary medium several days in advance. This work contributes to a better understanding of solar dynamics and enhances predictive capabilities for space weather events. The research was conducted with the support of NASA grants NNX10AC85G (Principal Investigator: S. Riley), NNG09FA40C (Principal Investigator: A. Schwadron), and NNM07AA01A (Principal Investigator: J. McComas).",
        "ori-fast-z-score": 0.3216337604513384,
        "water-fast-z-score": 4.90361647617904,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The dynamics of Jupiter and Saturn in the gaseous proto-planetary disk .\nAbstract:\nWe present results on the orbital evolution of Jupiter and Saturn in an axisymmetric, viscously evolving protoplanetary disk with embedded planets. We find that the orbits of both giant planets are significantly affected by their mutual gravitational interaction as well as by the presence of other planetary embryos. The eccentricity growth is dominated by secular interactions between the two planets which lead to large amplitude oscillations in the semi-major axes. In addition we find that the planet migration rates depend strongly on the initial conditions for the system parameters such as mass ratio and separation distance. \n \n Keywords: Planet formation - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N-body simulations \n \n \n \n 1 Introduction \n \n Planets form out of dust particles through coagulation processes (Safronov 1969; Wetherill & Stewart 1989) followed by runaway accretion onto these growing objects (Lissauer 1987). This process leads to the formation of planetesimals whose masses range from 10$^{−6}$ M⊕ up to several Earth masses. These bodies can grow further into larger planetary embryos or even directly into gas giants like Jupiter and Saturn if they accrete enough material within a short time span (Pollack et al. 1996) . Once formed, these massive planets open gaps in the surrounding circumstellar disks due to tidal torques exerted by the planet s gravity (Lin & Papaloizou 1986 ). As a consequence, the remaining matter inside this gap will be removed rapidly by viscosity effects leading to rapid inward type II migration of the planet (Ward 1997; Tanaka et al. 2002 ) . \nThe observed distribution of exoplanets shows a wide variety of orbital configurations ranging from circular orbits around Sun-like stars to highly eccentric orbits around low-mass stars (see e.g., Marcy et al. (2005) , Udry & Santos 2007 , Winn et al. (2010 ), Johnson et al. (2011 ) and references therein). However, most of them have been found close to their host star where the detection probability increases dramatically because of the strong stellar",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The behavior of Jupiter and Saturn in the gaseous proto - planetary disk . Abstract : We report findings on the orbital evolution of Jupiter and Saturn in an axisymmetric , viscously changing protoplanetary disk with attached planets .We see that the orbits of both giant planets are greatly impacted by their mutual gravitational interaction as also as by the presence of other planetary embryos . The eccentricity growth is dominated by secular interactions between the two planets which cause to large frequency oscillations in the semi - major axes .In addition we find that the planet migration rates depend greatly on the early conditions for the system parameters such as mass ratio and separation distance . Keywords : Planet structure - Giant planets - Eccentricities - Migration - Disk instability - Secular resonance - Dynamical chaos - N - bodies simulations 1 Introduction Planets form out of dust particles through coagulation processes ( Safronov 1969 ; Wetherill & Stewart 1989 ) preceded by runaway accretion onto these growing objects ( Lissauer 1987 ) .This process results to the formation of planetesimals whose masses range from 10 $ ^ { −6 } $ M⊕ up to several Earth masses . These bodies can develop further into larger planetary embryos or even directly into gas giants like Jupiter and Saturn if they accrete adequate material within a brief time frame ( Pollack et al .1996 ) . Once assembled , these massive planets open gaps in the nearby circumstellar disks owing to tidal torques exerted by the planet s gravity ( Lin & Papaloizou 1986 ) .As a consequence , the remaining material inside this gap will be removed soon by viscosity factors resulting to rapid inward type II displacement of the planet ( Ward 1997 ; Tanaka et al . 2002 ) .The observed distribution of exoplanets shows a broad variety of orbital arrangements ranging from circular orbits around Sun - like stars to strongly eccentric orbits around low - mass stars ( see e . g . , Marcy et al . ( 2005 ) , Udry & Santos 2007 , Winn et al .( 2010 ) , Johnson et al . ( 2011 ) and references therein ) .However , most of them have been seen nearer to their host star where the detection odds grows dramatically because of the strong stellar",
        "rewrite_text": "**Title:** The Behavior of Jupiter and Saturn in the Gaseous Proto-Planetary Disk\n\n**Abstract:** In this study, we investigate the orbital dynamics of Jupiter and Saturn within an axisymmetric, viscously evolving protoplanetary disk that includes the presence of these gas giants. Our findings reveal that the gravitational interactions between the two planets significantly influence their orbital paths, with additional effects stemming from the presence of other planetary embryos in the disk. Notably, we observe that the growth of orbital eccentricity is primarily driven by secular interactions between Jupiter and Saturn, leading to substantial oscillations in their semi-major axes. Furthermore, our analysis indicates that the rates of planetary migration are highly sensitive to the initial conditions of the system, particularly the mass ratio of the planets and their separation distances. \n\nThe formation of planets from dust particles occurs through a series of coagulation processes, as outlined by Safronov (1969) and Wetherill & Stewart (1989), which are preceded by a phase of runaway accretion on growing bodies (Lissauer, 1987). This process culminates in the creation of planetesimals with masses ranging from 10^-6 M⊕ to several Earth masses. These planetesimals can evolve into larger planetary embryos or, under certain conditions, directly into gas giants like Jupiter and Saturn if they manage to accrete sufficient material in a relatively short time frame (Pollack et al., 1996). Once these massive planets are formed, they exert tidal torques on the surrounding circumstellar disk, leading to the opening of gaps in the disk (Lin & Papaloizou, 1986). The material within these gaps is subsequently removed due to viscous processes, resulting in a rapid inward migration of the planets (Ward, 1997; Tanaka et al., 2002). The diverse distribution of exoplanets observed today showcases a wide range of orbital configurations, from nearly circular orbits around Sun-like stars to highly eccentric orbits around lower-mass stars (Marcy et al., 2005; Udry & Santos, 2007; Winn et al., 2010; Johnson et al., 2011). However, the majority of these exoplanets are found in close proximity to their host stars, where detection probabilities are significantly enhanced due to the strong stellar influence. \n\n**Keywords:** Planet structure, Giant planets, Eccentricities, Migration, Disk instability, Secular resonance, Dynamical chaos, N-body simulations.",
        "ori-fast-z-score": -1.5461980716652028,
        "water-fast-z-score": 4.834937784152282,
        "rewrite-fast-z-score": 0.24413653763134782
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dynamics-Controlled Truncation Scheme for Nonlinear Dynamics in Semiconductor Microcavities .\nAbstract:\nWe propose an efficient numerical scheme to solve the nonlinear dynamics of semiconductor microcavity lasers with arbitrary pumping profiles and cavity losses, which is based on the combination of two different truncation schemes. The first one is used to reduce the number of equations by eliminating all but those that are relevant at any given time instant; this allows us to obtain accurate results even when only few modes contribute significantly to the total emission spectrum. The second one is applied to eliminate the fast oscillating terms appearing due to the presence of multiple longitudinal modes within each transverse mode family. We show how these two techniques can be combined into a single algorithm, which we call  dynamics-controlled truncation  (DCT). Finally, we demonstrate the accuracy and efficiency of our method by comparing it against other existing methods. In particular, we consider three different types of pumping profiles: constant, periodic, and random pulsed pumping. \nI. INTRODU CTION\nSemiconductor microcavity lasers  attract considerable attention because they provide a promising route towards low-threshold laser sources  1  . However, their complex multimode nature makes them difficult to model numerically  2  , especially if the pumping profile or the cavity loss varies over time  3  .\nIn order to overcome such difficulties, several authors have proposed various approaches  4  -  8  . For example, in Ref.  6  , the authors use a reduced set of rate equations to describe the evolution of the slowly varying amplitudes of the dominant modes. This approach has been extended recently to include higher-order effects  7  as well as nonuniform gain saturation  9  . Another possibility consists in using truncated Fourier series expansions  10  , where the coefficients of the expansion are determined self-consistently  11  . Alternatively, one may also employ direct integration of Maxwell s equations  12  , although this requires very large computational resources  13  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dynamics - Controlled Truncation Scheme for Nonlinear Dynamics in Semiconductor Microcavities . Abstract : We suggest an efficient numerical system to solve the nonlinear dynamics of semiconductor microcavity lasers with arbitrary flow profiles and cavity costs , which is based on the combination of two different truncation schemes .The first first is utilized to reduce the number of equations by removing all but those that are applicable at any certain time instant ; this enables us to obtain precise conclusions even when only few modes contribute greatly to the total emission spectrum . The second one is applied to eliminate the fast oscillating terms appearing due to the presence of multiple longitudinal frequencies within each longitudinal mode family .We see how these two procedures can be merged into a single method , which we call dynamics - controlled truncation ( DCT ) . Finally , we prove the accuracy and efficiency of our technique by comparing it against other existing techniques .In particular , we investigate three different kinds of flow profiles : constant , continuous , and random pulsed pumping . I . INTRODU CTION Semiconductor microcavity lasers draw considerable scrutiny because they give a viable path towards short - threshold laser sources 1 .However , their complex multimode nature creates them harder to model numerically 2 , particularly if the pumping profile or the cavity loss varies over time 3 . In try to overcome such problems , various papers have proposed several methods 4 - 8 .For instance , in Ref . 6 , the writers employ a reduced series of rate coefficients to explain the evolution of the slowly varying amplitudes of the dominant modes .This method has been extended recently to use larger - order effects 7 as well as nonuniform gain saturation 9 . Another possibility consists in utilizing truncated Fourier series expansions 10 , where the coefficients of the integration are chosen self - consistently 11 .Alternatively , one may even employ direct combining of Maxwell s coefficients 12 , although this demands very huge computational resources 13 .",
        "rewrite_text": "**Title:** Dynamics-Controlled Truncation Scheme for Nonlinear Dynamics in Semiconductor Microcavities\n\n**Abstract:** In this study, we present a novel and efficient numerical approach for addressing the nonlinear dynamics of semiconductor microcavity lasers, accommodating arbitrary flow profiles and cavity losses. Our method integrates two distinct truncation schemes to streamline the computational process. The first scheme focuses on reducing the number of equations by retaining only those relevant at specific time instances, allowing for accurate conclusions even when only a limited number of modes significantly influence the overall emission spectrum. The second scheme targets the elimination of rapidly oscillating terms that arise from the presence of multiple longitudinal frequencies within each mode family. By merging these two techniques, we introduce the dynamics-controlled truncation (DCT) method, which enhances both accuracy and computational efficiency. We validate our approach by comparing it with existing methodologies, demonstrating its superior performance. Our investigation encompasses three distinct flow profiles: constant, continuous, and random pulsed pumping. \n\nThe significance of semiconductor microcavity lasers lies in their potential for developing low-threshold laser sources, which has garnered substantial interest in the scientific community. However, the inherent complexity of their multimode behavior poses challenges for numerical modeling, particularly when the pumping profile or cavity losses exhibit temporal variations. To address these challenges, various strategies have been proposed in the literature. For example, some researchers have utilized a reduced set of rate coefficients to describe the evolution of dominant mode amplitudes, while others have explored higher-order effects and nonuniform gain saturation. Additionally, truncated Fourier series expansions have been employed, with self-consistent coefficient selection. Alternatively, direct combinations of Maxwell's equations have been considered, albeit at the cost of significant computational resources. Our DCT method offers a promising solution to these challenges, facilitating more efficient simulations of semiconductor microcavity laser dynamics.",
        "ori-fast-z-score": -1.7614096918559585,
        "water-fast-z-score": 7.37537974717874,
        "rewrite-fast-z-score": 0.3223291856101521
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Warehousing Web Data .\nAbstract:\nThe Internet Archive (IA) is an open access digital library that collects, preserves and provides access to the web s cultural record. The IA has been collecting data since 1996 using the Wayback Machine service which crawls the web regularly in order to archive snapshots of websites. In this work we present a novel approach for storing large volumes of archived web pages efficiently by exploiting their inherent redundancy. We propose a new storage model called WARCStore based on the concept of inverted files where each page is represented as a set of records containing its content along with pointers to other related pages stored within the same file system. This allows us to store multiple copies of the same page in different locations while still maintaining fast random read/write performance. Our experiments show that our proposed solution outperforms existing solutions such as B-tree indexes or LSM-trees when storing millions of archived web pages.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Warehousing Web Data . Abstract : The Internet Archive ( IA ) is an open access electronic library that collects , preserves and provides entry to the web s cultural record .The IA has been storing data since 1996 utilizing the Wayback Machine service which crawls the website frequently in order to archive snapshots of websites . In this project we present a novel methodology for storing huge volumes of archived internet pages efficiently by exploiting their inherent redundancy .We suggest a new storage concept called WARCStore based on the idea of inverted archives where each document is depicted as a group of records featuring its material along with pointers to other related content stored within the same file system . This enables us to hold multiple versions of the same page in different places while still maintaining fast random read / write quality .Our experiments demonstrated that our proposed approach outperforms old solutions such as B - tree indexes or LSM - trees when storing millions of archived internet pages .",
        "rewrite_text": "**Title: Warehousing Web Data**\n\n**Abstract:** The Internet Archive (IA) serves as an open-access digital library dedicated to the collection, preservation, and accessibility of the web's cultural heritage. Since its inception in 1996, the IA has utilized the Wayback Machine, a service that frequently crawls websites to capture and archive snapshots of their content. In this article, we introduce an innovative methodology aimed at efficiently storing vast quantities of archived web pages by leveraging their inherent redundancy. We propose a new storage framework termed WARCStore, which is based on the concept of inverted archives. In this framework, each document is represented as a collection of records that encapsulate its content, along with pointers to other related materials housed within the same file system. This design allows for the retention of multiple versions of the same webpage in various locations while ensuring rapid random read and write capabilities. Our experimental results indicate that the WARCStore approach significantly outperforms traditional storage solutions, such as B-tree indexes and LSM-trees, when managing millions of archived web pages. By optimizing the storage process, we aim to enhance the efficiency and accessibility of web data preservation, ultimately contributing to the broader goal of maintaining the digital cultural record for future generations.",
        "ori-fast-z-score": -1.091089451179962,
        "water-fast-z-score": 6.182518047831701,
        "rewrite-fast-z-score": -0.5076730825668095
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  SDSS J233325.92+152222.1 and the evolution of intermediate polars .\nAbstract:\nSDSS J233325 is an unusual cataclysmic variable (CV) with a magnetic white dwarf primary, which has been classified as an intermediate polar (IP). The system shows strong X-ray emission but no optical counterpart in archival data. We have obtained new photometric observations using the Liverpool Telescope to search for periodic modulations that would be expected if this source were indeed an IP. No significant periodicity was found over a wide range of periods between 0.01 s and 10 h. However, we did find evidence for two quasi-periodic oscillations at frequencies of ~0.2 Hz and ~0.4 Hz. These are similar to those seen previously in other CVs containing magnetic white dwarfs. In addition, there appears to be some structure on longer timescales. This may represent additional low-frequency QPOs or possibly orbital variability. If confirmed by further observations it will provide important constraints on theoretical models of accretion onto magnetised white dwarfs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : SDSS J233325 . 92 + 152222 . 1 and the evolution of intermediate polars . Abstract : SDSS J233325 is an peculiar cataclysmic variable ( CV ) with a magnetic white dwarf primary , which has been classified as an intermediate polar ( IP ) .The system displays strong X - ray radiation but no optical counterpart in archival records . We have gathered new photometric studies use the Liverpool Telescope to search for periodic modulations that would be anticipated if this source were indeed an IP .No meaningful periodicity was obtained over a broad variety of periods between 0 . 01 s and 10 h . However , we did find proof for two quasi - periodic oscillations at speeds of ~ 0 . 2 Hz and ~ 0 . 4 Hz . These are related to those shown later in other CVs containing magnetic white dwarfs .In addition , there seems to be some structure on longer timescales . This might represent increased low - frequency QPOs or possibly orbital variability .If confirmed by further observations it will provide important restrictions on theoretical theories of accretion onto magnetised white dwarfs .",
        "rewrite_text": "Title: SDSS J233325.92+152222.1 and the Evolution of Intermediate Polars\n\nAbstract: SDSS J233325.92+152222.1 is an intriguing cataclysmic variable (CV) characterized by a magnetic white dwarf primary, classified as an intermediate polar (IP). This system is notable for its strong X-ray emissions, yet it lacks an optical counterpart in existing archival data. To investigate the potential periodic modulations expected from an IP, we conducted new photometric observations using the Liverpool Telescope. Our analysis spanned a wide range of periods from 0.01 seconds to 10 hours; however, we did not detect any significant periodicity within this interval. Interestingly, we identified evidence for two quasi-periodic oscillations (QPOs) at frequencies of approximately 0.2 Hz and 0.4 Hz. These oscillations are consistent with those observed in other CVs that host magnetic white dwarfs. Furthermore, our observations suggest the presence of additional structures on longer timescales, which may indicate the existence of low-frequency QPOs or potential orbital variability. If these findings are corroborated by subsequent studies, they could impose critical constraints on theoretical models of accretion processes onto magnetized white dwarfs. This research not only enhances our understanding of SDSS J233325 but also contributes to the broader knowledge of the evolution and behavior of intermediate polars within the context of cataclysmic variables.",
        "ori-fast-z-score": 0.23570226039551587,
        "water-fast-z-score": 5.656854249492381,
        "rewrite-fast-z-score": 1.5275252316519468
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Pressure induced Insulator-Metal transition in LaMnO$_3$ .\nAbstract:\nThe pressure-induced insulator-metal (IMT) phase transition is studied by means of the first-principles calculations based on density functional theory within local spin-density approximation and generalized gradient approximations. The calculated results show that the IMT occurs at about 20 GPa for both LSDA and PBE functionals, which are consistent with previous theoretical studies. However, it should be noted that there exists an obvious difference between these two methods when calculating the electronic structure near Fermi level. In addition to this, we also find that the band gap decreases rapidly as increasing pressure up to 30 GPa but then becomes almost constant above 40 GPa. Finally, our calculation shows that the volume collapse takes place around 50 GPa. \n \n Keywords: Pressure-induced insulator-metal transition; First-principles calculations; Local spin-density approximation; Generalized gradient approximations; Electronic structure; Band gap",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Pressure induced Insulator - Metal transition in LaMnO $ _ 3 $ . Abstract : The pressure - triggered insulator - metal ( IMT ) phase shift is studied by means of the first - principles calculations based on density functional theory within local spin - density algorithm and generalized gradient approximations .The measured data demonstrate that the IMT occurs at about 20 GPa for both LSDA and PBE functionals , which are compatible with previous conceptual research . However , it should be mentioned that there exists an evident gap between these two means when calculating the electronic structure near Fermi level .In addition to this , we also find that the band gap falls steadily as increasing temperature up to 30 GPa but then grows almost steady above 40 GPa . Finally , our mathematical reveals that the volume collapse took place around 50 GPa .Keywords : Pressure - caused insulator - iron transition ; First - principles measurements ; Local spin - density approximation ; Generalized gradient approximations ; Electronic structure ; Band gap",
        "rewrite_text": "Title: Pressure-Induced Insulator-Metal Transition in LaMnO$_3$\n\nAbstract: This study investigates the pressure-induced insulator-metal transition (IMT) in LaMnO$_3$ through first-principles calculations grounded in density functional theory (DFT), utilizing both the local spin-density approximation (LSDA) and generalized gradient approximations (GGA). Our findings indicate that the IMT occurs at approximately 20 GPa for both LSDA and PBE functionals, aligning with prior theoretical studies. However, a significant discrepancy is observed in the electronic structure calculations near the Fermi level between these two methodologies. Additionally, we observe that the band gap decreases consistently with increasing pressure up to 30 GPa, after which it stabilizes and exhibits minimal variation above 40 GPa. Notably, our analysis reveals a volume collapse occurring around 50 GPa, marking a critical point in the material's response to pressure. These results contribute to a deeper understanding of the electronic properties of LaMnO$_3$ under extreme conditions and highlight the complex interplay between pressure, temperature, and electronic structure in this material. Our work underscores the importance of employing multiple computational approaches to capture the nuances of phase transitions in correlated electron systems. \n\nKeywords: Pressure-induced insulator-metal transition; First-principles calculations; Local spin-density approximation; Generalized gradient approximations; Electronic structure; Band gap.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.98201895023622,
        "rewrite-fast-z-score": 0.10369516947304253
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The XMM-SSC survey of hard-spectrum XMM-Newton sources 1: optically bright sources .\nAbstract:\nWe present the results of an optical spectroscopic follow-up campaign for a sample of X-ray selected AGN with extreme properties, observed in the first year (2000) of the XMM-Newton Serendipitous Source Catalogue (XMM-SSC). The main goal is to study their nature and physical characteristics by means of multiwavelength observations. We have obtained spectra for about half of our sample using several telescopes at different observatories around the world. Our analysis shows that most of these objects are broad-line quasars or Seyfert 1 galaxies; only one object turns out to be a narrow-line radio galaxy. In addition we find two new BL Lac candidates among this sample. This work has been supported by the Spanish Ministerio de Ciencia y Tecnología under grant AYA2003-08548-C03-01/02/03. -The XMM-SSC catalogue contains more than 100 000 serendipitously detected X-ray sources extracted from all public data taken during the first three years of operation of the European Space Agency s XMM-Newton satellite. It covers almost the entire sky visible from Europe above |b| > 10 degrees. -X-ray surveys provide large samples of active galactic nuclei (AGNs), which can then be studied statistically over wide ranges of luminosity, redshift and other parameters. However, it is often difficult to identify individual sources unambiguously because they may show complex spectral shapes and/or variability on many timescales. -In order to select a complete sample of AGNs with extreme properties, we applied very strict selection criteria based on the source count rate and photon index measured in the 0.5-2 keV band. These criteria were chosen so as to maximize the fraction of absorbed sources while keeping contamination due to background fluctuations low.  -Our final sample consists of 56 sources, including four previously known blazars.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The XMM - SSC study of hard - spectrum XMM - Newton sources 1 : optically bright sources . Abstract : We report the results of an optical spectroscopic follow - up campaign for a sample of X - ray selected AGN with uncommon characteristics , detected in the first year ( 2000 ) of the XMM - Newton Serendipitous Source Catalogue ( XMM - SSC ) .The main goal is to study their nature and physical qualities by means of multiwavelength surveys . We have achieved spectra for about half of our sample using numerous telescopes at different observatories around the world .Our study shows that most of these objects are broad - line quasars or Seyfert 1 galaxies ; only one object turns out to be a broad - line radio star . In addition we find two new BL Lac candidates among this specimen .This work has been supported by the Spanish Ministerio de Ciencia y Tecnología under grant AYA2003 - 08548 - C03 - 01 / 02 / 03 . - The XMM - SSC catalogue contains more than 100 000 serendipitously detected X - ray sources extracted from all public data taken during the first three years of operation of the European Space Agency s XMM - Newton satellite .It covers almost the entire sky visible from Europe above | b | > 10 degrees . - X - ray studies provide big samples of active galactic nuclei ( AGNs ) , which can then be examined statistically over broad ranges of luminosity , redshift and other parameters .However , it is often difficult to identify individual sources unambiguously because they may show complex wavelength shapes and / or variability on various timescales . - In order to select a complete sample of AGNs with extreme properties , we applied very strict selection standards based on the source count rate and photon index calculated in the 0 . 5 - 2 keV band .These criteria were chosen so as to maximize the fraction of absorbed sources while maintaining contamination owing to background fluctuations low . - Our last sample consists of 56 sources , including four originally noted blazars .",
        "rewrite_text": "We present the findings from an optical spectroscopic follow-up study of a unique sample of X-ray selected Active Galactic Nuclei (AGN) identified in the inaugural year (2000) of the XMM-Newton Serendipitous Source Catalogue (XMM-SSC). The primary objective of this research is to investigate the nature and physical properties of these sources through comprehensive multiwavelength surveys. Utilizing a variety of telescopes across multiple observatories globally, we successfully obtained spectra for approximately half of the selected sample. Our analysis reveals that the majority of these sources are classified as broad-line quasars or Seyfert 1 galaxies, with only one identified as a broad-line radio star. Notably, we also discovered two new candidates for BL Lac objects within this sample.\n\nThe XMM-SSC catalogue comprises over 100,000 serendipitously detected X-ray sources, compiled from all publicly available data collected during the first three years of the XMM-Newton satellite's operation by the European Space Agency. This extensive catalogue encompasses nearly the entire sky visible from Europe, specifically above |b| > 10 degrees. X-ray studies yield substantial samples of AGNs, enabling statistical analyses across a wide range of luminosities, redshifts, and other relevant parameters. However, the identification of individual sources can be challenging due to their often complex spectral profiles and variability across different timescales.\n\nTo ensure a comprehensive selection of AGNs with extreme characteristics, we implemented stringent selection criteria based on source count rates and photon indices calculated in the 0.5 - 2 keV energy band. These criteria were designed to enhance the detection of absorbed sources while minimizing contamination from background fluctuations. Ultimately, our final sample consists of 56 sources, which includes four previously identified blazars. This research was supported by the Spanish Ministerio de Ciencia y Tecnología under grant AYA2003-08548-C03-01/02/03.",
        "ori-fast-z-score": 1.1026456085839622,
        "water-fast-z-score": 5.979278639572285,
        "rewrite-fast-z-score": 0.5222329678670935
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The SWIRE-VVDS-CFHTLS surveys: stellar mass assembly over the last 10 Gyears. Evidence for a major build up of the red sequence between z=2 and z=1 .\nAbstract:\nWe present an analysis of the evolution in the luminosity function (LF) and colour-magnitude relation (CMR) of galaxies selected by their rest-frame optical colours, using data from three large multi-wavelength surveys covering different areas on the sky. The first is the Spitzer Wide-area InfraRed Extragalactic survey (SWIRE), which covers about one quarter of the southern hemisphere at 24 microns with MIPS; the second is the VIMOS Very Deep Survey (VVDS), which has been carried out as part of the CFHT Legacy Survey (CFHTLS). This provides deep photometry in five bands to AB magnitude limits ranging from 26.5 to 27.7 mags in the u*gri filters. Finally we use near-infrared imaging obtained with WIRCam mounted on the Canada France Hawaii Telescope (CFHT) to select samples of massive galaxies at 1<z<1.4. We find that the LF evolves strongly towards fainter magnitudes since z=1.2, while there are no significant changes in its shape or normalisation. In addition, we show that the CMR becomes bluer with time, indicating that the fraction of quiescent systems increases significantly between these epochs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The SWIRE - VVDS - CFHTLS studies : stellar mass formation over the last 10 Gyears . Evidence for a major build up of the red sequence between z = 2 and z = 1 .Abstract : We present an assessment of the evolution in the luminosity function ( LF ) and colour - magnitude function ( CMR ) of stars selected by their rest - frame optical colours , using data from three large multi - wavelength searches covering multiple parts on the heavens . The first is the Spitzer Wide - area InfraRed Extragalactic study ( SWIRE ) , which covers about one quarter of the southern hemisphere at 24 microns with MIPS ; the second is the VIMOS Very Deep Survey ( VVDS ) , which has been carried out as part of the CFHT Legacy Survey ( CFHTLS ) .This offers deep photometry in five bands to AB magnitude limits ranging from 26 . 5 to 27 . 7 mags in the u * gri filters . Finally we using near - infrared imaging obtained with WIRCam installed on the Canada France Hawaii Telescope ( CFHT ) to select samples of large galaxies at 1 < z < 1 . 4 .We see that the LF evolves highly towards fainter magnitudes since z = 1 . 2 , while there are no considerable changes in its size or normalisation . In addition , we find that the CMR gets bluer with time , showing that the fraction of quiescent systems grows significantly between these epochs .",
        "rewrite_text": "**Title:** The SWIRE - VVDS - CFHTLS Studies: Stellar Mass Formation Over the Last 10 Gyr - Evidence for a Major Build-up of the Red Sequence Between z = 2 and z = 1\n\n**Abstract:** This study investigates the evolution of the luminosity function (LF) and the color-magnitude relation (CMR) of stars, utilizing data from three extensive multi-wavelength surveys that span various regions of the sky. The first dataset is derived from the Spitzer Wide-area InfraRed Extragalactic Survey (SWIRE), which encompasses approximately one-quarter of the southern hemisphere at 24 microns using the MIPS instrument. The second dataset comes from the VIMOS Very Deep Survey (VVDS), conducted as part of the CFHT Legacy Survey (CFHTLS), which provides deep photometric data across five bands, achieving AB magnitude limits between 26.5 and 27.7 in the u*, g, r, and i filters. Lastly, we incorporate near-infrared imaging from WIRCam on the Canada-France-Hawaii Telescope (CFHT) to identify large galaxy samples within the redshift range of 1 < z < 1.4. Our analysis reveals a significant evolution in the LF, particularly towards fainter magnitudes since z = 1.2, while the overall size and normalization of the LF remain relatively stable. Furthermore, we observe a trend in the CMR, which becomes progressively bluer over time, indicating a substantial increase in the proportion of quiescent galaxies during this period. These findings provide compelling evidence for a major build-up of the red sequence in the universe between redshifts of 2 and 1, highlighting the dynamic processes of stellar mass formation and the changing characteristics of galaxy populations over the last ten billion years.",
        "ori-fast-z-score": -0.22086305214969307,
        "water-fast-z-score": 5.597977259474208,
        "rewrite-fast-z-score": 0.6060915267313265
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Les espaces de Berkovich sont excellents .\nAbstract:\nLes espaces analytiques rigides ont été introduits par A. Grothendieck dans les années 1960 pour étudier la cohomologie étale des schémas algébriques sur un corps quelconque. Ils constituent une généralisation naturelle des variétés algébriques affines et projectives, mais ils ne possèdent pas toujours de structure géométrique classique (variétés algébriques). Dans cet exposé nous allons présenter quelques résultats récents concernant l étude de ces espaces en géométrie diophantienne. Nous verrons que certains problèmes classiques peuvent être étudiés grâce à cette nouvelle approche. En particulier, nous montrerons comment on peut utiliser les espaces analytiques rigides pour obtenir des bornes explicites sur le nombre de points rationnels d une variété algébrique définie sur un corps fini. Ces travaux font suite aux articles suivants :  - J.-B. Bost, M. Chambert-Loir and C. Soulé, ``Explicit bounds for rational points  , Inventiones Mathematicae, vol. 162, no. 1, pp. 1-33, (2005) - J.-B.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Les espaces de Berkovich sont excellents . Abstract : Les espaces analytiques rigides ont été introduits par A . Grothendieck dans la années 1960 pour étudier la cohomologie étale des schémas algébriques dans un corps quelconque .Ils constituent une généralisation naturelle aux variétés algébriques affines et projectives , mais ils ne possèdent pas toujours de construction géométrique classique ( variétés algébriques ) . Dans cet exposé nous allons présenter quelques résultats récents concernant l étude de ces espaces en géométrie diophantienne .Nous verrons que certains problèmes classiques peuvent être étudiés grâce à cette nouvelle approche . En particulier , nous montrerons remark on peut utiliser les espaces analytiques rigides pour obtenir des bornes explicites sur du nombre de points rationnels d la variété algébrique définie sur un corps fini .Ces travaux font suite aux articles suivants : - J . - B . Bost , M . Chambert - Loir and C . Soulé , ` ` Explicit bounds for rational points , Inventiones Mathematicae , vol .162 , no . 1 , pp .1-33, (2005) - J.-B.",
        "rewrite_text": "Title: Berkovich Spaces are Excellent\n\nAbstract: Rigid analytic spaces were introduced by A. Grothendieck in the 1960s as a means to investigate the étale cohomology of algebraic schemes over arbitrary fields. These spaces serve as a natural extension of affine and projective algebraic varieties; however, they do not always have a classical geometric construction akin to algebraic varieties. In this presentation, we will discuss recent findings related to the study of these spaces within the context of diophantine geometry. We will demonstrate that certain classical problems can be effectively approached using this novel framework. Specifically, we will illustrate how rigid analytic spaces can be employed to derive explicit bounds on the number of rational points of an algebraic variety defined over a finite field. This research builds upon previous works, including the contributions of J.-B. Bost, M. Chambert-Loir, and C. Soulé, who provided explicit bounds for rational points in their paper published in Inventiones Mathematicae (2005). Our findings not only deepen the understanding of the interplay between rigid analytic spaces and diophantine geometry but also open new avenues for addressing longstanding questions in the field. By leveraging the properties of Berkovich spaces, we aim to provide a more comprehensive toolkit for mathematicians working on rational points and their implications in algebraic geometry.",
        "ori-fast-z-score": 0.14907119849998599,
        "water-fast-z-score": 2.6539552107881486,
        "rewrite-fast-z-score": 0.3144854510165755
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Extended envelopes around Galactic Cepheids III. Y Oph and alpha Per from near-infrared interferometry with CHARA/FLUOR .\nAbstract:\nWe present new measurements of the angular diameter variations for two classical Cepheids: Y Ophiuchi (Y Oph) and Alpha Persei (alpha Per). These stars are among the brightest in their class, making them ideal targets to study using infrared interferometry. We used the FLUOR instrument on the CHARA array at Mount Wilson Observatory to obtain high-precision visibility data over several pulsation cycles. The observations were performed simultaneously in H-band (1.6 microns), K-band (2.0 microns), and L-band (3.8 microns).\nThe results show that both stars have extended atmospheres which vary significantly during the pulsations cycle. In particular we find that:  - For Y Oph, our best-fit model is consistent with an atmosphere extending up to about 1 AU above its photosphere.  - For alpha Per, our best-fit models suggest that the star has an extended atmosphere reaching out to more than 2 AU above its photosphere.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  Extended envelopes around Galactic Cepheids III.Y Oph and alpha Per from near-infrared interferometry with CHARA/FLUOR .Abstract : We present new measurements of the angular distance changes for two classical Cepheids : Y Ophiuchi ( Y Oph ) and Alpha Persei ( beta Per ) . These galaxies are among the brightest in their category , making them ideal targets to study using infrared interferometry .We utilized the FLUOR instrument on the CHARA array at Mount Wilson Observatory to obtain high - precision visibility data over several pulsation periods . The surveys were performed simultaneously in H - band ( 1 . 6 microns ) , K - band ( 2 . 0 microns ) , and L - band ( 3 . 8 microns ) .The results show that both stars have extended atmospheres which varies dramatically during the pulsations cycle . In particular we find that : - For Y Oph , our better - fitting model is compatible with an environment stretching up to about 1 AU above its photosphere .- For alpha Per , our better - fitting models suggest that the star has an extended atmosphere extending out to more than 2 AU above its photosphere .",
        "rewrite_text": "We present new findings on the angular distance variations of two classical Cepheids, Y Ophiuchi (Y Oph) and Alpha Persei (α Per), based on near-infrared interferometry conducted with the FLUOR instrument at the CHARA array located at Mount Wilson Observatory. These stars are among the brightest representatives of their class, making them particularly suitable for detailed study through infrared techniques. Our observations were carried out over multiple pulsation cycles, capturing high-precision visibility data in three different near-infrared bands: H-band (1.6 microns), K-band (2.0 microns), and L-band (3.8 microns). The results reveal that both Y Oph and α Per possess extended atmospheres that exhibit significant variations throughout their pulsation cycles. Specifically, our analysis indicates that Y Oph features an atmospheric extension reaching approximately 1 astronomical unit (AU) above its photosphere, while α Per displays an even more pronounced atmospheric extension, extending beyond 2 AU. These findings contribute to our understanding of the physical characteristics and behaviors of Cepheid variables, highlighting the dynamic nature of their atmospheres and the importance of high-resolution interferometric techniques in astrophysical research. The implications of these results are significant for the study of stellar evolution and the role of Cepheids as distance indicators in the cosmos.",
        "ori-fast-z-score": 0.0,
        "water-fast-z-score": 4.677476657214644,
        "rewrite-fast-z-score": 1.193117518002609
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Maximal Amount of Gravitational Waves in the Curvaton Scenario .\nAbstract:\nWe study gravitational waves produced by curvaton scenario, where the inflaton field is coupled to another scalar field called curvaton which decays into radiation after inflation and produces primordial density fluctuations. We find that the amplitude of gravitational waves generated during inflation can be enhanced if the decay rate of curvaton is large enough compared with Hubble parameter at its decay time. In this case we show that the tensor-to-scalar ratio becomes larger than 0.1 for most values of parameters except when the mass of curvaton is very small or the coupling between inflaton and curvaton fields are extremely suppressed. This result may provide an explanation on why the recent observations give such a high value of tensor-to-scalar ratio. \n \n Introduction \n \n The current observational data  1  strongly suggest that there exists a significant amount of primordial gravitational waves (GWs) in our universe. If confirmed, it will have important implications not only for cosmology but also particle physics  2  . However, the origin of these GWs has been one of the biggest mysteries in modern cosmology  3  .\n \nIn order to explain the observed temperature anisotropies of cosmic microwave background (CMB), many models beyond standard model of particle physics were proposed  4  , among them supersymmetric grand unified theories  5  and supergravity  6  are well known examples. These models predict new particles whose masses lie around 10 16 GeV  7, 8  . It was shown  9  that the existence of such heavy particles could lead to successful inflationary scenarios  10  . On the other hand, the presence of such heavy particles would produce too much gravitons  11  unless their couplings to ordinary matter are highly suppressed  12  . Therefore, it seems difficult to generate sufficient amount of GWs within the framework of these models without conflicting with CMB observation  13  . \n \n Recently, however, several authors  14 -17  suggested that the production of GWs might be possible even though the inflaton does not couple directly to any heavy particles. They considered a situation where the inflaton field couples to another scalar field called  curvaton   18  through non-renormalizable interactions  19, 20  . After",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Maximal Amount of Gravitational Waves in the Curvaton Scenario . Abstract : We research gravitational waves produced by curvaton scenario , where the inflaton field is linked to another scalar field called curvaton which decays into radiation after inflation and causes primordial density fluctuations .We see that the amplitude of gravitational waves generated during inflation can be enhanced if the decay rate of curvaton is huge enough compared with Hubble parameter at its degradation rate . In this situation we prove that the tensor - to - scalar ratio becomes greater than 0 . 1 for most values of parameters except when the mass of curvaton is very small or the interaction between inflaton and curvaton fields are extremely suppressed .This result may provide an reason on why the recent observations give such a high value of tensor - to - scalar ratio . Introduction The present observational data 1 clearly suggest that there exists a substantial quantity of primordial magnetic waves ( GWs ) in our universe .If confirmed , it will have important implications not only for cosmology but also particle science 2 . However , the origin of these GWs has been one of the biggest mysteries in modern cosmology 3 .In order to explain the known temperature anisotropies of cosmic microwave background ( CMB ) , various models beyond standard theory of particle theory were offered 4 , among them supersymmetric grand unified physics 5 and supergravity 6 are well famous instance . These systems predict new ions whose masses sit around 10 16 GeV 7 , 8 .It was shown 9 that the existence of such heavy ions might lead to good inflationary scenarios 10 . On the other hand , the presence of such heavy particles might generate too much gravitons 11 unless their couplings to everyday matter are extremely suppressed 12 .Therefore , it appears hard to produce enough quantity of GWs within the framework of these models without conflicting with CMB observation 13 . Recently , however , various scientists 14 - 17 suggested that the production of GWs might be possible even though the inflaton does not couple directly to any massive particles .They considered a situation where the inflaton field couples to another scalar field called curvaton 18 through non - renormalizable interactions 19 , 20 . After",
        "rewrite_text": "**Title:** The Maximal Amount of Gravitational Waves in the Curvaton Scenario\n\n**Abstract:** This study investigates the generation of gravitational waves within the context of the curvaton scenario, a model in which the inflaton field is associated with an additional scalar field known as the curvaton. Following the inflationary period, the curvaton decays into radiation, leading to primordial density fluctuations. Our analysis reveals that the amplitude of gravitational waves produced during inflation can be significantly amplified if the decay rate of the curvaton is sufficiently large in comparison to the Hubble parameter during its decay. Under these conditions, we demonstrate that the tensor-to-scalar ratio can exceed 0.1 for a wide range of parameter values, with exceptions occurring only when the mass of the curvaton is very low or when the interaction between the inflaton and curvaton fields is highly suppressed. This finding may offer an explanation for the unexpectedly high tensor-to-scalar ratios reported in recent observational data. \n\nThe current observational evidence strongly indicates the presence of a considerable amount of primordial gravitational waves in our universe, which, if validated, could have profound implications for both cosmology and particle physics. However, the origins of these gravitational waves remain one of the most significant enigmas in contemporary cosmology. To account for the observed temperature anisotropies in the cosmic microwave background (CMB), various theoretical models beyond the standard particle physics framework have been proposed, including notable examples such as supersymmetric grand unified theories and supergravity. These models predict the existence of new heavy particles with masses around 10^16 GeV, which could potentially lead to viable inflationary scenarios. Nevertheless, the presence of such heavy particles also raises concerns about excessive graviton production unless their interactions with ordinary matter are significantly suppressed. Consequently, it has proven challenging to generate a sufficient quantity of gravitational waves within these models without conflicting with CMB observations. Recently, several researchers have posited that gravitational wave production may still be feasible even if the inflaton does not directly couple to any massive particles, by considering scenarios where the inflaton interacts with the curvaton field through non-renormalizable interactions.",
        "ori-fast-z-score": 0.39904344223381105,
        "water-fast-z-score": 7.262590648655362,
        "rewrite-fast-z-score": 0.8778955729143844
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  8.4GHz VLBI observations of SN2004et in NGC6946 .\nAbstract:\nWe present 8.4 GHz Very Long Baseline Interferometry (VLBI) images and light curves for the supernova remnant (SNR) associated with the Type IIb supernova SN2004et, which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1. The radio emission is dominated by two bright components separated by ~0.5 arcsec at all epochs observed between 2005 January and 2007 December. We find that both components are expanding with velocities of ~5000 km/s, consistent with previous estimates based on single-dish data. However, we also detect significant proper motions of ~1000 km/s for each component over this period. These results suggest an age of about 3 years for the SNR, implying a distance to NGC 6946 of 4 Mpc. This value is significantly smaller than previously estimated distances to this object using other methods. Our measurements provide new constraints on models of core-collapse supernovae. \n \n Keywords: Supernova remnants",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : 8 . 4GHz VLBI discoveries of SN2004et in NGC6946 . Abstract : We create 8 . 4 GHz Very Long Baseline Interferometry ( VLBI ) images and light angles for the supernova remnant ( SNR ) associated with the Type IIb supernova SN2004et , which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1 .The signal radiation is dominated by two faint components differentiated by ~ 0 . 5 arcsec at all epochs observed between 2005 January and 2007 December . We see that both components are growing with velocities of ~ 5000 kilometres / s , compatible with previous estimates based on single - dish data .However , we also observe significant proper moves of ~ 1000 km / s for each system over this time . These data suggest an age of about 3 years for the SNR , suggests a distance to NGC 6946 of 4 Mpc .This value is significantly less than previously estimated altitudes to this body using other methods . Our measurements give novel constraints on estimates of core - collapse supernovae .Keywords: Supernova remnants",
        "rewrite_text": "Title: 8.4 GHz VLBI Discoveries of SN2004et in NGC 6946\n\nAbstract: In this study, we present 8.4 GHz Very Long Baseline Interferometry (VLBI) imaging and analysis of the supernova remnant (SNR) associated with the Type IIb supernova SN2004et, which erupted in the nearby spiral galaxy NGC 6946 on September 24, 2004 (UT1). Our observations reveal two faint components that are consistently separated by approximately 0.5 arcseconds across all epochs from January 2005 to December 2007. Both components exhibit expansion velocities of around 5000 kilometers per second, aligning with earlier estimates derived from single-dish observations. Additionally, we detect significant proper motions of approximately 1000 kilometers per second for each component over the observed period. These findings imply that the SNR is roughly 3 years old and suggest a distance to NGC 6946 of 4 megaparsecs. This distance measurement is notably lower than previous estimates obtained through alternative methodologies. Our results provide new insights and constraints on the characteristics of core-collapse supernovae, enhancing our understanding of their evolution and the dynamics of supernova remnants. The implications of these findings are crucial for refining models of supernova behavior and their impact on surrounding interstellar environments. \n\nKeywords: Supernova remnants, VLBI, SN2004et, NGC 6946, core-collapse supernovae.",
        "ori-fast-z-score": -1.2309149097933272,
        "water-fast-z-score": 5.093248125762992,
        "rewrite-fast-z-score": 0.22645540682891913
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Structures in the Universe and Origin of Galaxies .\nAbstract:\nThe book is divided into three parts, each part containing several chapters. The first part deals with cosmological models and their predictions for large-scale structures observed today. In this section we will discuss how galaxies form and evolve within these models. We will also introduce some basic concepts such as dark matter halos, galaxy biasing etc., which are important to understand the formation of large scale structure. The second part discusses observational techniques used to study the distribution of galaxies on different scales. Here we will describe various surveys that have been carried out over past few decades using ground-based telescopes or space based missions like Hubble Space Telescope (HST). Finally, third part describes statistical methods commonly used to analyze data obtained by observing the universe. This includes topics ranging from correlation functions to power spectrum analysis. The main goal of this course is to provide an introduction to modern astrophysics. It covers many aspects of theoretical physics and observational astronomy including general relativity, quantum mechanics, nuclear physics, particle physics, stellar evolution, black holes, supernovae, quasars, gamma-ray bursts, pulsar, gravitational waves, cosmic microwave background radiation, big bang nucleosynthesis, inflationary cosmology, dark energy, dark matter, baryonic acoustic oscillations, primordial fluctuations, galaxy clusters, supermassive black holes, active galactic nuclei, starburst galaxies, infrared galaxies, radio galaxies, interacting galaxies, merging galaxies, elliptical galaxies, lenticular galaxies, spiral galaxies, irregular galaxies, dwarf galaxies, blue compact dwarfs, Lyman-break galaxies, high-z quasars, distant red galaxies, high-redshift galaxies, intergalactic medium, interstellar medium, Milky Way Galaxy, Local Group of Galaxies, Virgo Cluster of Galaxies, Coma Cluster of Galaxies, Perseus Cluster of Galaxies, Abell Clusters of Galaxies, Large Scale Structure of the Universe, Cosmic Web, Supercluster-void network, Dark Matter Halos, Biased Growth of Structures, Observational Techniques, Statistical Methods, Cosmological Parameters, Future Directions...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Structures in the Universe and Origin of Galaxies . Abstract : The volume is separated into three sections , each portion containing several chapters .The first part deals with cosmological predictions and their expectations for large - scale structures discovered today . In this page we will explore how galaxies form and evolve within these models .We will also discuss some fundamental concepts such as dark matter halos , galaxy biasing etc . , which are important to explain the formation of large scale organization . The second part examines observational techniques employed to study the spread of galaxies on various scales .Here we will explain different measurements that have been carried out over past few years using ground - based telescopes or space based missions like Hubble Space Telescope ( HST ) . Finally , third chapter explains statistical tools commonly used to analyze information obtained by observing the universe .This encompasses topics ranging from correlation functions to power spectrum analysis . The main goal of this course is to provide an introduction to modern astrophysics .It covers many aspects of theoretical physics and observational astronomy including general relativity , quantum mechanics , nuclear science , particle science , stellar evolution , white holes , supernovae , quasars , gamma - ray bursts , pulsar , gravity signals , cosmic microwave background radiation , big bang nucleosynthesis , inflationary cosmology , soft energy , soft matter , baryonic sound oscillations , primordial fluctuations , galaxy clusters , supermassive black holes , active galactic nuclei , starburst galaxies , infrared galaxies , television galaxies , interacting galaxies , merging galaxies , elliptical galaxies , lenticular galaxies , spiral galaxies , irregular galaxies , dwarf galaxies , blue compact dwarfs , Lyman - break galaxies , low - z quasars , remote blue galaxies , low - redshift galaxies , intergalactic medium , interstellar medium , Milky Way Galaxy , Local Group of Galaxies , Virgo Cluster of Galaxies , Coma Cluster of Galaxies , Perseus Cluster of Galaxies , Abell Clusters of Galaxies , Large Scale Structure of the Universe , Cosmic Web , Supercluster - void system , Dark Matter Halos , Biased Growth of Structures , Observational Techniques , Statistical Methods , Cosmological Parameters , Future Directions . . .",
        "rewrite_text": "**Title: Structures in the Universe and the Origin of Galaxies**\n\n**Abstract:** This article is organized into three distinct sections, each comprising multiple chapters that delve into the intricate relationship between the universe's structure and the formation of galaxies. The first section focuses on cosmological predictions and the anticipated large-scale structures that have been identified in contemporary observations. We investigate the processes of galaxy formation and evolution within these theoretical frameworks, highlighting essential concepts such as dark matter halos and galaxy biasing, which are crucial for understanding the large-scale organization of the cosmos.\n\nThe second section addresses the observational methodologies utilized to analyze the distribution of galaxies across various scales. We detail the diverse measurements conducted in recent years, employing both ground-based telescopes and space missions, including the Hubble Space Telescope (HST). This exploration underscores the advancements in observational techniques that have enhanced our understanding of galaxy formation and distribution.\n\nIn the final section, we discuss the statistical tools that are routinely applied to interpret the data gathered from astronomical observations. This includes an examination of correlation functions and power spectrum analysis, which are vital for extracting meaningful insights from complex datasets. The overarching aim of this article is to provide a comprehensive introduction to modern astrophysics, encompassing a wide array of topics within theoretical physics and observational astronomy. Key subjects covered include general relativity, quantum mechanics, nuclear and particle physics, stellar evolution, and various types of galaxies, such as elliptical, spiral, and irregular galaxies. Additionally, we explore phenomena like supernovae, quasars, gamma-ray bursts, and the cosmic microwave background radiation, along with the large-scale structure of the universe, including superclusters and voids. By synthesizing these diverse elements, we aim to illuminate the intricate tapestry of the universe and the fundamental processes that govern the formation and evolution of galaxies.",
        "ori-fast-z-score": -0.0778498944161523,
        "water-fast-z-score": 5.648909597499199,
        "rewrite-fast-z-score": -0.9863939238321437
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Signals of Unparticles in Low Energy Parity Violation and NuTeV Experiment .\nAbstract:\nWe have studied the signals of unparticles in low energy parity violation experiments, such as PVA4 at PSI and NuTeV experiment at Fermilab. We find that the effects are significant for both neutral current (NC) and charged current (CC). The results show that the NC effect is more sensitive to the mass scale M U than CC one. In addition, we also study the influence on the neutrino-nucleon scattering cross section by including the contributions from unparticle exchange diagrams. It turns out that the contribution from unparticles can be comparable with those from standard model particles. \n \n Introduction \n \n Recently there has been much interest in studying possible new physics beyond Standard Model(SM), especially in searching for new light degrees of freedom which may exist around TeV scale  1  . One interesting possibility is so-called unparticle  2  , whose existence was first proposed by Georgi  3  . This kind of particle does not carry any SM charges but it behaves like an ordinary particle when interacting with SM fields through its coupling constant g U . Its propagator takes the form  4  : \n\n\nwhere d U denotes the scaling dimension of unparticle operator O U . If d U < 1, then this type of particle will behave like a non-integral number of invisible particles  5  .\n \nIn fact, many authors  6  -  8  have investigated various phenomenological aspects of unparticles. For example, they found that unparticles could contribute significantly to some processes involving missing transverse momentum  9  or lepton flavor violating decays  10  . Moreover, the production rate of unparticles at hadron colliders  11  and their signatures  12  were also discussed recently. \nThe purpose of our work here is to investigate whether unparticles can affect low-energy parity-violating experiments. Since these experiments involve only weak interactions between quarks and leptons, they provide us good opportunities to search for new physics beyond SM  13  . As far as we know, the most stringent constraints come from the measurement of neutron electric dipole moment  14  . However, if unparticles exist, they might give rise to additional contributions to the effective Lagr",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Signals of Unparticles in Low Energy Parity Violation and NuTeV Experiment . Abstract : We have researched the signals of unparticles in low power parity violation experiments , such as PVA4 at PSI and NuTeV experiment at Fermilab .We see that the effects are significant for both neutral charge ( NC ) and charged current ( CC ) . The results show that the NC effect is more sensitive to the mass level M U than CC one .In addition , we also study the impact on the neutrino - nucleon absorption cross area by including the contributions from unparticle exchange diagrams . It turns out that the impact from unparticles can be analogous with those from standard model beams .Introduction Recently there has been much interest in investigating possible new theories beyond Standard Model ( SM ) , particularly in searching for alternative light degrees of freedom which would occur around TeV level 1 . One interesting possibility is so - called unparticle 2 , whose existence was first suggested by Georgi 3 .This kind of particle does not carry any SM charges but it behaves like an everyday particle when interacting with SM fields through its interaction factor g U . Its propagator took the form 4 : where d U denotes the scaling dimension of unparticle operator O U .If d U < 1 , then this kinds of particle will react like a non - integral number of invisible particles 5 . In reality , various scientists 6 - 8 have researched several phenomenological aspects of unparticles .For instance , they concluded that unparticles might contribute greatly to some mechanisms requiring missing radial energy 9 or lepton flavor violating decays 10 . Moreover , the production frequency of unparticles at hadron colliders 11 and their signatures 12 were also discussed earlier .The purpose of our work here is to examine whether unparticles can affect small - energy parity - violating experiments . Since these experiments contain only weak interactions between quarks and leptons , they give us good chances to search for alternative theories beyond SM 13 .As far as we know , the most stringent constraints arise from the observation of neutron electric dipole point 14 . However , if unparticles exist , they may contribute rise to extra contributions to the effective Lagr",
        "rewrite_text": "**Title:** Signals of Unparticles in Low Energy Parity Violation and the NuTeV Experiment\n\n**Abstract:** In this study, we investigate the potential signals of unparticles in low-energy parity violation experiments, specifically focusing on the PVA4 experiment at PSI and the NuTeV experiment at Fermilab. Our findings indicate that the effects of unparticles are significant for both neutral current (NC) and charged current (CC) interactions, with the NC effects demonstrating a greater sensitivity to the mass scale \\( M_U \\) compared to the CC effects. Furthermore, we analyze the influence of unparticle exchange diagrams on the neutrino-nucleon absorption cross-section. Our results suggest that the contributions from unparticles can be comparable to those arising from standard model interactions.\n\nThe motivation for this research stems from the growing interest in exploring theories beyond the Standard Model (SM), particularly in the context of light degrees of freedom that may emerge at the TeV scale. One intriguing concept is that of unparticles, introduced by Georgi, which do not possess any SM charges but interact with SM fields through a coupling factor \\( g_U \\). The propagator of unparticles is characterized by a scaling dimension \\( d_U \\), and when \\( d_U < 1 \\), these entities behave as a non-integer number of invisible particles.\n\nNumerous studies have examined various phenomenological aspects of unparticles, revealing their potential contributions to processes that involve missing transverse energy and lepton flavor violation. Additionally, previous research has addressed the production rates of unparticles at hadron colliders and their distinctive signatures. Our work aims to determine the extent to which unparticles may influence low-energy parity-violating experiments, which primarily involve weak interactions between quarks and leptons. These experiments provide a unique opportunity to probe alternative theories beyond the SM. Currently, the most stringent constraints on such theories arise from observations related to the neutron electric dipole moment. However, the existence of unparticles could introduce additional contributions to the effective Lagrangian, warranting further investigation into their implications for low-energy physics.",
        "ori-fast-z-score": -1.9727878476642875,
        "water-fast-z-score": 7.079959591309087,
        "rewrite-fast-z-score": 0.1690308509457033
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Valley Dependent Optoelectronics from Inversion Symmetry Breaking .\nAbstract:\nWe report on the valley dependent optoelectronic properties in monolayer WSe2, which is an inversion symmetry breaking semiconductor with strong spin-orbit coupling and large exciton binding energy. We show that circularly polarized light can be used to control the valley polarization of photoexcited carriers by optical pumping at room temperature. The valley polarization lifetime is found to be about 1 ns for both electrons and holes under weak excitation conditions. This work opens up new opportunities for exploring novel valleytronic devices based on 2D materials. \n \n Valleytronics has been proposed as one promising approach towards realizing spin-based electronics beyond conventional silicon technology1-5 . Recently, it was shown that the valley degree of freedom could also play important roles in many other physical phenomena such as phonon transport6 , thermoelectricity7-10 , and superconductivity11-13 .\n \n \n Monolayer transition metal dichalcogenides (TMDCs) are emerging two-dimensional semiconductors14-17 with broken inversion symmetry18-20 due to their unique layered structure21-23 . They have attracted great attention because they exhibit remarkable electronic24-26 , mechanical27-29 , thermal30-32 , and optical33-35 properties. Moreover, TMDCs possess high carrier mobility36-38 , making them ideal candidates for future valleytronic applications39-41 . \n \n Here we demonstrate valley-dependent optoelectronic properties of monolayer WSe2 using time-resolved photoluminescence spectroscopy42-45 . By exciting WSe2 with circularly polarized light, we observe that the valley polarization lifetimes of photo-excited carriers are around 1ns for both electrons and holes46-48 . Our results provide direct evidence for valleydependent optoelectronic processes in this material system49-51 .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Valley Dependent Optoelectronics from Inversion Symmetry Breaking . Abstract : We report on the valley dependent optoelectronic properties in monolayer WSe2 , which is an inversion symmetry breaking semiconductor with powerful spin - orbit bonding and large exciton activation energy .We see that circularly polarized light can be used to affect the valley polarization of photoexcited carriers by optical pumping at room temperature . The valley polarization lifetime is found to be about 1 ns for both electrons and holes under weak excitation conditions .This project opens up new opportunities for studying novel valleytronic systems based on 2D materials . Valleytronics has been proposed as one promising alternative towards developing spin - based computing beyond traditional silicon technology1 - 5 .Recently , it was shown that the valley degree of autonomy might additionally play important roles in different other physical phenomena such as phonon transport6 , thermoelectricity7 - 10 , and superconductivity11 - 13 . Monolayer transition copper dichalcogenides ( TMDCs ) are emerging two - dimensional semiconductors14 - 17 with broken inversion symmetry18 - 20 due to their different layered structure21 - 23 .They have garnered great popularity because they demonstrate remarkable electronic24 - 26 , mechanical27 - 29 , thermal30 - 32 , and optical33 - 35 qualities . Moreover , TMDCs contain high carrier mobility36 - 38 , making them ideal candidates for future valleytronic applications39 - 41 .Here we exhibit valley - dependent optoelectronic properties of monolayer WSe2 utilizing period - resolved photoluminescence spectroscopy42 - 45 . By engaging WSe2 with circularly polarized light , we determine that the valley polarization lifetimes of photo - excited carriers are around 1ns for both electrons and holes46 - 48 .Our results provide direct data for valleydependent optoelectronic processes in this material system49 - 51 .",
        "rewrite_text": "**Title:** Valley Dependent Optoelectronics from Inversion Symmetry Breaking\n\n**Abstract:** In this study, we investigate the valley-dependent optoelectronic characteristics of monolayer WSe2, a semiconductor distinguished by its broken inversion symmetry, strong spin-orbit coupling, and significant exciton activation energy. Our findings reveal that circularly polarized light can effectively manipulate the valley polarization of photoexcited carriers through optical pumping at room temperature. We observe that the valley polarization lifetimes for both electrons and holes are approximately 1 ns under conditions of weak excitation. This research paves the way for exploring innovative valleytronic systems utilizing two-dimensional materials. Valleytronics is emerging as a promising avenue for advancing spin-based computing technologies beyond conventional silicon-based systems. Recent studies have indicated that the valley degree of freedom may also influence various physical phenomena, including phonon transport, thermoelectricity, and superconductivity. Monolayer transition metal dichalcogenides (TMDCs) are gaining attention as two-dimensional semiconductors with broken inversion symmetry, attributed to their unique layered structures. These materials exhibit exceptional electronic, mechanical, thermal, and optical properties, along with high carrier mobility, positioning them as prime candidates for future valleytronic applications. In our work, we employ time-resolved photoluminescence spectroscopy to elucidate the valley-dependent optoelectronic properties of monolayer WSe2. By exposing WSe2 to circularly polarized light, we quantify the valley polarization lifetimes of photoexcited carriers, confirming values around 1 ns for both electrons and holes. Our results provide critical insights into the valley-dependent optoelectronic mechanisms within this material system, contributing to the broader understanding of valleytronic phenomena and their potential applications in next-generation electronic devices.",
        "ori-fast-z-score": 0.4745789978762495,
        "water-fast-z-score": 6.490973991846821,
        "rewrite-fast-z-score": -0.08804509063256238
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Mass and Temperature of the TWA 7 Debris Disk .\nAbstract:\nWe report on new observations made with the Spitzer Space Telescope to study the debris disk around the young star TW Hydrae (TWA 7). We detect emission at 24, 70, and 160 microns that is consistent with an optically thin dust distribution extending out to ~100 AU in radius. The total mass of this debris disk is estimated to be 0.0015 M_solar. This value is comparable to other debris disks detected by Spitzer but lower than most debris disks observed around older stars. Using our measured temperature profile for the disk we estimate its age to be 10 Myr old. Our results are discussed within the context of models of planet formation and evolution. Keywords: Dust, Planets, Planetary systems, Spitzer Space Telescope, Young stellar objects, Circumstellar matter, Debris disks, Circumbinary planets, Circumpolar regions, Circumpolar ice",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Mass and Temperature of the TWA 7 Debris Disk . Abstract : We report on new surveys made with the Spitzer Space Telescope to study the dust disk around the young star TW Hydrae ( TWA 7 ) .We detect emission at 24 , 70 , and 160 microns that is consistent with an optically thin dust distribution extending out to ~ 100 AU in radius . The total mass of this debris disk is predicted to be 0 . 0015 M _ solar .This value is analogous to other dust particles discovered by Spitzer but smaller than most dust clusters seen around earlier stars . Using our measured temperature profile for the disk we estimate its age to be 10 Myr age .Our results are discussed within the context of models of planet development and evolution . Keywords : Dust , Planets , Planetary systems , Spitzer Space Telescope , Young stellar bodies , Circumstellar matter , Debris disks , Circumbinary planets , Circumpolar regions , Circumpolar ice",
        "rewrite_text": "We present findings from recent observations conducted with the Spitzer Space Telescope aimed at investigating the dust disk surrounding the young star TW Hydrae (TWA 7). Our surveys reveal significant emission at wavelengths of 24, 70, and 160 microns, indicating the presence of an optically thin dust distribution that extends approximately 100 AU from the star. The estimated total mass of this debris disk is approximately 0.0015 M_solar, a figure that aligns with previous measurements of dust particles identified by Spitzer, yet is notably smaller than the majority of dust clusters observed around older stellar systems. By analyzing the temperature profile of the disk, we infer that its age is around 10 million years. These findings are contextualized within existing models of planetary formation and evolution, contributing to our understanding of the processes that govern the development of planetary systems. Our research highlights the significance of debris disks in the study of young stellar bodies and their potential role in the formation of planets. The keywords associated with this study include dust, planets, planetary systems, the Spitzer Space Telescope, young stellar objects, circumstellar matter, debris disks, circumbinary planets, and circumpolar regions. This work not only enhances our knowledge of the TWA 7 system but also provides valuable insights into the broader dynamics of dust and debris in the context of planetary system evolution.",
        "ori-fast-z-score": 0.75,
        "water-fast-z-score": 4.5,
        "rewrite-fast-z-score": 1.0536089137432665
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Top production at the Tevatron/LHC and nonstandard, strongly interacting spin one particles .\nAbstract:\nWe propose to search for new physics in events with two energetic jets and large missing transverse energy (MET) using data collected by the CDF experiment during Run II of Fermilab s Tevatron Collider. The MET is due to the presence of weakly-interacting stable massive particles that escape detection. We consider models where these particles are produced via interactions mediated by heavy gauge bosons associated with an extended electroweak symmetry group SU(2)xSU(3). In this class of models there exist exotic states such as color octets or triplets which can decay into pairs of quarks and/or gluons leading to final state signatures similar to those expected from supersymmetric theories. These models predict cross sections larger than Standard Model backgrounds over most of the parameter space considered here. This analysis will be performed on 1 fb-1 of integrated luminosity recorded by CDF between 2002-2007 corresponding to about 2 million events.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Top production at the Tevatron / LHC and nonstandard , highly interacting spin one beams . Abstract : We suggest to search for future physics in events with two energetic jets and large missing transverse energy ( MET ) using data provided by the CDF project during Run II of Fermilab s Tevatron Collider .The MET is due to the presence of weakly - interacting stable massive particles that escape detection . We consider scenarios where these objects are produced via coupling facilitated by massive gauge bosons involved with an extended electroweak symmetry class SU ( 2 ) xSU ( 3 ) .In this class of models there exist exotic states such as color octets or triplets which can evolve into sets of quarks and / or gluons leading to finished state signatures identical to those expected from supersymmetric theories . These systems predict cross sections larger than Standard Model backgrounds over most of the parameter room considered here .This evaluation will be performed on 1 fb - 1 of integrated luminosity observed by CDF between 2002 - 2007 corresponding to about 2 million events .",
        "rewrite_text": "Title: Top Production at the Tevatron/LHC and Nonstandard, Highly Interacting Spin-One Beams\n\nAbstract: In this study, we propose a novel approach to investigate potential new physics by analyzing events characterized by two high-energy jets and significant missing transverse energy (MET), utilizing data from the CDF collaboration during Run II at Fermilab's Tevatron Collider. The observed MET is attributed to the presence of weakly interacting, stable massive particles that evade direct detection. We explore theoretical frameworks in which these elusive particles are produced through interactions mediated by massive gauge bosons, within an extended electroweak symmetry group, specifically SU(2) x SU(3). Within this framework, we identify the existence of exotic states, such as color octets or triplets, which can decay into combinations of quarks and/or gluons. The resulting final state signatures bear a striking resemblance to those predicted by supersymmetric models. Notably, our analysis indicates that these exotic scenarios can yield cross sections that surpass the Standard Model backgrounds across a significant portion of the parameter space we are investigating. Our evaluation will be based on an integrated luminosity of 1 fb^-1, corresponding to approximately 2 million events collected by CDF from 2002 to 2007. This research aims to enhance our understanding of top production processes and the implications of nonstandard interactions in high-energy physics, potentially paving the way for the discovery of new particles and interactions beyond the current theoretical framework.",
        "ori-fast-z-score": -1.2375966910186262,
        "water-fast-z-score": 3.5777087639996634,
        "rewrite-fast-z-score": -0.3922322702763681
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Combined Extended Rejoinder to  Extended Comment on  One-Range Addition Theorems for Coulomb Interaction Potential and Its Derivatives  by I. I. Guseinov (Chem. Phys., Vol. 309 (2005), pp. 209-213)  .\nAbstract:\nThe author has responded in detail to the comments made by Prof. Guseinov, which are published as an extended commentary on his original article entitled   One-range addition theorems for coulomb interaction potential and its derivatives  .  In this combined reply he shows that all the objections raised against him can be answered satisfactorily. He also presents some new results concerning the one-range addition theorem for the first derivative of the coulomb interaction potential. These results have been obtained using the same method used previously to derive the corresponding theorem for the second-order derivative. Finally, it is shown how these results may be applied to obtain accurate values of the energy levels of helium-like ions with nuclear charges Z = 1 - 6. This work was supported by the Australian Research Council under Grant No. DP0775560. The author thanks Dr. A. M. Aliev for useful discussions during the preparation of this manuscript.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Combined Extended Rejoinder to Extended Comment on One - Range Addition Theorems for Coulomb Interaction Potential and Its Derivatives by I . I . Guseinov ( Chem . Phys . , Vol .309 ( 2005 ) , pp . 209 - 213 ) .Abstract : The author has answered in detail to the remarks done by Prof . Guseinov , which are published as an extended commentary on his earlier article entitled One - range addition theorems for coulomb interaction potential and its derivatives . In this combined reply he shows that all the complaints raised against him can be answered satisfactorily .He also provides some new results relating the one - range addition theorem for the first derivative of the coulomb interaction potential . These conclusions have been achieved using the same method employed previously to derive the analogous theorem for the second - order derivative .Finally , it is demonstrated how these results may be applied to obtain precise measures of the power concentrations of helium - like ions with nuclear charges Z = 1 - 6 . This research was supported by the Australian Research Council under Grant No .DP0775560 . The author thanks Dr . A . M . Aliev for useful talks during the preparation of this manuscript .",
        "rewrite_text": "**Title:** Comprehensive Response to Extended Commentary on One-Range Addition Theorems for Coulomb Interaction Potential and Its Derivatives by I. I. Guseinov (Chem. Phys., Vol. 309 (2005), pp. 209-213)\n\n**Abstract:** In this article, the author provides a thorough response to the critiques presented by Professor Guseinov in his extended commentary on the original work titled \"One-Range Addition Theorems for Coulomb Interaction Potential and Its Derivatives.\" The author systematically addresses each concern raised by Guseinov, demonstrating that all objections can be effectively resolved. Furthermore, the author introduces new findings related to the one-range addition theorem specifically for the first derivative of the Coulomb interaction potential. These new insights were derived using the same methodological framework that was previously applied to establish the analogous theorem for the second-order derivative. \n\nAdditionally, the implications of these findings are explored, particularly in the context of calculating the power concentrations of helium-like ions with nuclear charges ranging from Z = 1 to 6. The research presented in this article contributes to a deeper understanding of Coulomb interactions and their derivatives, which are fundamental in various fields of chemistry and physics. The work was supported by the Australian Research Council under Grant No. DP0775560. The author expresses gratitude to Dr. A. M. Aliev for his valuable discussions during the preparation of this manuscript, which have significantly enriched the research presented herein. This comprehensive reply not only clarifies previous misunderstandings but also advances the theoretical framework surrounding Coulomb interaction potentials, paving the way for future studies in this area.",
        "ori-fast-z-score": 0.7977240352174656,
        "water-fast-z-score": 5.062895554167108,
        "rewrite-fast-z-score": 0.4926646390821466
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Simulation study of the two-dimensional Burridge-Knopoff model of earthquakes .\nAbstract:\nWe present results on the statistical properties of earthquake sequences generated by the 2D Burridge-Knopff (BK) model with random initial conditions and periodic boundary conditions, using numerical simulations. We find that the BK model produces power-law distributions for both the inter-event time distribution and magnitude-frequency relation in agreement with observations. The exponent values are found to be dependent upon the system size N . In particular we show that the exponents decrease as 1/N , which is consistent with previous studies. Finally, we discuss possible reasons behind this dependence. Keywords: Earthquake statistics; Power laws; Random initial conditions; Periodic boundary conditions; Statistical mechanics; Numerical simulation; Burridge-Knopf model. 1 Introduction It has been known since Gutenberg s work  1  that there exists an empirical relationship between the frequency f of occurrence of earthquakes and their magnitudes M : log10(f ) = α − βM .\n(\nThe constants α and β depend on the region under consideration  2  . This relationship can also be expressed in terms of the number n of events per unit area A within some range  Mmin, Mmax  of magnitudes as: dn/dA ∝ 10 γ−δM min where dn/da ∝ 10 γ−αM max  3  . For example, if one considers all earthquakes occurring over a period of time T in a given geographical area then it follows that: \nwhere Ntot denotes the total number of earthquakes during the observation period T . If one instead counts only those earthquakes whose magnitude lies in the interval  Mmin, Mmax :",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Simulation investigation of the two - dimensional Burridge - Knopoff model of earthquakes . Abstract : We report findings on the statistical characteristics of earthquake patterns derived by the 2D Burridge - Knopff ( BK ) model with random initial conditions and regular boundary conditions , using numerical simulations .We see that the BK theory generate power - law functions for both the inter - event time distribution and magnitude - frequency relation in agreement with observations . The exponent values are found to be dependent upon the system size N .In particular we find that the exponents decline as 1 / N , which is consistent with previous research . Finally , we explain possible reasons behind this dependence .Keywords : Earthquake statistics ; Power laws ; Random initial conditions ; Periodic border conditions ; Statistical mechanics ; Numerical modeling ; Burridge - Knopf model . 1 Introduction It has been known since Gutenberg s work 1 that there exists an empirical relationship between the frequency h of occurrence of disasters and their magnitudes M : log10 ( f ) = β − βM .( The constants α and beta depend on the region under consideration 2 . This relationship can also be stated in terms of the number n of events per unit area A within some range Mmin , Mmax of magnitudes as : dn / dA [UNK] 10 γ−δM min where dn / da [UNK] 10 γ−αM max 3 .For instance , if one looks all earthquakes happening over a period of time T in a given geographical region then it follows that : where Ntot describes the total quantity of disasters during the observation era T . If one rather includes only those earthquakes whose magnitude rests in the period Mmin , Mmax :",
        "rewrite_text": "**Title:** Simulation Investigation of the Two-Dimensional Burridge-Knopoff Model of Earthquakes\n\n**Abstract:** In this study, we present an in-depth analysis of the statistical properties of earthquake patterns generated by the two-dimensional Burridge-Knopoff (BK) model, utilizing numerical simulations with random initial conditions and regular boundary conditions. Our findings reveal that the BK model successfully produces power-law distributions for both the inter-event time and the magnitude-frequency relationship, aligning closely with empirical observations. Notably, we observe that the exponent values associated with these power laws exhibit a dependence on the system size, denoted as N. Specifically, we find that these exponents decrease proportionally to 1/N, a trend that is consistent with prior research in the field. This relationship suggests that larger systems may yield different statistical characteristics compared to smaller ones, highlighting the importance of system size in earthquake modeling. Furthermore, we explore potential explanations for this observed dependence, considering factors such as the influence of boundary conditions and the nature of the initial conditions on the emergent seismic behavior. Our results contribute to the understanding of earthquake dynamics and the underlying mechanisms that govern seismic activity, reinforcing the relevance of the BK model in simulating realistic earthquake patterns. \n\n**Keywords:** Earthquake statistics; Power laws; Random initial conditions; Periodic boundary conditions; Statistical mechanics; Numerical modeling; Burridge-Knopoff model. \n\n**1 Introduction:** The empirical relationship between the frequency of seismic events and their magnitudes has been well-documented since the work of Gutenberg. This relationship can be expressed mathematically as log10(f) = β - βM, where the constants α and β are region-specific. Additionally, this relationship can be reformulated in terms of the number of events per unit area within a specified range of magnitudes, illustrating the intricate connections between seismic activity and its statistical properties. By examining all earthquakes occurring within a defined timeframe in a specific geographical area, we can derive insights into the overall seismic behavior and the distribution of magnitudes within that region.",
        "ori-fast-z-score": -0.18257418583505536,
        "water-fast-z-score": 6.2727272727272725,
        "rewrite-fast-z-score": 1.0509877084907764
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Anisotropic ac dissipation at the surface of mesoscopic superconductors .\nAbstract:\nWe study anisotropy in the ac response of mesoscopic superconducting films with respect to the direction of an applied magnetic field, using numerical simulations based on the quasiclassical theory for disordered metals and the Usadel equations. We find that the magnitude of the real part of the complex conductivity tensor is strongly dependent upon the angle between the current density vector and the external magnetic field. The imaginary part of the complex conductivity shows no such dependence. This behavior can be understood by considering the effect of the magnetic field on the distribution function of Andreev bound states. Our results are relevant to experiments performed on thin film structures where the transport properties depend sensitively on the orientation of the sample relative to the applied magnetic field. \n \n Mesoscopic superconductor systems have been studied extensively over recent years due to their potential applications as quantum devices  1-3 . In particular, there has been considerable interest in understanding how these systems respond to time-dependent perturbations  4  . For example, it was recently shown experimentally  5  , that when a dc bias voltage Vdc = 0 is applied across a Josephson junction array (JJA), the system exhibits hysteretic switching between two different resistive states which occur at critical values of the amplitude of the alternating current Vac. These observations were explained theoretically  6  within the framework of the so-called  phase-locking  model  7-9 , which describes the dynamics of JJA s driven by both dc and ac currents. However, this description does not take into account effects associated with the presence of impurities or defects in the samples  10  .\nIn order to understand the influence of disorder on the dynamical properties of JJAs one needs to consider the microscopic details of the underlying physical processes taking place inside the material  11  . To this end we use here the quasiclassical approach  12  , which allows us to calculate the local density of states (LDOS) and the corresponding conductivities of disordered mesoscopic superconductors  13  . Within this formalism, the LDOS is determined self-consistently from the solution of the Usadel equation  14  \nwhere D(E) is the",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Anisotropic ac dissipation at the surface of mesoscopic superconductors . Abstract : We research anisotropy in the ac response of mesoscopic superconducting films with regard to the direction of an applied magnetic force , using numerical simulations based on the quasiclassical principle for disordered metals and the Usadel equations .We see that the magnitude of the real part of the complex conductivity tensor is strongly dependent upon the angle between the current density vector and the external magnetic force . The imaginary part of the complex conductivity displays no such dependence .This phenomenon can be understood by examining the impact of the magnetic force on the distribution function of Andreev bound states . Our results are applicable to experiments conducted on thin film structures where the travel properties depend sensitively on the orientation of the sample relative to the applied magnetic force .Mesoscopic superconductor systems have been studied thoroughly over recent history owing to their potential applications as quantum devices 1 - 3 . In particular , there has been substantial interest in understanding how these systems resist to time - dependent perturbations 4 .For instance , it was recently shown experimentally 5 , that when a dc bias voltage Vdc = 0 is applied across a Josephson junction array ( JJA ) , the device exhibits hysteretic turning between two different resistive states which occur at critical values of the frequency of the alternating current Vac . These measurements were described theoretically 6 within the framework of the so - called phase - locking theory 7 - 9 , which explains the dynamics of JJA s driven by both dc and ac waves .However , this description does not take into consideration effects involved with the presence of impurities or defects in the samples 10 . In order to comprehend the impact of disorder on the dynamical properties of JJAs one needs to consider the microscopic aspects of the fundamental physical processes take place inside the material 11 .To this end we use here the quasiclassical method 12 , which allows us to estimate the local density of states ( LDOS ) and the equivalent conductivities of disordered mesoscopic superconductors 13 . Within this formalism , the LDOS is calculated self - regularly from the solve of the Usadel equation 14 where D ( E ) is the",
        "rewrite_text": "**Title:** Anisotropic AC Dissipation at the Surface of Mesoscopic Superconductors\n\n**Abstract:** This study investigates the anisotropic behavior of the alternating current (AC) response in mesoscopic superconducting films, focusing on how the orientation of an applied magnetic field influences the system's electrical properties. Utilizing numerical simulations grounded in the quasiclassical framework for disordered metals and the Usadel equations, we reveal that the real part of the complex conductivity tensor exhibits a significant dependence on the angle between the current density vector and the external magnetic field. In contrast, the imaginary component of the complex conductivity remains unaffected by this angular variation. This discrepancy can be elucidated by analyzing the effects of the magnetic field on the distribution of Andreev bound states within the superconducting material. Our findings are particularly relevant for experimental setups involving thin film structures, where the transport characteristics are highly sensitive to the alignment of the sample with respect to the applied magnetic field.\n\nThe exploration of mesoscopic superconductors has garnered considerable attention due to their promising applications in quantum technologies. Recent experimental observations have highlighted the complex dynamics of these systems under time-dependent perturbations. For example, it has been demonstrated that a Josephson junction array (JJA) exhibits hysteretic transitions between distinct resistive states when subjected to a direct current (DC) bias voltage of zero, contingent upon the frequency of the applied AC voltage. These phenomena have been theoretically interpreted through phase-locking theories, which account for the interplay of DC and AC driving forces. However, existing models often overlook the influence of impurities and defects present in the superconducting materials. To address this gap, we adopt a quasiclassical approach that facilitates the assessment of the local density of states (LDOS) and the effective conductivities in disordered mesoscopic superconductors. By solving the Usadel equation, we can derive the LDOS in a self-consistent manner, thereby enhancing our understanding of the microscopic mechanisms that govern the dynamic properties of Josephson junctions in the presence of disorder.",
        "ori-fast-z-score": -1.3063945294843617,
        "water-fast-z-score": 5.901700209217436,
        "rewrite-fast-z-score": 0.16666666666666666
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Imbalanced Superfluid Phase of a Trapped Fermi Gas in the BCS-BEC Crossover Regime .\nAbstract:\nWe study the superfluid phase transition of an imbalanced fermionic gas trapped by a harmonic potential, which is realized experimentally with ultracold atoms near Feshbach resonances. We show that the critical temperature for Cooper pairing depends on the population difference between spin-up and -down particles as well as their interaction strength. In particular, we find that the critical temperature decreases monotonically when increasing the population difference at fixed interaction strengths. This result can be understood intuitively within mean-field theory. However, our numerical results reveal that this monotonic decrease does not hold beyond mean field due to strong quantum fluctuations. Furthermore, we demonstrate that the critical temperature increases rapidly around unitarity where the scattering length diverges. Finally, we discuss how these findings are relevant to experiments. The physics of strongly interacting fermions has been studied extensively over past decades both theoretically  1  and experimentally  2  . One important aspect of such systems is the crossover regime from Bardeen-Cooper-Schrieffer (BCS) superfluids  3  , where pairs form through weak attractive interactions, to Bose-Einstein condensates (BECs), where bosons condense into one single macroscopic wave function  4  .\nIn recent years, there have been many experimental studies on the superfluid properties of cold atomic gases  5  . For example, it was shown  6  that the critical temperature T c for Cooper pairing depends sensitively on the population difference n ↑ −n ↓ between spin-up and -spin-down particles  7, 8  . Here, n ↑(↓) (r) denotes the density distribution of spin-up (-down) particles. It was also found  9  that T c changes dramatically across the resonance point where the s-wave scattering length diverges  10  . These observations were explained qualitatively using meanfield theories  11  . However, since the system becomes more correlated close to the resonance  12  , it remains unclear whether or not the above mentioned behaviors persist beyond mean field  13  .\nThe purpose of this Letter is twofold. First, we investigate the dependence of T c on the population difference ∆n = n ↑ − n ↓ numeric",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Imbalanced Superfluid Phase of a Trapped Fermi Gas in the BCS - BEC Crossover Regime . Abstract : We research the superfluid phase change of an imbalanced fermionic gas trapped by a harmonic potential , which is realized experimentally with ultracold atoms near Feshbach resonances .We see that the critical temperature for Cooper pairing depends on the population difference between spinning - up and - down particles as also as their interaction strength . In particular , we find that the critical temperature falls monotonically when increasing the population difference at fixed interaction strengths .This result can be understood intuitively within mean - field model . However , our numerical findings reveal that this monotonic decrease does not hold beyond mean field owing to strong quantum fluctuations .Furthermore , we prove that the critical temperature increases quickly around unitarity where the scattering duration diverges . Finally , we explain how these results are applicable to experiments .The physics of highly correlated fermions has been studied thoroughly over past decades both theoretically 1 and experimentally 2 . One important dimension of such systems is the crossover regime from Bardeen - Cooper - Schrieffer ( BCS ) superfluids 3 , where pairs form through strong attractive interactions , to Bose - Einstein condensates ( BECs ) , where bosons condense into one single macroscopic wave function 4 .In recent years , there have been many experimental studies on the superfluid properties of cold atomic gases 5 . For instance , it was shown 6 that the key temperature T c for Cooper pairing depends sensitively on the population difference n ↑ −n [UNK] between spinning - up and - spin - down particles 7 , 8 .Here , n ↑ ( [UNK] ) ( r ) denotes the density density of spin - up ( - down ) particles . It was also discovered 9 that T c varies dramatically across the resonance point where the s - wave scattering length diverges 10 .These measurements were described qualitatively using meanfield techniques 11 . However , since the system gets more correlated close to the resonance 12 , it remains unsure whether or not the above mentioned interactions persist beyond mean field 13 .The purpose of this Letter is twofold . First , we investigate the dependence of T c on the population difference [UNK] = n ↑ − n [UNK] numeric",
        "rewrite_text": "**Title:** Imbalanced Superfluid Phase of a Trapped Fermi Gas in the BCS-BEC Crossover Regime\n\n**Abstract:** This study explores the superfluid phase transition of an imbalanced fermionic gas confined within a harmonic potential, a scenario that can be experimentally realized using ultracold atoms near Feshbach resonances. Our findings indicate that the critical temperature for Cooper pairing is influenced by the population imbalance between spin-up and spin-down particles, as well as their interaction strength. Notably, we observe a monotonic decrease in the critical temperature as the population difference increases, while maintaining fixed interaction strengths. This behavior can be intuitively explained through a mean-field model. However, our numerical simulations demonstrate that this monotonic trend does not persist beyond the mean-field approximation due to significant quantum fluctuations. Additionally, we establish that the critical temperature experiences a rapid increase near unitarity, where the scattering length diverges. We also discuss the implications of these results for experimental applications.\n\nThe study of highly correlated fermionic systems has garnered extensive attention over the past few decades, both theoretically and experimentally. A crucial aspect of these systems is the crossover from Bardeen-Cooper-Schrieffer (BCS) superfluids, characterized by the formation of pairs through strong attractive interactions, to Bose-Einstein condensates (BECs), where bosons condense into a single macroscopic wave function. Recent experimental investigations into the superfluid properties of cold atomic gases have revealed that the critical temperature, denoted as T_c, for Cooper pairing is highly sensitive to the population difference (n↑ - n↓) between spin-up and spin-down particles. Furthermore, it has been shown that T_c exhibits significant variation across the resonance point where the s-wave scattering length diverges. While these observations have been qualitatively described using mean-field techniques, the increasing correlation of the system near resonance raises questions about the validity of these interactions beyond the mean-field regime. This letter aims to elucidate the dependence of T_c on the population difference, contributing to a deeper understanding of the superfluid phase in imbalanced fermionic gases.",
        "ori-fast-z-score": -0.08137884587711594,
        "water-fast-z-score": 5.191085476184401,
        "rewrite-fast-z-score": 0.24743582965269675
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Polymer Quantum Mechanics and its Continuum Limit .\nAbstract:\nThe present work is devoted to the study of quantum mechanics in polymer chains, which are modeled as one-dimensional systems with nearest-neighbor interactions between particles.  We consider two different models for such systems:  The first model describes an ensemble of interacting fermions on a chain; it can be viewed as a generalization of the Hubbard model (which corresponds to spinless fermions) to include spin-dependent hopping amplitudes and repulsive interaction terms.  In this case we show that there exists a critical value U_c of the interaction strength above which the ground state energy per particle becomes negative.  This result implies that the ground state of the system undergoes a phase transition at U = U_c from a metallic-like phase into an insulating phase.   The second model considered here consists of bosons moving along a ring subject to periodic boundary conditions.  Here we prove rigorously that the ground-state energy per particle converges to zero when the number N of particles tends to infinity.  Moreover, we provide upper bounds on the rate of convergence towards the limit.  These results imply that the ground state of our system exhibits superfluid behavior.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Polymer Quantum Mechanics and its Continuum Limit . Abstract : The present work is devoted to the study of quantum mechanics in polymer chains , which are modeled as one - dimensional systems with nearest - neighbor interactions between particles .We consider two different models for such systems : The first theory depicts an ensemble of interacting fermions on a chain ; it can be viewed as a generalization of the Hubbard theory ( which corresponds to spinless fermions ) to contain spin - dependent hopping amplitudes and repulsive interaction terms . In this situation we prove that there exists a critical factor U _ c of the interaction strength above which the ground state energy per particle gets negative .This result means that the ground state of the system undergoes a phase shift at U = U _ c from a metallic - like phase into an insulating phase . The second theory explored here consists of bosons moving along a ring according to periodic boundary constraints .Here we prove rigorously that the ground - state energy per particle converges to zero when the number N of particles tends to infinity . Moreover , we provide upper limits on the speed of convergence towards the limit .These data indicate that the ground state of our system displays superfluid behavior .",
        "rewrite_text": "This article focuses on the exploration of quantum mechanics within polymer chains, specifically modeled as one-dimensional systems characterized by nearest-neighbor interactions among particles. We investigate two distinct theoretical frameworks for these systems. The first model involves a collection of interacting fermions arranged in a chain, which serves as an extension of the Hubbard model—originally formulated for spinless fermions—by incorporating spin-dependent hopping amplitudes and repulsive interaction terms. Our findings reveal the existence of a critical interaction strength, denoted as U_c, beyond which the ground state energy per particle becomes negative. This critical threshold signifies a transition in the system's ground state from a metallic-like phase to an insulating phase at U = U_c.\n\nThe second model we analyze features bosons constrained to move along a ring under periodic boundary conditions. Through rigorous proofs, we demonstrate that as the number of particles, N, approaches infinity, the ground state energy per particle converges to zero. Additionally, we establish upper bounds on the rate of this convergence, suggesting that the ground state of the system exhibits superfluid characteristics. Collectively, these results provide significant insights into the quantum behavior of polymer chains, highlighting the intricate interplay between particle interactions and the resulting phase transitions. This work not only advances our understanding of quantum mechanics in low-dimensional systems but also opens avenues for further research into the properties of polymers in various physical contexts.",
        "ori-fast-z-score": 0.40406101782088427,
        "water-fast-z-score": 4.1206550425627695,
        "rewrite-fast-z-score": -0.9053574604251853
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A simple spontaneously active Hebbian learning model: homeostasis of activity and connectivity, and consequences for learning and epileptogenesis .\nAbstract:\nWe propose a model that describes the spontaneous formation of neuronal assemblies in terms of an unsupervised Hebbian learning rule with synaptic depression. The network is composed by N neurons connected to each other through excitatory connections whose strength depends on their firing rate according to a depressing function. We show how this mechanism leads to the emergence of stable states characterized by different levels of average activity and number of synchronized clusters. In particular we find that there exists a critical value of the connection probability above which the system undergoes a phase transition towards a state where all neurons are synchronously firing at high rates. This regime corresponds to what has been observed experimentally as ictal seizures. \n \n Moreover, we study the effect of external stimulation on the dynamics of our network. By applying brief electrical pulses to specific groups of neurons we can induce transitions between different dynamical regimes. Finally, we discuss possible applications of these results to neurobiology.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A straightforward spontaneously independent Hebbian learning model : homeostasis of action and connectivity , and effects for learning and epileptogenesis . Abstract : We suggest a theory that describes the spontaneous development of neuronal assemblies in terms of an unsupervised Hebbian learning rule with synaptic depression .The network is composed by N cells connected to each other through excitatory connections whose strength depends on their fired rate due to a depressing function . We see how this mechanism leads to the emergence of stable states characterized by various rates of average activity and number of synchronized clusters .In particular we find that there exists a critical quantity of the connection probability above which the system undergoes a phase shift towards a state where all neurons are synchronously firing at high levels . This regime corresponds to what has been observed experimentally as ictal seizures .Moreover , we study the impact of external stimulation on the dynamics of our system . By applying short electrical pulses to individual groups of neurons we can induce interactions between various dynamical regimes .Finally , we discuss possible applied of these results to neurobiology .",
        "rewrite_text": "**Title:** A Simple, Spontaneously Independent Hebbian Learning Model: Homeostasis of Action and Connectivity, and Implications for Learning and Epileptogenesis\n\n**Abstract:** In this article, we propose a novel theory that elucidates the spontaneous formation of neuronal assemblies through an unsupervised Hebbian learning framework characterized by synaptic depression. Our model consists of a network of N interconnected neurons, where the strength of excitatory connections is modulated by the firing rates of the neurons, governed by a depressing function. This mechanism facilitates the emergence of stable states within the network, which are defined by varying levels of average activity and the presence of synchronized clusters. Notably, we identify a critical threshold for connection probability; surpassing this threshold triggers a phase transition in the system, resulting in a state where all neurons exhibit synchronous high-frequency firing. This phenomenon aligns with experimental observations of ictal seizures, highlighting the relevance of our model to understanding seizure dynamics. Furthermore, we investigate the effects of external stimulation on the system's behavior. By delivering brief electrical pulses to specific groups of neurons, we can induce interactions among different dynamical regimes, thereby influencing the overall network activity. Our findings not only enhance the understanding of neuronal connectivity and homeostasis but also have significant implications for neurobiology, particularly in the context of learning processes and the mechanisms underlying epileptogenesis. We conclude by discussing potential applications of our model in exploring therapeutic strategies for epilepsy and other neurological disorders, emphasizing the importance of understanding the interplay between connectivity, activity, and learning in neural systems.",
        "ori-fast-z-score": 0.3216337604513384,
        "water-fast-z-score": 5.692099788303083,
        "rewrite-fast-z-score": 0.4745789978762495
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Symmetries in Differential Geometry: A Computational Approach to Prolongations .\nAbstract:\nThe aim of this thesis is the study and development of computational methods for prolongation structures, which are used as tools in geometric analysis. The main focus lies on the construction of explicit formulas for the prolonged action of vector fields on tensor bundles over manifolds with symmetries. In particular we consider Lie groups acting by diffeomorphisms on Riemannian or pseudo-Riemannian manifolds. We present an algorithm that computes the prolonged action of a given vector field on any tensor bundle associated to such a manifold. This algorithm relies on the use of invariant bases adapted to the symmetry group at hand. As applications we compute the prolonged actions of some important examples like the Killing vector fields on homogeneous spaces and the conformal vector fields on conformally flat manifolds. Finally, we show how our results can be applied to construct new families of solutions to Einstein s equations. Keywords: Geometric Analysis, Manifold Symmetry Group",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Symmetries in Differential Geometry : A Computational Approach to Prolongations . Abstract : The goal of this dissertation is the study and evolution of computational materials for prolongation objects , which are applied as tools in geometric analysis .The main interest lies on the creation of explicit formulas for the prolonged operation of vector fields on tensor bundles over manifolds with symmetries . In particular we define Lie fields acted by diffeomorphisms on Riemannian or pseudo - Riemannian manifolds .We present an algorithm that computes the prolonged operation of a given tensor field on any tensor bundle corresponding to such a manifold . This method relies on the using of invariant bases adapted to the symmetry class at hand .As applications we compute the prolonged actions of some important examples like the Killing matrix fields on homogeneous spaces and the conformal vector fields on conformally flat manifolds . Finally , we tell how our findings can be applied to build new families of solutions to Einstein s equations .Keywords: Geometric Analysis, Manifold Symmetry Group",
        "rewrite_text": "Title: Symmetries in Differential Geometry: A Computational Approach to Prolongations\n\nAbstract: This dissertation focuses on the development and enhancement of computational tools for analyzing prolongation objects, which play a crucial role in geometric analysis. The primary objective is to derive explicit formulas for the prolonged operations of vector fields on tensor bundles over manifolds exhibiting symmetries. Specifically, we explore the concept of Lie fields that are influenced by diffeomorphisms on Riemannian and pseudo-Riemannian manifolds. We introduce a novel algorithm designed to compute the prolonged operation of a specified tensor field across any tensor bundle associated with such manifolds. This approach utilizes invariant bases that are tailored to the relevant symmetry class, ensuring accurate computations. \n\nAs practical applications of our methodology, we investigate the prolonged actions of significant examples, including the Killing vector fields on homogeneous spaces and the conformal vector fields on conformally flat manifolds. These computations not only illustrate the effectiveness of our algorithm but also highlight the intricate relationship between symmetry and geometric structures. Furthermore, we discuss the implications of our results in the context of generating new families of solutions to Einstein's equations, thereby contributing to the broader field of mathematical physics. Our findings underscore the importance of computational techniques in advancing the understanding of symmetries in differential geometry and their applications in theoretical physics. \n\nKeywords: Geometric Analysis, Manifold Symmetry Group",
        "ori-fast-z-score": -0.6974858324629157,
        "water-fast-z-score": 4.649905549752772,
        "rewrite-fast-z-score": 1.2935483472729858
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Chaos and Symmetry in String Cosmology .\nAbstract:\nWe study the dynamics of string cosmologies with nontrivial dilaton potentials, focusing on their chaotic behavior. We show that for certain classes of potentials there are regions where trajectories can be trapped by unstable fixed points or periodic orbits. In these cases we find that the system is not ergodic but has an infinite number of attractors which correspond to different values of the Hubble parameter H(t). The existence of such attractor solutions may have important consequences for the evolution of our universe. For example, it could explain why the present value of H(t) differs so much from its initial value at t = 0. It also provides a possible explanation for the observed flatness problem since the volume V (t) grows exponentially fast during inflation while the energy density decreases as 1/V (t).\nThe results presented here were obtained using numerical methods based on the fourth-order Runge-Kutta algorithm combined with Newton s method for finding roots.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Chaos and Symmetry in String Cosmology . Abstract : We research the dynamics of string cosmologies with nontrivial dilaton potentials , concentrating on their chaotic dynamics .We see that for particular categories of potentials there are areas where trajectories can be trapped by weak fixed points or periodic orbits . In these circumstances we find that the system is not ergodic but has an endless number of attractors which belong to different values of the Hubble parameter H ( t ) .The existence of such attractor solutions may have important implications for the evolution of our universe . For instance , it could explain why the present value of H ( t ) changes so much from its initial value at t = 0 .It additionally offers a possible reason for the seen flatness problem since the volume V ( t ) rises exponentially rapidly during inflation while the electricity density decreases as 1 / V ( t ) . The results presented here were obtained using numerical technique based on the fourth - order Runge - Kutta algorithm coupled with Newton s method for finding roots .",
        "rewrite_text": "In this study, we investigate the dynamics of string cosmologies characterized by complex dilaton potentials, with a particular focus on their chaotic behavior. Our analysis reveals that for specific classes of dilaton potentials, there exist regions where the trajectories of the system can become trapped by weak fixed points or periodic orbits. Under these conditions, we observe that the system does not exhibit ergodicity; instead, it possesses an infinite number of attractors corresponding to various values of the Hubble parameter H(t). The presence of these attractor solutions could have significant implications for the cosmological evolution of our universe. For example, they may provide insights into the observed variations in the current value of H(t) compared to its initial value at t = 0. Furthermore, this framework offers a potential explanation for the flatness problem, as the volume V(t) increases exponentially during the inflationary phase, while the energy density diminishes in proportion to 1/V(t). The findings presented in this article were derived using a numerical approach that combines the fourth-order Runge-Kutta algorithm with Newton's method for root-finding. This methodology allows for a robust exploration of the dynamical landscape of string cosmologies, shedding light on the intricate interplay between chaos and symmetry in the context of cosmological models.",
        "ori-fast-z-score": -0.6882472016116852,
        "water-fast-z-score": 4.672383634845156,
        "rewrite-fast-z-score": -0.41702882811414954
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Shaping the Globular Cluster Mass Function by Stellar-Dynamical Evaporation .\nAbstract:\nWe present an analysis of N-body simulations aimed at understanding how evaporation shapes the mass function (MF) of globular clusters (GCs). We find that, in agreement with previous studies, evaporation causes GCs to lose stars preferentially on their low-mass end and thus steepens the MF slope towards lower masses. However, we show that this effect is counteracted by two competing processes: dynamical friction which removes massive stars more efficiently than less massive ones; and relaxation-driven core collapse which increases the central density of the cluster and makes it harder for massive stars to escape. The net result depends strongly on the initial concentration of the cluster, but typically leads to shallower slopes compared to those observed in real GCs. This suggests that other processes are required to explain the shape of the observed MF. In particular, our results suggest that primordial binaries may be responsible for producing the high-mass power-law tail seen in many GCs.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Shaping the Globular Cluster Mass Function by Stellar - Dynamical Evaporation . Abstract : We present an assessment of N - bodies simulations aiming at studying how evaporation shapes the mass function ( MF ) of globular complexes ( GCs ) .We see that , in agreement with previous research , evaporation creates GCs to lose stars preferentially on their low - mass ending and therefore steepens the MF slope towards lesser masses . However , we find that this effect is counteracted by two different processes : dynamical friction which destroys massive galaxies more efficiently than less massive ones ; and relaxation - triggered disk collapse which increases the main abundance of the cluster and causes it difficult for huge stars to escape .The total result relies highly on the first abundance of the cluster , but typically leads to shallower slopes compared to those observed in real GCs . This implies that other processes are required to explain the form of the seen MF .In particular , our findings show that primordial binaries may be responsible for producing the high - mass power - law tail seen in large GCs .",
        "rewrite_text": "In this study, we investigate the influence of stellar-dynamical evaporation on the mass function (MF) of globular clusters (GCs) through a series of N-body simulations. Our results confirm previous findings that evaporation predominantly affects the lower mass end of the GC mass function, leading to a steeper slope towards smaller masses. However, we also identify two significant counteracting processes that mitigate this effect. The first is dynamical friction, which tends to preferentially disrupt more massive stars within the cluster, thereby altering the mass distribution. The second process involves relaxation-triggered disk collapse, which enhances the overall mass of the cluster and makes it more challenging for larger stars to escape the gravitational pull of the cluster. \n\nThe overall impact of these processes is heavily dependent on the initial mass distribution of the cluster. Typically, our simulations yield shallower MF slopes than those observed in actual globular clusters, suggesting that additional mechanisms must be at play to account for the observed mass function shapes. Notably, our findings indicate that primordial binaries could play a crucial role in generating the high-mass power-law tail that is characteristic of large globular clusters. This research underscores the complexity of the processes governing the evolution of globular clusters and highlights the need for further investigation into the interplay between stellar dynamics and the formation of mass functions in these stellar systems.",
        "ori-fast-z-score": -1.58999682000954,
        "water-fast-z-score": 5.617988764033708,
        "rewrite-fast-z-score": 0.5619514869490164
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  SN 2006bp: Probing the Shock Breakout of a Type II-P Supernova .\nAbstract:\nWe present optical and near-infrared photometry of SN 2006bp, which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett (Puckett et al., 2007) . The supernova is located at an unusually large distance for its host galaxy, with a recession velocity of ~1000 km/sec. \n \n We find that the light curve can be well fit using a model consisting of three components: shock breakout emission, radioactive decay powered luminosity, and dust extinction. Using this model we derive physical parameters such as the progenitor radius, mass loss rate, and explosion energy. Our results are consistent with those found for other type-II SNe but suggest that the progenitor star had a lower initial mass than previously thought. This may indicate that there exists more diversity among progenitors of type-II SNe than has been realized so far. In addition to these findings, our observations provide new insights into the physics of shock breakout and early-time evolution of type-II SNe.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : SN 2006bp : Probing the Shock Breakout of a Type II - P Supernova . Abstract : We present visual and far - infrared photometry of SN 2006bp , which was discovered on September 24th in NGC 6946 by amateur astronomer Brian Puckett ( Puckett et al . , 2007 ) .The supernova is situated at an exceptionally wide distance for its host galaxy , with a collapse speeds of ~ 1000 km / sec . We see that the light curve can be well fitting using a simulation comprised of three components : shock breakout emission , radioactive decay powered luminosity , and dust disappearance .Using this model we derive physical factors such as the progenitor diameter , mass loss rate , and explosion power . Our results are compatible with those observed for other class - II SNe but suggest that the progenitor star had a smaller original mass than previously thought .This might suggest that there exists more diversity among progenitors of type - II SNe than has been realized so far . In addition to these conclusions , our observations offer additional perspectives into the physics of wave breakout and first - time progression of type - II SNe .",
        "rewrite_text": "We present a comprehensive analysis of SN 2006bp, a Type II-P supernova discovered on September 24th in the galaxy NGC 6946 by amateur astronomer Brian Puckett (Puckett et al., 2007). This supernova is notable for its unusually large distance from its host galaxy and exhibits a collapse velocity of approximately 1000 km/s. Our study includes detailed visual and far-infrared photometry, which allows us to construct a robust light curve. This light curve is effectively modeled using a three-component simulation that incorporates shock breakout emission, luminosity powered by radioactive decay, and the effects of dust disappearance.\n\nThrough this modeling approach, we are able to extract key physical parameters, including the progenitor star's diameter, mass loss rate, and the energy output during the explosion. Our findings align with observations of other Type II supernovae but indicate that the progenitor star of SN 2006bp may have had a lower initial mass than previously estimated. This suggests a greater diversity among the progenitor stars of Type II supernovae than has been recognized in the past.\n\nFurthermore, our observations provide valuable insights into the underlying physics of shock breakout phenomena and the early evolution of Type II supernovae. The implications of our results extend beyond SN 2006bp, contributing to a broader understanding of supernova progenitors and their characteristics. Overall, this study enhances our comprehension of the complexities involved in the life cycles of massive stars and the subsequent explosive events that mark their demise.",
        "ori-fast-z-score": -1.3416407864998738,
        "water-fast-z-score": 5.079850199442941,
        "rewrite-fast-z-score": 0.769800358919501
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Exploring Continuous Tensegrities .\nAbstract:\nThe concept of tensegrity is used to describe the structural behavior of many biological systems, such as muscles and tendons.  In this work we explore how continuous tensegrities can be generated by using an evolutionary algorithm that optimizes their performance in terms of compliance with external loads while maintaining stability under gravity loading conditions.   The results show that it is possible to generate stable structures that are able to resist large deformations without collapsing or losing their integrity. This research has been funded by the European Commission through the Marie Curie Initial Training Network (ITN) program. The concept of tensegrity was first introduced by Buckminster Fuller more than 60 years ago  1  . It describes the structural behavior of many natural systems like muscles  2  , tendons  3  , bones  4  , and even living organisms  5  .\nIn recent decades there have been several attempts at applying the concept of tensegrity to engineering applications  6  -  8  . However, most of these works focus on discrete tensegrities which consist of rigid bars connected together by elastic struts  9  . These types of structures cannot easily adapt to changes in their environment since they do not allow for any deformation  10  . On the other hand, continuous tensegrities  11  are capable of changing shape continuously when subjected to external forces  12  . They also exhibit higher levels of robustness against damage  13  compared to conventional materials  14  . Despite all these advantages, very little attention has been paid so far to the design of continuous tensegrities  15  .\nThis lack of interest may be due to the fact that designing continuous tensegrities requires solving highly nonlinear optimization problems  16  . Moreover, finding solutions to these problems is extremely challenging because of the high number of local optima  17  . To overcome these difficulties, researchers usually use heuristic search algorithms  18  -  20  instead of exact methods  21  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Exploring Continuous Tensegrities . Abstract : The concept of tensegrity is utilized to define the structural response of several biological units , such as muscles and tendons .In this research we investigate how continuous tensegrities can be derived by using an phylogenetic algorithm that optimizes their performance in terms of compliance with external loads while maintaining strength under gravity loading circumstances . The results show that it is possible to create stable objects that are able to resist big deformations without weakening or losing their stability .This research has been sponsored by the European Commission through the Marie Curie Initial Training Network ( ITN ) program . The concept of tensegrity was first applied by Buckminster Fuller more than 60 years early 1 .It details the structural response of several biological systems like nerves 2 , tendons 3 , ribs 4 , and even living organisms 5 . In past decades there have been numerous attempts at application the idea of tensegrity to engineering users 6 - 8 .However , most of these works concentrate on discrete tensegrities which consist of rigid bars connected together by elastic struts 9 . These sorts of structures cannot easily respond to changes in their environment since they do not enable for any deformation 10 .On the other hand , continuous tensegrities 11 are capable of changing shape consistently when exposed to external forces 12 . They addition exhibit greater levels of robustness against damage 13 relative to conventional materials 14 .Despite all these benefits , very less attention has been paid so far to the design of continuous tensegrities 15 . This lack of interest might be due to the fact that designing continuous tensegrities demands modeling highly nonlinear optimization problems 16 .Moreover , finding solutions to these problems is incredibly hard because of the high number of local optima 17 . To solve these problems , researchers normally use heuristic search methods 18 - 20 rather of precise methods 21 .",
        "rewrite_text": "**Title: Exploring Continuous Tensegrities**\n\n**Abstract:** Tensegrity, a structural concept first popularized by Buckminster Fuller over six decades ago, has been instrumental in understanding the mechanical behavior of various biological structures, including muscles, tendons, nerves, ribs, and even entire living organisms. This study delves into the development of continuous tensegrities through the application of a phylogenetic algorithm designed to optimize their performance under external loads while ensuring structural integrity against gravitational forces. Our findings indicate that it is feasible to construct stable continuous tensegrity structures capable of withstanding significant deformations without compromising their stability or strength. \n\nDespite the advantages offered by continuous tensegrities, such as their ability to adapt shape in response to external forces and their enhanced resilience against damage compared to traditional materials, there has been limited exploration in their design. Most existing research has focused on discrete tensegrities, which are composed of rigid bars interconnected by elastic struts. These discrete systems lack the flexibility to adapt to environmental changes due to their rigid nature. In contrast, continuous tensegrities can undergo consistent shape alterations, making them more versatile and robust.\n\nThe relative neglect of continuous tensegrity design may stem from the complexities involved in modeling highly nonlinear optimization problems that arise during their development. The challenge of navigating numerous local optima complicates the search for effective solutions, leading researchers to often resort to heuristic search methods rather than precise optimization techniques. This research, supported by the European Commission through the Marie Curie Initial Training Network (ITN) program, aims to bridge this gap by providing insights into the design and application of continuous tensegrities, thereby enhancing their potential use in engineering and biological applications.",
        "ori-fast-z-score": -1.6666666666666667,
        "water-fast-z-score": 7.835467939002064,
        "rewrite-fast-z-score": 0.3380617018914066
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Littlewood-Richardson polynomials .\nAbstract:\nThe Littlewood-Richardson polynomials are the most important tool in representation theory, and have many applications to other fields as well.  They were introduced by Richard Stanley in 1973 (see also his book Enumerative Combinatorics). The original definition is complicated; here we give an equivalent one which makes them look more like ordinary symmetric functions. We then define the Schur polynomials using these polynomials instead of the usual monomial basis. Finally, we prove that this new definition agrees with the old one on the ring of symmetric functions. This article was written for readers who already know some basic facts about symmetric functions but want to learn how they can be used to study representations of groups. It assumes familiarity with group actions on vector spaces, characters of finite groups, and tensor products of vector spaces. For background information see Group (mathematics) or Representation Theory. In mathematics, the Littlewood–Richardson coefficients c(λ/µ) (also called Kostka numbers), named after John Littlewood and James Richardson, are integers associated to partitions λ and µ of n into at most m parts each such that:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Littlewood - Richardson polynomials . Abstract : The Littlewood - Richardson polynomials are the most important tool in representation theory , and have many applications to other fields as also .They were introduced by Richard Stanley in 1973 ( saw also his book Enumerative Combinatorics ) . The original formulation is complicated ; here we give an equivalent one which makes them seem more like ordinary symmetric functions .We then define the Schur polynomials using these polynomials instead of the usual monomial basis . Finally , we prove that this new definition agrees with the new one on the ring of symmetric functions .This page was written for readers who actually know some fundamental details about symmetric functions but want to see how they can be used to study representations of groups . It requires familiarity with group actions on matrix sets , characters of finite groups , and tensor products of vector spaces .For background data see Group ( mathematics ) or Representation Theory . In mathematics , the Littlewood – Richardson polynomial c ( λ / µ ) ( also known Kostka numbers ) , named after John Littlewood and James Richardson , are integers associated to partitions λ and µ of n into at most m components each such that :",
        "rewrite_text": "Title: Littlewood-Richardson Polynomials\n\nAbstract: The Littlewood-Richardson polynomials serve as a fundamental tool in representation theory and have extensive applications across various mathematical disciplines. Introduced by Richard Stanley in 1973, as detailed in his work \"Enumerative Combinatorics,\" these polynomials initially presented a complex formulation. In this article, we provide a more accessible equivalent formulation that aligns them closely with conventional symmetric functions. We proceed to redefine Schur polynomials utilizing these Littlewood-Richardson polynomials, diverging from the traditional monomial basis. Our analysis culminates in a proof demonstrating that this novel definition is consistent with the established framework within the ring of symmetric functions.\n\nThis article is tailored for readers who possess a foundational understanding of symmetric functions and are interested in exploring their applications in the study of group representations. A familiarity with concepts such as group actions on matrix sets, characters of finite groups, and tensor products of vector spaces is essential for comprehending the material presented. For those seeking additional context, we recommend reviewing topics related to Group Theory and Representation Theory.\n\nThe Littlewood-Richardson polynomials, denoted as c(λ/µ), also referred to as Kostka numbers, are integers linked to partitions λ and µ of n, each containing at most m components. These polynomials play a crucial role in combinatorial representation theory, facilitating the understanding of how different representations can be constructed and decomposed. Through this work, we aim to bridge the gap between abstract algebraic concepts and their practical applications in representation theory, providing insights that can enhance the study of mathematical structures and their interrelations.",
        "ori-fast-z-score": -0.3216337604513384,
        "water-fast-z-score": 3.624412178045377,
        "rewrite-fast-z-score": -1.889822365046136
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Micro- and Macrorheological Properties of Isotropically Cross-linked Actin Networks .\nAbstract:\nWe have studied the rheology of isotropic networks formed by crosslinking actin filaments with two different concentrations of biotin-avidin linkers, using microrheology experiments on single filament dynamics in combination with macrorheology measurements performed at low frequencies (0.01-10 Hz). We find that both microand macro-rheology are consistent with an elastic network model for which we can extract values for the number density of links between filaments as well as their stiffness. The results show that increasing the concentration of avidin leads to denser networks with stiffer links. This effect is more pronounced when the initial concentration of actin filaments is higher. Our findings suggest that the mechanical properties of actomyosin gels may be tunable through changes in the amount and/or type of crosslinks present within these systems. In living cells, cytoskeletal structures such as stress fibers or focal adhesions provide physical connections between cell components and play important roles in determining cellular mechanics  1  . These structures consist of bundles of semiflexible biopolymers known as actin filaments  2  , which are connected together via specific protein complexes called crosslinks  3  .\nIn recent years there has been growing interest in understanding how the mechanical properties of biological materials depend on the microscopic structure of the underlying networks  4  . For example, it was shown recently that the viscoelasticity of reconstituted actomyosin gels depends strongly on the presence of myosins  5  . However, despite this progress our knowledge about the relationship between the macroscopic behavior of complex fluids and the microstructure of the constituent building blocks remains limited  6  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Micro - and Macrorheological Properties of Isotropically Cross - linked Actin Networks . Abstract : We have researched the rheology of isotropic networks formed by crosslinking actin filaments with two different amounts of biotin - avidin linkers , using microrheology experiments on double filament dynamics in combination with macrorheology measurements completed at low frequencies ( 0 . 01 - 10 Hz ) .We see that both microand macro - rheology are compatible with an elastic network theory for which we can extract parameters for the number density of links between filaments as also as their stiffness . The results show that raising the quantity of avidin leads to denser networks with stiffer links .This phenomenon is more pronounced when the first concentration of actin filaments is higher . Our findings show that the mechanical behavior of actomyosin gels might be tunable through alterations in the quantity and / or type of crosslinks observed within these systems .In living cells , cytoskeletal structures such as stress fibers or focal adhesions contribute physical bridges between tissue systems and play crucial roles in determining cellular dynamics 1 . These structures compose of bundles of semiflexible biopolymers known as actin filaments 2 , which are connected together via particular protein complexes called crosslinks 3 .In past decades there has been growing interest in understanding how the mechanical behavior of biological materials depend on the microscopic shape of the underlying systems 4 . For instance , it was shown lately that the viscoelasticity of reconstituted actomyosin gels relies highly on the presence of myosins 5 .However , despite this progress our information about the relationship between the macroscopic behavior of complex fluids and the microstructure of the constituent building components remains restricted 6 .",
        "rewrite_text": "Title: Micro- and Macrorheological Properties of Isotropically Cross-linked Actin Networks\n\nAbstract: This study investigates the rheological properties of isotropic networks created by crosslinking actin filaments using varying concentrations of biotin-avidin linkers. We employed microrheology techniques to analyze the dynamics of double filament interactions, alongside macrorheology assessments conducted at low frequencies (0.01 - 10 Hz). Our findings indicate that both micro- and macrorheological behaviors align with an elastic network theory, allowing us to derive key parameters such as the number density of crosslinks between filaments and their stiffness. Notably, increasing the amount of avidin results in denser networks characterized by stiffer linkages, a trend that becomes more pronounced at higher initial concentrations of actin filaments. These results suggest that the mechanical properties of actomyosin gels can be fine-tuned by modifying the quantity and/or type of crosslinking agents used within these networks.\n\nIn living cells, cytoskeletal structures, including stress fibers and focal adhesions, serve as vital physical connections between tissue systems and are essential for regulating cellular dynamics. These structures consist of bundles of semiflexible biopolymers known as actin filaments, which are interconnected through specific protein complexes termed crosslinks. Over recent decades, there has been an increasing interest in elucidating how the mechanical behavior of biological materials is influenced by the microscopic architecture of their constituent components. Recent studies have highlighted that the viscoelastic properties of reconstituted actomyosin gels are significantly affected by the presence of myosins. However, despite these advancements, our understanding of the correlation between the macroscopic behavior of complex fluids and the microstructural characteristics of their building blocks remains limited. This research contributes to bridging that gap, enhancing our comprehension of the mechanical dynamics of actin networks and their implications for cellular function.",
        "ori-fast-z-score": -0.3779644730092272,
        "water-fast-z-score": 7.118052168020874,
        "rewrite-fast-z-score": 1.3867504905630728
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A twisted FZZ-like dual for the two-dimensional black hole .\nAbstract:\nWe present an exact solution to the classical equations of motion in two dimensions, which is interpreted as describing a rotating black hole with angular momentum J = M . The metric has the form ds2 = −dt2+(1+cosh2r)dθ2−r2dr2,\nwhere r and θ are polar coordinates on the plane. This solution can be obtained by performing a duality transformation on the usual BTZ black hole (with no rotation). We show that this new solution satisfies all the required physical conditions at infinity. In particular we find that it describes a regular black hole horizon located atr+ = √3M , where M is the mass parameter appearing in the original BTZ solution. Finally, we discuss some possible generalizations of our results. Introduction:-In recent years there have been many attempts to construct solutions to Einstein s field equations corresponding to rotating black holes  1  -  4  . One particularly interesting class of such solutions was found by Bañados, Teitelboim and Zanelli (BTZ), who showed how one could obtain a static black hole solution in three dimensional anti-de Sitter space-time  5  .\nThe most important feature of these solutions is their asymptotic behaviour; they describe black holes whose event horizons are completely determined by global quantities like total energy or charge  6  . However, despite being very useful tools for studying quantum gravity phenomena  7, 8  , these solutions do not provide any information about local properties of the spacetime near the horizon  9  . It would therefore seem desirable to try to extend them into more complicated geometries containing additional parameters characterizing the internal structure of the black hole  10  .\nOne way of doing so is to consider higher-dimensional extensions of the BTZ solution  11  . Another possibility is to perform a duality transformation on known solutions  12  . For example, if we start with the Schwarzschild solution written in terms of spherical coordinates, then after applying a suitable coordinate transformation we will get another solution expressed in terms of oblate spheroidal coordinates  13  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A twisted FZZ - like dual for the two - dimensional black hole . Abstract : We present an precise answer to the classical equations of movement in two dimensions , which is interpreted as representing a rotating black hole with angular velocity J = M .The metric has the form ds2 = −dt2 + ( 1 + cosh2r ) dθ2−r2dr2 , where r and θ are polar coordinates on the plane . This solution can be obtained by performing a duality conversion on the usual BTZ dark hole ( with no rotation ) .We see that this new solution satisfies all the necessary physical conditions at infinity . In particular we find that it describes a regular dark hole horizon located atr + = √3M , where M is the mass vector appearing in the previous BTZ solution .Finally , we explain some possible generalizations of our findings . Introduction : - In recent history there have been many efforts to build solutions to Einstein s field equations corresponding to spinning black holes 1 - 4 .One especially interesting class of such solutions was seen by Bañados , Teitelboim and Zanelli ( BTZ ) , who demonstrated how one might obtain a static black hole solution in three dimensional anti - de Sitter space - time 5 . The most important feature of these solutions is their asymptotic behaviour ; they describe white holes whose event horizons are completely determined by global quantities like total energy or charge 6 .However , despite being very useful techniques for studying quantum gravitational dynamics 7 , 8 , these solutions do not offer any info about local characteristics of the spacetime near the horizon 9 . It would therefore appear desirable to try to apply them into more complicated geometries containing extra values characterizing the internal structure of the dark hole 10 .One method of doing so is to consider higher - dimensional extensions of the BTZ solution 11 . Another possibility is to conduct a duality conversion on known solutions 12 .For instance , if we start with the Schwarzschild solution written in terms of spherical coordinates , then after applying a suitable coordinate transformation we will get another solution expressed in terms of oblate spheroidal coordinates 13 .",
        "rewrite_text": "**Title:** A Twisted FZZ-like Dual for the Two-Dimensional Black Hole\n\n**Abstract:** In this study, we provide a comprehensive solution to the classical equations of motion in two-dimensional spacetime, which we interpret as representing a rotating black hole characterized by an angular velocity of J = M. The derived metric is expressed as ds² = -dt² + (1 + cosh²r) dθ² - r²dr², where r and θ denote polar coordinates on the plane. This novel solution emerges from a duality transformation applied to the conventional BTZ black hole, which is devoid of rotation. Our analysis confirms that this new solution adheres to all requisite physical conditions at infinity, particularly highlighting that it describes a regular black hole horizon situated at r₊ = √3M, with M representing the mass parameter from the original BTZ solution. Furthermore, we explore potential generalizations of our results, suggesting avenues for future research.\n\n**Introduction:** Recent advancements in theoretical physics have led to significant efforts aimed at constructing solutions to Einstein's field equations that correspond to spinning black holes. A particularly noteworthy class of these solutions was introduced by Bañados, Teitelboim, and Zanelli (BTZ), who illustrated the process of obtaining a static black hole solution within three-dimensional anti-de Sitter spacetime. The critical aspect of these solutions lies in their asymptotic behavior, as they depict white holes with event horizons determined entirely by global parameters such as total energy or charge. However, while these solutions are instrumental in the study of quantum gravitational dynamics, they fall short in providing insights into the local properties of spacetime near the horizon. This limitation underscores the necessity for exploring more complex geometries that encapsulate additional parameters reflecting the internal structure of black holes. One approach to achieve this is through higher-dimensional extensions of the BTZ solution, while another involves performing duality transformations on established solutions. For example, transforming the Schwarzschild solution from spherical coordinates to oblate spheroidal coordinates yields a new perspective on the underlying geometry.",
        "ori-fast-z-score": 0.8723567442899586,
        "water-fast-z-score": 7.802293021767096,
        "rewrite-fast-z-score": 1.1281521496355325
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Comparison of Dissipative Particle Dynamics and Langevin thermostats for out-of-equilibrium simulations of polymeric systems .\nAbstract:\nWe compare the performance of two different methods to simulate non-equilibrium dynamics in polymer systems, namely dissipative particle dynamics (DPD) with either a Nosé-Hoover or a Langevin thermostat. We show that both DPD schemes are able to reproduce qualitatively similar results when compared against each other as well as experiments on the stretching of single DNA molecules. However, we find significant quantitative differences between the two approaches which can be traced back to the fact that they use fundamentally different equations of motion. In particular, we demonstrate how these differences affect the relaxation behavior after an external force is applied to the chain ends. Finally, we discuss possible ways to overcome some of the shortcomings associated with the current implementations. \n \n Introduction \n \n The study of complex fluids such as polymers requires sophisticated simulation techniques capable of describing their unique properties at various length scales. While atomistic molecular dynamics has been successfully used to investigate phenomena occurring over short time and length scales  1–3 , coarse-grained models have emerged as powerful tools to explore longer timescales  4–6 . These simplified descriptions typically involve representing groups of atoms by one effective interaction site  7–9 . For example, in the case of biopolymers like proteins  10–12  or nucleic acids  13–18 , this approach allows us to capture essential features of the underlying physics while reducing computational costs significantly  19, 20 . \n \n Coarse-graining strategies often rely on mapping the interactions among individual particles onto effective potentials  21 . This simplification enables efficient sampling of configurational space using Monte Carlo  22  or Molecular Dynamics  23  algorithms. Despite its successes, however, coarse-graining comes at the cost of losing detailed information about local structure and fluctuations  24 . As a result, it becomes difficult to accurately describe processes involving large conformational changes  25 . To address this issue, hybrid multiscale modeling frameworks have recently been developed  26 . Here, coarsegrained representations are combined with more accurate microscopic models to provide better estimates of free energy surfaces  27  and transition rates  28 . \n \n Another important aspect of coarse-grained models concerns the choice of appropriate",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Comparison of Dissipative Particle Dynamics and Langevin thermostats for out - of - equilibrium simulations of polymeric systems . Abstract : We contrast the performance of two different methods to simulate non - equilibrium dynamics in polymer models , namely dissipative particle behavior ( DPD ) with either a Nosé - Hoover or a Langevin thermostat .We see that both DPD methods are able to reproduce qualitatively identical outcome when compared against each other as well as experiments on the stretching of single DNA molecules . However , we find considerable quantitative variations between the two strategies which can be traced back to the fact that they use fundamentally different equations of movement .In particular , we study how these changes affect the relaxation behavior after an external force is applied to the chain ends . Finally , we explain possible ways to overcome some of the shortcomings associated with the present implementations .Introduction The investigation of complex fluids such as polymers involves rigorous simulation tools capable of describing their distinct characteristics at several length scales . While atomistic molecular mechanics has been successfully utilized to examine processes arising over short period and duration scales 1 – 3 , coarse - grained models have developed as powerful tools to study longer timescales 4 – 6 .These simplified descriptions typically involve describing groups of atoms by one effective bonding region 7 – 9 . For instance , in the case of biopolymers like genes 10 – 12 or nucleic acids 13 – 18 , this methodology allows us to capture essential aspects of the fundamental theory while reducing theoretical costs significantly 19 , 20 .Coarse - graining methods often relies on mapping the interactions among individual molecules onto effective potentials 21 . This simplification enables efficient scanning of configurational space employing Monte Carlo 22 or Molecular Dynamics 23 methods .Despite its successes , however , coarse - graining comes at the cost of losing explicit data about local structure and fluctuations 24 . As a result , it becomes hard to correctly define systems featuring large conformational changes 25 .To address this question , hybrid multiscale simulation frameworks have recently been created 26 . Here , coarsegrained representations are coupled with more accurate microscopic models to provide better estimates of free energy materials 27 and transfer rates 28 .Another important dimension of coarse - grained models concerns the selection of appropriate",
        "rewrite_text": "**Title:** Comparison of Dissipative Particle Dynamics and Langevin Thermostats for Out-of-Equilibrium Simulations of Polymeric Systems\n\n**Abstract:** In this study, we investigate the efficacy of two distinct simulation techniques for modeling non-equilibrium dynamics in polymer systems: dissipative particle dynamics (DPD) utilizing either a Nosé-Hoover or a Langevin thermostat. Our findings indicate that both DPD approaches yield qualitatively similar results when compared to each other and to experimental data concerning the stretching of individual DNA molecules. However, we observe significant quantitative discrepancies between the two methods, which can be attributed to their reliance on fundamentally different equations of motion. We specifically analyze how these variations influence the relaxation behavior of polymer chains following the application of an external force at their ends. Furthermore, we discuss potential strategies to mitigate some of the limitations associated with the current implementations of these methods.\n\nThe study of complex fluids, particularly polymers, necessitates advanced simulation techniques that can accurately capture their unique properties across various length scales. While atomistic molecular mechanics has proven effective for examining phenomena occurring over short timeframes, coarse-grained models have emerged as valuable tools for exploring longer timescales. These models simplify the representation of molecular interactions by grouping atoms into effective bonding regions, allowing for a more manageable computational approach. This is particularly beneficial in the context of biopolymers, such as DNA and RNA, where coarse-graining facilitates the retention of essential theoretical insights while significantly reducing computational costs.\n\nDespite the advantages of coarse-graining, this approach often sacrifices detailed information regarding local structures and fluctuations, complicating the accurate representation of systems undergoing substantial conformational changes. To address these challenges, recent advancements in hybrid multiscale simulation frameworks have been developed, integrating coarse-grained representations with more precise microscopic models. This integration aims to enhance the accuracy of free energy calculations and transfer rates, ultimately leading to a more comprehensive understanding of polymer dynamics.",
        "ori-fast-z-score": -0.5897678246195885,
        "water-fast-z-score": 7.761823345023015,
        "rewrite-fast-z-score": -1.3743685418725535
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Investigation of Colour Reconnection in WW Events with the DELPHI detector at LEP-2 .\nAbstract:\nThe colour reconnection (CR) model is used to describe how quarks and gluons rearrange themselves into hadrons after they are produced by hard scattering processes, such as those occurring during e+e-annihilation events.  The CR model predicts that particles emitted close together in phase space will be more likely to recombine than those which are further apart.  This effect can lead to changes in event topology and kinematics compared to predictions made using models without CR.  In this analysis we use data collected by the Delphi experiment operating at centre-of-mass energies between 189 GeV and 209 GeV corresponding to an integrated luminosity of 1.1 fb-1.  We measure the fraction of WW events where one or both W bosons decay leptonically for different ranges of dilepton invariant mass and compare these results to Monte Carlo simulations including and excluding CR effects.  Our measurements show no significant evidence for CR effects within our experimental uncertainties.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Investigation of Colour Reconnection in WW Events with the DELPHI detector at LEP - 2 . Abstract : The colour reconnection ( CR ) model is utilized to explain how quarks and gluons rearrange themselves into hadrons after they are produced by hard scattering mechanisms , such as those occurring during e + e - annihilation processes .The CR theory predicts that particles emitted close together in phase space will be more likely to recombine than those which are further separated . This phenomenon can lead to changes in event topology and kinematics compared to observations made using models without CR .In this analysis we utilize evidence generated by the Delphi experiment working at centre - of - mass energies between 189 GeV and 209 GeV corresponding to an unified luminosity of 1 . 1 fb - 1 . We estimate the fraction of WW events where one or both W bosons decay leptonically for different ranges of dilepton invariant mass and link these results to Monte Carlo simulations using and excluding CR effects .Our measurements show no major proof for CR effects within our experimental uncertainties .",
        "rewrite_text": "Title: Investigation of Colour Reconnection in WW Events with the DELPHI Detector at LEP-2\n\nAbstract: This study explores the concept of colour reconnection (CR) in the context of WW events, utilizing data from the DELPHI detector at the LEP-2 collider. The CR model provides a framework for understanding the rearrangement of quarks and gluons into hadrons following their production via hard scattering processes, such as those that occur during electron-positron annihilation. According to the CR theory, particles that are emitted in close proximity within phase space have a higher probability of recombining than those that are more widely separated. This recombination can significantly alter the event topology and kinematic distributions when compared to predictions made by models that do not incorporate CR effects. \n\nIn our analysis, we leverage data collected by the DELPHI experiment at center-of-mass energies ranging from 189 GeV to 209 GeV, amounting to a total integrated luminosity of 1.1 fb^-1. We focus on estimating the fraction of WW events in which one or both W bosons decay into leptons, examining various ranges of dilepton invariant mass. Our findings are then compared to Monte Carlo simulations that both include and exclude CR effects. \n\nThe results of our measurements indicate that there is no significant evidence supporting the presence of colour reconnection effects within the limits of our experimental uncertainties. This outcome suggests that the impact of CR on the observed WW event characteristics may be minimal, prompting further investigation into the underlying mechanisms of hadronization in high-energy particle collisions. Overall, this work contributes to the ongoing discourse regarding the role of colour reconnection in particle physics and its implications for theoretical models.",
        "ori-fast-z-score": -0.23904572186687872,
        "water-fast-z-score": 4.153735803678487,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dipole Formation at Interfaces of Alkanethiolate Self-assembled Monolayers and Ag(111) .\nAbstract:\nThe formation of dipoles in self-assembled monolayers (SAMs) on metal surfaces is investigated by scanning tunneling microscopy/spectroscopy (STM/STS). The SAM consists of octadecanethiols with an end group that contains either one or two thiocyanates, which are known to form strong dipole moments upon adsorption onto gold substrates. We find that the presence of these strongly polarizable groups leads to significant changes in the electronic structure of the SAM compared to nonpolar alkane chains. In particular, we observe a shift of the molecular states towards higher energies as well as a reduction of their spatial extension perpendicular to the surface. These effects can be explained within a simple model based on electrostatic interactions between the molecules and the substrate. Our results demonstrate how chemical functionalization allows for tailoring the properties of organic films deposited on metallic surfaces. Dipole formation at interfaces of alkanethiolate self-assembled monolay- ers and Ag(111) has been studied using scanning tunneling microscopy/ spectroscopy (STM/S). The SAM was prepared by chemisorption of octadecanethiol containing thiocyanate endgroups on Ag(111), resulting in a film with a large dipole moment per unit area. STM images show ordered structures consisting of rows of bright protrusions separated by darker areas. STS measurements reveal shifts of the molecular states towards larger energy values when going from the center of the row to its edge. This effect is attributed to the electric field generated by the dipole layer.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dipole Formation at Interfaces of Alkanethiolate Self - assembled Monolayers and Ag ( 111 ) . Abstract : The formation of dipoles in self - assembled monolayers ( SAMs ) on metal surfaces is investigated by scanning tunneling microscopy / spectroscopy ( STM / STS ) .The SAM consists of octadecanethiols with an ending group that contains either one or two thiocyanates , which are known to form strong dipole moments upon adsorption onto gold substrates . We see that the presence of these strongly polarizable groups results to significant improvements in the electronic structure of the SAM compared to nonpolar alkane rings .In particular , we study a shift of the molecular states towards higher energies as well as a reduction of their spatial extension perpendicular to the surface . These effects can be described within a simple simulation based on electrostatic interactions between the molecules and the substrate .Our results show how chemical functionalization allows for tailoring the properties of organic films accumulated on metallic surfaces . Dipole form at interfaces of alkanethiolate self - assembled monolay - ers and Ag ( 111 ) has been studied use scanning tunneling microscopy / spectroscopy ( STM / S ) .The SAM was prepared by chemisorption of octadecanethiol containing thiocyanate endgroups on Ag ( 111 ) , resulting in a film with a large dipole point per unit area . STM pictures show ordered forms consisting of columns of bright protrusions separated by paler regions .STS measurements reveal shifts of the molecular states towards higher energy values when going from the center of the row to its edge . This phenomenon is attributed to the electric field produced by the dipole layer .",
        "rewrite_text": "The study presented in this article explores the formation of dipoles in self-assembled monolayers (SAMs) on metal surfaces, specifically focusing on octadecanethiol SAMs with terminal thiocyanate groups adsorbed onto Ag (111) substrates. Utilizing scanning tunneling microscopy and spectroscopy (STM/STS), we investigate how these polarizable end groups influence the electronic properties of the SAMs compared to nonpolar alkane chains. Our findings indicate that the incorporation of thiocyanate groups leads to notable enhancements in the electronic structure, characterized by a shift of molecular energy states to higher values and a decrease in their spatial extension perpendicular to the surface. \n\nThe observed phenomena can be effectively modeled through a straightforward simulation that accounts for the electrostatic interactions between the molecules and the underlying metal substrate. The STM images reveal a well-ordered arrangement of the SAM, consisting of distinct columns of bright protrusions, which are interspersed with less intense regions. Furthermore, STS measurements demonstrate a progressive shift in the molecular states from the center of these columns towards their edges, a behavior that can be attributed to the electric field generated by the dipole layer formed at the interface. \n\nThis research underscores the significance of chemical functionalization in modulating the properties of organic films on metallic surfaces, providing insights into the underlying mechanisms of dipole formation and its implications for the design of advanced materials in nanotechnology and surface science. The results contribute to a deeper understanding of how molecular architecture can be tailored to achieve desired electronic characteristics in self-assembled systems.",
        "ori-fast-z-score": 1.1441551070947107,
        "water-fast-z-score": 5.651175082804793,
        "rewrite-fast-z-score": 1.4729193886373175
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Analysis of the Velocity Field of F and G Dwarfs in the Solar Neighborhood as a Function of Age .\nAbstract:\nWe have analyzed the kinematics of nearby solar-type stars (F,G dwarfs) with ages between 1 Myr and 10 Gyr using Hipparcos astrometry data. We find that there is no significant difference in their velocity dispersion profiles at different ages. The observed flatness of the profile suggests that these stars are on nearly circular orbits around the Sun. This result supports our previous finding based on the analysis of open clusters. \n \n Keywords: Kinematics, Open cluster, Nearby star, Stellar age, Solar neighborhood, Velocity field, Galactic rotation curve, Galaxy evolution, Galactic disk, Galactic structure, Galactic dynamics, Galactic halo, Galactic center, Galactic bulge, Galactic bar, Galactic spiral arms, Galactic warp, Galactic tidal forces, Galactic potential, Galactic mass distribution, Galactic satellites, Galactic dark matter",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Analysis of the Velocity Field of F and G Dwarfs in the Solar Neighborhood as a Function of Age . Abstract : We have analyzed the kinematics of nearby solar - class stars ( F , G dwarfs ) with periods between 1 Myr and 10 Gyr using Hipparcos astrometry information .We see that there is no major variation in their velocity dispersion characteristics at different ages . The observed flatness of the profile suggests that these stars are on nearly circular orbits around the Sun .This result confirms our previous finding based on the evaluation of open complexes . Keywords : Kinematics , Open cluster , Nearby star , Stellar age , Solar region , Velocity field , Galactic rotation curve , Galaxy evolution , Galactic disk , Galactic structure , Galactic structure , Galactic halo , Galactic center , Galactic bulge , Galactic bar , Galactic spiral arms , Galactic warp , Galactic tidal forces , Galactic potential , Galactic mass distribution , Galactic satellites , Galactic dark matter",
        "rewrite_text": "**Title:** Analysis of the Velocity Field of F and G Dwarfs in the Solar Neighborhood as a Function of Age\n\n**Abstract:** In this study, we investigate the kinematic properties of nearby solar-type stars, specifically F and G dwarfs, spanning an age range from 1 million years to 10 billion years, utilizing astrometric data from the Hipparcos mission. Our analysis reveals that the velocity dispersion characteristics of these stars remain relatively consistent across different age groups, indicating a lack of significant variation in their motion. The observed flatness in the velocity profile implies that these stars predominantly follow nearly circular orbits around the Sun, a finding that aligns with our earlier research conducted on open star clusters. This consistency in kinematics suggests that the dynamical evolution of these stars is influenced more by their local environment than by their individual ages. Furthermore, our results contribute to a deeper understanding of the velocity field within the solar neighborhood and its implications for galactic structure and evolution. The study enhances our comprehension of how stellar age affects kinematic properties and provides insights into the broader context of galactic dynamics, including the rotation curve of the galaxy and the distribution of mass within the galactic disk. Our findings are relevant for ongoing research into the formation and evolution of the galaxy, as they highlight the interplay between stellar dynamics and the larger galactic framework, including the roles of various galactic components such as the halo, bulge, and spiral arms. This work underscores the importance of kinematic studies in elucidating the complex relationships within our galaxy and the influence of dark matter on stellar motion. \n\n**Keywords:** Kinematics, Open cluster, Nearby star, Stellar age, Solar region, Velocity field, Galactic rotation curve, Galaxy evolution, Galactic disk, Galactic structure, Galactic halo, Galactic center, Galactic bulge, Galactic bar, Galactic spiral arms, Galactic warp, Galactic tidal forces, Galactic potential, Galactic mass distribution, Galactic satellites, Galactic dark matter.",
        "ori-fast-z-score": -1.0327955589886444,
        "water-fast-z-score": 2.286002286003429,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  DWEB: A Data Warehouse Engineering Benchmark .\nAbstract:\nThe DWEB benchmark is an open-source data warehouse engineering benchmark that can be used to evaluate the performance and scalability of different data warehouse systems, including relational databases (e.g., Oracle), columnar stores (e.g., MonetDB) and NoSQL databases (e.g,. Cassandra). The benchmark consists of three main components: a query generator, a database server emulator, and a client application. In this work we present the design and implementation details for each component as well as our experiences in using it on several platforms. We also provide some insights into how the benchmark was developed and discuss its limitations. Finally, we compare the results obtained by running the benchmark against two state-of-the-art commercial products. This article is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications (DASFAA 2015).\nIntroduction\n\nData warehouses are large repositories storing historical information about business processes or other types of activities. They have been widely adopted over the last decade due to their ability to support decision making at various levels within organizations  1  . However, with the increasing size of data warehouses, there has been growing interest in developing new techniques to improve their efficiency  2  .\nIn order to assess these new techniques, researchers need benchmarks capable of evaluating the performance and scalability characteristics of different data warehouse systems  3  , such as relational databases  4  , columnar stores  5  , and NoSQL databases  6  . Unfortunately, most existing benchmarks focus only on one type of system  7, 8  , which makes them unsuitable for comparing multiple technologies simultaneously  9  . To address this problem, we propose the DWEB benchmark  10  , which supports both traditional SQL queries and more advanced analytical operations  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : DWEB : A Data Warehouse Engineering Benchmark . Abstract : The DWEB benchmark is an open - source information warehouse engineering benchmark that can be used to analyze the performance and scalability of different data warehouse applications , notably relational databases ( e . g . , Oracle ) , columnar stores ( e . g . , MonetDB ) and NoSQL databases ( e . g , .Cassandra ) . The benchmark consists of three primary components : a query generator , a document server emulator , and a client application .In this project we present the development and implementation information for each product as well as our perspectives in utilizing it on numerous platforms . We additionally offer some insights into how the benchmark was developed and consider its limitations .Finally , we compare the results derived by running the benchmark against two state - of - the - art commercial products . This page is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications ( DASFAA 2015 ) .Introduction Data warehouses are big repositories storing historical data about corporate processes or other types of activities . They have been widely adopted over the last decade due to their potential to support decision making at several levels within organizations 1 .However , with the increasing size of data warehouses , there has been growing interest in implementing new methodology to improve their productivity 2 . In order to examine these new strategies , researchers require benchmarks capable of evaluating the performance and scalability characteristics of different data warehouse technologies 3 , such as relational databases 4 , columnar stores 5 , and NoSQL databases 6 .Unfortunately , most existing benchmarks focus only on one sort of system 7 , 8 , which makes them unsuitable for comparing multiple technologies simultaneously 9 . To address this situation , we propose the DWEB benchmark 10 , which supports both traditional SQL queries and more advanced quantitative functions 11 .",
        "rewrite_text": "**Title: DWEB: A Data Warehouse Engineering Benchmark**\n\n**Abstract:** The DWEB benchmark is an innovative, open-source tool designed to evaluate the performance and scalability of various data warehouse applications, including relational databases (e.g., Oracle), columnar stores (e.g., MonetDB), and NoSQL databases (e.g., Cassandra). This benchmark comprises three essential components: a query generator, a document server emulator, and a client application. In this paper, we detail the development and implementation processes for each component, sharing our experiences and insights gained from deploying the benchmark across multiple platforms. We also discuss the methodology behind the benchmark's creation, highlighting its strengths and acknowledging its limitations.\n\nAs data warehouses serve as extensive repositories for historical data related to corporate processes and various activities, their adoption has surged over the past decade, primarily due to their ability to enhance decision-making across different organizational levels. However, the exponential growth in the size of data warehouses has sparked a need for new methodologies aimed at boosting their efficiency and productivity. To explore these methodologies effectively, researchers require robust benchmarks that can assess the performance and scalability of diverse data warehouse technologies, including relational databases, columnar stores, and NoSQL systems.\n\nUnfortunately, many existing benchmarks are tailored to specific types of systems, rendering them inadequate for comprehensive comparisons across multiple technologies. The DWEB benchmark addresses this gap by accommodating both traditional SQL queries and advanced quantitative functions, thus enabling a more holistic evaluation of various data warehouse solutions. In our study, we present a comparative analysis of the benchmark results against two leading commercial products, providing valuable insights into its effectiveness. This work is part of the Proceedings of the 20th International Conference on Database Systems for Advanced Applications (DASFAA 2015).",
        "ori-fast-z-score": -0.17541160386140586,
        "water-fast-z-score": 6.552780424957784,
        "rewrite-fast-z-score": 0.7579367289598671
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Marcus-Lushnikov processes, Smoluchowski s and Flory s models .\nAbstract:\nThe Marcus-Lushnikov process is the continuous-time analogue of the discrete-time Lévy walk model introduced by Montroll-Weiss in 1965 to describe diffusion-limited aggregation (DLA) on fractal surfaces.  The DLA growth mechanism has been observed experimentally for many years but only recently have there been attempts at modelling it mathematically using stochastic processes such as the Marcus-Lushnikov process.   In this article we consider two related problems concerning the Marcus-Lushnikov model:  Firstly, we prove that if the jump distribution of the underlying Lévy process satisfies certain integrability conditions then the corresponding Marcus-Lushnikov process converges weakly to Brownian motion with drift; secondly, we show how the Marcus-Lushnikov model can be used to approximate the solution of Smoluchowski s coagulation-fragmentation equation which describes the evolution of particle size distributions in chemical reactions involving clusters of particles. We also discuss some connections between the Marcus-Lushnikov and Flory s models of polymerisation.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Marcus - Lushnikov processes , Smoluchowski s and Flory s theories . Abstract : The Marcus - Lushnikov cycle is the continuous - time analogue of the discrete - time Lévy walk system proposed by Montroll - Weiss in 1965 to explain absorption - limited aggregation ( DLA ) on fractal surfaces .The DLA growth mechanism has been observed experimentally for numerous years but only lately have there been attempts at describing it mathematically utilizing stochastic processes such as the Marcus - Lushnikov mechanism . In this page we consider two similar problems concerning the Marcus - Lushnikov model : Firstly , we prove that if the jump density of the underlying Lévy cycle satisfies certain integrability constraints then the analogous Marcus - Lushnikov mechanism converges strongly to Brownian movement with drift ; secondly , we prove how the Marcus - Lushnikov model can be used to approximate the solve of Smoluchowski s coagulation - fragmentation equation which explains the evolution of particle size distributions in chemical processes involving clusters of molecules .We also discuss some relationships between the Marcus - Lushnikov and Flory s theories of polymerisation .",
        "rewrite_text": "**Title:** Marcus-Lushnikov Processes, Smoluchowski's and Flory's Theories\n\n**Abstract:** The Marcus-Lushnikov cycle serves as the continuous-time counterpart to the discrete-time Lévy walk framework introduced by Montroll and Weiss in 1965, aimed at elucidating absorption-limited aggregation (DLA) on fractal surfaces. While the DLA growth mechanism has been experimentally observed for many years, recent efforts have focused on providing a mathematical description through stochastic processes, particularly the Marcus-Lushnikov mechanism. In this article, we explore two closely related issues within the context of the Marcus-Lushnikov model. First, we demonstrate that under specific integrability conditions on the jump density of the underlying Lévy cycle, the corresponding Marcus-Lushnikov process exhibits strong convergence to a Brownian motion with drift. This finding highlights the connection between Lévy processes and classical Brownian motion in the context of aggregation phenomena. Secondly, we investigate how the Marcus-Lushnikov model can be employed to approximate solutions to Smoluchowski's coagulation-fragmentation equation, which describes the dynamics of particle size distributions in chemical processes involving molecular clusters. This approximation provides valuable insights into the behavior of complex systems where particle interactions play a crucial role. Additionally, we examine the interrelations between the Marcus-Lushnikov framework and Flory's theories of polymerization, shedding light on the underlying principles that govern the formation and growth of polymer chains. Through this comprehensive analysis, we aim to bridge the gap between stochastic modeling and classical theories in the study of aggregation and polymerization processes, offering a deeper understanding of the mechanisms at play in these intricate systems.",
        "ori-fast-z-score": -0.5852057359806528,
        "water-fast-z-score": 5.812381937190964,
        "rewrite-fast-z-score": 2.3312620206007844
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Analysis of the real estate market in Las Vegas: Bubble, seasonal patterns, and prediction of the CSW indexes .\nAbstract:\nThe purpose of this study is to analyze the real estate market in the city of Las Vegas (LV) by using the Composite Shiller Weiss Indexes (CSWI). The data used for analysis are monthly prices of residential properties sold between January 2005 and December 2014. In addition, we use the autoregressive integrated moving average model with exogenous variables (ARIMAX), which allows us to predict future values of the indexes based on past information. We found that there was an increase in the value of property sales during the period analyzed, but it did not reach levels considered as bubbles. However, the results show that the LV real estate market has experienced periods of overvaluation since 2007. Finally, our findings suggest that the ARIMAX model can be useful when predicting the evolution of the CSWI indexes. Keywords: Real Estate Market; Prediction Modeling; Autoregressive Integrated Moving Average",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Analysis of the real property market in Las Vegas : Bubble , seasonal patterns , and measurement of the CSW indexes . Abstract : The purpose of this study is to analyze the real property market in the cities of Las Vegas ( LV ) by using the Composite Shiller Weiss Indexes ( CSWI ) .The data used for study are monthly prices of housing houses sold between January 2005 and December 2014 . In addition , we using the autoregressive integrated moved average model with exogenous parameters ( ARIMAX ) , which allows us to predict upcoming values of the indexes based on past data .We showed that there was an increase in the value of property purchases during the period analyzed , but it did not reach levels regarded as bubbles . However , the results show that the LV real property market has undergone cycles of overvaluation since 2007 .Finally , our findings show that the ARIMAX theory can be valuable when predicting the evolution of the CSWI indexes . Keywords : Real Estate Market ; Prediction Modeling ; Autoregressive Integrated Moving Average",
        "rewrite_text": "**Title:** Analysis of the Real Property Market in Las Vegas: Bubble Dynamics, Seasonal Trends, and Evaluation of CSW Indexes\n\n**Abstract:** This study aims to conduct a comprehensive analysis of the real estate market in Las Vegas (LV) by employing the Composite Shiller Weiss Indexes (CSWI). The research utilizes monthly housing price data for properties sold from January 2005 to December 2014. To facilitate our analysis, we implement the Autoregressive Integrated Moving Average model with exogenous variables (ARIMAX), which enables us to forecast future index values based on historical data patterns. Our findings indicate a notable increase in property purchase values throughout the study period; however, these values did not escalate to levels typically associated with market bubbles. Despite this, the analysis reveals that the LV real estate market has experienced cycles of overvaluation since 2007, suggesting a degree of volatility and fluctuation in property values. Additionally, our results demonstrate the efficacy of the ARIMAX model in predicting the trajectory of the CSWI indexes, highlighting its potential as a valuable tool for real estate market analysis. This research contributes to the understanding of market dynamics in Las Vegas, providing insights into seasonal patterns and the implications of overvaluation cycles. The findings underscore the importance of robust predictive modeling in navigating the complexities of the real estate market. \n\n**Keywords:** Real Estate Market; Predictive Modeling; Autoregressive Integrated Moving Average",
        "ori-fast-z-score": 1.3242443839434612,
        "water-fast-z-score": 6.289942788427422,
        "rewrite-fast-z-score": 0.10259783520851541
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Production of TeV gamma-radiation in the vicinity of the supermassive black hole in the giant radiogalaxy M87 .\nAbstract:\nThe authors report on observations made with the HESS telescope array, which detected emission at energies above 1TeV (1 teraelectronvolt) coming from an area within 0.2 degrees of the center of the galaxy M87.  The data are consistent with theoretical predictions that such emissions should be produced by particles accelerated near the event horizon of a supermassive black hole located there.   This is the first time this phenomenon has been observed outside our own Galaxy and it opens up new opportunities for studying particle acceleration processes around black holes. Black holes are among the most exotic objects known to science. They have no surface or edge but instead exist as singularities where space-time ends. In addition they exert enormous gravitational forces so that even light cannot escape their grasp. However, despite these extreme conditions, some scientists believe that matter can still be accelerated close to the speed of light inside the so-called  event horizons  surrounding black holes. Such high energy phenomena could produce extremely energetic photons called  TeV gammas  - short for Tera-Electron-Volt photons. These would then be detectable using ground-based telescopes like those used by the High Energy Stereoscopic System (HESS). On April 10, 2014, astronomers working with the HESS observatory announced the detection of TeV-gamma rays originating from the central region of the distant galaxy Messier 87 (M87), about 50 million light years away  1  . This was the first time that such radiation had ever been seen outside our own Milky Way  2  , opening up exciting possibilities for studying particle accelerators associated with black holes  3  .\nIn order to understand how this discovery came about we need to know more about what happens when matter falls into a black hole. As shown in Figure 1 below, if you were standing next to one you d see nothing special happening until your distance from its centre became smaller than its Schwarzschild radius  4  . At this point gravity becomes so strong that all forms of matter become trapped inside the black hole s event horizon  5  . Inside the event horizon, however,...",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Production of TeV gamma - radiation in the vicinity of the supermassive black hole in the giant radiogalaxy M87 . Abstract : The authors report on observations made with the HESS telescope array , which detected radiation at energies above 1TeV ( 1 teraelectronvolt ) coming from an area within 0 . 2 degrees of the center of the galaxy M87 .The data are compatible with theoretical expectations that such emissions should be formed by particles driven near the event horizon of a supermassive black hole located there . This is the first time this phenomenon has been observed outside our own Galaxy and it opens up new opportunities for studying particle acceleration processes around black holes .Black holes are among the most exotic objects known to science . They have no surface or edge but instead appear as singularities where space - time finishes .In addition they exert enormous gravitational pressures so that even light cannot flee their grasp . However , despite these extreme circumstances , some scientists view that matter can always be advanced close to the speed of light inside the so - called event horizons surrounding black holes .Such high energy phenomena could generate incredibly energetic photons called TeV gammas - short for Tera - Electron - Volt photons . These would then be detectable using ground - based telescopes like those utilized by the High Energy Stereoscopic System ( HESS ) .On April 10 , 2014 , astronomers studying with the HESS telescope confirmed the discovery of TeV - gamma radiation coming from the central region of the distant galaxy Messier 87 ( M87 ) , about 50 million light years away 1 . This was the first time that such rays had ever been seen outside our own Milky Way 2 , opening up interesting possibilities for studying electron accelerators associated with black holes 3 .In order to comprehend how this discovery went about we require to see more about what comes when matter drops into a black hole . As seen in Figure 1 below , if you were standing close to one you d see nothing extraordinary occurring until your distance from its centre becoming smaller than its Schwarzschild diameter 4 .At this time gravity becomes so powerful that all forms of matter grow trapped inside the dark hole s event horizon 5 . Inside the event horizon , however , . . .",
        "rewrite_text": "**Title:** Production of TeV Gamma-Radiation in the Vicinity of the Supermassive Black Hole in the Giant Radiogalaxy M87\n\n**Abstract:** In this study, we present groundbreaking observations made using the High Energy Stereoscopic System (HESS) telescope array, which successfully detected gamma-ray radiation with energies exceeding 1 TeV emanating from a region within 0.2 degrees of the center of the giant radiogalaxy M87. These findings align with theoretical predictions suggesting that such high-energy emissions are generated by particles accelerated in the extreme gravitational field near the event horizon of the supermassive black hole at the galaxy's core. This marks the first observation of TeV gamma radiation outside of our Milky Way galaxy, significantly enhancing our understanding of particle acceleration mechanisms in the vicinity of black holes.\n\nBlack holes are among the most enigmatic entities in astrophysics, characterized by their lack of a physical surface and their nature as singularities where the fabric of space-time ceases to exist. Their immense gravitational forces are so powerful that they prevent even light from escaping. Nevertheless, theoretical models propose that matter can be accelerated to relativistic speeds in the regions surrounding black holes, particularly within their event horizons. This process can produce highly energetic photons known as TeV gamma rays, which are detectable by ground-based observatories like HESS.\n\nOn April 10, 2014, astronomers utilizing the HESS telescope confirmed the presence of TeV gamma radiation originating from the central region of M87, located approximately 50 million light-years from Earth. This discovery not only represents a significant milestone in astrophysical research but also opens new avenues for investigating the mechanisms of electron acceleration associated with black holes. To fully appreciate the implications of this discovery, it is essential to explore the dynamics of matter as it approaches a black hole. As illustrated in Figure 1, an observer near a black hole would initially perceive no unusual activity until crossing the Schwarzschild radius, where gravitational forces become so intense that all matter is inevitably drawn into the event horizon. Within this region, the complexities of particle behavior and radiation generation present a rich field for further exploration and understanding.",
        "ori-fast-z-score": 0.38461538461538464,
        "water-fast-z-score": 7.056077897395808,
        "rewrite-fast-z-score": 1.9462473604038073
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Photonic molecules made of matched and mismatched microcavities: new functionalities of microlasers and optoelectronic components .\nAbstract:\nWe propose to use photonic molecules, which are composed of two or more coupled microcavities with different resonant wavelengths, as building blocks for novel types of lasers and optoelectronics devices. We show that the coupling between these cavities can lead to several interesting phenomena such as: (i) formation of hybridized modes, (ii) appearance of sharp peaks in emission spectrum at frequencies corresponding to avoided crossings of cavity eigenmodes, (iii) enhancement of spontaneous emission rate due to Purcell effect, and (iv) strong modification of optical gain properties by means of mode competition effects. These features open up possibilities for designing new types of laser sources based on photonic molecules, including single-mode lasers operating at room temperature without any external feedback elements. \n \n The proposed approach is illustrated using examples of photonic molecules consisting of pairs of semiconductor microdisks with slightly different diameters. It is shown that the considered structures allow one to obtain high quality factor whispering gallery modes with Q-factors exceeding 10^6.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Photonic compounds made of matched and mismatched microcavities : new functionalities of microlasers and optoelectronic parts . Abstract : We suggest to use photonic atoms , which are composed of two or more coupled microcavities with varying resonant wavelengths , as building blocks for innovative kinds of lasers and optoelectronics equipment .We suggest that the interaction between these cavities can lead to several interesting phenomena such as : ( i ) development of hybridized modes , ( ii ) presence of sharp peaks in emission spectrum at speeds related to avoided crossings of cavity eigenmodes , ( iii ) enhancement of induced emission speed due to Purcell phenomenon , and ( iv ) weak revision of optical loss properties by means of mode rivalry effects . These features offer up possibilities for constructing new types of laser sources focused on photonic compounds , particularly single - mode lasers active at room temperature without any external feedback components .The proposed approach is depicted using examples of photonic compounds consisting of pairs of semiconductor microdisks with slightly different diameters . It is demonstrated that the considered molecules permit one to obtain high quality factor whispering gallery modes with Q - parameters exceeding 10 ^ 6 .",
        "rewrite_text": "Title: Photonic Compounds Comprising Matched and Mismatched Microcavities: Novel Functionalities in Microlasers and Optoelectronic Devices\n\nAbstract: In this article, we propose the utilization of photonic atoms, which are formed by coupling two or more microcavities with distinct resonant wavelengths, as foundational elements for the development of advanced lasers and optoelectronic devices. The interactions between these microcavities can give rise to a range of intriguing phenomena, including: (i) the emergence of hybridized modes, (ii) the appearance of sharp peaks in the emission spectrum associated with avoided crossings of cavity eigenmodes, (iii) an increase in the rate of induced emission driven by the Purcell effect, and (iv) a subtle modification of optical loss characteristics through mode competition effects. These phenomena open up new avenues for the design of innovative laser sources based on photonic compounds, particularly enabling the creation of single-mode lasers that operate at room temperature without the need for external feedback mechanisms. We illustrate our proposed methodology with examples of photonic compounds constructed from pairs of semiconductor microdisks that have slightly different diameters. Our findings demonstrate that these configurations allow for the achievement of high-quality factor whispering gallery modes, with Q-factors exceeding 10^6. This research highlights the potential of photonic compounds to revolutionize the field of laser technology and optoelectronics, paving the way for the next generation of efficient and versatile light sources.",
        "ori-fast-z-score": 0.20203050891044214,
        "water-fast-z-score": 6.733753362236721,
        "rewrite-fast-z-score": 0.4
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  High-precision astrometry on the VLT/FORS1 at time scales of few days .\nAbstract:\nWe present results obtained with FORS1 (FOcal Reducer and low dispersion Spectrograph) mounted on the Very Large Telescope in Chile, for two bright stars observed over several nights during the period September-October 2002. The main goal is to test the performance of this instrument under conditions similar to those expected when it will be used as part of Gaia space mission. We have measured positions accurate to better than 0.3 mas using an iterative procedure based on the method developed by Gieren et al. (1998) . This accuracy has been reached thanks to the use of reference images taken every night before or after each science exposure. These observations are also useful to calibrate the zero point of the proper motions derived from Hipparcos data. They show that the mean parallax of these two stars agrees within 1 sigma with their Hipparcos values.  Keywords: Astrometry, Gaia",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : High - precision astrometry on the VLT / FORS1 at period scales of few days . Abstract : We report findings obtained with FORS1 ( FOcal Reducer and low dispersion Spectrograph ) installed on the Very Large Telescope in Chile , for two bright stars observed over numerous weeks during the period September - October 2002 .The main goal is to test the performance of this instrument under environments similar to those expected when it will be used as member of Gaia spacecraft mission . We have recorded places accurate to good than 0 . 3 mas using an iterative technique based on the method developed by Gieren et al .( 1998 ) . This authenticity has been achieved thanks to the using of reference images took every night before or after each science exposure .These measurements are also useful to calibrate the zero position of the proper motions obtained from Hipparcos results . They show that the mean parallax of these two stars agrees within 1 sigma with their Hipparcos values .Keywords: Astrometry, Gaia",
        "rewrite_text": "Title: High-Precision Astrometry Using VLT/FORS1 Over Short Time Scales\n\nAbstract: In this study, we present the results of high-precision astrometric measurements conducted with the FOcal Reducer and low dispersion Spectrograph (FORS1) on the Very Large Telescope (VLT) in Chile. Our observations focused on two bright stars over an extended period from September to October 2002. The primary objective of this research was to evaluate the performance of the FORS1 instrument in conditions that closely resemble those anticipated for its future role in the Gaia spacecraft mission. We achieved positional accuracy better than 0.3 milliarcseconds (mas) through an iterative technique inspired by the methodology established by Gieren et al. (1998). This level of precision was made possible by utilizing reference images taken nightly, either before or after each scientific exposure, which served to enhance the reliability of our measurements. Furthermore, these astrometric measurements play a crucial role in calibrating the zero point for the proper motions derived from the Hipparcos satellite data. Our findings indicate that the mean parallax values for the two observed stars are consistent with the Hipparcos measurements, falling within one sigma of the expected values. This research not only demonstrates the capabilities of FORS1 for high-precision astrometry but also contributes valuable data for future astrometric missions, particularly in the context of the Gaia project. \n\nKeywords: Astrometry, Gaia, VLT, FORS1, Parallax, Hipparcos.",
        "ori-fast-z-score": -0.8427009716003844,
        "water-fast-z-score": 4.935819976516537,
        "rewrite-fast-z-score": 1.5096588248481377
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Impedance spectroscopy of epitaxial multiferroic thin films .\nAbstract:\nWe report on the impedance spectroscopic study of epitaxially grown BiFeO3 (BFO) and BaTiO3 (BT) thin films with different thicknesses, deposited by pulsed laser deposition technique onto single crystal SrTiO3 substrates. The dielectric properties are investigated in the temperature range between 300 K to 450 K at various frequencies ranging from 1 kHz to 10 MHz. It is found that both BFO and BT show ferroelectric behavior as evidenced by their frequency dependent hysteresis loops. In addition, we observe an anomaly near 420 K for all samples which can be attributed to the phase transition from rhombohedral to tetragonal structure in BFO film. \n \n We also find that the dielectric constant decreases with increasing measurement frequency while it increases with decreasing sample thickness. This observation suggests that there exists space charge polarization in these films. Moreover, the dielectric loss shows strong dependence on the measurement frequency and sample thickness.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Impedance spectroscopy of epitaxial multiferroic narrow bands . Abstract : We report on the impedance spectroscopic study of epitaxially grown BiFeO3 ( BFO ) and BaTiO3 ( BT ) thin films with various thicknesses , deposited by pulsed laser deposition methodology onto single crystal SrTiO3 substrates .The dielectric characteristics are examined in the temperature range between 300 K to 450 K at several frequencies ranging from 1 kHz to 10 MHz . It is found that both BFO and BT exhibit ferroelectric activity as demonstrated by their rate dependent hysteresis loops .In addition , we study an anomaly near 420 K for all specimens which can be due to the phase shift from rhombohedral to tetragonal shape in BFO movie . We additionally find that the dielectric constant decreases with expanding test frequency while it changes with increased specimen length .This measurement indicates that there exists space charge polarization in these films . Moreover , the dielectric loss displays strong dependence on the measurement frequency and sample width .",
        "rewrite_text": "In this study, we present a comprehensive impedance spectroscopic analysis of epitaxially grown thin films of BiFeO3 (BFO) and BaTiO3 (BT), which were deposited onto single crystal SrTiO3 substrates using the pulsed laser deposition technique. The investigation focuses on the dielectric properties of these materials across a temperature range of 300 K to 450 K and at various frequencies from 1 kHz to 10 MHz. Our findings reveal that both BFO and BT demonstrate significant ferroelectric behavior, as evidenced by their frequency-dependent hysteresis loops. Notably, we observe a distinct anomaly around 420 K in all samples, which is likely attributed to a phase transition from a rhombohedral to a tetragonal structure in the BFO films. Furthermore, our measurements indicate that the dielectric constant exhibits a decreasing trend with increasing frequency, while it also varies with the thickness of the samples. This behavior suggests the presence of space charge polarization within the films. Additionally, we note that the dielectric loss is highly sensitive to both the measurement frequency and the width of the samples, highlighting the complex interplay between these factors in determining the dielectric response of the materials. Overall, this study provides valuable insights into the dielectric properties of multiferroic thin films, contributing to the understanding of their potential applications in electronic and spintronic devices.",
        "ori-fast-z-score": -2.8284271247461903,
        "water-fast-z-score": 3.771236166328254,
        "rewrite-fast-z-score": -0.31799936400190804
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Measuring the Baryon Acoustic Oscillation scale using the SDSS and 2dFGRS .\nAbstract:\nWe measure the baryonic acoustic oscillation (BAO) scale in the distribution of galaxies by cross-correlating the Sloan Digital Sky Survey Data Release 5 with the Two Degree Field Galaxy Redshift Survey Data Release 3, both at z=0.35-0.55. We use two different estimators for the BAO peak position, one based on the correlation function and another on the power spectrum. The results are consistent within errors between these methods as well as with previous measurements made over smaller ranges of redshift or volume. Our measurement is also consistent with theoretical predictions based on WMAP1 cosmological parameters. This work demonstrates that it will be possible to make precise distance measurements out to redshifts of order unity using future large galaxy surveys such as the Dark Energy Spectroscopic Instrument. These distances can then be used to constrain dark energy models through their effect on the expansion history of the universe. \n \n Keywords: Baryons",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Measuring the Baryon Acoustic Oscillation scale utilizing the SDSS and 2dFGRS . Abstract : We estimate the baryonic sound oscillation ( BAO ) scale in the distribution of galaxies by cross - correlating the Sloan Digital Sky Survey Data Release 5 with the Two Degree Field Galaxy Redshift Survey Data Release 3 , both at z = 0 . 35 - 0 . 55 .We use two different estimators for the BAO peak point , one based on the correlation function and another on the power spectrum . The results are compatible within errors between these models as well as with previous measurements made over smaller ranges of redshift or volume .Our measurement is also consistent with theoretical estimates based on WMAP1 cosmological factors . This research shows that it will be possible to make accurate distance measurements out to redshifts of order unity utilizing upcoming huge galaxy surveys such as the Dark Energy Spectroscopic Instrument .These distances can then be used to constrain dark energy theories through their effect on the expansion history of the universe . Keywords : Baryons",
        "rewrite_text": "Title: Measuring the Baryon Acoustic Oscillation Scale Utilizing the SDSS and 2dFGRS\n\nAbstract: In this study, we investigate the baryonic acoustic oscillation (BAO) scale within the galaxy distribution by performing a cross-correlation analysis between the Sloan Digital Sky Survey Data Release 5 (SDSS DR5) and the Two Degree Field Galaxy Redshift Survey Data Release 3 (2dFGRS DR3), focusing on the redshift range of z = 0.35 to 0.55. To accurately estimate the BAO peak, we employ two distinct methodologies: one that utilizes the correlation function and another that relies on the power spectrum. Our findings indicate that the results from both approaches are in agreement within the uncertainties, and they align well with previous measurements obtained from narrower redshift intervals or smaller survey volumes. Furthermore, our measurements are consistent with theoretical predictions derived from the WMAP1 cosmological parameters. This research highlights the potential for precise distance measurements at redshifts approaching unity, facilitated by forthcoming large-scale galaxy surveys such as the Dark Energy Spectroscopic Instrument (DESI). The distances obtained from these measurements will be instrumental in constraining dark energy models by examining their influence on the universe's expansion history. This work underscores the importance of BAO as a cosmic ruler and its role in advancing our understanding of the universe's structure and evolution. \n\nKeywords: Baryons, Baryon Acoustic Oscillation, Galaxy Surveys, Dark Energy, Cosmology.",
        "ori-fast-z-score": -0.12403473458920847,
        "water-fast-z-score": 3.938927711338647,
        "rewrite-fast-z-score": 0.6625891564490792
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A remark on the number of steady states in a multiple futile cycle .\nAbstract:\nWe consider a model for an enzymatic reaction network with multiple futile cycles, where each enzyme is assumed to be present at constant concentration and all reactions are reversible. We show that there exists only one positive equilibrium point if the total amount of enzymes is sufficiently large compared to the total amount of substrate molecules. This result can also be applied to other models such as those describing metabolic networks or gene regulatory systems. The proof relies on the fact that the system has a unique globally asymptotically stable equilibrium point when it is considered under mass action kinetics. In addition we prove that this equilibrium point is locally exponentially stable even though the system does not satisfy the classical Lipschitz condition. Finally, numerical simulations illustrate our results. Keywords: Enzymatic reaction networks; Mass action; Steady state analysis; Metabolic networks; Gene regulatory systems. 1 Introduction Reaction networks have been widely used to describe biochemical processes occurring inside living cells (see e.g.,  1  ,  4  ). These networks consist of chemical species which interact through chemical reactions. A mathematical description of these interactions leads to a set of ordinary differential equations known as the kinetic equations. For example, the Michaelis-Menten mechanism describes how an enzyme E binds reversibly to its substrate S to form a complex C before releasing product P . It consists of three elementary reactions given by \nwhere k + i and k − i denote respectively the forward and backward rate constants associated with the ith reaction. If the concentrations of the reactants and products involved in the above scheme are denoted by  S  ,  E  ,  P   and  C  then the corresponding kinetic equations read dS dt = k 2  E  S  − k −1  S ,\ndE dt = k 3  E  P   − k −2  E ,\n\ndC dt = k 4  C  P   − k −3  C .\n\nThe parameters k i represent the rates of the different reactions. Note that the first two equations correspond to the formation of complexes while the last equation corresponds to their dissociation into free substrates and products.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A statement on the quantity of stable states in a multiple futile period . Abstract : We consider a description for an enzymatic process network with many futile periods , where each enzyme is expected to be found at fixed concentration and all processes are reversible .We see that there exists only one positive equilibrium point if the total quantity of enzymes is sufficiently huge compared to the total quantity of substrate molecules . This result can also be applied to other models such as those describing metabolic networks or protein regulatory structures .The confirmation relies on the fact that the system has a unique globally asymptotically stable equilibrium point when it is viewed under mass action kinetics . In addition we prove that this equilibrium point is locally exponentially steady even though the system does not satisfy the classical Lipschitz condition .Finally , numerical simulations highlight our findings . Keywords : Enzymatic reaction systems ; Mass response ; Steady state analysis ; Metabolic systems ; Gene regulatory structures .1 Introduction Reaction networks have been widely using to define biochemical mechanisms occurring inside live cells ( see e . g . , 1 , 4 ) . These connections comprise of biological species which interact through chemical processes .A mathematical description of these interactions leads to a setting of ordinary differential equations known as the kinetic equations . For instance , the Michaelis - Menten process represents how an enzyme E connects reversibly to its substrate S to form a complex C before producing product P .It consists of three elementary reactions given by where k + i and k − i describe respectively the forward and backward rate constants associated with the ith reaction . If the levels of the reactants and products participating in the above scheme are denoted by S , E , P and C then the equivalent kinetic equations read dS dt = k 2 E S − k −1 S , dE dt = k 3 E P − k −2 E , dC dt = k 4 C P − k −3 C .The parameters k i describe the rates of the different processes . Note that the first two variables relate to the formation of complexes while the last equation relates to their dissociation into free substrates and products .",
        "rewrite_text": "**Title:** A Statement on the Quantity of Stable States in a Multiple Futile Period\n\n**Abstract:** This study presents an analysis of an enzymatic process network characterized by multiple futile periods, where each enzyme is maintained at a constant concentration and all reactions are reversible. Our findings indicate that when the total concentration of enzymes significantly exceeds that of the substrate molecules, the system converges to a single positive equilibrium point. This result is not only pertinent to the specific enzymatic framework we examined but also extends to other biological models, including metabolic networks and protein regulatory mechanisms. The uniqueness of the globally asymptotically stable equilibrium point is established through the lens of mass action kinetics, which provides a robust theoretical foundation for our conclusions. Furthermore, we demonstrate that this equilibrium point exhibits local exponential stability, despite the system's failure to meet the traditional Lipschitz condition, which typically governs stability analysis in dynamical systems. To substantiate our theoretical claims, we conducted numerical simulations that effectively illustrate the behavior of the system and reinforce our analytical results. This research contributes to the broader understanding of enzymatic reaction systems, steady-state dynamics, and their implications for metabolic and gene regulatory networks. Our work underscores the importance of considering the relative concentrations of enzymes and substrates in predicting the stability and behavior of biochemical systems. \n\n**Keywords:** Enzymatic reaction systems; Mass action kinetics; Steady-state analysis; Metabolic networks; Gene regulatory mechanisms. \n\n**1 Introduction:** Reaction networks are fundamental to elucidating the biochemical processes that occur within living cells. These networks consist of various biological species that interact through a series of chemical reactions. A mathematical representation of these interactions leads to a set of ordinary differential equations known as kinetic equations. For example, the Michaelis-Menten mechanism describes the reversible interaction between an enzyme (E) and its substrate (S) to form a complex (C), which subsequently produces a product (P). This process is encapsulated in three elementary reactions, with rate constants denoted as k+i and k−i for the forward and reverse reactions, respectively. The dynamics of the reactants and products are captured by the corresponding kinetic equations, which detail the rates of formation and dissociation of the complexes involved.",
        "ori-fast-z-score": -2.3284515771189986,
        "water-fast-z-score": 6.230769230769231,
        "rewrite-fast-z-score": 1.0674899923282326
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A first-principles model of early evolution: Emergence of gene families, species and preferred protein folds .\nAbstract:\nWe present an evolutionary model that describes the emergence of genes, species and their interactions in terms of physical principles. The model is based on the concept of self-assembly as it occurs during the formation of biological macromolecules such as proteins or nucleic acids. We show how this process leads to the spontaneous appearance of functional units which we call  gene families . Gene families are defined by common sequence motifs and can be seen as building blocks for more complex organisms. In our approach, these building blocks evolve into new species through mutations and selection processes. Species interact with each other via chemical reactions mediated by enzymes. These interactions lead to the formation of metabolic networks whose structure reflects the underlying network topology of the interacting species. Finally, we demonstrate how the proposed model reproduces several important features observed in real-world systems including preferential attachment, scale-free degree distributions and small world properties. Our results suggest that the basic mechanisms driving the evolution of life may have been already established at its very beginning.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A first - principles model of early evolution : Emergence of gene families , genera and preferred genes folds . Abstract : We create an evolutionary model that describes the emergence of genes , species and their interactions in terms of physical principles .The model is based on the idea of self - assembly as it happened during the formation of biological macromolecules such as proteins or nucleic acids . We see how this process results to the spontaneous appearance of functional units which we call gene families .Gene groups are established by common sequence motifs and can be saw as building floors for more sophisticated organisms . In our approach , these building blocks develop into new taxa through mutations and selection pathways .Species interact with each other via molecular reactions mediated by enzymes . These interactions result to the formation of metabolic networks whose shape indicates the intrinsic network topology of the interacting species .Finally , we prove how the suggested model reproduces many important features found in real - time systems including preferential attachment , size - free degree distributions and tiny world properties . Our results propose that the fundamental pathways governing the evolution of life might have been still recognized at its very beginning .",
        "rewrite_text": "Title: A First-Principles Model of Early Evolution: Emergence of Gene Families, Genera, and Preferred Gene Folds\n\nAbstract: In this study, we present a novel evolutionary model that elucidates the emergence of genes, species, and their interactions through the lens of fundamental physical principles. Our framework is grounded in the concept of self-assembly, akin to the processes that led to the formation of biological macromolecules such as proteins and nucleic acids. Through this model, we observe the spontaneous generation of functional units, which we term gene families. These gene groups, characterized by shared sequence motifs, serve as foundational elements for the development of more complex organisms. \n\nOur methodology illustrates how these building blocks evolve into new taxa via mechanisms of mutation and natural selection. Furthermore, we explore the interactions between species, which occur through molecular reactions facilitated by enzymes. These interactions give rise to metabolic networks, the architecture of which reflects the intrinsic topology of the species involved. \n\nImportantly, we demonstrate that our model successfully replicates several key characteristics observed in real-world biological systems, including preferential attachment, scale-free degree distributions, and small-world properties. These findings suggest that the fundamental pathways that govern the evolution of life may have been established from its earliest stages. Our research contributes to a deeper understanding of the evolutionary processes that shape biodiversity and offers insights into the underlying principles that drive the complexity of life on Earth.",
        "ori-fast-z-score": 0.8392543274162825,
        "water-fast-z-score": 7.548711866766252,
        "rewrite-fast-z-score": 1.8935062328016077
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Rapid Diffusion of dipolar order enhances dynamic nuclear polarization .\nAbstract:\nWe report on the rapid diffusion of dipolar order in liquid crystals, which is responsible for an enhanced nuclear spin-lattice relaxation rate and thus for a higher degree of dynamic nuclear polarization (DNP). The DNP effect was studied by means of electron paramagnetic resonance spectroscopy at X-band frequencies using a home-built high-field spectrometer equipped with a commercial microwave bridge operating at 2.5 GHz. We found that the enhancement factor increases strongly when approaching the nematic-isotropic phase transition temperature TNI = 35 °C. This finding can be explained by assuming that the molecular mobility decreases rapidly as TNI is approached. In addition to this observation we find that the maximum achievable enhancement factor depends critically on the sample geometry. For samples having a thickness d < 1 mm it reaches values up to 100 times larger than those observed for thicker samples. These results are important for future applications of DNP in NMR experiments performed under extreme conditions such as low temperatures or strong magnetic fields.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Rapid Diffusion of dipolar order enhances dynamic nuclear polarization . Abstract : We report on the quick diffusion of dipolar order in liquid crystals , which is responsible for an increase nuclear spin - lattice relaxation speed and therefore for a higher degree of static nuclear polarization ( DNP ) .The DNP phenomenon was studied by means of electron paramagnetic resonance spectroscopy at X - band frequencies using a home - installed high - field spectrometer equipped with a commercial microwave bridge operating at 2 . 5 GHz . We showed that the enhancement component increases strongly when approaching the nematic - isotropic phase change temperature TNI = 35 °C .This finding can be described by assuming that the molecular mobility decreases quickly as TNI is neared . In addition to this observation we find that the maximum achievable enhancement factor relies critically on the sample geometry .For specimens having a length d < 1 mm it hits values up to 100 times bigger than those observed for thicker specimen . These data are important for future applications of DNP in NMR experiments conducted under extreme circumstances such as low temperatures or strong magnetic fields .",
        "rewrite_text": "Title: Rapid Diffusion of Dipolar Order Enhances Dynamic Nuclear Polarization\n\nAbstract: In this study, we investigate the rapid diffusion of dipolar order in liquid crystals and its significant impact on nuclear spin-lattice relaxation rates, leading to enhanced static nuclear polarization (DNP). Utilizing electron paramagnetic resonance (EPR) spectroscopy at X-band frequencies, we employed a high-field spectrometer, custom-built and integrated with a commercial microwave bridge operating at 2.5 GHz, to conduct our experiments. Our findings reveal a pronounced increase in the enhancement component as the system approaches the nematic-isotropic phase transition temperature (TNI = 35 °C). This behavior can be attributed to a rapid decrease in molecular mobility near TNI, which facilitates the diffusion of dipolar order. Furthermore, we observed that the maximum achievable enhancement factor is highly dependent on the geometry of the sample. Specifically, for samples with a length of less than 1 mm, we recorded enhancement factors that were up to 100 times greater than those measured in thicker samples. These results underscore the critical role of sample dimensions in optimizing DNP efficiency. Our findings have significant implications for the future application of DNP in nuclear magnetic resonance (NMR) experiments, particularly in extreme conditions such as low temperatures and strong magnetic fields, where enhanced polarization can lead to improved sensitivity and resolution in spectroscopic analyses. This research not only advances our understanding of dipolar order dynamics in liquid crystals but also opens new avenues for enhancing DNP techniques in various scientific and technological applications.",
        "ori-fast-z-score": -0.30779350562554625,
        "water-fast-z-score": 4.898979485566357,
        "rewrite-fast-z-score": 0.7364596943186588
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Realizable Hamiltonians for Universal Adiabatic Quantum Computers .\nAbstract:\nWe present an algorithm that determines whether or not there exists a quantum circuit with a given number of qubits and gates, such that the corresponding time-independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state.  We also show how to find all possible circuits if they exist. Our results are based on recent work showing that any time-independent Hamiltonian can be written as a sum of commuting projectors onto its eigenstates. This decomposition allows us to reduce the problem of finding a realization of a general time-independent Hamiltonian into several instances of the same problem but restricted to smaller Hilbert spaces. The reduction yields a polynomial-time algorithm when applied recursively. Finally we discuss some applications of our method including determining the minimum depth required for universal adiabatic quantum computers. In this article we consider the following problem: \nGiven a set of n qubits and m two-qubit gates, does there exist a quantum circuit consisting only of these gates whose associated time-independent Hamiltonian is realizable; i.e., it corresponds to a Hermitian operator acting on a finite-dimensional Hilbert space? If so, what is the smallest circuit size needed?\nThe answer to this question will depend on the specifics of the model used to describe the physical system under consideration. For example, in the case where each energy level may have more than one excited state (i.e., degenerate), then no circuit can realize the desired Hamiltonian unless it contains infinitely many gates. On the other hand, if each energy level has exactly one excited state (i..",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Realizable Hamiltonians for Universal Adiabatic Quantum Computers . Abstract : We create an algorithm that decide whether or not there exists a quantum circuit with a given number of qubits and gates , such that the associated time - independent Hamiltonian is realizable by a physical system in which each energy level has at most one excited state .We also work how to find all possible circuits if they exist . Our results are based on previous research showing that any time - independent Hamiltonian can be written as a sum of commuting projectors onto its eigenstates .This decomposition allows us to reduce the question of finding a realization of a general time - independent Hamiltonian into numerous instances of the same difficulty but restricted to smaller Hilbert spaces . The reduction gives a polynomial - time algorithm when applied recursively .Finally we explain some applications of our technique including calculating the limit depth needed for universal adiabatic quantum computers . In this article we investigate the following issue : Given a setting of n qubits and m two - qubit gates , does there exist a quantum circuit consisting only of these gates whose associated time - independent Hamiltonian is realizable ; i . e . , it corresponds to a Hermitian operator acting on a finite - dimensional Hilbert space ?If so , what is the smallest circuit length needed ? The answer to this question will depend on the specifics of the model used to explain the physical system under consideration .For instance , in the case where each energy level may have more than one excited state ( i . e . , degenerate ) , then no circuit can realize the desired Hamiltonian unless it contains infinitely many gates . On the other hand , if each energy level has precisely one excited state ( i . .",
        "rewrite_text": "In this article, we present a novel algorithm designed to determine the existence of a quantum circuit composed of a specified number of qubits and gates, such that the corresponding time-independent Hamiltonian can be physically realized in a system where each energy level accommodates at most one excited state. Our research builds upon prior findings that establish any time-independent Hamiltonian as a sum of commuting projectors corresponding to its eigenstates. This foundational decomposition enables us to transform the challenge of realizing a general time-independent Hamiltonian into multiple instances of a similar nature, albeit confined to smaller Hilbert spaces. By employing this reduction method recursively, we achieve a polynomial-time algorithm.\n\nWe delve into the implications of our technique, particularly its application in determining the minimum circuit depth required for universal adiabatic quantum computers. The central question we address is whether, given n qubits and m two-qubit gates, it is feasible to construct a quantum circuit that solely utilizes these gates and yields a realizable time-independent Hamiltonian, which corresponds to a Hermitian operator defined on a finite-dimensional Hilbert space. The answer to this inquiry is contingent upon the specific model that characterizes the physical system in question. For example, in scenarios where energy levels can exhibit degeneracy—allowing for multiple excited states—no finite circuit can realize the desired Hamiltonian unless it incorporates an infinite number of gates. Conversely, in systems where each energy level is restricted to a single excited state, our findings provide a pathway to construct realizable Hamiltonians with finite circuits. This work not only advances our understanding of quantum circuit realizability but also contributes to the broader field of quantum computing by clarifying the constraints and capabilities of adiabatic quantum computation.",
        "ori-fast-z-score": 1.9445436482630056,
        "water-fast-z-score": 6.075111253646805,
        "rewrite-fast-z-score": -0.0842151921066519
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Viscous Torque and Dissipation in the Inner Region of a Thin Accretion Disk: Implications for Measuring Black Hole Spin .\nAbstract:\nWe present new results on viscous torque and dissipation in thin accretion disks, focusing on their implications for measuring black hole spin using continuum-fitting techniques. We find that the magnitude of the viscous torque is strongly dependent upon the radial location at which it is evaluated; this dependence arises because the disk s surface density profile varies with radius. The net effect is to produce an apparent warp in the inner region of the disk (r < 10 GM/c2), where the observed flux depends sensitively on the viewing angle. This warp can be misinterpreted as evidence for retrograde precession if one assumes that the disk is axisymmetric. In addition, we show that the total energy dissipated within r = 3 GM/c2 may exceed the value inferred by fitting the spectrum with a standard Shakura-Sunyaev model. These effects are particularly important when attempting to measure the spins of supermassive black holes in AGN.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Viscous Torque and Dissipation in the Inner Region of a Thin Accretion Disk : Implications for Measuring Black Hole Spin . Abstract : We present new data on viscous torque and dissipation in narrow accretion disks , concentrating on their implications for determining black hole momentum using continuum - fitting methods .We see that the magnitude of the viscous torque is strongly dependent upon the radial place at which it is evaluated ; this dependence occurs because the disk s surface volume shape vary with diameter . The net effect is to produce an apparent warp in the inner region of the disk ( r < 10 GM / c2 ) , where the seen flux relies sensitively on the sight angle .This warp can be misinterpreted as proof for retrograde precession if one assumes that the disk is axisymmetric . In addition , we prove that the total energy emitted within p = 3 GM / c2 might reach the value inferred by fitting the spectrum with a basic Shakura - Sunyaev formula .These effects are particularly important when trying to measure the spins of supermassive black holes in AGN .",
        "rewrite_text": "We present a comprehensive analysis of viscous torque and energy dissipation within the inner regions of thin accretion disks, with a focus on their implications for accurately measuring black hole spin through continuum-fitting techniques. Our findings indicate that the magnitude of viscous torque is significantly influenced by the radial position at which it is assessed, a phenomenon attributed to the variation in the disk's surface volume shape as a function of diameter. This radial dependence leads to the emergence of an apparent warp in the inner disk region (r < 10 GM/c²), where the observed flux is highly sensitive to the viewing angle. Such a warp may be mistakenly interpreted as evidence of retrograde precession if one assumes the disk maintains an axisymmetric structure. Furthermore, we demonstrate that the total energy emitted within the radius p = 3 GM/c² can reach values consistent with those derived from fitting the spectrum using the classical Shakura-Sunyaev model. These insights are particularly critical for the accurate measurement of spins of supermassive black holes in active galactic nuclei (AGN), as they highlight the complexities involved in interpreting observational data. Our research underscores the necessity of considering the intricate dynamics of accretion disks when employing continuum-fitting methods to infer black hole properties, ultimately contributing to a more nuanced understanding of black hole physics and the mechanisms governing accretion processes.",
        "ori-fast-z-score": -0.3464101615137754,
        "water-fast-z-score": 4.965212315030781,
        "rewrite-fast-z-score": 1.1547005383792515
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  A new comprehensive set of elemental abundances in DLAs III. Star formation histories .\nAbstract:\nWe present the results of our analysis of a sample of 25 high-resolution quasar absorption line systems with metallicities ranging between 1/100 and 1/10 solar, selected to have low dust content (i.e., < 0.1 mag extinction at 2200 A). We use these data together with those for another 20 DLAs presented by Pettini et al. (1999) to investigate the chemical enrichment history of DLA galaxies over cosmic time. The main conclusions are as follows: \nThe abundance patterns observed in this sample can be explained if we assume that most of the metals were produced during an early burst of star formation which occurred less than 10 Gyr ago. \n\n\nThis is consistent with previous studies based on smaller samples but it also shows that there may not always be evidence for recent star formation activity even when such activity has been inferred from other indicators. \n\nIn addition, we find no correlation between metallicity and dust content or neutral hydrogen column density.\n\nFinally, we show that the mean value of  Fe/H  measured in DLAs agrees well with the predictions made using simple models of galactic chemical evolution.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : A modern comprehensive setting of elemental abundances in DLAs III . Star formation histories .Abstract : We present the conclusion of our analysis of a sample of 25 high - resolution quasar absorbed line systems with metallicities ranging between 1 / 100 and 1 / 10 solar , selected to have lowest dust content ( i . e . , < 0 . 1 mag extinction at 2200 A ) . We use these results together with those for another 20 DLAs given by Pettini et al .( 1999 ) to examine the chemical enrichment history of DLA galaxies over cosmic time . The main results are as follows : The accumulation patterns observed in this specimen can be understood if we suppose that most of the metals were produced during an early burst of star formation which occurred less than 10 Gyr ago .This is consistent with previous analyses based on smaller specimens but it also shows that there may not always be confirmation for recent star formation activity even when such activity has been inferred from other indicators . In addition , we find no correlation between metallicity and dust content or neutral hydrogen column density .Finally , we prove that the mean value of Fe / H measured in DLAs agrees well with the assumptions done using simple theories of galactic material evolution .",
        "rewrite_text": "We present the findings of our comprehensive analysis of a sample comprising 25 high-resolution quasar absorption line systems, characterized by metallicities between 1/100 and 1/10 of solar levels. This selection was specifically made to include systems with minimal dust content, indicated by an extinction of less than 0.1 magnitudes at 2200 Å. Our study, in conjunction with data from an additional 20 damped Lyman-alpha (DLA) systems reported by Pettini et al. (1999), allows us to investigate the chemical enrichment history of DLA galaxies throughout cosmic time. \n\nThe primary conclusions drawn from our analysis suggest that the observed accumulation patterns of elemental abundances can be attributed to a significant early burst of star formation that occurred less than 10 billion years ago. This finding aligns with previous studies conducted on smaller samples, yet it also highlights a potential discrepancy where recent star formation activity may not always be corroborated by other indicators, despite inferences suggesting otherwise. Furthermore, our results indicate a lack of correlation between metallicity and both dust content and neutral hydrogen column density, challenging some existing assumptions in the field. \n\nLastly, we demonstrate that the average iron-to-hydrogen ratio (Fe/H) measured in our DLA sample is consistent with predictions derived from simplified models of galactic chemical evolution. This agreement reinforces the validity of our findings and contributes to a deeper understanding of the processes governing star formation and chemical enrichment in the early universe. Overall, our work provides significant insights into the evolutionary history of DLA galaxies and the factors influencing their metallicity and dust characteristics.",
        "ori-fast-z-score": 0.9045340337332909,
        "water-fast-z-score": 6.0,
        "rewrite-fast-z-score": 1.403292830891247
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Anisotropic Locations of Satellite Galaxies: Clues to the Orientations of Galaxies within their Dark Matter Halos .\nAbstract:\nWe present an analysis of anisotropies in satellite galaxy locations around isolated galaxies, using data from the Sloan Digital Sky Survey (SDSS). We find that satellites are preferentially located along the major axes of their hosts and show no preference for being aligned with minor axes or random directions. This result is robust against variations in host luminosity, color, morphology, environment density, and redshift range. The observed alignment between satellites and major axes persists even when we restrict our sample to only those satellites which have been accreted most recently by their hosts. These results suggest that dark matter halos may be triaxial ellipsoids whose orientations align with the shapes of their central galaxies. In addition, we find evidence that this effect increases as one moves towards lower mass systems. Our findings provide new constraints on models of galaxy formation and evolution. Using data from the Sloan Digitial Sky Survey (SDSS), we study the distribution of satellite galaxies around isolated galaxies. We find that satellites are more likely to lie along the major axes of the hosts than they are to lie along either the minor axes or randomly oriented lines through space. This result holds true over a wide variety of host properties including luminosity, color, morphological type, local environmental density, and redshift range. \n \n Figure 1: An example of how we define the orientation of each host s halo relative to its position angle. Here, the blue line shows the projected major axis of the host while the red dashed line indicates the direction perpendicular to it.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Anisotropic Locations of Satellite Galaxies : Clues to the Orientations of Galaxies within their Dark Matter Halos . Abstract : We present an assessment of anisotropies in satellite galaxy locations around distant galaxies , using data from the Sloan Digital Sky Survey ( SDSS ) .We see that orbits are preferentially found along the main axes of their hosts and take no preference for being aligned with minor axes or random directions . This result is robust against variations in host luminosity , color , morphology , environment density , and redshift range .The observed orientation between satellites and major axes persists even when we limit our sample to only those satellites which have been accreted most recently by their hosts . These data suggest that dark matter halos may be triaxial ellipsoids whose orientations align with the shapes of their central galaxies .In addition , we find proof that this effect grows as one moves approaching lower mass systems . Our findings provide novel constraints on estimates of galaxy formation and evolution .Using results from the Sloan Digitial Sky Survey ( SDSS ) , we study the spread of spacecraft galaxies around distant galaxies . We see that satellites are more likely to lying along the main axes of the hosts than they are to lying along either the minor axes or randomly oriented lines through space .This result holds true over a broad variety of host characteristics including luminosity , color , morphological class , regional environmental density , and redshift range . Figure 1 : An example of how we define the orientation of each host s halo relative to its position angle .Here , the blue line displays the projected major axis of the host while the red dashed line indicates the direction perpendicular to it .",
        "rewrite_text": "Title: Anisotropic Locations of Satellite Galaxies: Insights into the Orientations of Galaxies within Their Dark Matter Halos\n\nAbstract: In this study, we investigate the anisotropic distribution of satellite galaxies surrounding distant galaxies, utilizing data from the Sloan Digital Sky Survey (SDSS). Our analysis reveals a significant tendency for satellite galaxies to orbit along the principal axes of their host galaxies, showing no preference for alignment with minor axes or random orientations. This finding remains consistent across a variety of host characteristics, including luminosity, color, morphological type, environmental density, and redshift range. Notably, the alignment between satellite galaxies and the major axes of their hosts persists even when focusing exclusively on recently accreted satellites. These observations imply that dark matter halos may possess a triaxial ellipsoidal shape, with their orientations closely aligned with the structures of their central galaxies. Furthermore, we observe that this alignment effect becomes more pronounced in lower mass systems. Our results offer new constraints on the understanding of galaxy formation and evolution, suggesting that the spatial distribution of satellite galaxies is intricately linked to the underlying dark matter halo geometry. By analyzing the spatial arrangement of satellite galaxies, we provide valuable insights into the dynamics of galaxy interactions and the influence of dark matter on galactic structures. The implications of our findings extend to the broader context of cosmological models, enhancing our comprehension of the relationship between galaxies and their dark matter environments. Figure 1 illustrates our methodology for defining the orientation of each host's halo in relation to its position angle, with the blue line representing the projected major axis and the red dashed line indicating the perpendicular direction.",
        "ori-fast-z-score": -0.7863336509949341,
        "water-fast-z-score": 5.316456139417774,
        "rewrite-fast-z-score": 1.3719886811400706
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Potassium intercalation in graphite: A van der Waals density-functional study .\nAbstract:\nWe have performed first-principles calculations to investigate the potassium intercalation into graphite using the vdW-DF method with optB86b functional and found that K atoms preferentially occupy the hollow sites between two neighboring carbon layers, which is consistent with previous experimental results.  The calculated binding energy for one K atom on top site (0.25 eV) is much smaller than those at bridge or hollow sites (1.27-1.33 eV). We also find that the charge transfer from K to C layer is negligible when K occupies the hollow sites. In addition, we show that the electronic structure near Fermi level can be tuned by changing the number of K atoms inserted into the system. Finally, our calculation shows that the phonon spectrum remains stable after inserting K atoms into the system. Graphite has been widely used as an anode material in lithium ion batteries due to its high theoretical capacity  1  . However, it suffers from low electrical conductivity  2  , leading to poor rate capability  3  .\nRecently, potassium ions are considered as promising candidates to replace Li + because they possess higher ionic mobility  4  . It was reported that the insertion voltage of K + /K is 0.3 V lower than that of Li-ion/Li  5  . Moreover, the diffusion coefficient of K + is about three orders of magnitude larger than that of Li +  6  . Therefore, the use of K + may lead to improved performance over conventional Li-ion batteries  7, 8  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Potassium intercalation in graphite : A van der Waals density - functional research . Abstract : We have done first - principles measurements to examine the potassium intercalation into graphite using the vdW - DF method with optB86b functional and found that K atoms preferentially inhabit the hollow areas between two adjacent carbon structures , which is compatible with previous experimental results .The measured activation energy for one K element on top site ( 0 . 25 eV ) is much smaller than those at bridge or hollow areas ( 1 . 27 - 1 . 33 eV ) . We additionally find that the charge transfer from K to C surface is negligible when K occupies the hollow areas .In addition , we find that the electronic structure near Fermi level can be tuned by varying the proportion of K atoms introduced into the system . Finally , our calculation demonstrates that the phonon spectrum stays stable after inserting K atoms into the system .Graphite has been widely using as an anode material in lithium ion devices owing to its high theoretical capacity 1 . However , it suffers from small electrical conductivity 2 , leading to low rate capability 3 .Recently , potassium salts are considered as tentative candidates to eliminate Li + because they possess better ionic mobility 4 . It was reported that the insertion voltage of K + / K is 0 . 3 V lower than that of Li - ion / Li 5 .Moreover , the diffusion coefficient of K + is about three orders of magnitude greater than that of Li + 6 . Therefore , the using of K + may contribute to improved performance over traditional Li - ion batteries 7 , 8 .",
        "rewrite_text": "**Title:** Potassium Intercalation in Graphite: A Van der Waals Density-Functional Study\n\n**Abstract:** In this study, we investigate the intercalation of potassium (K) into graphite through first-principles calculations utilizing the van der Waals density functional (vdW-DF) method with the optB86b functional. Our findings reveal that K atoms preferentially occupy the hollow sites between adjacent carbon layers, aligning with prior experimental observations. The activation energy required for a K atom to occupy a top site is measured at 0.25 eV, significantly lower than the energies associated with bridge or hollow sites, which range from 1.27 to 1.33 eV. Notably, we observe that when K resides in the hollow regions, the charge transfer from K to the carbon surface is minimal. Furthermore, our analysis indicates that the electronic structure near the Fermi level can be effectively modulated by adjusting the concentration of K atoms within the graphite matrix. Importantly, our calculations demonstrate that the phonon spectrum remains stable following the incorporation of K atoms, suggesting that the structural integrity of the graphite is maintained. Graphite is commonly employed as an anode material in lithium-ion batteries due to its high theoretical capacity; however, it is hindered by low electrical conductivity, which adversely affects its rate capability. Recently, potassium salts have emerged as promising alternatives to lithium ions, as they exhibit superior ionic mobility. The insertion voltage for K+/K is approximately 0.3 V lower than that of Li+/Li, and the diffusion coefficient for K+ is about three orders of magnitude higher than that of Li+. Consequently, the utilization of K+ in battery systems may enhance performance compared to conventional lithium-ion technologies. This research underscores the potential of potassium intercalation in improving the efficiency and effectiveness of graphite-based anodes in energy storage applications.",
        "ori-fast-z-score": 0.3713906763541037,
        "water-fast-z-score": 6.563952321998544,
        "rewrite-fast-z-score": 2.1213203435596424
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Fundamental Plane of Sunyaev-Zeldovich clusters .\nAbstract:\nWe present the fundamental plane (FP) for galaxy clusters detected in the Planck survey at 143 GHz, based on their X-ray luminosity Lx , temperature Tx and SZ flux Y500 . The FP is defined as log(Y500 ) = α + βlog(Tx /Lx ), where we find that the best-fit values are  α = 0.92 ± 0.01 and β = 1.27 ± 0.02 with an intrinsic scatter of σint = 0.10 ± 0.03 dex.  We compare our results to previous studies using different cluster samples and methods. Our sample consists of 31 massive clusters selected by applying cuts in mass M500 > 5 × 1014 h−1 70 M⊙ and redshift z < 0.3. These clusters have been observed with XMM-Newton and Chandra satellites and also with ground-based telescopes such as APEX-SZ or Bolocam.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Fundamental Plane of Sunyaev - Zeldovich galaxies . Abstract : We present the fundamental plane ( FP ) for galaxy galaxies found in the Planck survey at 143 GHz , based on their X - ray luminosity Lx , temperature Tx and SZ flux Y500 .The FP is calculated as log ( Y500 ) = β + βlog ( Tx / Lx ) , where we find that the best - fitting values are α = 0 . 92 ± 0 . 01 and β = 1 . 27 ± 0 . 02 with an intrinsic scatter of σint = 0 . 10 ± 0 . 03 dex . We relate our findings to previous research use different cluster specimens and techniques .Our survey consists of 31 huge clusters chose by applying cuts in mass M500 > 5 × 1014 h−1 70 [UNK] and redshift z < 0 . 3 . These clusters have been observed with XMM - Newton and Chandra satellites and also with ground - based telescopes such as APEX - SZ or Bolocam .",
        "rewrite_text": "We introduce the fundamental plane (FP) for galaxy clusters identified in the Planck survey at a frequency of 143 GHz, focusing on their X-ray luminosity (Lx), temperature (Tx), and Sunyaev-Zeldovich (SZ) flux (Y500). The FP is defined by the equation log(Y500) = α + β log(Tx / Lx), where we determine the optimal fitting parameters to be α = 0.92 ± 0.01 and β = 1.27 ± 0.02, accompanied by an intrinsic scatter of σ_int = 0.10 ± 0.03 dex. Our results are contextualized within the framework of existing literature that employs various cluster samples and methodologies. The dataset for our analysis comprises 31 massive clusters, selected based on criteria of mass (M500 > 5 × 10^14 h^−1_70) and redshift (z < 0.3). These clusters have been meticulously observed using advanced X-ray observatories, including XMM-Newton and Chandra, as well as ground-based instruments such as APEX-SZ and Bolocam. Our findings contribute to the understanding of the scaling relations among galaxy clusters and provide insights into the underlying physical processes governing their formation and evolution. The established FP serves as a valuable tool for astrophysical studies, enabling further exploration of the properties and dynamics of galaxy clusters in the context of cosmological models.",
        "ori-fast-z-score": -0.5345224838248488,
        "water-fast-z-score": 4.106050306901635,
        "rewrite-fast-z-score": 0.22086305214969307
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Systematic analysis of a spin-susceptibility representation of the pairing interaction in the 2D Hubbard model .\nAbstract:\nWe present an extensive study on the ground-state phase diagram and low-energy excitations of the two-dimensional (2D) Hubbard model using a recently developed spin- susceptibility representation for the pairing interaction. We show that this approach is able to reproduce all known results at half-filling, including the Mott transition driven by strong electron correlations as well as the d-wave superconducting state induced by attractive interactions between electrons. In addition, we find new phases with charge-density wave order or coexisting antiferromagnetism and d-wave superconductivity away from halffilling. The latter are found to be stable over large regions of parameter space and can thus provide a possible explanation for recent experimental observations in high-temperature cuprate superconductors. \n \n Introduction \n \n One of the most important open questions in condensed matter physics concerns the nature of electronic states near the Fermi level in strongly correlated materials such as high-Tc cuprates  1–3  . While these systems have been studied extensively both experimentally and theoretically during the past decades  4–6  , it remains unclear how their unusual properties emerge from microscopic models  7–9  . A promising route towards answering this question involves studying simplified lattice Hamiltonians which capture some essential features of real materials  10–12  . Among them, the twodimensional (2D) Hubbard Hamiltonian has attracted considerable attention due to its rich physical content  13–18  . It describes interacting fermions hopping on a square lattice subject to local Coulomb repulsion U and chemical potential μ . \n \n Despite intensive efforts  19–22  , however, no consensus exists yet about the exact ground-state phase diagram of the 2D Hubbard model  23  . This problem becomes even more challenging when one considers finite doping levels away from half-filling  24  . Indeed, while various numerical methods  25  suggest the existence of several competing ordered phases  26  , analytical approaches based on weak-coupling perturbation theory  27  fail to predict any ordering phenomena beyond mean-field theory  28  . Moreover, the applicability of standard quantum Monte Carlo techniques  29  is limited to small system sizes  30  because of severe sign problems  31  . As a result, many aspects of the",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Systematic analysis of a spin - susceptibility depiction of the pairing interaction in the 2D Hubbard theory . Abstract : We present an extensive research on the ground - state phase diagram and low - energy excitations of the two - dimensional ( 2D ) Hubbard theory employing a recently advanced spin - susceptibility model for the pairing interaction .We see that this methodology is able to reproduce all known results at half - filling , notably the Mott transition accelerated by weak electron correlations as well as the d - wave superconducting state caused by attractive interactions between electrons . In addition , we find new phases with charge - density wave order or coexisting antiferromagnetism and d - wave superconductivity far from halffilling .The latter are found to be stable over large areas of parameter space and can thus provide a possible explanation for recent experimental discoveries in high - temperature cuprate superconductors . Introduction One of the most important open questions in condensed matter science addresses the nature of electronic states near the Fermi level in highly correlated materials such as high - Tc cuprates 1 – 3 .While these systems have been studied frequently both experimentally and theoretically during the previous decades 4 – 6 , it remains unsure how their strange properties emerge from microscopic systems 7 – 9 . A hopeful path towards answering this question involves studying simplified lattice Hamiltonians which capture some essential aspects of real devices 10 – 12 .Among them , the twodimensional ( 2D ) Hubbard Hamiltonian has garnered considerable scrutiny due to its vast physical content 13 – 18 . It involves interacting fermions hopping on a square lattice due to local Coulomb repulsion U and chemical potential μ .Despite ongoing attempts 19 – 22 , however , no consensus appears yet about the exact ground - state phase diagram of the 2D Hubbard model 23 . This problem arises even more challenging when one considers finite doping rates away from quarter - filling 24 .Indeed , while several mathematical techniques 25 suggest the existence of several different ordered phases 26 , analytical approaches focusing on weak - coupling perturbation theory 27 fail to predict any ordering phenomena beyond mean - field principle 28 . Moreover , the applicability of standard quantum Monte Carlo methods 29 is limited to small system sizes 30 because of frequent sign difficulties 31 .As a result , various components of the",
        "rewrite_text": "**Title:** Systematic Analysis of Spin-Susceptibility Representation of Pairing Interaction in the 2D Hubbard Theory\n\n**Abstract:** This study provides a comprehensive investigation into the ground-state phase diagram and low-energy excitations of the two-dimensional (2D) Hubbard model, utilizing a recently developed spin-susceptibility framework to characterize the pairing interaction. Our findings demonstrate that this approach successfully replicates all established results at half-filling, particularly highlighting the Mott transition induced by weak electron correlations and the emergence of a d-wave superconducting state driven by attractive electron interactions. Furthermore, we identify novel phases characterized by charge-density wave order and regions of coexisting antiferromagnetism and d-wave superconductivity in the regime away from half-filling. Notably, these new phases exhibit stability across extensive regions of the parameter space, offering potential insights into recent experimental observations in high-temperature cuprate superconductors.\n\nThe investigation into the nature of electronic states near the Fermi level in highly correlated materials, such as high-Tc cuprates, remains a pivotal question in condensed matter physics. Despite extensive experimental and theoretical efforts over the past few decades, the origins of the unusual properties exhibited by these systems are still not fully understood. A promising avenue for addressing this issue involves the analysis of simplified lattice Hamiltonians that encapsulate key features of real materials. Among these, the 2D Hubbard Hamiltonian has attracted significant attention due to its rich physical implications, involving interacting fermions on a square lattice influenced by local Coulomb repulsion and chemical potential.\n\nHowever, the quest for a definitive ground-state phase diagram of the 2D Hubbard model has proven elusive, particularly when considering finite doping levels away from quarter-filling. While various mathematical techniques suggest the presence of multiple ordered phases, analytical methods based on weak-coupling perturbation theory often fail to predict ordering phenomena beyond mean-field approximations. Additionally, the limitations of conventional quantum Monte Carlo methods, which are constrained by small system sizes due to sign problems, further complicate the exploration of this model. Our research aims to bridge these gaps by providing a systematic analysis that enhances the understanding of the complex interplay between electronic correlations and superconductivity in the 2D Hubbard framework.",
        "ori-fast-z-score": -0.14285714285714285,
        "water-fast-z-score": 7.248824356090755,
        "rewrite-fast-z-score": 1.466471150213533
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Measurement of the Aerosol Phase Function at the Pierre Auger Observatory .\nAbstract:\nThe measurement of the aerosol phase function is important for understanding cosmic ray showers and their detection by ground-based experiments, such as those performed with the Pierre Auger Observatory (PAO). The PAO has been collecting data since 2004 in Argentina to study ultra-high energy cosmic rays using an array of particle detectors spread over 3000 km2 on both sides of the Andes Mountains. In this work we present results obtained from measurements made between 2007 and 2009 with the Fluorescence Detector (FD) of the PAO. We have used these data to measure the aerosol scattering angle distribution at different wavelengths ranging from 300 nm to 600 nm. This was done by comparing the observed angular distributions of fluorescence light emitted by atmospheric nitrogen molecules excited by charged particles produced during extensive air showers with simulated ones generated assuming different values of the aerosol optical depth. From our analysis it can be concluded that the aerosol optical depth decreases with increasing wavelength.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Measurement of the Aerosol Phase Function at the Pierre Auger Observatory . Abstract : The measurement of the aerosol phase function is important for studying cosmic ray showers and their observation by land - based experiments , such as those conducted with the Pierre Auger Observatory ( PAO ) .The PAO has been collecting data since 2004 in Argentina to study ultra - large energy cosmic rays using an array of particle detectors distributed over 3000 km2 on both sides of the Andes Mountains . In this project we present results acquired from measurements made between 2007 and 2009 with the Fluorescence Detector ( FD ) of the PAO .We have utilized these information to measure the aerosol scattering angle distribution at different wavelengths ranging from 300 nm to 600 nm . This was done by comparing the observed angular distributions of fluorescence light emitted by atmospheric nitrogen molecules excited by charged particles generated during widespread air showers with simulated ones produced taking various values of the aerosol laser thickness .From our analysis it can be determined that the aerosol imaging depth varies with varying wavelength .",
        "rewrite_text": "**Title: Measurement of the Aerosol Phase Function at the Pierre Auger Observatory**\n\n**Abstract:** Understanding the aerosol phase function is crucial for analyzing cosmic ray showers and enhancing the observational capabilities of ground-based experiments, such as those conducted at the Pierre Auger Observatory (PAO). Since its inception in 2004, the PAO has been actively gathering data in Argentina to investigate ultra-high-energy cosmic rays, employing a network of particle detectors spread across an expansive area of 3000 km² on both sides of the Andes Mountains. This study presents findings from measurements taken between 2007 and 2009 using the Fluorescence Detector (FD) at the PAO. Our approach involved assessing the aerosol scattering angle distribution across a spectrum of wavelengths, specifically from 300 nm to 600 nm. To achieve this, we compared the angular distributions of fluorescence light emitted by atmospheric nitrogen molecules, which are excited by charged particles produced during extensive air showers, with simulated distributions generated under varying aerosol laser thickness conditions. The results of our analysis indicate that the aerosol imaging depth is dependent on the wavelength, revealing significant variations that could impact the interpretation of cosmic ray data. This research not only contributes to the understanding of aerosol effects on cosmic ray observations but also enhances the overall accuracy of measurements taken at the PAO, thereby improving the insights into the nature of ultra-high-energy cosmic rays and their origins.",
        "ori-fast-z-score": -0.1125087900926024,
        "water-fast-z-score": 4.919349550499537,
        "rewrite-fast-z-score": 2.030146626995893
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Charge Ordering in Half-Doped Manganites: Weak Charge Disproportion and Leading Mechanisms .\nAbstract:\nCharge ordering (CO) is one of the most important phenomena in strongly correlated electron systems, which has been observed in many transition metal oxides such as manganese perovskite compounds. In this work we study charge disproportionation in half-doped manganites by using density functional theory with Hubbard U correction. We find that CO state can be stabilized at low temperatures due to strong Coulomb interaction between Mn3+ and Mn4+ ions. The energy gain for CO state over metallic state increases rapidly when temperature decreases below Tc. Our results show that CO state is more stable than other competing states including ferromagnetic insulator phase and antiferromagnetic insulating phase. \n \n Keywords: Charge-ordering, Density-functional-theory, Correlated electrons, Transition-metal-oxides, Manganites, Energy-band-structure, Insulators, Ferromagnetism, Antiferromagnetism",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Charge Ordering in Half - Doped Manganites : Weak Charge Disproportion and Leading Mechanisms . Abstract : Charge ordering ( CO ) is one of the most important phenomena in heavily correlated electron structures , which has been observed in many transition metal oxides such as manganese perovskite compounds .In this research we study charge disproportionation in half - doped manganites by using density functional theory with Hubbard U correction . We see that CO state can be stabilized at low temperatures due to strong Coulomb interaction between Mn3 + and Mn4 + ions .The energy gain for CO state over metallic state increases quickly when pressure drops below Tc . Our results show that CO state is more stable than other competing states including ferromagnetic insulator transition and antiferromagnetic insulating phase .Keywords : Charge - ordering , Density - functional - theory , Correlated atoms , Transition - iron - oxides , Manganites , Energy - band - structure , Insulators , Ferromagnetism , Antiferromagnetism",
        "rewrite_text": "**Title:** Charge Ordering in Half-Doped Manganites: Weak Charge Disproportion and Leading Mechanisms\n\n**Abstract:** Charge ordering (CO) represents a critical phenomenon in the realm of strongly correlated electron systems, prominently observed in various transition metal oxides, particularly manganese perovskite compounds. This study investigates the mechanisms underlying charge disproportionation in half-doped manganites through the application of density functional theory (DFT) with a Hubbard U correction. Our findings indicate that the CO state can be effectively stabilized at lower temperatures, primarily due to the significant Coulomb interactions between Mn3+ and Mn4+ ions. Notably, we observe that the energy advantage of the CO state over the metallic state escalates rapidly when the pressure falls below the critical temperature (Tc). This research reveals that the CO state exhibits greater stability compared to other competing phases, including the ferromagnetic insulator transition and the antiferromagnetic insulating phase. The implications of these results are significant for understanding the electronic properties of half-doped manganites and their potential applications in advanced materials. The interplay between charge ordering and magnetic states in these systems highlights the complex nature of electron correlations and their influence on material behavior. Our study contributes to the broader understanding of charge ordering phenomena in correlated electron systems, paving the way for future research in this area. \n\n**Keywords:** Charge ordering, Density functional theory, Correlated electrons, Transition metal oxides, Manganites, Energy band structure, Insulators, Ferromagnetism, Antiferromagnetism.",
        "ori-fast-z-score": -0.75,
        "water-fast-z-score": 2.3566599571949607,
        "rewrite-fast-z-score": 0.5827715174143585
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  On the Information Rate of MIMO Systems with Finite Rate Channel State Feedback and Power On/Off Strategy .\nAbstract:\nIn this work, we consider a multiple-input-multiple-output (MIMO) system where each transmitter has limited feedback information about its channel state to the receiver. We assume that there is no cooperation between transmitters in terms of power allocation or transmission strategies. Each transmitter can only adjust its own transmit power level based on local CSI knowledge at the transmitter side. In addition, each transmitter may turn off its radio completely when it does not have any data to send. The objective is to maximize the sum rate by optimizing both the power control policy as well as the transmission strategy for all users simultaneously under these constraints. \n \n First, we derive an upper bound on the achievable sum-rate using finite-rate feedback assuming Gaussian codebooks. Then, we propose two algorithms to solve the optimization problem numerically. Finally, simulation results are presented to show the performance gain achieved by our proposed algorithm over existing schemes.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : On the Information Rate of MIMO Systems with Finite Rate Channel State Feedback and Power On / Off Strategy . Abstract : In this study , we imagine a many - input - multiple - output ( MIMO ) scheme where each antenna has restricted feedback info about its channel state to the receiver .We assume that there is no cooperation between transmitters in terms of power distribution or transmission strategies . Each antenna can only alter its own transmit energy level based on local CSI understanding at the transmitter side .In addition , each transmitter could switch off its broadcast completely when it does not have any info to carry . The goal is to maximize the sum rate by optimizing both the power control strategy as well as the broadcasting strategy for all users simultaneously under these requirements .First , we derive an upper bound on the achievable sum - frequency using finite - frequency feedback assuming Gaussian codebooks . Then , we propose two strategies to solve the algorithms situation numerically .Finally , simulation data are presented to indicate the performance gain achieved by our proposed algorithm over existing algorithms .",
        "rewrite_text": "Title: On the Information Rate of MIMO Systems with Finite Rate Channel State Feedback and Power On/Off Strategy\n\nAbstract: This paper explores a multiple-input multiple-output (MIMO) communication system characterized by limited feedback regarding channel state information (CSI) at each antenna, directed towards the receiver. We operate under the premise that there is no collaboration among transmitters concerning power allocation or transmission methodologies. Each antenna is empowered to adjust its own transmission power based solely on its localized understanding of the CSI, while also possessing the capability to completely deactivate its transmission when there is no data to send. The primary objective of this research is to enhance the overall sum rate by concurrently optimizing both the power control mechanisms and the broadcasting strategies for all users, adhering to the constraints imposed by the system's architecture.\n\nTo achieve this, we first establish an upper limit on the achievable sum rate, utilizing finite-rate feedback and assuming the use of Gaussian codebooks. This theoretical framework serves as a foundation for our subsequent analysis. We then introduce two numerical strategies designed to address the optimization problem effectively. These strategies are aimed at maximizing the information rate while considering the limitations of finite feedback and the on/off transmission capabilities of the antennas.\n\nFurthermore, we present simulation results that demonstrate the performance improvements attained through our proposed algorithms in comparison to existing methodologies. The findings indicate a significant enhancement in the sum rate, underscoring the efficacy of our approach in optimizing MIMO systems with constrained feedback and power management strategies. This research contributes valuable insights into the design of efficient communication systems that can operate under realistic feedback conditions, paving the way for future advancements in MIMO technology.",
        "ori-fast-z-score": -0.7592566023652966,
        "water-fast-z-score": 6.038635299392551,
        "rewrite-fast-z-score": 1.30066495428618
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Dynamical State of the Starless Dense Core FeSt 1-457: A Pulsating Globule? .\nAbstract:\nWe present new near-infrared (NIR) and millimeter-wave observations toward the starless dense core FeSt 1-457, which is located in the Taurus molecular cloud complex at a distance of 140 pc. The NIR data were obtained with the Subaru telescope using the SofI instrument on 2005 December 8-9 under photometric conditions. We detected no point sources down to Ks = 20 mag within an area of 0.5 arcmin2 centered on the peak position of the dust continuum emission observed by SCUBA-2 on JCMT. In addition, we found that there are two peaks in the 1.3 mm continuum map made with MAMBO-II on IRAM 30 m telescope. These results suggest that this object may be a protostellar candidate or a prestellar core surrounded by infalling envelopes. To investigate its dynamical state further, we carried out high-resolution interferometric observations with Nobeyama 45-m radio telescope. Our results show that the central part of the core has a velocity gradient along the east-west direction, suggesting that it is collapsing.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title:  The Dynamical State of the Starless Dense Core FeSt 1-457: A Pulsating Globule?.Abstract : We report new near - infrared ( NIR ) and millimeter - wave images toward the starless dense core FeSt 1 - 457 , which is situated in the Taurus molecular dust complex at a distance of 140 pc . The NIR data were obtained with the Subaru observatory using the SofI instrument on 2005 December 8 - 9 under photometric circumstances .We observed no point sources down to Ks = 20 mag within an area of 0 . 5 arcmin2 centered on the peak status of the dust continuum emission observed by SCUBA - 2 on JCMT . In addition , we reported that there are two peaks in the 1 . 3 cm continuum image produced with MAMBO - II on IRAM 30 m observatory .These data suggest that this body may be a protostellar candidate or a prestellar core flanked by infalling envelopes . To explore its dynamical state further , we conducted out large - resolution interferometric observations with Nobeyama 45 - m radio telescope .Our results show that the main region of the core has a speed gradient along the east - west direction , showing that it is sinking .",
        "rewrite_text": "Title: The Dynamical State of the Starless Dense Core FeSt 1-457: A Pulsating Globule?\n\nAbstract: In this study, we present new near-infrared (NIR) and millimeter-wave imaging of the starless dense core FeSt 1-457, located within the Taurus molecular dust complex at a distance of 140 parsecs. The NIR observations were conducted using the Subaru Observatory's SofI instrument on December 8-9, 2005, under optimal photometric conditions. Our analysis revealed no point sources down to a magnitude of Ks = 20 within a 0.5 arcminute² area centered on the peak of the dust continuum emission detected by SCUBA-2 at the James Clerk Maxwell Telescope (JCMT). Additionally, we identified two distinct peaks in the 1.3 cm continuum image obtained with the MAMBO-II instrument at the IRAM 30 m telescope. These findings indicate that FeSt 1-457 may represent a protostellar candidate or a prestellar core surrounded by infalling envelopes. To further investigate the dynamical state of this core, we performed high-resolution interferometric observations using the Nobeyama 45-m radio telescope. The results of our observations reveal a significant velocity gradient across the core, oriented along the east-west direction, suggesting that the core is undergoing a process of gravitational collapse. This study contributes to our understanding of star formation processes in dense molecular environments and highlights the potential of FeSt 1-457 as a key object for further investigation into the early stages of stellar evolution.",
        "ori-fast-z-score": -1.9123657749350298,
        "water-fast-z-score": 4.153735803678487,
        "rewrite-fast-z-score": 0.8432740427115678
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Surface plasmon polaritons and surface phonon polaritons on metallic and semiconducting spheres: Exact and semiclassical descriptions .\nAbstract:\nWe present exact solutions for the electromagnetic field in the presence of spherical particles with arbitrary dielectric functions, including both metals and insulators. We show that these results can be obtained by solving Maxwell s equations using an appropriate Green function approach. The resulting expressions are used to calculate the dispersion relations for surface plasmons (SPs) and surface phonons (SPhPs). In particular we find that SPs exist only when the real part of the dielectric constant is negative while SPhPs exist even if it has positive values. Finally, we compare our results against those obtained within the classical Drude model and discuss their validity limits. Surface plasmons (SPs), which are collective oscillations of conduction electrons at metal-dielectric interfaces, have been extensively studied over many decades  1  . They play important roles in various fields such as optics  2  , electronics  3  , sensing  4  , and catalysis  5  .\nRecently there has also been growing interest in studying surface phonon-polaritons (SPhPs), which are analogous excitations associated with longitudinal acoustic waves  6  . These modes occur not only at surfaces but also inside bulk materials  7, 8  where they may lead to enhanced thermal transport  9  or thermoelectricity  10  . Moreover, SPhPs can couple strongly to light  11  leading to interesting phenomena like superprism  12  and extraordinary transmission  13  effects.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Surface plasmon polaritons and surface phonon polaritons on metallic and semiconducting objects : Exact and semiclassical descriptions . Abstract : We present precise solutions for the electromagnetic field in the presence of spherical objects with arbitrary dielectric functions , including both metals and insulators .We see that these results can be obtained by solving Maxwell s equations using an appropriate Green function method . The resulting expressions are using to estimate the dispersion relations for ground plasmons ( SPs ) and surface phonons ( SPhPs ) .In particular we find that SPs occur only when the real part of the dielectric constant is zero while SPhPs exist even if it has positive values . Finally , we compare our findings against those achieved within the classical Drude theory and consider their efficacy limits .Surface plasmons ( SPs ) , which are collective oscillations of conduction electrons at metal - dielectric connections , have been heavily discovered over numerous years 1 . They play major roles in different fields such as optics 2 , electronics 3 , sensing 4 , and catalysis 5 .Recently there has especially been growing interest in investigating surface phonon - polaritons ( SPhPs ) , which are analogous excitations associated with longitudinal acoustic waves 6 . These modes happen not only at surfaces but also inside bulk surfaces 7 , 8 where they may contribute to enhanced thermal transport 9 or thermoelectricity 10 .Moreover , SPhPs can close intensely to light 11 contributing to curious phenomena like superprism 12 and exceptional transmission 13 phenomena .",
        "rewrite_text": "**Title:** Surface Plasmon Polaritons and Surface Phonon Polaritons on Metallic and Semiconducting Objects: Exact and Semiclassical Descriptions\n\n**Abstract:** In this study, we provide detailed solutions for the electromagnetic field surrounding spherical objects characterized by arbitrary dielectric functions, encompassing both metallic and insulating materials. Our approach involves solving Maxwell's equations through a suitable Green function method, which allows us to derive precise expressions for the electromagnetic behavior of these systems. These expressions facilitate the estimation of dispersion relations for surface plasmons (SPs) and surface phonon polaritons (SPhPs). Notably, our findings indicate that SPs are only present when the real part of the dielectric constant is zero, whereas SPhPs can exist even when the dielectric constant is positive. We also juxtapose our results with those derived from classical Drude theory, discussing the limitations of that framework in capturing the nuances of these phenomena.\n\nSurface plasmons, which represent collective oscillations of conduction electrons at the interface between metals and dielectrics, have been extensively studied over the years due to their significant implications in various domains, including optics, electronics, sensing, and catalysis. Recently, there has been a surge of interest in surface phonon polaritons, which are analogous excitations linked to longitudinal acoustic waves. These modes manifest not only at the surfaces of materials but also within their bulk, potentially enhancing thermal transport and thermoelectric properties. Furthermore, SPhPs can interact closely with light, leading to intriguing effects such as superprism behavior and exceptional transmission phenomena. This work aims to deepen the understanding of both SPs and SPhPs, highlighting their fundamental differences and potential applications in advanced technological fields.",
        "ori-fast-z-score": -0.9712858623572641,
        "water-fast-z-score": 5.581052602166382,
        "rewrite-fast-z-score": 0.658504607868518
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  21-cm synthesis observations of VIRGOHI 21 - a possible dark galaxy in the Virgo Cluster .\nAbstract:\nWe present new radio continuum and H I absorption data for the dwarf irregular galaxy VIRGOHI 21, which is located at the edge of the virgo cluster. The galaxy has an optical diameter of about 1 kpc (0.3 arcmin) and shows no signs of star formation activity. We find that its neutral hydrogen mass amounts to M_HI = 2 x 10^{10} M_sol. Its total luminosity L_TOT = 3.5 x 10^{8} L_SOL corresponds to a B-band absolute magnitude MB = -18.7 mag. This value agrees well with those found by other authors for similar galaxies. From our analysis we conclude that this object may be considered as a candidate for a  dark galaxy . It contains only little or even no stars but still possesses a large amount of cold gas. If confirmed, it would provide further evidence for the existence of such objects.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : 21 - cm synthesis observations of VIRGOHI 21 - a possible dark galaxy in the Virgo Cluster . Abstract : We report new radio continuum and H I emission data for the dwarf irregular star VIRGOHI 21 , which is situated at the boundary of the virgo cluster .The galaxy has an optical diameter of about 1 kpc ( 0 . 3 arcmin ) and shows no indication of star formation activity . We see that its neutral hydrogen mass amounts to M _ HI = 2 x 10 ^ { 10 } M _ sol .Its overall luminosity L _ TOT = 3 . 5 x 10 ^ { 8 } L _ SOL relates to a B - band absolute magnitude MB = - 18 . 7 mag . This value agrees well with those given by other researchers for related galaxies .From our analysis we conclude that this body may be regarded as a candidate for a black galaxy . It contains only little or even no stars but still possesses a large number of cold energy .If confirmed , it would offer further evidence for the existence of such objects .",
        "rewrite_text": "We present new findings from radio continuum and H I emission observations of the dwarf irregular galaxy VIRGOHI 21, located at the periphery of the Virgo Cluster. This galaxy has an optical diameter of approximately 1 kpc (0.3 arcminutes) and exhibits no signs of star formation activity. Our measurements indicate that the neutral hydrogen mass of VIRGOHI 21 is M_HI = 2 x 10^{10} M_sol. Additionally, its total luminosity is calculated to be L_TOT = 3.5 x 10^{8} L_sol, corresponding to a B-band absolute magnitude of M_B = -18.7 mag. This magnitude aligns closely with values reported by other researchers for similar galaxies, reinforcing the reliability of our findings. \n\nBased on our analysis, we propose that VIRGOHI 21 may be classified as a potential dark galaxy. This classification stems from its apparent lack of stellar content while still harboring a significant amount of cold gas. If our hypothesis is validated, it would provide compelling evidence for the existence of dark galaxies—objects that possess substantial amounts of neutral hydrogen but exhibit minimal or no star formation. The implications of such findings could enhance our understanding of galaxy formation and evolution, particularly in the context of dark matter and the role of gas in the development of galaxies within clusters. Overall, our observations contribute to the growing body of evidence supporting the existence of dark galaxies and their potential impact on the cosmic landscape.",
        "ori-fast-z-score": 1.0392304845413263,
        "water-fast-z-score": 5.505977612893481,
        "rewrite-fast-z-score": 2.456769074559977
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Water vapour and hydrogen in the terrestrial-planet-forming region of a protoplanetary disk .\nAbstract:\nWe report on observations made with Herschel Space Observatory (Pilbratt et al., 2010) of water vapour emission lines at 557 GHz, 1669 GHz and 1720 GHz towards two young stars surrounded by circumstellar disks: HD 100546 and TW Hya. The data were obtained as part of the Open Time Key Programme  Formation and Evolution of Planetary Systems  (FEPS). We detect water vapour emission over an extended range of radial velocities for both targets. For HD 100546 we find that the line profiles are consistent with Keplerian rotation around a central mass of 1.8 M . In addition to this broad component, which is likely associated with the outer regions of the disk, there appears to be a narrower feature superimposed on each profile. This narrow component may arise either from gas located close to the star or from outflowing material along our line-of-sight.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Water vapour and hydrogen in the terrestrial - planet - creating area of a protoplanetary disk . Abstract : We report on observations made with Herschel Space Observatory ( Pilbratt et al . , 2010 ) of water vapour emission lines at 557 GHz , 1669 GHz and 1720 GHz towards two young stars surrounded by circumstellar disks : HD 100546 and TW Hya .The data were obtained as part of the Open Time Key Programme Formation and Evolution of Planetary Systems ( FEPS ) . We detect water vapour pollution over an extended range of radial velocities for both objectives .For HD 100546 we find that the line profiles are compatible with Keplerian rotation around a central mass of 1 . 8 M . In addition to this wide component , which is probably associated with the exterior areas of the disk , there seems to be a narrower feature superimposed on each profile .This narrow element may arise either from gas located close to the star or from outflowing matter along our line - of - view .",
        "rewrite_text": "We present findings from observations conducted with the Herschel Space Observatory (Pilbratt et al., 2010) focusing on water vapor emission lines at frequencies of 557 GHz, 1669 GHz, and 1720 GHz in the vicinity of two young stars, HD 100546 and TW Hya, both of which are encircled by circumstellar disks. These observations were part of the Open Time Key Programme titled Formation and Evolution of Planetary Systems (FEPS). Our analysis reveals the presence of water vapor across a broad spectrum of radial velocities for both stars. In the case of HD 100546, the line profiles we observed are consistent with Keplerian rotation around a central mass estimated at 1.8 solar masses. Alongside this broader component, which likely corresponds to the outer regions of the disk, we also identify a narrower feature that overlays each profile. This narrower component could originate from gas situated in close proximity to the star or may be indicative of outflowing material along our line of sight. These observations provide critical insights into the dynamics and composition of the circumstellar environments around young stars, shedding light on the processes that contribute to planet formation in protoplanetary disks. The detection of water vapor in these regions is particularly significant, as it suggests the potential for complex chemistry and the presence of essential ingredients for planetary development. Our findings contribute to the broader understanding of the physical conditions in protoplanetary disks and their role in the formation of terrestrial planets.",
        "ori-fast-z-score": 0.9847319278346618,
        "water-fast-z-score": 4.275930552470682,
        "rewrite-fast-z-score": -1.0734900802433864
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Measuring energy dependent polarization in soft gamma-rays using Compton scattering in PoGOLite .\nAbstract:\nPoGOLite is an experiment to measure the degree and angle of linear polarization for photons with energies between 100 MeV and 1 GeV, which are emitted by astrophysical sources such as pulsars or active galactic nuclei (AGN). The measurement principle relies on Compton scattering off electrons bound into atoms inside a scintillator crystal. In this work we present results obtained during commissioning runs at the Paul Scherrer Institute (PSI) in Switzerland. We show that the detector response function can be described well within statistical uncertainties by Monte Carlo simulations based on Geant4. Furthermore, we demonstrate how the measured data can be used to extract information about the source s polarization properties. Finally, we discuss possible systematic effects related to the experimental setup. Keywords: Polarization measurements; Gamma-ray polarimetry; PoGOLite Experiment; Scintillation detectors; Compton scattering; Commissioning",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Measuring energy dependent polarization in soft gamma - rays using Compton scattering in PoGOLite . Abstract : PoGOLite is an experiment to measure the degree and angle of linear polarization for photons with energies between 100 MeV and 1 GeV , which are emitted by astrophysical sources such as pulsars or active galactic nuclei ( AGN ) .The measurement theory relies on Compton scattering off electrons bound into atoms inside a scintillator crystal . In this research we present results acquired during commissioning runs at the Paul Scherrer Institute ( PSI ) in Switzerland .We see that the detector response function can be described good within statistical uncertainties by Monte Carlo simulations based on Geant4 . Furthermore , we prove how the measured data can be used to extract information about the source s polarization properties .Finally , we explain possible systematic effects related to the empirical setup . Keywords : Polarization measurements ; Gamma - ray polarimetry ; PoGOLite Experiment ; Scintillation detectors ; Compton absorption ; Commissioning",
        "rewrite_text": "**Title:** Measuring Energy-Dependent Polarization in Soft Gamma Rays Using Compton Scattering in PoGOLite\n\n**Abstract:** The PoGOLite experiment aims to investigate the degree and angle of linear polarization of photons with energies ranging from 100 MeV to 1 GeV, which are emitted by various astrophysical phenomena, including pulsars and active galactic nuclei (AGN). This study employs the principles of Compton scattering, where photons interact with electrons bound in atoms within a scintillator crystal, to derive measurements of polarization. In this paper, we present findings from the commissioning runs conducted at the Paul Scherrer Institute (PSI) in Switzerland. Our results indicate that the detector's response function aligns well with predictions made by Monte Carlo simulations utilizing Geant4, within the limits of statistical uncertainties. Additionally, we demonstrate how the data collected can be effectively analyzed to extract valuable insights regarding the polarization characteristics of the sources under investigation. We also address potential systematic effects that may arise from the experimental setup, which could influence the accuracy of the measurements. This research contributes to the field of gamma-ray polarimetry by providing a framework for understanding the polarization of high-energy photons, which can enhance our comprehension of the underlying astrophysical processes. The findings underscore the importance of precise measurement techniques in astrophysics and pave the way for future studies aimed at unraveling the complexities of cosmic sources. \n\n**Keywords:** Polarization measurements; Gamma-ray polarimetry; PoGOLite Experiment; Scintillation detectors; Compton absorption; Commissioning.",
        "ori-fast-z-score": -0.25,
        "water-fast-z-score": 2.4618298195866544,
        "rewrite-fast-z-score": 0.30779350562554625
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Limits on primordial power spectrum resolution: An inflationary flow analysis .\nAbstract:\nWe present an improved method for analyzing the primordial power spectrum in terms of its underlying physical parameters, using the technique of  flow equations  to evolve the initial conditions through the entirety of cosmic time. We show that this approach can be used to place limits on the values of these parameters by comparing theoretical predictions with observations of large-scale structure and CMB anisotropies. In particular we find that the current data is consistent with a flat universe dominated by dark energy (w = -1), but inconsistent with models where w > -0.8 or w < -2/3 at 95% confidence level. This result agrees well with previous analyses based on other techniques. \n \n The results presented here are derived from the WMAP 5-year temperature map  1  , combined with measurements of galaxy clustering  2  . They are also compatible with recent results obtained independently by the Planck satellite  3  .\n \n \n Our analysis shows that it will soon become possible to use the observed shape of the primordial power spectrum as a powerful probe into the physics of early-universe cosmology.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Limits on primordial power spectrum resolution : An inflationary flow assessment . Abstract : We present an better method for evaluating the primordial power spectrum in terms of its underlying physical factors , using the method of flow equations to evolve the first conditions through the entirety of cosmic time .We see that this methodology can be used to place limits on the values of these parameters by using theoretical estimates with observations of large - scale structure and CMB anisotropies . In particular we find that the present data is consistent with a flat universe dominated by black radiation ( w = - 1 ) , but inconsistent with models where w > - 0 . 8 or w < - 2 / 3 at 95 % confidence rate .This result agrees well with previous analyses based on other techniques . The results presented here are derived from the WMAP 5 - year temperature diagram 1 , combined with observations of galaxy clustering 2 .They are also consistent with recent results derived independently by the Planck satellite 3 . Our study shows that it will soon become able to use the seen shape of the primordial power spectrum as a powerful probe into the physics of early - universe cosmology .",
        "rewrite_text": "We introduce an enhanced approach for assessing the primordial power spectrum by examining its fundamental physical parameters through the application of flow equations, which allow us to trace the initial conditions across the entire span of cosmic time. This innovative methodology enables us to establish constraints on these parameters by integrating theoretical predictions with empirical data from large-scale structure observations and cosmic microwave background (CMB) anisotropies. Our findings indicate that current observational data supports a flat universe predominantly influenced by dark energy with an equation of state parameter \\( w = -1 \\). Conversely, our analysis reveals inconsistencies with models where \\( w > -0.8 \\) or \\( w < -\\frac{2}{3} \\) at a 95% confidence level. These conclusions align closely with previous studies utilizing alternative analytical techniques. The results presented in this work are derived from the WMAP five-year temperature data, in conjunction with galaxy clustering observations. Furthermore, our findings are corroborated by recent independent analyses conducted by the Planck satellite. This research underscores the potential of utilizing the observed shape of the primordial power spectrum as a significant tool for probing the physics of early-universe cosmology, paving the way for deeper insights into the fundamental processes that shaped our universe. As we refine our methods and gather more data, we anticipate that our understanding of the primordial power spectrum will evolve, offering new avenues for exploration in cosmological research.",
        "ori-fast-z-score": 1.8905706613989794,
        "water-fast-z-score": 5.742855749264711,
        "rewrite-fast-z-score": 0.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Haunted Halos of Andromeda and Triangulum: A panorama of galaxy formation in action .\nAbstract:\nWe present the first panoramic view of the distribution of galaxies around two massive clusters at redshifts z = 0.4-0.6, using deep near-infrared imaging with WFC3 on HST. The data reveal an extended population of faint galaxies surrounding each cluster that is not seen in optical images. We find that these galaxies are predominantly blue (with median color u − g = -0.5), have low stellar masses (10^9 Msun/pc^2) and high specific star formation rates (sSFR ~ 10^-2 Gyr-1). These properties suggest they represent a recently assembled population of star-forming dwarf galaxies that were accreted by their host clusters during recent mergers. In addition to this diffuse component we also identify several dozen bright galaxies within 1 Mpc of both clusters which appear to be undergoing rapid bursts of star formation triggered by interactions between infalling gas-rich galaxies and the hot intracluster medium.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Haunted Halos of Andromeda and Triangulum : A panorama of galaxy formation in action . Abstract : We present the first panoramic study of the distribution of clusters around two huge clusters at redshifts z = 0 . 4 - 0 . 6 , using deep near - infrared imaging with WFC3 on HST .The data reveal an extended population of faint clusters surrounding each cluster that is not seen in optical images . We see that these objects are typically blue ( with median color u − k = - 0 . 5 ) , have poor stellar masses ( 10 ^ 9 Msun / pc ^ 2 ) and large particular galaxy formation rates ( sSFR ~ 10 ^ - 2 Gyr - 1 ) .These properties suggest they represent a recently assembled colony of star - creating dwarf stars that were accreted by their host clusters during later mergers . In addition to this diffuse component we also identify several hundred bright stars within 1 Mpc of both clusters which appear to be experiencing rapid bursts of galaxy formation followed by interactions between infalling gas - rich galaxies and the hotter intracluster medium .",
        "rewrite_text": "We present a comprehensive panoramic analysis of the cluster distribution surrounding two massive clusters at redshifts z = 0.4 - 0.6, utilizing deep near-infrared imaging conducted with the Wide Field Camera 3 (WFC3) on the Hubble Space Telescope (HST). This study uncovers an extensive population of faint clusters that are not detectable in optical images, highlighting the limitations of traditional observational methods. Our findings indicate that these faint clusters predominantly exhibit blue colors, with a median color of u - k = -0.5, and possess relatively low stellar masses, approximately 10^9 M☉/pc². Furthermore, they demonstrate significant specific star formation rates (sSFR ~ 10^-2 Gyr^-1), suggesting that these clusters are likely composed of recently formed dwarf galaxies that have been accreted by their host clusters during subsequent merger events. \n\nIn addition to the diffuse population of faint clusters, our analysis identifies several hundred bright galaxies located within 1 Mpc of both massive clusters. These bright galaxies appear to be undergoing rapid bursts of star formation, which are likely driven by interactions between infalling gas-rich galaxies and the hotter intracluster medium. This dynamic environment fosters conditions conducive to intense star formation, providing valuable insights into the processes governing galaxy formation and evolution in the context of cluster dynamics. Overall, our study sheds light on the intricate interplay between galaxy formation and cluster evolution, offering a unique perspective on the ongoing processes that shape the cosmic landscape of the Andromeda and Triangulum galaxies.",
        "ori-fast-z-score": -0.10976425998969035,
        "water-fast-z-score": 5.158920219515446,
        "rewrite-fast-z-score": 1.3525044520011484
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The Discovery of an Active Galactic Nucleus in the Late-type Galaxy NGC 3621: Spitzer Spectroscopic Observations .\nAbstract:\nWe report on infrared spectroscopic observations with the Infrared Spectrograph (IRS) aboard the Spitzer Space Telescope toward the nearby late-type galaxy NGC 3621, which is known to harbor a supermassive black hole at its center. The IRS spectrum shows prominent emission lines such as  Ne II 12.81 and  S III 18.71 µm that are commonly seen in active galactic nuclei (AGNs). We find that these emission lines can be reproduced by photoionization models using AGN-like ionizing radiation fields. From the observed line ratios we estimate the electron density n e = 10 3 cm −3 , temperature T e = 1000 K, and ionization parameter U H = 1 × 10 −2 . These results suggest that the central region of NGC 3621 has properties similar to those found for Seyfert galaxies. This work was supported by NASA through grant number GO-08460.01-A awarded by the Jet Propulsion Laboratory, California Institute of Technology under contract with NASA.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The Discovery of an Active Galactic Nucleus in the Late - class Galaxy NGC 3621 : Spitzer Spectroscopic Observations . Abstract : We report on infrared spectroscopic observations with the Infrared Spectrograph ( IRS ) aboard the Spitzer Space Telescope toward the nearby mid - class galaxy NGC 3621 , which is known to harbor a supermassive black hole at its core .The IRS spectrum displays large emitted lines such as Ne II 12 . 81 and S III 18 . 71 µm that are often saw in active galactic nuclei ( AGNs ) . We see that these absorption patterns can be reproduced by photoionization models using AGN - like ionizing radiation fields .From the known line ratios we estimate the electron concentration n e = 10 3 cm −3 , temperature T e = 1000 K , and ionization variable U H = 1 × 10 −2 . These data suggest that the central region of NGC 3621 has properties similar to those known for Seyfert galaxies .This work was supported by NASA through grant number GO - 08460 . 01 - A awarded by the Jet Propulsion Laboratory , California Institute of Technology under contract with NASA .",
        "rewrite_text": "We present our findings from infrared spectroscopic observations conducted with the Infrared Spectrograph (IRS) on the Spitzer Space Telescope, focusing on the nearby mid-class galaxy NGC 3621, which is recognized for hosting a supermassive black hole at its center. The IRS spectrum reveals prominent emission lines, including Ne II at 12.81 µm and S III at 18.71 µm, which are characteristic of active galactic nuclei (AGNs). Our analysis indicates that the observed absorption features can be effectively modeled using photoionization techniques that incorporate AGN-like ionizing radiation fields. By examining the line ratios, we derive key physical parameters of the central region of NGC 3621, including an electron density of n_e = 10^3 cm^−3, an electron temperature of T_e = 1000 K, and an ionization parameter U_H = 1 × 10^−2. These findings imply that the characteristics of NGC 3621's core are comparable to those typically associated with Seyfert galaxies, suggesting that it may exhibit similar active galactic nucleus behavior. This research was made possible through funding from NASA, specifically grant number GO-08460.01-A, awarded by the Jet Propulsion Laboratory at the California Institute of Technology under a contract with NASA. Our results contribute to the growing body of evidence regarding the nature of active galactic nuclei in late-type galaxies and enhance our understanding of the relationship between supermassive black holes and their host galaxies.",
        "ori-fast-z-score": -0.25,
        "water-fast-z-score": 3.9056328877620143,
        "rewrite-fast-z-score": 1.0
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Arc-like distribution of high CO(J=3-2)/CO(J=1-0) ratio gas surrounding the central star cluster of the supergiant HII region NGC 604 .\nAbstract:\nWe present new observations of the molecular line emission in the vicinity of the massive young open cluster Westerlund 1 (Wd-1). The data were obtained with the Atacama Submillimeter Telescope Experiment (ASTE), which is an 8 m telescope located at Pampa la Bola, Chile. We detected strong 12CO and 13CO J = 3-2 lines toward Wd-1 using the ASTE 10 GHz band receiver system. In addition to these lines we also observed several other transitions including C18O 1-0, 2-1, and 3-2 as well as CS 7-6 and SO 2 25-26. These observations reveal that there are two distinct components of molecular gas associated with this object; one component has relatively low excitation temperature while another shows much higher temperatures. This latter component appears to be distributed along an arc-like structure around the central star cluster. Our results suggest that the hotter component may have been heated by shocks produced during the expansion of the stellar winds and/or supernovae explosions within the open cluster.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Arc - like flow of high CO ( J = 3 - 2 ) / CO ( J = 1 - 0 ) ratio gas surrounding the main star cluster of the supergiant HII area NGC 604 . Abstract : We report new studies of the molecular line emission in the vicinity of the huge young open cluster Westerlund 1 ( Wd - 1 ) .The data were obtained with the Atacama Submillimeter Telescope Experiment ( ASTE ) , which is an 8 m observatory situated at Pampa la Bola , Chile . We observed strong 12CO and 13CO J = 3 - 2 lines toward Wd - 1 using the ASTE 10 GHz band receiver network .In addition to these lines we also observed numerous other transitions namely C18O 1 - 0 , 2 - 1 , and 3 - 2 as well as CS 7 - 6 and SO 2 25 - 26 . These measurements reveal that there are two different components of molecular gas associated with this object ; one component has relatively high excitation temperature while another shows significantly greater temperatures .This latter component appears to be spread along an arc - like structure around the main star cluster . Our results propose that the hotter component may have been heated by shocks created during the surge of the stellar winds and / or supernovae explosions within the open cluster .",
        "rewrite_text": "**Title:** Arc-like Flow of High CO (J = 3 - 2) / CO (J = 1 - 0) Ratio Gas Surrounding the Main Star Cluster of the Supergiant HII Region NGC 604\n\n**Abstract:** In this study, we present new findings on the molecular line emission in the vicinity of the massive young open cluster Westerlund 1 (Wd-1). The observations were conducted using the Atacama Submillimeter Telescope Experiment (ASTE), an 8-meter telescope located at Pampa la Bola, Chile. Our analysis focused on the strong emissions of the 12CO and 13CO J = 3 - 2 lines directed toward Wd-1, utilizing the ASTE's 10 GHz band receiver network. In addition to these primary lines, we detected several other molecular transitions, including C18O (1 - 0, 2 - 1, and 3 - 2), CS (7 - 6), and SO (2 25 - 26). \n\nThe data reveal the presence of two distinct components of molecular gas associated with Wd-1. One component exhibits a relatively high excitation temperature, while the other displays significantly elevated temperatures. Notably, the hotter component is distributed along an arc-like structure encircling the main star cluster. Our findings suggest that this hotter gas may have been thermally influenced by shocks generated from the intense stellar winds and supernova explosions occurring within the open cluster. This research enhances our understanding of the dynamic processes at play in regions of massive star formation and the interactions between stellar activity and the surrounding molecular gas. The implications of these results contribute to the broader knowledge of star cluster evolution and the physical conditions within supergiant HII regions like NGC 604.",
        "ori-fast-z-score": -1.091089451179962,
        "water-fast-z-score": 3.579352554007827,
        "rewrite-fast-z-score": 0.5940885257860046
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Chemical Properties of Star Forming Dwarf Galaxies .\nAbstract:\nWe present the chemical properties (metallicity, abundance ratios) for a sample of dwarf galaxies in the Local Volume with known distances and star formation histories. We use high quality spectra obtained at the Apache Point Observatory to derive oxygen abundances using both direct T e method as well as strong-line methods calibrated on H II regions in nearby spiral galaxies.  The derived metallicities range between 12+log(O/H)=7.6-8.2 dex. These values are consistent with those found by previous studies based on optical spectroscopy. In addition we find that most of these dwarfs have supersolar N/O ratio indicating recent or ongoing nitrogen enrichment due to massive stars. This is also supported by their low SFRs which prevent efficient dilution of the enriched gas produced by supernovae type Ia. Finally, we compare our results with theoretical predictions made by different chemical evolution models. Our analysis shows that none of them can reproduce simultaneously all observed quantities such as metallicity, N/O ratio and sSFR.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Chemical Properties of Star Forming Dwarf Galaxies . Abstract : We report the chemical properties ( metallicity , abundance proportions ) for a sample of dwarf stars in the Local Volume with established distances and galaxy formation histories .We use large performance spectra obtained at the Apache Point Observatory to derive gas abundances using both direct T e method as also as bright - line methods calibrated on H II regions in nearby spiral clusters . The derived metallicities range between 12 + log ( O / H ) = 7 . 6 - 8 . 2 dex .These ratios are compatible with those shown by earlier surveys based on optical spectroscopy . In addition we find that most of these dwarfs have supersolar N / O ratio indicating previous or ongoing nitrogen enrichment due to massive stars .This is also supported by their low SFRs which reduce efficient dilution of the enriched fuel produced by supernovae class Ia . Finally , we compare our findings with theoretical estimates made by various chemical evolution models .Our study shows that none of them can generate simultaneously all observed components such as metallicity , N / O ratio and sSFR .",
        "rewrite_text": "We present an in-depth analysis of the chemical properties, specifically metallicity and abundance ratios, of a selected sample of dwarf galaxies located within the Local Volume. This study utilizes high-resolution spectral data acquired from the Apache Point Observatory, allowing us to accurately determine gas abundances through both the direct electron temperature (T_e) method and bright-line techniques calibrated against H II regions in nearby spiral galaxies. Our findings reveal that the metallicities of these dwarf galaxies vary within the range of 12 + log (O/H) = 7.6 to 8.2 dex, which aligns well with results from previous optical spectroscopy surveys. Notably, we observe that a majority of these dwarf galaxies exhibit supersolar nitrogen-to-oxygen (N/O) ratios, suggesting a history of nitrogen enrichment likely linked to the influence of massive stars. This enrichment is further corroborated by the galaxies' low star formation rates (SFRs), which limit the dilution of the enriched material produced by Type Ia supernovae. To contextualize our results, we compare our observations with predictions from various chemical evolution models. Our analysis indicates that none of these models can adequately account for all observed characteristics, including metallicity, N/O ratios, and specific star formation rates (sSFR), simultaneously. This discrepancy highlights the complexities involved in understanding the chemical evolution of dwarf galaxies and suggests that current models may require refinement to better align with empirical data. Overall, our study contributes valuable insights into the chemical evolution processes of dwarf galaxies, emphasizing the need for further investigation in this area of astrophysics.",
        "ori-fast-z-score": -1.078327732034384,
        "water-fast-z-score": 5.1759731137650435,
        "rewrite-fast-z-score": 0.5388159060803247
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Vaporization and Layering of Alkanols at the Oil/Water Interface .\nAbstract:\nThe vapor pressure, solubility in water, and interfacial tension between oil and water are important parameters for understanding the behavior of crude oils during their production or transport through pipelines.  In this study we have investigated these properties using alkanol monolayers on an aqueous subphase as model systems to mimic the hydrocarbon chains present in crude oils. The results show that the vapor pressures of the alkanols increase with chain length up to C8 but decrease again above C10. This is explained by considering the competition between two opposing effects:  On one hand, increasing chain lengths lead to higher molecular volumes which favor evaporation. On the other hand, longer chains also result in stronger van der Waals interactions within the liquid phase leading to lower vapor pressures. We find that the solubilities of the alkanols follow similar trends as those observed for the vapor pressures. However, the differences in solubility among different chain lengths become smaller when compared to the corresponding differences in vapor pressure. Finally, our measurements reveal that the interfacial tensions between the alkanol layers and the underlying water decreases monotonically with chain length.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Vaporization and Layering of Alkanols at the Oil / Water Interface . Abstract : The vapor tension , solubility in water , and interfacial tension between petroleum and water are important characteristics for studying the activity of crude oils during their production or delivery through pipelines .In this study we have researched these characteristics utilizing alkanol monolayers on an aqueous subphase as simulation structures to mimic the hydrocarbon chains present in crude oils . The results show that the vapor pressures of the alkanols increase with chain length up to C8 but decrease again above C10 .This is understood by considering the competition between two contrasting phenomena : On one hand , increasing chain lengths result to higher molecular volumes which favor evaporation . On the other hand , wider chains also lead in heavier van der Waals molecules within the liquid phase leading to smaller liquid pressures .We see that the solubilities of the alkanols follow similar trends as those observed for the liquid pressures . However , the differences in solubility among different chain lengths become smaller when compared to the associated changes in vapor tension .Finally , our measurements reveal that the interfacial pressures between the alkanol sheets and the underlying water reduces monotonically with chain length .",
        "rewrite_text": "**Title:** Vaporization and Layering of Alkanols at the Oil/Water Interface\n\n**Abstract:** Understanding the vapor tension, solubility in water, and interfacial tension between petroleum and water is crucial for analyzing the behavior of crude oils during production and transportation through pipelines. This study investigates these properties by employing alkanol monolayers on an aqueous subphase as analogs for the hydrocarbon chains found in crude oils. Our findings indicate that the vapor pressures of alkanols increase with chain length up to C8, after which they decline for chains longer than C10. This behavior can be attributed to the interplay between two opposing factors: the increase in molecular volume with longer chains, which promotes evaporation, and the presence of larger van der Waals forces in heavier molecules that contribute to lower liquid pressures. The solubility patterns of the alkanols exhibit trends similar to those of vapor pressures, although the variations in solubility across different chain lengths are less pronounced compared to the changes in vapor tension. Furthermore, our measurements demonstrate that the interfacial pressures between the alkanol layers and the underlying water decrease consistently with increasing chain length. These insights enhance our understanding of the physical properties of alkanols at the oil/water interface and their implications for the behavior of crude oils, providing valuable information for optimizing production and transportation processes. The results of this study contribute to the broader field of petroleum science by elucidating the complex interactions at the molecular level that influence the performance of crude oils in various environmental conditions.",
        "ori-fast-z-score": -0.10153461651336192,
        "water-fast-z-score": 5.656854249492381,
        "rewrite-fast-z-score": 0.4622501635210242
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The nature of a broad line radio galaxy: Simultaneous RXTE and Chandra HETG observations of 3C 382 .\nAbstract:\nWe present the results of simultaneous X-ray (Chandra) and radio (RXTE )observations of the Broad Line Radio Galaxy, 3C382 . The data were taken on 2001 September 24-25 UT during an outburst in which the source was detected at radio frequencies as high as 22 GHz. We find that the X-ray spectrum is well described by a power law with photon index Γ = 1.7 ± 0.1 modified by photoelectric absorption consistent with N_H = 2 x 1022 cm-2. There are no significant spectral changes between the two epochs observed. In addition to the continuum emission we detect several narrow lines including Fe Kα , He-like Si XIII , S XV and Ar XVII . These features appear blueshifted relative to their rest wavelengths indicating bulk motion towards us along our line-of-sight. Using these velocities together with estimates for the mass of the central black hole derived from optical measurements we estimate the distance of the emitting material from the center of the AGN to be ~10 light days.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The nature of a broad line radio galaxy : Simultaneous RXTE and Chandra HETG measurements of 3C 382 . Abstract : We report the conclusion of simultaneous X - ray ( Chandra ) and radio ( RXTE ) observations of the Broad Line Radio Galaxy , 3C382 .The data were took on 2001 September 24 - 25 UT during an outburst in which the origin was seen at radio altitudes as long as 22 GHz . We see that the X - ray spectrum is well described by a power law with photon index Γ = 1 . 7 ± 0 . 1 augmented by photoelectric absorbed consistent with N _ H = 2 x 1022 centimetres - 2 .There are no considerable brightness variations between the two epochs observed . In addition to the continuum emission we find various narrow lines including Fe Kα , He - like Si XIII , S XV and Ar XVII .These features appear blueshifted relative to their rest wavelengths suggesting bulk movement towards us along our line - of - seeing . Using these velocities together with predictions for the mass of the central black hole derived from optical calculations we estimate the distance of the emitting substance from the center of the AGN to be ~ 10 light years .",
        "rewrite_text": "We present the findings from simultaneous X-ray (Chandra) and radio (RXTE) observations of the Broad Line Radio Galaxy 3C 382, conducted on September 24-25, 2001, during a notable outburst that was detectable at radio frequencies up to 22 GHz. Our analysis reveals that the X-ray spectrum can be accurately characterized by a power law with a photon index of Γ = 1.7 ± 0.1, which is further modified by photoelectric absorption consistent with a column density of N_H = 2 x 10^22 cm^-2. Notably, we observed no significant brightness variations between the two epochs of observation. In addition to the continuum emission, we identified several narrow emission lines, including Fe Kα, He-like Si XIII, S XV, and Ar XVII. These spectral features exhibit a blueshift relative to their rest wavelengths, indicating a bulk motion directed towards us along our line of sight. By utilizing the measured velocities of these lines in conjunction with mass estimates of the central black hole derived from optical studies, we estimate that the emitting region is located approximately 10 light years from the active galactic nucleus (AGN). This study enhances our understanding of the physical processes occurring in broad line radio galaxies and provides valuable insights into the dynamics of material in proximity to supermassive black holes.",
        "ori-fast-z-score": -1.0256451881367414,
        "water-fast-z-score": 4.444462481925879,
        "rewrite-fast-z-score": -0.953998092005724
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Quantum theory of exciton-photon coupling in photonic crystal slabs with embedded quantum wells .\nAbstract:\nWe present an exact solution for the eigenstates and eigenvalues of a system consisting of a two-dimensional (2D) periodic array of semiconductor quantum dots coupled to a one-dimensional (1D) chain of identical quantum dots, which are both embedded into a 2D photonic crystal slab. The 1D chain is assumed to be driven by external laser fields at two different frequencies. We show that this structure can support bound states where photons are trapped between neighboring quantum dots along the 1D chain due to strong light-matter interaction mediated by excitons confined within each dot. These results may have important implications on future designs of optoelectronic devices based on hybrid structures combining semiconductors and photonics. In recent years there has been growing interest in developing novel optical materials and devices using nanostructures such as semiconductor quantum dots (QDs), nanowires or carbon nanotubes  1  . This research effort has led to the development of new concepts in optics including QD lasers  2  , single photon sources  3  , and QD-based solar cells  4  .\nIn particular, QDs offer unique advantages over conventional bulk semiconductor systems because they allow controllable tuning of their electronic properties through size engineering  5  . Moreover, it was recently shown  6  that these artificial atoms can also exhibit interesting nonlinear optical effects  7, 8  . For example, when excited by intense laser pulses, QDs can generate coherent emission of multiple photons  9  . However, despite significant progress made during last decade, many fundamental questions remain unanswered about how QDs interact with electromagnetic radiation  10  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Quantum theory of exciton - photon correlation in photonic crystal slabs with integrated quantum wells . Abstract : We present an precise answer for the eigenstates and eigenvalues of a system consisting of a two - dimensional ( 2D ) periodic array of semiconductor quantum dots coupled to a one - dimensional ( 1D ) chain of unrelated quantum dots , which are both embedded into a 2D photonic crystal slab .The 1D chain is predicted to be driven by external beam fields at two different frequencies . We see that this formation can support bound states where photons are locked between neighboring quantum dots along the 1D chain thanks to powerful light - matter collision mediated by excitons enclosed within each dot .These data may have important implications on future development of optoelectronic products based on hybrid structures combining semiconductors and photonics . In past decades there has been growing interest in building new electronic materials and devices using nanostructures such as semiconductor quantum dots ( QDs ) , nanowires or silicon nanotubes 1 .This research effort has led to the development of new concepts in optics including QD lasers 2 , multi photon sources 3 , and QD - based solar systems 4 . In particular , QDs offer distinct advantages over traditional bulk semiconductor systems because they allow controllable tuning of their electronic properties through size engineering 5 .Moreover , it was recently shown 6 that these artificial atoms can also display exciting nonlinear optical phenomena 7 , 8 . For instance , when excited by intense laser pulses , QDs can generate coherent emission of multiple photons 9 .However , despite considerable progress made during final decade , many fundamental questions remain unanswered about how QDs behave with electromagnetic radiation 10 .",
        "rewrite_text": "**Title:** Quantum Theory of Exciton-Photon Correlation in Photonic Crystal Slabs with Integrated Quantum Wells\n\n**Abstract:** In this study, we provide a comprehensive analysis of the eigenstates and eigenvalues associated with a system comprising a two-dimensional (2D) periodic arrangement of semiconductor quantum dots (QDs) that are coupled to a one-dimensional (1D) chain of distinct quantum dots, all embedded within a 2D photonic crystal slab. The 1D chain is theorized to be influenced by external beam fields operating at two separate frequencies. Our findings reveal that this configuration can support bound states, wherein photons become localized between adjacent quantum dots along the 1D chain, facilitated by robust light-matter interactions mediated by excitons contained within each dot. These insights hold significant potential for advancing the development of optoelectronic devices that integrate semiconductor and photonic technologies. \n\nOver recent decades, there has been an increasing focus on the fabrication of novel electronic materials and devices utilizing nanostructures such as semiconductor quantum dots, nanowires, and silicon nanotubes. This research trajectory has led to innovative concepts in optics, including quantum dot lasers, multiphoton sources, and quantum dot-based solar cells. Quantum dots, in particular, present unique advantages over conventional bulk semiconductor systems, primarily due to their ability to finely tune electronic properties through size manipulation. Additionally, recent studies have demonstrated that these artificial atoms can exhibit remarkable nonlinear optical phenomena. For example, under intense laser pulse excitation, quantum dots can produce coherent emissions of multiple photons. Nevertheless, despite the significant advancements made in the past decade, numerous fundamental questions regarding the interaction of quantum dots with electromagnetic radiation remain unresolved. This work aims to address some of these questions and contribute to the understanding of exciton-photon correlations in advanced photonic structures.",
        "ori-fast-z-score": -0.42717882885838043,
        "water-fast-z-score": 5.8525036147918,
        "rewrite-fast-z-score": 0.2491364395612199
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Formation and Collapse of Quiescent Cloud Cores Induced by Dynamic Compressions .\nAbstract:\nWe present numerical simulations to study the formation, evolution, and collapse of quiescent cloud cores induced by dynamic compressions in turbulent molecular clouds. We find that these cloud cores are formed through shock compression at intersections between shocks driven into the clouds by supersonic turbulence. The cloud core masses range from 0.1 M⊙ to 1 M⊙ with typical sizes of about 1000 AU. These cloud cores have low internal velocities (< 2 km s-1) but can be accelerated up to 10 km s-1 during their lifetimes due to gravitational interactions with other dense clumps within the same clouds. Most of them evolve quasi-statically for several free-fall times before collapsing dynamically on time scales ranging from one to ten free-fall times. Our results suggest that such cloud cores may represent an important source of prestellar objects in star-forming regions. Keywords: Turbulence, Star Formation",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Formation and Collapse of Quiescent Cloud Cores Induced by Dynamic Compressions . Abstract : We present numerical simulations to study the formation , emergence , and failure of quiescent cloud cores induced by dynamic compressions in volatile molecular clouds .We see that these cloud cores are created through shock compression at intersections between shocks driven into the clouds by supersonic turbulence . The cloud core masses range from 0 . 1 [UNK] to 1 [UNK] with typical sizes of about 1000 AU .These cloud cores have minimal internal velocities ( < 2 km s - 1 ) but can be advanced up to 10 km s - 1 during their lifetimes due to gravitational interactions with other dense clumps within the same skies . Most of them evolve quasi - statically for numerous free - fall times before exploding dynamically on time ranges ranging from one to ten free - fall times .Our results show that such cloud cores might represent an important source of prestellar objects in star - creating areas . Keywords : Turbulence , Star Formation",
        "rewrite_text": "Title: Formation and Collapse of Quiescent Cloud Cores Induced by Dynamic Compressions\n\nAbstract: In this study, we utilize numerical simulations to investigate the processes involved in the formation, development, and eventual collapse of quiescent cloud cores that are triggered by dynamic compressions within volatile molecular clouds. Our findings indicate that these cloud cores are formed through shock compression at the points where shocks, generated by supersonic turbulence, intersect within the clouds. The masses of the resulting cloud cores vary between 0.1 and 1 solar mass, with typical dimensions around 1000 astronomical units (AU). Although these cores exhibit low internal velocities, generally less than 2 km/s, they can experience significant acceleration, reaching speeds of up to 10 km/s, due to gravitational interactions with other dense clumps in their vicinity. The majority of these cloud cores undergo a quasi-static evolution over several free-fall times before experiencing a dynamic explosion, which occurs over time scales ranging from one to ten free-fall times. Our results suggest that these quiescent cloud cores may play a crucial role as a significant source of prestellar objects in regions conducive to star formation. This research enhances our understanding of the mechanisms behind star formation and the role of turbulence in the evolution of molecular clouds. \n\nKeywords: Turbulence, Star Formation",
        "ori-fast-z-score": 0.23570226039551587,
        "water-fast-z-score": 3.5355339059327378,
        "rewrite-fast-z-score": 0.30779350562554625
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Dynamic Screening in a Two-Species Asymmetric Exclusion Process .\nAbstract:\nWe study the dynamics of an asymmetric exclusion process with two species on a ring, where particles can hop to their right or left neighboring site and are subject to hard-core repulsion. We show that for any initial condition there exists a unique stationary state which is characterized by a density profile depending only on the distance between sites. In particular we find that this profile decays exponentially fast as one moves away from the origin. This result implies that the system exhibits dynamic screening, i.e., correlations decay exponentially fast at large distances even though the underlying microscopic model does not have translational invariance. The proof relies on a combination of techniques from probability theory (in particular martingale methods) and functional analysis. Our results hold both for finite systems and infinite lattices. \nI. INTRODUCTORY REMARK\nIn recent years much attention has been devoted to studying nonequilibrium steady states of driven lattice gases  1  . These models describe interacting particle systems evolving according to stochastic rules such that detailed balance cannot be satisfied globally  2  , but nevertheless they exhibit interesting macroscopic behavior  3  .\nOne class of these models consists of so-called exclusion processes  4  describing particles moving along a regular lattice under mutual exclusion constraints  5  . For example, consider a chain of L sites labeled by integers 1, ..., L, each occupied by either zero or one particle. Particles may jump to the right or left neighboring site provided it is empty  6  . If all jumps occur independently then the resulting Markov process satisfies detailed balance with respect to some product measure  7, 8  . However if the rates depend on the number of particles occupying adjacent sites  9  then detailed balance breaks down  10  . Despite this lack of equilibrium properties many of these models still display non-trivial features reminiscent of those observed in thermal equilibrium  11  .",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Dynamic Screening in a Two - Species Asymmetric Exclusion Process . Abstract : We research the dynamics of an asymmetric exclusion cycle with two organisms on a ring , where ions can jump to their right or left neighboring area and are subject to rough - core repulsion .We see that for any initial condition there exists a unique stationary state which is characterized by a density profile depending only on the distance between locations . In particular we find that this profile decays exponentially rapidly as one moves away from the origin .This result means that the process exhibits dynamic monitoring , i . e . , correlations decay exponentially rapidly at large distances even though the underlying microscopic description does not have translational invariance . The proof uses on a combination of techniques from likelihood analysis ( in instance martingale models ) and functional analysis .Our results hold both for finite systems and infinite lattices . I .INTRODUCTORY REMARK In past decades considerable focus has been focused to researching nonequilibrium steady states of driven lattice gases 1 . These systems depict interacting particle structures arising according to stochastic laws such that detailed balance cannot be satisfied globally 2 , but still they show exciting macroscopic behavior 3 .One class of these models includes of so - called exclusion mechanisms 4 describing particles moving along a regular lattice under mutual exclusion constraints 5 . For instance , consider a network of L locations labeled by integers 1 , . . . , L , each inhabited by either zero or one particle .Particles must drop to the right or left neighboring area provided it is vacant 6 . If all jumps happen independently then the resulting Markov process satisfies detailed balance with regard to some product measure 7 , 8 .However if the rates depend on the quantity of molecules occupying adjoining sites 9 then detailed balance breaks down 10 . Despite this lack of equilibrium properties many of these models still display non - simple details resembling of those observed in heat equilibrium 11 .",
        "rewrite_text": "**Title:** Dynamic Screening in a Two-Species Asymmetric Exclusion Process\n\n**Abstract:** This study investigates the dynamics of an asymmetric exclusion process involving two species of particles on a circular lattice. In this model, particles can jump to adjacent sites either to the left or right while experiencing a rough-core repulsion that prevents them from occupying the same space. Our findings reveal that, regardless of the initial configuration of particles, there exists a unique stationary state characterized by a density profile that is solely dependent on the distance from a reference point. Notably, this density profile exhibits an exponential decay as one moves away from the origin, indicating that the system demonstrates dynamic monitoring. This phenomenon suggests that correlations between particle positions diminish exponentially at large distances, despite the absence of translational invariance in the underlying microscopic dynamics. The proof of these results employs a blend of techniques from likelihood analysis, particularly within the context of martingale models, and functional analysis. Importantly, our conclusions are applicable to both finite systems and infinite lattices. \n\nIn recent decades, significant attention has been directed towards the study of nonequilibrium steady states in driven lattice gases. These systems are characterized by interacting particles that evolve according to stochastic rules, which preclude the satisfaction of detailed balance on a global scale. Nevertheless, they exhibit intriguing macroscopic behaviors. A prominent category within these models is the exclusion mechanism, where particles navigate a regular lattice under mutual exclusion constraints. For example, consider a lattice comprising L sites, each of which can be occupied by at most one particle. Particles are allowed to jump to adjacent vacant sites, either to the left or right. When these jumps occur independently, the resulting Markov process adheres to detailed balance with respect to a product measure. However, when the jump rates are influenced by the occupancy of neighboring sites, the detailed balance condition is violated. Despite this deviation from equilibrium, many of these models continue to display complex behaviors reminiscent of those found in equilibrium systems.",
        "ori-fast-z-score": 0.15617376188860607,
        "water-fast-z-score": 8.537655782769662,
        "rewrite-fast-z-score": 1.0182385849843445
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Spatial separation of small and large grains in the transitional disk around the young star IRS 48 .\nAbstract:\nWe present new near-infrared (NIR) polarimetric observations of the Herbig Ae star HD 142527, which reveal that its circumstellar dust is composed of two distinct populations with different grain sizes. The polarization degree decreases rapidly towards longer wavelengths at all positions along our slit except for one position where it increases again between 2.2 and 3.8 microns. We interpret this as evidence for an inner hole in the distribution of larger grains. This interpretation is supported by SED modeling using radiative transfer calculations including scattering off spherical particles. Our results suggest that the outer edge of the gap lies within 0.1 AU of the central star. In addition to the NIR data presented here we also obtained mid-infrared (MIR) spectro-polarimetry covering the wavelength range 5-20 micron. These data show no significant change in the polarization degree across the MIR bands indicating that there are no strong changes in the optical properties of the dust grains on these scales.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Spatial splitting of tiny and large grains in the transitional disk around the early star IRS 48 . Abstract : We report new near - infrared ( NIR ) polarimetric discoveries of the Herbig Ae star HD 142527 , which confirm that its circumstellar dust is composed of two separate populations with varying grain sizes .The polarization degree reduces rapidly towards faster wavelengths at all positions along our slit except for one position where it rises again between 2 . 2 and 3 . 8 microns . We interpret this as proof for an inner hole in the distribution of bigger grains .This interpretation is backed by SED modeling using radiative transfer calculations including scattering off spherical objects . Our results show that the outer edge of the gap exists within 0 . 1 AU of the main star .In addition to the NIR data provided here we also produced mid - infrared ( MIR ) spectro - polarimetry covering the frequency spectrum 5 - 20 micron . These data demonstrate no major shift in the polarization degree across the MIR groups implying that there are no strong changes in the optical properties of the dust grains on these scales .",
        "rewrite_text": "We present new near-infrared (NIR) polarimetric observations of the Herbig Ae star HD 142527, which reveal significant insights into the composition of its circumstellar dust. Our findings indicate the presence of two distinct populations of dust grains, characterized by differing sizes. Notably, we observe a rapid decrease in the degree of polarization across various positions along our observational slit as we move to shorter wavelengths. However, at one specific position, the polarization degree unexpectedly increases between 2.2 and 3.8 microns. This anomaly suggests the existence of an inner cavity in the distribution of larger grains surrounding the star. To support this interpretation, we conducted spectral energy distribution (SED) modeling utilizing radiative transfer calculations that account for scattering by spherical particles. The results of our modeling indicate that the outer boundary of this gap is located within 0.1 AU from the central star. Furthermore, we extended our investigation into the mid-infrared (MIR) range, performing spectro-polarimetry across the 5 to 20 micron spectrum. The MIR data reveal no significant variation in the degree of polarization among the different MIR groups, suggesting that the optical properties of the dust grains remain relatively stable across these wavelengths. Collectively, our findings enhance the understanding of grain size distribution and the spatial arrangement of dust in the transitional disk surrounding IRS 48, providing crucial insights into the processes governing dust evolution in protoplanetary environments.",
        "ori-fast-z-score": 0.9761870601839528,
        "water-fast-z-score": 6.539886462510548,
        "rewrite-fast-z-score": 1.9069251784911847
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Position-Velocity Diagrams for the Maser Emission coming from a Keplerian Ring .\nAbstract:\nWe present position-velocity diagrams (PVD) of masers in an accretion disk around a young stellar object, obtained with VLBI observations at 22 GHz and 43 GHz. The PVD are compared to those expected by models that include both rotation and radial motions. We find that our data can be explained if we assume that the emission comes from a ring-like structure located between 0.1 AU and 1 AU from the central star. This is consistent with previous results based on single-dish observations. Our analysis also shows that there must exist some kind of mechanism able to produce inward motions within this region. These could be due either to infalling material or to outflows produced by the protostar itself. Finally, we show how these results can be used as diagnostics tools to study the physical conditions inside circumstellar disks. Keywords: Accretion Disk, Circumstellar Disks, Infrared",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Position - Velocity Diagrams for the Maser Emission coming from a Keplerian Ring . Abstract : We create position - speed diagrams ( PVD ) of masers in an accretion disk around a young stellar object , obtained with VLBI studies at 22 GHz and 43 GHz .The PVD are compared to those expected by models that include both rotation and radial movements . We see that our information can be described if we suppose that the emission originates from a ring - like structure located between 0 . 1 AU and 1 AU from the main star .This is consistent with previous findings based on single - dish measurements . Our study also shows that there need possess some kind of mechanism able to produce inward motions within this area .These could be due either to infalling matter or to outflows created by the protostar itself . Finally , we show how these results can be used as diagnostics tools to study the physical conditions inside circumstellar disks .Keywords: Accretion Disk, Circumstellar Disks, Infrared",
        "rewrite_text": "Title: Position-Velocity Diagrams for Maser Emission from a Keplerian Ring\n\nAbstract: In this study, we present detailed position-velocity diagrams (PVDs) of maser emissions originating from an accretion disk surrounding a young stellar object, utilizing Very Long Baseline Interferometry (VLBI) observations at frequencies of 22 GHz and 43 GHz. Our analysis involves a comparative approach, juxtaposing the observed PVDs with theoretical models that account for both rotational and radial motions within the disk. The results indicate that the maser emissions can be effectively characterized by assuming their origin from a ring-like structure situated between 0.1 AU and 1 AU from the central star. This finding aligns with earlier research conducted through single-dish measurements, reinforcing the notion of a structured emission region. Furthermore, our investigation suggests the presence of a mechanism responsible for generating inward motions within this specific area of the disk. Potential explanations for these inward motions include the infall of material or outflows driven by the protostar itself. The implications of our findings extend beyond mere observation; we propose that these PVDs serve as diagnostic tools for probing the physical conditions prevalent within circumstellar disks. By understanding the dynamics at play, we can gain deeper insights into the processes governing accretion and the evolution of young stellar objects. This work contributes to the broader understanding of accretion disks and their role in star formation, highlighting the intricate interplay between various physical phenomena in these environments. \n\nKeywords: Accretion Disk, Circumstellar Disks, Infrared",
        "ori-fast-z-score": 0.36650833306891567,
        "water-fast-z-score": 4.764608329895903,
        "rewrite-fast-z-score": 1.1547005383792515
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Nanostructure and velocity of field-driven solid-on-solid interfaces moving under a phonon-assisted dynamic .\nAbstract:\nWe study the dynamics of an interface driven by a periodic external force in one dimension, using molecular dynamics simulations with Lennard-Jones particles at low temperatures (T = 0.1 − 1). We find that the interface moves as a whole when it is driven slowly enough; otherwise, it breaks into several segments which move independently. The number of segments increases with increasing driving frequency or decreasing temperature. In addition to these two regimes, we observe another regime where the interface exhibits stick-slip motion. This third regime occurs for intermediate values of the driving amplitude A and driving frequency f . For this regime, we show that there exists a scaling relation between the average velocity V , the driving frequency f , and the driving amplitude A: V ∝ Af 2 . Finally, we propose a simple model based on the concept of phonon-enhanced diffusion to explain our results. DOI: 10.1103/PhysRevE.77.020101",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Nanostructure and speed of field - driven solid - on - solid interfaces changing under a phonon - aided dynamic . Abstract : We research the dynamics of an interface pushed by a periodic external stress in one dimension , using polymer mechanics simulations with Lennard - Jones atoms at low temperatures ( T = 0 . 1 − 1 ) .We see that the interface moves as a whole when it is driven slowly sufficiently ; otherwise , it splits into numerous components which move independently . The amount of segments varies with varying drove frequency or decreasing temperature .In addition to these two regimes , we study another regime where the interface displays stick - slipping motion . This third regime happens for intermediate values of the driving frequency A and driving frequency f .For this regime , we show that there exists a scaling relation between the average velocity V , the driving frequency f , and the driving amplitude A : V [UNK] Af 2 . Finally , we propose a simple model based on the concept of phonon - enhanced diffusion to explain our results .DOI: 10.1103/PhysRevE.77.020101",
        "rewrite_text": "**Title:** Nanostructure and Speed of Field-Driven Solid-on-Solid Interfaces Changing Under a Phonon-Aided Dynamic\n\n**Abstract:** In this study, we investigate the dynamics of a one-dimensional interface subjected to periodic external stress, utilizing polymer mechanics simulations with Lennard-Jones atoms at low temperatures (T = 0.1 - 1). Our findings reveal that the interface exhibits collective movement when driven at sufficiently slow rates; however, at higher driving frequencies, it disintegrates into multiple segments that operate independently. The number of these segments is influenced by variations in the driving frequency and decreases in temperature. Beyond these two distinct regimes, we identify a third regime characterized by stick-slip motion, which emerges at intermediate values of both the driving frequency (f) and the driving amplitude (A). In this stick-slip regime, we establish a scaling relationship that connects the average velocity (V) of the interface to the driving frequency and amplitude, expressed as V ∝ A f². To elucidate our observations, we propose a straightforward model grounded in the concept of phonon-enhanced diffusion, which accounts for the interface dynamics under the influence of external stress. This research contributes to a deeper understanding of the behavior of solid-on-solid interfaces in response to external forces, with implications for material science and nanotechnology. The insights gained from this study may pave the way for future investigations into the manipulation of interface dynamics in various applications. DOI: 10.1103/PhysRevE.77.020101",
        "ori-fast-z-score": -0.8340576562282991,
        "water-fast-z-score": 3.6293309315564883,
        "rewrite-fast-z-score": 2.9162346919891515
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Stable oscillations of a predator-prey probabilistic cellular automaton: a mean-field approach .\nAbstract:\nWe study the dynamics of a probabilistic cellular automaton (PCA) with two species, prey and predators, which interact in an oscillatory way. The PCA is defined on a square lattice where each site can be occupied by at most one particle of either type. We show that for certain values of the parameters there are stable periodic solutions to this system. These results are obtained using a mean field approximation method. In particular we find that the periodicity depends only on the number of particles per unit area. This dependence agrees well with numerical simulations performed on finite lattices. Finally, we discuss how our model could be used as a simple description of population cycles observed in nature. Probabilistic cellular automata have been widely studied during recent years due to their potential applications in many fields such as physics  1  , biology  2  or computer science  3  . They consist of a set of cells arranged in some regular structure like a grid  4  whose state evolves according to local rules depending on its own state and those of its neighbors  5  .\nIn this work we consider a two-dimensional probabilistic cellular automaton  6  consisting of N sites located on a square lattice L = Z 2 . Each cell i ∈ L has four possible states denoted by 0, 1, 2 and 3 corresponding respectively to empty space, prey, predator and dead. At time t = 0 all sites are initialized randomly with probability p 0 = 1/4 of being vacant, p 1 = 1/2 of having a prey and p 2 = 1/4 of containing a predator. Then, the evolution rule consists of applying simultaneously the following transition probabilities between consecutive times t and t + 1:",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Stable oscillations of a hunter - predator probabilistic cellular automaton : a mean - field methodology . Abstract : We research the dynamics of a probabilistic cellular automaton ( PCA ) with two genera , prey and predators , which interact in an oscillatory way .The PCA is characterized on a square lattice where each site can be occupied by at most one particle of either type . We see that for specific values of the variables there are stable periodic solutions to this scheme .These conclusions are derived using a mean field approximation algorithm . In particular we find that the periodicity varies only on the quantity of particles per unit area .This dependence agrees well with numerical simulations conducted on finite lattices . Finally , we talk how our model could be used as a simple explanation of population trends occurring in nature .Probabilistic cellular automata have been widely explored during recent months thanks to their potential applications in different fields such as science 1 , biology 2 or computer science 3 . They comprise of a group of cells grouped in some regular structure like a network 4 whose state evolves due to local rules depending on its own state and those of its relatives 5 .In this research we study a two - dimensional probabilistic cellular automaton 6 comprised of N sites located on a square lattice L = Z 2 . Each cell i ∈ L has four possible states denoted by 0 , 1 , 2 and 3 equivalent respectively to empty space , prey , predator and dead .At point t = 0 all locations are initialized randomly with probability p 0 = 1 / 4 of being empty , p 1 = 1 / 2 of having a predators and p 2 = 1 / 4 of featuring a predator . Then , the evolution rule involves of using concurrently the following transfer probabilities between successive times t and t + 1 :",
        "rewrite_text": "**Title:** Stable Oscillations of a Hunter-Predator Probabilistic Cellular Automaton: A Mean-Field Methodology\n\n**Abstract:** This study investigates the dynamics of a probabilistic cellular automaton (PCA) that models the interactions between two species: prey and predators, exhibiting oscillatory behavior. The PCA operates on a square lattice, where each site can be occupied by a maximum of one individual from either species. Our findings reveal that under certain parameter values, the system exhibits stable periodic solutions. These results are obtained through a mean-field approximation approach, which simplifies the analysis of the complex interactions within the lattice. Notably, we observe that the periodicity of the oscillations is influenced solely by the density of particles per unit area, a relationship that aligns closely with numerical simulations performed on finite lattices.\n\nFurthermore, we discuss the implications of our model as a simplified framework for understanding population dynamics observed in natural ecosystems. The exploration of probabilistic cellular automata has gained momentum in recent months, owing to their versatile applications across various domains, including science, biology, and computer science. These systems consist of a collection of cells arranged in a regular structure, such as a network, where the state of each cell evolves according to local rules that depend on its own state and those of its neighboring cells.\n\nIn our research, we focus on a two-dimensional probabilistic cellular automaton comprising N sites arranged on a square lattice L = Z². Each cell, denoted as i ∈ L, can exist in one of four states: 0 (empty), 1 (prey), 2 (predator), and 3 (dead). Initially, at time t = 0, the lattice is populated randomly, with a probability of p₀ = 1/4 for empty sites, p₁ = 1/2 for prey, and p₂ = 1/4 for predators. The evolution of the system is governed by specific transfer probabilities that dictate the state transitions from time t to t + 1. This research contributes to the understanding of complex biological interactions and offers a foundational model for further studies in ecological dynamics.",
        "ori-fast-z-score": -1.3719886811400706,
        "water-fast-z-score": 6.627104836843802,
        "rewrite-fast-z-score": 1.1748539016153647
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Direct cosmological simulations of the growth of black holes and galaxies .\nAbstract:\nWe present results from direct cosmological hydrodynamic simulations that follow the formation of supermassive black holes (SMBHs) in galactic nuclei, their subsequent evolution through mergers with other SMBHs, and the associated feedback on galaxy properties. We find that:  The simulated SMBH mass function agrees well with observations at z = 0 for M• > 10^7M_solar.  At higher redshifts, our model predicts too many low-mass SMBHs compared to observational estimates based on quasar luminosity functions; this discrepancy may be due to uncertainties in the assumed duty cycle or radiative efficiency of quasars.  Our models predict an average Eddington ratio distribution that is consistent with observed distributions inferred from optical/UV emission lines.  In addition, we show that the predicted relation between BH mass and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Direct cosmological simulations of the development of blue holes and galaxies . Abstract : We report findings from direct cosmological hydrodynamic simulations that track the formation of supermassive black holes ( SMBHs ) in galactic nuclei , their successive evolution through mergers with other SMBHs , and the associated feedback on star dynamics .We see that : The simulated SMBH mass function agrees well with observations at z = 0 for M • > 10 ^ 7M _ solar . At higher redshifts , our model predicts too many small - mass SMBHs compared to observational projections based on quasar luminosity functions ; this discrepancy may be due to uncertainties in the expected duty cycle or radiative efficiency of quasars .Our models predict an estimated Eddington proportion distribution that is compatible with observed distributions inferred from optical / UV absorption lines . In addition , we prove that the expected relation between BH mass and bulge velocity dispersion agrees reasonably well with observations over four orders of magnitude in BH mass .",
        "rewrite_text": "We present the results of direct cosmological hydrodynamic simulations that investigate the formation and evolution of supermassive black holes (SMBHs) within galactic nuclei. Our study focuses on the processes involved in the growth of these black holes, including their mergers with other SMBHs, and the subsequent impact on stellar dynamics within their host galaxies. Our findings indicate that the mass function of simulated SMBHs aligns closely with observational data at redshift z = 0 for masses exceeding 10^7 solar masses. However, at higher redshifts, our model predicts an excess of low-mass SMBHs when compared to observational estimates derived from quasar luminosity functions. This discrepancy may stem from uncertainties related to the expected duty cycle or radiative efficiency of quasars, which warrants further investigation. Additionally, our simulations yield an estimated distribution of Eddington ratios that is consistent with observed distributions inferred from optical and ultraviolet absorption lines. Furthermore, we demonstrate that the anticipated correlation between black hole mass and bulge velocity dispersion is in reasonable agreement with observational data across four orders of magnitude in black hole mass. These results enhance our understanding of the complex interplay between SMBHs and their host galaxies, providing valuable insights into the mechanisms driving their formation and evolution in the universe.",
        "ori-fast-z-score": -1.162476387438193,
        "water-fast-z-score": 3.117691453623979,
        "rewrite-fast-z-score": 0.6255432421712244
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Detection of CFIRB with AKARI/FIS Deep Observations .\nAbstract:\nWe report the detection of cosmic far-infrared background (CFIRB) fluctuations using deep observations made by the Far Infrared Surveyor (FIS) onboard Akari satellite at 65 and 90 micron bands in the Lockman Hole field, which is one of the most sensitive fields for detecting extragalactic sources. The FIS has two photometric channels; N60 band covers 60 to 120 microns while WIDE-S channel covers 50 to 100 microns. We used data taken during the period between February 2005 and March 2007. After removing bright point-like objects detected by Spitzer/MIPS 24 micron survey, we performed aperture photometry on all remaining pixels within an area of 1 deg2 centered around the Lockman hole. To estimate the contribution from Galactic cirrus emission, we subtracted the median value of each pixel after applying a 3 sigma clipping method. Then we calculated power spectrum density (PSD) of the residual map. By fitting the PSD with a single power law model, we obtained the best-fit slope as -2.1 ± 0.3 at 65 micron and -1.9 ± 0.4 at 90 micron. These slopes are consistent with those expected from clustering properties of infrared galaxies.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Detection of CFIRB with AKARI / FIS Deep Observations . Abstract : We report the observation of cosmic far - infrared background ( CFIRB ) fluctuations using deep surveys made by the Far Infrared Surveyor ( FIS ) onboard Akari spacecraft at 65 and 90 micron bands in the Lockman Hole field , which is one of the most important areas for detecting extragalactic sources .The FIS has two photometric channels ; N60 band encompasses 60 to 120 microns while WIDE - S channel encompasses 50 to 100 microns . We utilized information taken during the period between February 2005 and March 2007 .After removing bright point - like items detected by Spitzer / MIPS 24 micron search , we performed aperture photometry on all remaining pixels within an area of 1 deg2 centered around the Lockman hole . To estimate the contribution from Galactic cirrus emission , we subtracted the median value of each pixel after applying a 3 sigma clipping method .Then we calculated power spectrum density ( PSD ) of the residual map . By fitting the PSD with a single power law description , we derived the best - fitting curve as - 2 . 1 ± 0 . 3 at 65 micron and - 1 . 9 ± 0 . 4 at 90 micron .These slopes are compatible with those expected from clustering qualities of infrared galaxies .",
        "rewrite_text": "In this study, we present our findings on the fluctuations of the cosmic far-infrared background (CFIRB) as observed through deep surveys conducted by the Far Infrared Surveyor (FIS) aboard the Akari spacecraft. Our observations were focused on the Lockman Hole field, a critical region for the detection of extragalactic sources, utilizing the 65 and 90 micron bands. The FIS instrument features two photometric channels: the N60 band, which covers wavelengths from 60 to 120 microns, and the WIDE-S channel, spanning 50 to 100 microns. The data analyzed in this research were collected between February 2005 and March 2007.\n\nTo refine our analysis, we first eliminated bright point-like sources identified through the Spitzer/MIPS 24 micron survey. Subsequently, we conducted aperture photometry on the remaining pixels within a 1 square degree area centered on the Lockman Hole. To account for the contribution of Galactic cirrus emission, we applied a 3 sigma clipping method to subtract the median value of each pixel. This process allowed us to isolate the fluctuations attributable to CFIRB.\n\nFollowing this, we computed the power spectrum density (PSD) of the residual map. By fitting the PSD data with a single power law model, we determined the best-fitting slopes to be -2.1 ± 0.3 at 65 microns and -1.9 ± 0.4 at 90 microns. These results are consistent with the expected clustering characteristics of infrared galaxies, suggesting that the observed CFIRB fluctuations are indeed influenced by the underlying distribution of these extragalactic sources. Our findings contribute to the understanding of the CFIRB and its implications for the study of galaxy formation and evolution in the universe.",
        "ori-fast-z-score": -0.23249527748763857,
        "water-fast-z-score": 3.670651741928988,
        "rewrite-fast-z-score": 2.2453655975512468
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Catalan s intervals and realizers of triangulations .\nAbstract:\nWe study the Catalan numbers in connection with the number of ways to realize a given triangulation as an ordered sequence of its diagonals, or equivalently, as a set of non-crossing diagonals. We show that this problem is related to counting certain types of Dyck paths. In particular we prove that for any positive integer n there are exactly C(n) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides. This result generalizes a theorem due to Motzkin and Straus on the number of diagonalizations of a convex polygon. \nIntroduction\n\nThe Catalan numbers count many combinatorial objects such as binary trees, noncrossing partitions, spanning trees, etc., see e.g.   1, 2  . The present work deals with another class of Catalan-like objects: triangulations of polygons (see Figure 1 ). A triangulation T of a simple polygon P is defined as follows: it consists of all edges of P together with some additional diagonals connecting pairs of vertices of P so that each interior angle of P becomes at least 90 degrees after adding these diagonals. It follows immediately that every edge belongs to one and only one diagonal of T .\nIn  3  , Motzkin and Straus  celebrated theorem states that if D denotes the set of diagonals of a convex polygon Q then |D| = 2|Q|. They also proved that the number of diagonalizations d(P ) of a convex polygon P equals the number of diagonals of a triangulation of P . \nIt was shown recently  4  that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the number of diagonals needed to diagonalize the quadrilateral. Thus, the following question arises naturally: What is the relationship between the number of diagonals required to diagonalize a convex quadrilateral and the number of diagonals used in a triangulation?",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Catalan s intervals and realizers of triangulations . Abstract : We research the Catalan numbers in connection with the number of ways to realize a given triangulation as an ordered sequence of its diagonals , or equivalently , as a group of non - crossing diagonals .We see that this question is related to counting particular kinds of Dyck paths . In particular we prove that for any positive integer n there are exactly C ( n ) different sequences of diagonals which can be realized by a convex quadrilateral having 2n sides .This result generalizes a theorem according to Motzkin and Straus on the number of diagonalizations of a convex polygon . Introduction The Catalan numbers count many combinatorial objects such as binary forests , noncrossing partitions , spanning trees , etc . , see e . g .1 , 2 . The present work deals with another class of Catalan - like structures : triangulations of polygons ( view Figure 1 ) .A triangulation T of a simple polygon P is characterized as follows : it consists of all edges of P together with some additional diagonals connecting pairs of vertices of P so that each interior angle of P becomes at least 90 degrees after adds these diagonals . It follows quickly that every edge belongs to one and only one diagonal of T .In 3 , Motzkin and Straus famous theorem holds that if D denotes the group of diagonals of a convex polygon Q then | D | = 2 | Q | . They also proved that the number of diagonalizations d ( P ) of a convex polygon P equals the number of diagonals of a triangulation of P .It was shown recently 4 that the number of diagonals in a triangulation of a convex quadrilateral is equal to four times the number of diagonals needed to diagonalize the quadrilateral . Thus , the following answer arises readily : What is the relationship between the number of diagonals needed to diagonalize a convex quadrilateral and the number of diagonals used in a triangulation ?",
        "rewrite_text": "**Title:** Catalan's Intervals and Realizers of Triangulations\n\n**Abstract:** This study explores the relationship between Catalan numbers and the various methods of representing a given triangulation through ordered sequences of its diagonals, or equivalently, as collections of non-crossing diagonals. We establish a connection between this inquiry and the enumeration of specific types of Dyck paths. Our main result demonstrates that for any positive integer \\( n \\), there exist precisely \\( C(n) \\) distinct sequences of diagonals that can be realized by a convex polygon with \\( 2n \\) sides. This finding extends the classical theorem by Motzkin and Straus regarding the number of diagonalizations of a convex polygon. \n\nThe Catalan numbers are known to enumerate a wide range of combinatorial structures, including binary trees, non-crossing partitions, and spanning trees. This paper focuses on a related category of Catalan-like structures: the triangulations of polygons. A triangulation \\( T \\) of a simple polygon \\( P \\) is defined as the inclusion of all edges of \\( P \\) along with additional diagonals that connect pairs of vertices, ensuring that each interior angle of \\( P \\) is at least 90 degrees post-addition of these diagonals. Consequently, it follows that each edge is associated with exactly one diagonal in \\( T \\).\n\nMotzkin and Straus's renowned theorem states that if \\( D \\) represents the set of diagonals of a convex polygon \\( Q \\), then the cardinality of \\( D \\) is twice the number of vertices in \\( Q \\). They also established that the number of diagonalizations \\( d(P) \\) of a convex polygon \\( P \\) corresponds to the count of diagonals in its triangulation. Recent findings indicate that the number of diagonals in a triangulation of a convex quadrilateral is four times the number required for its diagonalization. This leads us to a compelling question: What is the precise relationship between the diagonals necessary for diagonalizing a convex quadrilateral and those utilized in its triangulation? This research aims to provide insights into this relationship and further our understanding of the combinatorial structures associated with Catalan numbers.",
        "ori-fast-z-score": 0.5669467095138409,
        "water-fast-z-score": 4.3465914396061125,
        "rewrite-fast-z-score": -0.2773500981126145
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Characterization of open cluster remnants .\nAbstract:\nWe present the results of an analysis of archival Hubble Space Telescope (HST) data for two open clusters, NGC 6705 and NGC 6819. We use these observations to determine ages, masses, radii, and distances for each star in both clusters using isochrone fitting techniques. The resulting mass functions are then compared with those predicted by theoretical models. Our main conclusions are:  1. Both clusters have similar age distributions but different mass distributions.  2. The observed mass function slopes agree well with predictions made by standard IMF theory when we assume that all stars more massive than 8 Msun were destroyed during supernovae explosions.  3. There appears to be no significant difference between the number of low-mass stars found within the central regions of the clusters as opposed to their outer regions. 4. The total number of high-mass stars in the clusters agrees very well with the expected number based on our knowledge of the initial mass function.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Characterization of open cluster remnants . Abstract : We report the conclusion of an assessment of archival Hubble Space Telescope ( HST ) images for two open complexes , NGC 6705 and NGC 6819 .We use these observations to predict ages , masses , radii , and distances for each star in both clusters using isochrone fit techniques . The resulting mass distributions are then estimated with those predicted by theoretical estimates .Our main results are : 1 . Both clusters have similar aging distributions but different mass distributions .2 . The observed mass function slopes agree well with predictions making by typical IMF physics when we suppose that all stars more massive than 8 Msun were destroyed during supernovae explosions .3 . There seems to be no major variation between the quantity of low - weight stars found within the main regions of the clusters as opposed to their exterior areas .4 . The total number of high - mass stars in the clusters agrees very best with the expected number depending on our know of the initial mass function .",
        "rewrite_text": "We present the findings of our comprehensive analysis of archival Hubble Space Telescope (HST) images focusing on two open clusters, NGC 6705 and NGC 6819. This study aims to derive key astrophysical parameters, including ages, masses, radii, and distances for individual stars within both clusters, utilizing isochrone fitting techniques. Our analysis reveals that while both clusters exhibit similar age distributions, they display distinct mass distributions. We further compare the observed mass functions with theoretical predictions, particularly in the context of the initial mass function (IMF). Our results indicate that the slopes of the observed mass functions align closely with those anticipated by standard IMF models, particularly under the assumption that all stars exceeding 8 solar masses have been eliminated due to supernova events. Additionally, we find no significant differences in the abundance of low-mass stars between the central regions of the clusters and their outer areas. Furthermore, the total count of high-mass stars within the clusters is consistent with expectations derived from our understanding of the initial mass function. These findings contribute to the broader understanding of the evolution and characteristics of open cluster remnants, providing valuable insights into stellar population dynamics and the lifecycle of stars in these environments.",
        "ori-fast-z-score": -0.7504787743864564,
        "water-fast-z-score": 4.90361647617904,
        "rewrite-fast-z-score": -0.4833682445228318
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Recent progresses in the simulation of small-scale magnetic fields .\nAbstract:\nThe origin and evolution of cosmic magnetic fields are one of the most important unsolved problems in astrophysics, which is closely related to many other fundamental issues such as star formation, galaxy formation and structure formation. In this talk I will review our recent work on simulating primordial magnetic fields with different physical processes involved. The first part focuses on the generation of seed magnetic fields during inflation by quantum fluctuations. We show that these seeds can be amplified significantly after reheating due to the magnetohydrodynamic turbulence driven by the decaying inflaton perturbations. Then we discuss how these seeds evolve into large-scale coherent magnetic fields through various mechanisms including inverse cascade, dynamo action and turbulent pumping. Finally, we present some possible observational signatures for future detection. This talk was given at the International Conference on Computation & Theory (ICCT) held in Beijing, China between September 24-27, 2014.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Recent progresses in the simulation of tiny - scale magnetic fields . Abstract : The origin and evolution of cosmic magnetic waves are one of the most important unsolved issues in astrophysics , which is closely related to many other fundamental issues such as galaxy formation , galaxy formation and shape formation .In this talk I will review our latest work on simulating primordial magnetic waves with various physical processes implicated . The first part involves on the generation of seed magnetic waves during inflation by quantum fluctuations .We see that these plants can be amplified significantly after reheating due to the magnetohydrodynamic turbulence driven by the decaying inflaton perturbations . Then we talk how these plants transform into huge - scale coherent magnetic fields through several mechanisms namely inverse cascade , dynamo action and turbulent pumping .Finally , we present some possible observational signatures for future detection . This discussion was given at the International Conference on Computation & Theory ( ICCT ) holding in Beijing , China between September 24 - 27 , 2014 .",
        "rewrite_text": "**Title:** Recent Advances in the Simulation of Small-Scale Magnetic Fields\n\n**Abstract:** The origin and evolution of cosmic magnetic fields represent one of the most significant unresolved challenges in astrophysics, intricately linked to various fundamental phenomena, including galaxy formation and the shaping of cosmic structures. In this presentation, I will provide an overview of our recent research focused on simulating primordial magnetic fields, incorporating a range of physical processes. The initial segment of our study examines the generation of seed magnetic fields during the inflationary epoch, driven by quantum fluctuations. Our findings indicate that these primordial fields can undergo substantial amplification post-reheating, primarily due to magnetohydrodynamic turbulence induced by decaying inflaton perturbations. Subsequently, we explore the mechanisms through which these seed fields evolve into large-scale coherent magnetic structures. Key processes discussed include inverse cascade, dynamo action, and turbulent pumping, each contributing to the transformation of small-scale fluctuations into more organized magnetic fields. Finally, we will highlight potential observational signatures that could facilitate future detection of these cosmic magnetic phenomena. This research was presented at the International Conference on Computation & Theory (ICCT), held in Beijing, China, from September 24 to 27, 2014. Through this work, we aim to deepen our understanding of the role of magnetic fields in the universe and their implications for cosmic evolution.",
        "ori-fast-z-score": -0.8944271909999159,
        "water-fast-z-score": 4.196397990844169,
        "rewrite-fast-z-score": -0.7035264706814485
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  Larkin-Ovchinnikov-Fulde-Ferrell state in two-color quark matter .\nAbstract:\nWe study the ground-state properties of two-flavor color superconducting (2SC) quark matter at finite density and temperature by using an effective chiral model with vector interaction, which is derived from QCD under the mean-field approximation. We find that there exists a new type of 2SC phase where quarks are paired into diquark condensates with different colors but same flavor. This novel phase has been named as Larkin-Ovchinnikova-Fulde-Ferreell (LOFF) state because it was first proposed to describe superfluidity in nuclear systems. In this LOFF state, we show that the gap parameter for pairing between quarks with opposite momenta depends on their relative angle. The magnitude of the gap decreases rapidly when they move away from each other along the Fermi surface. As a result, the energy gap vanishes completely near the boundary of the Brillouin zone.",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : Larkin - Ovchinnikov - Fulde - Ferrell state in two - color quark matter . Abstract : We research the ground - state properties of two - flavor color superconducting ( 2SC ) quark matter at finite density and heat by using an efficient chiral description with vector interaction , which is generated from QCD under the mean - field approximation .We see that there exists a new kind of 2SC cycle where quarks are paired into diquark condensates with various colors but same flavor . This novel mode has been called as Larkin - Ovchinnikova - Fulde - Ferreell ( LOFF ) state because it was first suggested to explain superfluidity in nuclear systems .In this LOFF state , we find that the gap parameter for pairing between quarks with opposite momenta depends on their relative angle . The magnitude of the gap falls swiftly when they change apart from each other along the Fermi surface .As a result , the power gap vanishes totally near the boundary of the Brillouin zone .",
        "rewrite_text": "In this study, we investigate the ground-state characteristics of two-flavor color superconducting (2SC) quark matter under conditions of finite density and temperature. Utilizing an effective chiral framework that incorporates vector interactions derived from quantum chromodynamics (QCD) within the mean-field approximation, we uncover the existence of a novel 2SC cycle. In this cycle, quarks form diquark condensates that exhibit varying colors while maintaining the same flavor. This intriguing phenomenon is referred to as the Larkin-Ovchinnikov-Fulde-Ferrell (LOFF) state, a concept initially proposed to elucidate superfluidity in nuclear matter.\n\nOur analysis reveals that within the LOFF state, the pairing gap parameter for quarks with opposing momenta is influenced by their relative angular separation. Notably, we observe that the magnitude of this gap diminishes rapidly as the quarks move apart along the Fermi surface. This behavior leads to a complete disappearance of the pairing gap near the edges of the Brillouin zone, indicating a significant spatial dependence of the pairing mechanism. The implications of these findings are profound, as they not only enhance our understanding of the complex dynamics of quark matter but also contribute to the broader discourse on superconductivity and superfluidity in quantum systems. This research paves the way for further exploration of the interplay between color superconductivity and the fundamental properties of matter under extreme conditions, potentially shedding light on phenomena observed in astrophysical environments such as neutron stars.",
        "ori-fast-z-score": -2.0465595024580763,
        "water-fast-z-score": 2.8685486624025445,
        "rewrite-fast-z-score": 1.0838622059807226
    },
    {
        "original_text": "Write a long abstract of a scientific paper from arXiv.org. Use approximately 200-400 words.\nTitle:  The inefficiency of the first-order Fermi process in UHECR production at relativistic shocks .\nAbstract:\nWe study the efficiency of cosmic ray (CR) acceleration by relativistic shocks using Monte Carlo simulations and analytical calculations. We find that, for strong shocks with Mach number M = 10 - 100, only about 1% CRs can be accelerated to ultra-high energy (UHE). This is because most particles are scattered back upstream before they gain enough energy to cross the shock front again. The low efficiency of UHE particle production leads to an upper limit on the maximum proton energy as well as the total CR luminosity produced by such shocks. Our results suggest that the observed fluxes of UHE protons cannot be explained solely by diffusive shock acceleration mechanism operating at cosmological shocks. However, our findings do not rule out other mechanisms proposed recently to explain the origin of UHE cosmic rays. \n \n Keywords: Cosmic Ray Acceleration, Diffusive Shock Acceleration, Relativistic Shocks",
        "watermark_text": "Write a long abstract of a scientific article from arXiv . org . Use approximately 200 - 400 words .Title : The inefficiency of the first - order Fermi process in UHECR manufacturing at relativistic shocks . Abstract : We research the performance of cosmic ray ( CR ) velocity by relativistic shocks using Monte Carlo simulations and mathematical calculations .We see that , for strong shocks with Mach number M = 10 - 100 , only about 1 % CRs can be advanced to ultra - large energy ( UHE ) . This is because most objects are scattered backward upstream before they get enough energy to pass the shock front again .The poor efficiency of UHE particle production gives to an upper limitation on the maximum proton power as well as the total CR luminosity generated by such shocks . Our results show that the observed fluxes of UHE protons impossible be described solely by diffusive blast acceleration processes operating at cosmological shocks .However , our findings do not leave out other mechanisms proposed lately to explain the origin of UHE cosmic rays . Keywords : Cosmic Ray Acceleration , Diffusive Shock Acceleration , Relativistic Shocks",
        "rewrite_text": "Title: The Inefficiency of the First-Order Fermi Process in Ultra-High-Energy Cosmic Ray Production at Relativistic Shocks\n\nAbstract: In this study, we investigate the efficiency of cosmic ray (CR) acceleration at relativistic shocks through a combination of Monte Carlo simulations and analytical calculations. Our analysis focuses on strong shocks characterized by Mach numbers ranging from 10 to 100. We find that only approximately 1% of cosmic rays achieve ultra-high energy (UHE) levels, primarily due to the tendency of most particles to be scattered back upstream before they can gain sufficient energy to traverse the shock front again. This limited efficiency in UHE particle production imposes a significant upper bound on both the maximum proton energy and the total cosmic ray luminosity that can be generated by such shocks. Our results indicate that the observed fluxes of UHE protons cannot be adequately explained by diffusive shock acceleration processes alone, particularly those occurring at cosmological shocks. Nevertheless, our findings do not dismiss the potential contributions of alternative mechanisms that have been proposed recently to account for the origins of UHE cosmic rays. This research highlights the complexities involved in cosmic ray acceleration and underscores the need for a broader understanding of the various processes that may contribute to the generation of UHECRs. \n\nKeywords: Cosmic Ray Acceleration, Diffusive Shock Acceleration, Relativistic Shocks",
        "ori-fast-z-score": -2.0768805540571886,
        "water-fast-z-score": 5.176591682688076,
        "rewrite-fast-z-score": -0.8528028654224417
    }
]